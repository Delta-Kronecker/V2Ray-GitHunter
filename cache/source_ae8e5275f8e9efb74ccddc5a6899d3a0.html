






<!DOCTYPE html>
<html
  lang="en"
  
  data-color-mode="auto" data-light-theme="light" data-dark-theme="dark"
  data-a11y-animated-images="system" data-a11y-link-underlines="true"
  
  >




  <head>
    <meta charset="utf-8">
  <link rel="dns-prefetch" href="https://github.githubassets.com">
  <link rel="dns-prefetch" href="https://avatars.githubusercontent.com">
  <link rel="dns-prefetch" href="https://github-cloud.s3.amazonaws.com">
  <link rel="dns-prefetch" href="https://user-images.githubusercontent.com/">
  <link rel="preconnect" href="https://github.githubassets.com" crossorigin>
  <link rel="preconnect" href="https://avatars.githubusercontent.com">

  

  <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/light-44e67b0cd5d5.css" /><link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/light_high_contrast-b51c2fae25e8.css" /><link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/dark-cb035ed575b8.css" /><link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/dark_high_contrast-99e9b1169976.css" /><link data-color-theme="light" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light-44e67b0cd5d5.css" /><link data-color-theme="light_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light_high_contrast-b51c2fae25e8.css" /><link data-color-theme="light_colorblind" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light_colorblind-dadcba82130c.css" /><link data-color-theme="light_colorblind_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light_colorblind_high_contrast-cdc36145225e.css" /><link data-color-theme="light_tritanopia" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light_tritanopia-0ca195e3b5f3.css" /><link data-color-theme="light_tritanopia_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light_tritanopia_high_contrast-f9fb5556a83f.css" /><link data-color-theme="dark" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark-cb035ed575b8.css" /><link data-color-theme="dark_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_high_contrast-99e9b1169976.css" /><link data-color-theme="dark_colorblind" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_colorblind-9541c4141757.css" /><link data-color-theme="dark_colorblind_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_colorblind_high_contrast-bc604fc65912.css" /><link data-color-theme="dark_tritanopia" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_tritanopia-384776200fd7.css" /><link data-color-theme="dark_tritanopia_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_tritanopia_high_contrast-489c70dedd0a.css" /><link data-color-theme="dark_dimmed" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_dimmed-1545a2e9e540.css" /><link data-color-theme="dark_dimmed_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_dimmed_high_contrast-4c1792a987c3.css" />

  <style type="text/css">
    :root {
      --tab-size-preference: 4;
    }

    pre, code {
      tab-size: var(--tab-size-preference);
    }
  </style>

    <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-primitives-15839d47b75d.css" />
    <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-a5c85403da8c.css" />
    <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/global-4d11e88b2383.css" />
    <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/github-6aeb6451a33d.css" />
  <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/repository-5d735668c600.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/code-9c9b8dc61e74.css" />

  

  <script type="application/json" id="client-env">{"locale":"en","featureFlags":["alternate_user_config_repo","api_insights_show_missing_data_banner","attestations_filtering","attestations_sorting","billing_unfiltered_discounts","client_version_header","codespaces_prebuild_region_target_update","contentful_lp_footnotes","copilot_agent_cli_public_preview","copilot_agent_task_list_v2","copilot_agent_tasks_btn_code_nav","copilot_agent_tasks_btn_code_view","copilot_agent_tasks_btn_code_view_lines","copilot_api_agentic_issue_marshal_yaml","copilot_api_github_draft_update_issue_skill","copilot_chat_attach_multiple_images","copilot_chat_file_redirect","copilot_chat_reduce_quota_checks","copilot_chat_search_bar_redirect","copilot_chat_selection_attachments","copilot_chat_vision_in_claude","copilot_chat_vision_skip_thread_create","copilot_custom_copilots","copilot_custom_copilots_feature_preview","copilot_duplicate_thread","copilot_extensions_deprecation_notice","copilot_features_raycast_logo","copilot_file_block_ref_matching","copilot_free_to_paid_telem","copilot_ftp_hyperspace_upgrade_prompt","copilot_ftp_settings_upgrade","copilot_ftp_upgrade_to_pro_from_models","copilot_ftp_your_copilot_settings","copilot_generate_commit_message_dry_regenerate","copilot_immersive_structured_model_picker","copilot_immersive_task_within_chat_thread","copilot_insights_column_chart_axis_legibility_fix","copilot_insights_usage_export_ndjson","copilot_mission_control_feedback","copilot_mission_control_session_feedback","copilot_no_floating_button","copilot_read_shared_conversation","copilot_spaces_as_attachments","copilot_spaces_ga","copilot_spark_loading_webgl","copilot_spark_progressive_error_handling","copilot_spark_read_iteration_history_from_git_v2","copilot_spark_use_billing_headers","copilot_spark_write_iteration_history_to_git","copilot_stable_conversation_view","copilot_workbench_agent_seed_tool","copilot_workbench_cache","copilot_workbench_connection_reload_banner","copilot_workbench_preview_analytics","copilot_workbench_skip_repo_on_codespace","copilot_workbench_use_single_prompt","direct_to_salesforce","disable_dashboard_universe_2025_private_preview","dotcom_chat_client_side_skills","failbot_report_error_react_apps_on_page","ghost_pilot_confidence_truncation_25","ghost_pilot_confidence_truncation_40","global_search_multi_orgs","hpc_improve_dom_insertion_observer","inp_reduced_threshold","insert_before_patch","issue_fields_report_usage","issues_copilot_cross_repo_assign","issues_react_blur_item_picker_on_close","issues_react_bots_timeline_pagination","issues_react_prohibit_title_fallback","issues_react_remove_placeholders","issues_sticky_sidebar","kb_convert_to_space","lifecycle_label_name_updates","link_contact_sales_swp_marketo","marketing_pages_search_explore_provider","mcp_registry_install","memex_mwl_filter_field_delimiter","migrate_toasts_to_banners_web_notifications","new_traffic_page_banner","open_agent_session_in_vscode_insiders","pinned_issue_fields","primer_react_segmented_control_tooltip","primer_react_unified_portal_root","record_sso_banner_metrics","ref_selector_create_tag_dialog","remove_child_patch","report_hydro_web_vitals","repos_insights_remove_new_url","sample_network_conn_type","scheduled_reminders_updated_limits","site_homepage_collaborate_video","site_homepage_contentful","site_msbuild_webgl_hero","spark_fix_rename","spark_force_push_after_checkout","spark_kv_encocoded_keys","spark_show_data_access_on_publish","spark_sync_repository_after_iteration","viewscreen_sandbox","webp_support","workbench_store_readonly"],"copilotApiOverrideUrl":"https://api.githubcopilot.com"}</script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/high-contrast-cookie-f3788027bd8d.js"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/wp-runtime-b73258c5aaae.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_oddbird_popover-polyfill_dist_popover-fn_js-468bf7cab607.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_stacktrace-parser_dist_stack-trace-parser_esm_js-node_modules_github_bro-2f4e04-280c10ec004d.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/environment-b4e74adb6411.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_primer_behaviors_dist_esm_index_mjs-3eee64e5ddf0.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_selector-observer_dist_index_esm_js-9ab93471824e.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_relative-time-element_dist_index_js-ef89d23fcc0a.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_auto-complete-element_dist_index_js-node_modules_github_catalyst_-0d7d60-ad3a87b2f0eb.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_text-expander-element_dist_index_js-754f5b5e9e7e.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_filter-input-element_dist_index_js-node_modules_github_remote-inp-665e70-ac788066c220.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_markdown-toolbar-element_dist_index_js-d41270eb61be.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_file-attachment-element_dist_index_js-node_modules_primer_view-co-777ce2-9ec8c103bf42.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/github-elements-9e1d42c09c62.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/element-registry-212230e65885.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_braintree_browser-detection_dist_browser-detection_js-node_modules_githu-bb80ec-f11c694928ba.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_lit-html_lit-html_js-9012bef51135.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_mini-throttle_dist_index_js-node_modules_morphdom_dist_morphdom-e-c1896e-ba47f43192a8.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_remote-form_dist_index_js-node_modules_delegated-events_dist_inde-893f9f-9ba0881c72fb.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_turbo_dist_turbo_es2017-esm_js-8eb9b2209bcd.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_hotkey_dist_index_js-node_modules_github_hydro-analytics-client_d-dd3ec8-1f3d5f90de2b.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_quote-selection_dist_index_js-node_modules_github_session-resume_-31b9f3-9021ed20220b.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/packages_document-metadata_document-metadata_ts-packages_failbot_failbot_ts-06156f7d8d1a.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/packages_updatable-content_updatable-content_ts-38f5e2f7c2a7.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/app_assets_modules_github_behaviors_ajax-error_ts-app_assets_modules_github_behaviors_details-6493f1-cecb020e2bb7.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/app_assets_modules_github_behaviors_task-list_ts-app_assets_modules_github_throttled-input_ts-047775-cfe8770908d1.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/app_assets_modules_github_behaviors_commenting_edit_ts-app_assets_modules_github_behaviors_ht-83c235-d8c5bfe37d1d.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/behaviors-d431b500aedc.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_delegated-events_dist_index_js-node_modules_github_catalyst_lib_index_js-ef6d0f-20d6767cecc0.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/notifications-global-d89a4ddd4532.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_virtualized-list_es_index_js-node_modules_github_template-parts_lib_inde-f69fd1-ead47121f2f7.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_remote-form_dist_index_js-node_modules_delegated-events_dist_inde-0d71a9-129b4f34d384.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/app_assets_modules_github_ref-selector_ts-63ecfa2887c1.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/codespaces-8cfd06ba3e39.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_filter-input-element_dist_index_js-node_modules_github_remote-inp-3eebbd-7f6bf4b8b391.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_mini-throttle_dist_decorators_js-node_modules_delegated-events_di-e161aa-9086b9aee9d1.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_file-attachment-element_dist_index_js-node_modules_github_remote--abdaf7-71f92102de66.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/repositories-7c2a36f9c401.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_mini-throttle_dist_index_js-node_modules_github_catalyst_lib_inde-96937f-70732ff56a20.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/code-menu-614eb4e0c016.js" defer="defer"></script>
  
  <script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/primer-react-cdd6dd11a475.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/react-lib-25ef56e89e94.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/react-core-26c9e2751844.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/octicons-react-dfcd3f5e8531.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_emotion_is-prop-valid_dist_emotion-is-prop-valid_esm_js-node_modules_emo-825c28-cdae255a4bbc.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_mini-throttle_dist_index_js-node_modules_github_hydro-analytics-c-c228f9-e9af1d9bff76.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_tanstack_query-core_build_modern_mutation_js-node_modules_tanstack_query-9bf7e4-2246c69bea10.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_swc_helpers_esm__class_private_method_get_js-node_modules_swc_helpers_es-d6b1a6-13297632eddc.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/packages_notifications-subscriptions-menu_entry_ts-packages_promise-with-resolvers-polyfill_p-15cb60-9c0f034a796f.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/notifications-subscriptions-menu-c28df4f8626e.js" defer="defer"></script>
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.f595f41454298e934d3c.module.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/notifications-subscriptions-menu.bab8822ac328fb95c70d.module.css" />

  <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.f595f41454298e934d3c.module.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/notifications-subscriptions-menu.bab8822ac328fb95c70d.module.css" />


  <title>GitHub - coderonion/awesome-yolo-object-detection: ðŸš€ðŸš€ðŸš€ A collection of some awesome public YOLO object detection series projects and the related object detection datasets.</title>



  <meta name="route-pattern" content="/:user_id/:repository" data-turbo-transient>
  <meta name="route-controller" content="files" data-turbo-transient>
  <meta name="route-action" content="disambiguate" data-turbo-transient>
  <meta name="fetch-nonce" content="v2:515a6721-8eb7-ba0a-7b66-e450a60aff90">

    
  <meta name="current-catalog-service-hash" content="f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb">


  <meta name="request-id" content="DC02:1A434F:BBDD2F:102D5A8:68FB563D" data-pjax-transient="true"/><meta name="html-safe-nonce" content="6c5b79325121764f3e7b2f56b9c435114922256726d86663d3013d53b5286b15" data-pjax-transient="true"/><meta name="visitor-payload" content="eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiJEQzAyOjFBNDM0RjpCQkREMkY6MTAyRDVBODo2OEZCNTYzRCIsInZpc2l0b3JfaWQiOiIxNzM1NDgyNjc5ODk0OTU1NTQ1IiwicmVnaW9uX2VkZ2UiOiJpYWQiLCJyZWdpb25fcmVuZGVyIjoiaWFkIn0=" data-pjax-transient="true"/><meta name="visitor-hmac" content="3b1b408113ffae2575a6091d8fdfc2a9b1f31eb125b6a77b0ecc8f942595d433" data-pjax-transient="true"/>


    <meta name="hovercard-subject-tag" content="repository:461270746" data-turbo-transient>


  <meta name="github-keyboard-shortcuts" content="repository,copilot" data-turbo-transient="true" />
  

  <meta name="selected-link" value="repo_source" data-turbo-transient>
  <link rel="assets" href="https://github.githubassets.com/">

    <meta name="google-site-verification" content="Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I">

<meta name="octolytics-url" content="https://collector.github.com/github/collect" />

  <meta name="analytics-location" content="/&lt;user-name&gt;/&lt;repo-name&gt;" data-turbo-transient="true" />

  




    <meta name="user-login" content="">

  

    <meta name="viewport" content="width=device-width">

    

      <meta name="description" content="ðŸš€ðŸš€ðŸš€ A collection of some awesome public YOLO object detection series projects and the related object detection datasets. - coderonion/awesome-yolo-object-detection">

      <link rel="search" type="application/opensearchdescription+xml" href="/opensearch.xml" title="GitHub">

    <link rel="fluid-icon" href="https://github.com/fluidicon.png" title="GitHub">
    <meta property="fb:app_id" content="1401488693436528">
    <meta name="apple-itunes-app" content="app-id=1477376905, app-argument=https://github.com/coderonion/awesome-yolo-object-detection" />

      <meta name="twitter:image" content="https://opengraph.githubassets.com/35910d5b1c76bcd0169b4fb1bc83b8c2324a4caeef65559bac5ad6c45cf5ec13/coderonion/awesome-yolo-object-detection" /><meta name="twitter:site" content="@github" /><meta name="twitter:card" content="summary_large_image" /><meta name="twitter:title" content="GitHub - coderonion/awesome-yolo-object-detection: ðŸš€ðŸš€ðŸš€ A collection of some awesome public YOLO object detection series projects and the related object detection datasets." /><meta name="twitter:description" content="ðŸš€ðŸš€ðŸš€ A collection of some awesome public YOLO object detection series projects and the related object detection datasets. - coderonion/awesome-yolo-object-detection" />
  <meta property="og:image" content="https://opengraph.githubassets.com/35910d5b1c76bcd0169b4fb1bc83b8c2324a4caeef65559bac5ad6c45cf5ec13/coderonion/awesome-yolo-object-detection" /><meta property="og:image:alt" content="ðŸš€ðŸš€ðŸš€ A collection of some awesome public YOLO object detection series projects and the related object detection datasets. - coderonion/awesome-yolo-object-detection" /><meta property="og:image:width" content="1200" /><meta property="og:image:height" content="600" /><meta property="og:site_name" content="GitHub" /><meta property="og:type" content="object" /><meta property="og:title" content="GitHub - coderonion/awesome-yolo-object-detection: ðŸš€ðŸš€ðŸš€ A collection of some awesome public YOLO object detection series projects and the related object detection datasets." /><meta property="og:url" content="https://github.com/coderonion/awesome-yolo-object-detection" /><meta property="og:description" content="ðŸš€ðŸš€ðŸš€ A collection of some awesome public YOLO object detection series projects and the related object detection datasets. - coderonion/awesome-yolo-object-detection" />
  




      <meta name="hostname" content="github.com">



        <meta name="expected-hostname" content="github.com">


  <meta http-equiv="x-pjax-version" content="edb0d926ab1906770550b20a43d9b38dd31aa9f43125e46b0f03b199f9f5ffc9" data-turbo-track="reload">
  <meta http-equiv="x-pjax-csp-version" content="21a43568025709b66240454fc92d4f09335a96863f8ab1c46b4a07f6a5b67102" data-turbo-track="reload">
  <meta http-equiv="x-pjax-css-version" content="9a5723604920ed305ee49e39cb1005f635d72600a9d3ee8570586b8be07865c3" data-turbo-track="reload">
  <meta http-equiv="x-pjax-js-version" content="e219e7f22a568c92e2760b3fa72fe03f661aed0635cfdd507899c28619d497b7" data-turbo-track="reload">

  <meta name="turbo-cache-control" content="no-preview" data-turbo-transient="">

      <meta data-hydrostats="publish">
  <meta name="go-import" content="github.com/coderonion/awesome-yolo-object-detection git https://github.com/coderonion/awesome-yolo-object-detection.git">

  <meta name="octolytics-dimension-user_id" content="99076655" /><meta name="octolytics-dimension-user_login" content="coderonion" /><meta name="octolytics-dimension-repository_id" content="461270746" /><meta name="octolytics-dimension-repository_nwo" content="coderonion/awesome-yolo-object-detection" /><meta name="octolytics-dimension-repository_public" content="true" /><meta name="octolytics-dimension-repository_is_fork" content="false" /><meta name="octolytics-dimension-repository_network_root_id" content="461270746" /><meta name="octolytics-dimension-repository_network_root_nwo" content="coderonion/awesome-yolo-object-detection" />



      <link rel="canonical" href="https://github.com/coderonion/awesome-yolo-object-detection" data-turbo-transient>


    <meta name="turbo-body-classes" content="logged-out env-production page-responsive">


  <meta name="browser-stats-url" content="https://api.github.com/_private/browser/stats">

  <meta name="browser-errors-url" content="https://api.github.com/_private/browser/errors">

  <meta name="release" content="52b212fa9d89c9c0399bcd8a7727377c16297ef9">
  <meta name="ui-target" content="full">

  <link rel="mask-icon" href="https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg" color="#000000">
  <link rel="alternate icon" class="js-site-favicon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png">
  <link rel="icon" class="js-site-favicon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" data-base-href="https://github.githubassets.com/favicons/favicon">

<meta name="theme-color" content="#1e2327">
<meta name="color-scheme" content="light dark" />


  <link rel="manifest" href="/manifest.json" crossOrigin="use-credentials">

  </head>

  <body class="logged-out env-production page-responsive" style="word-wrap: break-word;">
    <div data-turbo-body class="logged-out env-production page-responsive" style="word-wrap: break-word;">
      



    <div class="position-relative header-wrapper js-header-wrapper ">
      <a href="#start-of-content" data-skip-target-assigned="false" class="px-2 py-4 color-bg-accent-emphasis color-fg-on-emphasis show-on-focus js-skip-to-content">Skip to content</a>

      <span data-view-component="true" class="progress-pjax-loader Progress position-fixed width-full">
    <span style="width: 0%;" data-view-component="true" class="Progress-item progress-pjax-loader-bar left-0 top-0 color-bg-accent-emphasis"></span>
</span>      
      
      <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.f595f41454298e934d3c.module.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/keyboard-shortcuts-dialog.2de9c7d6456a311fce49.module.css" />

<react-partial
  partial-name="keyboard-shortcuts-dialog"
  data-ssr="false"
  data-attempted-ssr="false"
  data-react-profiling="false"
>
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{"docsUrl":"https://docs.github.com/get-started/accessibility/keyboard-shortcuts"}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>





      

          

              
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_gsap_index_js-6265bea06e74.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_remote-form_dist_index_js-node_modules_delegated-events_dist_inde-94fd67-dc050877d1bf.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/sessions-917229b8a853.js" defer="defer"></script>

<header class="HeaderMktg header-logged-out js-details-container js-header Details f4 py-3" role="banner" data-is-top="true" data-color-mode=light data-light-theme=light data-dark-theme=dark>
  <h2 class="sr-only">Navigation Menu</h2>

  <button type="button" class="HeaderMktg-backdrop d-lg-none border-0 position-fixed top-0 left-0 width-full height-full js-details-target" aria-label="Toggle navigation">
    <span class="d-none">Toggle navigation</span>
  </button>

  <div class="d-flex flex-column flex-lg-row flex-items-center px-3 px-md-4 px-lg-5 height-full position-relative z-1">
    <div class="d-flex flex-justify-between flex-items-center width-full width-lg-auto">
      <div class="flex-1">
        <button aria-label="Toggle navigation" aria-expanded="false" type="button" data-view-component="true" class="js-details-target js-nav-padding-recalculate js-header-menu-toggle Button--link Button--medium Button d-lg-none color-fg-inherit p-1">  <span class="Button-content">
    <span class="Button-label"><div class="HeaderMenu-toggle-bar rounded my-1"></div>
            <div class="HeaderMenu-toggle-bar rounded my-1"></div>
            <div class="HeaderMenu-toggle-bar rounded my-1"></div></span>
  </span>
</button>
      </div>

      <a class="mr-lg-3 color-fg-inherit flex-order-2 js-prevent-focus-on-mobile-nav"
        href="/"
        aria-label="Homepage"
        data-analytics-event="{&quot;category&quot;:&quot;Marketing nav&quot;,&quot;action&quot;:&quot;click to go to homepage&quot;,&quot;label&quot;:&quot;ref_page:Marketing;ref_cta:Logomark;ref_loc:Header&quot;}">
        <svg height="32" aria-hidden="true" viewBox="0 0 24 24" version="1.1" width="32" data-view-component="true" class="octicon octicon-mark-github">
    <path d="M12 1C5.923 1 1 5.923 1 12c0 4.867 3.149 8.979 7.521 10.436.55.096.756-.233.756-.522 0-.262-.013-1.128-.013-2.049-2.764.509-3.479-.674-3.699-1.292-.124-.317-.66-1.293-1.127-1.554-.385-.207-.936-.715-.014-.729.866-.014 1.485.797 1.691 1.128.99 1.663 2.571 1.196 3.204.907.096-.715.385-1.196.701-1.471-2.448-.275-5.005-1.224-5.005-5.432 0-1.196.426-2.186 1.128-2.956-.111-.275-.496-1.402.11-2.915 0 0 .921-.288 3.024 1.128a10.193 10.193 0 0 1 2.75-.371c.936 0 1.871.123 2.75.371 2.104-1.43 3.025-1.128 3.025-1.128.605 1.513.221 2.64.111 2.915.701.77 1.127 1.747 1.127 2.956 0 4.222-2.571 5.157-5.019 5.432.399.344.743 1.004.743 2.035 0 1.471-.014 2.654-.014 3.025 0 .289.206.632.756.522C19.851 20.979 23 16.854 23 12c0-6.077-4.922-11-11-11Z"></path>
</svg>
      </a>

      <div class="d-flex flex-1 flex-order-2 text-right d-lg-none gap-2 flex-justify-end">
          <a
            href="/login?return_to=https%3A%2F%2Fgithub.com%2Fcoderonion%2Fawesome-yolo-object-detection"
            class="HeaderMenu-link HeaderMenu-button d-inline-flex f5 no-underline border color-border-default rounded-2 px-2 py-1 color-fg-inherit js-prevent-focus-on-mobile-nav"
            data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/coderonion/awesome-yolo-object-detection&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="58d2cabbb70ca01d75dca7c221ecbb07ba8bbb2e720c6b8e354fda024d7f8087"
            data-analytics-event="{&quot;category&quot;:&quot;Marketing nav&quot;,&quot;action&quot;:&quot;click to Sign in&quot;,&quot;label&quot;:&quot;ref_page:Marketing;ref_cta:Sign in;ref_loc:Header&quot;}"
          >
            Sign in
          </a>
              <div class="AppHeader-appearanceSettings">
    <react-partial-anchor>
      <button data-target="react-partial-anchor.anchor" id="icon-button-8127f96d-bcfd-417c-a05b-2e27b4b687f5" aria-labelledby="tooltip-f2a1ef8d-96d0-4b8e-85bd-6f6a5df3e496" type="button" disabled="disabled" data-view-component="true" class="Button Button--iconOnly Button--invisible Button--medium AppHeader-button HeaderMenu-link border cursor-wait">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-sliders Button-visual">
    <path d="M15 2.75a.75.75 0 0 1-.75.75h-4a.75.75 0 0 1 0-1.5h4a.75.75 0 0 1 .75.75Zm-8.5.75v1.25a.75.75 0 0 0 1.5 0v-4a.75.75 0 0 0-1.5 0V2H1.75a.75.75 0 0 0 0 1.5H6.5Zm1.25 5.25a.75.75 0 0 0 0-1.5h-6a.75.75 0 0 0 0 1.5h6ZM15 8a.75.75 0 0 1-.75.75H11.5V10a.75.75 0 1 1-1.5 0V6a.75.75 0 0 1 1.5 0v1.25h2.75A.75.75 0 0 1 15 8Zm-9 5.25v-2a.75.75 0 0 0-1.5 0v1.25H1.75a.75.75 0 0 0 0 1.5H4.5v1.25a.75.75 0 0 0 1.5 0v-2Zm9 0a.75.75 0 0 1-.75.75h-6a.75.75 0 0 1 0-1.5h6a.75.75 0 0 1 .75.75Z"></path>
</svg>
</button><tool-tip id="tooltip-f2a1ef8d-96d0-4b8e-85bd-6f6a5df3e496" for="icon-button-8127f96d-bcfd-417c-a05b-2e27b4b687f5" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.f595f41454298e934d3c.module.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.6c63a6de228d6520804d.module.css" />

<react-partial
  partial-name="appearance-settings"
  data-ssr="false"
  data-attempted-ssr="false"
  data-react-profiling="false"
>
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>


      </template>
    </react-partial-anchor>
  </div>

      </div>
    </div>


    <div class="HeaderMenu js-header-menu height-fit position-lg-relative d-lg-flex flex-column flex-auto top-0">
      <div class="HeaderMenu-wrapper d-flex flex-column flex-self-start flex-lg-row flex-auto rounded rounded-lg-0">
            <nav class="HeaderMenu-nav" aria-label="Global">
              <ul class="d-lg-flex list-style-none">
                  <li class="HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item">
      <button type="button" class="HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target" aria-expanded="false">
        Platform
        <svg opacity="0.5" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-down HeaderMenu-icon ml-1">
    <path d="M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z"></path>
</svg>
      </button>

      <div class="HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 pt-2 pt-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 dropdown-menu-wide">
        <div class="d-lg-flex dropdown-menu-wide">
            <div class="HeaderMenu-column px-lg-4">
                <div class="">

                  <ul class="list-style-none f5" >
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_platform_navbar&quot;}" href="https://github.com/features/copilot">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-copilot color-fg-subtle mr-3">
    <path d="M23.922 16.992c-.861 1.495-5.859 5.023-11.922 5.023-6.063 0-11.061-3.528-11.922-5.023A.641.641 0 0 1 0 16.736v-2.869a.841.841 0 0 1 .053-.22c.372-.935 1.347-2.292 2.605-2.656.167-.429.414-1.055.644-1.517a10.195 10.195 0 0 1-.052-1.086c0-1.331.282-2.499 1.132-3.368.397-.406.89-.717 1.474-.952 1.399-1.136 3.392-2.093 6.122-2.093 2.731 0 4.767.957 6.166 2.093.584.235 1.077.546 1.474.952.85.869 1.132 2.037 1.132 3.368 0 .368-.014.733-.052 1.086.23.462.477 1.088.644 1.517 1.258.364 2.233 1.721 2.605 2.656a.832.832 0 0 1 .053.22v2.869a.641.641 0 0 1-.078.256ZM12.172 11h-.344a4.323 4.323 0 0 1-.355.508C10.703 12.455 9.555 13 7.965 13c-1.725 0-2.989-.359-3.782-1.259a2.005 2.005 0 0 1-.085-.104L4 11.741v6.585c1.435.779 4.514 2.179 8 2.179 3.486 0 6.565-1.4 8-2.179v-6.585l-.098-.104s-.033.045-.085.104c-.793.9-2.057 1.259-3.782 1.259-1.59 0-2.738-.545-3.508-1.492a4.323 4.323 0 0 1-.355-.508h-.016.016Zm.641-2.935c.136 1.057.403 1.913.878 2.497.442.544 1.134.938 2.344.938 1.573 0 2.292-.337 2.657-.751.384-.435.558-1.15.558-2.361 0-1.14-.243-1.847-.705-2.319-.477-.488-1.319-.862-2.824-1.025-1.487-.161-2.192.138-2.533.529-.269.307-.437.808-.438 1.578v.021c0 .265.021.562.063.893Zm-1.626 0c.042-.331.063-.628.063-.894v-.02c-.001-.77-.169-1.271-.438-1.578-.341-.391-1.046-.69-2.533-.529-1.505.163-2.347.537-2.824 1.025-.462.472-.705 1.179-.705 2.319 0 1.211.175 1.926.558 2.361.365.414 1.084.751 2.657.751 1.21 0 1.902-.394 2.344-.938.475-.584.742-1.44.878-2.497Z"></path><path d="M14.5 14.25a1 1 0 0 1 1 1v2a1 1 0 0 1-2 0v-2a1 1 0 0 1 1-1Zm-5 0a1 1 0 0 1 1 1v2a1 1 0 0 1-2 0v-2a1 1 0 0 1 1-1Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          GitHub Copilot

        </div>

        Write better code with AI
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_spark&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_spark_link_platform_navbar&quot;}" href="https://github.com/features/spark">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-sparkle-fill color-fg-subtle mr-3">
    <path d="M11.296 1.924c.24-.656 1.168-.656 1.408 0l.717 1.958a11.25 11.25 0 0 0 6.697 6.697l1.958.717c.657.24.657 1.168 0 1.408l-1.958.717a11.25 11.25 0 0 0-6.697 6.697l-.717 1.958c-.24.657-1.168.657-1.408 0l-.717-1.958a11.25 11.25 0 0 0-6.697-6.697l-1.958-.717c-.656-.24-.656-1.168 0-1.408l1.958-.717a11.25 11.25 0 0 0 6.697-6.697l.717-1.958Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          GitHub Spark

            <span class="HeaderMenu-label">
              New
            </span>
        </div>

        Build and deploy intelligent apps
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_models&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_models_link_platform_navbar&quot;}" href="https://github.com/features/models">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-ai-model color-fg-subtle mr-3">
    <path d="M19.375 8.5a3.25 3.25 0 1 1-3.163 4h-3a3.252 3.252 0 0 1-4.443 2.509L7.214 17.76a3.25 3.25 0 1 1-1.342-.674l1.672-2.957A3.238 3.238 0 0 1 6.75 12c0-.907.371-1.727.97-2.316L6.117 6.846A3.253 3.253 0 0 1 1.875 3.75a3.25 3.25 0 1 1 5.526 2.32l1.603 2.836A3.25 3.25 0 0 1 13.093 11h3.119a3.252 3.252 0 0 1 3.163-2.5ZM10 10.25a1.75 1.75 0 1 0-.001 3.499A1.75 1.75 0 0 0 10 10.25ZM5.125 2a1.75 1.75 0 1 0 0 3.5 1.75 1.75 0 0 0 0-3.5Zm12.5 9.75a1.75 1.75 0 1 0 3.5 0 1.75 1.75 0 0 0-3.5 0Zm-14.25 8.5a1.75 1.75 0 1 0 3.501-.001 1.75 1.75 0 0 0-3.501.001Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          GitHub Models

            <span class="HeaderMenu-label">
              New
            </span>
        </div>

        Manage and compare prompts
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_platform_navbar&quot;}" href="https://github.com/security/advanced-security">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-shield-check color-fg-subtle mr-3">
    <path d="M16.53 9.78a.75.75 0 0 0-1.06-1.06L11 13.19l-1.97-1.97a.75.75 0 0 0-1.06 1.06l2.5 2.5a.75.75 0 0 0 1.06 0l5-5Z"></path><path d="m12.54.637 8.25 2.675A1.75 1.75 0 0 1 22 4.976V10c0 6.19-3.771 10.704-9.401 12.83a1.704 1.704 0 0 1-1.198 0C5.77 20.705 2 16.19 2 10V4.976c0-.758.489-1.43 1.21-1.664L11.46.637a1.748 1.748 0 0 1 1.08 0Zm-.617 1.426-8.25 2.676a.249.249 0 0 0-.173.237V10c0 5.46 3.28 9.483 8.43 11.426a.199.199 0 0 0 .14 0C17.22 19.483 20.5 15.461 20.5 10V4.976a.25.25 0 0 0-.173-.237l-8.25-2.676a.253.253 0 0 0-.154 0Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          GitHub Advanced Security

        </div>

        Find and fix vulnerabilities
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_platform_navbar&quot;}" href="https://github.com/features/actions">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-workflow color-fg-subtle mr-3">
    <path d="M1 3a2 2 0 0 1 2-2h6.5a2 2 0 0 1 2 2v6.5a2 2 0 0 1-2 2H7v4.063C7 16.355 7.644 17 8.438 17H12.5v-2.5a2 2 0 0 1 2-2H21a2 2 0 0 1 2 2V21a2 2 0 0 1-2 2h-6.5a2 2 0 0 1-2-2v-2.5H8.437A2.939 2.939 0 0 1 5.5 15.562V11.5H3a2 2 0 0 1-2-2Zm2-.5a.5.5 0 0 0-.5.5v6.5a.5.5 0 0 0 .5.5h6.5a.5.5 0 0 0 .5-.5V3a.5.5 0 0 0-.5-.5ZM14.5 14a.5.5 0 0 0-.5.5V21a.5.5 0 0 0 .5.5H21a.5.5 0 0 0 .5-.5v-6.5a.5.5 0 0 0-.5-.5Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Actions

        </div>

        Automate any workflow
      </div>

    
</a></li>

                  </ul>
                </div>
            </div>
            <div class="HeaderMenu-column px-lg-4 pb-3 pb-lg-0 border-lg-right">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 pb-3">

                  <ul class="list-style-none f5" >
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_platform_navbar&quot;}" href="https://github.com/features/codespaces">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-codespaces color-fg-subtle mr-3">
    <path d="M3.5 3.75C3.5 2.784 4.284 2 5.25 2h13.5c.966 0 1.75.784 1.75 1.75v7.5A1.75 1.75 0 0 1 18.75 13H5.25a1.75 1.75 0 0 1-1.75-1.75Zm-2 12c0-.966.784-1.75 1.75-1.75h17.5c.966 0 1.75.784 1.75 1.75v4a1.75 1.75 0 0 1-1.75 1.75H3.25a1.75 1.75 0 0 1-1.75-1.75ZM5.25 3.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h13.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Zm-2 12a.25.25 0 0 0-.25.25v4c0 .138.112.25.25.25h17.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25Z"></path><path d="M10 17.75a.75.75 0 0 1 .75-.75h6.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1-.75-.75Zm-4 0a.75.75 0 0 1 .75-.75h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1-.75-.75Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Codespaces

        </div>

        Instant dev environments
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_platform_navbar&quot;}" href="https://github.com/features/issues">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-issue-opened color-fg-subtle mr-3">
    <path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1ZM2.5 12a9.5 9.5 0 0 0 9.5 9.5 9.5 9.5 0 0 0 9.5-9.5A9.5 9.5 0 0 0 12 2.5 9.5 9.5 0 0 0 2.5 12Zm9.5 2a2 2 0 1 1-.001-3.999A2 2 0 0 1 12 14Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Issues

        </div>

        Plan and track work
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_platform_navbar&quot;}" href="https://github.com/features/code-review">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-code-review color-fg-subtle mr-3">
    <path d="M10.3 6.74a.75.75 0 0 1-.04 1.06l-2.908 2.7 2.908 2.7a.75.75 0 1 1-1.02 1.1l-3.5-3.25a.75.75 0 0 1 0-1.1l3.5-3.25a.75.75 0 0 1 1.06.04Zm3.44 1.06a.75.75 0 1 1 1.02-1.1l3.5 3.25a.75.75 0 0 1 0 1.1l-3.5 3.25a.75.75 0 1 1-1.02-1.1l2.908-2.7-2.908-2.7Z"></path><path d="M1.5 4.25c0-.966.784-1.75 1.75-1.75h17.5c.966 0 1.75.784 1.75 1.75v12.5a1.75 1.75 0 0 1-1.75 1.75h-9.69l-3.573 3.573A1.458 1.458 0 0 1 5 21.043V18.5H3.25a1.75 1.75 0 0 1-1.75-1.75ZM3.25 4a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h2.5a.75.75 0 0 1 .75.75v3.19l3.72-3.72a.749.749 0 0 1 .53-.22h10a.25.25 0 0 0 .25-.25V4.25a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Code Review

        </div>

        Manage code changes
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_platform_navbar&quot;}" href="https://github.com/features/discussions">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-comment-discussion color-fg-subtle mr-3">
    <path d="M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v9.5A1.75 1.75 0 0 1 14.25 14H8.061l-2.574 2.573A1.458 1.458 0 0 1 3 15.543V14H1.75A1.75 1.75 0 0 1 0 12.25v-9.5C0 1.784.784 1 1.75 1ZM1.5 2.75v9.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-9.5a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Z"></path><path d="M22.5 8.75a.25.25 0 0 0-.25-.25h-3.5a.75.75 0 0 1 0-1.5h3.5c.966 0 1.75.784 1.75 1.75v9.5A1.75 1.75 0 0 1 22.25 20H21v1.543a1.457 1.457 0 0 1-2.487 1.03L15.939 20H10.75A1.75 1.75 0 0 1 9 18.25v-1.465a.75.75 0 0 1 1.5 0v1.465c0 .138.112.25.25.25h5.5a.75.75 0 0 1 .53.22l2.72 2.72v-2.19a.75.75 0 0 1 .75-.75h2a.25.25 0 0 0 .25-.25v-9.5Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Discussions

        </div>

        Collaborate outside of code
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_platform_navbar&quot;}" href="https://github.com/features/code-search">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-code-square color-fg-subtle mr-3">
    <path d="M10.3 8.24a.75.75 0 0 1-.04 1.06L7.352 12l2.908 2.7a.75.75 0 1 1-1.02 1.1l-3.5-3.25a.75.75 0 0 1 0-1.1l3.5-3.25a.75.75 0 0 1 1.06.04Zm3.44 1.06a.75.75 0 1 1 1.02-1.1l3.5 3.25a.75.75 0 0 1 0 1.1l-3.5 3.25a.75.75 0 1 1-1.02-1.1l2.908-2.7-2.908-2.7Z"></path><path d="M2 3.75C2 2.784 2.784 2 3.75 2h16.5c.966 0 1.75.784 1.75 1.75v16.5A1.75 1.75 0 0 1 20.25 22H3.75A1.75 1.75 0 0 1 2 20.25Zm1.75-.25a.25.25 0 0 0-.25.25v16.5c0 .138.112.25.25.25h16.5a.25.25 0 0 0 .25-.25V3.75a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Code Search

        </div>

        Find more, search less
      </div>

    
</a></li>

                  </ul>
                </div>
            </div>
            <div class="HeaderMenu-column px-lg-4">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 mb-3 pb-3">

                      <span class="d-block h4 color-fg-default my-1" id="platform-explore-heading">Explore</span>

                  <ul class="list-style-none f5" aria-labelledby="platform-explore-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;why_github&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;why_github_link_platform_navbar&quot;}" href="https://github.com/why-github">
      Why GitHub

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary Link--external" target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;documentation&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;documentation_link_platform_navbar&quot;}" href="https://docs.github.com">
      Documentation

    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle">
    <path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path>
</svg>
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary Link--external" target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_skills&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_skills_link_platform_navbar&quot;}" href="https://skills.github.com">
      GitHub Skills

    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle">
    <path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path>
</svg>
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary Link--external" target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;blog&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;blog_link_platform_navbar&quot;}" href="https://github.blog">
      Blog

    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle">
    <path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path>
</svg>
</a></li>

                  </ul>
                </div>
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 pb-3">

                      <span class="d-block h4 color-fg-default my-1" id="platform-integrations-heading">Integrations</span>

                  <ul class="list-style-none f5" aria-labelledby="platform-integrations-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_marketplace&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_marketplace_link_platform_navbar&quot;}" href="https://github.com/marketplace">
      GitHub Marketplace

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;mcp_registry&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;mcp_registry_link_platform_navbar&quot;}" href="https://github.com/mcp">
      MCP Registry

    
</a></li>

                  </ul>
                </div>
            </div>
        </div>

          <div class="HeaderMenu-trailing-link rounded-bottom-2 mt-lg-4 px-lg-4 py-4 py-lg-3 f5 text-semibold">
            <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all_features&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_features_link_platform_navbar&quot;}" href="https://github.com/features">
              View all features
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-right HeaderMenu-trailing-link-icon">
    <path d="M6.22 3.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L9.94 8 6.22 4.28a.75.75 0 0 1 0-1.06Z"></path>
</svg>
</a>          </div>
      </div>
</li>


                  <li class="HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item">
      <button type="button" class="HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target" aria-expanded="false">
        Solutions
        <svg opacity="0.5" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-down HeaderMenu-icon ml-1">
    <path d="M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z"></path>
</svg>
      </button>

      <div class="HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 pt-2 pt-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 dropdown-menu-wide">
        <div class="d-lg-flex dropdown-menu-wide">
            <div class="HeaderMenu-column px-lg-4 pb-3 pb-lg-0 border-lg-right">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 pb-3">

                      <span class="d-block h4 color-fg-default my-1" id="solutions-by-company-size-heading">By company size</span>

                  <ul class="list-style-none f5" aria-labelledby="solutions-by-company-size-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprises&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprises_link_solutions_navbar&quot;}" href="https://github.com/enterprise">
      Enterprises

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;small_and_medium_teams&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;small_and_medium_teams_link_solutions_navbar&quot;}" href="https://github.com/team">
      Small and medium teams

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;startups&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;startups_link_solutions_navbar&quot;}" href="https://github.com/enterprise/startups">
      Startups

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;nonprofits&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;nonprofits_link_solutions_navbar&quot;}" href="/solutions/industry/nonprofits">
      Nonprofits

    
</a></li>

                  </ul>
                </div>
            </div>
            <div class="HeaderMenu-column px-lg-4 pb-3 pb-lg-0 border-lg-right">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 pb-3">

                      <span class="d-block h4 color-fg-default my-1" id="solutions-by-use-case-heading">By use case</span>

                  <ul class="list-style-none f5" aria-labelledby="solutions-by-use-case-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;app_modernization&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;app_modernization_link_solutions_navbar&quot;}" href="/solutions/use-case/app-modernization">
      App Modernization

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;devsecops&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;devsecops_link_solutions_navbar&quot;}" href="/solutions/use-case/devsecops">
      DevSecOps

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;devops&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;devops_link_solutions_navbar&quot;}" href="/solutions/use-case/devops">
      DevOps

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ci_cd&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ci_cd_link_solutions_navbar&quot;}" href="/solutions/use-case/ci-cd">
      CI/CD

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all_use_cases&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_use_cases_link_solutions_navbar&quot;}" href="/solutions/use-case">
      View all use cases

    
</a></li>

                  </ul>
                </div>
            </div>
            <div class="HeaderMenu-column px-lg-4">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 pb-3">

                      <span class="d-block h4 color-fg-default my-1" id="solutions-by-industry-heading">By industry</span>

                  <ul class="list-style-none f5" aria-labelledby="solutions-by-industry-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;healthcare&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;healthcare_link_solutions_navbar&quot;}" href="/solutions/industry/healthcare">
      Healthcare

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;financial_services&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;financial_services_link_solutions_navbar&quot;}" href="/solutions/industry/financial-services">
      Financial services

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;manufacturing&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;manufacturing_link_solutions_navbar&quot;}" href="/solutions/industry/manufacturing">
      Manufacturing

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;government&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;government_link_solutions_navbar&quot;}" href="/solutions/industry/government">
      Government

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all_industries&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_industries_link_solutions_navbar&quot;}" href="/solutions/industry">
      View all industries

    
</a></li>

                  </ul>
                </div>
            </div>
        </div>

          <div class="HeaderMenu-trailing-link rounded-bottom-2 mt-lg-4 px-lg-4 py-4 py-lg-3 f5 text-semibold">
            <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all_solutions&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_solutions_link_solutions_navbar&quot;}" href="/solutions">
              View all solutions
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-right HeaderMenu-trailing-link-icon">
    <path d="M6.22 3.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L9.94 8 6.22 4.28a.75.75 0 0 1 0-1.06Z"></path>
</svg>
</a>          </div>
      </div>
</li>


                  <li class="HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item">
      <button type="button" class="HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target" aria-expanded="false">
        Resources
        <svg opacity="0.5" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-down HeaderMenu-icon ml-1">
    <path d="M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z"></path>
</svg>
      </button>

      <div class="HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 pt-2 pt-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 pb-2 pb-lg-4 dropdown-menu-wide">
        <div class="d-lg-flex dropdown-menu-wide">
            <div class="HeaderMenu-column px-lg-4 pb-3 pb-lg-0 border-lg-right">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 pb-3">

                      <span class="d-block h4 color-fg-default my-1" id="resources-topics-heading">Topics</span>

                  <ul class="list-style-none f5" aria-labelledby="resources-topics-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ai&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ai_link_resources_navbar&quot;}" href="/resources/articles?topic=ai">
      AI

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;devops&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;devops_link_resources_navbar&quot;}" href="/resources/articles?topic=devops">
      DevOps

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;security&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;security_link_resources_navbar&quot;}" href="/resources/articles?topic=security">
      Security

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;software_development&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;software_development_link_resources_navbar&quot;}" href="/resources/articles?topic=software-development">
      Software Development

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_link_resources_navbar&quot;}" href="/resources/articles">
      View all

    
</a></li>

                  </ul>
                </div>
            </div>
            <div class="HeaderMenu-column px-lg-4">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 border-bottom-0">

                      <span class="d-block h4 color-fg-default my-1" id="resources-explore-heading">Explore</span>

                  <ul class="list-style-none f5" aria-labelledby="resources-explore-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary Link--external" target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle">
    <path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path>
</svg>
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;events_amp_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;events_amp_webinars_link_resources_navbar&quot;}" href="https://github.com/resources/events">
      Events &amp; Webinars

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ebooks_amp_whitepapers&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ebooks_amp_whitepapers_link_resources_navbar&quot;}" href="https://github.com/resources/whitepapers">
      Ebooks &amp; Whitepapers

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://github.com/partners">
      Partners

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                  </ul>
                </div>
            </div>
        </div>

      </div>
</li>


                  <li class="HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item">
      <button type="button" class="HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target" aria-expanded="false">
        Open Source
        <svg opacity="0.5" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-down HeaderMenu-icon ml-1">
    <path d="M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z"></path>
</svg>
      </button>

      <div class="HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 pt-2 pt-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 pb-2 pb-lg-4">
        <div class="d-lg-flex dropdown-menu-wide">
            <div class="HeaderMenu-column px-lg-4">
                <div class="border-bottom mb-3 mb-lg-3 pb-3">

                  <ul class="list-style-none f5" >
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="/sponsors">
      
      <div>
        <div class="color-fg-default h4">
          GitHub Sponsors

        </div>

        Fund open source developers
      </div>

    
</a></li>

                  </ul>
                </div>
                <div class="border-bottom mb-3 mb-lg-3 pb-3">

                  <ul class="list-style-none f5" >
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
        <div class="color-fg-default h4">
          The ReadME Project

        </div>

        GitHub community articles
      </div>

    
</a></li>

                  </ul>
                </div>
                <div class="border-bottom border-bottom-0">

                      <span class="d-block h4 color-fg-default my-1" id="open-source-repositories-heading">Repositories</span>

                  <ul class="list-style-none f5" aria-labelledby="open-source-repositories-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;topics&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;topics_link_open_source_navbar&quot;}" href="https://github.com/topics">
      Topics

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;trending&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;trending_link_open_source_navbar&quot;}" href="https://github.com/trending">
      Trending

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;collections&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;collections_link_open_source_navbar&quot;}" href="https://github.com/collections">
      Collections

    
</a></li>

                  </ul>
                </div>
            </div>
        </div>

      </div>
</li>


                  <li class="HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item">
      <button type="button" class="HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target" aria-expanded="false">
        Enterprise
        <svg opacity="0.5" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-down HeaderMenu-icon ml-1">
    <path d="M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z"></path>
</svg>
      </button>

      <div class="HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 pt-2 pt-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 pb-2 pb-lg-4">
        <div class="d-lg-flex dropdown-menu-wide">
            <div class="HeaderMenu-column px-lg-4">
                <div class="border-bottom mb-3 mb-lg-3 pb-3">

                  <ul class="list-style-none f5" >
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="/enterprise">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-stack color-fg-subtle mr-3">
    <path d="M11.063 1.456a1.749 1.749 0 0 1 1.874 0l8.383 5.316a1.751 1.751 0 0 1 0 2.956l-8.383 5.316a1.749 1.749 0 0 1-1.874 0L2.68 9.728a1.751 1.751 0 0 1 0-2.956Zm1.071 1.267a.25.25 0 0 0-.268 0L3.483 8.039a.25.25 0 0 0 0 .422l8.383 5.316a.25.25 0 0 0 .268 0l8.383-5.316a.25.25 0 0 0 0-.422Z"></path><path d="M1.867 12.324a.75.75 0 0 1 1.035-.232l8.964 5.685a.25.25 0 0 0 .268 0l8.964-5.685a.75.75 0 0 1 .804 1.267l-8.965 5.685a1.749 1.749 0 0 1-1.874 0l-8.965-5.685a.75.75 0 0 1-.231-1.035Z"></path><path d="M1.867 16.324a.75.75 0 0 1 1.035-.232l8.964 5.685a.25.25 0 0 0 .268 0l8.964-5.685a.75.75 0 0 1 .804 1.267l-8.965 5.685a1.749 1.749 0 0 1-1.874 0l-8.965-5.685a.75.75 0 0 1-.231-1.035Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Enterprise platform

        </div>

        AI-powered developer platform
      </div>

    
</a></li>

                  </ul>
                </div>
                <div class="border-bottom border-bottom-0">

                      <span class="d-block h4 color-fg-default my-1" id="enterprise-available-add-ons-heading">Available add-ons</span>

                  <ul class="list-style-none f5" aria-labelledby="enterprise-available-add-ons-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_enterprise_navbar&quot;}" href="https://github.com/security/advanced-security">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-shield-check color-fg-subtle mr-3">
    <path d="M16.53 9.78a.75.75 0 0 0-1.06-1.06L11 13.19l-1.97-1.97a.75.75 0 0 0-1.06 1.06l2.5 2.5a.75.75 0 0 0 1.06 0l5-5Z"></path><path d="m12.54.637 8.25 2.675A1.75 1.75 0 0 1 22 4.976V10c0 6.19-3.771 10.704-9.401 12.83a1.704 1.704 0 0 1-1.198 0C5.77 20.705 2 16.19 2 10V4.976c0-.758.489-1.43 1.21-1.664L11.46.637a1.748 1.748 0 0 1 1.08 0Zm-.617 1.426-8.25 2.676a.249.249 0 0 0-.173.237V10c0 5.46 3.28 9.483 8.43 11.426a.199.199 0 0 0 .14 0C17.22 19.483 20.5 15.461 20.5 10V4.976a.25.25 0 0 0-.173-.237l-8.25-2.676a.253.253 0 0 0-.154 0Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          GitHub Advanced Security

        </div>

        Enterprise-grade security features
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;copilot_for_business&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;copilot_for_business_link_enterprise_navbar&quot;}" href="/features/copilot/copilot-business">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-copilot color-fg-subtle mr-3">
    <path d="M23.922 16.992c-.861 1.495-5.859 5.023-11.922 5.023-6.063 0-11.061-3.528-11.922-5.023A.641.641 0 0 1 0 16.736v-2.869a.841.841 0 0 1 .053-.22c.372-.935 1.347-2.292 2.605-2.656.167-.429.414-1.055.644-1.517a10.195 10.195 0 0 1-.052-1.086c0-1.331.282-2.499 1.132-3.368.397-.406.89-.717 1.474-.952 1.399-1.136 3.392-2.093 6.122-2.093 2.731 0 4.767.957 6.166 2.093.584.235 1.077.546 1.474.952.85.869 1.132 2.037 1.132 3.368 0 .368-.014.733-.052 1.086.23.462.477 1.088.644 1.517 1.258.364 2.233 1.721 2.605 2.656a.832.832 0 0 1 .053.22v2.869a.641.641 0 0 1-.078.256ZM12.172 11h-.344a4.323 4.323 0 0 1-.355.508C10.703 12.455 9.555 13 7.965 13c-1.725 0-2.989-.359-3.782-1.259a2.005 2.005 0 0 1-.085-.104L4 11.741v6.585c1.435.779 4.514 2.179 8 2.179 3.486 0 6.565-1.4 8-2.179v-6.585l-.098-.104s-.033.045-.085.104c-.793.9-2.057 1.259-3.782 1.259-1.59 0-2.738-.545-3.508-1.492a4.323 4.323 0 0 1-.355-.508h-.016.016Zm.641-2.935c.136 1.057.403 1.913.878 2.497.442.544 1.134.938 2.344.938 1.573 0 2.292-.337 2.657-.751.384-.435.558-1.15.558-2.361 0-1.14-.243-1.847-.705-2.319-.477-.488-1.319-.862-2.824-1.025-1.487-.161-2.192.138-2.533.529-.269.307-.437.808-.438 1.578v.021c0 .265.021.562.063.893Zm-1.626 0c.042-.331.063-.628.063-.894v-.02c-.001-.77-.169-1.271-.438-1.578-.341-.391-1.046-.69-2.533-.529-1.505.163-2.347.537-2.824 1.025-.462.472-.705 1.179-.705 2.319 0 1.211.175 1.926.558 2.361.365.414 1.084.751 2.657.751 1.21 0 1.902-.394 2.344-.938.475-.584.742-1.44.878-2.497Z"></path><path d="M14.5 14.25a1 1 0 0 1 1 1v2a1 1 0 0 1-2 0v-2a1 1 0 0 1 1-1Zm-5 0a1 1 0 0 1 1 1v2a1 1 0 0 1-2 0v-2a1 1 0 0 1 1-1Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Copilot for business

        </div>

        Enterprise-grade AI features
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;premium_support&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;premium_support_link_enterprise_navbar&quot;}" href="/premium-support">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-comment-discussion color-fg-subtle mr-3">
    <path d="M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v9.5A1.75 1.75 0 0 1 14.25 14H8.061l-2.574 2.573A1.458 1.458 0 0 1 3 15.543V14H1.75A1.75 1.75 0 0 1 0 12.25v-9.5C0 1.784.784 1 1.75 1ZM1.5 2.75v9.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-9.5a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Z"></path><path d="M22.5 8.75a.25.25 0 0 0-.25-.25h-3.5a.75.75 0 0 1 0-1.5h3.5c.966 0 1.75.784 1.75 1.75v9.5A1.75 1.75 0 0 1 22.25 20H21v1.543a1.457 1.457 0 0 1-2.487 1.03L15.939 20H10.75A1.75 1.75 0 0 1 9 18.25v-1.465a.75.75 0 0 1 1.5 0v1.465c0 .138.112.25.25.25h5.5a.75.75 0 0 1 .53.22l2.72 2.72v-2.19a.75.75 0 0 1 .75-.75h2a.25.25 0 0 0 .25-.25v-9.5Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Premium Support

        </div>

        Enterprise-grade 24/7 support
      </div>

    
</a></li>

                  </ul>
                </div>
            </div>
        </div>

      </div>
</li>


                  <li class="HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item">
    <a class="HeaderMenu-link no-underline px-0 px-lg-2 py-3 py-lg-2 d-block d-lg-inline-block" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;platform&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;platform_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

              </ul>
            </nav>

        <div class="d-flex flex-column flex-lg-row width-full flex-justify-end flex-lg-items-center text-center mt-3 mt-lg-0 text-lg-left ml-lg-3">
                


<qbsearch-input class="search-input" data-scope="repo:coderonion/awesome-yolo-object-detection" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="yF9D9nowakYSBfHXKQDeErtfylK2HB4LICcFgM52zzjkM19wpdvwJXrT4e7gnluHtjUn0nPRawiHKjhSjBZ_1A" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="coderonion/awesome-yolo-object-detection" data-current-org="" data-current-owner="coderonion" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div
    class="search-input-container search-with-dialog position-relative d-flex flex-row flex-items-center mr-4 rounded"
    data-action="click:qbsearch-input#searchInputContainerClicked"
  >
      <button
        type="button"
        class="header-search-button placeholder  input-button form-control d-flex flex-1 flex-self-stretch flex-items-center no-wrap width-full py-0 pl-2 pr-0 text-left border-0 box-shadow-none"
        data-target="qbsearch-input.inputButton"
        aria-label="Search or jump toâ€¦"
        aria-haspopup="dialog"
        placeholder="Search or jump to..."
        data-hotkey=s,/
        autocapitalize="off"
        data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;searchbar&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;input&quot;,&quot;label&quot;:&quot;searchbar_input_global_navbar&quot;}"
        data-action="click:qbsearch-input#handleExpand"
      >
        <div class="mr-2 color-fg-muted">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-search">
    <path d="M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z"></path>
</svg>
        </div>
        <span class="flex-1" data-target="qbsearch-input.inputButtonText">Search or jump to...</span>
          <div class="d-flex" data-target="qbsearch-input.hotkeyIndicator">
            <svg xmlns="http://www.w3.org/2000/svg" width="22" height="20" aria-hidden="true" class="mr-1"><path fill="none" stroke="#979A9C" opacity=".4" d="M3.5.5h12c1.7 0 3 1.3 3 3v13c0 1.7-1.3 3-3 3h-12c-1.7 0-3-1.3-3-3v-13c0-1.7 1.3-3 3-3z"></path><path fill="#979A9C" d="M11.8 6L8 15.1h-.9L10.8 6h1z"></path></svg>
          </div>
      </button>

    <input type="hidden" name="type" class="js-site-search-type-field">

    
<div class="Overlay--hidden " data-modal-dialog-overlay>
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true" class="Overlay Overlay--width-large Overlay--height-auto">
      <h1 id="search-suggestions-dialog-header" class="sr-only">Search code, repositories, users, issues, pull requests...</h1>
    <div class="Overlay-body Overlay-body--paddingNone">
      
          <div data-view-component="true">        <div class="search-suggestions position-fixed width-full color-shadow-large border color-fg-default color-bg-default overflow-hidden d-flex flex-column query-builder-container"
          style="border-radius: 12px;"
          data-target="qbsearch-input.queryBuilderContainer"
          hidden
        >
          <!-- '"` --><!-- </textarea></xmp> --></option></form><form id="query-builder-test-form" action="" accept-charset="UTF-8" method="get">
  <query-builder data-target="qbsearch-input.queryBuilder" id="query-builder-query-builder-test" data-filter-key=":" data-view-component="true" class="QueryBuilder search-query-builder">
    <div class="FormControl FormControl--fullWidth">
      <label id="query-builder-test-label" for="query-builder-test" class="FormControl-label sr-only">
        Search
      </label>
      <div
        class="QueryBuilder-StyledInput width-fit "
        data-target="query-builder.styledInput"
      >
          <span id="query-builder-test-leadingvisual-wrap" class="FormControl-input-leadingVisualWrap QueryBuilder-leadingVisualWrap">
            <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-search FormControl-input-leadingVisual">
    <path d="M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z"></path>
</svg>
          </span>
        <div data-target="query-builder.styledInputContainer" class="QueryBuilder-StyledInputContainer">
          <div
            aria-hidden="true"
            class="QueryBuilder-StyledInputContent"
            data-target="query-builder.styledInputContent"
          ></div>
          <div class="QueryBuilder-InputWrapper">
            <div aria-hidden="true" class="QueryBuilder-Sizer" data-target="query-builder.sizer"></div>
            <input id="query-builder-test" name="query-builder-test" value="" autocomplete="off" type="text" role="combobox" spellcheck="false" aria-expanded="false" aria-describedby="validation-86f16a7a-2220-4d89-837f-82d3aaaa493e" data-target="query-builder.input" data-action="
          input:query-builder#inputChange
          blur:query-builder#inputBlur
          keydown:query-builder#inputKeydown
          focus:query-builder#inputFocus
        " data-view-component="true" class="FormControl-input QueryBuilder-Input FormControl-medium" />
          </div>
        </div>
          <span class="sr-only" id="query-builder-test-clear">Clear</span>
          <button role="button" id="query-builder-test-clear-button" aria-labelledby="query-builder-test-clear query-builder-test-label" data-target="query-builder.clearButton" data-action="
                click:query-builder#clear
                focus:query-builder#clearButtonFocus
                blur:query-builder#clearButtonBlur
              " variant="small" hidden="hidden" type="button" data-view-component="true" class="Button Button--iconOnly Button--invisible Button--medium mr-1 px-2 py-0 d-flex flex-items-center rounded-1 color-fg-muted">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x-circle-fill Button-visual">
    <path d="M2.343 13.657A8 8 0 1 1 13.658 2.343 8 8 0 0 1 2.343 13.657ZM6.03 4.97a.751.751 0 0 0-1.042.018.751.751 0 0 0-.018 1.042L6.94 8 4.97 9.97a.749.749 0 0 0 .326 1.275.749.749 0 0 0 .734-.215L8 9.06l1.97 1.97a.749.749 0 0 0 1.275-.326.749.749 0 0 0-.215-.734L9.06 8l1.97-1.97a.749.749 0 0 0-.326-1.275.749.749 0 0 0-.734.215L8 6.94Z"></path>
</svg>
</button>

      </div>
      <template id="search-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-search">
    <path d="M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z"></path>
</svg>
</template>

<template id="code-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-code">
    <path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path>
</svg>
</template>

<template id="file-code-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-file-code">
    <path d="M4 1.75C4 .784 4.784 0 5.75 0h5.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v8.586A1.75 1.75 0 0 1 14.25 15h-9a.75.75 0 0 1 0-1.5h9a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 10 4.25V1.5H5.75a.25.25 0 0 0-.25.25v2.5a.75.75 0 0 1-1.5 0Zm1.72 4.97a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734l1.47-1.47-1.47-1.47a.75.75 0 0 1 0-1.06ZM3.28 7.78 1.81 9.25l1.47 1.47a.751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Zm8.22-6.218V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path>
</svg>
</template>

<template id="history-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-history">
    <path d="m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z"></path>
</svg>
</template>

<template id="repo-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo">
    <path d="M2 2.5A2.5 2.5 0 0 1 4.5 0h8.75a.75.75 0 0 1 .75.75v12.5a.75.75 0 0 1-.75.75h-2.5a.75.75 0 0 1 0-1.5h1.75v-2h-8a1 1 0 0 0-.714 1.7.75.75 0 1 1-1.072 1.05A2.495 2.495 0 0 1 2 11.5Zm10.5-1h-8a1 1 0 0 0-1 1v6.708A2.486 2.486 0 0 1 4.5 9h8ZM5 12.25a.25.25 0 0 1 .25-.25h3.5a.25.25 0 0 1 .25.25v3.25a.25.25 0 0 1-.4.2l-1.45-1.087a.249.249 0 0 0-.3 0L5.4 15.7a.25.25 0 0 1-.4-.2Z"></path>
</svg>
</template>

<template id="bookmark-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-bookmark">
    <path d="M3 2.75C3 1.784 3.784 1 4.75 1h6.5c.966 0 1.75.784 1.75 1.75v11.5a.75.75 0 0 1-1.227.579L8 11.722l-3.773 3.107A.751.751 0 0 1 3 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v9.91l3.023-2.489a.75.75 0 0 1 .954 0l3.023 2.49V2.75a.25.25 0 0 0-.25-.25Z"></path>
</svg>
</template>

<template id="plus-circle-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-plus-circle">
    <path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm7.25-3.25v2.5h2.5a.75.75 0 0 1 0 1.5h-2.5v2.5a.75.75 0 0 1-1.5 0v-2.5h-2.5a.75.75 0 0 1 0-1.5h2.5v-2.5a.75.75 0 0 1 1.5 0Z"></path>
</svg>
</template>

<template id="circle-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-dot-fill">
    <path d="M8 4a4 4 0 1 1 0 8 4 4 0 0 1 0-8Z"></path>
</svg>
</template>

<template id="trash-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-trash">
    <path d="M11 1.75V3h2.25a.75.75 0 0 1 0 1.5H2.75a.75.75 0 0 1 0-1.5H5V1.75C5 .784 5.784 0 6.75 0h2.5C10.216 0 11 .784 11 1.75ZM4.496 6.675l.66 6.6a.25.25 0 0 0 .249.225h5.19a.25.25 0 0 0 .249-.225l.66-6.6a.75.75 0 0 1 1.492.149l-.66 6.6A1.748 1.748 0 0 1 10.595 15h-5.19a1.75 1.75 0 0 1-1.741-1.575l-.66-6.6a.75.75 0 1 1 1.492-.15ZM6.5 1.75V3h3V1.75a.25.25 0 0 0-.25-.25h-2.5a.25.25 0 0 0-.25.25Z"></path>
</svg>
</template>

<template id="team-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-people">
    <path d="M2 5.5a3.5 3.5 0 1 1 5.898 2.549 5.508 5.508 0 0 1 3.034 4.084.75.75 0 1 1-1.482.235 4 4 0 0 0-7.9 0 .75.75 0 0 1-1.482-.236A5.507 5.507 0 0 1 3.102 8.05 3.493 3.493 0 0 1 2 5.5ZM11 4a3.001 3.001 0 0 1 2.22 5.018 5.01 5.01 0 0 1 2.56 3.012.749.749 0 0 1-.885.954.752.752 0 0 1-.549-.514 3.507 3.507 0 0 0-2.522-2.372.75.75 0 0 1-.574-.73v-.352a.75.75 0 0 1 .416-.672A1.5 1.5 0 0 0 11 5.5.75.75 0 0 1 11 4Zm-5.5-.5a2 2 0 1 0-.001 3.999A2 2 0 0 0 5.5 3.5Z"></path>
</svg>
</template>

<template id="project-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-project">
    <path d="M1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25V1.75C0 .784.784 0 1.75 0ZM1.5 1.75v12.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25ZM11.75 3a.75.75 0 0 1 .75.75v7.5a.75.75 0 0 1-1.5 0v-7.5a.75.75 0 0 1 .75-.75Zm-8.25.75a.75.75 0 0 1 1.5 0v5.5a.75.75 0 0 1-1.5 0ZM8 3a.75.75 0 0 1 .75.75v3.5a.75.75 0 0 1-1.5 0v-3.5A.75.75 0 0 1 8 3Z"></path>
</svg>
</template>

<template id="pencil-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-pencil">
    <path d="M11.013 1.427a1.75 1.75 0 0 1 2.474 0l1.086 1.086a1.75 1.75 0 0 1 0 2.474l-8.61 8.61c-.21.21-.47.364-.756.445l-3.251.93a.75.75 0 0 1-.927-.928l.929-3.25c.081-.286.235-.547.445-.758l8.61-8.61Zm.176 4.823L9.75 4.81l-6.286 6.287a.253.253 0 0 0-.064.108l-.558 1.953 1.953-.558a.253.253 0 0 0 .108-.064Zm1.238-3.763a.25.25 0 0 0-.354 0L10.811 3.75l1.439 1.44 1.263-1.263a.25.25 0 0 0 0-.354Z"></path>
</svg>
</template>

<template id="copilot-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copilot">
    <path d="M7.998 15.035c-4.562 0-7.873-2.914-7.998-3.749V9.338c.085-.628.677-1.686 1.588-2.065.013-.07.024-.143.036-.218.029-.183.06-.384.126-.612-.201-.508-.254-1.084-.254-1.656 0-.87.128-1.769.693-2.484.579-.733 1.494-1.124 2.724-1.261 1.206-.134 2.262.034 2.944.765.05.053.096.108.139.165.044-.057.094-.112.143-.165.682-.731 1.738-.899 2.944-.765 1.23.137 2.145.528 2.724 1.261.566.715.693 1.614.693 2.484 0 .572-.053 1.148-.254 1.656.066.228.098.429.126.612.012.076.024.148.037.218.924.385 1.522 1.471 1.591 2.095v1.872c0 .766-3.351 3.795-8.002 3.795Zm0-1.485c2.28 0 4.584-1.11 5.002-1.433V7.862l-.023-.116c-.49.21-1.075.291-1.727.291-1.146 0-2.059-.327-2.71-.991A3.222 3.222 0 0 1 8 6.303a3.24 3.24 0 0 1-.544.743c-.65.664-1.563.991-2.71.991-.652 0-1.236-.081-1.727-.291l-.023.116v4.255c.419.323 2.722 1.433 5.002 1.433ZM6.762 2.83c-.193-.206-.637-.413-1.682-.297-1.019.113-1.479.404-1.713.7-.247.312-.369.789-.369 1.554 0 .793.129 1.171.308 1.371.162.181.519.379 1.442.379.853 0 1.339-.235 1.638-.54.315-.322.527-.827.617-1.553.117-.935-.037-1.395-.241-1.614Zm4.155-.297c-1.044-.116-1.488.091-1.681.297-.204.219-.359.679-.242 1.614.091.726.303 1.231.618 1.553.299.305.784.54 1.638.54.922 0 1.28-.198 1.442-.379.179-.2.308-.578.308-1.371 0-.765-.123-1.242-.37-1.554-.233-.296-.693-.587-1.713-.7Z"></path><path d="M6.25 9.037a.75.75 0 0 1 .75.75v1.501a.75.75 0 0 1-1.5 0V9.787a.75.75 0 0 1 .75-.75Zm4.25.75v1.501a.75.75 0 0 1-1.5 0V9.787a.75.75 0 0 1 1.5 0Z"></path>
</svg>
</template>

<template id="copilot-error-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copilot-error">
    <path d="M16 11.24c0 .112-.072.274-.21.467L13 9.688V7.862l-.023-.116c-.49.21-1.075.291-1.727.291-.198 0-.388-.009-.571-.029L6.833 5.226a4.01 4.01 0 0 0 .17-.782c.117-.935-.037-1.395-.241-1.614-.193-.206-.637-.413-1.682-.297-.683.076-1.115.231-1.395.415l-1.257-.91c.579-.564 1.413-.877 2.485-.996 1.206-.134 2.262.034 2.944.765.05.053.096.108.139.165.044-.057.094-.112.143-.165.682-.731 1.738-.899 2.944-.765 1.23.137 2.145.528 2.724 1.261.566.715.693 1.614.693 2.484 0 .572-.053 1.148-.254 1.656.066.228.098.429.126.612.012.076.024.148.037.218.924.385 1.522 1.471 1.591 2.095Zm-5.083-8.707c-1.044-.116-1.488.091-1.681.297-.204.219-.359.679-.242 1.614.091.726.303 1.231.618 1.553.299.305.784.54 1.638.54.922 0 1.28-.198 1.442-.379.179-.2.308-.578.308-1.371 0-.765-.123-1.242-.37-1.554-.233-.296-.693-.587-1.713-.7Zm2.511 11.074c-1.393.776-3.272 1.428-5.43 1.428-4.562 0-7.873-2.914-7.998-3.749V9.338c.085-.628.677-1.686 1.588-2.065.013-.07.024-.143.036-.218.029-.183.06-.384.126-.612-.18-.455-.241-.963-.252-1.475L.31 4.107A.747.747 0 0 1 0 3.509V3.49a.748.748 0 0 1 .625-.73c.156-.026.306.047.435.139l14.667 10.578a.592.592 0 0 1 .227.264.752.752 0 0 1 .046.249v.022a.75.75 0 0 1-1.19.596Zm-1.367-.991L5.635 7.964a5.128 5.128 0 0 1-.889.073c-.652 0-1.236-.081-1.727-.291l-.023.116v4.255c.419.323 2.722 1.433 5.002 1.433 1.539 0 3.089-.505 4.063-.934Z"></path>
</svg>
</template>

<template id="workflow-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-workflow">
    <path d="M0 1.75C0 .784.784 0 1.75 0h3.5C6.216 0 7 .784 7 1.75v3.5A1.75 1.75 0 0 1 5.25 7H4v4a1 1 0 0 0 1 1h4v-1.25C9 9.784 9.784 9 10.75 9h3.5c.966 0 1.75.784 1.75 1.75v3.5A1.75 1.75 0 0 1 14.25 16h-3.5A1.75 1.75 0 0 1 9 14.25v-.75H5A2.5 2.5 0 0 1 2.5 11V7h-.75A1.75 1.75 0 0 1 0 5.25Zm1.75-.25a.25.25 0 0 0-.25.25v3.5c0 .138.112.25.25.25h3.5a.25.25 0 0 0 .25-.25v-3.5a.25.25 0 0 0-.25-.25Zm9 9a.25.25 0 0 0-.25.25v3.5c0 .138.112.25.25.25h3.5a.25.25 0 0 0 .25-.25v-3.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
</template>

<template id="book-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-book">
    <path d="M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z"></path>
</svg>
</template>

<template id="code-review-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-code-review">
    <path d="M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 13H8.061l-2.574 2.573A1.458 1.458 0 0 1 3 14.543V13H1.75A1.75 1.75 0 0 1 0 11.25v-8.5C0 1.784.784 1 1.75 1ZM1.5 2.75v8.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-8.5a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Zm5.28 1.72a.75.75 0 0 1 0 1.06L5.31 7l1.47 1.47a.751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.75.75 0 0 1 1.06 0Zm2.44 0a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L10.69 7 9.22 5.53a.75.75 0 0 1 0-1.06Z"></path>
</svg>
</template>

<template id="codespaces-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-codespaces">
    <path d="M0 11.25c0-.966.784-1.75 1.75-1.75h12.5c.966 0 1.75.784 1.75 1.75v3A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25Zm2-9.5C2 .784 2.784 0 3.75 0h8.5C13.216 0 14 .784 14 1.75v5a1.75 1.75 0 0 1-1.75 1.75h-8.5A1.75 1.75 0 0 1 2 6.75Zm1.75-.25a.25.25 0 0 0-.25.25v5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-5a.25.25 0 0 0-.25-.25Zm-2 9.5a.25.25 0 0 0-.25.25v3c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-3a.25.25 0 0 0-.25-.25Z"></path><path d="M7 12.75a.75.75 0 0 1 .75-.75h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1-.75-.75Zm-4 0a.75.75 0 0 1 .75-.75h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1-.75-.75Z"></path>
</svg>
</template>

<template id="comment-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-comment">
    <path d="M1 2.75C1 1.784 1.784 1 2.75 1h10.5c.966 0 1.75.784 1.75 1.75v7.5A1.75 1.75 0 0 1 13.25 12H9.06l-2.573 2.573A1.458 1.458 0 0 1 4 13.543V12H2.75A1.75 1.75 0 0 1 1 10.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h4.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
</template>

<template id="comment-discussion-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-comment-discussion">
    <path d="M1.75 1h8.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 10.25 10H7.061l-2.574 2.573A1.458 1.458 0 0 1 2 11.543V10h-.25A1.75 1.75 0 0 1 0 8.25v-5.5C0 1.784.784 1 1.75 1ZM1.5 2.75v5.5c0 .138.112.25.25.25h1a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h3.5a.25.25 0 0 0 .25-.25v-5.5a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25Zm13 2a.25.25 0 0 0-.25-.25h-.5a.75.75 0 0 1 0-1.5h.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 14.25 12H14v1.543a1.458 1.458 0 0 1-2.487 1.03L9.22 12.28a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215l2.22 2.22v-2.19a.75.75 0 0 1 .75-.75h1a.25.25 0 0 0 .25-.25Z"></path>
</svg>
</template>

<template id="organization-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-organization">
    <path d="M1.75 16A1.75 1.75 0 0 1 0 14.25V1.75C0 .784.784 0 1.75 0h8.5C11.216 0 12 .784 12 1.75v12.5c0 .085-.006.168-.018.25h2.268a.25.25 0 0 0 .25-.25V8.285a.25.25 0 0 0-.111-.208l-1.055-.703a.749.749 0 1 1 .832-1.248l1.055.703c.487.325.779.871.779 1.456v5.965A1.75 1.75 0 0 1 14.25 16h-3.5a.766.766 0 0 1-.197-.026c-.099.017-.2.026-.303.026h-3a.75.75 0 0 1-.75-.75V14h-1v1.25a.75.75 0 0 1-.75.75Zm-.25-1.75c0 .138.112.25.25.25H4v-1.25a.75.75 0 0 1 .75-.75h2.5a.75.75 0 0 1 .75.75v1.25h2.25a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25ZM3.75 6h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5ZM3 3.75A.75.75 0 0 1 3.75 3h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 3.75Zm4 3A.75.75 0 0 1 7.75 6h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 7 6.75ZM7.75 3h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5ZM3 9.75A.75.75 0 0 1 3.75 9h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 9.75ZM7.75 9h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5Z"></path>
</svg>
</template>

<template id="rocket-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-rocket">
    <path d="M14.064 0h.186C15.216 0 16 .784 16 1.75v.186a8.752 8.752 0 0 1-2.564 6.186l-.458.459c-.314.314-.641.616-.979.904v3.207c0 .608-.315 1.172-.833 1.49l-2.774 1.707a.749.749 0 0 1-1.11-.418l-.954-3.102a1.214 1.214 0 0 1-.145-.125L3.754 9.816a1.218 1.218 0 0 1-.124-.145L.528 8.717a.749.749 0 0 1-.418-1.11l1.71-2.774A1.748 1.748 0 0 1 3.31 4h3.204c.288-.338.59-.665.904-.979l.459-.458A8.749 8.749 0 0 1 14.064 0ZM8.938 3.623h-.002l-.458.458c-.76.76-1.437 1.598-2.02 2.5l-1.5 2.317 2.143 2.143 2.317-1.5c.902-.583 1.74-1.26 2.499-2.02l.459-.458a7.25 7.25 0 0 0 2.123-5.127V1.75a.25.25 0 0 0-.25-.25h-.186a7.249 7.249 0 0 0-5.125 2.123ZM3.56 14.56c-.732.732-2.334 1.045-3.005 1.148a.234.234 0 0 1-.201-.064.234.234 0 0 1-.064-.201c.103-.671.416-2.273 1.15-3.003a1.502 1.502 0 1 1 2.12 2.12Zm6.94-3.935c-.088.06-.177.118-.266.175l-2.35 1.521.548 1.783 1.949-1.2a.25.25 0 0 0 .119-.213ZM3.678 8.116 5.2 5.766c.058-.09.117-.178.176-.266H3.309a.25.25 0 0 0-.213.119l-1.2 1.95ZM12 5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
</template>

<template id="shield-check-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-shield-check">
    <path d="m8.533.133 5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667l5.25-1.68a1.748 1.748 0 0 1 1.066 0Zm-.61 1.429.001.001-5.25 1.68a.251.251 0 0 0-.174.237V7c0 1.36.275 2.666 1.057 3.859.784 1.194 2.121 2.342 4.366 3.298a.196.196 0 0 0 .154 0c2.245-.957 3.582-2.103 4.366-3.297C13.225 9.666 13.5 8.358 13.5 7V3.48a.25.25 0 0 0-.174-.238l-5.25-1.68a.25.25 0 0 0-.153 0ZM11.28 6.28l-3.5 3.5a.75.75 0 0 1-1.06 0l-1.5-1.5a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215l.97.97 2.97-2.97a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z"></path>
</svg>
</template>

<template id="heart-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-heart">
    <path d="m8 14.25.345.666a.75.75 0 0 1-.69 0l-.008-.004-.018-.01a7.152 7.152 0 0 1-.31-.17 22.055 22.055 0 0 1-3.434-2.414C2.045 10.731 0 8.35 0 5.5 0 2.836 2.086 1 4.25 1 5.797 1 7.153 1.802 8 3.02 8.847 1.802 10.203 1 11.75 1 13.914 1 16 2.836 16 5.5c0 2.85-2.045 5.231-3.885 6.818a22.066 22.066 0 0 1-3.744 2.584l-.018.01-.006.003h-.002ZM4.25 2.5c-1.336 0-2.75 1.164-2.75 3 0 2.15 1.58 4.144 3.365 5.682A20.58 20.58 0 0 0 8 13.393a20.58 20.58 0 0 0 3.135-2.211C12.92 9.644 14.5 7.65 14.5 5.5c0-1.836-1.414-3-2.75-3-1.373 0-2.609.986-3.029 2.456a.749.749 0 0 1-1.442 0C6.859 3.486 5.623 2.5 4.25 2.5Z"></path>
</svg>
</template>

<template id="server-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-server">
    <path d="M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v4c0 .372-.116.717-.314 1 .198.283.314.628.314 1v4a1.75 1.75 0 0 1-1.75 1.75H1.75A1.75 1.75 0 0 1 0 12.75v-4c0-.358.109-.707.314-1a1.739 1.739 0 0 1-.314-1v-4C0 1.784.784 1 1.75 1ZM1.5 2.75v4c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Zm.25 5.75a.25.25 0 0 0-.25.25v4c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25ZM7 4.75A.75.75 0 0 1 7.75 4h4.5a.75.75 0 0 1 0 1.5h-4.5A.75.75 0 0 1 7 4.75ZM7.75 10h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5ZM3 4.75A.75.75 0 0 1 3.75 4h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 4.75ZM3.75 10h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5Z"></path>
</svg>
</template>

<template id="globe-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-globe">
    <path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM5.78 8.75a9.64 9.64 0 0 0 1.363 4.177c.255.426.542.832.857 1.215.245-.296.551-.705.857-1.215A9.64 9.64 0 0 0 10.22 8.75Zm4.44-1.5a9.64 9.64 0 0 0-1.363-4.177c-.307-.51-.612-.919-.857-1.215a9.927 9.927 0 0 0-.857 1.215A9.64 9.64 0 0 0 5.78 7.25Zm-5.944 1.5H1.543a6.507 6.507 0 0 0 4.666 5.5c-.123-.181-.24-.365-.352-.552-.715-1.192-1.437-2.874-1.581-4.948Zm-2.733-1.5h2.733c.144-2.074.866-3.756 1.58-4.948.12-.197.237-.381.353-.552a6.507 6.507 0 0 0-4.666 5.5Zm10.181 1.5c-.144 2.074-.866 3.756-1.58 4.948-.12.197-.237.381-.353.552a6.507 6.507 0 0 0 4.666-5.5Zm2.733-1.5a6.507 6.507 0 0 0-4.666-5.5c.123.181.24.365.353.552.714 1.192 1.436 2.874 1.58 4.948Z"></path>
</svg>
</template>

<template id="issue-opened-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-issue-opened">
    <path d="M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z"></path>
</svg>
</template>

<template id="device-mobile-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-device-mobile">
    <path d="M3.75 0h8.5C13.216 0 14 .784 14 1.75v12.5A1.75 1.75 0 0 1 12.25 16h-8.5A1.75 1.75 0 0 1 2 14.25V1.75C2 .784 2.784 0 3.75 0ZM3.5 1.75v12.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25ZM8 13a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path>
</svg>
</template>

<template id="package-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-package">
    <path d="m8.878.392 5.25 3.045c.54.314.872.89.872 1.514v6.098a1.75 1.75 0 0 1-.872 1.514l-5.25 3.045a1.75 1.75 0 0 1-1.756 0l-5.25-3.045A1.75 1.75 0 0 1 1 11.049V4.951c0-.624.332-1.201.872-1.514L7.122.392a1.75 1.75 0 0 1 1.756 0ZM7.875 1.69l-4.63 2.685L8 7.133l4.755-2.758-4.63-2.685a.248.248 0 0 0-.25 0ZM2.5 5.677v5.372c0 .09.047.171.125.216l4.625 2.683V8.432Zm6.25 8.271 4.625-2.683a.25.25 0 0 0 .125-.216V5.677L8.75 8.432Z"></path>
</svg>
</template>

<template id="credit-card-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-credit-card">
    <path d="M10.75 9a.75.75 0 0 0 0 1.5h1.5a.75.75 0 0 0 0-1.5h-1.5Z"></path><path d="M0 3.75C0 2.784.784 2 1.75 2h12.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 14H1.75A1.75 1.75 0 0 1 0 12.25ZM14.5 6.5h-13v5.75c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25Zm0-2.75a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25V5h13Z"></path>
</svg>
</template>

<template id="play-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-play">
    <path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z"></path>
</svg>
</template>

<template id="gift-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-gift">
    <path d="M2 2.75A2.75 2.75 0 0 1 4.75 0c.983 0 1.873.42 2.57 1.232.268.318.497.668.68 1.042.183-.375.411-.725.68-1.044C9.376.42 10.266 0 11.25 0a2.75 2.75 0 0 1 2.45 4h.55c.966 0 1.75.784 1.75 1.75v2c0 .698-.409 1.301-1 1.582v4.918A1.75 1.75 0 0 1 13.25 16H2.75A1.75 1.75 0 0 1 1 14.25V9.332C.409 9.05 0 8.448 0 7.75v-2C0 4.784.784 4 1.75 4h.55c-.192-.375-.3-.8-.3-1.25ZM7.25 9.5H2.5v4.75c0 .138.112.25.25.25h4.5Zm1.5 0v5h4.5a.25.25 0 0 0 .25-.25V9.5Zm0-4V8h5.5a.25.25 0 0 0 .25-.25v-2a.25.25 0 0 0-.25-.25Zm-7 0a.25.25 0 0 0-.25.25v2c0 .138.112.25.25.25h5.5V5.5h-5.5Zm3-4a1.25 1.25 0 0 0 0 2.5h2.309c-.233-.818-.542-1.401-.878-1.793-.43-.502-.915-.707-1.431-.707ZM8.941 4h2.309a1.25 1.25 0 0 0 0-2.5c-.516 0-1 .205-1.43.707-.337.392-.646.975-.879 1.793Z"></path>
</svg>
</template>

<template id="code-square-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-code-square">
    <path d="M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25Zm7.47 3.97a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L10.69 8 9.22 6.53a.75.75 0 0 1 0-1.06ZM6.78 6.53 5.31 8l1.47 1.47a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215l-2-2a.75.75 0 0 1 0-1.06l2-2a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z"></path>
</svg>
</template>

<template id="device-desktop-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-device-desktop">
    <path d="M14.25 1c.966 0 1.75.784 1.75 1.75v7.5A1.75 1.75 0 0 1 14.25 12h-3.727c.099 1.041.52 1.872 1.292 2.757A.752.752 0 0 1 11.25 16h-6.5a.75.75 0 0 1-.565-1.243c.772-.885 1.192-1.716 1.292-2.757H1.75A1.75 1.75 0 0 1 0 10.25v-7.5C0 1.784.784 1 1.75 1ZM1.75 2.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25ZM9.018 12H6.982a5.72 5.72 0 0 1-.765 2.5h3.566a5.72 5.72 0 0 1-.765-2.5Z"></path>
</svg>
</template>

        <div class="position-relative">
                <ul
                  role="listbox"
                  class="ActionListWrap QueryBuilder-ListWrap"
                  aria-label="Suggestions"
                  data-action="
                    combobox-commit:query-builder#comboboxCommit
                    mousedown:query-builder#resultsMousedown
                  "
                  data-target="query-builder.resultsList"
                  data-persist-list=false
                  id="query-builder-test-results"
                  tabindex="-1"
                ></ul>
        </div>
      <div class="FormControl-inlineValidation" id="validation-86f16a7a-2220-4d89-837f-82d3aaaa493e" hidden="hidden">
        <span class="FormControl-inlineValidation--visual">
          <svg aria-hidden="true" height="12" viewBox="0 0 12 12" version="1.1" width="12" data-view-component="true" class="octicon octicon-alert-fill">
    <path d="M4.855.708c.5-.896 1.79-.896 2.29 0l4.675 8.351a1.312 1.312 0 0 1-1.146 1.954H1.33A1.313 1.313 0 0 1 .183 9.058ZM7 7V3H5v4Zm-1 3a1 1 0 1 0 0-2 1 1 0 0 0 0 2Z"></path>
</svg>
        </span>
        <span></span>
</div>    </div>
    <div data-target="query-builder.screenReaderFeedback" aria-live="polite" aria-atomic="true" class="sr-only"></div>
</query-builder></form>
          <div class="d-flex flex-row color-fg-muted px-3 text-small color-bg-default search-feedback-prompt">
            <a target="_blank" href="https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax" data-view-component="true" class="Link color-fg-accent text-normal ml-2">Search syntax tips</a>            <div class="d-flex flex-1"></div>
          </div>
        </div>
</div>

    </div>
</modal-dialog></div>
  </div>
  <div data-action="click:qbsearch-input#retract" class="dark-backdrop position-fixed" hidden data-target="qbsearch-input.darkBackdrop"></div>
  <div class="color-fg-default">
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true" class="Overlay Overlay-whenNarrow Overlay--size-medium Overlay--motion-scaleFade Overlay--disableScroll">
    <div data-view-component="true" class="Overlay-header">
  <div class="Overlay-headerContentWrap">
    <div class="Overlay-titleWrap">
      <h1 class="Overlay-title " id="feedback-dialog-title">
        Provide feedback
      </h1>
        
    </div>
    <div class="Overlay-actionWrap">
      <button data-close-dialog-id="feedback-dialog" aria-label="Close" aria-label="Close" type="button" data-view-component="true" class="close-button Overlay-closeButton"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg></button>
    </div>
  </div>
  
</div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        <div data-view-component="true" class="Overlay-body">        <!-- '"` --><!-- </textarea></xmp> --></option></form><form id="code-search-feedback-form" data-turbo="false" action="/search/feedback" accept-charset="UTF-8" method="post"><input type="hidden" data-csrf="true" name="authenticity_token" value="KoNtYEHV0OvuxFLk0KJy5/lgcGlv4jY21GhLcT2OeNhXwk4YiqzLp35ioTJqH8u6G7Yv36p7HAwGJAKqyVNwHA==" />
          <p>We read every piece of feedback, and take your input very seriously.</p>
          <textarea name="feedback" class="form-control width-full mb-2" style="height: 120px" id="feedback"></textarea>
          <input name="include_email" id="include_email" aria-label="Include my email address so I can be contacted" class="form-control mr-2" type="checkbox">
          <label for="include_email" style="font-weight: normal">Include my email address so I can be contacted</label>
</form></div>
      </scrollable-region>
      <div data-view-component="true" class="Overlay-footer Overlay-footer--alignEnd">          <button data-close-dialog-id="feedback-dialog" type="button" data-view-component="true" class="btn">    Cancel
</button>
          <button form="code-search-feedback-form" data-action="click:qbsearch-input#submitFeedback" type="submit" data-view-component="true" class="btn-primary btn">    Submit feedback
</button>
</div>
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true" class="Overlay Overlay-whenNarrow Overlay--size-medium Overlay--motion-scaleFade Overlay--disableScroll">
    <div data-view-component="true" class="Overlay-header Overlay-header--divided">
  <div class="Overlay-headerContentWrap">
    <div class="Overlay-titleWrap">
      <h1 class="Overlay-title " id="custom-scopes-dialog-title">
        Saved searches
      </h1>
        <h2 id="custom-scopes-dialog-description" class="Overlay-description">Use saved searches to filter your results more quickly</h2>
    </div>
    <div class="Overlay-actionWrap">
      <button data-close-dialog-id="custom-scopes-dialog" aria-label="Close" aria-label="Close" type="button" data-view-component="true" class="close-button Overlay-closeButton"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg></button>
    </div>
  </div>
  
</div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        <div data-view-component="true" class="Overlay-body">        <div data-target="custom-scopes.customScopesModalDialogFlash"></div>

        <div hidden class="create-custom-scope-form" data-target="custom-scopes.createCustomScopeForm">
        <!-- '"` --><!-- </textarea></xmp> --></option></form><form id="custom-scopes-dialog-form" data-turbo="false" action="/search/custom_scopes" accept-charset="UTF-8" method="post"><input type="hidden" data-csrf="true" name="authenticity_token" value="Y4uXKYzvdnJY+5HezcluxZrASOPfUOMFf27GoHftNjSyW4E6xNgZQuag9mxUvWk1tkEZI4iIY2HqtPQY5u43ag==" />
          <div data-target="custom-scopes.customScopesModalDialogFlash"></div>

          <input type="hidden" id="custom_scope_id" name="custom_scope_id" data-target="custom-scopes.customScopesIdField">

          <div class="form-group">
            <label for="custom_scope_name">Name</label>
            <auto-check src="/search/custom_scopes/check_name" required>
              <input
                type="text"
                name="custom_scope_name"
                id="custom_scope_name"
                data-target="custom-scopes.customScopesNameField"
                class="form-control"
                autocomplete="off"
                placeholder="github-ruby"
                required
                maxlength="50">
              <input type="hidden" data-csrf="true" value="VywzX7PfbDA8K5ymHFACYZFMs91ebrKWGf7VS6iegPt0BbefxH7jLWK2ehfWjEW5rM+yft1ehm8CaKPrcrnaUw==" />
            </auto-check>
          </div>

          <div class="form-group">
            <label for="custom_scope_query">Query</label>
            <input
              type="text"
              name="custom_scope_query"
              id="custom_scope_query"
              data-target="custom-scopes.customScopesQueryField"
              class="form-control"
              autocomplete="off"
              placeholder="(repo:mona/a OR repo:mona/b) AND lang:python"
              required
              maxlength="500">
          </div>

          <p class="text-small color-fg-muted">
            To see all available qualifiers, see our <a class="Link--inTextBlock" href="https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax">documentation</a>.
          </p>
</form>        </div>

        <div data-target="custom-scopes.manageCustomScopesForm">
          <div data-target="custom-scopes.list"></div>
        </div>

</div>
      </scrollable-region>
      <div data-view-component="true" class="Overlay-footer Overlay-footer--alignEnd Overlay-footer--divided">          <button data-action="click:custom-scopes#customScopesCancel" type="button" data-view-component="true" class="btn">    Cancel
</button>
          <button form="custom-scopes-dialog-form" data-action="click:custom-scopes#customScopesSubmit" data-target="custom-scopes.customScopesSubmitButton" type="submit" data-view-component="true" class="btn-primary btn">    Create saved search
</button>
</div>
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            <div class="position-relative HeaderMenu-link-wrap d-lg-inline-block">
              <a
                href="/login?return_to=https%3A%2F%2Fgithub.com%2Fcoderonion%2Fawesome-yolo-object-detection"
                class="HeaderMenu-link HeaderMenu-link--sign-in HeaderMenu-button flex-shrink-0 no-underline d-none d-lg-inline-flex border border-lg-0 rounded px-2 py-1"
                style="margin-left: 12px;"
                data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/coderonion/awesome-yolo-object-detection&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="58d2cabbb70ca01d75dca7c221ecbb07ba8bbb2e720c6b8e354fda024d7f8087"
                data-analytics-event="{&quot;category&quot;:&quot;Marketing nav&quot;,&quot;action&quot;:&quot;click to go to homepage&quot;,&quot;label&quot;:&quot;ref_page:Marketing;ref_cta:Sign in;ref_loc:Header&quot;}"
              >
                Sign in
              </a>
            </div>

              <a href="/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=coderonion%2Fawesome-yolo-object-detection"
                class="HeaderMenu-link HeaderMenu-link--sign-up HeaderMenu-button flex-shrink-0 d-flex d-lg-inline-flex no-underline border color-border-default rounded px-2 py-1"
                data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/coderonion/awesome-yolo-object-detection&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="58d2cabbb70ca01d75dca7c221ecbb07ba8bbb2e720c6b8e354fda024d7f8087"
                data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/&lt;user-name&gt;/&lt;repo-name&gt;;ref_cta:Sign up;ref_loc:header logged out&quot;}"
              >
                Sign up
              </a>

                <div class="AppHeader-appearanceSettings">
    <react-partial-anchor>
      <button data-target="react-partial-anchor.anchor" id="icon-button-4bcba3ba-2da3-4adc-b431-723f5590f8b6" aria-labelledby="tooltip-416de22d-5e57-40ac-965c-5562239ab1f9" type="button" disabled="disabled" data-view-component="true" class="Button Button--iconOnly Button--invisible Button--medium AppHeader-button HeaderMenu-link border cursor-wait">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-sliders Button-visual">
    <path d="M15 2.75a.75.75 0 0 1-.75.75h-4a.75.75 0 0 1 0-1.5h4a.75.75 0 0 1 .75.75Zm-8.5.75v1.25a.75.75 0 0 0 1.5 0v-4a.75.75 0 0 0-1.5 0V2H1.75a.75.75 0 0 0 0 1.5H6.5Zm1.25 5.25a.75.75 0 0 0 0-1.5h-6a.75.75 0 0 0 0 1.5h6ZM15 8a.75.75 0 0 1-.75.75H11.5V10a.75.75 0 1 1-1.5 0V6a.75.75 0 0 1 1.5 0v1.25h2.75A.75.75 0 0 1 15 8Zm-9 5.25v-2a.75.75 0 0 0-1.5 0v1.25H1.75a.75.75 0 0 0 0 1.5H4.5v1.25a.75.75 0 0 0 1.5 0v-2Zm9 0a.75.75 0 0 1-.75.75h-6a.75.75 0 0 1 0-1.5h6a.75.75 0 0 1 .75.75Z"></path>
</svg>
</button><tool-tip id="tooltip-416de22d-5e57-40ac-965c-5562239ab1f9" for="icon-button-4bcba3ba-2da3-4adc-b431-723f5590f8b6" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.f595f41454298e934d3c.module.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.6c63a6de228d6520804d.module.css" />

<react-partial
  partial-name="appearance-settings"
  data-ssr="false"
  data-attempted-ssr="false"
  data-react-profiling="false"
>
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>


      </template>
    </react-partial-anchor>
  </div>

          <button type="button" class="sr-only js-header-menu-focus-trap d-block d-lg-none">Resetting focus</button>
        </div>
      </div>
    </div>
  </div>
</header>

      <div hidden="hidden" data-view-component="true" class="js-stale-session-flash stale-session-flash flash flash-warn flash-full">
  
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
        <span class="js-stale-session-flash-signed-in" hidden>You signed in with another tab or window. <a class="Link--inTextBlock" href="">Reload</a> to refresh your session.</span>
        <span class="js-stale-session-flash-signed-out" hidden>You signed out in another tab or window. <a class="Link--inTextBlock" href="">Reload</a> to refresh your session.</span>
        <span class="js-stale-session-flash-switched" hidden>You switched accounts on another tab or window. <a class="Link--inTextBlock" href="">Reload</a> to refresh your session.</span>

    <button id="icon-button-9b7c304d-159b-4ad1-8556-344ec2c04622" aria-labelledby="tooltip-dcc4f593-9297-4f82-82b2-1727d4cfac18" type="button" data-view-component="true" class="Button Button--iconOnly Button--invisible Button--medium flash-close js-flash-close">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x Button-visual">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
</button><tool-tip id="tooltip-dcc4f593-9297-4f82-82b2-1727d4cfac18" for="icon-button-9b7c304d-159b-4ad1-8556-344ec2c04622" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute">Dismiss alert</tool-tip>


  
</div>
    </div>

  <div id="start-of-content" class="show-on-focus"></div>








    <div id="js-flash-container" class="flash-container" data-turbo-replace>




  <template class="js-flash-template">
    
<div class="flash flash-full   {{ className }}">
  <div >
    <button autofocus class="flash-close js-flash-close" type="button" aria-label="Dismiss this message">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
    </button>
    <div aria-atomic="true" role="alert" class="js-flash-alert">
      
      <div>{{ message }}</div>

    </div>
  </div>
</div>
  </template>
</div>


    






  <div
    class="application-main "
    data-commit-hovercards-enabled
    data-discussion-hovercards-enabled
    data-issue-and-pr-hovercards-enabled
    data-project-hovercards-enabled
  >
        <div itemscope itemtype="http://schema.org/SoftwareSourceCode" class="">
    <main id="js-repo-pjax-container" >
      
  





    






  
  <div id="repository-container-header"  class="pt-3 hide-full-screen" style="background-color: var(--page-header-bgColor, var(--color-page-header-bg));" data-turbo-replace>

      <div class="d-flex flex-nowrap flex-justify-end mb-3  px-3 px-lg-5" style="gap: 1rem;">

        <div class="flex-auto min-width-0 width-fit">
            
  <div class=" d-flex flex-wrap flex-items-center wb-break-word f3 text-normal">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo color-fg-muted mr-2">
    <path d="M2 2.5A2.5 2.5 0 0 1 4.5 0h8.75a.75.75 0 0 1 .75.75v12.5a.75.75 0 0 1-.75.75h-2.5a.75.75 0 0 1 0-1.5h1.75v-2h-8a1 1 0 0 0-.714 1.7.75.75 0 1 1-1.072 1.05A2.495 2.495 0 0 1 2 11.5Zm10.5-1h-8a1 1 0 0 0-1 1v6.708A2.486 2.486 0 0 1 4.5 9h8ZM5 12.25a.25.25 0 0 1 .25-.25h3.5a.25.25 0 0 1 .25.25v3.25a.25.25 0 0 1-.4.2l-1.45-1.087a.249.249 0 0 0-.3 0L5.4 15.7a.25.25 0 0 1-.4-.2Z"></path>
</svg>
    
    <span class="author flex-self-stretch" itemprop="author">
      <a class="url fn" rel="author" data-hovercard-type="user" data-hovercard-url="/users/coderonion/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="/coderonion">
        coderonion
</a>    </span>
    <span class="mx-1 flex-self-stretch color-fg-muted">/</span>
    <strong itemprop="name" class="mr-2 flex-self-stretch">
      <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="/coderonion/awesome-yolo-object-detection">awesome-yolo-object-detection</a>
    </strong>

    <span></span><span class="Label Label--secondary v-align-middle mr-1">Public</span>
  </div>


        </div>

        <div id="repository-details-container" class="flex-shrink-0" data-turbo-replace style="max-width: 70%;">
            <ul class="pagehead-actions flex-shrink-0 d-none d-md-inline" style="padding: 2px 0;">
    
      

  <li>
            <a href="/login?return_to=%2Fcoderonion%2Fawesome-yolo-object-detection" rel="nofollow" id="repository-details-watch-button" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/coderonion/awesome-yolo-object-detection&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="5846330545a83d2c5e8014b74dde29b8a0e5a2c6e07de83973a6d43d78bb2b49" aria-label="You must be signed in to change notification settings" data-view-component="true" class="btn-sm btn">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-bell mr-2">
    <path d="M8 16a2 2 0 0 0 1.985-1.75c.017-.137-.097-.25-.235-.25h-3.5c-.138 0-.252.113-.235.25A2 2 0 0 0 8 16ZM3 5a5 5 0 0 1 10 0v2.947c0 .05.015.098.042.139l1.703 2.555A1.519 1.519 0 0 1 13.482 13H2.518a1.516 1.516 0 0 1-1.263-2.36l1.703-2.554A.255.255 0 0 0 3 7.947Zm5-3.5A3.5 3.5 0 0 0 4.5 5v2.947c0 .346-.102.683-.294.97l-1.703 2.556a.017.017 0 0 0-.003.01l.001.006c0 .002.002.004.004.006l.006.004.007.001h10.964l.007-.001.006-.004.004-.006.001-.007a.017.017 0 0 0-.003-.01l-1.703-2.554a1.745 1.745 0 0 1-.294-.97V5A3.5 3.5 0 0 0 8 1.5Z"></path>
</svg>Notifications
</a>    <tool-tip id="tooltip-4423dca0-f8a7-4476-b31a-4997d1f0410b" for="repository-details-watch-button" popover="manual" data-direction="s" data-type="description" data-view-component="true" class="sr-only position-absolute">You must be signed in to change notification settings</tool-tip>

  </li>

  <li>
          <a icon="repo-forked" id="fork-button" href="/login?return_to=%2Fcoderonion%2Fawesome-yolo-object-detection" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:461270746,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/coderonion/awesome-yolo-object-detection&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="5294c62344eb3fa68995e97f3babf7716732ffd34b4f8c110c45095297520480" data-view-component="true" class="btn-sm btn">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo-forked mr-2">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>Fork
    <span id="repo-network-counter" data-pjax-replace="true" data-turbo-replace="true" title="220" data-view-component="true" class="Counter">220</span>
</a>
  </li>

  <li>
        <div data-view-component="true" class="BtnGroup d-flex">
        <a href="/login?return_to=%2Fcoderonion%2Fawesome-yolo-object-detection" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:461270746,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/coderonion/awesome-yolo-object-detection&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="9e69774e9978fdd8ecaf604568d6ce05dff82df73ffcc48affd44df95a91eba8" aria-label="You must be signed in to star a repository" data-view-component="true" class="tooltipped tooltipped-sw btn-sm btn">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-star v-align-text-bottom d-inline-block mr-2">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg><span data-view-component="true" class="d-inline">
          Star
</span>          <span id="repo-stars-counter-star" aria-label="1613 users starred this repository" data-singular-suffix="user starred this repository" data-plural-suffix="users starred this repository" data-turbo-replace="true" title="1,613" data-view-component="true" class="Counter js-social-count">1.6k</span>
</a></div>
  </li>

</ul>

        </div>
      </div>

        <div id="responsive-meta-container" data-turbo-replace>
      <div class="d-block d-md-none mb-2 px-3 px-md-4 px-lg-5">
      <p class="f4 mb-3 ">
        ðŸš€ðŸš€ðŸš€ A collection of some awesome public YOLO object detection series projects and the related object detection datasets.
      </p>

    

    <div class="mb-3">
        <a class="Link--secondary no-underline mr-3" href="/coderonion/awesome-yolo-object-detection/stargazers">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-star mr-1">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
          <span class="text-bold">1.6k</span>
          stars
</a>        <a class="Link--secondary no-underline mr-3" href="/coderonion/awesome-yolo-object-detection/forks">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo-forked mr-1">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>
          <span class="text-bold">220</span>
          forks
</a>        <a class="Link--secondary no-underline mr-3 d-inline-block" href="/coderonion/awesome-yolo-object-detection/branches">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-git-branch mr-1">
    <path d="M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z"></path>
</svg>
          <span>Branches</span>
</a>        <a class="Link--secondary no-underline d-inline-block" href="/coderonion/awesome-yolo-object-detection/tags">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-tag mr-1">
    <path d="M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z"></path>
</svg>
          <span>Tags</span>
</a>        <a class="Link--secondary no-underline d-inline-block" href="/coderonion/awesome-yolo-object-detection/activity">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-pulse mr-1">
    <path d="M6 2c.306 0 .582.187.696.471L10 10.731l1.304-3.26A.751.751 0 0 1 12 7h3.25a.75.75 0 0 1 0 1.5h-2.742l-1.812 4.528a.751.751 0 0 1-1.392 0L6 4.77 4.696 8.03A.75.75 0 0 1 4 8.5H.75a.75.75 0 0 1 0-1.5h2.742l1.812-4.529A.751.751 0 0 1 6 2Z"></path>
</svg>
          <span>Activity</span>
</a>    </div>

      <div class="d-flex flex-wrap gap-2">
        <div class="flex-1">
            <div data-view-component="true" class="BtnGroup d-flex">
        <a href="/login?return_to=%2Fcoderonion%2Fawesome-yolo-object-detection" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:461270746,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/coderonion/awesome-yolo-object-detection&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="9e69774e9978fdd8ecaf604568d6ce05dff82df73ffcc48affd44df95a91eba8" aria-label="You must be signed in to star a repository" data-view-component="true" class="tooltipped tooltipped-sw btn-sm btn btn-block">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-star v-align-text-bottom d-inline-block mr-2">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg><span data-view-component="true" class="d-inline">
          Star
</span>
</a></div>
        </div>
        <div class="flex-1">
                <a href="/login?return_to=%2Fcoderonion%2Fawesome-yolo-object-detection" rel="nofollow" id="files-overview-watch-button" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/coderonion/awesome-yolo-object-detection&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="5846330545a83d2c5e8014b74dde29b8a0e5a2c6e07de83973a6d43d78bb2b49" aria-label="You must be signed in to change notification settings" data-view-component="true" class="btn-sm btn btn-block">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-bell mr-2">
    <path d="M8 16a2 2 0 0 0 1.985-1.75c.017-.137-.097-.25-.235-.25h-3.5c-.138 0-.252.113-.235.25A2 2 0 0 0 8 16ZM3 5a5 5 0 0 1 10 0v2.947c0 .05.015.098.042.139l1.703 2.555A1.519 1.519 0 0 1 13.482 13H2.518a1.516 1.516 0 0 1-1.263-2.36l1.703-2.554A.255.255 0 0 0 3 7.947Zm5-3.5A3.5 3.5 0 0 0 4.5 5v2.947c0 .346-.102.683-.294.97l-1.703 2.556a.017.017 0 0 0-.003.01l.001.006c0 .002.002.004.004.006l.006.004.007.001h10.964l.007-.001.006-.004.004-.006.001-.007a.017.017 0 0 0-.003-.01l-1.703-2.554a1.745 1.745 0 0 1-.294-.97V5A3.5 3.5 0 0 0 8 1.5Z"></path>
</svg>Notifications
</a>    <tool-tip id="tooltip-9d9a00ff-f157-46cb-80db-f44fe1540db8" for="files-overview-watch-button" popover="manual" data-direction="s" data-type="description" data-view-component="true" class="sr-only position-absolute">You must be signed in to change notification settings</tool-tip>

        </div>
        <span>
          

        </span>
      </div>
  </div>

</div>


          <nav data-pjax="#js-repo-pjax-container" aria-label="Repository" data-view-component="true" class="js-repo-nav js-sidenav-container-pjax js-responsive-underlinenav overflow-hidden UnderlineNav px-3 px-md-4 px-lg-5">

  <ul data-view-component="true" class="UnderlineNav-body list-style-none">
      <li data-view-component="true" class="d-inline-flex">
  <a id="code-tab" href="/coderonion/awesome-yolo-object-detection" data-tab-item="i0code-tab" data-selected-links="repo_source repo_downloads repo_commits repo_releases repo_tags repo_branches repo_packages repo_deployments repo_attestations /coderonion/awesome-yolo-object-detection" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g c" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Code&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" aria-current="page" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item selected">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-code UnderlineNav-octicon d-none d-sm-inline">
    <path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path>
</svg>
        <span data-content="Code">Code</span>
          <span id="code-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true" class="Counter"></span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="issues-tab" href="/coderonion/awesome-yolo-object-detection/issues" data-tab-item="i1issues-tab" data-selected-links="repo_issues repo_labels repo_milestones /coderonion/awesome-yolo-object-detection/issues" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g i" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Issues&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-issue-opened UnderlineNav-octicon d-none d-sm-inline">
    <path d="M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z"></path>
</svg>
        <span data-content="Issues">Issues</span>
          <span id="issues-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="0" hidden="hidden" data-view-component="true" class="Counter">0</span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="pull-requests-tab" href="/coderonion/awesome-yolo-object-detection/pulls" data-tab-item="i2pull-requests-tab" data-selected-links="repo_pulls checks /coderonion/awesome-yolo-object-detection/pulls" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g p" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Pull requests&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-git-pull-request UnderlineNav-octicon d-none d-sm-inline">
    <path d="M1.5 3.25a2.25 2.25 0 1 1 3 2.122v5.256a2.251 2.251 0 1 1-1.5 0V5.372A2.25 2.25 0 0 1 1.5 3.25Zm5.677-.177L9.573.677A.25.25 0 0 1 10 .854V2.5h1A2.5 2.5 0 0 1 13.5 5v5.628a2.251 2.251 0 1 1-1.5 0V5a1 1 0 0 0-1-1h-1v1.646a.25.25 0 0 1-.427.177L7.177 3.427a.25.25 0 0 1 0-.354ZM3.75 2.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm0 9.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm8.25.75a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Z"></path>
</svg>
        <span data-content="Pull requests">Pull requests</span>
          <span id="pull-requests-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="0" hidden="hidden" data-view-component="true" class="Counter">0</span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="actions-tab" href="/coderonion/awesome-yolo-object-detection/actions" data-tab-item="i3actions-tab" data-selected-links="repo_actions /coderonion/awesome-yolo-object-detection/actions" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g a" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Actions&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-play UnderlineNav-octicon d-none d-sm-inline">
    <path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z"></path>
</svg>
        <span data-content="Actions">Actions</span>
          <span id="actions-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true" class="Counter"></span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="projects-tab" href="/coderonion/awesome-yolo-object-detection/projects" data-tab-item="i4projects-tab" data-selected-links="repo_projects new_repo_project repo_project /coderonion/awesome-yolo-object-detection/projects" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g b" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Projects&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-table UnderlineNav-octicon d-none d-sm-inline">
    <path d="M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25ZM6.5 6.5v8h7.75a.25.25 0 0 0 .25-.25V6.5Zm8-1.5V1.75a.25.25 0 0 0-.25-.25H6.5V5Zm-13 1.5v7.75c0 .138.112.25.25.25H5v-8ZM5 5V1.5H1.75a.25.25 0 0 0-.25.25V5Z"></path>
</svg>
        <span data-content="Projects">Projects</span>
          <span id="projects-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="0" hidden="hidden" data-view-component="true" class="Counter">0</span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="security-tab" href="/coderonion/awesome-yolo-object-detection/security" data-tab-item="i5security-tab" data-selected-links="security overview alerts policy token_scanning code_scanning /coderonion/awesome-yolo-object-detection/security" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g s" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Security&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-shield UnderlineNav-octicon d-none d-sm-inline">
    <path d="M7.467.133a1.748 1.748 0 0 1 1.066 0l5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667Zm.61 1.429a.25.25 0 0 0-.153 0l-5.25 1.68a.25.25 0 0 0-.174.238V7c0 1.358.275 2.666 1.057 3.86.784 1.194 2.121 2.34 4.366 3.297a.196.196 0 0 0 .154 0c2.245-.956 3.582-2.104 4.366-3.298C13.225 9.666 13.5 8.36 13.5 7V3.48a.251.251 0 0 0-.174-.237l-5.25-1.68ZM8.75 4.75v3a.75.75 0 0 1-1.5 0v-3a.75.75 0 0 1 1.5 0ZM9 10.5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
        <span data-content="Security">Security</span>
          <include-fragment src="/coderonion/awesome-yolo-object-detection/security/overall-count" accept="text/fragment+html" data-nonce="v2:515a6721-8eb7-ba0a-7b66-e450a60aff90" data-view-component="true">
  
  <div data-show-on-forbidden-error hidden>
    <div class="Box">
  <div class="blankslate-container">
    <div data-view-component="true" class="blankslate blankslate-spacious color-bg-default rounded-2">
      

      <h3 data-view-component="true" class="blankslate-heading">        Uh oh!
</h3>
      <p data-view-component="true">        <p class="color-fg-muted my-2 mb-2 ws-normal">There was an error while loading. <a class="Link--inTextBlock" data-turbo="false" href="" aria-label="Please reload this page">Please reload this page</a>.</p>
</p>

</div>  </div>
</div>  </div>
</include-fragment>

    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="insights-tab" href="/coderonion/awesome-yolo-object-detection/pulse" data-tab-item="i6insights-tab" data-selected-links="repo_graphs repo_contributors dependency_graph dependabot_updates pulse people community /coderonion/awesome-yolo-object-detection/pulse" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Insights&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-graph UnderlineNav-octicon d-none d-sm-inline">
    <path d="M1.5 1.75V13.5h13.75a.75.75 0 0 1 0 1.5H.75a.75.75 0 0 1-.75-.75V1.75a.75.75 0 0 1 1.5 0Zm14.28 2.53-5.25 5.25a.75.75 0 0 1-1.06 0L7 7.06 4.28 9.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.25-3.25a.75.75 0 0 1 1.06 0L10 7.94l4.72-4.72a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z"></path>
</svg>
        <span data-content="Insights">Insights</span>
          <span id="insights-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true" class="Counter"></span>


    
</a></li>
</ul>
    <div style="visibility:hidden;" data-view-component="true" class="UnderlineNav-actions js-responsive-underlinenav-overflow position-absolute pr-3 pr-md-4 pr-lg-5 right-0">      <action-menu data-select-variant="none" data-view-component="true">
  <focus-group direction="vertical" mnemonics retain>
    <button id="action-menu-6e714272-20ae-466e-999e-e4d9aa1b3744-button" popovertarget="action-menu-6e714272-20ae-466e-999e-e4d9aa1b3744-overlay" aria-controls="action-menu-6e714272-20ae-466e-999e-e4d9aa1b3744-list" aria-haspopup="true" aria-labelledby="tooltip-5b7699ec-457b-4e21-8f97-be263f879bdc" type="button" data-view-component="true" class="Button Button--iconOnly Button--secondary Button--medium UnderlineNav-item">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-kebab-horizontal Button-visual">
    <path d="M8 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3ZM1.5 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Zm13 0a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path>
</svg>
</button><tool-tip id="tooltip-5b7699ec-457b-4e21-8f97-be263f879bdc" for="action-menu-6e714272-20ae-466e-999e-e4d9aa1b3744-button" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute">Additional navigation options</tool-tip>


<anchored-position data-target="action-menu.overlay" id="action-menu-6e714272-20ae-466e-999e-e4d9aa1b3744-overlay" anchor="action-menu-6e714272-20ae-466e-999e-e4d9aa1b3744-button" align="start" side="outside-bottom" anchor-offset="normal" popover="auto" data-view-component="true">
  <div data-view-component="true" class="Overlay Overlay--size-auto">
    
      <div data-view-component="true" class="Overlay-body Overlay-body--paddingNone">          <action-list>
  <div data-view-component="true">
    <ul aria-labelledby="action-menu-6e714272-20ae-466e-999e-e4d9aa1b3744-button" id="action-menu-6e714272-20ae-466e-999e-e4d9aa1b3744-list" role="menu" data-view-component="true" class="ActionListWrap--inset ActionListWrap">
        <li hidden="hidden" data-menu-item="i0code-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-bf566beb-3206-43a3-946b-7deb5ab1efcd" href="/coderonion/awesome-yolo-object-detection" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-code">
    <path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Code
</span>      
</a>
  
</li>
        <li hidden="hidden" data-menu-item="i1issues-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-6e824c7c-67d1-4c70-aa54-1fdab60d5f02" href="/coderonion/awesome-yolo-object-detection/issues" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-issue-opened">
    <path d="M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Issues
</span>      
</a>
  
</li>
        <li hidden="hidden" data-menu-item="i2pull-requests-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-adf3aa77-8b7c-4eda-852e-355615c3236a" href="/coderonion/awesome-yolo-object-detection/pulls" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-git-pull-request">
    <path d="M1.5 3.25a2.25 2.25 0 1 1 3 2.122v5.256a2.251 2.251 0 1 1-1.5 0V5.372A2.25 2.25 0 0 1 1.5 3.25Zm5.677-.177L9.573.677A.25.25 0 0 1 10 .854V2.5h1A2.5 2.5 0 0 1 13.5 5v5.628a2.251 2.251 0 1 1-1.5 0V5a1 1 0 0 0-1-1h-1v1.646a.25.25 0 0 1-.427.177L7.177 3.427a.25.25 0 0 1 0-.354ZM3.75 2.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm0 9.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm8.25.75a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Pull requests
</span>      
</a>
  
</li>
        <li hidden="hidden" data-menu-item="i3actions-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-fb67ea4b-6fdb-45e1-ac9e-a2bd62d48a04" href="/coderonion/awesome-yolo-object-detection/actions" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-play">
    <path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Actions
</span>      
</a>
  
</li>
        <li hidden="hidden" data-menu-item="i4projects-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-99be6164-f953-4248-b6ec-1ac8b937f463" href="/coderonion/awesome-yolo-object-detection/projects" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-table">
    <path d="M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25ZM6.5 6.5v8h7.75a.25.25 0 0 0 .25-.25V6.5Zm8-1.5V1.75a.25.25 0 0 0-.25-.25H6.5V5Zm-13 1.5v7.75c0 .138.112.25.25.25H5v-8ZM5 5V1.5H1.75a.25.25 0 0 0-.25.25V5Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Projects
</span>      
</a>
  
</li>
        <li hidden="hidden" data-menu-item="i5security-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-4b52e30a-08b4-4856-8594-10bcca522c56" href="/coderonion/awesome-yolo-object-detection/security" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-shield">
    <path d="M7.467.133a1.748 1.748 0 0 1 1.066 0l5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667Zm.61 1.429a.25.25 0 0 0-.153 0l-5.25 1.68a.25.25 0 0 0-.174.238V7c0 1.358.275 2.666 1.057 3.86.784 1.194 2.121 2.34 4.366 3.297a.196.196 0 0 0 .154 0c2.245-.956 3.582-2.104 4.366-3.298C13.225 9.666 13.5 8.36 13.5 7V3.48a.251.251 0 0 0-.174-.237l-5.25-1.68ZM8.75 4.75v3a.75.75 0 0 1-1.5 0v-3a.75.75 0 0 1 1.5 0ZM9 10.5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Security
</span>      
</a>
  
</li>
        <li hidden="hidden" data-menu-item="i6insights-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-a1450798-9d73-42e4-9f84-4181571697e8" href="/coderonion/awesome-yolo-object-detection/pulse" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-graph">
    <path d="M1.5 1.75V13.5h13.75a.75.75 0 0 1 0 1.5H.75a.75.75 0 0 1-.75-.75V1.75a.75.75 0 0 1 1.5 0Zm14.28 2.53-5.25 5.25a.75.75 0 0 1-1.06 0L7 7.06 4.28 9.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.25-3.25a.75.75 0 0 1 1.06 0L10 7.94l4.72-4.72a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Insights
</span>      
</a>
  
</li>
</ul>    
</div></action-list>


</div>
      
</div></anchored-position>  </focus-group>
</action-menu></div>
</nav>

  </div>

  



<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance" class="">
    <div id="repo-content-pjax-container" class="repository-content " >
    



    
      
  <h1 class='sr-only'>coderonion/awesome-yolo-object-detection</h1>
  <div class="clearfix container-xl px-md-4 px-lg-5 px-3">
    <div>

  <div style="max-width: 100%" data-view-component="true" class="Layout Layout--flowRow-until-md react-repos-overview-margin Layout--sidebarPosition-end Layout--sidebarPosition-flowRow-end">
  <div data-view-component="true" class="Layout-main">      <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.f595f41454298e934d3c.module.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/app_assets_modules_react-partials_repos-overview_components_OverviewContent_module_css-app_as-2f8a17.0268c3a576b1dbc77d72.module.css" />

<react-partial
  partial-name="repos-overview"
  data-ssr="false"
  data-attempted-ssr="true"
  data-react-profiling="false"
>
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{"initialPayload":{"allShortcutsEnabled":false,"path":"/","repo":{"id":461270746,"defaultBranch":"main","name":"awesome-yolo-object-detection","ownerLogin":"coderonion","currentUserCanPush":false,"isFork":false,"isEmpty":false,"createdAt":"2022-02-19T17:57:06.000Z","ownerAvatar":"https://avatars.githubusercontent.com/u/99076655?v=4","public":true,"private":false,"isOrgOwned":false},"currentUser":null,"refInfo":{"name":"main","listCacheKey":"v0:1645293775.060168","canEdit":false,"refType":"branch","currentOid":"2e64f9d661bae442684585d3158b01e9f70853c6"},"tree":{"items":[{"name":"README.md","path":"README.md","contentType":"file"}],"templateDirectorySuggestionUrl":null,"readme":null,"totalCount":1,"showBranchInfobar":false},"fileTree":null,"fileTreeProcessingTime":null,"foldersToFetch":[],"treeExpanded":false,"symbolsExpanded":false,"copilotSWEAgentEnabled":false,"isOverview":true,"overview":{"banners":{"shouldRecommendReadme":false,"isPersonalRepo":false,"showUseActionBanner":false,"actionSlug":null,"actionId":null,"showProtectBranchBanner":false,"publishBannersInfo":{"dismissActionNoticePath":"/settings/dismiss-notice/publish_action_from_repo","releasePath":"/coderonion/awesome-yolo-object-detection/releases/new?marketplace=true","showPublishActionBanner":false},"interactionLimitBanner":null,"showInvitationBanner":false,"inviterName":null,"actionsMigrationBannerInfo":{"releaseTags":[],"showImmutableActionsMigrationBanner":false,"initialMigrationStatus":null},"showDeployBanner":false,"detectedStack":{"framework":null,"packageManager":null}},"codeButton":{"contactPath":"/contact","isEnterprise":false,"local":{"protocolInfo":{"httpAvailable":true,"sshAvailable":null,"httpUrl":"https://github.com/coderonion/awesome-yolo-object-detection.git","showCloneWarning":null,"sshUrl":null,"sshCertificatesRequired":null,"sshCertificatesAvailable":null,"ghCliUrl":"gh repo clone coderonion/awesome-yolo-object-detection","defaultProtocol":"http","newSshKeyUrl":"/settings/ssh/new","setProtocolPath":"/users/set_protocol"},"platformInfo":{"cloneUrl":"https://desktop.github.com","showVisualStudioCloneButton":false,"visualStudioCloneUrl":"https://windows.github.com","showXcodeCloneButton":false,"xcodeCloneUrl":"xcode://clone?repo=https%3A%2F%2Fgithub.com%2Fcoderonion%2Fawesome-yolo-object-detection","zipballUrl":"/coderonion/awesome-yolo-object-detection/archive/refs/heads/main.zip"}},"newCodespacePath":"/codespaces/new?hide_repo_select=true\u0026repo=461270746"},"popovers":{"rename":null,"renamedParentRepo":null},"commitCount":"410","overviewFiles":[{"displayName":"README.md","repoName":"awesome-yolo-object-detection","refName":"main","path":"README.md","preferredFileType":"readme","tabName":"README","richText":"\u003carticle class=\"markdown-body entry-content container-lg\" itemprop=\"text\"\u003e\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch1 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAwesome-YOLO-Object-Detection\u003c/h1\u003e\u003ca id=\"user-content-awesome-yolo-object-detection\" class=\"anchor\" aria-label=\"Permalink: Awesome-YOLO-Object-Detection\" href=\"#awesome-yolo-object-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sindresorhus/awesome\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8693bde04030b1670d5097703441005eba34240c32d1df1eb82a5f0d6716518e/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667\" alt=\"Awesome\" data-canonical-src=\"https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eðŸš€ðŸš€ðŸš€ YOLO is a great real-time one-stage object detection framework. This repository lists some awesome public YOLO object detection projects and datasets.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eContents\u003c/h2\u003e\u003ca id=\"user-content-contents\" class=\"anchor\" aria-label=\"Permalink: Contents\" href=\"#contents\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#awesome-yolo-object-detection\"\u003eAwesome-YOLO-Object-Detection\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#summary\"\u003eSummary\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#famous-yolo\"\u003eFamous YOLO\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#extensional-frameworks\"\u003eExtensional Frameworks\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#awesome-list\"\u003eAwesome List\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#paper-and-code-overview\"\u003ePaper and Code Overview\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#paper-review\"\u003ePaper Review\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#code-review\"\u003eCode Review\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#learning-resources\"\u003eLearning Resources\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#other-versions-of-yolo\"\u003eOther Versions of YOLO\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#pytorch-implementation\"\u003ePyTorch Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#c-implementation\"\u003eC Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#cpp-implementation\"\u003eCPP Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#ros-implementation\"\u003eROS Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#mojo-implementation\"\u003eMojo Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#rust-implementation\"\u003eRust Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#go-implementation\"\u003eGo Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#csharp-implementation\"\u003eCSharp Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#tensorflow-and-keras-implementation\"\u003eTensorflow and Keras Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#paddlepaddle-implementation\"\u003ePaddlePaddle Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#caffe-implementation\"\u003eCaffe Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#mxnet-implementation\"\u003eMXNet Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#web-implementation\"\u003eWeb Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#others\"\u003eOthers\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#lighter-and-deployment-frameworks\"\u003eLighter and Deployment Frameworks\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#high-performance-inference-engine\"\u003eHigh-performance Inference Engine\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#onnx\"\u003eONNX\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#tensorrt\"\u003eTensorRT\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#deepstream\"\u003eDeepStream\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#openvino\"\u003eOpenVINO\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#ncnn\"\u003eNCNN\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#mnn\"\u003eMNN\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#other-engine\"\u003eOther Engine\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#npu-and-fpga-hardware-deployment\"\u003eNPU and FPGA Hardware Deployment\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#rk3588\"\u003eRK3588\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#fpga\"\u003eFPGA\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#other-hardware\"\u003eOther Hardware\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#pruning-knoweldge-distillation-quantization\"\u003ePruning Knoweldge-Distillation Quantization\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#pruning\"\u003ePruning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#quantization\"\u003eQuantization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#knoweldge-distillation\"\u003eKnoweldge-Distillation\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#lightweight-backbones-and-fpn\"\u003eLightweight Backbones and FPN\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#object-detection-applications\"\u003eObject Detection Applications\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#open-world-object-detection\"\u003eOpen World Object Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#few-shot-object-detection\"\u003eFew-shot Object Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#small-object-detection\"\u003eSmall Object Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#multimodal-image-detection\"\u003eMultimodal Image Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#video-object-detection\"\u003eVideo Object Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#object-tracking\"\u003eObject Tracking\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#multi-object-tracking\"\u003eMulti-Object Tracking\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#Dynamic-object-tracking\"\u003eDynamic Object Tracking\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#deep-reinforcement-learning\"\u003eDeep Reinforcement Learning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#motion-control-field\"\u003eMotion Control Field\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#super-resolution-field\"\u003eSuper-Resolution Field\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#spiking-neural-network\"\u003eSpiking Neural Network\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#attention-and-transformer\"\u003eAttention and Transformer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#oriented-object-detection\"\u003eOriented Object Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#face-detection-and-recognition\"\u003eFace Detection and Recognition\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#face-detection\"\u003eFace Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#face-recognition\"\u003eFace Recognition\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#face-mask-detection\"\u003eFace Mask Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#social-distance-detection\"\u003eSocial Distance Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#autonomous-driving-field-detection\"\u003eAutonomous Driving Field Detection\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#vehicle-detection\"\u003eVehicle Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#license-plate-detection-and-recognition\"\u003eLicense Plate Detection and Recognition\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#lane-detection\"\u003eLane Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#driving-behavior-detection\"\u003eDriving Behavior Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#parking-slot-detection\"\u003eParking Slot Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#traffic-light-detection\"\u003eTraffic Light Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#traffic-sign-detection\"\u003eTraffic Sign Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#crosswalk-detection\"\u003eCrosswalk Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#traffic-accidents-detection\"\u003eTraffic Accidents Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#road-damage-detection\"\u003eRoad Damage Detection\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#animal-detection\"\u003eAnimal Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#helmet-detection\"\u003eHelmet Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#hand-detection\"\u003eHand Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#gesture-recognition\"\u003eGesture Recognition\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#action-detection\"\u003eAction Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#emotion-recognition\"\u003eEmotion Recognition\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#human-pose-estimation\"\u003eHuman Pose Estimation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#distance-measurement\"\u003eDistance Measurement\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#instance-and-semantic-segmentation\"\u003eInstance and Semantic Segmentation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#3d-object-detection\"\u003e3D Object Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#slam-field-detection\"\u003eSLAM Field Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#industrial-defect-detection\"\u003eIndustrial Defect Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#sar-image-detection\"\u003eSAR Image Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#safety-monitoring-field-detection\"\u003eSafety Monitoring Field Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#anti-uav-field-detection\"\u003eAnti-UAV Field Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#medical-field-detection\"\u003eMedical Field Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#chemistry-field-detection\"\u003eChemistry Field Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#agricultural-field-detection\"\u003eAgricultural Field Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#sports-field-detection\"\u003eSports Field Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#aerial-imagery-detection\"\u003eAerial Imagery Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#adverse-weather-conditions\"\u003eAdverse Weather Conditions\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#adversarial-attack-and-defense\"\u003eAdversarial Attack and Defense\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#camouflaged-detection\"\u003eCamouflaged Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#game-field-detection\"\u003eGame Field Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#automatic-annotation-tools\"\u003eAutomatic Annotation Tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#feature-map-visualization\"\u003eFeature Map Visualization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#object-detection-evaluation-metrics\"\u003eObject Detection Evaluation Metrics\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#gui\"\u003eGUI\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#swift-related\"\u003eSwift-Related\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#flutter-related\"\u003eFlutter-Related\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#streamlit-related\"\u003eStreamlit-Related\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#gradio-related\"\u003eGradio-Related\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#qt-related\"\u003eQT-Related\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#pyside-related\"\u003ePySide-Related\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#other-applications\"\u003eOther Applications\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#object-detection-datasets\"\u003eObject Detection Datasets\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#datasets-share-platform\"\u003eDatasets Share Platform\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#datasets-tools\"\u003eDatasets Tools\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#data-annotation\"\u003eData Annotation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#data-augmentation\"\u003eData Augmentation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#data-management\"\u003eData Management\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#general-detection-and-recognition-datasets\"\u003eGeneral Detection and Recognition Datasets\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#general-object-detection-datasets\"\u003eGeneral Object Detection Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#general-object-recognition-datasets\"\u003eGeneral Object Recognition Datasets\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#autonomous-driving-datasets\"\u003eAutonomous Driving Datasets\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#diverse-autonomous-driving-datasets\"\u003eDiverse Autonomous Driving Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#traffic-sign-detection-datasets\"\u003eTraffic Sign Detection Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#license-plate-detection-and-recognition-datasets\"\u003eLicense Plate Detection and Recognition Datasets\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#adverse-weather-datasets\"\u003eAdverse Weather Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#person-detection-datasets\"\u003ePerson Detection Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#anti-uav-datasets\"\u003eAnti-UAV Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#optical-aerial-imagery-datasets\"\u003eOptical Aerial Imagery Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#low-light-image-datasets\"\u003eLow-light Image Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#infrared-image-datasets\"\u003eInfrared Image Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#sar-image-datasets\"\u003eSAR Image Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#sonar-image-datasets\"\u003eSonar Image Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#multimodal-image-datasets\"\u003eMultimodal Image Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#3d-object-detection-datasets\"\u003e3D Object Detection Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#vehicle-to-everything-field-datasets\"\u003eVehicle-to-Everything Field Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#super-resolution-field-datasets\"\u003eSuper-Resolution Field Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#general-detection-and-recognition-datasets\"\u003eFace Detection and Recognition Datasets\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#face-detection-datasets\"\u003eFace Detection Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#face-recognition-datasets\"\u003eFace Recognition Datasets\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#blogs\"\u003eBlogs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#videos\"\u003eVideos\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSummary\u003c/h2\u003e\u003ca id=\"user-content-summary\" class=\"anchor\" aria-label=\"Permalink: Summary\" href=\"#summary\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFamous YOLO\u003c/h3\u003e\u003ca id=\"user-content-famous-yolo\" class=\"anchor\" aria-label=\"Permalink: Famous YOLO\" href=\"#famous-yolo\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://pjreddie.com/darknet/yolov1\" rel=\"nofollow\"\u003eYOLOv1\u003c/a\u003e (\u003ca href=\"https://github.com/pjreddie/darknet\"\u003eDarknet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e78db04b6860458ce48b5e37283248eaa001e108dc96b47135a89b088e322104/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a7265646469652f6461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e78db04b6860458ce48b5e37283248eaa001e108dc96b47135a89b088e322104/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a7265646469652f6461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pjreddie/darknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e) : \"You Only Look Once: Unified, Real-Time Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Redmon_You_Only_Look_CVPR_2016_paper.html\" rel=\"nofollow\"\u003eCVPR 2016\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://pjreddie.com/darknet/yolov2\" rel=\"nofollow\"\u003eYOLOv2\u003c/a\u003e (\u003ca href=\"https://github.com/pjreddie/darknet\"\u003eDarknet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e78db04b6860458ce48b5e37283248eaa001e108dc96b47135a89b088e322104/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a7265646469652f6461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e78db04b6860458ce48b5e37283248eaa001e108dc96b47135a89b088e322104/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a7265646469652f6461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pjreddie/darknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e) : \"YOLO9000: Better, Faster, Stronger\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_cvpr_2017/html/Redmon_YOLO9000_Better_Faster_CVPR_2017_paper.html\" rel=\"nofollow\"\u003eCVPR 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://pjreddie.com/darknet/yolo\" rel=\"nofollow\"\u003eYOLOv3\u003c/a\u003e (\u003ca href=\"https://github.com/pjreddie/darknet\"\u003eDarknet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e78db04b6860458ce48b5e37283248eaa001e108dc96b47135a89b088e322104/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a7265646469652f6461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e78db04b6860458ce48b5e37283248eaa001e108dc96b47135a89b088e322104/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a7265646469652f6461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pjreddie/darknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e) : \"YOLOv3: An Incremental Improvement\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1804.02767\" rel=\"nofollow\"\u003earXiv 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlexeyAB/darknet\"\u003eYOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7505022ae605a5ef90517df8e6a4dc3968e5ef0690bf8a25b096b10e7be52e02/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f6461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7505022ae605a5ef90517df8e6a4dc3968e5ef0690bf8a25b096b10e7be52e02/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f6461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlexeyAB/darknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e (\u003ca href=\"https://github.com/WongKinYiu/PyTorch_YOLOv4\"\u003eWongKinYiu/PyTorch_YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8c83f25931194dc8d66ccd01a9be4dd983a79e78a479e4b1c0e24cf51f3a482f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f5079546f7263685f594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8c83f25931194dc8d66ccd01a9be4dd983a79e78a479e4b1c0e24cf51f3a482f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f5079546f7263685f594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WongKinYiu/PyTorch_YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e) : \"YOLOv4: Optimal Speed and Accuracy of Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2004.10934\" rel=\"nofollow\"\u003earXiv 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlexeyAB/darknet\"\u003eScaled-YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7505022ae605a5ef90517df8e6a4dc3968e5ef0690bf8a25b096b10e7be52e02/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f6461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7505022ae605a5ef90517df8e6a4dc3968e5ef0690bf8a25b096b10e7be52e02/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f6461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlexeyAB/darknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e (\u003ca href=\"https://github.com/WongKinYiu/ScaledYOLOv4\"\u003eWongKinYiu/ScaledYOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0abe70c666d8b4efd9e6328cf5c3059b48694bbdec84a3e9425fa262f4d7ff0c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f5363616c6564594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0abe70c666d8b4efd9e6328cf5c3059b48694bbdec84a3e9425fa262f4d7ff0c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f5363616c6564594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WongKinYiu/ScaledYOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e) : \"Scaled-YOLOv4: Scaling Cross Stage Partial Network\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Scaled-YOLOv4_Scaling_Cross_Stage_Partial_Network_CVPR_2021_paper.html\" rel=\"nofollow\"\u003eCVPR 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ultralytics/yolov5\"\u003eYOLOv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c4b9baacd1c41802bd1cab446fd9e0918cdead966293fc2713e04ecd067b431d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c4b9baacd1c41802bd1cab446fd9e0918cdead966293fc2713e04ecd067b431d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ultralytics/yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 ðŸš€ in PyTorch \u0026gt; ONNX \u0026gt; CoreML \u0026gt; TFLite. \u003ca href=\"https://docs.ultralytics.com/\" rel=\"nofollow\"\u003edocs.ultralytics.com\u003c/a\u003e. YOLOv5 ðŸš€ is the world's most loved vision AI, representing \u003ca href=\"https://ultralytics.com/\" rel=\"nofollow\"\u003eUltralytics\u003c/a\u003e open-source research into future vision AI methods, incorporating lessons learned and best practices evolved over thousands of hours of research and development.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/meituan/YOLOv6\"\u003eYOLOv6\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f4fd0ceb4b638a82059e96ccf13d37d0f4d14c402857b8b68df56010c9c8209c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d65697475616e2f594f4c4f76363f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f4fd0ceb4b638a82059e96ccf13d37d0f4d14c402857b8b68df56010c9c8209c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d65697475616e2f594f4c4f76363f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/meituan/YOLOv6?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2209.02976\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WongKinYiu/yolov7\"\u003eYOLOv7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/92e74c40ebf900c86bd5f6f6912709d0ceea64a356c2ade1c048df317c8283bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f796f6c6f76373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/92e74c40ebf900c86bd5f6f6912709d0ceea64a356c2ade1c048df317c8283bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f796f6c6f76373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WongKinYiu/yolov7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2207.02696\" rel=\"nofollow\"\u003eCVPR 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ultralytics/ultralytics\"\u003eYOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6bb27e4c4557560b490abaee8cae2be867468ad0fe3c46ad3d106cbb0ef8766e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f756c7472616c79746963733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6bb27e4c4557560b490abaee8cae2be867468ad0fe3c46ad3d106cbb0ef8766e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f756c7472616c79746963733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ultralytics/ultralytics?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : NEW - YOLOv8 ðŸš€ in PyTorch \u0026gt; ONNX \u0026gt; OpenVINO \u0026gt; CoreML \u0026gt; TFLite. \u003ca href=\"https://docs.ultralytics.com/\" rel=\"nofollow\"\u003edocs.ultralytics.com\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WongKinYiu/yolov9\"\u003eYOLOv9\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/552a3c7c05050b066878c86eb77a49337c9ab68cbbc50a6bd0bf40958c5ae54c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f796f6c6f76393f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/552a3c7c05050b066878c86eb77a49337c9ab68cbbc50a6bd0bf40958c5ae54c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f796f6c6f76393f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WongKinYiu/yolov9?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2402.13616\" rel=\"nofollow\"\u003earXiv 2024\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MultimediaTechLab/YOLO\"\u003eMultimediaTechLab/YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cd2b684efe8400d761a589425755bdb5233b55715b29463d1de538a237f3374c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d756c74696d65646961546563684c61622f594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cd2b684efe8400d761a589425755bdb5233b55715b29463d1de538a237f3374c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d756c74696d65646961546563684c61622f594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MultimediaTechLab/YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO: Official Implementation of YOLOv9, YOLOv7, YOLO-RD. Welcome to the official implementation of YOLOv7 and YOLOv9, YOLO-RD. This repository will contains the complete codebase, pre-trained models, and detailed instructions for training and deploying YOLOv9.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/THU-MIG/yolov10\"\u003eYOLOv10\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/64311ea4b42dfd7858489a772f1384ff46d8a9301ef1ee04b28a38705888e475/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5448552d4d49472f796f6c6f7631303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/64311ea4b42dfd7858489a772f1384ff46d8a9301ef1ee04b28a38705888e475/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5448552d4d49472f796f6c6f7631303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/THU-MIG/yolov10?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOv10: Real-Time End-to-End Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2405.14458v1\" rel=\"nofollow\"\u003earXiv 2024\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ultralytics/ultralytics\"\u003eYOLOv11\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6bb27e4c4557560b490abaee8cae2be867468ad0fe3c46ad3d106cbb0ef8766e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f756c7472616c79746963733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6bb27e4c4557560b490abaee8cae2be867468ad0fe3c46ad3d106cbb0ef8766e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f756c7472616c79746963733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ultralytics/ultralytics?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : NEW - YOLOv8 ðŸš€ in PyTorch \u0026gt; ONNX \u0026gt; OpenVINO \u0026gt; CoreML \u0026gt; TFLite. \u003ca href=\"https://www.ultralytics.com/\" rel=\"nofollow\"\u003eUltralytics\u003c/a\u003e \u003ca href=\"https://github.com/ultralytics/ultralytics\"\u003eYOLOv11\u003c/a\u003e s a cutting-edge, state-of-the-art (SOTA) model that builds upon the success of previous YOLO versions and introduces new features and improvements to further boost performance and flexibility. YOLO11 is designed to be fast, accurate, and easy to use, making it an excellent choice for a wide range of object detection and tracking, instance segmentation, image classification and pose estimation tasks. \u003ca href=\"https://docs.ultralytics.com/\" rel=\"nofollow\"\u003edocs.ultralytics.com\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sunsmarterjie/yolov12\"\u003eYOLOv12\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a1b8c6ac4bef785acb7ab350cf7d86a4033215e711ebe3e87f093ebf1ae06539/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756e736d61727465726a69652f796f6c6f7631323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a1b8c6ac4bef785acb7ab350cf7d86a4033215e711ebe3e87f093ebf1ae06539/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756e736d61727465726a69652f796f6c6f7631323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sunsmarterjie/yolov12?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOv12: Attention-Centric Real-Time Object Detectors\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2502.12524\" rel=\"nofollow\"\u003earXiv 2025\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AILab-CVC/YOLO-World\"\u003eYOLO-World | YOLO-World-v2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4df4362f165830998e6956b59d1a08fcce2aa5a7c5018206bd948a4ecba4e178/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41494c61622d4356432f594f4c4f2d576f726c643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4df4362f165830998e6956b59d1a08fcce2aa5a7c5018206bd948a4ecba4e178/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41494c61622d4356432f594f4c4f2d576f726c643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AILab-CVC/YOLO-World?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLO-World: Real-Time Open-Vocabulary Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2401.17270\" rel=\"nofollow\"\u003eCVPR 2024\u003c/a\u003e\u003c/strong\u003e). \u003ca href=\"https://www.yoloworld.cc/\" rel=\"nofollow\"\u003ewww.yoloworld.cc\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/THU-MIG/yoloe\"\u003eYOLOE\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fcc2b287f618019615847350e34e3ae358e1c4d5c28473bd1fc37089756aec66/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5448552d4d49472f796f6c6f653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fcc2b287f618019615847350e34e3ae358e1c4d5c28473bd1fc37089756aec66/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5448552d4d49472f796f6c6f653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/THU-MIG/yoloe?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOE: Real-Time Seeing Anything\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2503.07465\" rel=\"nofollow\"\u003earXiv 2025\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eExtensional Frameworks\u003c/h3\u003e\u003ca id=\"user-content-extensional-frameworks\" class=\"anchor\" aria-label=\"Permalink: Extensional Frameworks\" href=\"#extensional-frameworks\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/QwenLM/Qwen2.5-VL\"\u003eQwen2.5-VL\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6e720aab8cce54c328ac3bfc79ce069691aa012cee4b48e05bf6eb46cf458839/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5177656e4c4d2f5177656e322d564c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6e720aab8cce54c328ac3bfc79ce069691aa012cee4b48e05bf6eb46cf458839/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5177656e4c4d2f5177656e322d564c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/QwenLM/Qwen2-VL?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Qwen2-VL is the multimodal large language model series developed by Qwen team, Alibaba Cloud. \"Qwen2.5-VL Technical Report\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2502.13923\" rel=\"nofollow\"\u003earXiv 2025\u003c/a\u003e\u003c/strong\u003e). \u003ca href=\"https://qwenlm.github.io/blog/qwen2.5-vl/\" rel=\"nofollow\"\u003e2025-01-26ï¼ŒQwen2.5 VL! Qwen2.5 VL! Qwen2.5 VL!\u003c/a\u003e. \"Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2409.12191\" rel=\"nofollow\"\u003earXiv 2024\u003c/a\u003e\u003c/strong\u003e). \"Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2308.12966\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MoonshotAI/Kimi-VL\"\u003eKimi-VL\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/011986e97c7e150ec0e2eb40dede4c9cdb464955d869db5de2bca7e86604b65a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f6f6e73686f7441492f4b696d692d564c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/011986e97c7e150ec0e2eb40dede4c9cdb464955d869db5de2bca7e86604b65a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f6f6e73686f7441492f4b696d692d564c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MoonshotAI/Kimi-VL?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Kimi-VL: Mixture-of-Experts Vision-Language Model for Multimodal Reasoning, Long-Context Understanding, and Strong Agent Capabilities. \"Kimi-VL Technical Report\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2504.07491\" rel=\"nofollow\"\u003earXiv 2025\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Liuziyu77/Visual-RFT\"\u003eVisual-RFT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2395d7d5e78f5fcb5b4d1368e3827df4a95489eac47d951f7ca4fd1d045aafbd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c69757a69797537372f56697375616c2d5246543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2395d7d5e78f5fcb5b4d1368e3827df4a95489eac47d951f7ca4fd1d045aafbd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c69757a69797537372f56697375616c2d5246543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Liuziyu77/Visual-RFT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸŒˆWe introduce Visual Reinforcement Fine-tuning (Visual-RFT), the first comprehensive adaptation of Deepseek-R1's RL strategy to the multimodal field. We use the Qwen2-VL-2/7B model as our base model and design a rule-based verifiable reward, which is integrated into a GRPO-based reinforcement fine-tuning framework to enhance the performance of LVLMs across various visual perception tasks. ViRFT extends R1's reasoning capabilities to multiple visual perception tasks, including various detection tasks like Open Vocabulary Detection, Few-shot Detection, Reasoning Grounding, and Fine-grained Image Classification. \"Visual-RFT: Visual Reinforcement Fine-Tuning\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2503.01785\" rel=\"nofollow\"\u003earXiv 2025\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/om-ai-lab/VLM-R1\"\u003eVLM-R1\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8816d165d9d4557df7579f42faae766a69d1fa60febc29cb4ba8f1186a5e0859/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6d2d61692d6c61622f564c4d2d52313f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8816d165d9d4557df7579f42faae766a69d1fa60febc29cb4ba8f1186a5e0859/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6d2d61692d6c61622f564c4d2d52313f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/om-ai-lab/VLM-R1?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : VLM-R1: A stable and generalizable R1-style Large Vision-Language Model. Solve Visual Understanding with Reinforced VLMs. \u003ca href=\"https://om-ai-lab.github.io/2025_03_20.html\" rel=\"nofollow\"\u003e2025-03-20ï¼ŒImproving Object Detection through Reinforcement Learning with VLM-R1\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eFlorence-2 : \"Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2311.06242\" rel=\"nofollow\"\u003eCVPR 2024\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/roboflow/maestro\"\u003emaestro\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3809d33b5bd6d0de50380b668f794c9e27a8d01a46fd303435cf426181fff8f1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626f666c6f772f6d61657374726f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3809d33b5bd6d0de50380b668f794c9e27a8d01a46fd303435cf426181fff8f1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626f666c6f772f6d61657374726f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/roboflow/maestro?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : VLM fine-tuning for everyone. maestro is a streamlined tool to accelerate the fine-tuning of multimodal models. By encapsulating best practices from our core modules, maestro handles configuration, data loading, reproducibility, and training loop setup. It currently offers ready-to-use recipes for popular vision-language models such as \u003ca href=\"https://arxiv.org/abs/2311.06242\" rel=\"nofollow\"\u003eFlorence-2\u003c/a\u003e, PaliGemma 2, and \u003ca href=\"https://github.com/QwenLM/Qwen2.5-VL\"\u003eQwen2.5-VL\u003c/a\u003e. \u003ca href=\"https://maestro.roboflow.com/latest/\" rel=\"nofollow\"\u003emaestro.roboflow.com\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/autodistill/autodistill\"\u003eAutodistill\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c62d847952be21af33a3611f569579505b739360aa218da771156aec4b408990/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6175746f64697374696c6c2f6175746f64697374696c6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c62d847952be21af33a3611f569579505b739360aa218da771156aec4b408990/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6175746f64697374696c6c2f6175746f64697374696c6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/autodistill/autodistill?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Images to inference with no labeling (use foundation models to train supervised models). Autodistill uses big, slower foundation models to train small, faster supervised models. Using autodistill, you can go from unlabeled images to inference on a custom model running at the edge with no human intervention in between. \u003ca href=\"https://docs.autodistill.com/\" rel=\"nofollow\"\u003edocs.autodistill.com\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LSH9832/edgeyolo\"\u003eEdgeYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/71bfe61077c58d0fa253ac07bd7e94e96e3eb3b1b3c7e62400b70a761da7664b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5348393833322f65646765796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/71bfe61077c58d0fa253ac07bd7e94e96e3eb3b1b3c7e62400b70a761da7664b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5348393833322f65646765796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LSH9832/edgeyolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : an edge-real-time anchor-free object detector with decent performance. \"Edge YOLO: Real-time intelligent object detection system based on edge-cloud cooperation in autonomous vehicles\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9740044\" rel=\"nofollow\"\u003eIEEE Transactions on Intelligent Transportation Systems, 2022\u003c/a\u003e\u003c/strong\u003e). \"EdgeYOLO: An Edge-Real-Time Object Detector\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2302.07483\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Megvii-BaseDetection/YOLOX\"\u003eYOLOX\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/216991188cbd256de25dc70a644f6e63b29358e53654f11778585bffd1416da8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d65677669692d42617365446574656374696f6e2f594f4c4f583f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/216991188cbd256de25dc70a644f6e63b29358e53654f11778585bffd1416da8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d65677669692d42617365446574656374696f6e2f594f4c4f583f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Megvii-BaseDetection/YOLOX?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOX: Exceeding YOLO Series in 2021\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2107.08430\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WongKinYiu/yolor\"\u003eYOLOR\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/20cb2135d98c84d6dc559a8fa4a8f4d9e3a383f79393fedf79c391fc755fa8cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f796f6c6f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/20cb2135d98c84d6dc559a8fa4a8f4d9e3a383f79393fedf79c391fc755fa8cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f796f6c6f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WongKinYiu/yolor?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"You Only Learn One Representation: Unified Network for Multiple Tasks\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2105.04206\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/megvii-model/YOLOF\"\u003eYOLOF\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9c9a60bdbf73bf12079a039743429cc3acc217b5f7e914e5e5e867ecd76cc13b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d65677669692d6d6f64656c2f594f4c4f463f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9c9a60bdbf73bf12079a039743429cc3acc217b5f7e914e5e5e867ecd76cc13b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d65677669692d6d6f64656c2f594f4c4f463f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/megvii-model/YOLOF?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"You Only Look One-level Feature\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2021/html/Chen_You_Only_Look_One-Level_Feature_CVPR_2021_paper.html\" rel=\"nofollow\"\u003eCVPR 2021\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hustvl/YOLOS\"\u003eYOLOS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/347d7acb3be34eb896c567936c6a53ba9e26ab0e70a8d4e71157680739694d10/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68757374766c2f594f4c4f533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/347d7acb3be34eb896c567936c6a53ba9e26ab0e70a8d4e71157680739694d10/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68757374766c2f594f4c4f533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hustvl/YOLOS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://proceedings.neurips.cc//paper/2021/hash/dc912a253d1e9ba40e2c597ed2376640-Abstract.html\" rel=\"nofollow\"\u003eNeurIPS 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tinyvision/DAMO-YOLO\"\u003eDAMO-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8dfabfb8ae32aaaf9b6849682e80dba0b7d10fe7b47b2dae00075106167c24c3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74696e79766973696f6e2f44414d4f2d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8dfabfb8ae32aaaf9b6849682e80dba0b7d10fe7b47b2dae00075106167c24c3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74696e79766973696f6e2f44414d4f2d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tinyvision/DAMO-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : DAMO-YOLO: a fast and accurate object detection method with some new techs, including NAS backbones, efficient RepGFPN, ZeroHead, AlignedOTA, and distillation enhancement. \"DAMO-YOLO : A Report on Real-Time Object Detection Design\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2211.15444\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Deci-AI/super-gradients\"\u003eYOLO-NAS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4d0992a13a31e5cf5ec6c1ec57c766f06455bcbf8d951e5a1463cf95dcd3f8e6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f446563692d41492f73757065722d6772616469656e74733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4d0992a13a31e5cf5ec6c1ec57c766f06455bcbf8d951e5a1463cf95dcd3f8e6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f446563692d41492f73757065722d6772616469656e74733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Deci-AI/super-gradients?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Easily train or fine-tune SOTA computer vision models with one open source training library. The home of \u003ca href=\"https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md\"\u003eYolo-NAS\u003c/a\u003e. \u003ca href=\"https://www.supergradients.com/\" rel=\"nofollow\"\u003ewww.supergradients.com\u003c/a\u003e. YOLO-NAS and YOLO-NAS-POSE architectures are out! The new YOLO-NAS delivers state-of-the-art performance with the unparalleled accuracy-speed performance, outperforming other models such as YOLOv5, YOLOv6, YOLOv7 and YOLOv8.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LilianHollard/LeYOLO\"\u003eLeYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6e8a1dc7e95f4d2b716635fe5606df68f9fd5c8b9c84d86a497f47ea6aca4221/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696c69616e486f6c6c6172642f4c65594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6e8a1dc7e95f4d2b716635fe5606df68f9fd5c8b9c84d86a497f47ea6aca4221/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696c69616e486f6c6c6172642f4c65594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LilianHollard/LeYOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"LeYOLO, New Scalable and Efficient CNN Architecture for Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2406.14239\" rel=\"nofollow\"\u003earXiv 2024\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/VDIGPKU/DynamicDet\"\u003eDynamicDet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/faa55adc7dd61e2f19de8e1e13e863a958ea99c650bc4a284f0381af8550b9bb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f56444947504b552f44796e616d69634465743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/faa55adc7dd61e2f19de8e1e13e863a958ea99c650bc4a284f0381af8550b9bb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f56444947504b552f44796e616d69634465743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/VDIGPKU/DynamicDet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"DynamicDet: A Unified Dynamic Architecture for Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2304.05552\" rel=\"nofollow\"\u003eCVPR 2023\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/IDEA-Research/DINO\"\u003eDINO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/17073ac7af4a5232b8652ef3b492f099a110784cc8b717523588714bc6553cb3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f44494e4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/17073ac7af4a5232b8652ef3b492f099a110784cc8b717523588714bc6553cb3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f44494e4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/IDEA-Research/DINO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2203.03605\" rel=\"nofollow\"\u003eICLR 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/IDEA-Research/GroundingDINO\"\u003eGroundingDINO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c6a434d03c84765d1ca6368c83522ccc7b0b5178349b2d0e2de3ef764d9be71e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f47726f756e64696e6744494e4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c6a434d03c84765d1ca6368c83522ccc7b0b5178349b2d0e2de3ef764d9be71e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f47726f756e64696e6744494e4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/IDEA-Research/GroundingDINO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2303.05499\" rel=\"nofollow\"\u003eECCV 2024\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lyuwenyu/RT-DETR\"\u003eRT-DETR | RT-DETRv2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b2943964cc1d38f2ae4eaa2c577a2830fbf2c083628cb5d9d30045ebe9d8ca58/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c797577656e79752f52542d444554523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b2943964cc1d38f2ae4eaa2c577a2830fbf2c083628cb5d9d30045ebe9d8ca58/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c797577656e79752f52542d444554523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lyuwenyu/RT-DETR?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"DETRs Beat YOLOs on Real-time Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2304.08069\" rel=\"nofollow\"\u003eCVPR 2024\u003c/a\u003e\u003c/strong\u003e). \"RT-DETRv2: Improved Baseline with Bag-of-Freebies for Real-Time Detection Transformer\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2407.17140\" rel=\"nofollow\"\u003earXiv 2024\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/alibaba/EasyCV\"\u003eEasyCV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3445dcd3d4af94bc921084370d5ececf1fdc295c61cd9cea76eac458a4937c38/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69626162612f4561737943563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3445dcd3d4af94bc921084370d5ececf1fdc295c61cd9cea76eac458a4937c38/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69626162612f4561737943563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/alibaba/EasyCV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An all-in-one toolkit for computer vision. \"YOLOX-PAI: An Improved YOLOX, Stronger and Faster than YOLOv6\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2208.13040\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dbolya/yolact\"\u003eYOLACT \u0026amp; YOLACT++\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a4f07a5ee346ff8bc58cccce5b08db570e6ef17727e6942901a72acbd0fd8b32/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64626f6c79612f796f6c6163743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a4f07a5ee346ff8bc58cccce5b08db570e6ef17727e6942901a72acbd0fd8b32/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64626f6c79612f796f6c6163743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dbolya/yolact?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : You Only Look At CoefficienTs. (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_ICCV_2019/html/Bolya_YOLACT_Real-Time_Instance_Segmentation_ICCV_2019_paper.html\" rel=\"nofollow\"\u003eICCV 2019\u003c/a\u003e, \u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9159935\" rel=\"nofollow\"\u003eIEEE TPAMI 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Jacobi93/Alpha-IoU\"\u003eAlpha-IoU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0c0ad215c33dafea285b25dbe6c63163bea9a290c31a6b1954ba62346fb93c69/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61636f626939332f416c7068612d496f553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0c0ad215c33dafea285b25dbe6c63163bea9a290c31a6b1954ba62346fb93c69/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61636f626939332f416c7068612d496f553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Jacobi93/Alpha-IoU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Alpha-IoU: A Family of Power Intersection over Union Losses for Bounding Box Regression\". (\u003cstrong\u003e\u003ca href=\"https://proceedings.neurips.cc//paper/2021/hash/a8f15eda80c50adb0e71943adc8015cf-Abstract.html\" rel=\"nofollow\"\u003eNeurIPS 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Zzh-tju/CIoU\"\u003eCIoU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3368cfb8d9c4c09f7dee503476dd80b00371f00c1d5f77c05e63ca11877e52cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a7a682d746a752f43496f553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3368cfb8d9c4c09f7dee503476dd80b00371f00c1d5f77c05e63ca11877e52cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a7a682d746a752f43496f553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Zzh-tju/CIoU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Complete-IoU (CIoU) Loss and Cluster-NMS for Object Detection and Instance Segmentation (YOLACT). (\u003cstrong\u003e\u003ca href=\"https://ojs.aaai.org/index.php/AAAI/article/view/6999\" rel=\"nofollow\"\u003eAAAI 2020\u003c/a\u003e, \u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9523600\" rel=\"nofollow\"\u003eIEEE TCYB 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/albumentations-team/albumentations\"\u003eAlbumentations\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/84c7a1c3a26134634d9163e335f0f5413cc53dd7befcd137da96b91aa7b41ed7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c62756d656e746174696f6e732d7465616d2f616c62756d656e746174696f6e733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/84c7a1c3a26134634d9163e335f0f5413cc53dd7befcd137da96b91aa7b41ed7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c62756d656e746174696f6e732d7465616d2f616c62756d656e746174696f6e733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/albumentations-team/albumentations?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Albumentations is a Python library for image augmentation. Image augmentation is used in deep learning and computer vision tasks to increase the quality of trained models. The purpose of image augmentation is to create new training samples from the existing data. \"Albumentations: Fast and Flexible Image Augmentations\". (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/2078-2489/11/2/125\" rel=\"nofollow\"\u003eInformation 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/doubleZ0108/Data-Augmentation\"\u003edoubleZ0108/Data-Augmentation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/aedc1387893882413eb22185722d1e0516af2d2abf95dde86dfdbe432b0aa677/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f75626c655a303130382f446174612d4175676d656e746174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/aedc1387893882413eb22185722d1e0516af2d2abf95dde86dfdbe432b0aa677/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f75626c655a303130382f446174612d4175676d656e746174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/doubleZ0108/Data-Augmentation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : General Data Augmentation Algorithms for Object Detection(esp. Yolo).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAwesome List\u003c/h3\u003e\u003ca id=\"user-content-awesome-list\" class=\"anchor\" aria-label=\"Permalink: Awesome List\" href=\"#awesome-list\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/coderonion/awesome-yolo-object-detection\"\u003eawesome-yolo-object-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/377d1f49944e12ae91ac2b8d6d391f35f2d5a51d89400d4dd563a5c080336f69/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636f6465726f6e696f6e2f617765736f6d652d796f6c6f2d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/377d1f49944e12ae91ac2b8d6d391f35f2d5a51d89400d4dd563a5c080336f69/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636f6465726f6e696f6e2f617765736f6d652d796f6c6f2d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/coderonion/awesome-yolo-object-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸš€ðŸš€ðŸš€ A collection of some awesome public YOLO object detection series projects and the related object detection datasets.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/srebroa/awesome-yolo\"\u003esrebroa/awesome-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/724ab0f93c843e89419702d529be92bf0f7b53b9d48460675c17751aae4faedb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73726562726f612f617765736f6d652d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/724ab0f93c843e89419702d529be92bf0f7b53b9d48460675c17751aae4faedb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73726562726f612f617765736f6d652d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/srebroa/awesome-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸš€ â­ The list of the most popular YOLO algorithms - awesome YOLO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Bubble-water/YOLO-Summary\"\u003eBubble-water/YOLO-Summary\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d081d0e1f4038de91235e244a323df1bdf6b078dcf737287f1c122c305db51a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427562626c652d77617465722f594f4c4f2d53756d6d6172793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d081d0e1f4038de91235e244a323df1bdf6b078dcf737287f1c122c305db51a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427562626c652d77617465722f594f4c4f2d53756d6d6172793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Bubble-water/YOLO-Summary?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO-Summary.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WZMIAOMIAO/deep-learning-for-image-processing\"\u003eWZMIAOMIAO/deep-learning-for-image-processing\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7f11beb96be0cfc8857720624fd199880e4477cb7f9f5811fabe17ff54d7f2af/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f575a4d49414f4d49414f2f646565702d6c6561726e696e672d666f722d696d6167652d70726f63657373696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7f11beb96be0cfc8857720624fd199880e4477cb7f9f5811fabe17ff54d7f2af/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f575a4d49414f4d49414f2f646565702d6c6561726e696e672d666f722d696d6167652d70726f63657373696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WZMIAOMIAO/deep-learning-for-image-processing?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : deep learning for image processing including classification and object-detection etc.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hoya012/deep_learning_object_detection\"\u003ehoya012/deep_learning_object_detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9349f1faf0da185bc9b83f62e68ffabde3a4a0aab0d6b49829882e2dab44e742/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686f79613031322f646565705f6c6561726e696e675f6f626a6563745f646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9349f1faf0da185bc9b83f62e68ffabde3a4a0aab0d6b49829882e2dab44e742/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686f79613031322f646565705f6c6561726e696e675f6f626a6563745f646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hoya012/deep_learning_object_detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A paper list of object detection using deep learning.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/amusi/awesome-object-detection\"\u003eamusi/awesome-object-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6e9636458085dc930d3d5a5140c699078bd6b7a65b54ccdc4814b63e3d3c13a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616d7573692f617765736f6d652d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6e9636458085dc930d3d5a5140c699078bd6b7a65b54ccdc4814b63e3d3c13a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616d7573692f617765736f6d652d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/amusi/awesome-object-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Awesome Object Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wenhwu/awesome-remote-sensing-change-detection\"\u003ewenhwu/awesome-remote-sensing-change-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/eed43edb355781cc4ca200cac9a1a20ecb2083dd4f0ef636a90d7db00832b941/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77656e6877752f617765736f6d652d72656d6f74652d73656e73696e672d6368616e67652d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/eed43edb355781cc4ca200cac9a1a20ecb2083dd4f0ef636a90d7db00832b941/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77656e6877752f617765736f6d652d72656d6f74652d73656e73696e672d6368616e67652d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wenhwu/awesome-remote-sensing-change-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : List of datasets, codes, and contests related to remote sensing change detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZHOUYI1023/awesome-radar-perception\"\u003eZHOUYI1023/awesome-radar-perception\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/88bc43d1844827affdbec130d7bb7be5e8fabc9127e798769ce6e241bbe1c7eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a484f555949313032332f617765736f6d652d72616461722d70657263657074696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/88bc43d1844827affdbec130d7bb7be5e8fabc9127e798769ce6e241bbe1c7eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a484f555949313032332f617765736f6d652d72616461722d70657263657074696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZHOUYI1023/awesome-radar-perception?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A curated list of radar datasets, detection, tracking and fusion.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lartpang/awesome-segmentation-saliency-dataset\"\u003elartpang/awesome-segmentation-saliency-dataset\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c035757b237ca395e7dac9783bee601ac2ca4a5eed89bee8fea8cf4566ba1ef6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c61727470616e672f617765736f6d652d7365676d656e746174696f6e2d73616c69656e63792d646174617365743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c035757b237ca395e7dac9783bee601ac2ca4a5eed89bee8fea8cf4566ba1ef6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c61727470616e672f617765736f6d652d7365676d656e746174696f6e2d73616c69656e63792d646174617365743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lartpang/awesome-segmentation-saliency-dataset?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A collection of some datasets for segmentation / saliency detection. Welcome to PR...ðŸ˜„\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TianhaoFu/Awesome-3D-Object-Detection\"\u003eTianhaoFu/Awesome-3D-Object-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7dc16b6262845f3865de1ef9718e8d3cd1c0414904b5e2cada41b244e5cd8ba1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5469616e68616f46752f417765736f6d652d33442d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7dc16b6262845f3865de1ef9718e8d3cd1c0414904b5e2cada41b244e5cd8ba1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5469616e68616f46752f417765736f6d652d33442d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TianhaoFu/Awesome-3D-Object-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Papers, code and datasets about deep learning for 3D Object Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xahidbuffon/Awesome_Underwater_Datasets\"\u003exahidbuffon/Awesome_Underwater_Datasets\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4591d28cdd67c513aea7f3158368e5fa74e870b7f3cb3a87b097ef33b9da6cad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7861686964627566666f6e2f417765736f6d655f556e64657277617465725f44617461736574733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4591d28cdd67c513aea7f3158368e5fa74e870b7f3cb3a87b097ef33b9da6cad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7861686964627566666f6e2f417765736f6d655f556e64657277617465725f44617461736574733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xahidbuffon/Awesome_Underwater_Datasets?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Pointers to large-scale underwater datasets and relevant resources.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/M-3LAB/awesome-industrial-anomaly-detection\"\u003eM-3LAB/awesome-industrial-anomaly-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4372d545ef3fc9c34e94cfa7c61d0f73bf9d4d46315d0058e52472723cb63944/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d2d334c41422f617765736f6d652d696e647573747269616c2d616e6f6d616c792d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4372d545ef3fc9c34e94cfa7c61d0f73bf9d4d46315d0058e52472723cb63944/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d2d334c41422f617765736f6d652d696e647573747269616c2d616e6f6d616c792d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/M-3LAB/awesome-industrial-anomaly-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Paper list and datasets for industrial image anomaly detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZhangXiwuu/Awesome_visual_place_recognition_datasets\"\u003eZhangXiwuu/Awesome_visual_place_recognition_datasets\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/16016d9428686e8f3df06a31308424acc381bce75c81719748c7c18c4dbb2f94/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68616e6758697775752f417765736f6d655f76697375616c5f706c6163655f7265636f676e6974696f6e5f64617461736574733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/16016d9428686e8f3df06a31308424acc381bce75c81719748c7c18c4dbb2f94/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68616e6758697775752f417765736f6d655f76697375616c5f706c6163655f7265636f676e6974696f6e5f64617461736574733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZhangXiwuu/Awesome_visual_place_recognition_datasets?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A curated list of Visual Place Recognition (VPR)/ loop closure detection (LCD) datasets.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ari-dasci/OD-WeaponDetection\"\u003eari-dasci/OD-WeaponDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/29705b459f69572b02f1764d521d865d3a666dd10b16fd9994e5c8e9ca6f2a5d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6172692d64617363692f4f442d576561706f6e446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/29705b459f69572b02f1764d521d865d3a666dd10b16fd9994e5c8e9ca6f2a5d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6172692d64617363692f4f442d576561706f6e446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ari-dasci/OD-WeaponDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Datasets for weapon detection based on image classification and object detection tasks.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DLLXW/objectDetectionDatasets\"\u003eDLLXW/objectDetectionDatasets\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4b4df4c1c3971195413d2bbac64bafd9b627c3473eb640463d4a7996b722cfc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f444c4c58572f6f626a656374446574656374696f6e44617461736574733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4b4df4c1c3971195413d2bbac64bafd9b627c3473eb640463d4a7996b722cfc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f444c4c58572f6f626a656374446574656374696f6e44617461736574733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DLLXW/objectDetectionDatasets?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ç›®æ ‡æ£€æµ‹æ•°æ®é›†åˆ¶ä½œ:VOC,COCO,YOLOç­‰å¸¸ç”¨æ•°æ®é›†æ ¼å¼çš„åˆ¶ä½œå’Œäº’ç›¸è½¬æ¢è„šæœ¬ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kuanhungchen/awesome-tiny-object-detection\"\u003ekuanhungchen/awesome-tiny-object-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5fd97e6d91205d05f25576b2ba586ced359183f03d8cea339ce1caaa844ffa7e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b75616e68756e676368656e2f617765736f6d652d74696e792d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5fd97e6d91205d05f25576b2ba586ced359183f03d8cea339ce1caaa844ffa7e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b75616e68756e676368656e2f617765736f6d652d74696e792d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kuanhungchen/awesome-tiny-object-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ•¶ A curated list of Tiny Object Detection papers and related resources.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003ePaper and Code Overview\u003c/h3\u003e\u003ca id=\"user-content-paper-and-code-overview\" class=\"anchor\" aria-label=\"Permalink: Paper and Code Overview\" href=\"#paper-and-code-overview\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003ePaper Review\u003c/h4\u003e\u003ca id=\"user-content-paper-review\" class=\"anchor\" aria-label=\"Permalink: Paper Review\" href=\"#paper-review\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/52CV/CV-Surveys\"\u003e52CV/CV-Surveys\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/eb09ce4cf38b11697a8137ec0baef98404acce18f4a18555747281f7a114ee19/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f353243562f43562d537572766579733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/eb09ce4cf38b11697a8137ec0baef98404acce18f4a18555747281f7a114ee19/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f353243562f43562d537572766579733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/52CV/CV-Surveys?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è®¡ç®—æœºè§†è§‰ç›¸å…³ç»¼è¿°ã€‚åŒ…æ‹¬ç›®æ ‡æ£€æµ‹ã€è·Ÿè¸ª........\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/GreenTeaHua/YOLO-Review\"\u003eGreenTeaHua/YOLO-Review\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b59ae77c526e1e56a8890a0e797315e305d2604982440d24d22aa8e420a9b5ee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f477265656e5465614875612f594f4c4f2d5265766965773f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b59ae77c526e1e56a8890a0e797315e305d2604982440d24d22aa8e420a9b5ee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f477265656e5465614875612f594f4c4f2d5265766965773f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/GreenTeaHua/YOLO-Review?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"A Review of YOLO Object Detection Based on Deep Learning\". \"åŸºäºŽæ·±åº¦å­¦ä¹ çš„YOLOç›®æ ‡æ£€æµ‹ç»¼è¿°\". (\u003cstrong\u003e\u003ca href=\"https://jeit.ac.cn/cn/article/doi/10.11999/JEIT210790\" rel=\"nofollow\"\u003eJournal of Electronics \u0026amp; Information Technology 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Review of Yolo Algorithm Developments\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/pii/S1877050922001363\" rel=\"nofollow\"\u003eProcedia Computer Science 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCode Review\u003c/h4\u003e\u003ca id=\"user-content-code-review\" class=\"anchor\" aria-label=\"Permalink: Code Review\" href=\"#code-review\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/iscyy/ultralyticsPro\"\u003eiscyy/ultralyticsPro\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6d01496969abb44c68a3238a64e904327ef4ec2629829088a7ddbea2f21c4e55/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736379792f756c7472616c797469637350726f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6d01496969abb44c68a3238a64e904327ef4ec2629829088a7ddbea2f21c4e55/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736379792f756c7472616c797469637350726f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/iscyy/ultralyticsPro?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ”¥ðŸ”¥ðŸ”¥ ä¸“æ³¨äºŽYOLO11ï¼ŒYOLOv8ã€YOLOv10ã€RT-DETRã€YOLOv7ã€YOLOv5æ”¹è¿›æ¨¡åž‹ï¼ŒSupport to improve backbone, neck, head, loss, IoU, NMS and other modulesðŸš€\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/open-mmlab/mmdetection\"\u003eMMDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/68b0f0a824d1ce240275fa6f85668a366029403a575fc71d41dfdccc91ae97e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d6d6d6c61622f6d6d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/68b0f0a824d1ce240275fa6f85668a366029403a575fc71d41dfdccc91ae97e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d6d6d6c61622f6d6d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/open-mmlab/mmdetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : OpenMMLab Detection Toolbox and Benchmark. \u003ca href=\"https://mmdetection.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003emmdetection.readthedocs.io\u003c/a\u003e. (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1906.07155\" rel=\"nofollow\"\u003earXiv 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/open-mmlab/mmyolo\"\u003eMMYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/34ba85ba06312ee3826006deb4ada6bbd8581b3110b169040a42119ae1ec6ff8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d6d6d6c61622f6d6d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/34ba85ba06312ee3826006deb4ada6bbd8581b3110b169040a42119ae1ec6ff8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d6d6d6c61622f6d6d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/open-mmlab/mmyolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : OpenMMLab YOLO series toolbox and benchmark. Implemented RTMDet, RTMDet-Rotated,YOLOv5, YOLOv6, YOLOv7, YOLOv8, YOLOX, PPYOLOE, etc. \u003ca href=\"https://mmyolo.readthedocs.io/zh_CN/dev/\" rel=\"nofollow\"\u003emmyolo.readthedocs.io/zh_CN/dev/\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/iscyy/yoloair\"\u003eiscyy/yoloair\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/adc54b3a08544f8ec2661f6cd4aad8c8272ebf67a92d46ba7a7b8d32f53ec32c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736379792f796f6c6f6169723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/adc54b3a08544f8ec2661f6cd4aad8c8272ebf67a92d46ba7a7b8d32f53ec32c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736379792f796f6c6f6169723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/iscyy/yoloair?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e :  ðŸ”¥ðŸ”¥ðŸ”¥ ä¸“æ³¨äºŽYOLOæ”¹è¿›æ¨¡åž‹ï¼ŒSupport to improve backbone, neck, head, loss, IoU, NMS and other modulesðŸš€.  YOLOAiræ˜¯ä¸€ä¸ªåŸºäºŽPyTorchçš„YOLOç®—æ³•åº“ã€‚ç»Ÿä¸€æ¨¡åž‹ä»£ç æ¡†æž¶ã€ç»Ÿä¸€åº”ç”¨ã€ç»Ÿä¸€æ”¹è¿›ã€æ˜“äºŽæ¨¡å—ç»„åˆã€æž„å»ºæ›´å¼ºå¤§çš„ç½‘ç»œæ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/iscyy/yoloair2\"\u003eiscyy/yoloair2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4e4c4e9554309946c83078ee2fa6da80171eb7c286d65f25bdad06aeec4c0a1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736379792f796f6c6f616972323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4e4c4e9554309946c83078ee2fa6da80171eb7c286d65f25bdad06aeec4c0a1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736379792f796f6c6f616972323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/iscyy/yoloair2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : â˜ï¸ðŸ’¡ðŸŽˆä¸“æ³¨äºŽæ”¹è¿›YOLOv7ï¼ŒSupport to improve Backbone, Neck, Head, Loss, IoU, NMS and other modules.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jizhishutong/YOLOU\"\u003ejizhishutong/YOLOU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/059c9754a72d6a1247c0e4b9c325c7285f47a7691f971348a3761ad717dfdea4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a697a6869736875746f6e672f594f4c4f553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/059c9754a72d6a1247c0e4b9c325c7285f47a7691f971348a3761ad717dfdea4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a697a6869736875746f6e672f594f4c4f553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jizhishutong/YOLOU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOUï¼šUnited, Study and easier to Deploy. â€‹ The purpose of our creation of YOLOU is to better learn the algorithms of the YOLO series and pay tribute to our predecessors. YOLOv3ã€YOLOv4ã€YOLOv5ã€YOLOv5-Liteã€YOLOv6-v1ã€YOLOv6-v2ã€YOLOv7ã€YOLOXã€YOLOX-Liteã€PP-YOLOEã€PP-PicoDet-Plusã€YOLO-Fastest v2ã€FastestDetã€YOLOv5-SPDã€TensorRTã€NCNNã€Tengineã€OpenVINO. \"å¾®ä¿¡å…¬ä¼—å·ã€Œé›†æ™ºä¹¦ç«¥ã€ã€Š\u003ca href=\"https://mp.weixin.qq.com/s/clupheQ8iHnhR4FJcTtB8A\" rel=\"nofollow\"\u003eYOLOUå¼€æº | æ±‡é›†YOLOç³»åˆ—æ‰€æœ‰ç®—æ³•ï¼Œé›†ç®—æ³•å­¦ä¹ ã€ç§‘ç ”æ”¹è¿›ã€è½åœ°äºŽä¸€èº«ï¼\u003c/a\u003eã€‹\"\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WangQvQ/Yolov5_Magic\"\u003eWangQvQ/Yolov5_Magic\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6a53bdbd6908292149e6bc0486cc3316c7f96751285a06da4c7c35c59b905614/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57616e675176512f596f6c6f76355f4d616769633f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6a53bdbd6908292149e6bc0486cc3316c7f96751285a06da4c7c35c59b905614/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57616e675176512f596f6c6f76355f4d616769633f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WangQvQ/Yolov5_Magic?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO MagicðŸª„ is an extension based on Ultralytics' YOLOv5, designed to provide more powerful functionality and simpler operations for visual tasks.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/positive666/yolo_research\"\u003epositive666/yolo_research\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/622bcf1d418489bfeff1f8aebacaa24c2407b169dd2cf1d1f86332ad846d8eef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706f7369746976653636362f796f6c6f5f72657365617263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/622bcf1d418489bfeff1f8aebacaa24c2407b169dd2cf1d1f86332ad846d8eef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706f7369746976653636362f796f6c6f5f72657365617263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/positive666/yolo_research?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸš€ yolo_reserach PLUS High-level. based on yolo-high-level project (detect\\pose\\classify\\segment):include yolov5\\yolov7\\yolov8\\ core ,improvement research ,SwintransformV2 and Attention Series. training skills, business customization, engineering deployment.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/augmentedstartups/AS-One\"\u003eaugmentedstartups/AS-One\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6c30868bf4a2fceebc83e072fe0a1933d2c90c5258215015151aaa44208e40b9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6175676d656e74656473746172747570732f41532d4f6e653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6c30868bf4a2fceebc83e072fe0a1933d2c90c5258215015151aaa44208e40b9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6175676d656e74656473746172747570732f41532d4f6e653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/augmentedstartups/AS-One?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Easy \u0026amp; Modular Computer Vision Detectors and Trackers - Run YOLO-NAS,v8,v7,v6,v5,R,X in under 20 lines of code. \u003ca href=\"https://www.augmentedstartups.com/\" rel=\"nofollow\"\u003ewww.augmentedstartups.com\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Oneflow-Inc/one-yolov5\"\u003eOneflow-Inc/one-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fa7664fba082b62f6752d4cb5761754274b55f55050dfbf7434ae8c4da05917b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f6e65666c6f772d496e632f6f6e652d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fa7664fba082b62f6752d4cb5761754274b55f55050dfbf7434ae8c4da05917b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f6e65666c6f772d496e632f6f6e652d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Oneflow-Inc/one-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A more efficient yolov5 with oneflow backend ðŸŽ‰ðŸŽ‰ðŸŽ‰. \"å¾®ä¿¡å…¬ä¼—å·ã€ŒGiantPandaCVã€ã€Š\u003ca href=\"https://mp.weixin.qq.com/s/tZ7swUd0biz7G3CiRkHHfw\" rel=\"nofollow\"\u003eOne-YOLOv5 å‘å¸ƒï¼Œä¸€ä¸ªè®­å¾—æ›´å¿«çš„YOLOv5\u003c/a\u003eã€‹\"\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PaddlePaddle/PaddleYOLO\"\u003ePaddlePaddle/PaddleYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7490811b89217d604dd745686ec5add19fd81867c35e39759c4ab3fed6f4af51/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506164646c65506164646c652f506164646c65594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7490811b89217d604dd745686ec5add19fd81867c35e39759c4ab3fed6f4af51/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506164646c65506164646c652f506164646c65594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PaddlePaddle/PaddleYOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e :  ðŸš€ðŸš€ðŸš€ YOLO series of PaddlePaddle implementation, PP-YOLOE+, YOLOv5, YOLOv6, YOLOv7, YOLOv8, YOLOX, YOLOv5u, YOLOv7u, RTMDet and so on. ðŸš€ðŸš€ðŸš€\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WangRongsheng/BestYOLO\"\u003eWangRongsheng/BestYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/00820d416a522d8a518f3ddb65865b908ee5cff45e0d0cf6a7980f1fe41d61e7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57616e67526f6e677368656e672f42657374594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/00820d416a522d8a518f3ddb65865b908ee5cff45e0d0cf6a7980f1fe41d61e7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57616e67526f6e677368656e672f42657374594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WangRongsheng/BestYOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸŒŸChange the world, it will become a better place. | ä»¥ç§‘ç ”å’Œç«žèµ›ä¸ºå¯¼å‘çš„æœ€å¥½çš„YOLOå®žè·µæ¡†æž¶!\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/KangChou/Cver4s\"\u003eKangChou/Cver4s\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/891996f8706a2763832f55c1f346db73104125f379f7dc661cf32b60028cc60a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b616e6743686f752f4376657234733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/891996f8706a2763832f55c1f346db73104125f379f7dc661cf32b60028cc60a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b616e6743686f752f4376657234733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/KangChou/Cver4s?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Cver4sï¼šComputer vision algorithm code base.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/chaizwj/yolov8-tricks\"\u003echaizwj/yolov8-tricks\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/57a68f7c830ecae585ef2ce17ac89a66a117da5b84a34d74cee6dcd16e5d9462/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636861697a776a2f796f6c6f76382d747269636b733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/57a68f7c830ecae585ef2ce17ac89a66a117da5b84a34d74cee6dcd16e5d9462/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636861697a776a2f796f6c6f76382d747269636b733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/chaizwj/yolov8-tricks?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ç›®æ ‡æ£€æµ‹ï¼Œé‡‡ç”¨yolov8ä½œä¸ºåŸºå‡†æ¨¡åž‹ï¼Œæ•°æ®é›†é‡‡ç”¨VisDrone2019ï¼Œå¸¦æœ‰è‡ªå·±çš„æ”¹è¿›ç­–ç•¥ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eLearning Resources\u003c/h3\u003e\u003ca id=\"user-content-learning-resources\" class=\"anchor\" aria-label=\"Permalink: Learning Resources\" href=\"#learning-resources\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zjhellofss/KuiperLLama\"\u003ezjhellofss/KuiperLLama\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5212ed716985c6e41ef7d711ed09c3e6855b657e005ea3df8cd3ea4890eda4f9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6a68656c6c6f6673732f4b75697065724c4c616d613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5212ed716985c6e41ef7d711ed09c3e6855b657e005ea3df8cd3ea4890eda4f9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6a68656c6c6f6673732f4b75697065724c4c616d613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zjhellofss/KuiperLLama?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ã€ŠåŠ¨æ‰‹è‡ªåˆ¶å¤§æ¨¡åž‹æŽ¨ç†æ¡†æž¶ã€‹ã€‚KuiperLLama åŠ¨æ‰‹è‡ªåˆ¶å¤§æ¨¡åž‹æŽ¨ç†æ¡†æž¶ï¼Œæ”¯æŒLLama2/3å’ŒQwen2.5ã€‚æ ¡æ‹›ã€ç§‹æ‹›ã€æ˜¥æ‹›ã€å®žä¹ å¥½é¡¹ç›®ï¼Œå¸¦ä½ ä»Žé›¶åŠ¨æ‰‹å®žçŽ°æ”¯æŒLLama2/3å’ŒQwen2.5çš„å¤§æ¨¡åž‹æŽ¨ç†æ¡†æž¶ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zjhellofss/KuiperInfer\"\u003ezjhellofss/KuiperInfer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e9cd23e1eff9e7eead1a60c5c66096068e0f160ec20ed0c00193632818dc2015/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6a68656c6c6f6673732f4b7569706572496e6665723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e9cd23e1eff9e7eead1a60c5c66096068e0f160ec20ed0c00193632818dc2015/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6a68656c6c6f6673732f4b7569706572496e6665723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zjhellofss/KuiperInfer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e :  æ ¡æ‹›ã€ç§‹æ‹›ã€æ˜¥æ‹›ã€å®žä¹ å¥½é¡¹ç›®ï¼å¸¦ä½ ä»Žé›¶å®žçŽ°ä¸€ä¸ªé«˜æ€§èƒ½çš„æ·±åº¦å­¦ä¹ æŽ¨ç†åº“ï¼Œæ”¯æŒå¤§æ¨¡åž‹ llama2 ã€Unetã€Yolov5ã€Resnetç­‰æ¨¡åž‹çš„æŽ¨ç†ã€‚Implement a high-performance deep learning inference library step by stepã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zjhellofss/kuiperdatawhale\"\u003ezjhellofss/kuiperdatawhale\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7341ac9e9134db02f63d20da1182e309b62a51871d3a8c69980b2bc34991bea8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6a68656c6c6f6673732f6b7569706572646174617768616c653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7341ac9e9134db02f63d20da1182e309b62a51871d3a8c69980b2bc34991bea8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6a68656c6c6f6673732f6b7569706572646174617768616c653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zjhellofss/kuiperdatawhale?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e :  ä»Žé›¶è‡ªåˆ¶æ·±åº¦å­¦ä¹ æŽ¨ç†æ¡†æž¶ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/roboflow/notebooks\"\u003eroboflow/notebooks\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cb8994cf72ba32b952ddded301356528f716f6dba2ce810c773f2e3bc533859e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626f666c6f772f6e6f7465626f6f6b733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cb8994cf72ba32b952ddded301356528f716f6dba2ce810c773f2e3bc533859e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626f666c6f772f6e6f7465626f6f6b733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/roboflow/notebooks?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Examples and tutorials on using SOTA computer vision models and techniques. Learn everything from old-school ResNet, through YOLO and object-detection transformers like DETR, to the latest models like Grounding DINO and SAM. \u003ca href=\"https://roboflow.com/models\" rel=\"nofollow\"\u003eroboflow.com/models\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yjh0410/PyTorch_YOLO_Tutorial\"\u003eyjh0410/PyTorch_YOLO_Tutorial\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/39ad804ea20036f1b93159bc1f54e8793a6d4abfb5aafb74d9977f11ba4824a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796a68303431302f5079546f7263685f594f4c4f5f5475746f7269616c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/39ad804ea20036f1b93159bc1f54e8793a6d4abfb5aafb74d9977f11ba4824a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796a68303431302f5079546f7263685f594f4c4f5f5475746f7269616c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yjh0410/PyTorch_YOLO_Tutorial?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO Tutorial.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HuKai97/yolov5-5.x-annotations\"\u003eHuKai97/yolov5-5.x-annotations\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9dabbaa442203ffb7526d4105433f855239b300c904eb0b034a570b8ccd231f7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48754b616939372f796f6c6f76352d352e782d616e6e6f746174696f6e733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9dabbaa442203ffb7526d4105433f855239b300c904eb0b034a570b8ccd231f7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48754b616939372f796f6c6f76352d352e782d616e6e6f746174696f6e733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HuKai97/yolov5-5.x-annotations?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä¸€ä¸ªåŸºäºŽyolov5-5.0çš„ä¸­æ–‡æ³¨é‡Šç‰ˆæœ¬ï¼\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/crkk-feng/yolov5-annotations\"\u003ecrkk-feng/yolov5-annotations\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3fed56cd3b40eaaa25505f01ade279f8052657dba27feef4481c9bae2b57aaec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63726b6b2d66656e672f796f6c6f76352d616e6e6f746174696f6e733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3fed56cd3b40eaaa25505f01ade279f8052657dba27feef4481c9bae2b57aaec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63726b6b2d66656e672f796f6c6f76352d616e6e6f746174696f6e733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/crkk-feng/yolov5-annotations?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Chinese annotated version of yolov5-5.0.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/XiaoJiNu/yolov5-v6-chinese-comment\"\u003eXiaoJiNu/yolov5-v6-chinese-comment\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c19f4e5b4f5c55dab862a9ae4e58e358ba2ff4af130303190197d53d8aee131a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5869616f4a694e752f796f6c6f76352d76362d6368696e6573652d636f6d6d656e743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c19f4e5b4f5c55dab862a9ae4e58e358ba2ff4af130303190197d53d8aee131a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5869616f4a694e752f796f6c6f76352d76362d6368696e6573652d636f6d6d656e743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/XiaoJiNu/yolov5-v6-chinese-comment?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5-v6ç‰ˆæœ¬æ³¨é‡Šã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/1131624548/About-YOLOv5-7-0\"\u003e1131624548/About-YOLOv5-7-0\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c19f4e5b4f5c55dab862a9ae4e58e358ba2ff4af130303190197d53d8aee131a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5869616f4a694e752f796f6c6f76352d76362d6368696e6573652d636f6d6d656e743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c19f4e5b4f5c55dab862a9ae4e58e358ba2ff4af130303190197d53d8aee131a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5869616f4a694e752f796f6c6f76352d76362d6368696e6573652d636f6d6d656e743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/XiaoJiNu/yolov5-v6-chinese-comment?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5ä»£ç æ³¨é‡Šã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zyds/yolov5-code\"\u003ezyds/yolov5-code\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/361aa9c52b30699bb408461dcdef61f59bacdc38a087a45dbb091f4a0ab6f146/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a7964732f796f6c6f76352d636f64653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/361aa9c52b30699bb408461dcdef61f59bacdc38a087a45dbb091f4a0ab6f146/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a7964732f796f6c6f76352d636f64653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zyds/yolov5-code?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : æ‰‹æŠŠæ‰‹å¸¦ä½ å®žæˆ˜ YOLOv5ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOther Versions of YOLO\u003c/h2\u003e\u003ca id=\"user-content-other-versions-of-yolo\" class=\"anchor\" aria-label=\"Permalink: Other Versions of YOLO\" href=\"#other-versions-of-yolo\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003ePyTorch Implementation\u003c/h3\u003e\u003ca id=\"user-content-pytorch-implementation\" class=\"anchor\" aria-label=\"Permalink: PyTorch Implementation\" href=\"#pytorch-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ultralytics/yolov3\"\u003eultralytics/yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/44655dae6444f06099d49af479b703057e872b1788dbf203320973ccfc3bd8c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/44655dae6444f06099d49af479b703057e872b1788dbf203320973ccfc3bd8c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ultralytics/yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv3 in PyTorch \u0026gt; ONNX \u0026gt; CoreML \u0026gt; TFLite.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/eriklindernoren/PyTorch-YOLOv3\"\u003eeriklindernoren/PyTorch-YOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3f74a8c3afca8e564692352d407b24d68569d4474f1cbbc1d56272171b23b4bf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6572696b6c696e6465726e6f72656e2f5079546f7263682d594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3f74a8c3afca8e564692352d407b24d68569d4474f1cbbc1d56272171b23b4bf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6572696b6c696e6465726e6f72656e2f5079546f7263682d594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/eriklindernoren/PyTorch-YOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Minimal PyTorch implementation of YOLOv3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Tianxiaomo/pytorch-YOLOv4\"\u003eTianxiaomo/pytorch-YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f94e89a828ca1f02070ea64baac3d775db42b3e9c89950f0b9cbd7065b1d9756/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5469616e7869616f6d6f2f7079746f7263682d594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f94e89a828ca1f02070ea64baac3d775db42b3e9c89950f0b9cbd7065b1d9756/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5469616e7869616f6d6f2f7079746f7263682d594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Tianxiaomo/pytorch-YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PyTorch ,ONNX and TensorRT implementation of YOLOv4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ayooshkathuria/pytorch-yolo-v3\"\u003eayooshkathuria/pytorch-yolo-v3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/baa9aecc5f7ccd64dbc0bcc9f679d64cd358e350e389f7c77e0d37f7ece106d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61796f6f73686b617468757269612f7079746f7263682d796f6c6f2d76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/baa9aecc5f7ccd64dbc0bcc9f679d64cd358e350e389f7c77e0d37f7ece106d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61796f6f73686b617468757269612f7079746f7263682d796f6c6f2d76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ayooshkathuria/pytorch-yolo-v3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A PyTorch implementation of the YOLO v3 object detection algorithm.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WongKinYiu/PyTorch_YOLOv4\"\u003eWongKinYiu/PyTorch_YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8c83f25931194dc8d66ccd01a9be4dd983a79e78a479e4b1c0e24cf51f3a482f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f5079546f7263685f594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8c83f25931194dc8d66ccd01a9be4dd983a79e78a479e4b1c0e24cf51f3a482f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f5079546f7263685f594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WongKinYiu/PyTorch_YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PyTorch implementation of YOLOv4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/argusswift/YOLOv4-pytorch\"\u003eargusswift/YOLOv4-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4ce17ce776f831b8e765de204974d7ce80aee5689571a742721b15cfa8ecd96d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f617267757373776966742f594f4c4f76342d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4ce17ce776f831b8e765de204974d7ce80aee5689571a742721b15cfa8ecd96d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f617267757373776966742f594f4c4f76342d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/argusswift/YOLOv4-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a pytorch repository of YOLOv4, attentive YOLOv4 and mobilenet YOLOv4 with PASCAL VOC and COCO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/longcw/yolo2-pytorch\"\u003elongcw/yolo2-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5ec74205ee239587cb6fa9a827ab08816e5069a20d02fee3e555ccfa16ea93a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6f6e6763772f796f6c6f322d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5ec74205ee239587cb6fa9a827ab08816e5069a20d02fee3e555ccfa16ea93a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6f6e6763772f796f6c6f322d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/longcw/yolo2-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv2 in PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolov5-v6.1-pytorch\"\u003ebubbliiiing/yolov5-v6.1-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/68541ded34bcce0941bc17e8f791365f238e29c7409eed9eb299d844874a0a51/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76352d76362e312d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/68541ded34bcce0941bc17e8f791365f238e29c7409eed9eb299d844874a0a51/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76352d76362e312d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolov5-v6.1-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¿™æ˜¯ä¸€ä¸ªyolov5-v6.1-pytorchçš„æºç ï¼Œå¯ä»¥ç”¨äºŽè®­ç»ƒè‡ªå·±çš„æ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolov5-pytorch\"\u003ebubbliiiing/yolov5-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3053e9842fce22410150493f549498b5de3fdfb3d0855408130b07d68d87a6ef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76352d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3053e9842fce22410150493f549498b5de3fdfb3d0855408130b07d68d87a6ef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76352d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolov5-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¿™æ˜¯ä¸€ä¸ªYoloV5-pytorchçš„æºç ï¼Œå¯ä»¥ç”¨äºŽè®­ç»ƒè‡ªå·±çš„æ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolov4-pytorch\"\u003ebubbliiiing/yolov4-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8b1c600e28be1130691c9f2288931e2bff61776360c49cd98ffc38fe2bccf754/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8b1c600e28be1130691c9f2288931e2bff61776360c49cd98ffc38fe2bccf754/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolov4-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¿™æ˜¯ä¸€ä¸ªYoloV4-pytorchçš„æºç ï¼Œå¯ä»¥ç”¨äºŽè®­ç»ƒè‡ªå·±çš„æ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolov4-tiny-pytorch\"\u003ebubbliiiing/yolov4-tiny-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/16431511267815a921e695e10edf354293821f5ca489f930f759dcd59059882f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d74696e792d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/16431511267815a921e695e10edf354293821f5ca489f930f759dcd59059882f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d74696e792d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolov4-tiny-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¿™æ˜¯ä¸€ä¸ªYoloV4-tiny-pytorchçš„æºç ï¼Œå¯ä»¥ç”¨äºŽè®­ç»ƒè‡ªå·±çš„æ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolo3-pytorch\"\u003ebubbliiiing/yolov3-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6aecda4076791858a1db686ce593409e1206bfb3be2d28850b6a1b62106641cc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f332d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6aecda4076791858a1db686ce593409e1206bfb3be2d28850b6a1b62106641cc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f332d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolo3-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¿™æ˜¯ä¸€ä¸ªyolo3-pytorchçš„æºç ï¼Œå¯ä»¥ç”¨äºŽè®­ç»ƒè‡ªå·±çš„æ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolox-pytorch\"\u003ebubbliiiing/yolox-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/45fdcbb6394df9bc3b0ba4b9bfa15e750a80b28a2ebf6df788455c7c3c12c0dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f782d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/45fdcbb6394df9bc3b0ba4b9bfa15e750a80b28a2ebf6df788455c7c3c12c0dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f782d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolox-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¿™æ˜¯ä¸€ä¸ªyolox-pytorchçš„æºç ï¼Œå¯ä»¥ç”¨äºŽè®­ç»ƒè‡ªå·±çš„æ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolov7-pytorch\"\u003ebubbliiiing/yolov7-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/31c2ce36ddd31aa1c2ef2858f0b74c15dadfef5f1b8aa6f85419ad4ba80ddaad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76372d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/31c2ce36ddd31aa1c2ef2858f0b74c15dadfef5f1b8aa6f85419ad4ba80ddaad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76372d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolov7-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¿™æ˜¯ä¸€ä¸ªyolov7çš„åº“ï¼Œå¯ä»¥ç”¨äºŽè®­ç»ƒè‡ªå·±çš„æ•°æ®é›†ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolov8-pytorch\"\u003ebubbliiiing/yolov8-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ff03fdb0b8ec2d15ad8780402bead449ba969b96de4035b2a64a26630fa560c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76382d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ff03fdb0b8ec2d15ad8780402bead449ba969b96de4035b2a64a26630fa560c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76382d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolov8-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¿™æ˜¯ä¸€ä¸ªyolov8-pytorchçš„ä»“åº“ï¼Œå¯ä»¥ç”¨äºŽè®­ç»ƒè‡ªå·±çš„æ•°æ®é›†ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BobLiu20/YOLOv3_PyTorch\"\u003eBobLiu20/YOLOv3_PyTorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a45978c36c92a780fa61815230f80c631d591952c4997c60043c16130a77d033/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f624c697532302f594f4c4f76335f5079546f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a45978c36c92a780fa61815230f80c631d591952c4997c60043c16130a77d033/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f624c697532302f594f4c4f76335f5079546f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BobLiu20/YOLOv3_PyTorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Full implementation of YOLOv3 in PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ruiminshen/yolo2-pytorch\"\u003eruiminshen/yolo2-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3a4a4d09616743257c41e4b726aba03d4c177414202ef102f17faf92386a18f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7275696d696e7368656e2f796f6c6f322d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3a4a4d09616743257c41e4b726aba03d4c177414202ef102f17faf92386a18f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7275696d696e7368656e2f796f6c6f322d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ruiminshen/yolo2-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PyTorch implementation of the YOLO (You Only Look Once) v2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DeNA/PyTorch_YOLOv3\"\u003eDeNA/PyTorch_YOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/dadcff9db8d2f628cafbe001d29be7b24b885d0f7c75c96d986cb1df4166b58f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44654e412f5079546f7263685f594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dadcff9db8d2f628cafbe001d29be7b24b885d0f7c75c96d986cb1df4166b58f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44654e412f5079546f7263685f594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DeNA/PyTorch_YOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Implementation of YOLOv3 in PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/abeardear/pytorch-YOLO-v1\"\u003eabeardear/pytorch-YOLO-v1\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/960b32d1196262580ea14d23b5f3eebbe8b595e279bd456a0befe041e79d3831/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6162656172646561722f7079746f7263682d594f4c4f2d76313f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/960b32d1196262580ea14d23b5f3eebbe8b595e279bd456a0befe041e79d3831/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6162656172646561722f7079746f7263682d594f4c4f2d76313f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/abeardear/pytorch-YOLO-v1?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : an experiment for yolo-v1, including training and testing.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wuzhihao7788/yolodet-pytorch\"\u003ewuzhihao7788/yolodet-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/255e3f7334505e87fe9e4ee2f37f477e3ec1a4ca2d57962a614f9f85318117fc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77757a686968616f373738382f796f6c6f6465742d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/255e3f7334505e87fe9e4ee2f37f477e3ec1a4ca2d57962a614f9f85318117fc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77757a686968616f373738382f796f6c6f6465742d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wuzhihao7788/yolodet-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : reproduce the YOLO series of papers in pytorch, including YOLOv4, PP-YOLO, YOLOv5ï¼ŒYOLOv3, etc.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/uvipen/Yolo-v2-pytorch\"\u003euvipen/Yolo-v2-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/37349629e0062d68977b612e3114bbd51950f68c15bb9294676fe0eff6a43b8e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f75766970656e2f596f6c6f2d76322d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/37349629e0062d68977b612e3114bbd51950f68c15bb9294676fe0eff6a43b8e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f75766970656e2f596f6c6f2d76322d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/uvipen/Yolo-v2-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO for object detection tasks.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Peterisfar/YOLOV3\"\u003ePeterisfar/YOLOV3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d9647b7f5895b458ebdecd49fc5aed6c241f8d77ff3ca7ec66ba0eca125b31ad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506574657269736661722f594f4c4f56333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d9647b7f5895b458ebdecd49fc5aed6c241f8d77ff3ca7ec66ba0eca125b31ad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506574657269736661722f594f4c4f56333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Peterisfar/YOLOV3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov3 by pytorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/misads/easy_detection\"\u003emisads/easy_detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7ab9507c18e3f420664084d3bf4829406e405ca627887a13269e28fd6e26d1bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69736164732f656173795f646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7ab9507c18e3f420664084d3bf4829406e405ca627887a13269e28fd6e26d1bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69736164732f656173795f646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/misads/easy_detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä¸€ä¸ªç®€å•æ–¹ä¾¿çš„ç›®æ ‡æ£€æµ‹æ¡†æž¶(PyTorchçŽ¯å¢ƒå¯ç›´æŽ¥è¿è¡Œï¼Œä¸éœ€è¦cudaç¼–è¯‘)ï¼Œæ”¯æŒFaster_RCNNã€Yoloç³»åˆ—(v2~v5)ã€EfficientDetã€RetinaNetã€Cascade-RCNNç­‰ç»å…¸ç½‘ç»œã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/miemie2013/miemiedetection\"\u003emiemiedetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7ff578725d5f02d1a2b3b410c50652e95ddc9e7e209a5f702d82a657d8562400/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69656d6965323031332f6d69656d6965646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7ff578725d5f02d1a2b3b410c50652e95ddc9e7e209a5f702d82a657d8562400/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69656d6965323031332f6d69656d6965646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/miemie2013/miemiedetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Pytorch and ncnn implementation of PPYOLOEã€YOLOXã€PPYOLOã€PPYOLOv2ã€SOLOv2 an so on.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pjh5672/YOLOv1\"\u003epjh5672/YOLOv1\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0693fee5a26ee5e2fe88eaa0681dba7f03a5b500aa7e5e5609ecc1fa1e6ace1e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a68353637322f594f4c4f76313f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0693fee5a26ee5e2fe88eaa0681dba7f03a5b500aa7e5e5609ecc1fa1e6ace1e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a68353637322f594f4c4f76313f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pjh5672/YOLOv1?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv1 implementation using PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pjh5672/YOLOv2\"\u003epjh5672/YOLOv2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/34e979c992fa3a44974a22bdaeed4ae05d6eef685b88f39d1b4102e33f58e6d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a68353637322f594f4c4f76323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/34e979c992fa3a44974a22bdaeed4ae05d6eef685b88f39d1b4102e33f58e6d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a68353637322f594f4c4f76323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pjh5672/YOLOv2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv2 implementation using PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pjh5672/YOLOv3\"\u003epjh5672/YOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b2ece60885e2598583e4b99e4d46f69d13928b3bde6b4cfc4a4b582a16ab246b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a68353637322f594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b2ece60885e2598583e4b99e4d46f69d13928b3bde6b4cfc4a4b582a16ab246b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a68353637322f594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pjh5672/YOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv3 implementation using PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Iywie/pl_YOLO\"\u003eIywie/pl_YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b542f0beb3de0f81554e175fd7313b8041fb0634d0ce7a42f7072c8b18c47ab7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f49797769652f706c5f594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b542f0beb3de0f81554e175fd7313b8041fb0634d0ce7a42f7072c8b18c47ab7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f49797769652f706c5f594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Iywie/pl_YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv7, YOLOX and YOLOv5 are working right now.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DavidLandup0/deepvision\"\u003eDavidLandup0/deepvision\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f607e2d8807aad4cca859284fc0ab28f2500539663be840da290059a579ac6d1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44617669644c616e647570302f64656570766973696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f607e2d8807aad4cca859284fc0ab28f2500539663be840da290059a579ac6d1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44617669644c616e647570302f64656570766973696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DavidLandup0/deepvision?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PyTorch and TensorFlow/Keras image models with automatic weight conversions and equal API/implementations - Vision Transformer (ViT), ResNetV2, EfficientNetV2, (planned...) DeepLabV3+, ConvNeXtV2, YOLO, NeRF, etc.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/theos-ai/easy-yolov7\"\u003etheos-ai/easy-yolov7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7bd601ba29a0df98823583062303d5032b65263c9c07784a63bd1969d07926d2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7468656f732d61692f656173792d796f6c6f76373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7bd601ba29a0df98823583062303d5032b65263c9c07784a63bd1969d07926d2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7468656f732d61692f656173792d796f6c6f76373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/theos-ai/easy-yolov7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This a clean and easy-to-use implementation of YOLOv7 in PyTorch, made with â¤ï¸ by Theos AI.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eC Implementation\u003c/h3\u003e\u003ca id=\"user-content-c-implementation\" class=\"anchor\" aria-label=\"Permalink: C Implementation\" href=\"#c-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ggerganov/ggml\"\u003eggml\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a2036c240e1e37b39dca30152fa9812f97e1402c6e05a46372006c7a3d3fae37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6767657267616e6f762f67676d6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a2036c240e1e37b39dca30152fa9812f97e1402c6e05a46372006c7a3d3fae37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6767657267616e6f762f67676d6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ggerganov/ggml?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tensor library for machine learning. Written in C.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/rockcarry/ffcnn\"\u003erockcarry/ffcnn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ac1e34df4315c599368222a15d599a1bb56a43e93fa7c3036112bcf9e09d0201/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f636b63617272792f6666636e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ac1e34df4315c599368222a15d599a1bb56a43e93fa7c3036112bcf9e09d0201/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f636b63617272792f6666636e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/rockcarry/ffcnn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ffcnn is a cnn neural network inference framework, written in 600 lines C language.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ar7775/Object-Detection-System-Yolo\"\u003ear7775/Object-Detection-System-Yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bccdcea8859e0be326897bc326f77a33831ffc647542bd8a1e3d90c141c60e40/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6172373737352f4f626a6563742d446574656374696f6e2d53797374656d2d596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bccdcea8859e0be326897bc326f77a33831ffc647542bd8a1e3d90c141c60e40/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6172373737352f4f626a6563742d446574656374696f6e2d53797374656d2d596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ar7775/Object-Detection-System-Yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object Detection System.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lstuma/YOLO_utils\"\u003elstuma/YOLO_utils\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/40a0ac6d1413338240be8553bdee59c043abe638f498ab2a2c53ba149ce8bed5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c7374756d612f594f4c4f5f7574696c733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/40a0ac6d1413338240be8553bdee59c043abe638f498ab2a2c53ba149ce8bed5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c7374756d612f594f4c4f5f7574696c733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lstuma/YOLO_utils?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A few utilities for the YOLO project implemented in C for extra speed.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RajneeshKumar12/yolo-detection-app\"\u003eRajneeshKumar12/yolo-detection-app\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/153a7f185ea336270371568f918e38817acb259f5de04f3b377f316df7d1ef8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52616a6e656573684b756d617231322f796f6c6f2d646574656374696f6e2d6170703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/153a7f185ea336270371568f918e38817acb259f5de04f3b377f316df7d1ef8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52616a6e656573684b756d617231322f796f6c6f2d646574656374696f6e2d6170703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RajneeshKumar12/yolo-detection-app?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo app for object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Deyht/CIANNA\"\u003eDeyht/CIANNA\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4fa2b914f1235bb61eb1cc8f3b208e4cb44817fa1891dee65094faa15e967aa8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44657968742f4349414e4e413f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4fa2b914f1235bb61eb1cc8f3b208e4cb44817fa1891dee65094faa15e967aa8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44657968742f4349414e4e413f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Deyht/CIANNA?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : CIANNA - Convolutional Interactive Artificial Neural Networks by/for Astrophysicists.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCPP Implementation\u003c/h3\u003e\u003ca id=\"user-content-cpp-implementation\" class=\"anchor\" aria-label=\"Permalink: CPP Implementation\" href=\"#cpp-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/walktree/libtorch-yolov3\"\u003ewalktree/libtorch-yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2896b9e6543dca19a5f010c6415a1ce31b8f882a9ba0e21c529f0999c1a7b717/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616c6b747265652f6c6962746f7263682d796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2896b9e6543dca19a5f010c6415a1ce31b8f882a9ba0e21c529f0999c1a7b717/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616c6b747265652f6c6962746f7263682d796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/walktree/libtorch-yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Libtorch implementation of the YOLO v3 object detection algorithm, written with pure C++.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yasenh/libtorch-yolov5\"\u003eyasenh/libtorch-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/561a6a1d97aa97273c363626fee78bce6a703ddc6b399b87b13e8cd75eb83579/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796173656e682f6c6962746f7263682d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/561a6a1d97aa97273c363626fee78bce6a703ddc6b399b87b13e8cd75eb83579/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796173656e682f6c6962746f7263682d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yasenh/libtorch-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A LibTorch inference implementation of the yolov5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Nebula4869/YOLOv5-LibTorch\"\u003eNebula4869/YOLOv5-LibTorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0069065a24bcbbe3423ab3c882c7698dd69c3046e30f6cf0d2c603a50b5f0ad5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e6562756c61343836392f594f4c4f76352d4c6962546f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0069065a24bcbbe3423ab3c882c7698dd69c3046e30f6cf0d2c603a50b5f0ad5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e6562756c61343836392f594f4c4f76352d4c6962546f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Nebula4869/YOLOv5-LibTorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real time object detection with deployment of YOLOv5 through LibTorch C++ API.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ncdhz/YoloV5-LibTorch\"\u003encdhz/YoloV5-LibTorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/deffd9d223d9157d2113d7a57fc949c46d4913b63f33d64d590d72293ea99af7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e6364687a2f596f6c6f56352d4c6962546f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/deffd9d223d9157d2113d7a57fc949c46d4913b63f33d64d590d72293ea99af7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e6364687a2f596f6c6f56352d4c6962546f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ncdhz/YoloV5-LibTorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä¸€ä¸ª C++ ç‰ˆæœ¬çš„ YoloV5 å°è£…åº“.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Rane2021/yolov5_train_cpp_inference\"\u003eRane2021/yolov5_train_cpp_inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/272c98663fd283afa1fcd4edea0b48a072ebb8cd109a4a8fa8c0bef5c4b5e05c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52616e65323032312f796f6c6f76355f747261696e5f6370705f696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/272c98663fd283afa1fcd4edea0b48a072ebb8cd109a4a8fa8c0bef5c4b5e05c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52616e65323032312f796f6c6f76355f747261696e5f6370705f696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Rane2021/yolov5_train_cpp_inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5è®­ç»ƒå’Œc++æŽ¨ç†ä»£ç ï¼Œæ•ˆæžœå‡ºè‰²ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/stephanecharette/DarkHelp\"\u003estephanecharette/DarkHelp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a91b674ef1d9314565263243c2e483c7691df3114e1ea423b6ea99e6ed0bb307/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374657068616e6563686172657474652f4461726b48656c703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a91b674ef1d9314565263243c2e483c7691df3114e1ea423b6ea99e6ed0bb307/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374657068616e6563686172657474652f4461726b48656c703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/stephanecharette/DarkHelp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The DarkHelp C++ API is a wrapper to make it easier to use the Darknet neural network framework within a C++ application.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/UNeedCryDear/yolov5-opencv-dnn-cpp\"\u003eUNeedCryDear/yolov5-opencv-dnn-cpp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7b5ab192d6624cc93699194e1a206734cce03fecac95288b0748495a9727d878/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f554e656564437279446561722f796f6c6f76352d6f70656e63762d646e6e2d6370703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7b5ab192d6624cc93699194e1a206734cce03fecac95288b0748495a9727d878/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f554e656564437279446561722f796f6c6f76352d6f70656e63762d646e6e2d6370703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/UNeedCryDear/yolov5-opencv-dnn-cpp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä½¿ç”¨opencvæ¨¡å—éƒ¨ç½²yolov5-6.0ç‰ˆæœ¬ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/UNeedCryDear/yolov5-seg-opencv-onnxruntime-cpp\"\u003eUNeedCryDear/yolov5-seg-opencv-onnxruntime-cpp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/25315f2d99a387c98b0df8815ba35756ad1ac3f84586361c2ce793f64593ab1f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f554e656564437279446561722f796f6c6f76352d7365672d6f70656e63762d6f6e6e7872756e74696d652d6370703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/25315f2d99a387c98b0df8815ba35756ad1ac3f84586361c2ce793f64593ab1f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f554e656564437279446561722f796f6c6f76352d7365672d6f70656e63762d6f6e6e7872756e74696d652d6370703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/UNeedCryDear/yolov5-seg-opencv-onnxruntime-cpp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5 segmentation with onnxruntime and opencv.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hpc203/yolov5-dnn-cpp-python\"\u003ehpc203/yolov5-dnn-cpp-python\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/31d1d903d62a7a0fa1a80296bba617ad258de500ac181b4b66d62a4c41733c0e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f796f6c6f76352d646e6e2d6370702d707974686f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/31d1d903d62a7a0fa1a80296bba617ad258de500ac181b4b66d62a4c41733c0e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f796f6c6f76352d646e6e2d6370702d707974686f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hpc203/yolov5-dnn-cpp-python?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ç”¨opencvçš„dnnæ¨¡å—åšyolov5ç›®æ ‡æ£€æµ‹ï¼ŒåŒ…å«C++å’ŒPythonä¸¤ä¸ªç‰ˆæœ¬çš„ç¨‹åºã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hpc203/yolox-opencv-dnn\"\u003ehpc203/yolox-opencv-dnn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ecf2c6e7b86be03e7a16f4da699ca469156fa6c400e4351da972ccb3b70bbf8b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f796f6c6f782d6f70656e63762d646e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ecf2c6e7b86be03e7a16f4da699ca469156fa6c400e4351da972ccb3b70bbf8b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f796f6c6f782d6f70656e63762d646e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hpc203/yolox-opencv-dnn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä½¿ç”¨OpenCVéƒ¨ç½²YOLOXï¼Œæ”¯æŒYOLOX-Sã€YOLOX-Mã€YOLOX-Lã€YOLOX-Xã€YOLOX-Darknet53äº”ç§ç»“æž„ï¼ŒåŒ…å«C++å’ŒPythonä¸¤ç§ç‰ˆæœ¬çš„ç¨‹åºã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hpc203/yolov7-opencv-onnxrun-cpp-py\"\u003ehpc203/yolov7-opencv-onnxrun-cpp-py\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5e264b42ef2ff864546ab92756a11fbd2065d1ad81e73e2a39f87d3237a75c10/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f796f6c6f76372d6f70656e63762d6f6e6e7872756e2d6370702d70793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5e264b42ef2ff864546ab92756a11fbd2065d1ad81e73e2a39f87d3237a75c10/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f796f6c6f76372d6f70656e63762d6f6e6e7872756e2d6370702d70793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hpc203/yolov7-opencv-onnxrun-cpp-py?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åˆ†åˆ«ä½¿ç”¨OpenCVã€ONNXRuntimeéƒ¨ç½²YOLOV7ç›®æ ‡æ£€æµ‹ï¼Œä¸€å…±åŒ…å«12ä¸ªonnxæ¨¡åž‹ï¼Œä¾ç„¶æ˜¯åŒ…å«C++å’ŒPythonä¸¤ä¸ªç‰ˆæœ¬çš„ç¨‹åºã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/doleron/yolov5-opencv-cpp-python\"\u003edoleron/yolov5-opencv-cpp-python\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7cd2d1ccee570c9963f7a7a958c68900a66f1798b035d64997f9cfacd8f939a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f6c65726f6e2f796f6c6f76352d6f70656e63762d6370702d707974686f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7cd2d1ccee570c9963f7a7a958c68900a66f1798b035d64997f9cfacd8f939a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f6c65726f6e2f796f6c6f76352d6f70656e63762d6370702d707974686f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/doleron/yolov5-opencv-cpp-python?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Example of using ultralytics YOLO V5 with OpenCV 4.5.4, C++ and Python.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/UNeedCryDear/yolov8-opencv-onnxruntime-cpp\"\u003eUNeedCryDear/yolov8-opencv-onnxruntime-cpp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8120f71fcb69687addd19c1cb4613a2078619c60479787a91612615077eaf99e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f554e656564437279446561722f796f6c6f76382d6f70656e63762d6f6e6e7872756e74696d652d6370703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8120f71fcb69687addd19c1cb4613a2078619c60479787a91612615077eaf99e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f554e656564437279446561722f796f6c6f76382d6f70656e63762d6f6e6e7872756e74696d652d6370703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/UNeedCryDear/yolov8-opencv-onnxruntime-cpp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : detection and instance segmentation of yolov8,use onnxruntime and opencv.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eROS Implementation\u003c/h3\u003e\u003ca id=\"user-content-ros-implementation\" class=\"anchor\" aria-label=\"Permalink: ROS Implementation\" href=\"#ros-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mgonzs13/yolov8_ros\"\u003emgonzs13/yolov8_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cc552bc31a9f418f376b0e5608572f164ec3e65e4a2521a17ea4e0bb077747ab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d676f6e7a7331332f796f6c6f76385f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cc552bc31a9f418f376b0e5608572f164ec3e65e4a2521a17ea4e0bb077747ab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d676f6e7a7331332f796f6c6f76385f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mgonzs13/yolov8_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Ultralytics YOLOv8, YOLOv9, YOLOv10, YOLOv11 for ROS 2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/leggedrobotics/darknet_ros\"\u003eleggedrobotics/darknet_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cfd81b1613c79ab28ce48949eca22d26a81dcd9dd9dce9816261c35030a0c218/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6567676564726f626f746963732f6461726b6e65745f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cfd81b1613c79ab28ce48949eca22d26a81dcd9dd9dce9816261c35030a0c218/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6567676564726f626f746963732f6461726b6e65745f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/leggedrobotics/darknet_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-Time Object Detection for ROS.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/engcang/ros-yolo-sort\"\u003eengcang/ros-yolo-sort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5a0ffdfcb6e3c0c6539070911a9478e23a8ae4dd92ad2fca6a953d6ca6d187dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656e6763616e672f726f732d796f6c6f2d736f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5a0ffdfcb6e3c0c6539070911a9478e23a8ae4dd92ad2fca6a953d6ca6d187dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656e6763616e672f726f732d796f6c6f2d736f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/engcang/ros-yolo-sort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO and SORT, and ROS versions of them.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/chrisgundling/YoloLight\"\u003echrisgundling/YoloLight\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d93a032c384df996ac1f300d5e23d408e38937c207d93dc927775fee5b4f37a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636872697367756e646c696e672f596f6c6f4c696768743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d93a032c384df996ac1f300d5e23d408e38937c207d93dc927775fee5b4f37a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636872697367756e646c696e672f596f6c6f4c696768743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/chrisgundling/YoloLight?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tiny-YOLO-v2 ROS Node for Traffic Light Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ar-Ray-code/YOLOX-ROS\"\u003eAr-Ray-code/YOLOX-ROS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2483d68d88d2e40c8376d7a155385a8be5deaa644291c6457b48f1a435c23199/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41722d5261792d636f64652f594f4c4f582d524f533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2483d68d88d2e40c8376d7a155385a8be5deaa644291c6457b48f1a435c23199/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41722d5261792d636f64652f594f4c4f582d524f533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ar-Ray-code/YOLOX-ROS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOX + ROS2 object detection package.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ar-Ray-code/YOLOv5-ROS\"\u003eAr-Ray-code/YOLOv5-ROS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/426daddc440e507129937ff139f2bf3fb7142a8b5f446d4d4eb6486dd3ddaf0f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41722d5261792d636f64652f594f4c4f76352d524f533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/426daddc440e507129937ff139f2bf3fb7142a8b5f446d4d4eb6486dd3ddaf0f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41722d5261792d636f64652f594f4c4f76352d524f533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ar-Ray-code/YOLOv5-ROS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 + ROS2 object detection package.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Tossy0423/yolov4-for-darknet_ros\"\u003eTossy0423/yolov4-for-darknet_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bd8239717ba8a5a7647502f9f4353063831b150e1fc7bd092fbbf5ee2767ac9f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f546f737379303432332f796f6c6f76342d666f722d6461726b6e65745f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bd8239717ba8a5a7647502f9f4353063831b150e1fc7bd092fbbf5ee2767ac9f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f546f737379303432332f796f6c6f76342d666f722d6461726b6e65745f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Tossy0423/yolov4-for-darknet_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is the environment in which YOLO V4 is ported to darknet_ros.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/qianmin/yolov5_ROS\"\u003eqianmin/yolov5_ROS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c30887fb2e8aa909cc0851b0323bd032634a446299985777fad1799c43e98628/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7169616e6d696e2f796f6c6f76355f524f533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c30887fb2e8aa909cc0851b0323bd032634a446299985777fad1799c43e98628/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7169616e6d696e2f796f6c6f76355f524f533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/qianmin/yolov5_ROS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : run YOLOv5 in ROSï¼ŒROSä½¿ç”¨YOLOv5ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ailllist/yolov5_ROS\"\u003eailllist/yolov5_ROS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/14b41e1eba932881c656bec8f8ffd598bc8c13152230087508960932e6618540/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61696c6c6c6973742f796f6c6f76355f524f533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/14b41e1eba932881c656bec8f8ffd598bc8c13152230087508960932e6618540/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61696c6c6c6973742f796f6c6f76355f524f533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ailllist/yolov5_ROS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5 for ros, not webcam.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Shua-Kang/ros_pytorch_yolov5\"\u003eShua-Kang/ros_pytorch_yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4b32d6e3b86a04a22b84a245374a25f0570837c42598dc1a29fc7f06a3adeb07/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536875612d4b616e672f726f735f7079746f7263685f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4b32d6e3b86a04a22b84a245374a25f0570837c42598dc1a29fc7f06a3adeb07/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536875612d4b616e672f726f735f7079746f7263685f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Shua-Kang/ros_pytorch_yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A ROS wrapper for yolov5. (master branch is v5.0 of yolov5; for v6.1, see branch v6.1).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ziyan0302/Yolov5_DeepSort_Pytorch_ros\"\u003eziyan0302/Yolov5_DeepSort_Pytorch_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9164d7b346dbceb0dd3c4272addd0e9d604738561eb4a4c4f92879ff1db52bec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6979616e303330322f596f6c6f76355f44656570536f72745f5079746f7263685f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9164d7b346dbceb0dd3c4272addd0e9d604738561eb4a4c4f92879ff1db52bec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6979616e303330322f596f6c6f76355f44656570536f72745f5079746f7263685f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ziyan0302/Yolov5_DeepSort_Pytorch_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Connect Yolov5 detection module and DeepSort tracking module via ROS.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/U07157135/ROS2-with-YOLOv5\"\u003eU07157135/ROS2-with-YOLOv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1560d3bb8de7b9b00dd233b932a342d6a7ee1955fd6f66a72ddafdb2a5ab2ca6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5530373135373133352f524f53322d776974682d594f4c4f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1560d3bb8de7b9b00dd233b932a342d6a7ee1955fd6f66a72ddafdb2a5ab2ca6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5530373135373133352f524f53322d776974682d594f4c4f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/U07157135/ROS2-with-YOLOv5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åœ¨ç„¡äººæ©Ÿä¸Šä»¥ROS2æŠ€è¡“å¯¦ç¾YOLOv5ç‰©ä»¶åµæ¸¬ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lukazso/yolov6-ros\"\u003elukazso/yolov6-ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7abd003e9a57ca44922cb29ad6a23314f2528a80ad399b01dc35e3fd839f4152/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c756b617a736f2f796f6c6f76362d726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7abd003e9a57ca44922cb29ad6a23314f2528a80ad399b01dc35e3fd839f4152/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c756b617a736f2f796f6c6f76362d726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lukazso/yolov6-ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ROS package for YOLOv6.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/qq44642754a/Yolov5_ros\"\u003eqq44642754a/Yolov5_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/96844cd733ebcc0775d6ab60a60412cf1f381486cf9695ab1dbc8c446c798b63/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f71713434363432373534612f596f6c6f76355f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/96844cd733ebcc0775d6ab60a60412cf1f381486cf9695ab1dbc8c446c798b63/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f71713434363432373534612f596f6c6f76355f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/qq44642754a/Yolov5_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time object detection with ROS, based on YOLOv5 and PyTorch (åŸºäºŽ YOLOv5çš„ROSå®žæ—¶å¯¹è±¡æ£€æµ‹).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lukazso/yolov7-ros\"\u003elukazso/yolov7-ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/19eaf8591de5df8352c108bc71e96bb140d62e71b9d10001457d1c982b0854b3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c756b617a736f2f796f6c6f76372d726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/19eaf8591de5df8352c108bc71e96bb140d62e71b9d10001457d1c982b0854b3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c756b617a736f2f796f6c6f76372d726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lukazso/yolov7-ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ROS package for official YOLOv7.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/phuoc101/yolov7_ros\"\u003ephuoc101/yolov7_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/235b05b3241424df39e747b50b4f6aca69994f7f86afbd10dfbf404bb91a3171/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7068756f633130312f796f6c6f76375f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/235b05b3241424df39e747b50b4f6aca69994f7f86afbd10dfbf404bb91a3171/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7068756f633130312f796f6c6f76375f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/phuoc101/yolov7_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ROS package for official YOLOv7.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ConfusionTechnologies/ros-yolov5-node\"\u003eConfusionTechnologies/ros-yolov5-node\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d59611cc9a1aa6faf1db208c1afb4ce5bf4d9fba558652a8dca221e04667e595/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436f6e667573696f6e546563686e6f6c6f676965732f726f732d796f6c6f76352d6e6f64653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d59611cc9a1aa6faf1db208c1afb4ce5bf4d9fba558652a8dca221e04667e595/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436f6e667573696f6e546563686e6f6c6f676965732f726f732d796f6c6f76352d6e6f64653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ConfusionTechnologies/ros-yolov5-node?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : For ROS2, uses ONNX GPU Runtime to inference YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ar-Ray-code/darknet_ros_fp16\"\u003eAr-Ray-code/darknet_ros_fp16\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a565de47dceb9eaa9f4c5862c284211b66cb5dd4acb1aa23de8723d11588fde1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41722d5261792d636f64652f6461726b6e65745f726f735f667031363f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a565de47dceb9eaa9f4c5862c284211b66cb5dd4acb1aa23de8723d11588fde1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41722d5261792d636f64652f6461726b6e65745f726f735f667031363f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ar-Ray-code/darknet_ros_fp16?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : darknet + ROS2 Humble + OpenCV4 + CUDA 11ï¼ˆcuDNN, Jetson Orinï¼‰.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wk123467/yolov5s_trt_ros\"\u003ewk123467/yolov5s_trt_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a0fd6d86d665a71b41ce3e2412b85fde9c17a9d75e336717ca6f4a85999707b0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776b3132333436372f796f6c6f7635735f7472745f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a0fd6d86d665a71b41ce3e2412b85fde9c17a9d75e336717ca6f4a85999707b0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776b3132333436372f796f6c6f7635735f7472745f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wk123467/yolov5s_trt_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åˆ©ç”¨TensorRTå¯¹yolov5sè¿›è¡ŒåŠ é€Ÿï¼Œå¹¶å°†å…¶åº”ç”¨äºŽROSï¼Œå®žçŽ°äº¤é€šæ ‡å¿—ã€çº¢ç»¿ç¯(ç›´æŽ¥è¾“å‡ºè·¯ç¯çŠ¶æ€)ã€è¡Œäººå’Œè½¦è¾†ç­‰äº¤é€šåœºæ™¯çš„æ£€æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PardisTaghavi/yolov7_strongsort_ros\"\u003ePardisTaghavi/yolov7_strongsort_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/67abe53c0d2f1f0f2dc2597fcc498e57f74968525df4f1bba4e15ba099709f22/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506172646973546167686176692f796f6c6f76375f7374726f6e67736f72745f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/67abe53c0d2f1f0f2dc2597fcc498e57f74968525df4f1bba4e15ba099709f22/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506172646973546167686176692f796f6c6f76375f7374726f6e67736f72745f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PardisTaghavi/yolov7_strongsort_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Integration of \"Yolov7 StrongSort\" with ROS for real time object tracking.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/af-doom/yolov8_ros_tensorrt-\"\u003eaf-doom/yolov8_ros_tensorrt-\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1317a0a91d6985a2b3cfbb00b4b8d2508ac99a7f36d8381634e4653fe6f9c8bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61662d646f6f6d2f796f6c6f76385f726f735f74656e736f7272742d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1317a0a91d6985a2b3cfbb00b4b8d2508ac99a7f36d8381634e4653fe6f9c8bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61662d646f6f6d2f796f6c6f76385f726f735f74656e736f7272742d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/af-doom/yolov8_ros_tensorrt-?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a YOLOv8 project based on ROS implementation, where YOLOv8 uses Tensorrt acceleration.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/KoKoMier/ros_darknet_yolov4\"\u003eKoKoMier/ros_darknet_yolov4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9c5161e9ede29964d5598823f9fa0a35e3770e9e62fbd9491b51a400c888e17d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6f4b6f4d6965722f726f735f6461726b6e65745f796f6c6f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9c5161e9ede29964d5598823f9fa0a35e3770e9e62fbd9491b51a400c888e17d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6f4b6f4d6965722f726f735f6461726b6e65745f796f6c6f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/KoKoMier/ros_darknet_yolov4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¿™æ˜¯æœºå™¨äººå°ç»„è§†è§‰ä¸Žé›·è¾¾çš„ç»“åˆç¨‹åºï¼Œé¦–å…ˆé€šè¿‡yoloç›®æ ‡æ£€æµ‹è¯†åˆ«åˆ°ç‰©ä½“ï¼Œç„¶åŽæŠŠè¯†åˆ«åˆ°çš„æ•°æ®å‘é€ç»™rosé‡Œé¢ç¨‹åºï¼Œç”¨äºŽé›·è¾¾æ•°æ®ç»“åˆã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/YellowAndGreen/Yolov5-OpenCV-Cpp-Python-ROS\"\u003eYellowAndGreen/Yolov5-OpenCV-Cpp-Python-ROS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9bfb2386ad14ad7cf2a4885739c36ab6e15746e5eca8df778928d6c0c3b9b6b4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59656c6c6f77416e64477265656e2f596f6c6f76352d4f70656e43562d4370702d507974686f6e2d524f533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9bfb2386ad14ad7cf2a4885739c36ab6e15746e5eca8df778928d6c0c3b9b6b4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59656c6c6f77416e64477265656e2f596f6c6f76352d4f70656e43562d4370702d507974686f6e2d524f533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/YellowAndGreen/Yolov5-OpenCV-Cpp-Python-ROS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Inference with YOLOv5, OpenCV 4.5.4 DNN, C++, ROS and Python.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mgonzs13/yolov8_ros\"\u003emgonzs13/yolov8_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cc552bc31a9f418f376b0e5608572f164ec3e65e4a2521a17ea4e0bb077747ab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d676f6e7a7331332f796f6c6f76385f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cc552bc31a9f418f376b0e5608572f164ec3e65e4a2521a17ea4e0bb077747ab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d676f6e7a7331332f796f6c6f76385f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mgonzs13/yolov8_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ROS 2 wrap for Ultralytics \u003ca href=\"https://github.com/ultralytics/ultralytics\"\u003eYOLOv8\u003c/a\u003e to perform object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fishros/yolov5_ros2\"\u003efishros/yolov5_ros2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/61ff7319e67d5e512e7bcd05d04e791a172fdb74a0f88634bfdd94905ca9db59/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66697368726f732f796f6c6f76355f726f73323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/61ff7319e67d5e512e7bcd05d04e791a172fdb74a0f88634bfdd94905ca9db59/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66697368726f732f796f6c6f76355f726f73323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/fishros/yolov5_ros2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽYoloV5çš„ROS2åŠŸèƒ½åŒ…ï¼Œå¯ä»¥å¿«é€Ÿå®Œæˆç‰©ä½“è¯†åˆ«ä¸Žä½å§¿å‘å¸ƒã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fateshelled/EdgeYOLO-ROS\"\u003efateshelled/EdgeYOLO-ROS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c7a3cf4654a0ac26b4f4584aadc7f740989e480b0302e7867751610a904669d0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666174657368656c6c65642f45646765594f4c4f2d524f533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c7a3cf4654a0ac26b4f4584aadc7f740989e480b0302e7867751610a904669d0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666174657368656c6c65642f45646765594f4c4f2d524f533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/fateshelled/EdgeYOLO-ROS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : EdgeYOLO + ROS2 object detection package.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/vivaldini/yolov6-uav\"\u003evivaldini/yolov6-uav\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7ed9636463dd97d8afb26dbd162a542fd3f03ee25ad39e1122f77f1f36e0fea8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f766976616c64696e692f796f6c6f76362d7561763f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7ed9636463dd97d8afb26dbd162a542fd3f03ee25ad39e1122f77f1f36e0fea8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f766976616c64696e692f796f6c6f76362d7561763f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/vivaldini/yolov6-uav?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository contains a ROS noetic package for YOLOv6 to recognize objects from UAV and provide their positions.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Alpaca-zip/ultralytics_ros\"\u003eAlpaca-zip/ultralytics_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/77f549b12d077dbcf651414b4a5cc09bd6a0e79961390b1c7e73e0577579b292/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c706163612d7a69702f756c7472616c79746963735f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/77f549b12d077dbcf651414b4a5cc09bd6a0e79961390b1c7e73e0577579b292/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c706163612d7a69702f756c7472616c79746963735f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Alpaca-zip/ultralytics_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ROS/ROS2 package for Ultralytics YOLOv8 real-time object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eMojo Implementation\u003c/h3\u003e\u003ca id=\"user-content-mojo-implementation\" class=\"anchor\" aria-label=\"Permalink: Mojo Implementation\" href=\"#mojo-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/taalhaataahir0102/Mojo-Yolo\"\u003etaalhaataahir0102/Mojo-Yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9c10face27f1e048bf683bd9b60302822751a6180dca0373f5fb591769bbd807/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7461616c686161746161686972303130322f4d6f6a6f2d596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9c10face27f1e048bf683bd9b60302822751a6180dca0373f5fb591769bbd807/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7461616c686161746161686972303130322f4d6f6a6f2d596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/taalhaataahir0102/Mojo-Yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Mojo-Yolo.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eRust Implementation\u003c/h3\u003e\u003ca id=\"user-content-rust-implementation\" class=\"anchor\" aria-label=\"Permalink: Rust Implementation\" href=\"#rust-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/huggingface/candle\"\u003eCandle\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/586e4cdae2010f8d60f1ee301e98154c870c483e2a1ecf48050f63e4587caad6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756767696e67666163652f63616e646c653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/586e4cdae2010f8d60f1ee301e98154c870c483e2a1ecf48050f63e4587caad6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756767696e67666163652f63616e646c653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/huggingface/candle?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Minimalist ML framework for Rust.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/huggingface/tokenizers\"\u003eTokenizers\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2aa91170d1b68534dff5f0b6c4a7366371773cf6f6467ec43b51e4304b4fab6a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756767696e67666163652f746f6b656e697a6572733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2aa91170d1b68534dff5f0b6c4a7366371773cf6f6467ec43b51e4304b4fab6a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756767696e67666163652f746f6b656e697a6572733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/huggingface/tokenizers?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ’¥ Fast State-of-the-Art Tokenizers optimized for Research and Production. \u003ca href=\"https://huggingface.co/docs/tokenizers/index\" rel=\"nofollow\"\u003ehuggingface.co/docs/tokenizers\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/huggingface/safetensors\"\u003eSafetensors\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e2d062826de5fa5d53219c83bd9f20f5f1d67c0ab775e1c90e636f3bb14fd10e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756767696e67666163652f7361666574656e736f72733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e2d062826de5fa5d53219c83bd9f20f5f1d67c0ab775e1c90e636f3bb14fd10e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756767696e67666163652f7361666574656e736f72733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/huggingface/safetensors?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Simple, safe way to store and distribute tensors. \u003ca href=\"https://huggingface.co/docs/safetensors/index\" rel=\"nofollow\"\u003ehuggingface.co/docs/safetensors\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/burn-rs/burn\"\u003eBurn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7b77aec3ab9378a213c5f73cbf6bc5ebb66b7a023641681394ef231af9703cd7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6275726e2d72732f6275726e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7b77aec3ab9378a213c5f73cbf6bc5ebb66b7a023641681394ef231af9703cd7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6275726e2d72732f6275726e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/burn-rs/burn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Burn - A Flexible and Comprehensive Deep Learning Framework in Rust. \u003ca href=\"https://burn-rs.github.io/\" rel=\"nofollow\"\u003eburn-rs.github.io/\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tensorflow/rust\"\u003eTensorFlow Rust\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/985bf6de8f06b05b56766ad7d2b700c1a7d8dc5f1780ac8debca98611f24115f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74656e736f72666c6f772f727573743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/985bf6de8f06b05b56766ad7d2b700c1a7d8dc5f1780ac8debca98611f24115f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74656e736f72666c6f772f727573743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tensorflow/rust?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Rust language bindings for TensorFlow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LaurentMazare/tch-rs\"\u003etch-rs\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8a072333378f114bff0a3fb74d5acab89b2c14f5d97029d16e93fc4b16cdbe40/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c617572656e744d617a6172652f7463682d72733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8a072333378f114bff0a3fb74d5acab89b2c14f5d97029d16e93fc4b16cdbe40/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c617572656e744d617a6172652f7463682d72733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LaurentMazare/tch-rs?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Rust bindings for the C++ api of PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/coreylowman/dfdx\"\u003edfdx\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b6d38dfe01c2a0de447731cc93ea27116a4fc78ca0fbef681dcb3a7c2a6379a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636f7265796c6f776d616e2f646664783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b6d38dfe01c2a0de447731cc93ea27116a4fc78ca0fbef681dcb3a7c2a6379a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636f7265796c6f776d616e2f646664783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/coreylowman/dfdx?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Deep learning in Rust, with shape checked tensors and neural networks.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sonos/tract\"\u003etract\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b529827f8fb7574e9d382e6d0c524f2f8ca19fd6e547387280d8a682c7ff6919/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736f6e6f732f74726163743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b529827f8fb7574e9d382e6d0c524f2f8ca19fd6e547387280d8a682c7ff6919/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736f6e6f732f74726163743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sonos/tract?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Sonos' Neural Network inference engine. Tiny, no-nonsense, self-contained, Tensorflow and ONNX inference\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pykeio/ort\"\u003eort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/45aa58d12c13b364706b818b5b1d2ea3e8dc88e081669aab1709ac161da8fc46/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70796b65696f2f6f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/45aa58d12c13b364706b818b5b1d2ea3e8dc88e081669aab1709ac161da8fc46/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70796b65696f2f6f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pykeio/ort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Rust wrapper for ONNX Runtime. \u003ca href=\"https://docs.rs/ort/latest/ort/\" rel=\"nofollow\"\u003edocs.rs/ort\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jamjamjon/usls\"\u003eusls\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8f253cf66976601163b49107a1ac27fa592cb74b0af20bfb552a586449fbb6c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a616d6a616d6a6f6e2f75736c733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8f253cf66976601163b49107a1ac27fa592cb74b0af20bfb552a586449fbb6c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a616d6a616d6a6f6e2f75736c733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jamjamjon/usls?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Rust library integrated with ONNXRuntime, providing a collection of Computer Vison and Vision-Language models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ptaxom/pnn\"\u003eptaxom/pnn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/07a28d05ce24384bbb8f7ca8a9d76e5d03d4ba6254c89bd55a9313e02f24769a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f707461786f6d2f706e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/07a28d05ce24384bbb8f7ca8a9d76e5d03d4ba6254c89bd55a9313e02f24769a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f707461786f6d2f706e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ptaxom/pnn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : pnn is \u003ca href=\"https://github.com/alexeyAB/darknet\"\u003eDarknet\u003c/a\u003e compatible neural nets inference engine implemented in Rust. By optimizing was achieved significant performance increment(especially in FP16 mode). pnn provide CUDNN-based and TensorRT-based inference engines.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bencevans/rust-opencv-yolov5\"\u003ebencevans/rust-opencv-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fe0cfb36050febd9fe2ab84e19627ef4926a8a7cee56a58024655d6ae409dea7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62656e636576616e732f727573742d6f70656e63762d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fe0cfb36050febd9fe2ab84e19627ef4926a8a7cee56a58024655d6ae409dea7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62656e636576616e732f727573742d6f70656e63762d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bencevans/rust-opencv-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 Inference with ONNX \u0026amp; OpenCV in Rust.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/masc-it/yolov5-api-rust\"\u003emasc-it/yolov5-api-rust\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d44191a707c1106a22064b2c677d18d451fbc38ab7d0c47ff0b942afd58deb89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6173632d69742f796f6c6f76352d6170692d727573743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d44191a707c1106a22064b2c677d18d451fbc38ab7d0c47ff0b942afd58deb89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6173632d69742f796f6c6f76352d6170692d727573743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/masc-it/yolov5-api-rust?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Rust API to run predictions with YoloV5 models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AndreyGermanov/yolov8_onnx_rust\"\u003eAndreyGermanov/yolov8_onnx_rust\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7aa8968fa8176dcf0be372926532a7848be8221538863cefb2820e583f6c0a2b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e647265794765726d616e6f762f796f6c6f76385f6f6e6e785f727573743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7aa8968fa8176dcf0be372926532a7848be8221538863cefb2820e583f6c0a2b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e647265794765726d616e6f762f796f6c6f76385f6f6e6e785f727573743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AndreyGermanov/yolov8_onnx_rust?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv8 inference using Rust.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/igor-yusupov/rusty-yolo\"\u003eigor-yusupov/rusty-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5a26edf23b4b96bdb350cc3ceb29339cf42580b18faaa19823f61b6a365a28e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69676f722d79757375706f762f72757374792d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5a26edf23b4b96bdb350cc3ceb29339cf42580b18faaa19823f61b6a365a28e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69676f722d79757375706f762f72757374792d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/igor-yusupov/rusty-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : rusty-yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/gsuyemoto/yolo-rust\"\u003egsuyemoto/yolo-rust\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e2267ffcfb501fcb7eecf9d2d2acc143ba455895211facbc34e4d98861f02c90/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67737579656d6f746f2f796f6c6f2d727573743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e2267ffcfb501fcb7eecf9d2d2acc143ba455895211facbc34e4d98861f02c90/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67737579656d6f746f2f796f6c6f2d727573743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/gsuyemoto/yolo-rust?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Run YOLO computer vision model using Rust and OpenCV and/or Torch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/alianse777/darknet-rust\"\u003ealianse777/darknet-rust\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9d023a70aaca47f6df9e449f30176222eec639375bc80157e3f1637446453435/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69616e73653737372f6461726b6e65742d727573743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9d023a70aaca47f6df9e449f30176222eec639375bc80157e3f1637446453435/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69616e73653737372f6461726b6e65742d727573743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/alianse777/darknet-rust?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Rust wrapper for Darknet, an open source neural network framework written in C and CUDA. \u003ca href=\"https://pjreddie.com/darknet/\" rel=\"nofollow\"\u003epjreddie.com/darknet/\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/12101111/yolo-rs\"\u003e12101111/yolo-rs\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/52356ad53a62c94879922bed103acaf8931acddf5ffb21f18e239b17f631ee4f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f31323130313131312f796f6c6f2d72733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/52356ad53a62c94879922bed103acaf8931acddf5ffb21f18e239b17f631ee4f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f31323130313131312f796f6c6f2d72733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/12101111/yolo-rs?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov3 \u0026amp; Yolov4 with TVM and rust.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TKGgunter/yolov4_tiny_rs\"\u003eTKGgunter/yolov4_tiny_rs\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e7df46344cfe2de11a9a3564a9fdefae4b73421ed30c2520567c3127b95e6911/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f544b4767756e7465722f796f6c6f76345f74696e795f72733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e7df46344cfe2de11a9a3564a9fdefae4b73421ed30c2520567c3127b95e6911/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f544b4767756e7465722f796f6c6f76345f74696e795f72733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TKGgunter/yolov4_tiny_rs?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A rust implementation of yolov4_tiny algorithm.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/flixstn/You-Only-Look-Once\"\u003eflixstn/You-Only-Look-Once\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6fb101ab3931ce05b25ab09a8b1521fcad33aa0150f0ad6ef60f43d380757ac5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666c697873746e2f596f752d4f6e6c792d4c6f6f6b2d4f6e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6fb101ab3931ce05b25ab09a8b1521fcad33aa0150f0ad6ef60f43d380757ac5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666c697873746e2f596f752d4f6e6c792d4c6f6f6b2d4f6e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/flixstn/You-Only-Look-Once?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Rust implementation of Yolo for object detection and tracking.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lenna-project/yolo-plugin\"\u003elenna-project/yolo-plugin\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d9a1a5b2b914fdebb591aca3629eba283242740b250188eed756fa9654e24231/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c656e6e612d70726f6a6563742f796f6c6f2d706c7567696e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d9a1a5b2b914fdebb591aca3629eba283242740b250188eed756fa9654e24231/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c656e6e612d70726f6a6563742f796f6c6f2d706c7567696e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lenna-project/yolo-plugin?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo Object Detection Plugin for Lenna.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/laclouis5/globox-rs\"\u003elaclouis5/globox-rs\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/81948ad3e5a1421633c030521e40b6a08c6834c978a23eb4bd7e548921ce8796/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c61636c6f756973352f676c6f626f782d72733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/81948ad3e5a1421633c030521e40b6a08c6834c978a23eb4bd7e548921ce8796/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c61636c6f756973352f676c6f626f782d72733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/laclouis5/globox-rs?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object detection toolbox for parsing, converting and evaluating bounding box annotations.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/metobom/tchrs-opencv-webcam-inference\"\u003emetobom/tchrs-opencv-webcam-inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0dcf4c07d2aba0561c19a40c482e38b71b691d485aba56a9ed48a1b8ee3fa205/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d65746f626f6d2f74636872732d6f70656e63762d77656263616d2d696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0dcf4c07d2aba0561c19a40c482e38b71b691d485aba56a9ed48a1b8ee3fa205/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d65746f626f6d2f74636872732d6f70656e63762d77656263616d2d696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/metobom/tchrs-opencv-webcam-inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This example shows steps for running a Python trained model on webcam feed with opencv and tch-rs. Model will run on GPU.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eGo Implementation\u003c/h3\u003e\u003ca id=\"user-content-go-implementation\" class=\"anchor\" aria-label=\"Permalink: Go Implementation\" href=\"#go-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LdDl/go-darknet\"\u003eLdDl/go-darknet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6cb814e79fdcebfb835ae8fe05a44e8652f3a41690bd693abb71a0c7f2a5d3f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c64446c2f676f2d6461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6cb814e79fdcebfb835ae8fe05a44e8652f3a41690bd693abb71a0c7f2a5d3f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c64446c2f676f2d6461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LdDl/go-darknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : go-darknet: Go bindings for Darknet (Yolo V4, Yolo V7-tiny, Yolo V3).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/adalkiran/distributed-inference\"\u003eadalkiran/distributed-inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5467b03f9b41915c1dd7a40f07a922abe7a9cfc0bb1ea22bd7148f3dace571fb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6164616c6b6972616e2f64697374726962757465642d696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5467b03f9b41915c1dd7a40f07a922abe7a9cfc0bb1ea22bd7148f3dace571fb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6164616c6b6972616e2f64697374726962757465642d696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/adalkiran/distributed-inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Cross-language and distributed deep learning inference pipeline for WebRTC video streams over Redis Streams. Currently supports YOLOX model, which can run well on CPU.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wimspaargaren/yolov3\"\u003ewimspaargaren/yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/78fce265afdf7e36a3ed79def3db3e49e88c00f3f8dcbd73fac1d1768eacefff/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77696d7370616172676172656e2f796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/78fce265afdf7e36a3ed79def3db3e49e88c00f3f8dcbd73fac1d1768eacefff/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77696d7370616172676172656e2f796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wimspaargaren/yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Go implementation of the yolo v3 object detection system.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wimspaargaren/yolov5\"\u003ewimspaargaren/yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8f1c2ee13be1075c2b76c9a5a1787f5d55878416bed260211a16df1441b97c55/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77696d7370616172676172656e2f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8f1c2ee13be1075c2b76c9a5a1787f5d55878416bed260211a16df1441b97c55/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77696d7370616172676172656e2f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wimspaargaren/yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Go implementation of the yolo v5 object detection system.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/genert/real_time_object_detection_go\"\u003egenert/real_time_object_detection_go\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/eef799a7d40318d9ac3f8e3b0df97bde9af30ef78233d7969d78ee5d0b1405f6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67656e6572742f7265616c5f74696d655f6f626a6563745f646574656374696f6e5f676f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/eef799a7d40318d9ac3f8e3b0df97bde9af30ef78233d7969d78ee5d0b1405f6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67656e6572742f7265616c5f74696d655f6f626a6563745f646574656374696f6e5f676f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/genert/real_time_object_detection_go?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real Time Object Detection with OpenCV, Go, and Yolo v4.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCSharp Implementation\u003c/h3\u003e\u003ca id=\"user-content-csharp-implementation\" class=\"anchor\" aria-label=\"Permalink: CSharp Implementation\" href=\"#csharp-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dotnet/machinelearning\"\u003eML.NET\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/13362bf4a6476fe326e915ad8068db923e34721581079c9473ed7f4029d0e7f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f746e65742f6d616368696e656c6561726e696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/13362bf4a6476fe326e915ad8068db923e34721581079c9473ed7f4029d0e7f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f746e65742f6d616368696e656c6561726e696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dotnet/machinelearning?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ML.NET is an open source and cross-platform machine learning framework for .NET.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dotnet/TorchSharp\"\u003eTorchSharp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/15eb7330c52dfe39425999ab85ebf8b51b691c873ea58d5d6fe24adb32f60251/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f746e65742f546f72636853686172703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/15eb7330c52dfe39425999ab85ebf8b51b691c873ea58d5d6fe24adb32f60251/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f746e65742f546f72636853686172703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dotnet/TorchSharp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A .NET library that provides access to the library that powers PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SciSharp/TensorFlow.NET\"\u003eTensorFlow.NET\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/09c133fa99e92c85bb13efbfceb28acb0eedcaf41769b84adc4350507a4709bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53636953686172702f54656e736f72466c6f772e4e45543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/09c133fa99e92c85bb13efbfceb28acb0eedcaf41769b84adc4350507a4709bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53636953686172702f54656e736f72466c6f772e4e45543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SciSharp/TensorFlow.NET?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : .NET Standard bindings for Google's TensorFlow for developing, training and deploying Machine Learning models in C# and F#.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/takuya-takeuchi/DlibDotNet\"\u003eDlibDotNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/aedac681ec9192b090982f570ae4a0eb1c2af6706096365a65638921fbe568e7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616b7579612d74616b65756368692f446c6962446f744e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/aedac681ec9192b090982f570ae4a0eb1c2af6706096365a65638921fbe568e7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616b7579612d74616b65756368692f446c6962446f744e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/takuya-takeuchi/DlibDotNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Dlib .NET wrapper written in C++ and C# for Windows, MacOS, Linux and iOS.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DiffSharp/DiffSharp\"\u003eDiffSharp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e61b7ef68addc492cfc582f0196a90e75e83f42eb7254291e33d6082d1ac390d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4469666653686172702f4469666653686172703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e61b7ef68addc492cfc582f0196a90e75e83f42eb7254291e33d6082d1ac390d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4469666653686172702f4469666653686172703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DiffSharp/DiffSharp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : DiffSharp: Differentiable Functional Programming.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dme-compunet/YOLOv8\"\u003edme-compunet/YOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/55d79485e7c1ae2fbfc92d6ab01dc585fb5ba584daa7d55f5cae4b903007f329/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646d652d636f6d70756e65742f594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/55d79485e7c1ae2fbfc92d6ab01dc585fb5ba584daa7d55f5cae4b903007f329/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646d652d636f6d70756e65742f594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dme-compunet/YOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Use YOLOv8 in real-time, for object detection, instance segmentation, pose estimation and image classification, via ONNX Runtime. \u003ca href=\"https://www.nuget.org/packages/YoloV8\" rel=\"nofollow\"\u003ewww.nuget.org/packages/YoloV8\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/techwingslab/yolov5-net\"\u003etechwingslab/yolov5-net\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/81058e3e417155701560d28eb5d51c270c1f819cd10cd3d47a7eaf079adad9ce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7465636877696e67736c61622f796f6c6f76352d6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/81058e3e417155701560d28eb5d51c270c1f819cd10cd3d47a7eaf079adad9ce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7465636877696e67736c61622f796f6c6f76352d6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/techwingslab/yolov5-net?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 object detection with C#, ML.NET, ONNX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sstainba/Yolov8.Net\"\u003esstainba/Yolov8.Net\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ea6139b829d2d8635c7d8693d6b0c922e9605df5cd3e0e6e4a034776ef5acdb2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73737461696e62612f596f6c6f76382e4e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ea6139b829d2d8635c7d8693d6b0c922e9605df5cd3e0e6e4a034776ef5acdb2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73737461696e62612f596f6c6f76382e4e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sstainba/Yolov8.Net?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A .net 6 implementation to use Yolov5 and Yolov8 models via the ONNX Runtime.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlturosDestinations/Alturos.Yolo\"\u003eAlturos.Yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a98ad31c4e663f788dca3204fc4cb511be742d3d4f3d8375e61be0a80604a82f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c7475726f7344657374696e6174696f6e732f416c7475726f732e596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a98ad31c4e663f788dca3204fc4cb511be742d3d4f3d8375e61be0a80604a82f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c7475726f7344657374696e6174696f6e732f416c7475726f732e596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlturosDestinations/Alturos.Yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : C# Yolo Darknet Wrapper (real-time object detection).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ivilson/Yolov7net\"\u003eivilson/Yolov7net\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/51beda14843c740a220050a84cd7d4215d723720e2017e1625536a3dadbb777d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6976696c736f6e2f596f6c6f76376e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/51beda14843c740a220050a84cd7d4215d723720e2017e1625536a3dadbb777d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6976696c736f6e2f596f6c6f76376e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ivilson/Yolov7net?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov7 Detector for .Net 6.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sangyuxiaowu/ml_yolov7\"\u003esangyuxiaowu/ml_yolov7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/40edbeba4bac1dedf31ebba1f5d53c86e079905ff9f404f019585d509b8cba88/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73616e6779757869616f77752f6d6c5f796f6c6f76373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/40edbeba4bac1dedf31ebba1f5d53c86e079905ff9f404f019585d509b8cba88/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73616e6779757869616f77752f6d6c5f796f6c6f76373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sangyuxiaowu/ml_yolov7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ML.NET Yolov7. \"å¾®ä¿¡å…¬ä¼—å·ã€Œæ¡‘æ¦†è‚–ç‰©ã€ã€Š\u003ca href=\"https://mp.weixin.qq.com/s/vXz6gavYJR2mh5KuJO_slA\" rel=\"nofollow\"\u003eYOLOv7 åœ¨ ML.NET ä¸­ä½¿ç”¨ ONNX æ£€æµ‹å¯¹è±¡\u003c/a\u003eã€‹\"\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/keijiro/TinyYOLOv2Barracuda\"\u003ekeijiro/TinyYOLOv2Barracuda\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a6429c69f71ca287223aba1d570f497ee573d558bdcdae5e06d92cc9ef818a96/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b65696a69726f2f54696e79594f4c4f76324261727261637564613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a6429c69f71ca287223aba1d570f497ee573d558bdcdae5e06d92cc9ef818a96/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b65696a69726f2f54696e79594f4c4f76324261727261637564613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/keijiro/TinyYOLOv2Barracuda?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tiny YOLOv2 on Unity Barracuda.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/derenlei/Unity_Detection2AR\"\u003ederenlei/Unity_Detection2AR\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3e7506c516faf056a532a168194b3710f07fddd4eceb80d291a28fc677e91d65/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646572656e6c65692f556e6974795f446574656374696f6e3241523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3e7506c516faf056a532a168194b3710f07fddd4eceb80d291a28fc677e91d65/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646572656e6c65692f556e6974795f446574656374696f6e3241523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/derenlei/Unity_Detection2AR?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Localize 2D image object detection in 3D Scene with Yolo in Unity Barracuda and ARFoundation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/died/YOLO3-With-OpenCvSharp4\"\u003edied/YOLO3-With-OpenCvSharp4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f18a9c87479a9a7eaf5526a9119c5280ca52b5236254406d7f91fa42a4ce5556/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646965642f594f4c4f332d576974682d4f70656e43765368617270343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f18a9c87479a9a7eaf5526a9119c5280ca52b5236254406d7f91fa42a4ce5556/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646965642f594f4c4f332d576974682d4f70656e43765368617270343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/died/YOLO3-With-OpenCvSharp4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Demo of implement YOLO v3 with OpenCvSharp v4 on C#.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mbaske/yolo-unity\"\u003embaske/yolo-unity\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/72a0cca9725264f5ac86ecedb548bba4e5431024b9f1b0d7b95d971a1f1a94f4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6261736b652f796f6c6f2d756e6974793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/72a0cca9725264f5ac86ecedb548bba4e5431024b9f1b0d7b95d971a1f1a94f4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6261736b652f796f6c6f2d756e6974793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mbaske/yolo-unity?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO In-Game Object Detection for Unity (Windows).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BobLd/YOLOv4MLNet\"\u003eBobLd/YOLOv4MLNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1dc3926c6590340b4eb3ca9ff90354080a5d2d434976e7bd4b07ed71eff75e85/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f624c642f594f4c4f76344d4c4e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1dc3926c6590340b4eb3ca9ff90354080a5d2d434976e7bd4b07ed71eff75e85/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f624c642f594f4c4f76344d4c4e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BobLd/YOLOv4MLNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Use the YOLO v4 and v5 (ONNX) models for object detection in C# using ML.Net.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/keijiro/YoloV4TinyBarracuda\"\u003ekeijiro/YoloV4TinyBarracuda\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3f75f0b55e58353fa70f3746a06f1bf76b89362d4a7be4d521d17750f245efff/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b65696a69726f2f596f6c6f563454696e794261727261637564613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3f75f0b55e58353fa70f3746a06f1bf76b89362d4a7be4d521d17750f245efff/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b65696a69726f2f596f6c6f563454696e794261727261637564613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/keijiro/YoloV4TinyBarracuda?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV4TinyBarracuda is an implementation of the YOLOv4-tiny object detection model on the Unity Barracuda neural network inference library.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zhang8043/YoloWrapper\"\u003ezhang8043/YoloWrapper\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/dc6167a62fb96d212045e5783098cf92041d918e3ac7a5391b12c114b2ff2b3d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68616e67383034332f596f6c6f577261707065723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dc6167a62fb96d212045e5783098cf92041d918e3ac7a5391b12c114b2ff2b3d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68616e67383034332f596f6c6f577261707065723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zhang8043/YoloWrapper?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : C#å°è£…YOLOv4ç®—æ³•è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/maalik0786/FastYolo\"\u003emaalik0786/FastYolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8b62ff6cd826f9eb97b7a5e0383ebba9eaf0ddc29e8ea4f59b2978fecd4aae68/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61616c696b303738362f46617374596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8b62ff6cd826f9eb97b7a5e0383ebba9eaf0ddc29e8ea4f59b2978fecd4aae68/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61616c696b303738362f46617374596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/maalik0786/FastYolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Fast Yolo for fast initializing, object detection and tracking.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Uehwan/CSharp-Yolo-Video\"\u003eUehwan/CSharp-Yolo-Video\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8b3433716d176021ffd1047b9351e3cf62a92ecd005178cefbfb08ad9b3f60a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f55656877616e2f4353686172702d596f6c6f2d566964656f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8b3433716d176021ffd1047b9351e3cf62a92ecd005178cefbfb08ad9b3f60a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f55656877616e2f4353686172702d596f6c6f2d566964656f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Uehwan/CSharp-Yolo-Video?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : C# Yolo for Video.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/https://github.com/HTTP123-A/HumanDetection_Yolov5NET\"\u003eHTTP123-A/HumanDetection_Yolov5NET\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/658512dbbf601e442b347bb2cf4f5cc7f3fbc67f199a8e938aabf06d5b024aa7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f485454503132332d412f48756d616e446574656374696f6e5f596f6c6f76354e45543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/658512dbbf601e442b347bb2cf4f5cc7f3fbc67f199a8e938aabf06d5b024aa7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f485454503132332d412f48756d616e446574656374696f6e5f596f6c6f76354e45543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HTTP123-A/HumanDetection_Yolov5NET?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 object detection with ML.NET, ONNX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Celine-Hsieh/Hand_Gesture_Training--yolov4\"\u003eCeline-Hsieh/Hand_Gesture_Training--yolov4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3c95aefa9f8c75a7a8ec40585bb3a95d8bf3d03aab81cc2c9fd506fb9935285f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43656c696e652d48736965682f48616e645f476573747572655f547261696e696e672d2d796f6c6f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3c95aefa9f8c75a7a8ec40585bb3a95d8bf3d03aab81cc2c9fd506fb9935285f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43656c696e652d48736965682f48616e645f476573747572655f547261696e696e672d2d796f6c6f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Celine-Hsieh/Hand_Gesture_Training--yolov4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Recognize the gestures' features using the YOLOv4 algorithm.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lin-tea/YOLOv5DetectionWithCSharp\"\u003elin-tea/YOLOv5DetectionWithCSharp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6de1e4170db4cdaadd9422ddef5a635feb3b60936d66b6a2fdfd421b4a3f6cbe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c696e2d7465612f594f4c4f7635446574656374696f6e576974684353686172703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6de1e4170db4cdaadd9422ddef5a635feb3b60936d66b6a2fdfd421b4a3f6cbe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c696e2d7465612f594f4c4f7635446574656374696f6e576974684353686172703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lin-tea/YOLOv5DetectionWithCSharp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5s inference In C# and Training In Python.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MirCore/Unity-Object-Detection-and-Localization-with-VR\"\u003eMirCore/Unity-Object-Detection-and-Localization-with-VR\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/972f654dfbb6dbc4d6579f9cdbf503577179014e620ae6231333f37d6757c542/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6972436f72652f556e6974792d4f626a6563742d446574656374696f6e2d616e642d4c6f63616c697a6174696f6e2d776974682d56523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/972f654dfbb6dbc4d6579f9cdbf503577179014e620ae6231333f37d6757c542/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6972436f72652f556e6974792d4f626a6563742d446574656374696f6e2d616e642d4c6f63616c697a6174696f6e2d776974682d56523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MirCore/Unity-Object-Detection-and-Localization-with-VR?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detect and localize objects from the front-facing camera image of a VR Headset in a 3D Scene in Unity using Yolo and Barracuda.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CarlAreDHopen-eaton/YoloObjectDetection\"\u003eCarlAreDHopen-eaton/YoloObjectDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a98a50e0b3fd8acd824ea348e42c65f75c266e24113ff95047b6228682f76189/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4361726c41726544486f70656e2d6561746f6e2f596f6c6f4f626a656374446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a98a50e0b3fd8acd824ea348e42c65f75c266e24113ff95047b6228682f76189/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4361726c41726544486f70656e2d6561746f6e2f596f6c6f4f626a656374446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CarlAreDHopen-eaton/YoloObjectDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo Object Detection Application for RTSP streams.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TimothyMeadows/Yolo6.NetCore\"\u003eTimothyMeadows/Yolo6.NetCore\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2454528d18834f68b0c5d221a6005f923084a2013e7a975fd32cab7316fa0bef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54696d6f7468794d6561646f77732f596f6c6f362e4e6574436f72653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2454528d18834f68b0c5d221a6005f923084a2013e7a975fd32cab7316fa0bef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54696d6f7468794d6561646f77732f596f6c6f362e4e6574436f72653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TimothyMeadows/Yolo6.NetCore?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : You Only Look Once (v6) for .NET Core LTS.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mwetzko/EasyYoloDarknet\"\u003emwetzko/EasyYoloDarknet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b5ed78c48f03abf2119c907312b16287aa3afd996c70a66a5b6b0147c8f84c7b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d7765747a6b6f2f45617379596f6c6f4461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b5ed78c48f03abf2119c907312b16287aa3afd996c70a66a5b6b0147c8f84c7b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d7765747a6b6f2f45617379596f6c6f4461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mwetzko/EasyYoloDarknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : EasyYoloDarknet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mwetzko/EasyYoloDarknet\"\u003emwetzko/EasyYoloDarknet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b5ed78c48f03abf2119c907312b16287aa3afd996c70a66a5b6b0147c8f84c7b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d7765747a6b6f2f45617379596f6c6f4461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b5ed78c48f03abf2119c907312b16287aa3afd996c70a66a5b6b0147c8f84c7b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d7765747a6b6f2f45617379596f6c6f4461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mwetzko/EasyYoloDarknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Windows optimized Yolo / Darknet Compile, Train and Detect.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cj-mills/Unity-OpenVINO-YOLOX\"\u003ecj-mills/Unity-OpenVINO-YOLOX\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/66f1f530f699e905c9f30325c095131af3813f139a36d8d42e8d22f8d7436131/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636a2d6d696c6c732f556e6974792d4f70656e56494e4f2d594f4c4f583f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/66f1f530f699e905c9f30325c095131af3813f139a36d8d42e8d22f8d7436131/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636a2d6d696c6c732f556e6974792d4f70656e56494e4f2d594f4c4f583f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cj-mills/Unity-OpenVINO-YOLOX?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This tutorial series covers how to perform object detection in the Unity game engine with the OpenVINOâ„¢ Toolkit.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/natml-hub/YOLOX\"\u003enatml-hub/YOLOX\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7720ebc131f5517d75ee77b1d3b30de724ddc4f8361be59f920725de4f138b64/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e61746d6c2d6875622f594f4c4f583f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7720ebc131f5517d75ee77b1d3b30de724ddc4f8361be59f920725de4f138b64/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e61746d6c2d6875622f594f4c4f583f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/natml-hub/YOLOX?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : High performance object detector based on YOLO series.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/thisistherealdiana/YOLO_project\"\u003ethisistherealdiana/YOLO_project\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e75214098978493e91d0bbb4264cd78b0c8a93a2dd13db854c300c86ed76b843/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7468697369737468657265616c6469616e612f594f4c4f5f70726f6a6563743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e75214098978493e91d0bbb4264cd78b0c8a93a2dd13db854c300c86ed76b843/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7468697369737468657265616c6469616e612f594f4c4f5f70726f6a6563743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/thisistherealdiana/YOLO_project?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO project made by Diana Kereselidze.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/oujunke/Yolo5Net\"\u003eoujunke/Yolo5Net\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c7e0d6731c6c8a65923c1f804a854fc8ca857bd1fa0ad191c325a08d18a35331/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f756a756e6b652f596f6c6f354e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c7e0d6731c6c8a65923c1f804a854fc8ca857bd1fa0ad191c325a08d18a35331/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f756a756e6b652f596f6c6f354e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/oujunke/Yolo5Net?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo5å®žçŽ°äºŽTensorFlow.Net.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wojciechp6/YOLO-UnityBarracuda\"\u003ewojciechp6/YOLO-UnityBarracuda\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fe1b5f7774c15e65a062b07dc2f63436530114667982b3b3818e79915d7f34df/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776f6a636965636870362f594f4c4f2d556e6974794261727261637564613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fe1b5f7774c15e65a062b07dc2f63436530114667982b3b3818e79915d7f34df/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776f6a636965636870362f594f4c4f2d556e6974794261727261637564613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wojciechp6/YOLO-UnityBarracuda?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object detection app build on Unity Barracuda and YOLOv2 Tiny.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RaminAbbaszadi/YoloWrapper-WPF\"\u003eRaminAbbaszadi/YoloWrapper-WPF\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1b7a4febd22d9ec6a93c1ca2b0916ccb48f69752d337891ae8877eb775d2c901/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52616d696e41626261737a6164692f596f6c6f577261707065722d5750463f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1b7a4febd22d9ec6a93c1ca2b0916ccb48f69752d337891ae8877eb775d2c901/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52616d696e41626261737a6164692f596f6c6f577261707065722d5750463f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RaminAbbaszadi/YoloWrapper-WPF?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : WPF (C#) Yolo Darknet Wrapper.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fengyhack/YoloWpf\"\u003efengyhack/YoloWpf\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ea856b34343d7b932471ecefd1425e23f171579e553d887a77139da5829997f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66656e67796861636b2f596f6c6f5770663f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ea856b34343d7b932471ecefd1425e23f171579e553d887a77139da5829997f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66656e67796861636b2f596f6c6f5770663f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/fengyhack/YoloWpf?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : GUI demo for Object Detection with YOLO and OpenCVSharp.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hanzhuang111/Yolov5Wpf\"\u003ehanzhuang111/Yolov5Wpf\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/41143381f260201a1280875cdf12ec967b3e49d6da462e96d493de7e470631f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68616e7a6875616e673131312f596f6c6f76355770663f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/41143381f260201a1280875cdf12ec967b3e49d6da462e96d493de7e470631f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68616e7a6875616e673131312f596f6c6f76355770663f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hanzhuang111/Yolov5Wpf?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä½¿ç”¨ML.NETéƒ¨ç½²YOLOV5 çš„ONNXæ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MaikoKingma/yolo-winforms-test\"\u003eMaikoKingma/yolo-winforms-test\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8de825f9e028deaccadad6a54af57b171085578433f9d41e9da933ae3c6d0772/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d61696b6f4b696e676d612f796f6c6f2d77696e666f726d732d746573743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8de825f9e028deaccadad6a54af57b171085578433f9d41e9da933ae3c6d0772/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d61696b6f4b696e676d612f796f6c6f2d77696e666f726d732d746573743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MaikoKingma/yolo-winforms-test?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Windows forms application that can execute pre-trained object detection models via ML.NET. In this instance the You Only Look Once version 4 (yolov4) is used.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SeanAnd/WebcamObjectDetection\"\u003eSeanAnd/WebcamObjectDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fbb2a879ddc3ce707a25eb6421414cd480f990a3424846d608310cd46880f655/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5365616e416e642f57656263616d4f626a656374446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fbb2a879ddc3ce707a25eb6421414cd480f990a3424846d608310cd46880f655/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5365616e416e642f57656263616d4f626a656374446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SeanAnd/WebcamObjectDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO object detection using webcam in winforms.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Devmawi/BlazorObjectDetection-Sample\"\u003eDevmawi/BlazorObjectDetection-Sample\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0a7a3aaeb487c934dad1fb44b7dc62bc26c0fbec3f566acc9eee3e21f4681ac4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465766d6177692f426c617a6f724f626a656374446574656374696f6e2d53616d706c653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0a7a3aaeb487c934dad1fb44b7dc62bc26c0fbec3f566acc9eee3e21f4681ac4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465766d6177692f426c617a6f724f626a656374446574656374696f6e2d53616d706c653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Devmawi/BlazorObjectDetection-Sample?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Simple project for demonstrating how to embed a continuously object detection with Yolo on a video in a hybrid Blazor app (WebView2).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Soju06/yolov5-annotation-viewer\"\u003eSoju06/yolov5-annotation-viewer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/af8a420482f287cbe6fbcd1b6953f5496aaee1094d3534746aaa2c5af6acad5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536f6a7530362f796f6c6f76352d616e6e6f746174696f6e2d7669657765723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/af8a420482f287cbe6fbcd1b6953f5496aaee1094d3534746aaa2c5af6acad5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536f6a7530362f796f6c6f76352d616e6e6f746174696f6e2d7669657765723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Soju06/yolov5-annotation-viewer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5 annotation viewer.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/developer-ken/YoloPredictorMLDotNet\"\u003edeveloper-ken/YoloPredictorMLDotNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8efb62ed3016a27f9182b14ec8b07146c2990d04818208ae6219de381f6802e5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646576656c6f7065722d6b656e2f596f6c6f507265646963746f724d4c446f744e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8efb62ed3016a27f9182b14ec8b07146c2990d04818208ae6219de381f6802e5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646576656c6f7065722d6b656e2f596f6c6f507265646963746f724d4c446f744e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/developer-ken/YoloPredictorMLDotNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloPredictorMLDotNet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LionelC-Kyo/CSharp_YoloV5_Torch\"\u003eLionelC-Kyo/CSharp_YoloV5_Torch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/74c95823b32eb626e61ce25fa67b4770b93ec65d72b3987355e3f95250bee81d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696f6e656c432d4b796f2f4353686172705f596f6c6f56355f546f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/74c95823b32eb626e61ce25fa67b4770b93ec65d72b3987355e3f95250bee81d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696f6e656c432d4b796f2f4353686172705f596f6c6f56355f546f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LionelC-Kyo/CSharp_YoloV5_Torch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Run Yolo V5 in C# By Torch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wanglvhang/OnnxYoloDemo\"\u003ewanglvhang/OnnxYoloDemo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e4a38e0671b113c40c05be738c7f678032c718bc959c195149a08dd345eb0d14/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e676c7668616e672f4f6e6e78596f6c6f44656d6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e4a38e0671b113c40c05be738c7f678032c718bc959c195149a08dd345eb0d14/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e676c7668616e672f4f6e6e78596f6c6f44656d6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wanglvhang/OnnxYoloDemo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : demo of using c# to run yolo onnx model with onnx runtime, and contains a windows capture tool to get bitmap from windows desktop and window.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BobLd/YOLOv3MLNet\"\u003eBobLd/YOLOv3MLNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4dc10b3385a2b85a8c90773c2e27e1d95955178ff87d81d1b21fbc5ea4d9ac52/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f624c642f594f4c4f76334d4c4e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4dc10b3385a2b85a8c90773c2e27e1d95955178ff87d81d1b21fbc5ea4d9ac52/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f624c642f594f4c4f76334d4c4e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BobLd/YOLOv3MLNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Use the YOLO v3 (ONNX) model for object detection in C# using ML.Net.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zgabi/Yolo.Net\"\u003ezgabi/Yolo.Net\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4b10c524cb2958891e32d68a2338941a330bf3aff9119560f6cb0673f6cce7a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a676162692f596f6c6f2e4e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4b10c524cb2958891e32d68a2338941a330bf3aff9119560f6cb0673f6cce7a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a676162692f596f6c6f2e4e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zgabi/Yolo.Net?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : zgabi/Yolo.Net\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/aliardan/RoadMarkingDetection\"\u003ealiardan/RoadMarkingDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d8a0e9657b36e21ea4b36d2ac3ddde74d43730cad416095efc50b4f5079b80dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69617264616e2f526f61644d61726b696e67446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d8a0e9657b36e21ea4b36d2ac3ddde74d43730cad416095efc50b4f5079b80dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69617264616e2f526f61644d61726b696e67446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/aliardan/RoadMarkingDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Road markings detection using yolov5 model based on ONNX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TimothyMeadows/Yolo5.NetCore\"\u003eTimothyMeadows/Yolo5.NetCore\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1bf8de3a3c69567b73a82121815fcda105f8af5d25d83f977ca50dc6806e437b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54696d6f7468794d6561646f77732f596f6c6f352e4e6574436f72653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1bf8de3a3c69567b73a82121815fcda105f8af5d25d83f977ca50dc6806e437b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54696d6f7468794d6561646f77732f596f6c6f352e4e6574436f72653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TimothyMeadows/Yolo5.NetCore?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : You Only Look Once (v5) for .NET Core LTS.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AD-HO/YOLOv5-ML.NET\"\u003eAD-HO/YOLOv5-ML.NET\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9a51a877c49715d4d7a57f4c441ca4ae0dc163f89e0ae63d71f1bbac55026a24/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41442d484f2f594f4c4f76352d4d4c2e4e45543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9a51a877c49715d4d7a57f4c441ca4ae0dc163f89e0ae63d71f1bbac55026a24/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41442d484f2f594f4c4f76352d4d4c2e4e45543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AD-HO/YOLOv5-ML.NET?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Inferencing Yolov5 ONNX model using ML.NET and ONNX Runtime.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ToxicSkill/YOLOV7-Webcam-inference\"\u003eToxicSkill/YOLOV7-Webcam-inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2052e5e273bf14fdfb73a4f3edddac2066f729d5db0cdf91e6753309a6ab2204/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f546f786963536b696c6c2f594f4c4f56372d57656263616d2d696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2052e5e273bf14fdfb73a4f3edddac2066f729d5db0cdf91e6753309a6ab2204/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f546f786963536b696c6c2f594f4c4f56372d57656263616d2d696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ToxicSkill/YOLOV7-Webcam-inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Simple WPF program for webcam inference with yoloV7 models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/aliardan/RoadMarkingDetection\"\u003ealiardan/RoadMarkingDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d8a0e9657b36e21ea4b36d2ac3ddde74d43730cad416095efc50b4f5079b80dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69617264616e2f526f61644d61726b696e67446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d8a0e9657b36e21ea4b36d2ac3ddde74d43730cad416095efc50b4f5079b80dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69617264616e2f526f61644d61726b696e67446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/aliardan/RoadMarkingDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Road markings detection using yolov5 model based on ONNX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/rabbitsun2/csharp_and_microsoft_ml_and_yolo_v5_sample\"\u003erabbitsun2/csharp_and_microsoft_ml_and_yolo_v5_sample\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8dd7c19660f9d09628f1a415412e2bb4936a9805361486e5c2007da0d5bb37d8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616262697473756e322f6373686172705f616e645f6d6963726f736f66745f6d6c5f616e645f796f6c6f5f76355f73616d706c653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8dd7c19660f9d09628f1a415412e2bb4936a9805361486e5c2007da0d5bb37d8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616262697473756e322f6373686172705f616e645f6d6963726f736f66745f6d6c5f616e645f796f6c6f5f76355f73616d706c653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/rabbitsun2/csharp_and_microsoft_ml_and_yolo_v5_sample?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : C#, Microsoft ML, Yolo v5, Microsoft ML.DNN, OpenCVSharp4 ì—°ê³„ í”„ë¡œì íŠ¸.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hsysfan/YOLOv5-Seg-OnnxRuntime\"\u003ehsysfan/YOLOv5-Seg-OnnxRuntime\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ca9dbcaf2cdcd6a17b49d981d92d7591316ef12154597d963ecd7d8ebfeef844/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6873797366616e2f594f4c4f76352d5365672d4f6e6e7852756e74696d653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ca9dbcaf2cdcd6a17b49d981d92d7591316ef12154597d963ecd7d8ebfeef844/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6873797366616e2f594f4c4f76352d5365672d4f6e6e7852756e74696d653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hsysfan/YOLOv5-Seg-OnnxRuntime?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 Segmenation Implementation in C# and OnnxRuntime.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dme-compunet/YOLOv8\"\u003edme-compunet/YOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/55d79485e7c1ae2fbfc92d6ab01dc585fb5ba584daa7d55f5cae4b903007f329/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646d652d636f6d70756e65742f594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/55d79485e7c1ae2fbfc92d6ab01dc585fb5ba584daa7d55f5cae4b903007f329/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646d652d636f6d70756e65742f594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dme-compunet/YOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Use YOLOv8 in real-time, for object detection, instance segmentation, pose estimation and image classification, via ONNX Runtime.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eTensorflow and Keras Implementation\u003c/h3\u003e\u003ca id=\"user-content-tensorflow-and-keras-implementation\" class=\"anchor\" aria-label=\"Permalink: Tensorflow and Keras Implementation\" href=\"#tensorflow-and-keras-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/YunYang1994/tensorflow-yolov3\"\u003eYunYang1994/tensorflow-yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/69cce1841872334df861ed1df2437aa6655dd7e8d06c4de54a9d02a76d560e35/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59756e59616e67313939342f74656e736f72666c6f772d796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/69cce1841872334df861ed1df2437aa6655dd7e8d06c4de54a9d02a76d560e35/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59756e59616e67313939342f74656e736f72666c6f772d796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/YunYang1994/tensorflow-yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ”¥ TensorFlow Code for technical report: \"YOLOv3: An Incremental Improvement\".\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zzh8829/yolov3-tf2\"\u003ezzh8829/yolov3-tf2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/92dc9c99ae837db75c9e522ba7df8922670e3adfb4211585b214d339931b6cd8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a7a68383832392f796f6c6f76332d7466323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/92dc9c99ae837db75c9e522ba7df8922670e3adfb4211585b214d339931b6cd8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a7a68383832392f796f6c6f76332d7466323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zzh8829/yolov3-tf2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV3 Implemented in Tensorflow 2.0.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hunglc007/tensorflow-yolov4-tflite\"\u003ehunglc007/tensorflow-yolov4-tflite\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7098e9f8b2c4dd5fb83792783315583ae677a2977772b463cd2e94bc6aa740fd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756e676c633030372f74656e736f72666c6f772d796f6c6f76342d74666c6974653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7098e9f8b2c4dd5fb83792783315583ae677a2977772b463cd2e94bc6aa740fd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756e676c633030372f74656e736f72666c6f772d796f6c6f76342d74666c6974653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hunglc007/tensorflow-yolov4-tflite?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv4, YOLOv4-tiny, YOLOv3, YOLOv3-tiny Implemented in Tensorflow 2.0, Android. Convert YOLO v4 .weights tensorflow, tensorrt and tflite.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/gliese581gg/YOLO_tensorflow\"\u003egliese581gg/YOLO_tensorflow\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/aa82feec1d7833d2e2da94f84d001ef00645377dde1ff329bf7ed5aefa2719d7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f676c6965736535383167672f594f4c4f5f74656e736f72666c6f773f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/aa82feec1d7833d2e2da94f84d001ef00645377dde1ff329bf7ed5aefa2719d7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f676c6965736535383167672f594f4c4f5f74656e736f72666c6f773f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/gliese581gg/YOLO_tensorflow?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : tensorflow implementation of 'YOLO : Real-Time Object Detection'.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/llSourcell/YOLO_Object_Detection\"\u003ellSourcell/YOLO_Object_Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/24e2476af366f53ca70a9d83d776389cf1b9173a207302e7c2e2e11c9d254e23/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6c536f757263656c6c2f594f4c4f5f4f626a6563745f446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/24e2476af366f53ca70a9d83d776389cf1b9173a207302e7c2e2e11c9d254e23/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6c536f757263656c6c2f594f4c4f5f4f626a6563745f446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/llSourcell/YOLO_Object_Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is the code for \"YOLO Object Detection\" by Siraj Raval on Youtube.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wizyoung/YOLOv3_TensorFlow\"\u003ewizyoung/YOLOv3_TensorFlow\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d6657184c0fec52576ce554f96e7180b53b602713aa9f45aa6f4971e5777c054/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77697a796f756e672f594f4c4f76335f54656e736f72466c6f773f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d6657184c0fec52576ce554f96e7180b53b602713aa9f45aa6f4971e5777c054/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77697a796f756e672f594f4c4f76335f54656e736f72466c6f773f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wizyoung/YOLOv3_TensorFlow?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Complete YOLO v3 TensorFlow implementation. Support training on your own dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/theAIGuysCode/yolov4-deepsort\"\u003etheAIGuysCode/yolov4-deepsort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b764532c2fd44fcef54c916633e37624e70b2f98a0ce7f9cac1a6a1c794753df/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746865414947757973436f64652f796f6c6f76342d64656570736f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b764532c2fd44fcef54c916633e37624e70b2f98a0ce7f9cac1a6a1c794753df/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746865414947757973436f64652f796f6c6f76342d64656570736f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/theAIGuysCode/yolov4-deepsort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object tracking implemented with YOLOv4, DeepSort, and TensorFlow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mystic123/tensorflow-yolo-v3\"\u003emystic123/tensorflow-yolo-v3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a6e882b64953df9ea2389f8585453256b164663578d1ff6b278cf8d629dcb8bb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d79737469633132332f74656e736f72666c6f772d796f6c6f2d76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a6e882b64953df9ea2389f8585453256b164663578d1ff6b278cf8d629dcb8bb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d79737469633132332f74656e736f72666c6f772d796f6c6f2d76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mystic123/tensorflow-yolo-v3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Implementation of YOLO v3 object detector in Tensorflow (TF-Slim).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hizhangp/yolo_tensorflow\"\u003ehizhangp/yolo_tensorflow\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/96a0fda47bdbb608a8aec1997045fb8cb8d7e814234c9081e94b603b30836671/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68697a68616e67702f796f6c6f5f74656e736f72666c6f773f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/96a0fda47bdbb608a8aec1997045fb8cb8d7e814234c9081e94b603b30836671/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68697a68616e67702f796f6c6f5f74656e736f72666c6f773f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hizhangp/yolo_tensorflow?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tensorflow implementation of YOLO, including training and test phase.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nilboy/tensorflow-yolo\"\u003enilboy/tensorflow-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/10d5c7153d31076a20b2526d21c3666be3f346f9ac22791ecbed2c51bf4120f9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e696c626f792f74656e736f72666c6f772d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/10d5c7153d31076a20b2526d21c3666be3f346f9ac22791ecbed2c51bf4120f9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e696c626f792f74656e736f72666c6f772d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nilboy/tensorflow-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : tensorflow implementation of 'YOLO : Real-Time Object Detection'(train and test).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/qqwweee/keras-yolo3\"\u003eqqwweee/keras-yolo3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f382abf5c94790e427de31f5c9d203ab654a4e5ee888948987fc2e2081aab7ec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f717177776565652f6b657261732d796f6c6f333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f382abf5c94790e427de31f5c9d203ab654a4e5ee888948987fc2e2081aab7ec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f717177776565652f6b657261732d796f6c6f333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/qqwweee/keras-yolo3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Keras implementation of YOLOv3 (Tensorflow backend).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/allanzelener/YAD2K\"\u003eallanzelener/YAD2K\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/98c54e5148f3043e7b9e13992811df219a07dc25eb944700b13bcf81fe3cd1bf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c6c616e7a656c656e65722f594144324b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/98c54e5148f3043e7b9e13992811df219a07dc25eb944700b13bcf81fe3cd1bf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c6c616e7a656c656e65722f594144324b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/allanzelener/YAD2K?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YAD2K: Yet Another Darknet 2 Keras.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/experiencor/keras-yolo2\"\u003eexperiencor/keras-yolo2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b93473c24b804f154d1adac7d04b22395908168d8ae803c4bc9bc4cea24a077c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657870657269656e636f722f6b657261732d796f6c6f323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b93473c24b804f154d1adac7d04b22395908168d8ae803c4bc9bc4cea24a077c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657870657269656e636f722f6b657261732d796f6c6f323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/experiencor/keras-yolo2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv2 in Keras and Applications.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/experiencor/keras-yolo3\"\u003eexperiencor/keras-yolo3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/58a9e41bf1f9e32dba41ece6c4f0ff980bd5b2a531a94d78df0ef0dac1ac206e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657870657269656e636f722f6b657261732d796f6c6f333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/58a9e41bf1f9e32dba41ece6c4f0ff980bd5b2a531a94d78df0ef0dac1ac206e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657870657269656e636f722f6b657261732d796f6c6f333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/experiencor/keras-yolo3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Training and Detecting Objects with YOLO3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SpikeKing/keras-yolo3-detection\"\u003eSpikeKing/keras-yolo3-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/92c8eedb3c9d56b27bf7df8ac446b153716b4d1d0c3ae4874dfde3182d6bb091/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5370696b654b696e672f6b657261732d796f6c6f332d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/92c8eedb3c9d56b27bf7df8ac446b153716b4d1d0c3ae4874dfde3182d6bb091/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5370696b654b696e672f6b657261732d796f6c6f332d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SpikeKing/keras-yolo3-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO v3 ç‰©ä½“æ£€æµ‹ç®—æ³•ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xiaochus/YOLOv3\"\u003exiaochus/YOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e5af5d5a93814b718e6ea0964549bc91c0f857a838e2b40eb0a15325d76089c8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616f636875732f594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e5af5d5a93814b718e6ea0964549bc91c0f857a838e2b40eb0a15325d76089c8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616f636875732f594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xiaochus/YOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Keras implementation of yolo v3 object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolo3-keras\"\u003ebubbliiiing/yolo3-keras\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2f8de2d19e71d2f3d340996fd8cef2dcce5286c05d0829cf910f96f327fb465d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f332d6b657261733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2f8de2d19e71d2f3d340996fd8cef2dcce5286c05d0829cf910f96f327fb465d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f332d6b657261733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolo3-keras?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¿™æ˜¯ä¸€ä¸ªyolo3-kerasçš„æºç ï¼Œå¯ä»¥ç”¨äºŽè®­ç»ƒè‡ªå·±çš„æ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolov4-keras\"\u003ebubbliiiing/yolov4-keras\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/223b8763864c8e5095a185503417c1ff72474b9b37595da441476507a6206655/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d6b657261733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/223b8763864c8e5095a185503417c1ff72474b9b37595da441476507a6206655/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d6b657261733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolov4-keras?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¿™æ˜¯ä¸€ä¸ªYoloV4-kerasçš„æºç ï¼Œå¯ä»¥ç”¨äºŽè®­ç»ƒè‡ªå·±çš„æ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolov4-tf2\"\u003ebubbliiiing/yolov4-tf2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/78bf74e5714836e301f505a83864f9aa18366e3d2d823588fc7d79ebf021d76e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d7466323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/78bf74e5714836e301f505a83864f9aa18366e3d2d823588fc7d79ebf021d76e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d7466323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolov4-tf2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¿™æ˜¯ä¸€ä¸ªyolo4-tf2ï¼ˆtensorflow2ï¼‰çš„æºç ï¼Œå¯ä»¥ç”¨äºŽè®­ç»ƒè‡ªå·±çš„æ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolov4-tiny-tf2\"\u003ebubbliiiing/yolov4-tiny-tf2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/40462360f8f13e583eecda8931c1e498c0f28240addf7442e1b9a2c364f4b544/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d74696e792d7466323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/40462360f8f13e583eecda8931c1e498c0f28240addf7442e1b9a2c364f4b544/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d74696e792d7466323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolov4-tiny-tf2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¿™æ˜¯ä¸€ä¸ªYoloV4-tiny-tf2çš„æºç ï¼Œå¯ä»¥ç”¨äºŽè®­ç»ƒè‡ªå·±çš„æ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pythonlessons/TensorFlow-2.x-YOLOv3\"\u003epythonlessons/TensorFlow-2.x-YOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ca3fd42659bbd1b6d9879445005011235d01d5f792fa36cce50280581db15163/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f707974686f6e6c6573736f6e732f54656e736f72466c6f772d322e782d594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ca3fd42659bbd1b6d9879445005011235d01d5f792fa36cce50280581db15163/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f707974686f6e6c6573736f6e732f54656e736f72466c6f772d322e782d594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pythonlessons/TensorFlow-2.x-YOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv3 implementation in TensorFlow 2.3.1.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/miemie2013/Keras-YOLOv4\"\u003emiemie2013/Keras-YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/06eb998a993df6aea7e1ba25b5323f9f395daff30300e666ce3339c5b3bdfa26/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69656d6965323031332f4b657261732d594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/06eb998a993df6aea7e1ba25b5323f9f395daff30300e666ce3339c5b3bdfa26/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69656d6965323031332f4b657261732d594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/miemie2013/Keras-YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PPYOLO AND YOLOv4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ma-Dan/keras-yolo4\"\u003eMa-Dan/keras-yolo4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2c189e2736465d4b9cdbaa10742c1899833a061fd09904d3d5aacbaca8b93131/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d612d44616e2f6b657261732d796f6c6f343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2c189e2736465d4b9cdbaa10742c1899833a061fd09904d3d5aacbaca8b93131/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d612d44616e2f6b657261732d796f6c6f343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ma-Dan/keras-yolo4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Keras implementation of YOLOv4 (Tensorflow backend).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/miranthajayatilake/YOLOw-Keras\"\u003emiranthajayatilake/YOLOw-Keras\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cbe50e9b152075fdfbc6059f01c9f476cb1fe6958a1c87a86a8b94807547a14b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6972616e7468616a61796174696c616b652f594f4c4f772d4b657261733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cbe50e9b152075fdfbc6059f01c9f476cb1fe6958a1c87a86a8b94807547a14b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6972616e7468616a61796174696c616b652f594f4c4f772d4b657261733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/miranthajayatilake/YOLOw-Keras?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv2 Object Detection w/ Keras (in just 20 lines of code).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/maiminh1996/YOLOv3-tensorflow\"\u003emaiminh1996/YOLOv3-tensorflow\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/144736fd84de7be7bbb8a31b7fd2048b7eed92cc5e04bfe14ec025a42e0bb930/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61696d696e68313939362f594f4c4f76332d74656e736f72666c6f773f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/144736fd84de7be7bbb8a31b7fd2048b7eed92cc5e04bfe14ec025a42e0bb930/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61696d696e68313939362f594f4c4f76332d74656e736f72666c6f773f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/maiminh1996/YOLOv3-tensorflow?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Re-implement YOLOv3 with TensorFlow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Stick-To/Object-Detection-Tensorflow\"\u003eStick-To/Object-Detection-Tensorflow\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/57ee0a553ad1548130b1d1d9364af3c2c43c1219a846c08f94da6d0d77248dee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f537469636b2d546f2f4f626a6563742d446574656374696f6e2d54656e736f72666c6f773f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/57ee0a553ad1548130b1d1d9364af3c2c43c1219a846c08f94da6d0d77248dee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f537469636b2d546f2f4f626a6563742d446574656374696f6e2d54656e736f72666c6f773f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Stick-To/Object-Detection-Tensorflow?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object Detection API Tensorflow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/avBuffer/Yolov5_tf\"\u003eavBuffer/Yolov5_tf\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d0b88aa2cd00c416cda98e60dd9368423710adcfe125d7b3d5d5002667eddb3b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61764275666665722f596f6c6f76355f74663f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d0b88aa2cd00c416cda98e60dd9368423710adcfe125d7b3d5d5002667eddb3b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61764275666665722f596f6c6f76355f74663f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/avBuffer/Yolov5_tf?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov5/Yolov4/ Yolov3/ Yolo_tiny in tensorflow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ruiminshen/yolo-tf\"\u003eruiminshen/yolo-tf\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/76012a882d3430830f37bdf48f4f85bb26795a7556126ff0970d5ddc10551652/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7275696d696e7368656e2f796f6c6f2d74663f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/76012a882d3430830f37bdf48f4f85bb26795a7556126ff0970d5ddc10551652/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7275696d696e7368656e2f796f6c6f2d74663f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ruiminshen/yolo-tf?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorFlow implementation of the YOLO (You Only Look Once).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xiao9616/yolo4_tensorflow2\"\u003exiao9616/yolo4_tensorflow2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/95c1eb598faa93b4695cbfad5bcdb3c69e6bd4df5137afd4e0174d2bd189705b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616f393631362f796f6c6f345f74656e736f72666c6f77323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/95c1eb598faa93b4695cbfad5bcdb3c69e6bd4df5137afd4e0174d2bd189705b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616f393631362f796f6c6f345f74656e736f72666c6f77323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xiao9616/yolo4_tensorflow2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolo 4th edition implemented by tensorflow2.0.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sicara/tf2-yolov4\"\u003esicara/tf2-yolov4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/da84ad7b5be3c9f1189886c4696380310e41dd7d9a07f2d88515365e05608acd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7369636172612f7466322d796f6c6f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/da84ad7b5be3c9f1189886c4696380310e41dd7d9a07f2d88515365e05608acd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7369636172612f7466322d796f6c6f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sicara/tf2-yolov4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A TensorFlow 2.0 implementation of YOLOv4: Optimal Speed and Accuracy of Object Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LongxingTan/Yolov5\"\u003eLongxingTan/Yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2073f53c6fe4a01fd58bbc741d10503ef516cab9a9b1bc09ed29fb491f48deee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c6f6e6778696e6754616e2f596f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2073f53c6fe4a01fd58bbc741d10503ef516cab9a9b1bc09ed29fb491f48deee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c6f6e6778696e6754616e2f596f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LongxingTan/Yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Efficient implementation of YOLOV5 in TensorFlow2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/geekjr/quickai\"\u003egeekjr/quickai\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ca5bc1905f588a0c5cfe84024d61ac83732034c700147fae12ccb435fc7d7d04/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6765656b6a722f717569636b61693f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ca5bc1905f588a0c5cfe84024d61ac83732034c700147fae12ccb435fc7d7d04/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6765656b6a722f717569636b61693f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/geekjr/quickai?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : QuickAI is a Python library that makes it extremely easy to experiment with state-of-the-art Machine Learning models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://gitee.com/CV_Lab/yolov5_rt_tfjs\" rel=\"nofollow\"\u003eCV_Lab/yolov5_rt_tfjs\u003c/a\u003e : ðŸš€ åŸºäºŽTensorFlow.jsçš„YOLOv5å®žæ—¶ç›®æ ‡æ£€æµ‹é¡¹ç›®ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Burf/TFDetection\"\u003eBurf/TFDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cf89c158090c1761515fa5c73b89866ce874e135e735c33bb5e9e0eb0f67ee5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427572662f5446446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cf89c158090c1761515fa5c73b89866ce874e135e735c33bb5e9e0eb0f67ee5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427572662f5446446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Burf/TFDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Detection Toolbox for Tensorflow2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/taipingeric/yolo-v4-tf.keras\"\u003etaipingeric/yolo-v4-tf.keras\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b030793d44ff9e197eb3254872d3703341efa24e1bcb05e4cc85037bb827e44f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616970696e67657269632f796f6c6f2d76342d74662e6b657261733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b030793d44ff9e197eb3254872d3703341efa24e1bcb05e4cc85037bb827e44f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616970696e67657269632f796f6c6f2d76342d74662e6b657261733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/taipingeric/yolo-v4-tf.keras?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A simple tf.keras implementation of YOLO v4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/david8862/keras-YOLOv3-model-set\"\u003edavid8862/keras-YOLOv3-model-set\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5b9abe069a1e8a1623bdc317705d0e790b4146488420617ad3d754791cf14866/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6461766964383836322f6b657261732d594f4c4f76332d6d6f64656c2d7365743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5b9abe069a1e8a1623bdc317705d0e790b4146488420617ad3d754791cf14866/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6461766964383836322f6b657261732d594f4c4f76332d6d6f64656c2d7365743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/david8862/keras-YOLOv3-model-set?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : end-to-end YOLOv4/v3/v2 object detection pipeline, implemented on tf.keras with different technologies.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003ePaddlePaddle Implementation\u003c/h3\u003e\u003ca id=\"user-content-paddlepaddle-implementation\" class=\"anchor\" aria-label=\"Permalink: PaddlePaddle Implementation\" href=\"#paddlepaddle-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PaddlePaddle/PaddleDetection\"\u003ePaddlePaddle/PaddleDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f3c9773ff34de7d0d273c5bd7486e9b01fe36c95a0f0fa0b9d86fbfb6fb7d045/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506164646c65506164646c652f506164646c65446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f3c9773ff34de7d0d273c5bd7486e9b01fe36c95a0f0fa0b9d86fbfb6fb7d045/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506164646c65506164646c652f506164646c65446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PaddlePaddle/PaddleDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object Detection toolkit based on PaddlePaddle. \"PP-YOLO: An Effective and Efficient Implementation of Object Detector\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2007.12099\" rel=\"nofollow\"\u003earXiv 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nemonameless/PaddleDetection_YOLOv5\"\u003enemonameless/PaddleDetection_YOLOv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/61c9615add66892a90cd6ca65dde57c1db3ae2dd70f5abea056505866a814dc7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e656d6f6e616d656c6573732f506164646c65446574656374696f6e5f594f4c4f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/61c9615add66892a90cd6ca65dde57c1db3ae2dd70f5abea056505866a814dc7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e656d6f6e616d656c6573732f506164646c65446574656374696f6e5f594f4c4f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nemonameless/PaddleDetection_YOLOv5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 of PaddleDetection, Paddle implementation of YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nemonameless/PaddleDetection_YOLOX\"\u003enemonameless/PaddleDetection_YOLOX\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e883d3715a631e2f9ec053a1411d746c0dd9d5e3a95bea4f2d75ced37f30727a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e656d6f6e616d656c6573732f506164646c65446574656374696f6e5f594f4c4f583f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e883d3715a631e2f9ec053a1411d746c0dd9d5e3a95bea4f2d75ced37f30727a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e656d6f6e616d656c6573732f506164646c65446574656374696f6e5f594f4c4f583f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nemonameless/PaddleDetection_YOLOX?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Paddle YOLOX, 51.8% on COCO val by YOLOX-x, 44.6% on YOLOX-ConvNeXt-s.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nemonameless/PaddleDetection_YOLOset\"\u003enemonameless/PaddleDetection_YOLOset\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f7dfc4961a9b68cc235b262ff54da416091dc4224de9c046b4eb20383f408211/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e656d6f6e616d656c6573732f506164646c65446574656374696f6e5f594f4c4f7365743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f7dfc4961a9b68cc235b262ff54da416091dc4224de9c046b4eb20383f408211/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e656d6f6e616d656c6573732f506164646c65446574656374696f6e5f594f4c4f7365743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nemonameless/PaddleDetection_YOLOset?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Paddle YOLO set: YOLOv3, PPYOLO, PPYOLOE, YOLOX, YOLOv5, YOLOv7 and so on.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/miemie2013/Paddle-YOLOv4\"\u003emiemie2013/Paddle-YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0fce707f3f45f23147f245271c4d5a8be3a26b443e7cb8316acd4786487d0d5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69656d6965323031332f506164646c652d594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0fce707f3f45f23147f245271c4d5a8be3a26b443e7cb8316acd4786487d0d5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69656d6965323031332f506164646c652d594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/miemie2013/Paddle-YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Paddle-YOLOv4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Sharpiless/PaddleDetection-Yolov5\"\u003eSharpiless/PaddleDetection-Yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/857b829521fd3bd2f58a49458c09d03db6a06abd0bbe0652daf584af2196e377/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f506164646c65446574656374696f6e2d596f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/857b829521fd3bd2f58a49458c09d03db6a06abd0bbe0652daf584af2196e377/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f506164646c65446574656374696f6e2d596f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Sharpiless/PaddleDetection-Yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽPaddlepaddleå¤çŽ°yolov5ï¼Œæ”¯æŒPaddleDetectionæŽ¥å£ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Nioolek/PPYOLOE_pytorch\"\u003eNioolek/PPYOLOE_pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6a93992f64621b8298cb9221906bddff90badd65b0ab80545f8c804a0e8df884/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e696f6f6c656b2f5050594f4c4f455f7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6a93992f64621b8298cb9221906bddff90badd65b0ab80545f8c804a0e8df884/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e696f6f6c656b2f5050594f4c4f455f7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Nioolek/PPYOLOE_pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An unofficial implementation of Pytorch version PP-YOLOE,based on Megvii YOLOX training code.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCaffe Implementation\u003c/h3\u003e\u003ca id=\"user-content-caffe-implementation\" class=\"anchor\" aria-label=\"Permalink: Caffe Implementation\" href=\"#caffe-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ChenYingpeng/caffe-yolov3\"\u003eChenYingpeng/caffe-yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/307e96673c3fb834371dee728e35170ddd1d1e9979fdd92051adda0a18cf88dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368656e59696e6770656e672f63616666652d796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/307e96673c3fb834371dee728e35170ddd1d1e9979fdd92051adda0a18cf88dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368656e59696e6770656e672f63616666652d796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ChenYingpeng/caffe-yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A real-time object detection framework of Yolov3/v4 based on caffe.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ChenYingpeng/darknet2caffe\"\u003eChenYingpeng/darknet2caffe\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f9234ff083ca12f5e4b58caab44c2ed4045005429df73149b091a06551ce51aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368656e59696e6770656e672f6461726b6e65743263616666653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f9234ff083ca12f5e4b58caab44c2ed4045005429df73149b091a06551ce51aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368656e59696e6770656e672f6461726b6e65743263616666653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ChenYingpeng/darknet2caffe?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Convert darknet weights to caffemodel.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/eric612/Caffe-YOLOv3-Windows\"\u003eeric612/Caffe-YOLOv3-Windows\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ee72874502fafefeb1cb7e098ffd88a4b10b2da1c12ec38d1ecc56f111abb96a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657269633631322f43616666652d594f4c4f76332d57696e646f77733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ee72874502fafefeb1cb7e098ffd88a4b10b2da1c12ec38d1ecc56f111abb96a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657269633631322f43616666652d594f4c4f76332d57696e646f77733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/eric612/Caffe-YOLOv3-Windows?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A windows caffe implementation of YOLO detection network.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Harick1/caffe-yolo\"\u003eHarick1/caffe-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/38f0f18570d5e42dd3ada3edfd95dc9d844ce6962bc715b384e8c45dd2576ac2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48617269636b312f63616666652d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/38f0f18570d5e42dd3ada3edfd95dc9d844ce6962bc715b384e8c45dd2576ac2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48617269636b312f63616666652d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Harick1/caffe-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Caffe for YOLO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/choasup/caffe-yolo9000\"\u003echoasup/caffe-yolo9000\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/db4ee788ba3fe69da1d9b7a63326211a664778b3dcbbfd98710ce29b95a0b59e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63686f617375702f63616666652d796f6c6f393030303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/db4ee788ba3fe69da1d9b7a63326211a664778b3dcbbfd98710ce29b95a0b59e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63686f617375702f63616666652d796f6c6f393030303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/choasup/caffe-yolo9000?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Caffe for YOLOv2 \u0026amp; YOLO9000.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/gklz1982/caffe-yolov2\"\u003egklz1982/caffe-yolov2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/24f694e54bb220b2c45550e030f83b32744d73d951ff07d9b7b2d7bf59a4d8c8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f676b6c7a313938322f63616666652d796f6c6f76323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/24f694e54bb220b2c45550e030f83b32744d73d951ff07d9b7b2d7bf59a4d8c8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f676b6c7a313938322f63616666652d796f6c6f76323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/gklz1982/caffe-yolov2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : caffe-yolov2.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eMXNet Implementation\u003c/h3\u003e\u003ca id=\"user-content-mxnet-implementation\" class=\"anchor\" aria-label=\"Permalink: MXNet Implementation\" href=\"#mxnet-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dmlc/gluon-cv\"\u003eGluon CV Toolkit\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/67e8a659da8bcf14d75581b0d011131aa56bed5993da5fc6d48b03d0f63ced30/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646d6c632f676c756f6e2d63763f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/67e8a659da8bcf14d75581b0d011131aa56bed5993da5fc6d48b03d0f63ced30/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646d6c632f676c756f6e2d63763f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dmlc/gluon-cv?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : GluonCV provides implementations of the state-of-the-art (SOTA) deep learning models in computer vision.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zhreshold/mxnet-yolo\"\u003ezhreshold/mxnet-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1a9c805e7d7623c2a0a0546063c565981a99cd2f044b0ff1ccae3055f92b4f0c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68726573686f6c642f6d786e65742d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1a9c805e7d7623c2a0a0546063c565981a99cd2f044b0ff1ccae3055f92b4f0c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68726573686f6c642f6d786e65742d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zhreshold/mxnet-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO: You only look once real-time object detector.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eWeb Implementation\u003c/h3\u003e\u003ca id=\"user-content-web-implementation\" class=\"anchor\" aria-label=\"Permalink: Web Implementation\" href=\"#web-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ModelDepot/tfjs-yolo-tiny\"\u003eModelDepot/tfjs-yolo-tiny\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/95e7d5171aca6a2cb42cc5a37fb7fbd153d1d0b82cf01e23c9e836fdf0548bba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f64656c4465706f742f74666a732d796f6c6f2d74696e793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/95e7d5171aca6a2cb42cc5a37fb7fbd153d1d0b82cf01e23c9e836fdf0548bba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f64656c4465706f742f74666a732d796f6c6f2d74696e793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ModelDepot/tfjs-yolo-tiny?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : In-Browser Object Detection using Tiny YOLO on Tensorflow.js.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/justadudewhohacks/tfjs-tiny-yolov2\"\u003ejustadudewhohacks/tfjs-tiny-yolov2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/44d4a6c3fc482435d3a3e91df3e9a9f44a7b7402613f9db16bd657aa831a6f90/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a757374616475646577686f6861636b732f74666a732d74696e792d796f6c6f76323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/44d4a6c3fc482435d3a3e91df3e9a9f44a7b7402613f9db16bd657aa831a6f90/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a757374616475646577686f6861636b732f74666a732d74696e792d796f6c6f76323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/justadudewhohacks/tfjs-tiny-yolov2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tiny YOLO v2 object detection with tensorflow.js.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/reu2018DL/YOLO-LITE\"\u003ereu2018DL/YOLO-LITE\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/80778432726d750c63bdbf7ab68003a4062cf1aad9c4eeb159252b07f2b4ab69/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72657532303138444c2f594f4c4f2d4c4954453f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/80778432726d750c63bdbf7ab68003a4062cf1aad9c4eeb159252b07f2b4ab69/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72657532303138444c2f594f4c4f2d4c4954453f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/reu2018DL/YOLO-LITE?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO-LITE is a web implementation of YOLOv2-tiny.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mobimeo/node-yolo\"\u003emobimeo/node-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e6dd3d99914b1ee67dab473610c27b703148942eaa0de43fdb26e980d2b9ac5f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6f62696d656f2f6e6f64652d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e6dd3d99914b1ee67dab473610c27b703148942eaa0de43fdb26e980d2b9ac5f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6f62696d656f2f6e6f64652d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mobimeo/node-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Node bindings for YOLO/Darknet image recognition library.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Sharpiless/Yolov5-Flask-VUE\"\u003eSharpiless/Yolov5-Flask-VUE\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/90a0db3fb21469de04241c2b56a8a0c5a4bb39b5efadf73d9d198afc08625cbc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76352d466c61736b2d5655453f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/90a0db3fb21469de04241c2b56a8a0c5a4bb39b5efadf73d9d198afc08625cbc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76352d466c61736b2d5655453f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Sharpiless/Yolov5-Flask-VUE?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽFlaskå¼€å‘åŽç«¯ã€VUEå¼€å‘å‰ç«¯æ¡†æž¶ï¼Œåœ¨WEBç«¯éƒ¨ç½²YOLOv5ç›®æ ‡æ£€æµ‹æ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/shaqian/tfjs-yolo\"\u003eshaqian/tfjs-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f5612b3707bbbc44ce50b401037c4b5df2c53b89ba22d03471eced2893c0cd59/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7368617169616e2f74666a732d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f5612b3707bbbc44ce50b401037c4b5df2c53b89ba22d03471eced2893c0cd59/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7368617169616e2f74666a732d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/shaqian/tfjs-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO v3 and Tiny YOLO v1, v2, v3 with Tensorflow.js.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zqingr/tfjs-yolov3\"\u003ezqingr/tfjs-yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d96ce8a883d78f2f4a358a68a605e1134bed92dd2b7e8634deb001bed29e2ecc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a71696e67722f74666a732d796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d96ce8a883d78f2f4a358a68a605e1134bed92dd2b7e8634deb001bed29e2ecc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a71696e67722f74666a732d796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zqingr/tfjs-yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Tensorflow js implementation of YOLOv3 and YOLOv3-tiny.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bennetthardwick/darknet.js\"\u003ebennetthardwick/darknet.js\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bbebcd4253f992efdc0be357b2a73a7cb61eb8cce09afeaae5ace4b1a9a5c598/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62656e6e657474686172647769636b2f6461726b6e65742e6a733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bbebcd4253f992efdc0be357b2a73a7cb61eb8cce09afeaae5ace4b1a9a5c598/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62656e6e657474686172647769636b2f6461726b6e65742e6a733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bennetthardwick/darknet.js?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A NodeJS wrapper of pjreddie's darknet / yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nihui/ncnn-webassembly-yolov5\"\u003enihui/ncnn-webassembly-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/efb42dd0f4f6883bf82afad80432bee64fbea22d428fe46d74c8b1d0cb100102/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e696875692f6e636e6e2d776562617373656d626c792d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/efb42dd0f4f6883bf82afad80432bee64fbea22d428fe46d74c8b1d0cb100102/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e696875692f6e636e6e2d776562617373656d626c792d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nihui/ncnn-webassembly-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Deploy YOLOv5 in your web browser with ncnn and webassembly.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/muhk01/Yolov5-on-Flask\"\u003emuhk01/Yolov5-on-Flask\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a0e26ec4e167038ed01cff1f0360fbeb819aafce40eb28f6b40330451b777e8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d75686b30312f596f6c6f76352d6f6e2d466c61736b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a0e26ec4e167038ed01cff1f0360fbeb819aafce40eb28f6b40330451b777e8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d75686b30312f596f6c6f76352d6f6e2d466c61736b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/muhk01/Yolov5-on-Flask?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Running YOLOv5 through web browser using Flask microframework.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tcyfree/yolov5\"\u003etcyfree/yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fdac64d776d2983ea0e2442abd9b3914da35c13c7b53f4b61cc73cc0a8e1a140/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746379667265652f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fdac64d776d2983ea0e2442abd9b3914da35c13c7b53f4b61cc73cc0a8e1a140/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746379667265652f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tcyfree/yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽFlaskå¼€å‘åŽç«¯ã€VUEå¼€å‘å‰ç«¯æ¡†æž¶ï¼Œåœ¨WEBç«¯éƒ¨ç½²YOLOv5ç›®æ ‡æ£€æµ‹æ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/siffyy/YOLOv5-Web-App-for-Vehicle-Detection\"\u003esiffyy/YOLOv5-Web-App-for-Vehicle-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9c91b5d607038bddf394a4693e466a5a041c61a492953529692563626c505cb3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7369666679792f594f4c4f76352d5765622d4170702d666f722d56656869636c652d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9c91b5d607038bddf394a4693e466a5a041c61a492953529692563626c505cb3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7369666679792f594f4c4f76352d5765622d4170702d666f722d56656869636c652d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/siffyy/YOLOv5-Web-App-for-Vehicle-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Repo for Web Application for Vehicle detection from Satellite Imagery using YOLOv5 model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Devmawi/BlazorObjectDetection-Sample\"\u003eDevmawi/BlazorObjectDetection-Sample\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0a7a3aaeb487c934dad1fb44b7dc62bc26c0fbec3f566acc9eee3e21f4681ac4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465766d6177692f426c617a6f724f626a656374446574656374696f6e2d53616d706c653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0a7a3aaeb487c934dad1fb44b7dc62bc26c0fbec3f566acc9eee3e21f4681ac4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465766d6177692f426c617a6f724f626a656374446574656374696f6e2d53616d706c653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Devmawi/BlazorObjectDetection-Sample?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A sample for demonstrating online execution of an onnx model by a Blazor app.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Hyuto/yolov5-onnxruntime-web\"\u003eHyuto/yolov5-onnxruntime-web\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f73317c3801a14112cc950c80e5ad4845acc8b61d4fa92c11b2b0e38b007ff8d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f487975746f2f796f6c6f76352d6f6e6e7872756e74696d652d7765623f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f73317c3801a14112cc950c80e5ad4845acc8b61d4fa92c11b2b0e38b007ff8d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f487975746f2f796f6c6f76352d6f6e6e7872756e74696d652d7765623f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Hyuto/yolov5-onnxruntime-web?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 right in your browser with onnxruntime-web.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOthers\u003c/h3\u003e\u003ca id=\"user-content-others\" class=\"anchor\" aria-label=\"Permalink: Others\" href=\"#others\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jinfagang/yolov7_d2\"\u003ejinfagang/yolov7_d2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/75ac2ec2ed94f7b5b8bf93a2d80ae03b5f10440c8ade9ba824eab65dcfa62e05/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a696e666167616e672f796f6c6f76375f64323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/75ac2ec2ed94f7b5b8bf93a2d80ae03b5f10440c8ade9ba824eab65dcfa62e05/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a696e666167616e672f796f6c6f76375f64323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jinfagang/yolov7_d2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ (Earlier YOLOv7 not official one) YOLO with Transformers and Instance Segmentation, with TensorRT acceleration! ðŸ”¥ðŸ”¥ðŸ”¥\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yang-0201/YOLOv6_pro\"\u003eyang-0201/YOLOv6_pro\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2ce9ac5f491826cbfc3c3008d94ceb548400eda43f3cd48bddeec5399d09a90d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f79616e672d303230312f594f4c4f76365f70726f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2ce9ac5f491826cbfc3c3008d94ceb548400eda43f3cd48bddeec5399d09a90d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f79616e672d303230312f594f4c4f76365f70726f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yang-0201/YOLOv6_pro?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Make it easier for yolov6 to change the network structure.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/j-marple-dev/AYolov2\"\u003ej-marple-dev/AYolov2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e87fe72ff0a677240effb3ba6bac8b6245f5948655d4311881fb8600a7b3695d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a2d6d6172706c652d6465762f41596f6c6f76323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e87fe72ff0a677240effb3ba6bac8b6245f5948655d4311881fb8600a7b3695d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a2d6d6172706c652d6465762f41596f6c6f76323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/j-marple-dev/AYolov2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The main goal of this repository is to rewrite the object detection pipeline with a better code structure for better portability and adaptability to apply new experimental methods. The object detection pipeline is based on \u003ca href=\"https://github.com/ultralytics/yolov5\"\u003eUltralytics YOLOv5\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fcakyon/yolov5-pip\"\u003efcakyon/yolov5-pip\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/181dce865af43b3ceeaa66297c4abe04f6eb885d68ec4883b8a8a825da686b75/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6663616b796f6e2f796f6c6f76352d7069703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/181dce865af43b3ceeaa66297c4abe04f6eb885d68ec4883b8a8a825da686b75/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6663616b796f6e2f796f6c6f76352d7069703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/fcakyon/yolov5-pip?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Packaged version of ultralytics/yolov5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kadirnar/yolov6-pip\"\u003ekadirnar/yolov6-pip\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/83a4b786e66c05082bde11bd221ea5bf74b15860fc6e6371cc662e6e21ebf77a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f796f6c6f76362d7069703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/83a4b786e66c05082bde11bd221ea5bf74b15860fc6e6371cc662e6e21ebf77a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f796f6c6f76362d7069703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kadirnar/yolov6-pip?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Packaged version of yolov6 model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kadirnar/yolov7-pip\"\u003ekadirnar/yolov7-pip\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fcc88c8f689bac403c5561a89c13f44b5e3f0ccf5fcffe82eb6e541955588ea9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f796f6c6f76372d7069703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fcc88c8f689bac403c5561a89c13f44b5e3f0ccf5fcffe82eb6e541955588ea9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f796f6c6f76372d7069703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kadirnar/yolov7-pip?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Packaged version of yolov7 model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kadirnar/torchyolo\"\u003ekadirnar/torchyolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/03c8a6e2443aa79b0fcfd8cc46ef788691df34f97509376bb23322430e53d5bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f746f726368796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/03c8a6e2443aa79b0fcfd8cc46ef788691df34f97509376bb23322430e53d5bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f746f726368796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kadirnar/torchyolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PyTorch implementation of YOLOv5, YOLOv6, YOLOv7, YOLOX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/shanglianlm0525/CvPytorch\"\u003eCvPytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ba551cd3c0404b99f027ebe9e1ff68b11284ae895f7363bb54dce7a047e1c2ee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7368616e676c69616e6c6d303532352f43765079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ba551cd3c0404b99f027ebe9e1ff68b11284ae895f7363bb54dce7a047e1c2ee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7368616e676c69616e6c6d303532352f43765079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/shanglianlm0525/CvPytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : CvPytorch is an open source COMPUTER VISION toolbox based on PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/frgfm/Holocron\"\u003eHolocron\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c1c4cf2e7ea11e006d2e56999997f0226f8a9a7e9222ccbecd8f7db644568f90/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f667267666d2f486f6c6f63726f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c1c4cf2e7ea11e006d2e56999997f0226f8a9a7e9222ccbecd8f7db644568f90/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f667267666d2f486f6c6f63726f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/frgfm/Holocron?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PyTorch implementations of recent Computer Vision tricks (ReXNet, RepVGG, Unet3p, YOLOv4, CIoU loss, AdaBelief, PolyLoss).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DL-Practise/YoloAll\"\u003eDL-Practise/YoloAll\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e30775ab2fd883b2328629fe0c7b61868830747e3bdb3666c0992dcc49843637/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f444c2d50726163746973652f596f6c6f416c6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e30775ab2fd883b2328629fe0c7b61868830747e3bdb3666c0992dcc49843637/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f444c2d50726163746973652f596f6c6f416c6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DL-Practise/YoloAll?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloAll is a collection of yolo all versions. you you use YoloAll to test yolov3/yolov5/yolox/yolo_fastest.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/msnh2012/Msnhnet\"\u003emsnh2012/Msnhnet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e2b3164bbcd5e135a9730be6a8f8e319c63d18aaaa29508bd0442e5fb85bca45/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d736e68323031322f4d736e686e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e2b3164bbcd5e135a9730be6a8f8e319c63d18aaaa29508bd0442e5fb85bca45/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d736e68323031322f4d736e686e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/msnh2012/Msnhnet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : (yolov3 yolov4 yolov5 unet ...)A mini pytorch inference framework which inspired from darknet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xinghanliuying/yolov5-trick\"\u003exinghanliuying/yolov5-trick\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/91ebf281beafca1882db28e35cb8f4e184350ba5548a910ba79e9e52d757fa53/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78696e6768616e6c697579696e672f796f6c6f76352d747269636b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/91ebf281beafca1882db28e35cb8f4e184350ba5548a910ba79e9e52d757fa53/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78696e6768616e6c697579696e672f796f6c6f76352d747269636b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xinghanliuying/yolov5-trick?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽyolov5çš„æ”¹è¿›åº“ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BMW-InnovationLab/BMW-YOLOv4-Training-Automation\"\u003eBMW-InnovationLab/BMW-YOLOv4-Training-Automation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2ecbce3b056df31c432437681ef4a5727734394ae1564a8f1d2dc4dac9521ab8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f424d572d496e6e6f766174696f6e4c61622f424d572d594f4c4f76342d547261696e696e672d4175746f6d6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2ecbce3b056df31c432437681ef4a5727734394ae1564a8f1d2dc4dac9521ab8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f424d572d496e6e6f766174696f6e4c61622f424d572d594f4c4f76342d547261696e696e672d4175746f6d6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BMW-InnovationLab/BMW-YOLOv4-Training-Automation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv4-v3 Training Automation API for Linux.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AntonMu/TrainYourOwnYOLO\"\u003eAntonMu/TrainYourOwnYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/18654c49f1d1514b5e3e67a8287c3783656bc904ac3c8d0dc19d9b46ee094fcf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e746f6e4d752f547261696e596f75724f776e594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/18654c49f1d1514b5e3e67a8287c3783656bc904ac3c8d0dc19d9b46ee094fcf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e746f6e4d752f547261696e596f75724f776e594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AntonMu/TrainYourOwnYOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Train a state-of-the-art yolov3 object detector from scratch!\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/madhawav/YOLO3-4-Py\"\u003emadhawav/YOLO3-4-Py\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ef379b0c142ca5c497c41c505d5265aa0d85e8a5afe186448c246a8fd86fba98/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d616468617761762f594f4c4f332d342d50793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ef379b0c142ca5c497c41c505d5265aa0d85e8a5afe186448c246a8fd86fba98/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d616468617761762f594f4c4f332d342d50793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/madhawav/YOLO3-4-Py?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Python wrapper on Darknet. Compatible with YOLO V3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/theAIGuysCode/yolov4-custom-functions\"\u003etheAIGuysCode/yolov4-custom-functions\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/af252087e8c8581a60b23bb9addec4a153e71b1802cba6327e9e063cd7571470/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746865414947757973436f64652f796f6c6f76342d637573746f6d2d66756e6374696f6e733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/af252087e8c8581a60b23bb9addec4a153e71b1802cba6327e9e063cd7571470/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746865414947757973436f64652f796f6c6f76342d637573746f6d2d66756e6374696f6e733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/theAIGuysCode/yolov4-custom-functions?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Wide Range of Custom Functions for YOLOv4, YOLOv4-tiny, YOLOv3, and YOLOv3-tiny Implemented in TensorFlow, TFLite, and TensorRT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tiquasar/FLAITER\"\u003etiquasar/FLAITER\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/47159639a6a6d90c3acf47e60e6cf7f588cc9a39ee94ab77265a4a963bddd168/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74697175617361722f464c41495445523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/47159639a6a6d90c3acf47e60e6cf7f588cc9a39ee94ab77265a4a963bddd168/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74697175617361722f464c41495445523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tiquasar/FLAITER?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Machine Learning and AI Mobile Application.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kadirnar/Minimal-Yolov6\"\u003ekadirnar/Minimal-Yolov6\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/dcdb67d8dd1902d19c002a6635d9b05067a7599a1333c2e394b3fc4426532018/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f4d696e696d616c2d596f6c6f76363f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dcdb67d8dd1902d19c002a6635d9b05067a7599a1333c2e394b3fc4426532018/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f4d696e696d616c2d596f6c6f76363f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kadirnar/Minimal-Yolov6?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Minimal-Yolov6.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DataXujing/YOLOv6\"\u003eDataXujing/YOLOv6\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1376f59ff435534195ed900b5b04c52e39aae9dc90c19527edbfff62f58728bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f76363f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1376f59ff435534195ed900b5b04c52e39aae9dc90c19527edbfff62f58728bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f76363f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DataXujing/YOLOv6?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸŒ€ ðŸŒ€ æ‰‹æ‘¸æ‰‹ ç¾Žå›¢ YOLOv6æ¨¡åž‹è®­ç»ƒå’ŒTensorRTç«¯åˆ°ç«¯éƒ¨ç½²æ–¹æ¡ˆæ•™ç¨‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DataXujing/YOLOv7\"\u003eDataXujing/YOLOv7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b9725daecb5df18b934fb9ad1b2a3a894a207a8f8c012d9d57379153e8380891/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f76373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b9725daecb5df18b934fb9ad1b2a3a894a207a8f8c012d9d57379153e8380891/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f76373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DataXujing/YOLOv7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ”¥ðŸ”¥ðŸ”¥ Official YOLOv7è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†å¹¶å®žçŽ°ç«¯åˆ°ç«¯çš„TensorRTæ¨¡åž‹åŠ é€ŸæŽ¨æ–­ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DataXujing/YOLOv8\"\u003eDataXujing/YOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2601cd11edfbaed709b30521504e1f6c803379dd865a3631add1939700498c61/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2601cd11edfbaed709b30521504e1f6c803379dd865a3631add1939700498c61/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DataXujing/YOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ”¥ Official YOLOv8æ¨¡åž‹è®­ç»ƒå’Œéƒ¨ç½²ã€‚Official YOLOv8 è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†å¹¶åŸºäºŽNVIDIA TensorRTå’ŒåŽä¸ºæ˜‡è…¾ç«¯åˆ°ç«¯æ¨¡åž‹åŠ é€Ÿä»¥åŠå®‰å“æ‰‹æœºç«¯éƒ¨ç½²ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DataXujing/YOLOv9\"\u003eDataXujing/YOLOv9\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/508c404273b82639991732f7c4ff22b86aaeeb3397511ca66f04046fa6964b02/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f76393f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/508c404273b82639991732f7c4ff22b86aaeeb3397511ca66f04046fa6964b02/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f76393f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DataXujing/YOLOv9?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ”¥ YOLOv9 paperè§£æžï¼Œè®­ç»ƒè‡ªå·±çš„æ•°æ®é›†ï¼ŒTensorRTç«¯åˆ°ç«¯éƒ¨ç½²ï¼Œ NCNNå®‰å“æ‰‹æœºéƒ¨ç½²ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Code-keys/yolov5-darknet\"\u003eCode-keys/yolov5-darknet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cb8788b0ed78e07e6b689eab96915e9432ecc8739b65603262fb9045dd5caef5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436f64652d6b6579732f796f6c6f76352d6461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cb8788b0ed78e07e6b689eab96915e9432ecc8739b65603262fb9045dd5caef5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436f64652d6b6579732f796f6c6f76352d6461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Code-keys/yolov5-darknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5-darknet support yaml \u0026amp;\u0026amp; cfg.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Code-keys/yolo-darknet\"\u003eCode-keys/yolo-darknet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a01fbb77a4a808004994d5e82ac9ff48efa7a863e5e02f7ee648fb32d8107417/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436f64652d6b6579732f796f6c6f2d6461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a01fbb77a4a808004994d5e82ac9ff48efa7a863e5e02f7ee648fb32d8107417/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436f64652d6b6579732f796f6c6f2d6461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Code-keys/yolo-darknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO-family complemented by darknet. yolov5 yolov7 et al ...\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pooya-mohammadi/deep_utils\"\u003epooya-mohammadi/deep_utils\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f9d3cd6b23b4bcb4bb1ddef2cdf1d9c7ebee3e1a4c44f986ce4a58e54bdfcd95/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706f6f79612d6d6f68616d6d6164692f646565705f7574696c733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f9d3cd6b23b4bcb4bb1ddef2cdf1d9c7ebee3e1a4c44f986ce4a58e54bdfcd95/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706f6f79612d6d6f68616d6d6164692f646565705f7574696c733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pooya-mohammadi/deep_utils?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A toolkit full of handy functions including most used models and utilities for deep-learning practitioners!\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yl-jiang/YOLOSeries\"\u003eyl-jiang/YOLOSeries\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ecf098b6a49aa5d70f1d3fc5fb373b0dce86a2b0e98f5395e434b6ec77b2bf77/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796c2d6a69616e672f594f4c4f5365726965733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ecf098b6a49aa5d70f1d3fc5fb373b0dce86a2b0e98f5395e434b6ec77b2bf77/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796c2d6a69616e672f594f4c4f5365726965733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yl-jiang/YOLOSeries?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO Series.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yjh0410/FreeYOLO\"\u003eyjh0410/FreeYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/51be201dd97beab31b18da6204d1dca9accf336303a0e2096df20e9429c783fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796a68303431302f46726565594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/51be201dd97beab31b18da6204d1dca9accf336303a0e2096df20e9429c783fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796a68303431302f46726565594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yjh0410/FreeYOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : FreeYOLO is inspired by many other excellent works, such as YOLOv7 and YOLOX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/open-yolo/yolov7\"\u003eopen-yolo/yolov7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8e35b28b1b315f65551a02a1722bf7c00f09f9914b9793c566012b8ce19b1ef2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d796f6c6f2f796f6c6f76373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8e35b28b1b315f65551a02a1722bf7c00f09f9914b9793c566012b8ce19b1ef2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d796f6c6f2f796f6c6f76373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/open-yolo/yolov7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Improved and packaged version of WongKinYiu/yolov7.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/iloveai8086/YOLOC\"\u003eiloveai8086/YOLOC\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e06425fc63e9f09d510caa0ed472ce839f9cb66c8f38c37a807a8f0c843e81db/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696c6f76656169383038362f594f4c4f433f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e06425fc63e9f09d510caa0ed472ce839f9cb66c8f38c37a807a8f0c843e81db/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696c6f76656169383038362f594f4c4f433f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/iloveai8086/YOLOC?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸš€YOLOC is Combining different modules to build an different Object detection model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/miemie2013/miemiedetection\"\u003emiemie2013/miemiedetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7ff578725d5f02d1a2b3b410c50652e95ddc9e7e209a5f702d82a657d8562400/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69656d6965323031332f6d69656d6965646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7ff578725d5f02d1a2b3b410c50652e95ddc9e7e209a5f702d82a657d8562400/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69656d6965323031332f6d69656d6965646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/miemie2013/miemiedetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Pytorch and ncnn implementation of PPYOLOEã€YOLOXã€PPYOLOã€PPYOLOv2ã€SOLOv2 an so on.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RyanCCC/YOLOSeries\"\u003eRyanCCC/YOLOSeries\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/310e35f7cda9fe1a2b2a4fcdd490f8731520dfeb712ba924d6c35ec4ea2cbc4b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5279616e4343432f594f4c4f5365726965733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/310e35f7cda9fe1a2b2a4fcdd490f8731520dfeb712ba924d6c35ec4ea2cbc4b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5279616e4343432f594f4c4f5365726965733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RyanCCC/YOLOSeries?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOç®—æ³•çš„å®žçŽ°ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HuKai97/YOLOX-Annotations\"\u003eHuKai97/YOLOX-Annotations\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d2cf808b3bd3d5fc6b02e3f20cdc40fca16dfdc91eb65643be34c24983de0332/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48754b616939372f594f4c4f582d416e6e6f746174696f6e733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d2cf808b3bd3d5fc6b02e3f20cdc40fca16dfdc91eb65643be34c24983de0332/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48754b616939372f594f4c4f582d416e6e6f746174696f6e733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HuKai97/YOLOX-Annotations?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä¸€ä¸ªYOLOXçš„ä¸­æ–‡æ³¨é‡Šç‰ˆæœ¬ï¼Œä¾›å¤§å®¶å‚è€ƒå­¦ä¹ ï¼\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/isLinXu/YOLOv8_Efficient\"\u003eisLinXu/YOLOv8_Efficient\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9213d69cc8f4aa8f64471b43e3ba0230c07bddf2b00c4d5b73e5046965b73981/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69734c696e58752f594f4c4f76385f456666696369656e743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9213d69cc8f4aa8f64471b43e3ba0230c07bddf2b00c4d5b73e5046965b73981/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69734c696e58752f594f4c4f76385f456666696369656e743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/isLinXu/YOLOv8_Efficient?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸš€Simple and efficient use for Ultralytics yolov8ðŸš€\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/z1069614715/objectdetection_script\"\u003ez1069614715/objectdetection_script\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ddeda98af5ea8d744a454e2b494551e3a2b7b4c8755be3e638fc036add0e4cff/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a313036393631343731352f6f626a656374646574656374696f6e5f7363726970743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ddeda98af5ea8d744a454e2b494551e3a2b7b4c8755be3e638fc036add0e4cff/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a313036393631343731352f6f626a656374646574656374696f6e5f7363726970743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/z1069614715/objectdetection_script?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä¸€äº›å…³äºŽç›®æ ‡æ£€æµ‹çš„è„šæœ¬çš„æ”¹è¿›æ€è·¯ä»£ç ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eLighter and Deployment Frameworks\u003c/h2\u003e\u003ca id=\"user-content-lighter-and-deployment-frameworks\" class=\"anchor\" aria-label=\"Permalink: Lighter and Deployment Frameworks\" href=\"#lighter-and-deployment-frameworks\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eHigh-performance Inference Engine\u003c/h3\u003e\u003ca id=\"user-content-high-performance-inference-engine\" class=\"anchor\" aria-label=\"Permalink: High-performance Inference Engine\" href=\"#high-performance-inference-engine\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eé«˜æ€§èƒ½æŽ¨ç†å¼•æ“Ž\u003c/h4\u003e\u003ca id=\"user-content-é«˜æ€§èƒ½æŽ¨ç†å¼•æ“Ž\" class=\"anchor\" aria-label=\"Permalink: é«˜æ€§èƒ½æŽ¨ç†å¼•æ“Ž\" href=\"#é«˜æ€§èƒ½æŽ¨ç†å¼•æ“Ž\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eONNX\u003c/h5\u003e\u003ca id=\"user-content-onnx\" class=\"anchor\" aria-label=\"Permalink: ONNX\" href=\"#onnx\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/microsoft/onnxruntime\"\u003eONNX Runtime\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a2f598ebbcb9fce782597f473cff1718e1677ccd89cf37f150bd088d4937e887/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6963726f736f66742f6f6e6e7872756e74696d653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a2f598ebbcb9fce782597f473cff1718e1677ccd89cf37f150bd088d4937e887/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6963726f736f66742f6f6e6e7872756e74696d653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/microsoft/onnxruntime?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ONNX Runtime: cross-platform, high performance ML inferencing and training accelerator. \u003ca href=\"https://onnxruntime.ai/\" rel=\"nofollow\"\u003eonnxruntime.ai\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/onnx/onnx\"\u003eONNX\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/eadfb34447ae8a8b2bd008ba0c388c4d8cb3e0640c9278cccb2c227b9aaf73ab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6e6e782f6f6e6e783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/eadfb34447ae8a8b2bd008ba0c388c4d8cb3e0640c9278cccb2c227b9aaf73ab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6e6e782f6f6e6e783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/onnx/onnx?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Open Neural Network Exchange. Open standard for machine learning interoperability. \u003ca href=\"https://onnx.ai/\" rel=\"nofollow\"\u003eonnx.ai\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/onnx/onnxmltools\"\u003eONNXMLTools\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d4f6f208dc051ab689b7773f3faf9008607850cff9ad7796428c139075e7ecbd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6e6e782f6f6e6e786d6c746f6f6c733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d4f6f208dc051ab689b7773f3faf9008607850cff9ad7796428c139075e7ecbd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6e6e782f6f6e6e786d6c746f6f6c733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/onnx/onnxmltools?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ONNXMLTools enables you to convert models from different machine learning toolkits into \u003ca href=\"https://github.com/onnx/onnx\"\u003eONNX\u003c/a\u003e. \u003ca href=\"https://onnx.ai/\" rel=\"nofollow\"\u003eonnx.ai\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xboot/libonnx\"\u003exboot/libonnx\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8bfb4abace40e7107043e6d495a5c1ce18662920a353e5e2834a0f382118b9ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78626f6f742f6c69626f6e6e783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8bfb4abace40e7107043e6d495a5c1ce18662920a353e5e2834a0f382118b9ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78626f6f742f6c69626f6e6e783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xboot/libonnx?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A lightweight, portable pure C99 onnx inference engine for embedded devices with hardware acceleration support.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kraiskil/onnx2c\"\u003ekraiskil/onnx2c\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/12be4f92e4ebe218a2b01a488ea2b6d2497b2b66e98cd94504b9be97b6c0d4dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b726169736b696c2f6f6e6e7832633f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/12be4f92e4ebe218a2b01a488ea2b6d2497b2b66e98cd94504b9be97b6c0d4dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b726169736b696c2f6f6e6e7832633f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kraiskil/onnx2c?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Open Neural Network Exchange to C compiler. Onnx2c is a \u003ca href=\"https://onnx.ai/\" rel=\"nofollow\"\u003eONNX\u003c/a\u003e to C compiler. It will read an ONNX file, and generate C code to be included in your project. Onnx2c's target is \"Tiny ML\", meaning running the inference on microcontrollers.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sonos/tract\"\u003etract\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b529827f8fb7574e9d382e6d0c524f2f8ca19fd6e547387280d8a682c7ff6919/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736f6e6f732f74726163743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b529827f8fb7574e9d382e6d0c524f2f8ca19fd6e547387280d8a682c7ff6919/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736f6e6f732f74726163743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sonos/tract?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Sonos' Neural Network inference engine. Tiny, no-nonsense, self-contained, Tensorflow and ONNX inference\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pykeio/ort\"\u003eort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/45aa58d12c13b364706b818b5b1d2ea3e8dc88e081669aab1709ac161da8fc46/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70796b65696f2f6f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/45aa58d12c13b364706b818b5b1d2ea3e8dc88e081669aab1709ac161da8fc46/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70796b65696f2f6f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pykeio/ort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Rust wrapper for ONNX Runtime. \u003ca href=\"https://docs.rs/ort/latest/ort/\" rel=\"nofollow\"\u003edocs.rs/ort\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nbigaouette/onnxruntime-rs\"\u003eonnxruntime-rs\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/37355e862d6aaf161a8880fb22a16a1932f116b66206a2b6c85a889030d6d0eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e626967616f75657474652f6f6e6e7872756e74696d652d72733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/37355e862d6aaf161a8880fb22a16a1932f116b66206a2b6c85a889030d6d0eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e626967616f75657474652f6f6e6e7872756e74696d652d72733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nbigaouette/onnxruntime-rs?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is an attempt at a Rust wrapper for \u003ca href=\"https://github.com/microsoft/onnxruntime\"\u003eMicrosoft's ONNX Runtime\u003c/a\u003e (version 1.8).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/webonnx/wonnx\"\u003eWonnx\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2f6e0f93d6b26e6ed79ab8aa8c1411b5c5822bd2d0bd24ef87543727b18fef34/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7765626f6e6e782f776f6e6e783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2f6e0f93d6b26e6ed79ab8aa8c1411b5c5822bd2d0bd24ef87543727b18fef34/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7765626f6e6e782f776f6e6e783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/webonnx/wonnx?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Wonnx is a GPU-accelerated ONNX inference run-time written 100% in Rust, ready for the web.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/maekawatoshiki/altius\"\u003ealtius\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f263afc1427585c0872223370743d58f3623d72ac3d46af4bead36da02cdf35f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61656b617761746f7368696b692f616c746975733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f263afc1427585c0872223370743d58f3623d72ac3d46af4bead36da02cdf35f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61656b617761746f7368696b692f616c746975733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/maekawatoshiki/altius?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Small ONNX inference runtime written in Rust.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Hyuto/yolo-nas-onnx\"\u003eHyuto/yolo-nas-onnx\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bd13e254814719dac044388f2cb9c905c1dd4140a0841bfc5a7f9f37afc5af95/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f487975746f2f796f6c6f2d6e61732d6f6e6e783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bd13e254814719dac044388f2cb9c905c1dd4140a0841bfc5a7f9f37afc5af95/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f487975746f2f796f6c6f2d6e61732d6f6e6e783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Hyuto/yolo-nas-onnx?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Inference YOLO-NAS ONNX model. \u003ca href=\"https://hyuto.github.io/yolo-nas-onnx/\" rel=\"nofollow\"\u003ehyuto.github.io/yolo-nas-onnx/\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DanielSarmiento04/yolov10cpp\"\u003eDanielSarmiento04/yolov10cpp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8479531a9c7c4aa842eb2b358a71d8d76ad9f610d010c08ef408dfcdd9cec199/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44616e69656c5361726d69656e746f30342f796f6c6f7631306370703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8479531a9c7c4aa842eb2b358a71d8d76ad9f610d010c08ef408dfcdd9cec199/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44616e69656c5361726d69656e746f30342f796f6c6f7631306370703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DanielSarmiento04/yolov10cpp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Implementation of yolo v10 in c++ std 17 over opencv and onnxruntime.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eTensorRT\u003c/h5\u003e\u003ca id=\"user-content-tensorrt\" class=\"anchor\" aria-label=\"Permalink: TensorRT\" href=\"#tensorrt\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NVIDIA/TensorRT\"\u003eTensorRT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0375d1cf222c092085220f7c6c3c9969ea4549482355526cf93ed5d689fcd87b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412f54656e736f7252543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0375d1cf222c092085220f7c6c3c9969ea4549482355526cf93ed5d689fcd87b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412f54656e736f7252543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NVIDIA/TensorRT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : NVIDIAÂ® TensorRTâ„¢ is an SDK for high-performance deep learning inference on NVIDIA GPUs. This repository contains the open source components of TensorRT. \u003ca href=\"https://developer.nvidia.com/tensorrt\" rel=\"nofollow\"\u003edeveloper.nvidia.com/tensorrt\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NVIDIA/TensorRT-LLM\"\u003eTensorRT-LLM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ee764b9764a279377a54f33585cd0e13cea0c7ee0a421e1db79bcb756df74c8f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412f54656e736f7252542d4c4c4d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ee764b9764a279377a54f33585cd0e13cea0c7ee0a421e1db79bcb756df74c8f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412f54656e736f7252542d4c4c4d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NVIDIA/TensorRT-LLM?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs. TensorRT-LLM also contains components to create Python and C++ runtimes that execute those TensorRT engines. \u003ca href=\"https://nvidia.github.io/TensorRT-LLM\" rel=\"nofollow\"\u003envidia.github.io/TensorRT-LLM\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NVIDIA/TensorRT-Model-Optimizer\"\u003eNVIDIA/TensorRT-Model-Optimizer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e4de7bc60820e749a190eb0570051780232075a76de93cce711a7aa23b181e01/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412f54656e736f7252542d4d6f64656c2d4f7074696d697a65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e4de7bc60820e749a190eb0570051780232075a76de93cce711a7aa23b181e01/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412f54656e736f7252542d4d6f64656c2d4f7074696d697a65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NVIDIA/TensorRT-Model-Optimizer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRT Model Optimizer is a unified library of state-of-the-art model optimization techniques such as quantization, pruning, distillation, etc. It compresses deep learning models for downstream deployment frameworks like TensorRT-LLM or TensorRT to optimize inference speed on NVIDIA GPUs. \u003ca href=\"https://nvidia.github.io/TensorRT-Model-Optimizer/\" rel=\"nofollow\"\u003envidia.github.io/TensorRT-Model-Optimizer\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kalfazed/tensorrt_starter\"\u003ekalfazed/tensorrt_starter\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c2e0bc22fd3c9803c385c16a5a9402233aa321ab5b0078a033eba7035c8badda/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616c66617a65642f74656e736f7272745f737461727465723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c2e0bc22fd3c9803c385c16a5a9402233aa321ab5b0078a033eba7035c8badda/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616c66617a65642f74656e736f7272745f737461727465723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kalfazed/tensorrt_starter?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository give a guidline to learn CUDA and TensorRT from the beginning.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wang-xinyu/tensorrtx\"\u003ewang-xinyu/tensorrtx\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8c496330b4704f24e8aa74a7a72a4293a4529c96c1c46e0b67876b1059fba55b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e672d78696e79752f74656e736f727274783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8c496330b4704f24e8aa74a7a72a4293a4529c96c1c46e0b67876b1059fba55b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e672d78696e79752f74656e736f727274783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wang-xinyu/tensorrtx?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRTx aims to implement popular deep learning networks with tensorrt network definition APIs.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/laugh12321/TensorRT-YOLO\"\u003elaugh12321/TensorRT-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5b30d047ada124253400bc8a6d24644473d84536d0294cb5af05b35e25e2cac1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6175676831323332312f54656e736f7252542d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5b30d047ada124253400bc8a6d24644473d84536d0294cb5af05b35e25e2cac1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6175676831323332312f54656e736f7252542d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/laugh12321/TensorRT-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸš€ Easier \u0026amp; Faster YOLO Deployment Toolkit for NVIDIA ðŸ› ï¸. ðŸš€ TensorRT-YOLO is an easy-to-use, extremely efficient inference deployment tool for the YOLO series designed specifically for NVIDIA devices. The project not only integrates TensorRT plugins to enhance post-processing but also utilizes CUDA kernels and CUDA graphs to accelerate inference. ðŸš€ TensorRT-YOLO æ˜¯ä¸€æ¬¾ä¸“ä¸º NVIDIA è®¾å¤‡è®¾è®¡çš„æ˜“ç”¨çµæ´»ã€æžè‡´é«˜æ•ˆçš„YOLOç³»åˆ—æŽ¨ç†éƒ¨ç½²å·¥å…·ã€‚é¡¹ç›®ä¸ä»…é›†æˆäº† TensorRT æ’ä»¶ä»¥å¢žå¼ºåŽå¤„ç†æ•ˆæžœï¼Œè¿˜ä½¿ç”¨äº† CUDA æ ¸å‡½æ•°ä»¥åŠ CUDA å›¾æ¥åŠ é€ŸæŽ¨ç†ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/olibartfast/object-detection-inference\"\u003eolibartfast/object-detection-inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4fa000d3b07903db52223b4a193230ff7441c5cf6ae27e86615a8463a553fde3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6c6962617274666173742f6f626a6563742d646574656374696f6e2d696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4fa000d3b07903db52223b4a193230ff7441c5cf6ae27e86615a8463a553fde3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6c6962617274666173742f6f626a6563742d646574656374696f6e2d696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/olibartfast/object-detection-inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : C++ object detection inference from video or image input source. Inference for object detection from a video or image input source, with support for multiple switchable frameworks to manage the inference process, and optional GStreamer integration for video capture.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/shouxieai/tensorRT_Pro\"\u003eshouxieai/tensorRT_Pro\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ca59a545d98996ab947a2c9aeafe9fc1beff6df602a0b929d45749187424e86b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73686f7578696561692f74656e736f7252545f50726f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ca59a545d98996ab947a2c9aeafe9fc1beff6df602a0b929d45749187424e86b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73686f7578696561692f74656e736f7252545f50726f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/shouxieai/tensorRT_Pro?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : C++ library based on tensorrt integration.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/shouxieai/infer\"\u003eshouxieai/infer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/13239cfe07e93039bdb929406298d13159398027283ed7bc325d6a488164238a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73686f7578696561692f696e6665723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/13239cfe07e93039bdb929406298d13159398027283ed7bc325d6a488164238a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73686f7578696561692f696e6665723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/shouxieai/infer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A new tensorrt integrate. Easy to integrate many tasks.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Melody-Zhou/tensorRT_Pro-YOLOv8\"\u003eMelody-Zhou/tensorRT_Pro-YOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e290917e1beecc650ba393365a9af6d843069926f5d206a2bd05b541b6509d5d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d656c6f64792d5a686f752f74656e736f7252545f50726f2d594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e290917e1beecc650ba393365a9af6d843069926f5d206a2bd05b541b6509d5d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d656c6f64792d5a686f752f74656e736f7252545f50726f2d594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Melody-Zhou/tensorRT_Pro-YOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository is based on \u003ca href=\"https://github.com/shouxieai/tensorRT_Pro\"\u003eshouxieai/tensorRT_Pro\u003c/a\u003e, with adjustments to support YOLOv8. å‰å·²æ”¯æŒ YOLOv8ã€YOLOv8-Clsã€YOLOv8-Segã€YOLOv8-OBBã€YOLOv8-Poseã€RT-DETRã€ByteTrackã€YOLOv9ã€YOLOv10ã€RTMOã€PP-OCRv4ã€LaneATT é«˜æ€§èƒ½æŽ¨ç†ï¼ï¼ï¼ðŸš€ðŸš€ðŸš€\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FeiYull/TensorRT-Alpha\"\u003eFeiYull/TensorRT-Alpha\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/906e2316bb7843807dfb69787764cc1bf56a4fed36dd3e228c3576bb5ed203f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f746f726368327472743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/906e2316bb7843807dfb69787764cc1bf56a4fed36dd3e228c3576bb5ed203f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f746f726368327472743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NVIDIA-AI-IOT/torch2trt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ”¥ðŸ”¥ðŸ”¥TensorRT for YOLOv8ã€YOLOv8-Poseã€YOLOv8-Segã€YOLOv8-Clsã€YOLOv7ã€YOLOv6ã€YOLOv5ã€YOLONAS......ðŸš€ðŸš€ðŸš€CUDA IS ALL YOU NEED.ðŸŽðŸŽðŸŽ\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zhiqwang/yolort\"\u003ezhiqwang/yolort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/77f3143b81f59c13a081e5b6974e990b16d67cce05675983e4a41ebf8a60d8a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68697177616e672f796f6c6f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/77f3143b81f59c13a081e5b6974e990b16d67cce05675983e4a41ebf8a60d8a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68697177616e672f796f6c6f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zhiqwang/yolort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolort is a runtime stack for yolov5 on specialized accelerators such as tensorrt, libtorch, onnxruntime, tvm and ncnn. \u003ca href=\"https://zhiqwang.com/yolort/\" rel=\"nofollow\"\u003ezhiqwang.com/yolort\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/1461521844lijin/trt_yolo_video_pipeline\"\u003e1461521844lijin/trt_yolo_video_pipeline\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b7dc39a0d64dcdee2a495ef963801041779f33282c35a442ca7b5a2deb000a58/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f313436313532313834346c696a696e2f7472745f796f6c6f5f766964656f5f706970656c696e653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b7dc39a0d64dcdee2a495ef963801041779f33282c35a442ca7b5a2deb000a58/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f313436313532313834346c696a696e2f7472745f796f6c6f5f766964656f5f706970656c696e653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/1461521844lijin/trt_yolo_video_pipeline?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRT+YOLOç³»åˆ—çš„ å¤šè·¯ å¤šå¡ å¤šå®žä¾‹ å¹¶è¡Œè§†é¢‘åˆ†æžå¤„ç†æ¡ˆä¾‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/l-sf/Linfer\"\u003el-sf/Linfer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ab04faa5de0bd75fe6d962274280b9e1cb59a48859c55b328aeac03829d0ebf9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c2d73662f4c696e6665723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ab04faa5de0bd75fe6d962274280b9e1cb59a48859c55b328aeac03829d0ebf9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c2d73662f4c696e6665723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/l-sf/Linfer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽTensorRTçš„C++é«˜æ€§èƒ½æŽ¨ç†åº“ï¼ŒYolov10, YoloPv2ï¼ŒYolov5/7/X/8ï¼ŒRT-DETRï¼Œå•ç›®æ ‡è·Ÿè¸ªOSTrackã€LightTrackã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/taifyang/yolo-inference\"\u003etaifyang/yolo-inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fd63c5266ceeacc79ecc3c904d7206f1cf2ed6ceac60086f4065d9381a3bc967/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7461696679616e672f796f6c6f2d696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fd63c5266ceeacc79ecc3c904d7206f1cf2ed6ceac60086f4065d9381a3bc967/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7461696679616e672f796f6c6f2d696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/taifyang/yolo-inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : C++ and Python implementations of YOLOv5, YOLOv6, YOLOv7, YOLOv8, YOLOv9, YOLOv10, YOLOv11 inference.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/triple-Mu/YOLOv8-TensorRT\"\u003etriple-Mu/YOLOv8-TensorRT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c2aa79ac3d7f461d748dd43ba96d31757f8eb7322d3deac7546d001ed23248d8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f747269706c652d4d752f594f4c4f76382d54656e736f7252543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c2aa79ac3d7f461d748dd43ba96d31757f8eb7322d3deac7546d001ed23248d8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f747269706c652d4d752f594f4c4f76382d54656e736f7252543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/triple-Mu/YOLOv8-TensorRT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv8 using TensorRT accelerate !\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/emptysoal/TensorRT-YOLOv8-ByteTrack\"\u003eemptysoal/TensorRT-YOLOv8-ByteTrack\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3de99ef022efea487cb0a9295a6ea4c5b29438eb8209f9a501d4b1db5429a656/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656d707479736f616c2f54656e736f7252542d594f4c4f76382d42797465547261636b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3de99ef022efea487cb0a9295a6ea4c5b29438eb8209f9a501d4b1db5429a656/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656d707479736f616c2f54656e736f7252542d594f4c4f76382d42797465547261636b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/emptysoal/TensorRT-YOLOv8-ByteTrack?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An object tracking project with YOLOv8 and ByteTrack, speed up by C++ and TensorRT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Linaom1214/TensorRT-For-YOLO-Series\"\u003eLinaom1214/TensorRT-For-YOLO-Series\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/504699f5f0f48bdcce503d21c6cb588227768f95a2abc8cf450c04b49a1b6265/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696e616f6d313231342f54656e736f7252542d466f722d594f4c4f2d5365726965733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/504699f5f0f48bdcce503d21c6cb588227768f95a2abc8cf450c04b49a1b6265/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696e616f6d313231342f54656e736f7252542d466f722d594f4c4f2d5365726965733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Linaom1214/TensorRT-For-YOLO-Series?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : tensorrt for yolo series (YOLOv10,YOLOv9,YOLOv8,YOLOv7,YOLOv6,YOLOX,YOLOv5), nms plugin support.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/spacewalk01/yolov11-tensorrt\"\u003espacewalk01/yolov11-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5007e0fedd6e021dd75fd274c2617c83051abcfcebc17d66ea5dde0335aeda5f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737061636577616c6b30312f796f6c6f7631312d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5007e0fedd6e021dd75fd274c2617c83051abcfcebc17d66ea5dde0335aeda5f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737061636577616c6b30312f796f6c6f7631312d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/spacewalk01/yolov11-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : C++ implementation of YOLOv11 using TensorRT API.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cyrusbehr/YOLOv8-TensorRT-CPP\"\u003ecyrusbehr/YOLOv8-TensorRT-CPP\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/40c832f1bcbe15f0b32e335aed3a2130641f42b1e8950521eacd0d9346dba660/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6379727573626568722f594f4c4f76382d54656e736f7252542d4350503f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/40c832f1bcbe15f0b32e335aed3a2130641f42b1e8950521eacd0d9346dba660/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6379727573626568722f594f4c4f76382d54656e736f7252542d4350503f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cyrusbehr/YOLOv8-TensorRT-CPP?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv8 TensorRT C++ Implementation. A C++ Implementation of YoloV8 using TensorRT Supports object detection, semantic segmentation, and body pose estimation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/emptysoal/TensorRT-YOLOv8\"\u003eemptysoal/TensorRT-YOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3ba343e54dc8fc076f7292598112a38bca94838864dff48fbb5513c970263387/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656d707479736f616c2f54656e736f7252542d594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3ba343e54dc8fc076f7292598112a38bca94838864dff48fbb5513c970263387/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656d707479736f616c2f54656e736f7252542d594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/emptysoal/TensorRT-YOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Based on tensorrt v8.0+, deploy detect, pose, segment, tracking of YOLOv8 with C++ and python api.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hamdiboukamcha/yolov10-tensorrt\"\u003ehamdiboukamcha/yolov10-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/867fc18b51a4b44d2b519dc175c2393d99f3190193d947efa9f3df5d383ab81f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68616d6469626f756b616d6368612f796f6c6f7631302d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/867fc18b51a4b44d2b519dc175c2393d99f3190193d947efa9f3df5d383ab81f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68616d6469626f756b616d6368612f796f6c6f7631302d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hamdiboukamcha/yolov10-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv10 C++ TensorRT : Real-Time End-to-End Object Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NVIDIA-AI-IOT/torch2trt\"\u003eVIDIA-AI-IOT/torch2trt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/906e2316bb7843807dfb69787764cc1bf56a4fed36dd3e228c3576bb5ed203f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f746f726368327472743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/906e2316bb7843807dfb69787764cc1bf56a4fed36dd3e228c3576bb5ed203f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f746f726368327472743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NVIDIA-AI-IOT/torch2trt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An easy to use PyTorch to TensorRT converter.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DefTruth/lite.ai.toolkit\"\u003eDefTruth/lite.ai.toolkit\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4872d3a5f1c9cbb9000aee906bd1f2488666f1bea1bc63be201c5807f369cdf3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44656654727574682f6c6974652e61692e746f6f6c6b69743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4872d3a5f1c9cbb9000aee906bd1f2488666f1bea1bc63be201c5807f369cdf3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44656654727574682f6c6974652e61692e746f6f6c6b69743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DefTruth/lite.ai.toolkit?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ›  A lite C++ toolkit of awesome AI models with ONNXRuntime, NCNN, MNN and TNN. YOLOX, YOLOP, YOLOv6, YOLOR, MODNet, YOLOX, YOLOv7, YOLOv5. MNN, NCNN, TNN, ONNXRuntime. â€œðŸ› Lite.Ai.ToolKit: ä¸€ä¸ªè½»é‡çº§çš„C++ AIæ¨¡åž‹å·¥å…·ç®±ï¼Œç”¨æˆ·å‹å¥½ï¼ˆè¿˜è¡Œå§ï¼‰ï¼Œå¼€ç®±å³ç”¨ã€‚å·²ç»åŒ…æ‹¬ 100+ æµè¡Œçš„å¼€æºæ¨¡åž‹ã€‚è¿™æ˜¯ä¸€ä¸ªæ ¹æ®ä¸ªäººå…´è¶£æ•´ç†çš„C++å·¥å…·ç®±ï¼Œ, æ¶µç›–ç›®æ ‡æ£€æµ‹ã€äººè„¸æ£€æµ‹ã€äººè„¸è¯†åˆ«ã€è¯­ä¹‰åˆ†å‰²ã€æŠ å›¾ç­‰é¢†åŸŸã€‚â€\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PaddlePaddle/FastDeploy\"\u003ePaddlePaddle/FastDeploy\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/034bb02e20083b6a0f4779a11bca9b666d41aa6e87b3ba24d3cbc1aef1c18cac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506164646c65506164646c652f466173744465706c6f793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/034bb02e20083b6a0f4779a11bca9b666d41aa6e87b3ba24d3cbc1aef1c18cac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506164646c65506164646c652f466173744465706c6f793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PaddlePaddle/FastDeploy?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : âš¡ï¸An Easy-to-use and Fast Deep Learning Model Deployment Toolkit for â˜ï¸Cloud ðŸ“±Mobile and ðŸ“¹Edge. Including Image, Video, Text and Audio 20+ main stream scenarios and 150+ SOTA models with end-to-end optimization, multi-platform and multi-framework support.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/enazoe/yolo-tensorrt\"\u003eenazoe/yolo-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9b137a9061b7007e457b3c20b26c68c517854225035cfcbd7932267d060d5fed/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656e617a6f652f796f6c6f2d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9b137a9061b7007e457b3c20b26c68c517854225035cfcbd7932267d060d5fed/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656e617a6f652f796f6c6f2d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/enazoe/yolo-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRT8.Support Yolov5n,s,m,l,x .darknet -\u0026gt; tensorrt. Yolov4 Yolov3 use raw darknet *.weights and *.cfg fils. If the wrapper is useful to you,please Star it.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/guojianyang/cv-detect-robot\"\u003eguojianyang/cv-detect-robot\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/44e9eb4379b88f43464390c78025883ff45ade2416aa369ab10600ae45e61162/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67756f6a69616e79616e672f63762d6465746563742d726f626f743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/44e9eb4379b88f43464390c78025883ff45ade2416aa369ab10600ae45e61162/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67756f6a69616e79616e672f63762d6465746563742d726f626f743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/guojianyang/cv-detect-robot?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥Docker NVIDIA Docker2 YOLOV5 YOLOX YOLO Deepsort TensorRT ROS Deepstream Jetson Nano TX2 NX for High-performance deployment(é«˜æ€§èƒ½éƒ¨ç½²)ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BlueMirrors/Yolov5-TensorRT\"\u003eBlueMirrors/Yolov5-TensorRT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8e3eb2c51ead40bdeaceed64150e1c6c7bc061b08217044f58f52027807a3fda/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426c75654d6972726f72732f596f6c6f76352d54656e736f7252543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8e3eb2c51ead40bdeaceed64150e1c6c7bc061b08217044f58f52027807a3fda/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426c75654d6972726f72732f596f6c6f76352d54656e736f7252543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BlueMirrors/Yolov5-TensorRT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov5 TensorRT Implementations.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lewes6369/TensorRT-Yolov3\"\u003elewes6369/TensorRT-Yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/41e16240d345aeacd2f7bdd1d714c3e771ec6b87bc7cac82800fab06bcca0574/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c65776573363336392f54656e736f7252542d596f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/41e16240d345aeacd2f7bdd1d714c3e771ec6b87bc7cac82800fab06bcca0574/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c65776573363336392f54656e736f7252542d596f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lewes6369/TensorRT-Yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRT for Yolov3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CaoWGG/TensorRT-YOLOv4\"\u003eCaoWGG/TensorRT-YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8a744e928dd0b1349807d2b2708b889d7e9490c30242cfacc566f712e427043e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43616f5747472f54656e736f7252542d594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8a744e928dd0b1349807d2b2708b889d7e9490c30242cfacc566f712e427043e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43616f5747472f54656e736f7252542d594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CaoWGG/TensorRT-YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e :tensorrt5, yolov4, yolov3,yolov3-tniy,yolov3-tniy-prn.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/isarsoft/yolov4-triton-tensorrt\"\u003eisarsoft/yolov4-triton-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9cb8a8e8da43900a28c26172087a6470cad4fa8c07619a5ddb5b06d22824f79e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736172736f66742f796f6c6f76342d747269746f6e2d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9cb8a8e8da43900a28c26172087a6470cad4fa8c07619a5ddb5b06d22824f79e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736172736f66742f796f6c6f76342d747269746f6e2d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/isarsoft/yolov4-triton-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv4 on Triton Inference Server with TensorRT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TrojanXu/yolov5-tensorrt\"\u003eTrojanXu/yolov5-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/085879deb0d9dd5659f2aaae5c5000f78e056138125d6f90d391e23dc77b47ef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54726f6a616e58752f796f6c6f76352d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/085879deb0d9dd5659f2aaae5c5000f78e056138125d6f90d391e23dc77b47ef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54726f6a616e58752f796f6c6f76352d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TrojanXu/yolov5-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A tensorrt implementation of yolov5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tjuskyzhang/Scaled-YOLOv4-TensorRT\"\u003etjuskyzhang/Scaled-YOLOv4-TensorRT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f7f8d4bdaa4065f11591039fa72f54e662d7b29908146e58d7de17745977e17e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746a75736b797a68616e672f5363616c65642d594f4c4f76342d54656e736f7252543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f7f8d4bdaa4065f11591039fa72f54e662d7b29908146e58d7de17745977e17e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746a75736b797a68616e672f5363616c65642d594f4c4f76342d54656e736f7252543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tjuskyzhang/Scaled-YOLOv4-TensorRT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Implement yolov4-tiny-tensorrt, yolov4-csp-tensorrt, yolov4-large-tensorrt(p5, p6, p7) layer by layer using TensorRT API.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Syencil/tensorRT\"\u003eSyencil/tensorRT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e9731538c347e03f7b16e1ae7039a1aa8ae3aee8dd0ce708842a65f0ce41d276/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5379656e63696c2f74656e736f7252543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e9731538c347e03f7b16e1ae7039a1aa8ae3aee8dd0ce708842a65f0ce41d276/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5379656e63696c2f74656e736f7252543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Syencil/tensorRT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRT-7 Network Lib åŒ…æ‹¬å¸¸ç”¨ç›®æ ‡æ£€æµ‹ã€å…³é”®ç‚¹æ£€æµ‹ã€äººè„¸æ£€æµ‹ã€OCRç­‰ å¯è®­ç»ƒè‡ªå·±æ•°æ®ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SeanAvery/yolov5-tensorrt\"\u003eSeanAvery/yolov5-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3325f6f83e8e5bde02d42260d7e359e39047f1a0132a767c65836718aad698a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5365616e41766572792f796f6c6f76352d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3325f6f83e8e5bde02d42260d7e359e39047f1a0132a767c65836718aad698a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5365616e41766572792f796f6c6f76352d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SeanAvery/yolov5-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 in TensorRT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Monday-Leo/YOLOv7_Tensorrt\"\u003eMonday-Leo/YOLOv7_Tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e2609229a68b3694b738d682f6bc90574e085a783036980caa110ff7439fb557/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f6e6461792d4c656f2f594f4c4f76375f54656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e2609229a68b3694b738d682f6bc90574e085a783036980caa110ff7439fb557/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f6e6461792d4c656f2f594f4c4f76375f54656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Monday-Leo/YOLOv7_Tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A simple implementation of Tensorrt YOLOv7.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ibaiGorordo/ONNX-YOLOv6-Object-Detection\"\u003eibaiGorordo/ONNX-YOLOv6-Object-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a4058e765b7ec6dbaf214664230c38b44b76e640d6a784fbe14e02e17f6ec13b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69626169476f726f72646f2f4f4e4e582d594f4c4f76362d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a4058e765b7ec6dbaf214664230c38b44b76e640d6a784fbe14e02e17f6ec13b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69626169476f726f72646f2f4f4e4e582d594f4c4f76362d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ibaiGorordo/ONNX-YOLOv6-Object-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Python scripts performing object detection using the YOLOv6 model in ONNX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ibaiGorordo/ONNX-YOLOv7-Object-Detection\"\u003eibaiGorordo/ONNX-YOLOv7-Object-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9e0df6d0b164197cd27cabb2ccb7a85e8a0ee144c2bbbe2e566dffd429c9cc90/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69626169476f726f72646f2f4f4e4e582d594f4c4f76372d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9e0df6d0b164197cd27cabb2ccb7a85e8a0ee144c2bbbe2e566dffd429c9cc90/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69626169476f726f72646f2f4f4e4e582d594f4c4f76372d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ibaiGorordo/ONNX-YOLOv7-Object-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Python scripts performing object detection using the YOLOv7 model in ONNX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/triple-Mu/yolov7\"\u003etriple-Mu/yolov7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/41d5206d8d0d21ff41530e72cf55fe7e0b3eacff6362777776a319781cf1de6d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f747269706c652d4d752f796f6c6f76373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/41d5206d8d0d21ff41530e72cf55fe7e0b3eacff6362777776a319781cf1de6d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f747269706c652d4d752f796f6c6f76373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/triple-Mu/yolov7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : End2end TensorRT YOLOv7.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hewen0901/yolov7_trt\"\u003ehewen0901/yolov7_trt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6b5c5e62a81acae515fee0fc0f208912d06fe1a00b5a0042e8ff6c0ccd3e6908/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686577656e303930312f796f6c6f76375f7472743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6b5c5e62a81acae515fee0fc0f208912d06fe1a00b5a0042e8ff6c0ccd3e6908/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686577656e303930312f796f6c6f76375f7472743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hewen0901/yolov7_trt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov7ç›®æ ‡æ£€æµ‹ç®—æ³•çš„c++ tensorrtéƒ¨ç½²ä»£ç ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tsutof/tiny_yolov2_onnx_cam\"\u003etsutof/tiny_yolov2_onnx_cam\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0b000dead55d0c856760d0c5411955768bb7ecceda08e8e1d9e8f21a5cce4b3f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f747375746f662f74696e795f796f6c6f76325f6f6e6e785f63616d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0b000dead55d0c856760d0c5411955768bb7ecceda08e8e1d9e8f21a5cce4b3f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f747375746f662f74696e795f796f6c6f76325f6f6e6e785f63616d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tsutof/tiny_yolov2_onnx_cam?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tiny YOLO v2 Inference Application with NVIDIA TensorRT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Monday-Leo/Yolov5_Tensorrt_Win10\"\u003eMonday-Leo/Yolov5_Tensorrt_Win10\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f7e8570cbb8f3a2e06ea1f2faf91e6b4fb7eb3aa1297ae5cf5f0df573da88a38/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f6e6461792d4c656f2f596f6c6f76355f54656e736f7272745f57696e31303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f7e8570cbb8f3a2e06ea1f2faf91e6b4fb7eb3aa1297ae5cf5f0df573da88a38/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f6e6461792d4c656f2f596f6c6f76355f54656e736f7272745f57696e31303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Monday-Leo/Yolov5_Tensorrt_Win10?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A simple implementation of tensorrt yolov5 python/c++ðŸ”¥\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Wulingtian/yolov5_tensorrt_int8\"\u003eWulingtian/yolov5_tensorrt_int8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1a7daaf88c474cbc2e315446bb2adb9d9dcc34331b8ffe0fc804b6cef715e834/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57756c696e677469616e2f796f6c6f76355f74656e736f7272745f696e74383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1a7daaf88c474cbc2e315446bb2adb9d9dcc34331b8ffe0fc804b6cef715e834/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57756c696e677469616e2f796f6c6f76355f74656e736f7272745f696e74383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Wulingtian/yolov5_tensorrt_int8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRT int8 é‡åŒ–éƒ¨ç½² yolov5s æ¨¡åž‹ï¼Œå®žæµ‹3.3msä¸€å¸§ï¼\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Wulingtian/yolov5_tensorrt_int8_tools\"\u003eWulingtian/yolov5_tensorrt_int8_tools\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/acbdb43e28a723dadc2de3027e4462d5487128a10b4bc459492e2a2e686bce57/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57756c696e677469616e2f796f6c6f76355f74656e736f7272745f696e74385f746f6f6c733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/acbdb43e28a723dadc2de3027e4462d5487128a10b4bc459492e2a2e686bce57/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57756c696e677469616e2f796f6c6f76355f74656e736f7272745f696e74385f746f6f6c733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Wulingtian/yolov5_tensorrt_int8_tools?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : tensorrt int8 é‡åŒ–yolov5 onnxæ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MadaoFY/yolov5_TensorRT_inference\"\u003eMadaoFY/yolov5_TensorRT_inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/60858563edcd7cd842d9d636671744b1a0e14236dc03d68531864145225b95ea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6164616f46592f796f6c6f76355f54656e736f7252545f696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/60858563edcd7cd842d9d636671744b1a0e14236dc03d68531864145225b95ea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6164616f46592f796f6c6f76355f54656e736f7252545f696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MadaoFY/yolov5_TensorRT_inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è®°å½•yolov5çš„TensorRTé‡åŒ–åŠæŽ¨ç†ä»£ç ï¼Œç»å®žæµ‹å¯è¿è¡ŒäºŽJetsonå¹³å°ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ibaiGorordo/ONNX-YOLOv8-Object-Detection\"\u003eibaiGorordo/ONNX-YOLOv8-Object-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/655c84f66b1eed29eef8c2689c0157f8a43cad94fc45e9238a94c9ef25694364/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69626169476f726f72646f2f4f4e4e582d594f4c4f76382d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/655c84f66b1eed29eef8c2689c0157f8a43cad94fc45e9238a94c9ef25694364/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69626169476f726f72646f2f4f4e4e582d594f4c4f76382d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ibaiGorordo/ONNX-YOLOv8-Object-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Python scripts performing object detection using the YOLOv8 model in ONNX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/we0091234/yolov8-tensorrt\"\u003ewe0091234/yolov8-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0e11f06202dcfa168e4fc4b1b9779b156cb393336246ce69036420a10a3c9f37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7765303039313233342f796f6c6f76382d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0e11f06202dcfa168e4fc4b1b9779b156cb393336246ce69036420a10a3c9f37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7765303039313233342f796f6c6f76382d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/we0091234/yolov8-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov8 tensorrt åŠ é€Ÿ.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FeiYull/yolov8-tensorrt\"\u003eFeiYull/yolov8-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cf51132da93738691e2c8412a82f1b4417889c28c5f0cb27bd4a2873a19195c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46656959756c6c2f796f6c6f76382d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cf51132da93738691e2c8412a82f1b4417889c28c5f0cb27bd4a2873a19195c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46656959756c6c2f796f6c6f76382d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FeiYull/yolov8-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv8çš„TensorRT+CUDAåŠ é€Ÿéƒ¨ç½²ï¼Œä»£ç å¯åœ¨Winã€Linuxä¸‹è¿è¡Œã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cvdong/YOLO_TRT_SIM\"\u003ecvdong/YOLO_TRT_SIM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d206284982b7588a61891358294ca64adabdf4e041a6902267d0a4c9fadbe722/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6376646f6e672f594f4c4f5f5452545f53494d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d206284982b7588a61891358294ca64adabdf4e041a6902267d0a4c9fadbe722/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6376646f6e672f594f4c4f5f5452545f53494d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cvdong/YOLO_TRT_SIM?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ‡ ä¸€å¥—ä»£ç åŒæ—¶æ”¯æŒYOLO X, V5, V6, V7, V8 TRTæŽ¨ç† â„¢ï¸ ðŸ” ,å‰åŽå¤„ç†å‡ç”±CUDAæ ¸å‡½æ•°å®žçŽ° CPP/CUDAðŸš€\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cvdong/YOLO_TRT_PY\"\u003ecvdong/YOLO_TRT_PY\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/28021c8fd009112321e281286a6cbf05389957f0c44fd3dfcc709198b7ffc836/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6376646f6e672f594f4c4f5f5452545f50593f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/28021c8fd009112321e281286a6cbf05389957f0c44fd3dfcc709198b7ffc836/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6376646f6e672f594f4c4f5f5452545f50593f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cvdong/YOLO_TRT_PY?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ° ä¸€å¥—ä»£ç åŒæ—¶æ”¯æŒYOLOV5, V6, V7, V8 TRTæŽ¨ç† â„¢ï¸ PYTHON \u003cg-emoji class=\"g-emoji\" alias=\"airplane\"\u003eâœˆï¸\u003c/g-emoji\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Psynosaur/Jetson-SecVision\"\u003ePsynosaur/Jetson-SecVision\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f44949899f3e3571614b5724473c096afd9e6fc9c28307e250539e53cd22a7cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5073796e6f736175722f4a6574736f6e2d536563566973696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f44949899f3e3571614b5724473c096afd9e6fc9c28307e250539e53cd22a7cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5073796e6f736175722f4a6574736f6e2d536563566973696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Psynosaur/Jetson-SecVision?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Person detection for Hikvision DVR with AlarmIO ports, uses TensorRT and yolov4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tatsuya-fukuoka/yolov7-onnx-infer\"\u003etatsuya-fukuoka/yolov7-onnx-infer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/354c328209a12c0ec19fef3d51516589ebd53368aff8ab31922c4c1b89469f10/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746174737579612d66756b756f6b612f796f6c6f76372d6f6e6e782d696e6665723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/354c328209a12c0ec19fef3d51516589ebd53368aff8ab31922c4c1b89469f10/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746174737579612d66756b756f6b612f796f6c6f76372d6f6e6e782d696e6665723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tatsuya-fukuoka/yolov7-onnx-infer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Inference with yolov7's onnx model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MadaoFY/yolov5_TensorRT_inference\"\u003eMadaoFY/yolov5_TensorRT_inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/60858563edcd7cd842d9d636671744b1a0e14236dc03d68531864145225b95ea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6164616f46592f796f6c6f76355f54656e736f7252545f696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/60858563edcd7cd842d9d636671744b1a0e14236dc03d68531864145225b95ea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6164616f46592f796f6c6f76355f54656e736f7252545f696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MadaoFY/yolov5_TensorRT_inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è®°å½•yolov5çš„TensorRTé‡åŒ–åŠæŽ¨ç†ä»£ç ï¼Œç»å®žæµ‹å¯è¿è¡ŒäºŽJetsonå¹³å°ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ervgan/yolov5_tensorrt_inference\"\u003eervgan/yolov5_tensorrt_inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b6dca175c1b92b47fc54fc4900289664866e72a73f46615cb9b512e7c762e524/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f65727667616e2f796f6c6f76355f74656e736f7272745f696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b6dca175c1b92b47fc54fc4900289664866e72a73f46615cb9b512e7c762e524/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f65727667616e2f796f6c6f76355f74656e736f7272745f696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ervgan/yolov5_tensorrt_inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRT cpp inference for Yolov5 model. Supports yolov5 v1.0, v2.0, v3.0, v3.1, v4.0, v5.0, v6.0, v6.2, v7.0.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlbinZhu/easy-trt\"\u003eAlbinZhu/easy-trt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9432205eafcbdf093914cfcb5fcac7c750bac719d2905bf96300e06cd02bee3e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c62696e5a68752f656173792d7472743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9432205eafcbdf093914cfcb5fcac7c750bac719d2905bf96300e06cd02bee3e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c62696e5a68752f656173792d7472743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlbinZhu/easy-trt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRT for YOLOv10 with CUDA.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PrinceP/tensorrt-cpp-for-onnx\"\u003ePrinceP/tensorrt-cpp-for-onnx\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3637b1c708aa8e7c8b2668b96e4eb5b5b20144a648b357100a0dcded87457fcf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5072696e6365502f74656e736f7272742d6370702d666f722d6f6e6e783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3637b1c708aa8e7c8b2668b96e4eb5b5b20144a648b357100a0dcded87457fcf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5072696e6365502f74656e736f7272742d6370702d666f722d6f6e6e783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PrinceP/tensorrt-cpp-for-onnx?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tensorrt codebase to inference in c++ for all major neural arch using onnx.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hamdiboukamcha/Yolo-V10-cpp-TensorRT\"\u003ehamdiboukamcha/Yolo-V10-cpp-TensorRT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/78b79a37fc01fb407b56de375c4b491962f30a2aa46088431249a9df01573f7f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68616d6469626f756b616d6368612f596f6c6f2d5631302d6370702d54656e736f7252543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/78b79a37fc01fb407b56de375c4b491962f30a2aa46088431249a9df01573f7f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68616d6469626f756b616d6368612f596f6c6f2d5631302d6370702d54656e736f7252543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hamdiboukamcha/Yolo-V10-cpp-TensorRT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The YOLOv10 C++ TensorRT Project in C++ and optimized using NVIDIA TensorRT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DataXujing/YOLOv12-TensorRT\"\u003eDataXujing/YOLOv12-TensorRT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/41e23db69776f7617e835b1d3cc546402e379ab320fee03562cde39bbdba03a5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f7631322d54656e736f7252543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/41e23db69776f7617e835b1d3cc546402e379ab320fee03562cde39bbdba03a5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f7631322d54656e736f7252543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DataXujing/YOLOv12-TensorRT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv12 TensorRT ç«¯åˆ°ç«¯æ¨¡åž‹åŠ é€ŸæŽ¨ç†å’ŒINT8é‡åŒ–å®žçŽ°ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eDeepStream\u003c/h5\u003e\u003ca id=\"user-content-deepstream\" class=\"anchor\" aria-label=\"Permalink: DeepStream\" href=\"#deepstream\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NVIDIA-AI-IOT/deepstream_reference_apps\"\u003eNVIDIA-AI-IOT/deepstream_reference_apps\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/142e450769825a3832d5060982824bc1a1700ba932170db757d3be6ae2d724a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f6465657073747265616d5f7265666572656e63655f617070733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/142e450769825a3832d5060982824bc1a1700ba932170db757d3be6ae2d724a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f6465657073747265616d5f7265666572656e63655f617070733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NVIDIA-AI-IOT/deepstream_reference_apps?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Reference Apps using DeepStream 6.1.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NVIDIA-AI-IOT/deepstream_python_apps\"\u003eNVIDIA-AI-IOT/deepstream_python_apps\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/35604b7d8133062622b680359795a789af314cf985369807d1f8ef3ec8933c70/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f6465657073747265616d5f707974686f6e5f617070733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/35604b7d8133062622b680359795a789af314cf985369807d1f8ef3ec8933c70/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f6465657073747265616d5f707974686f6e5f617070733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NVIDIA-AI-IOT/deepstream_python_apps?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : DeepStream SDK Python bindings and sample applications.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NVIDIA-AI-IOT/yolov5_gpu_optimization\"\u003eNVIDIA-AI-IOT/deepstream_python_apps\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/adb2f5e1839408a70daa5d8b051e01c8b52a2dde78030e6579e634dba57d4915/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f796f6c6f76355f6770755f6f7074696d697a6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/adb2f5e1839408a70daa5d8b051e01c8b52a2dde78030e6579e634dba57d4915/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f796f6c6f76355f6770755f6f7074696d697a6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NVIDIA-AI-IOT/yolov5_gpu_optimization?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository provides YOLOV5 GPU optimization sample.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/marcoslucianops/DeepStream-Yolo\"\u003emarcoslucianops/DeepStream-Yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/081b4a864d27afb69387494716270e4d632d57f309830d551704d07e465c8271/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6172636f736c756369616e6f70732f4465657053747265616d2d596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/081b4a864d27afb69387494716270e4d632d57f309830d551704d07e465c8271/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6172636f736c756369616e6f70732f4465657053747265616d2d596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/marcoslucianops/DeepStream-Yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : NVIDIA DeepStream SDK 6.1.1 / 6.1 / 6.0.1 / 6.0 implementation for YOLO models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DanaHan/Yolov5-in-Deepstream-5.0\"\u003eDanaHan/Yolov5-in-Deepstream-5.0\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7c32d28e01f71fa39c58426c534f6876e8fb83a34fc553f54d0685b8c32b9a4f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44616e6148616e2f596f6c6f76352d696e2d4465657073747265616d2d352e303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7c32d28e01f71fa39c58426c534f6876e8fb83a34fc553f54d0685b8c32b9a4f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44616e6148616e2f596f6c6f76352d696e2d4465657073747265616d2d352e303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DanaHan/Yolov5-in-Deepstream-5.0?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Describe how to use yolov5 in Deepstream 5.0.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ozinc/Deepstream6_YoloV5_Kafka\"\u003eozinc/Deepstream6_YoloV5_Kafka\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9cbd7c29561ffc932679b7a7505d87c59d57ce5430b3f12e13e2e8171407ef35/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f7a696e632f4465657073747265616d365f596f6c6f56355f4b61666b613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9cbd7c29561ffc932679b7a7505d87c59d57ce5430b3f12e13e2e8171407ef35/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f7a696e632f4465657073747265616d365f596f6c6f56355f4b61666b613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ozinc/Deepstream6_YoloV5_Kafka?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository gives a detailed explanation on making custom trained deepstream-Yolo models predict and send message over kafka.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kn1ghtf1re/yolov8-deepstream-6-1\"\u003ekn1ghtf1re/yolov8-deepstream-6-1\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7193e3c60f1c699add1af0a849f1ca740682c5ab35e492c7f3cf78c8f10a81e7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b6e31676874663172652f796f6c6f76382d6465657073747265616d2d362d313f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7193e3c60f1c699add1af0a849f1ca740682c5ab35e492c7f3cf78c8f10a81e7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b6e31676874663172652f796f6c6f76382d6465657073747265616d2d362d313f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kn1ghtf1re/yolov8-deepstream-6-1?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv8 by Ultralytics in DeepStream 6.1.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bharath5673/Deepstream\"\u003ebharath5673/Deepstream\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/50b87de6dbfd9edd53c5676a8a38e1db358ac39c5862742f3c2ed67daf0570ad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62686172617468353637332f4465657073747265616d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/50b87de6dbfd9edd53c5676a8a38e1db358ac39c5862742f3c2ed67daf0570ad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62686172617468353637332f4465657073747265616d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bharath5673/Deepstream?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov2 ,yolov5 ,yolov6 ,yolov7 ,yolov7,yolovR ,yolovX on deepstream.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/insight-platform/Savant\"\u003eSavant\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/857a2d7be9080390d32196265f8554ad18084b2b2c3c38c2c9e7545563ffd618/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e73696768742d706c6174666f726d2f536176616e743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/857a2d7be9080390d32196265f8554ad18084b2b2c3c38c2c9e7545563ffd618/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e73696768742d706c6174666f726d2f536176616e743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/insight-platform/Savant?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Python Computer Vision \u0026amp; Video Analytics Framework With Batteries Included. \u003ca href=\"https://savant-ai.io/\" rel=\"nofollow\"\u003esavant-ai.io\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/quangdungluong/DeepStream-YOLOv11\"\u003eSavant\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3df4b6911846dfdb989b93829dbe9574fef802d5d61c1f1ddd7bc8a1d317023d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7175616e6764756e676c756f6e672f4465657053747265616d2d594f4c4f7631313f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3df4b6911846dfdb989b93829dbe9574fef802d5d61c1f1ddd7bc8a1d317023d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7175616e6764756e676c756f6e672f4465657053747265616d2d594f4c4f7631313f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/quangdungluong/DeepStream-YOLOv11?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Plug-and-Play Custom Parsers for AI Models in NVIDIA DeepStream SDK. Supported YOLOv11 model.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOpenVINO\u003c/h5\u003e\u003ca id=\"user-content-openvino\" class=\"anchor\" aria-label=\"Permalink: OpenVINO\" href=\"#openvino\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/openvinotoolkit/openvino\"\u003eOpenVINO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/739efdd36838aef02d043f818bec13c5446a9bf61dbaeb47092365a93930072e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e76696e6f746f6f6c6b69742f6f70656e76696e6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/739efdd36838aef02d043f818bec13c5446a9bf61dbaeb47092365a93930072e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e76696e6f746f6f6c6b69742f6f70656e76696e6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/openvinotoolkit/openvino?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This open source version includes several components: namely Model Optimizer, OpenVINOâ„¢ Runtime, Post-Training Optimization Tool, as well as CPU, GPU, MYRIAD, multi device and heterogeneous plugins to accelerate deep learning inferencing on IntelÂ® CPUs and IntelÂ® Processor Graphics.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PINTO0309/OpenVINO-YoloV3\"\u003ePINTO0309/OpenVINO-YoloV3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/84a3665ed018a6f17827b03ca21fc9be7086bde65381321bdc40294b7889e2d3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f50494e544f303330392f4f70656e56494e4f2d596f6c6f56333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/84a3665ed018a6f17827b03ca21fc9be7086bde65381321bdc40294b7889e2d3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f50494e544f303330392f4f70656e56494e4f2d596f6c6f56333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PINTO0309/OpenVINO-YoloV3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV3/tiny-YoloV3 + RaspberryPi3/Ubuntu LaptopPC + NCS/NCS2 + USB Camera + Python + OpenVINO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TNTWEN/OpenVINO-YOLOV4\"\u003eTNTWEN/OpenVINO-YOLOV4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3df5c4f9cc0fa614efa57a9266abc841840e5f9469b79c1685a8440c48308fad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f544e5457454e2f4f70656e56494e4f2d594f4c4f56343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3df5c4f9cc0fa614efa57a9266abc841840e5f9469b79c1685a8440c48308fad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f544e5457454e2f4f70656e56494e4f2d594f4c4f56343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TNTWEN/OpenVINO-YOLOV4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is implementation of YOLOv4,YOLOv4-relu,YOLOv4-tiny,YOLOv4-tiny-3l,Scaled-YOLOv4 and INT8 Quantization in OpenVINO2021.3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fb029ed/yolov5_cpp_openvino\"\u003efb029ed/yolov5_cpp_openvino\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8c50d6464af8e5f96e853baf1001b50f00ad24d33bd093b18e0ee3cb57103ace/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666230323965642f796f6c6f76355f6370705f6f70656e76696e6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8c50d6464af8e5f96e853baf1001b50f00ad24d33bd093b18e0ee3cb57103ace/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666230323965642f796f6c6f76355f6370705f6f70656e76696e6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/fb029ed/yolov5_cpp_openvino?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ç”¨c++å®žçŽ°äº†yolov5ä½¿ç”¨openvinoçš„éƒ¨ç½²ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dlod-openvino/yolov5_infer\"\u003edlod-openvino/yolov5_infer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/90a36f9b4bde35ec2fe1fc355f749c059fd663b9cfdb539e00d4ec3bc19533c1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646c6f642d6f70656e76696e6f2f796f6c6f76355f696e6665723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/90a36f9b4bde35ec2fe1fc355f749c059fd663b9cfdb539e00d4ec3bc19533c1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646c6f642d6f70656e76696e6f2f796f6c6f76355f696e6665723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dlod-openvino/yolov5_infer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Do the YOLOv5 model inference by OpenCV/OpenVINO based on onnx model format.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/snail0614/yolov5.6_openvino_cpp\"\u003esnail0614/yolov5.6_openvino_cpp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1c22fe4c6db8fd684bc3de0346fc745def428833eceb1cd6dc2b1f7d5f6c2b12/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736e61696c303631342f796f6c6f76352e365f6f70656e76696e6f5f6370703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1c22fe4c6db8fd684bc3de0346fc745def428833eceb1cd6dc2b1f7d5f6c2b12/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736e61696c303631342f796f6c6f76352e365f6f70656e76696e6f5f6370703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/snail0614/yolov5.6_openvino_cpp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5.6.1 OpenVINOçš„C++å®žçŽ°ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/shungfu/openvino_yolov5v7\"\u003eshungfu/openvino_yolov5v7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5fb33f13f6cf3e8ec06ca4a41043ce585052dc053cb77fa121a69f225531b315/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7368756e6766752f6f70656e76696e6f5f796f6c6f763576373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5fb33f13f6cf3e8ec06ca4a41043ce585052dc053cb77fa121a69f225531b315/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7368756e6766752f6f70656e76696e6f5f796f6c6f763576373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/shungfu/openvino_yolov5v7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 YOLOv7 INT8 quantization using OpenVINO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dacquaviva/yolov5-openvino-cpp-python\"\u003edacquaviva/yolov5-openvino-cpp-python\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/472de67c713818b3ebb7a96d8b199ecf503f0bf59fe413ce727df287685f4072/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646163717561766976612f796f6c6f76352d6f70656e76696e6f2d6370702d707974686f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/472de67c713818b3ebb7a96d8b199ecf503f0bf59fe413ce727df287685f4072/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646163717561766976612f796f6c6f76352d6f70656e76696e6f2d6370702d707974686f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dacquaviva/yolov5-openvino-cpp-python?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Example of using ultralytics YOLOv5 with Openvino in C++ and Python.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/rlggyp/YOLOv10-OpenVINO-CPP-Inference\"\u003erlggyp/YOLOv10-OpenVINO-CPP-Inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/252fc6ce15289046fa03dab9c8d16f2c7840273956570557d348b04fe4afc7df/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726c676779702f594f4c4f7631302d4f70656e56494e4f2d4350502d496e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/252fc6ce15289046fa03dab9c8d16f2c7840273956570557d348b04fe4afc7df/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726c676779702f594f4c4f7631302d4f70656e56494e4f2d4350502d496e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/rlggyp/YOLOv10-OpenVINO-CPP-Inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv10 C++ implementation using OpenVINO for efficient and accurate real-time object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eNCNN\u003c/h5\u003e\u003ca id=\"user-content-ncnn\" class=\"anchor\" aria-label=\"Permalink: NCNN\" href=\"#ncnn\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Tencent/ncnn\"\u003eNCNN\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5c72531566f052b2acd667593b42e0dd599bbb415bf7ea22ace7bbe4a9f9bfc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54656e63656e742f6e636e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5c72531566f052b2acd667593b42e0dd599bbb415bf7ea22ace7bbe4a9f9bfc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54656e63656e742f6e636e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Tencent/ncnn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ncnn is a high-performance neural network inference framework optimized for the mobile platform.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Baiyuetribe/ncnn-models\"\u003eBaiyuetribe/ncnn-models\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/24fdd8179935c60095f33ffa3f6766f1bd6a334bdb1a41ef1d141c8966d730b4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42616979756574726962652f6e636e6e2d6d6f64656c733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/24fdd8179935c60095f33ffa3f6766f1bd6a334bdb1a41ef1d141c8966d730b4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42616979756574726962652f6e636e6e2d6d6f64656c733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Baiyuetribe/ncnn-models?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : awesome AI models with NCNN, and how they were converted âœ¨âœ¨âœ¨\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloV10-ncnn-Raspberry-Pi-4\"\u003eQengineering/YoloV10-ncnn-Raspberry-Pi-4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8f1467be7a431d720889ca97396c9fdc930d73b7477d86e532dadf98a32557bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f5631302d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8f1467be7a431d720889ca97396c9fdc930d73b7477d86e532dadf98a32557bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f5631302d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloV10-ncnn-Raspberry-Pi-4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV10 for a bare Raspberry Pi 4 or 5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cmdbug/YOLOv5_NCNN\"\u003ecmdbug/YOLOv5_NCNN\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7d0a12e2c178bf39b01e0baa2701b17544eae7da261de9e69d342c0d9344fc04/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636d646275672f594f4c4f76355f4e434e4e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7d0a12e2c178bf39b01e0baa2701b17544eae7da261de9e69d342c0d9344fc04/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636d646275672f594f4c4f76355f4e434e4e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cmdbug/YOLOv5_NCNN?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ… Deploy ncnn on mobile phones. Support Android and iOS. ç§»åŠ¨ç«¯ncnnéƒ¨ç½²ï¼Œæ”¯æŒAndroidä¸ŽiOSã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/natanielruiz/android-yolo\"\u003enatanielruiz/android-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/eb72a9ad9c0ddfced4200ea88c62db25dd5151de475a8f50269e541e96f846cf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e6174616e69656c7275697a2f616e64726f69642d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/eb72a9ad9c0ddfced4200ea88c62db25dd5151de475a8f50269e541e96f846cf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e6174616e69656c7275697a2f616e64726f69642d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/natanielruiz/android-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time object detection on Android using the YOLO network with TensorFlow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nihui/ncnn-android-yolov5\"\u003enihui/ncnn-android-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9908c82ca5f6036a71be93c8d7fc762fcdc98dc2d6ff9e738e1be39f3730da4d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e696875692f6e636e6e2d616e64726f69642d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9908c82ca5f6036a71be93c8d7fc762fcdc98dc2d6ff9e738e1be39f3730da4d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e696875692f6e636e6e2d616e64726f69642d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nihui/ncnn-android-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The YOLOv5 object detection android example.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/szaza/android-yolo-v2\"\u003eszaza/android-yolo-v2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3e8e27d75bbdb29df6335c1434f86523297618e61e80c7ab06963068feb312b2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737a617a612f616e64726f69642d796f6c6f2d76323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3e8e27d75bbdb29df6335c1434f86523297618e61e80c7ab06963068feb312b2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737a617a612f616e64726f69642d796f6c6f2d76323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/szaza/android-yolo-v2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Android YOLO real time object detection sample application with Tensorflow mobile.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FeiGeChuanShu/ncnn-android-yolox\"\u003eFeiGeChuanShu/ncnn-android-yolox\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2b114dd6b421b1c1e7799fb83bcdac016f815cef0127128ea8d3e3edb2ec113c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4665694765436875616e5368752f6e636e6e2d616e64726f69642d796f6c6f783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2b114dd6b421b1c1e7799fb83bcdac016f815cef0127128ea8d3e3edb2ec113c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4665694765436875616e5368752f6e636e6e2d616e64726f69642d796f6c6f783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FeiGeChuanShu/ncnn-android-yolox?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real time yolox Android demo by ncnn.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xiangweizeng/darknet2ncnn\"\u003exiangweizeng/darknet2ncnn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/29a4385eaf0d66811c436727bbdf04933e959834b1e1b43d109d76dd3a2ab874/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616e677765697a656e672f6461726b6e6574326e636e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/29a4385eaf0d66811c436727bbdf04933e959834b1e1b43d109d76dd3a2ab874/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616e677765697a656e672f6461726b6e6574326e636e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xiangweizeng/darknet2ncnn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Darknet2ncnn converts the darknet model to the ncnn model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sunnyden/YOLOV5_NCNN_Android\"\u003esunnyden/YOLOV5_NCNN_Android\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6b041b9363aede2525a4062a91633a4ef4fccd2eefd223a58c11e49404604825/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756e6e7964656e2f594f4c4f56355f4e434e4e5f416e64726f69643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6b041b9363aede2525a4062a91633a4ef4fccd2eefd223a58c11e49404604825/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756e6e7964656e2f594f4c4f56355f4e434e4e5f416e64726f69643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sunnyden/YOLOV5_NCNN_Android?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 C++ Implementation on Android using NCNN framework.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/duangenquan/YoloV2NCS\"\u003eduangenquan/YoloV2NCS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c88b9402f1c4ff6ee2f6a548b5daeddfbd3a2a1878518d702edacf7d524dfa86/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6475616e67656e7175616e2f596f6c6f56324e43533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c88b9402f1c4ff6ee2f6a548b5daeddfbd3a2a1878518d702edacf7d524dfa86/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6475616e67656e7175616e2f596f6c6f56324e43533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/duangenquan/YoloV2NCS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This project shows how to run tiny yolo v2 with movidius stick.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lp6m/yolov5s_android\"\u003elp6m/yolov5s_android\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e744cfaaab54cd282316cd8a67e63802c3f45888ab9e36a46ad82735a030f4b7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c70366d2f796f6c6f7635735f616e64726f69643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e744cfaaab54cd282316cd8a67e63802c3f45888ab9e36a46ad82735a030f4b7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c70366d2f796f6c6f7635735f616e64726f69643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lp6m/yolov5s_android?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Run yolov5s on Android device!\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/KoheiKanagu/ncnn_yolox_flutter\"\u003eKoheiKanagu/ncnn_yolox_flutter\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2ee24377c35806d6f248958efdba14dfc9c0d7c2ad93093f89300d2f9da66826/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6f6865694b616e6167752f6e636e6e5f796f6c6f785f666c75747465723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2ee24377c35806d6f248958efdba14dfc9c0d7c2ad93093f89300d2f9da66826/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6f6865694b616e6167752f6e636e6e5f796f6c6f785f666c75747465723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/KoheiKanagu/ncnn_yolox_flutter?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a plugin to run YOLOX on ncnn.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cyrillkuettel/ncnn-android-yolov5\"\u003ecyrillkuettel/ncnn-android-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9ff61d0d29f4604d83c193f3bd32381cd55d506c92df4b5f1b41ff637d627d89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f637972696c6c6b75657474656c2f6e636e6e2d616e64726f69642d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9ff61d0d29f4604d83c193f3bd32381cd55d506c92df4b5f1b41ff637d627d89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f637972696c6c6b75657474656c2f6e636e6e2d616e64726f69642d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cyrillkuettel/ncnn-android-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a sample ncnn android project, it depends on ncnn library and opencv.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DataXujing/ncnn_android_yolov6\"\u003eDataXujing/ncnn_android_yolov6\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1cca359d0c267435cc4c5d1a06d5cb1145d2318e598c0594ad36e603eaf2890d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f6e636e6e5f616e64726f69645f796f6c6f76363f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1cca359d0c267435cc4c5d1a06d5cb1145d2318e598c0594ad36e603eaf2890d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f6e636e6e5f616e64726f69645f796f6c6f76363f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DataXujing/ncnn_android_yolov6?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : æ‰‹æ‘¸æ‰‹å®žçŽ°åŸºäºŽQTå’ŒNCNNçš„å®‰å“æ‰‹æœºYOLOv6æ¨¡åž‹çš„éƒ¨ç½²ï¼\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloV3-ncnn-Raspberry-Pi-4\"\u003eQengineering/YoloV3-ncnn-Raspberry-Pi-4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/359fd3a7a21ef726aa0c1ed43e5f4ca5604229e8688f31261ff3fcc96d1d899a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56332d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/359fd3a7a21ef726aa0c1ed43e5f4ca5604229e8688f31261ff3fcc96d1d899a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56332d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloV3-ncnn-Raspberry-Pi-4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV3 Raspberry Pi 4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloV4-ncnn-Raspberry-Pi-4\"\u003eQengineering/YoloV4-ncnn-Raspberry-Pi-4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c5593836c6dd9fdd9da4ff0a16cb74f78a6eb97d38b66d9e9f1ff6853e69432a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56342d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c5593836c6dd9fdd9da4ff0a16cb74f78a6eb97d38b66d9e9f1ff6853e69432a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56342d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloV4-ncnn-Raspberry-Pi-4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV4 on a bare Raspberry Pi 4 with ncnn framework.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloV5-ncnn-Raspberry-Pi-4\"\u003eQengineering/YoloV5-ncnn-Raspberry-Pi-4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/09671a5b4c5fc25d7f0ce714cfd23302075d6179b96c65f618db37e2f54a0fb4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56352d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/09671a5b4c5fc25d7f0ce714cfd23302075d6179b96c65f618db37e2f54a0fb4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56352d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloV5-ncnn-Raspberry-Pi-4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV5 for a bare Raspberry Pi 4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloV6-ncnn-Raspberry-Pi-4\"\u003eQengineering/YoloV6-ncnn-Raspberry-Pi-4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/eaed56b04578eb5bddba6eb92f7a26514a2114fa605d0a1c4d735b4d3cf5ed53/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56362d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/eaed56b04578eb5bddba6eb92f7a26514a2114fa605d0a1c4d735b4d3cf5ed53/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56362d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloV6-ncnn-Raspberry-Pi-4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV6 for a bare Raspberry Pi using ncnn.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloV7-ncnn-Raspberry-Pi-4\"\u003eQengineering/YoloV7-ncnn-Raspberry-Pi-4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/adc9f37bba0efa266a00c4c0edf1408a6fa18c5b0643e669bcc76cc7612bf3fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56372d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/adc9f37bba0efa266a00c4c0edf1408a6fa18c5b0643e669bcc76cc7612bf3fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56372d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloV7-ncnn-Raspberry-Pi-4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV7 for a bare Raspberry Pi using ncnn.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloV8-ncnn-Raspberry-Pi-4\"\u003eQengineering/YoloV8-ncnn-Raspberry-Pi-4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b6cd90ae8fa955be67d84e8d026e8b9399f9952fa219f36af28330783c8ed1eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56382d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b6cd90ae8fa955be67d84e8d026e8b9399f9952fa219f36af28330783c8ed1eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56382d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloV8-ncnn-Raspberry-Pi-4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV8 for a bare Raspberry Pi 4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FeiGeChuanShu/ncnn-android-yolov8\"\u003eFeiGeChuanShu/ncnn-android-yolov8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ae353aa0ee568f3ae05de50723e822674f1efbc144548466f8926a4992a134c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4665694765436875616e5368752f6e636e6e2d616e64726f69642d796f6c6f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ae353aa0ee568f3ae05de50723e822674f1efbc144548466f8926a4992a134c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4665694765436875616e5368752f6e636e6e2d616e64726f69642d796f6c6f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FeiGeChuanShu/ncnn-android-yolov8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real time yolov8 Android demo by ncnn.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FLamefiREz/yolov10-android-ncnn\"\u003eFLamefiREz/yolov10-android-ncnn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c902ba55930831b85c1a363d186144f42814c1cb0b3f9552ba2edbce9b41fe11/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f464c616d65666952457a2f796f6c6f7631302d616e64726f69642d6e636e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c902ba55930831b85c1a363d186144f42814c1cb0b3f9552ba2edbce9b41fe11/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f464c616d65666952457a2f796f6c6f7631302d616e64726f69642d6e636e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FLamefiREz/yolov10-android-ncnn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov10-android-ncnn.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eMNN\u003c/h5\u003e\u003ca id=\"user-content-mnn\" class=\"anchor\" aria-label=\"Permalink: MNN\" href=\"#mnn\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/alibaba/MNN\"\u003eMNN\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f65ac69d4afe8f811e289774cee39b8a0c45a37b539db52ad5af444a6ab8117d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69626162612f4d4e4e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f65ac69d4afe8f811e289774cee39b8a0c45a37b539db52ad5af444a6ab8117d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69626162612f4d4e4e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/alibaba/MNN?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : MNN is a blazing fast, lightweight deep learning framework, battle-tested by business-critical use cases in Alibaba. (\u003cstrong\u003e\u003ca href=\"https://proceedings.mlsys.org/paper/2020/hash/8f14e45fceea167a5a36dedd4bea2543-Abstract.html\" rel=\"nofollow\"\u003eMLSys 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/apxlwl/MNN-yolov3\"\u003eapxlwl/MNN-yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/00b80e3d6d6516105c460cd829ef6d4bae9bf9f03ec12f1eef4416d7ae146840/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6170786c776c2f4d4e4e2d796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/00b80e3d6d6516105c460cd829ef6d4bae9bf9f03ec12f1eef4416d7ae146840/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6170786c776c2f4d4e4e2d796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/apxlwl/MNN-yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : MNN demo of Strongeryolo, including channel pruning, android support...\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOther Engine\u003c/h5\u003e\u003ca id=\"user-content-other-engine\" class=\"anchor\" aria-label=\"Permalink: Other Engine\" href=\"#other-engine\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/apache/tvm\"\u003eTVM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/98823984dbc785e54ff14e39483f27188d21c990af5250f0a677dbc22ddc1296/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6170616368652f74766d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/98823984dbc785e54ff14e39483f27188d21c990af5250f0a677dbc22ddc1296/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6170616368652f74766d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/apache/tvm?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Open deep learning compiler stack for cpu, gpu and specialized accelerators.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ceccocats/tkDNN\"\u003ececcocats/tkDNN\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/182ae2c1843f4faf86c2ebdfd3d95f42d568f6215dfb609a641f2589a39cf964/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636563636f636174732f746b444e4e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/182ae2c1843f4faf86c2ebdfd3d95f42d568f6215dfb609a641f2589a39cf964/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636563636f636174732f746b444e4e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ceccocats/tkDNN?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Deep neural network library and toolkit to do high performace inference on NVIDIA jetson platforms. \"A Systematic Assessment of Embedded Neural Networks for Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/document/9212130\" rel=\"nofollow\"\u003eIEEE ETFA 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/OAID/Tengine\"\u003eTengine\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8ca3bfd45d2c41f059351cd57fb0b72b87df96861b890bad58aa7b143fcaa61c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f4149442f54656e67696e653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8ca3bfd45d2c41f059351cd57fb0b72b87df96861b890bad58aa7b143fcaa61c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f4149442f54656e67696e653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/OAID/Tengine?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tengine is a lite, high performance, modular inference engine for embedded device.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/paddlepaddle/paddle-lite\"\u003ePaddle Lite\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c327d099615f469136b9ee9d9cae01142a3a7242da191535e5d88d621d22262e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706164646c65706164646c652f706164646c652d6c6974653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c327d099615f469136b9ee9d9cae01142a3a7242da191535e5d88d621d22262e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706164646c65706164646c652f706164646c652d6c6974653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/paddlepaddle/paddle-lite?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Multi-platform high performance deep learning inference engine (é£žæ¡¨å¤šç«¯å¤šå¹³å°é«˜æ€§èƒ½æ·±åº¦å­¦ä¹ æŽ¨ç†å¼•æ“Žï¼‰ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DeployAI/nndeploy\"\u003eDeployAI/nndeploy\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5c16c6f36ec6da6b7e64d893ad79122a91e8f496485f46387c1af19013d81034/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465706c6f7941492f6e6e6465706c6f793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5c16c6f36ec6da6b7e64d893ad79122a91e8f496485f46387c1af19013d81034/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465706c6f7941492f6e6e6465706c6f793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DeployAI/nndeploy?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : nndeploy is a cross-platform, high-performing, and straightforward AI model deployment framework. We strive to deliver a consistent and user-friendly experience across various inference framework in complex deployment environments and focus on performance. nndeployä¸€æ¬¾è·¨å¹³å°ã€é«˜æ€§èƒ½ã€ç®€å•æ˜“ç”¨çš„æ¨¡åž‹ç«¯åˆ°ç«¯éƒ¨ç½²æ¡†æž¶ã€‚æˆ‘ä»¬è‡´åŠ›äºŽå±è”½ä¸åŒæŽ¨ç†æ¡†æž¶çš„å·®å¼‚ï¼Œæä¾›ä¸€è‡´ä¸”ç”¨æˆ·å‹å¥½çš„ç¼–ç¨‹ä½“éªŒï¼ŒåŒæ—¶ä¸“æ³¨äºŽéƒ¨ç½²å…¨æµç¨‹çš„æ€§èƒ½ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yhwang-hub/dl_model_infer\"\u003eyhwang-hub/dl_model_infer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/07aada3f299dd15c7a814b88943c15a530898871fb31f83bf06da03440d07ee2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796877616e672d6875622f646c5f6d6f64656c5f696e6665723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/07aada3f299dd15c7a814b88943c15a530898871fb31f83bf06da03440d07ee2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796877616e672d6875622f646c5f6d6f64656c5f696e6665723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yhwang-hub/dl_model_infer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : his is a c++ version of the AI reasoning library. Currently, it only supports the reasoning of the tensorrt model. The follow-up plan supports the c++ reasoning of frameworks such as Openvino, NCNN, and MNN. There are two versions for pre- and post-processing, c++ version and cuda version. It is recommended to use the cuda version., This repository provides accelerated deployment cases of deep learning CV popular models, and cuda c supports dynamic-batch image process, infer, decode, NMS.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hollance/YOLO-CoreML-MPSNNGraph\"\u003ehollance/YOLO-CoreML-MPSNNGraph\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/70e456dcebfd43fefd4430577098f5dde664abf1df10980eaa96626ad64dc914/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686f6c6c616e63652f594f4c4f2d436f72654d4c2d4d50534e4e47726170683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/70e456dcebfd43fefd4430577098f5dde664abf1df10980eaa96626ad64dc914/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686f6c6c616e63652f594f4c4f2d436f72654d4c2d4d50534e4e47726170683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hollance/YOLO-CoreML-MPSNNGraph?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tiny YOLO for iOS implemented using CoreML but also using the new MPS graph API.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/r4ghu/iOS-CoreML-Yolo\"\u003er4ghu/iOS-CoreML-Yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8abc8c19f000c68e4a3d04d7e5aed0312ba6f531f0fa0c55d98b8d2d87a3c7e8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72346768752f694f532d436f72654d4c2d596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8abc8c19f000c68e4a3d04d7e5aed0312ba6f531f0fa0c55d98b8d2d87a3c7e8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72346768752f694f532d436f72654d4c2d596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/r4ghu/iOS-CoreML-Yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is the implementation of Object Detection using Tiny YOLO v1 model on Apple's CoreML Framework.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/airockchip/rknn_model_zoo\"\u003eairockchip/rknn_model_zoo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d3cfbdb3b4622b63af680668b0b266e343326c494a6974b0c691e82590e8b2a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6169726f636b636869702f726b6e6e5f6d6f64656c5f7a6f6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d3cfbdb3b4622b63af680668b0b266e343326c494a6974b0c691e82590e8b2a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6169726f636b636869702f726b6e6e5f6d6f64656c5f7a6f6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/airockchip/rknn_model_zoo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Rockchip Neural Network(RKNN)æ˜¯ç‘žèŠ¯å¾®ä¸ºäº†åŠ é€Ÿæ¨¡åž‹æŽ¨ç†è€ŒåŸºäºŽè‡ªèº«NPUç¡¬ä»¶æž¶æž„å®šä¹‰çš„ä¸€å¥—æ¨¡åž‹æ ¼å¼.ä½¿ç”¨è¯¥æ ¼å¼å®šä¹‰çš„æ¨¡åž‹åœ¨Rockchip NPUä¸Šå¯ä»¥èŽ·å¾—è¿œé«˜äºŽCPU/GPUçš„æ€§èƒ½ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LynxiTechnology/Lynxi-model-zoo\"\u003eLynxiTechnology/Lynxi-model-zoo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ab1ec2d79393427c2e35bf8e431375ccaf4a4aa99dbec015b5a8cf9c403175d7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c796e7869546563686e6f6c6f67792f4c796e78692d6d6f64656c2d7a6f6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ab1ec2d79393427c2e35bf8e431375ccaf4a4aa99dbec015b5a8cf9c403175d7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c796e7869546563686e6f6c6f67792f4c796e78692d6d6f64656c2d7a6f6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LynxiTechnology/Lynxi-model-zoo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Lynxi-model-zoo.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eNPU and FPGA Hardware Deployment\u003c/h3\u003e\u003ca id=\"user-content-npu-and-fpga-hardware-deployment\" class=\"anchor\" aria-label=\"Permalink: NPU and FPGA Hardware Deployment\" href=\"#npu-and-fpga-hardware-deployment\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eNPU å’Œ FPGA ç¡¬ä»¶éƒ¨ç½²\u003c/h4\u003e\u003ca id=\"user-content-npu-å’Œ-fpga-ç¡¬ä»¶éƒ¨ç½²\" class=\"anchor\" aria-label=\"Permalink: NPU å’Œ FPGA ç¡¬ä»¶éƒ¨ç½²\" href=\"#npu-å’Œ-fpga-ç¡¬ä»¶éƒ¨ç½²\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eRK3588\u003c/h5\u003e\u003ca id=\"user-content-rk3588\" class=\"anchor\" aria-label=\"Permalink: RK3588\" href=\"#rk3588\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloV8-NPU\"\u003eQengineering/YoloV8-NPU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a1c70014fb4985fdb23a08603ce619f42d7e6b87d6a031b174e95449be52efc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56382d4e50553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a1c70014fb4985fdb23a08603ce619f42d7e6b87d6a031b174e95449be52efc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56382d4e50553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloV8-NPU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV8 for RK3566/68/88 NPU (Rock 5, Orange Pi 5, Radxa Zero 3).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/aemior/yolov8n_rk3588\"\u003eaemior/yolov8n_rk3588\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d9c44d64203c838cce4c250a819a162af8b23058cdcbcccee062634219d91b13/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61656d696f722f796f6c6f76386e5f726b333538383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d9c44d64203c838cce4c250a819a162af8b23058cdcbcccee062634219d91b13/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61656d696f722f796f6c6f76386e5f726b333538383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/aemior/yolov8n_rk3588?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository contains a demonstration of Yolv8n running on an RK3588 device.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cqu20160901/yolov8n_rknn_Cplusplus_dfl\"\u003ecqu20160901/yolov8n_rknn_Cplusplus_dfl\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cb7af19950f93e942e66fa8cb9c61787ffc89eb527eb73d567ca87a69c0b2d5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63717532303136303930312f796f6c6f76386e5f726b6e6e5f43706c7573706c75735f64666c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cb7af19950f93e942e66fa8cb9c61787ffc89eb527eb73d567ca87a69c0b2d5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63717532303136303930312f796f6c6f76386e5f726b6e6e5f43706c7573706c75735f64666c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cqu20160901/yolov8n_rknn_Cplusplus_dfl?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov8 ç‘žèŠ¯å¾® rknn æ¿ç«¯ C++éƒ¨ç½²ï¼Œä½¿ç”¨å¹³å° rk3588ï¼Œå…¨ç½‘æœ€ç®€å•ã€è¿è¡Œæœ€å¿«çš„éƒ¨ç½²æ–¹å¼ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cqu20160901/yolov8seg_rknn_Cplusplus\"\u003ecqu20160901/yolov8seg_rknn_Cplusplus\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/15c2bf5953561406f967fe18ea34cd3ac6186f7c3a755b8f63de2cbdd27adc34/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63717532303136303930312f796f6c6f76387365675f726b6e6e5f43706c7573706c75733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/15c2bf5953561406f967fe18ea34cd3ac6186f7c3a755b8f63de2cbdd27adc34/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63717532303136303930312f796f6c6f76387365675f726b6e6e5f43706c7573706c75733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cqu20160901/yolov8seg_rknn_Cplusplus?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov8seg ç‘žèŠ¯å¾® rknn æ¿ç«¯ C++éƒ¨ç½²ï¼Œä½¿ç”¨å¹³å° rk3588ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ley-WL/ultralytics-rknn\"\u003eLey-WL/ultralytics-rknn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9bd6bf4ff8707afb5bca389e0d778fed2f4dd456966c7156e3b0b594cbb06a25/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c65792d574c2f756c7472616c79746963732d726b6e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9bd6bf4ff8707afb5bca389e0d778fed2f4dd456966c7156e3b0b594cbb06a25/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c65792d574c2f756c7472616c79746963732d726b6e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ley-WL/ultralytics-rknn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽultralytics-yolov8, å°†å…¶æ£€æµ‹/åˆ†ç±»/åˆ†å‰²/å§¿æ€ç­‰ä»»åŠ¡ç§»æ¤åˆ°rk3588ä¸Šã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/455670288/rknn-yolov8s-multi-thread-inference\"\u003e455670288/rknn-yolov8s-multi-thread-inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6c93a2ecfd9dd657253857a8cee46536856add009a8754f149d9dde64217eac1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3435353637303238382f726b6e6e2d796f6c6f7638732d6d756c74692d7468726561642d696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6c93a2ecfd9dd657253857a8cee46536856add009a8754f149d9dde64217eac1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3435353637303238382f726b6e6e2d796f6c6f7638732d6d756c74692d7468726561642d696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/455670288/rknn-yolov8s-multi-thread-inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov8såœ¨rk3588çš„æŽ¨ç†éƒ¨ç½²ï¼Œå¹¶ä½¿ç”¨å¤šçº¿ç¨‹æ± å¹¶è¡ŒnpuæŽ¨ç†åŠ é€Ÿã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/leafqycc/rknn-cpp-Multithreading\"\u003eleafqycc/rknn-cpp-Multithreading\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9febc2df204bd3ab181507d8ce079d023c4009e59c95e8fe3eeec003945542b3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c656166717963632f726b6e6e2d6370702d4d756c7469746872656164696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9febc2df204bd3ab181507d8ce079d023c4009e59c95e8fe3eeec003945542b3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c656166717963632f726b6e6e2d6370702d4d756c7469746872656164696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/leafqycc/rknn-cpp-Multithreading?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A simple demo of yolov5s running on rk3588/3588s using c++ (about 142 frames). / ä¸€ä¸ªä½¿ç”¨c++åœ¨rk3588/3588sä¸Šè¿è¡Œçš„yolov5sç®€å•demo(142å¸§/s)ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/leafqycc/rknn-multi-threaded\"\u003eleafqycc/rknn-multi-threaded\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2262a24a1c58019b2fb5dffcc5b739aeecdcb654e5ba6e0c1315db53fe57b5a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c656166717963632f726b6e6e2d6d756c74692d74687265616465643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2262a24a1c58019b2fb5dffcc5b739aeecdcb654e5ba6e0c1315db53fe57b5a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c656166717963632f726b6e6e2d6d756c74692d74687265616465643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/leafqycc/rknn-multi-threaded?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A simple demo of yolov5s running on rk3588/3588s using Python (about 72 frames). / ä¸€ä¸ªä½¿ç”¨Pythonåœ¨rk3588/3588sä¸Šè¿è¡Œçš„yolov5sç®€å•demo(å¤§çº¦72å¸§/s)ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wzxzhuxi/rknn-3588-npu-yolo-accelerate\"\u003ewzxzhuxi/rknn-3588-npu-yolo-accelerate\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a9d2310e28ac2c39c7dee1dff8d1d60aa63012c309f14cd848aef0a2e66a1c99/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f777a787a687578692f726b6e6e2d333538382d6e70752d796f6c6f2d616363656c65726174653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a9d2310e28ac2c39c7dee1dff8d1d60aa63012c309f14cd848aef0a2e66a1c99/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f777a787a687578692f726b6e6e2d333538382d6e70752d796f6c6f2d616363656c65726174653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wzxzhuxi/rknn-3588-npu-yolo-accelerate?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : rknn-3588éƒ¨ç½²yolov5ï¼Œåˆ©ç”¨çº¿ç¨‹æ± å®žçŽ°npuæŽ¨ç†åŠ é€Ÿï¼›Deploying YOLOv5 on RKNN-3588, utilizing a thread pool to achieve NPU inference acceleration.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kaylorchen/rk3588-yolo-demo\"\u003ekaylorchen/rk3588-yolo-demo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2ea197e2546a8c4ceff56564eff68524259d7afb5196f48aa063031a6fdfeb20/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b61796c6f726368656e2f726b333538382d796f6c6f2d64656d6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2ea197e2546a8c4ceff56564eff68524259d7afb5196f48aa063031a6fdfeb20/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b61796c6f726368656e2f726b333538382d796f6c6f2d64656d6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kaylorchen/rk3588-yolo-demo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The project is a multi-threaded inference demo of Yolo running on the RK3588 platform, which has been adapted for reading video files and camera feeds. The demo uses the Yolov8n model for file inference, with a maximum inference frame rate of up to 100 frames per second.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MontaukLaw/yolov5_3588_multi_thread\"\u003eMontaukLaw/yolov5_3588_multi_thread\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fcf234021ca5720a2973c524e760a551e24be96aec160c6600bc0d725d35edf6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f6e7461756b4c61772f796f6c6f76355f333538385f6d756c74695f7468726561643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fcf234021ca5720a2973c524e760a551e24be96aec160c6600bc0d725d35edf6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f6e7461756b4c61772f796f6c6f76355f333538385f6d756c74695f7468726561643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MontaukLaw/yolov5_3588_multi_thread?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : å¯åŠ¨å¤šçº¿ç¨‹, reluæ¿€æ´», 3588çš„yoloéƒ¨ç½², å¸§çŽ‡150ä»¥ä¸Š.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/crab2rab/RKNN-YOLOV5-BatchInference-MultiThreading\"\u003ecrab2rab/RKNN-YOLOV5-BatchInference-MultiThreading\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7b2cec4fea2d402004f9fde8060c8636599655896ec94f75fdde846910fa0cc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63726162327261622f524b4e4e2d594f4c4f56352d4261746368496e666572656e63652d4d756c7469546872656164696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7b2cec4fea2d402004f9fde8060c8636599655896ec94f75fdde846910fa0cc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63726162327261622f524b4e4e2d594f4c4f56352d4261746368496e666572656e63652d4d756c7469546872656164696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/crab2rab/RKNN-YOLOV5-BatchInference-MultiThreading?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : RKNN-YOLOV5-BatchInference-MultiThreadingYOLOV5å¤šå¼ å›¾ç‰‡å¤šçº¿ç¨‹C++æŽ¨ç†ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloV10-NPU\"\u003eQengineering/YoloV10-NPU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/303a2c99bb41e2a1094595f30b4bfeaaadc47e867feecc5d796562dea09a0540/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f5631302d4e50553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/303a2c99bb41e2a1094595f30b4bfeaaadc47e867feecc5d796562dea09a0540/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f5631302d4e50553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloV10-NPU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV10 NPU for the RK3566/68/88.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cqu20160901/yolov10_rknn_Cplusplus\"\u003ecqu20160901/yolov10_rknn_Cplusplus\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d1545aef12dcc02fee833975959a10af05512b984389b64f37bc1465d9989a8d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63717532303136303930312f796f6c6f7631305f726b6e6e5f43706c7573706c75733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d1545aef12dcc02fee833975959a10af05512b984389b64f37bc1465d9989a8d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63717532303136303930312f796f6c6f7631305f726b6e6e5f43706c7573706c75733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cqu20160901/yolov10_rknn_Cplusplus?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov10 ç‘žèŠ¯å¾® rknn æ¿ç«¯ C++éƒ¨ç½²ï¼Œä½¿ç”¨å¹³å° rk3588ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Zhou-sx/yolov5_Deepsort_rknn\"\u003eZhou-sx/yolov5_Deepsort_rknn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/07808ab2be52e7ea599b1a0f280918ab9ac8c9828ac317d6e3f73157c6b9cdfc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a686f752d73782f796f6c6f76355f44656570736f72745f726b6e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/07808ab2be52e7ea599b1a0f280918ab9ac8c9828ac317d6e3f73157c6b9cdfc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a686f752d73782f796f6c6f76355f44656570736f72745f726b6e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Zhou-sx/yolov5_Deepsort_rknn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Track vehicles and persons on rk3588 / rk3399pro.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Applied-Deep-Learning-Lab/Yolov5_RK3588\"\u003eApplied-Deep-Learning-Lab/Yolov5_RK3588\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/385e57389335c16cddd9709a51cc2c8504e699a178a66a91f2e9a24dd36aef1c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4170706c6965642d446565702d4c6561726e696e672d4c61622f596f6c6f76355f524b333538383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/385e57389335c16cddd9709a51cc2c8504e699a178a66a91f2e9a24dd36aef1c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4170706c6965642d446565702d4c6561726e696e672d4c61622f596f6c6f76355f524b333538383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Applied-Deep-Learning-Lab/Yolov5_RK3588?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov5_RK3588.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cqu20160901/yolov10_onnx_rknn_horizon_tensorRT\"\u003ecqu20160901/yolov10_onnx_rknn_horizon_tensorRT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5ce002e416b43788a94b8b646341cf82c6e55c463ed3553e11a205a580b18fea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63717532303136303930312f796f6c6f7631305f6f6e6e785f726b6e6e5f686f72697a6f6e5f74656e736f7252543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5ce002e416b43788a94b8b646341cf82c6e55c463ed3553e11a205a580b18fea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63717532303136303930312f796f6c6f7631305f6f6e6e785f726b6e6e5f686f72697a6f6e5f74656e736f7252543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cqu20160901/yolov10_onnx_rknn_horizon_tensorRT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov10 ç›®æ ‡æ£€æµ‹éƒ¨ç½²ç‰ˆæœ¬ï¼Œä¾¿äºŽç§»æ¤ä¸åŒå¹³å°ï¼ˆonnxã€tensorRTã€rknnã€Horizonï¼‰ï¼Œå…¨ç½‘éƒ¨ç½²æœ€ç®€å•ã€è¿è¡Œé€Ÿåº¦æœ€å¿«çš„éƒ¨ç½²æ–¹å¼ï¼ˆå…¨ç½‘é¦–å‘ï¼‰ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/icetd/RkYoloRtspServer\"\u003eicetd/RkYoloRtspServer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c55ce9603f82e112b04ea983b06c2ed244e0ea063ad311d1e8bd5af5b6061d32/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69636574642f526b596f6c6f527473705365727665723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c55ce9603f82e112b04ea983b06c2ed244e0ea063ad311d1e8bd5af5b6061d32/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69636574642f526b596f6c6f527473705365727665723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/icetd/RkYoloRtspServer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : simple yolov5 rtspserver for rk3588.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFPGA\u003c/h5\u003e\u003ca id=\"user-content-fpga\" class=\"anchor\" aria-label=\"Permalink: FPGA\" href=\"#fpga\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Xilinx/Vitis-AI/tree/master/demo\"\u003eXilinx/Vitis-AI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4c94f32044c8405aa56b21388a5b40815d886653f720ca946eb1ac4354c2f3d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f58696c696e782f56697469732d41493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4c94f32044c8405aa56b21388a5b40815d886653f720ca946eb1ac4354c2f3d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f58696c696e782f56697469732d41493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Xilinx/Vitis-AI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Vitis AI offers a unified set of high-level C++/Python programming APIs to run AI applications across edge-to-cloud platforms, including DPU for Alveo, and DPU for Zynq Ultrascale+ MPSoC and Zynq-7000. It brings the benefits to easily port AI applications from cloud to edge and vice versa. 10 samples in \u003ca href=\"https://github.com/Xilinx/Vitis-AI/tree/master/demo/VART\"\u003eVART Samples\u003c/a\u003e are available to help you get familiar with the unfied programming APIs. \u003ca href=\"https://github.com/Xilinx/Vitis-AI/tree/master/demo/Vitis-AI-Library\"\u003eVitis-AI-Library\u003c/a\u003e provides an easy-to-use and unified interface by encapsulating many efficient and high-quality neural networks.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tensil-ai/tensil\"\u003etensil-ai/tensil\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0706eeeef9d261e1e171873cffb4f9875c009c4f41877179d1ff36636a52fa12/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74656e73696c2d61692f74656e73696c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0706eeeef9d261e1e171873cffb4f9875c009c4f41877179d1ff36636a52fa12/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74656e73696c2d61692f74656e73696c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tensil-ai/tensil?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Open source machine learning accelerators. \u003ca href=\"https://www.tensil.ai/\" rel=\"nofollow\"\u003ewww.tensil.ai\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/19801201/SpinalHDL_CNN_Accelerator\"\u003e19801201/SpinalHDL_CNN_Accelerator\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6e49b43aef15ad5b12d53a1a3aa861293cc3d6332e0d9b3191af1f63d4fd1cca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f31393830313230312f5370696e616c48444c5f434e4e5f416363656c657261746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6e49b43aef15ad5b12d53a1a3aa861293cc3d6332e0d9b3191af1f63d4fd1cca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f31393830313230312f5370696e616c48444c5f434e4e5f416363656c657261746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/19801201/SpinalHDL_CNN_Accelerator?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : CNN accelerator implemented with Spinal HDL.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dhm2013724/yolov2_xilinx_fpga\"\u003edhm2013724/yolov2_xilinx_fpga\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f00aa2c85a8afcba3e0ffedb4974a88d7040786f4dbc9512a312327bd71b0ab6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64686d323031333732342f796f6c6f76325f78696c696e785f667067613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f00aa2c85a8afcba3e0ffedb4974a88d7040786f4dbc9512a312327bd71b0ab6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64686d323031333732342f796f6c6f76325f78696c696e785f667067613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dhm2013724/yolov2_xilinx_fpga?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv2 Accelerator in Xilinx's Zynq-7000 Soc(PYNQ-z2, Zedboard and ZCU102). (\u003cstrong\u003e\u003ca href=\"https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD\u0026amp;dbname=CMFDTEMP\u0026amp;filename=1019228234.nh\u0026amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoOGhUTzA5T0tESzdFZ2pyR1NJR1ZBaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!\u0026amp;v=MjE5NTN5dmdXN3JBVkYyNkY3RzZGdFBQcTVFYlBJUjhlWDFMdXhZUzdEaDFUM3FUcldNMUZyQ1VSTE9lWnVkdUY=\" rel=\"nofollow\"\u003eç¡•å£«è®ºæ–‡ 2019\u003c/a\u003e, \u003ca href=\"https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFQ\u0026amp;dbname=CJFDLAST2019\u0026amp;filename=DZJY201908009\u0026amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoOGhUTzA5T0tESzdFZ2pyR1NJR1ZBaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!\u0026amp;v=MDU0NDJDVVJMT2VadWR1Rnl2Z1c3ck1JVGZCZDdHNEg5ak1wNDlGYllSOGVYMUx1eFlTN0RoMVQzcVRyV00xRnI=\" rel=\"nofollow\"\u003eç”µå­æŠ€æœ¯åº”ç”¨ 2019\u003c/a\u003e, \u003ca href=\"https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFQ\u0026amp;dbname=CJFDTEMP\u0026amp;filename=KXTS201910005\u0026amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoOGhUTzA5T0tESzdFZ2pyR1NJR1ZBaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!\u0026amp;v=MjkwNzdXTTFGckNVUkxPZVp1ZHVGeXZnVzdyT0xqWGZmYkc0SDlqTnI0OUZZWVI4ZVgxTHV4WVM3RGgxVDNxVHI=\" rel=\"nofollow\"\u003eè®¡ç®—æœºç§‘å­¦ä¸ŽæŽ¢ç´¢ 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Yu-Zhewen/Tiny_YOLO_v3_ZYNQ\"\u003eYu-Zhewen/Tiny_YOLO_v3_ZYNQ\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7926885e41b34df6e228c8b714af9f4bedc43bbd524ef93e0462d25dc600dfde/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59752d5a686577656e2f54696e795f594f4c4f5f76335f5a594e513f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7926885e41b34df6e228c8b714af9f4bedc43bbd524ef93e0462d25dc600dfde/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59752d5a686577656e2f54696e795f594f4c4f5f76335f5a594e513f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Yu-Zhewen/Tiny_YOLO_v3_ZYNQ?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Implement Tiny YOLO v3 on ZYNQ. \"A Parameterisable FPGA-Tailored Architecture for YOLOv3-Tiny\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/chapter/10.1007/978-3-030-44534-8_25\" rel=\"nofollow\"\u003eARC 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HSqure/ultralytics-pt-yolov3-vitis-ai-edge\"\u003eHSqure/ultralytics-pt-yolov3-vitis-ai-edge\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f6b5be8ac9d083e68bbd318a5906955d1b9d188a7765890675589413fe659a9b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4853717572652f756c7472616c79746963732d70742d796f6c6f76332d76697469732d61692d656467653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f6b5be8ac9d083e68bbd318a5906955d1b9d188a7765890675589413fe659a9b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4853717572652f756c7472616c79746963732d70742d796f6c6f76332d76697469732d61692d656467653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HSqure/ultralytics-pt-yolov3-vitis-ai-edge?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This demo is only used for inference testing of Vitis AI v1.4 and quantitative compilation of DPU. It is compatible with the training results of \u003ca href=\"https://github.com/ultralytics/yolov3\"\u003eultralytics/yolov3\u003c/a\u003e v9.5.0 (it needs to use the model saving method of Pytorch V1.4).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mcedrdiego/Kria_yolov3_ppe\"\u003emcedrdiego/Kria_yolov3_ppe\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/77dbac1d0ddd4958a7c8399a550be18f66a9a6fca67a2295a863e3992d7fa131/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d63656472646965676f2f4b7269615f796f6c6f76335f7070653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/77dbac1d0ddd4958a7c8399a550be18f66a9a6fca67a2295a863e3992d7fa131/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d63656472646965676f2f4b7269615f796f6c6f76335f7070653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mcedrdiego/Kria_yolov3_ppe?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Kria KV260 Real-Time Personal Protective Equipment Detection. \"Deep Learning for Site Safety: Real-Time Detection of Personal Protective Equipment\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S0926580519308325\" rel=\"nofollow\"\u003eAutomation in Construction 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xlsjdjdk/Ship-Detection-based-on-YOLOv3-and-KV260\"\u003exlsjdjdk/Ship-Detection-based-on-YOLOv3-and-KV260\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/46e444d3963a9330fe2175dafcfe6935f096e59fd8f20a3f3cd75dd9ceca0079/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f786c736a646a646b2f536869702d446574656374696f6e2d62617365642d6f6e2d594f4c4f76332d616e642d4b563236303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/46e444d3963a9330fe2175dafcfe6935f096e59fd8f20a3f3cd75dd9ceca0079/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f786c736a646a646b2f536869702d446574656374696f6e2d62617365642d6f6e2d594f4c4f76332d616e642d4b563236303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xlsjdjdk/Ship-Detection-based-on-YOLOv3-and-KV260?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is the entry project of the Xilinx Adaptive Computing Challenge 2021. It uses YOLOv3 for ship target detection in optical remote sensing images, and deploys DPU on the KV260 platform to achieve hardware acceleration.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Pomiculture/YOLOv4-Vitis-AI\"\u003ePomiculture/YOLOv4-Vitis-AI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5d5400d006d023d1691aab4f7d537a5bba1c752a118c8a9e1917cf8438cc42fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506f6d6963756c747572652f594f4c4f76342d56697469732d41493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5d5400d006d023d1691aab4f7d537a5bba1c752a118c8a9e1917cf8438cc42fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506f6d6963756c747572652f594f4c4f76342d56697469732d41493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Pomiculture/YOLOv4-Vitis-AI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Custom YOLOv4 for apple recognition (clean/damaged) on Alveo U280 accelerator card using Vitis AI framework.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mkshuvo2/ZCU104_YOLOv3_Post_Processing\"\u003emkshuvo2/ZCU104_YOLOv3_Post_Processing\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/30bc6ed72362fa2e1f529284985697b26861824ee17a22778ed18c800e206c55/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6b736875766f322f5a43553130345f594f4c4f76335f506f73745f50726f63657373696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/30bc6ed72362fa2e1f529284985697b26861824ee17a22778ed18c800e206c55/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6b736875766f322f5a43553130345f594f4c4f76335f506f73745f50726f63657373696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mkshuvo2/ZCU104_YOLOv3_Post_Processing?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tensor outputs form Vitis AI Runner Class for YOLOv3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/puffdrum/v4tiny_pt_quant\"\u003epuffdrum/v4tiny_pt_quant\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e6c8a4491ff2be5386fcf8c2af7ace3f07de29ba5b221bc37142928737967a89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f707566666472756d2f763474696e795f70745f7175616e743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e6c8a4491ff2be5386fcf8c2af7ace3f07de29ba5b221bc37142928737967a89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f707566666472756d2f763474696e795f70745f7175616e743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/puffdrum/v4tiny_pt_quant?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : quantization for yolo with xilinx/vitis-ai-pytorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/chanshann/LITE_YOLOV3_TINY_VITISAI\"\u003echanshann/LITE_YOLOV3_TINY_VITISAI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/75ee010fc582b69eca3af1a177a82a4dcb88de846fa5300ec685301b94bc640a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368616e7368616e6e2f4c4954455f594f4c4f56335f54494e595f564954495341493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/75ee010fc582b69eca3af1a177a82a4dcb88de846fa5300ec685301b94bc640a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368616e7368616e6e2f4c4954455f594f4c4f56335f54494e595f564954495341493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/chanshann/LITE_YOLOV3_TINY_VITISAI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : LITE_YOLOV3_TINY_VITISAI.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LukiBa/zybo_yolo\"\u003eLukiBa/zybo_yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f9580c0619165e771e0c894e0a0f7c5ee6818b7edb5a99c3cf87defd9a7ab181/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c756b6942612f7a79626f5f796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f9580c0619165e771e0c894e0a0f7c5ee6818b7edb5a99c3cf87defd9a7ab181/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c756b6942612f7a79626f5f796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LukiBa/zybo_yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO example implementation using Intuitus CNN accelerator on ZYBO ZYNQ-7000 FPGA board.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/matsuda-slab/YOLO_ZYNQ_MASTER\"\u003ematsuda-slab/YOLO_ZYNQ_MASTER\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/195a81ce55ce91382f31dfdf1257708c68156345c2f88415b4b34d3ad7088c83/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6174737564612d736c61622f594f4c4f5f5a594e515f4d41535445523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/195a81ce55ce91382f31dfdf1257708c68156345c2f88415b4b34d3ad7088c83/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6174737564612d736c61622f594f4c4f5f5a594e515f4d41535445523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/matsuda-slab/YOLO_ZYNQ_MASTER?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Implementation of YOLOv3-tiny on FPGA.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FerberZhang/Yolov2-FPGA-CNN-\"\u003eFerberZhang/Yolov2-FPGA-CNN-\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2d9f0a57b49470c68ee90c060c8158ef044314e2ad319c49d9599265226f9336/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4665726265725a68616e672f596f6c6f76322d465047412d434e4e2d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2d9f0a57b49470c68ee90c060c8158ef044314e2ad319c49d9599265226f9336/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4665726265725a68616e672f596f6c6f76322d465047412d434e4e2d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FerberZhang/Yolov2-FPGA-CNN-?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A demo for accelerating YOLOv2 in xilinx's fpga PYNQ.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ChainZeeLi/FPGA_DPU\"\u003eChainZeeLi/FPGA_DPU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1c5dd5934a82e5c7c919e8d93b74595c605a12389e10f3f6be70904cda8a8392/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436861696e5a65654c692f465047415f4450553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1c5dd5934a82e5c7c919e8d93b74595c605a12389e10f3f6be70904cda8a8392/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436861696e5a65654c692f465047415f4450553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ChainZeeLi/FPGA_DPU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This project is to implement YOLO v3 on Xilinx FPGA with DPU.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xbdxwyh/yolov3_fpga_project\"\u003exbdxwyh/yolov3_fpga_project\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/51f01ebe58c9e0bca9c692f55212c9da111550f319d7cce7baa30954a55f1927/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f786264787779682f796f6c6f76335f667067615f70726f6a6563743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/51f01ebe58c9e0bca9c692f55212c9da111550f319d7cce7baa30954a55f1927/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f786264787779682f796f6c6f76335f667067615f70726f6a6563743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xbdxwyh/yolov3_fpga_project?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov3_fpga_project.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZLkanyo009/Yolo-compression-and-deployment-in-FPGA\"\u003eZLkanyo009/Yolo-compression-and-deployment-in-FPGA\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c07e32bdfb35d6bc2a35adea1cd4cae2345c06d92318fd4957e9449149ba9327/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a4c6b616e796f3030392f596f6c6f2d636f6d7072657373696f6e2d616e642d6465706c6f796d656e742d696e2d465047413f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c07e32bdfb35d6bc2a35adea1cd4cae2345c06d92318fd4957e9449149ba9327/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a4c6b616e796f3030392f596f6c6f2d636f6d7072657373696f6e2d616e642d6465706c6f796d656e742d696e2d465047413f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZLkanyo009/Yolo-compression-and-deployment-in-FPGA?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽFPGAé‡åŒ–çš„äººè„¸å£ç½©æ£€æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xiying-boy/yolov3-AX7350\"\u003exiying-boy/yolov3-AX7350\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d62bde51ec453c352b91557cac25f78d23c4f2c36a4a20a0a34293226a204f0e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f786979696e672d626f792f796f6c6f76332d4158373335303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d62bde51ec453c352b91557cac25f78d23c4f2c36a4a20a0a34293226a204f0e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f786979696e672d626f792f796f6c6f76332d4158373335303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xiying-boy/yolov3-AX7350?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽHLS_YOLOV3çš„é©±åŠ¨æ–‡ä»¶ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/himewel/yolowell\"\u003ehimewel/yolowell\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cd932cde45b0e6256e3bfd428d5bd335bd21b4d05c1777287a301ee8c256d32d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68696d6577656c2f796f6c6f77656c6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cd932cde45b0e6256e3bfd428d5bd335bd21b4d05c1777287a301ee8c256d32d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68696d6577656c2f796f6c6f77656c6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/himewel/yolowell?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A set of hardware architectures to build a co-design of convolutional neural networks inference at FPGA devices.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/embedeep/Free-TPU\"\u003eembedeep/Free-TPU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b178973a2fb2042677967163b0eda0c3f48765fe25239060d48a4cdd9cd65d36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656d6265646565702f467265652d5450553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b178973a2fb2042677967163b0eda0c3f48765fe25239060d48a4cdd9cd65d36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656d6265646565702f467265652d5450553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/embedeep/Free-TPU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Free TPU for FPGA with Lenet, MobileNet, Squeezenet, Resnet, Inception V3, YOLO V3, and ICNet. Deep learning acceleration using Xilinx zynq (Zedboard or ZC702 ) or kintex-7 to solve image classification, detection, and segmentation problem.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yarakigit/design_contest_yolo_change_ps_to_pl\"\u003eyarakigit/design_contest_yolo_change_ps_to_pl\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a378b98be334909e2d3f15d207f63c95c39a8803f8879d8ac3522b1f4bf54a5f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796172616b696769742f64657369676e5f636f6e746573745f796f6c6f5f6368616e67655f70735f746f5f706c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a378b98be334909e2d3f15d207f63c95c39a8803f8879d8ac3522b1f4bf54a5f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796172616b696769742f64657369676e5f636f6e746573745f796f6c6f5f6368616e67655f70735f746f5f706c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yarakigit/design_contest_yolo_change_ps_to_pl?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Converts pytorch yolo format weights to C header files for bare-metal (FPGA implementation).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MasLiang/CNN-On-FPGA\"\u003eMasLiang/CNN-On-FPGA\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/83121c4c89131dc9cf45df88eda0ab51c6e9b4e3efde9558f5be7d8f399749c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d61734c69616e672f434e4e2d4f6e2d465047413f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/83121c4c89131dc9cf45df88eda0ab51c6e9b4e3efde9558f5be7d8f399749c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d61734c69616e672f434e4e2d4f6e2d465047413f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MasLiang/CNN-On-FPGA?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is the code of the CNN on FPGA.But this can only be used for reference at present for some files are write coarsly using ISE.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/adamgallas/fpga_accelerator_yolov3tiny\"\u003eadamgallas/fpga_accelerator_yolov3tiny\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4fd0eee231a29d2ea75669b687d4445d51418e96f68a22c205a668c6666126ab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6164616d67616c6c61732f667067615f616363656c657261746f725f796f6c6f763374696e793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4fd0eee231a29d2ea75669b687d4445d51418e96f68a22c205a668c6666126ab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6164616d67616c6c61732f667067615f616363656c657261746f725f796f6c6f763374696e793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/adamgallas/fpga_accelerator_yolov3tiny?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : fpga_accelerator_yolov3tiny.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ylk678910/tiny-yolov3-fpga\"\u003eylk678910/tiny-yolov3-fpga\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6de0e5079fbf09681dc7688fc2bba5466c40eae0e56d4a7fe0be6eca8c47c70f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796c6b3637383931302f74696e792d796f6c6f76332d667067613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6de0e5079fbf09681dc7688fc2bba5466c40eae0e56d4a7fe0be6eca8c47c70f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796c6b3637383931302f74696e792d796f6c6f76332d667067613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ylk678910/tiny-yolov3-fpga?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Use an all-programmable SoC board to implement locating and tracking tasks. The hardware algorithm, a row-stationary-like strategy, can parallel calculate and reduce the storage buffer area on FPGA.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zhen8838/K210_Yolo_framework\"\u003ezhen8838/K210_Yolo_framework\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a7623e42bdb0f457861d1012fa301df4393f330144c30a98e5ab0ee023b89d67/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68656e383833382f4b3231305f596f6c6f5f6672616d65776f726b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a7623e42bdb0f457861d1012fa301df4393f330144c30a98e5ab0ee023b89d67/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68656e383833382f4b3231305f596f6c6f5f6672616d65776f726b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zhen8838/K210_Yolo_framework?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo v3 framework base on tensorflow, support multiple models, multiple datasets, any number of output layers, any number of anchors, model prune, and portable model to K210 !\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SEASKY-Master/SEASKY_K210\"\u003eSEASKY-Master/SEASKY_K210\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b83d2d73b18d4ef531f9b96ecaa6f4d829529cd3df85aab626a1df9bb6ca190c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f534541534b592d4d61737465722f534541534b595f4b3231303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b83d2d73b18d4ef531f9b96ecaa6f4d829529cd3df85aab626a1df9bb6ca190c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f534541534b592d4d61737465722f534541534b595f4b3231303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SEASKY-Master/SEASKY_K210?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : K210 PCB YOLO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SEASKY-Master/Yolo-for-k210\"\u003eSEASKY-Master/Yolo-for-k210\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/db5d9f38068f602381e58f4fccded95816044d18053bdf27381f3b6131f90085/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f534541534b592d4d61737465722f596f6c6f2d666f722d6b3231303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/db5d9f38068f602381e58f4fccded95816044d18053bdf27381f3b6131f90085/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f534541534b592d4d61737465722f596f6c6f2d666f722d6b3231303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SEASKY-Master/Yolo-for-k210?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo-for-k210.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TonyZ1Min/yolo-for-k210\"\u003eTonyZ1Min/yolo-for-k210\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cf41aaa6840e2781bd8a6b6d016c3fd6efe8785bafcfec128a4f844c7cf77d07/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f546f6e795a314d696e2f796f6c6f2d666f722d6b3231303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cf41aaa6840e2781bd8a6b6d016c3fd6efe8785bafcfec128a4f844c7cf77d07/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f546f6e795a314d696e2f796f6c6f2d666f722d6b3231303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TonyZ1Min/yolo-for-k210?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : keras-yolo-for-k210.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/vseasky/yolo-for-k210\"\u003evseasky/yolo-for-k210\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b2a81ca657f7d083760d9244b582bdf98f4b4ee9bba8d6e79775e6a4306cf497/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76736561736b792f796f6c6f2d666f722d6b3231303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b2a81ca657f7d083760d9244b582bdf98f4b4ee9bba8d6e79775e6a4306cf497/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76736561736b792f796f6c6f2d666f722d6b3231303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/vseasky/yolo-for-k210?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo-for-k210.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/InnoIPA/dpu-sc\"\u003eInnoIPA/dpu-sc\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2bd4df0e34d14bede104c4529198ff113a38d27f288f205e57fb4bc6ad338036/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e6e6f6970612f6470752d73633f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2bd4df0e34d14bede104c4529198ff113a38d27f288f205e57fb4bc6ad338036/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e6e6f6970612f6470752d73633f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/innoipa/dpu-sc?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : dpu-sc presented how to create quick demos to run AI inference(YOLOv4-Tiny, LPRNet) on DPU with MPSoC.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/InnoIPA/vaiGo\"\u003eInnoIPA/vaiGO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7c2dbaa1f1eafc570d8a4c0ab48354e16372d52347672706da4ba7d0c95584e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e6e6f6970612f766169474f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7c2dbaa1f1eafc570d8a4c0ab48354e16372d52347672706da4ba7d0c95584e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e6e6f6970612f766169474f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/innoipa/vaiGO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : vaiGO means Vitis-ai GO. We provide utility and tutorial that make it easy to convert a trained AI model into a bitstream that can be deployed on an FPGA Edge AI Box.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/InnoIPA/EXMU-X261-usermanual\"\u003eInnoIPA/EXMU-X261-usermanual\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b43e4cba45f22afa6075d1c8a4264c339985290eb938501cdfb6b728fb60b4db/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e6e6f6970612f65786d752d783236312d757365726d616e75616c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b43e4cba45f22afa6075d1c8a4264c339985290eb938501cdfb6b728fb60b4db/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e6e6f6970612f65786d752d783236312d757365726d616e75616c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/innoipa/exmu-x261-usermanual?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : We have built more defect detection solutions with YOLOv4-tiny on EXMU-X261.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOther Hardware\u003c/h5\u003e\u003ca id=\"user-content-other-hardware\" class=\"anchor\" aria-label=\"Permalink: Other Hardware\" href=\"#other-hardware\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/guichristmann/edge-tpu-tiny-yolo\"\u003eguichristmann/edge-tpu-tiny-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/efa3777710bb38efb87ce2be8b9c2f436fabaa9ee07abe1c6dae9d833c543e54/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6775696368726973746d616e6e2f656467652d7470752d74696e792d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/efa3777710bb38efb87ce2be8b9c2f436fabaa9ee07abe1c6dae9d833c543e54/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6775696368726973746d616e6e2f656467652d7470752d74696e792d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/guichristmann/edge-tpu-tiny-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Run Tiny YOLO-v3 on Google's Edge TPU USB Accelerator.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Charlie839242/-Trash-Classification-Car\"\u003eCharlie839242/-Trash-Classification-Car\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9d5a493de72f4220195559763acc69b80f191632b9ecf5fc29aa06037854faef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436861726c69653833393234322f2d54726173682d436c617373696669636174696f6e2d4361723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9d5a493de72f4220195559763acc69b80f191632b9ecf5fc29aa06037854faef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436861726c69653833393234322f2d54726173682d436c617373696669636174696f6e2d4361723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Charlie839242/-Trash-Classification-Car?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¿™æ˜¯ä¸€ä¸ªåŸºäºŽyolo-fastestæ¨¡åž‹çš„å°è½¦ï¼Œä¸»æŽ§æ˜¯art-piå¼€å‘æ¿ï¼Œä½¿ç”¨äº†rt threadæ“ä½œç³»ç»Ÿã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Charlie839242/Deploy-yolo-fastest-tflite-on-raspberry\"\u003eCharlie839242/Deploy-yolo-fastest-tflite-on-raspberry\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/52f26d4b3aa359569c10a4a0ad8f774664dd4dd9a2e5771173e1c457c0293667/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436861726c69653833393234322f4465706c6f792d796f6c6f2d666173746573742d74666c6974652d6f6e2d7261737062657272793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/52f26d4b3aa359569c10a4a0ad8f774664dd4dd9a2e5771173e1c457c0293667/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436861726c69653833393234322f4465706c6f792d796f6c6f2d666173746573742d74666c6974652d6f6e2d7261737062657272793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Charlie839242/Deploy-yolo-fastest-tflite-on-raspberry?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This project deploys a yolo fastest model in the form of tflite on raspberry 3b+.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mahxn0/Hisi3559A_Yolov5\"\u003emahxn0/Hisi3559A_Yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5dfab46b375c7aea8e7802af9b960d537191b5115479948849ce0b59e9b930f7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6168786e302f4869736933353539415f596f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5dfab46b375c7aea8e7802af9b960d537191b5115479948849ce0b59e9b930f7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6168786e302f4869736933353539415f596f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mahxn0/Hisi3559A_Yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽhisi3559açš„yolov5è®­ç»ƒéƒ¨ç½²å…¨æµç¨‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZhenxinYUAN/YOLO_hi3516Deploy\"\u003eZhenxinYUAN/YOLO_hi3516Deploy\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/181831c669692586726b833cbb803eb65842e4f4e1af56d8dc01eee7d67ff95e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68656e78696e5955414e2f594f4c4f5f6869333531364465706c6f793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/181831c669692586726b833cbb803eb65842e4f4e1af56d8dc01eee7d67ff95e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68656e78696e5955414e2f594f4c4f5f6869333531364465706c6f793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZhenxinYUAN/YOLO_hi3516Deploy?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Deploy Yolo series algorithms on Hisilicon platform hi3516, including yolov3, yolov5, yolox, etc.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jveitchmichaelis/edgetpu-yolo\"\u003ejveitchmichaelis/edgetpu-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d50e3882a1a786d9728ec69f86057d6f2b40451a8f3b96403f8b7c22ea8ae622/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a7665697463686d69636861656c69732f656467657470752d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d50e3882a1a786d9728ec69f86057d6f2b40451a8f3b96403f8b7c22ea8ae622/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a7665697463686d69636861656c69732f656467657470752d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jveitchmichaelis/edgetpu-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Minimal-dependency Yolov5 export and inference demonstration for the Google Coral EdgeTPU.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xiaqing10/Hisi_YoLoV5\"\u003exiaqing10/Hisi_YoLoV5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/96e6349577d188b8d65229f84ab7e8cb9cd41ea0a1c7b80a21fe13a0a2083115/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78696171696e6731302f486973695f596f4c6f56353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/96e6349577d188b8d65229f84ab7e8cb9cd41ea0a1c7b80a21fe13a0a2083115/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78696171696e6731302f486973695f596f4c6f56353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xiaqing10/Hisi_YoLoV5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : æµ·æ€nnieè·‘yolov5ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BaronLeeLZP/hi3516dv300_nnie-yolov3-demo\"\u003eBaronLeeLZP/hi3516dv300_nnie-yolov3-demo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/387c424f009adc0397388d36250080046b4643640da7c9f00c05ef4df1d1636c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4261726f6e4c65654c5a502f68693335313664763330305f6e6e69652d796f6c6f76332d64656d6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/387c424f009adc0397388d36250080046b4643640da7c9f00c05ef4df1d1636c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4261726f6e4c65654c5a502f68693335313664763330305f6e6e69652d796f6c6f76332d64656d6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BaronLeeLZP/hi3516dv300_nnie-yolov3-demo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åœ¨æµ·æ€Hisiliconçš„Hi3516dv300èŠ¯ç‰‡ä¸Šï¼Œåˆ©ç”¨nnieå’Œopencvåº“ï¼Œç®€æ´äº†å®˜æ–¹yolov3ç”¨ä¾‹ä¸­å„ç§å¤æ‚çš„åµŒå¥—è°ƒç”¨/å¤æ‚ç¼–è¯‘ï¼Œæä¾›äº†äº¤å‰ç¼–è¯‘åŽå¯æˆåŠŸä¸Šæ¿éƒ¨ç½²è¿è¡Œçš„demoã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/OpenVINO-dev-contest/YOLOv7_OpenVINO\"\u003eOpenVINO-dev-contest/YOLOv7_OpenVINO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/39563e830c4e0564f74a379e4333afc9a894e3ad978371587893ae5ba11d614c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f70656e56494e4f2d6465762d636f6e746573742f594f4c4f76375f4f70656e56494e4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/39563e830c4e0564f74a379e4333afc9a894e3ad978371587893ae5ba11d614c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f70656e56494e4f2d6465762d636f6e746573742f594f4c4f76375f4f70656e56494e4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/OpenVINO-dev-contest/YOLOv7_OpenVINO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository will demostrate how to deploy a offical YOLOv7 pre-trained model with OpenVINO runtime api.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/littledeep/YOLOv5-RK3399Pro\"\u003elittledeep/YOLOv5-RK3399Pro\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6041cbcf1f1cc328a38e497b1f181f64a2a9ecaa3cbe959bd713f06301a6bad8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6974746c65646565702f594f4c4f76352d524b3333393950726f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6041cbcf1f1cc328a38e497b1f181f64a2a9ecaa3cbe959bd713f06301a6bad8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6974746c65646565702f594f4c4f76352d524b3333393950726f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/littledeep/YOLOv5-RK3399Pro?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PyTorch--\u0026gt;ONNX--\u0026gt;RKNN.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jnulzl/YOLOV5_RK1126\"\u003ejnulzl/YOLOV5_RK1126\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cdbd0d4adb78e2f80b5cc9c3cecd6cb0055b4b207bf0419ad38adbba4b373f9e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a6e756c7a6c2f594f4c4f56355f524b313132363f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cdbd0d4adb78e2f80b5cc9c3cecd6cb0055b4b207bf0419ad38adbba4b373f9e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a6e756c7a6c2f594f4c4f56355f524b313132363f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jnulzl/YOLOV5_RK1126?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5 rk1126 cpp code.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloCam\"\u003eQengineering/YoloCam\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b04463f0a9e4991031f990a1e4274c64c4754ee1872cc27480f28ce8fdf40f85/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f43616d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b04463f0a9e4991031f990a1e4274c64c4754ee1872cc27480f28ce8fdf40f85/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f43616d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloCam?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : AI camera with live feed, email notification, Gdrive storage and event-triggered GPIO. Raspberry Pi stand-alone AI-powered camera with live feed, email notification and event-triggered cloud storage.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LSH9832/edgeyolo\"\u003eLSH9832/edgeyolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/71bfe61077c58d0fa253ac07bd7e94e96e3eb3b1b3c7e62400b70a761da7664b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5348393833322f65646765796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/71bfe61077c58d0fa253ac07bd7e94e96e3eb3b1b3c7e62400b70a761da7664b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5348393833322f65646765796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LSH9832/edgeyolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : an edge-real-time anchor-free object detector with decent performance.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/liuyuan000/Rv1126_YOLOv5-Lite\"\u003eliuyuan000/Rv1126_YOLOv5-Lite\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/94588fb5930eed5deb0294ec3807faa87969028fdbd24fd94d38e76bf34fd1eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c69757975616e3030302f5276313132365f594f4c4f76352d4c6974653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/94588fb5930eed5deb0294ec3807faa87969028fdbd24fd94d38e76bf34fd1eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c69757975616e3030302f5276313132365f594f4c4f76352d4c6974653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/liuyuan000/Rv1126_YOLOv5-Lite?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5-Liteåœ¨Rv1126éƒ¨ç½²ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003ePruning Knoweldge-Distillation Quantization\u003c/h3\u003e\u003ca id=\"user-content-pruning-knoweldge-distillation-quantization\" class=\"anchor\" aria-label=\"Permalink: Pruning Knoweldge-Distillation Quantization\" href=\"#pruning-knoweldge-distillation-quantization\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003ePruning\u003c/h5\u003e\u003ca id=\"user-content-pruning\" class=\"anchor\" aria-label=\"Permalink: Pruning\" href=\"#pruning\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch6 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eå‰ªæž\u003c/h6\u003e\u003ca id=\"user-content-å‰ªæž\" class=\"anchor\" aria-label=\"Permalink: å‰ªæž\" href=\"#å‰ªæž\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/VainF/Torch-Pruning\"\u003eTorch-Pruning\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/26313a3ae281feb15c55af3831ca95e4e815b16300f8f52dcf9cc7b6bfe34ccd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5661696e462f546f7263682d5072756e696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/26313a3ae281feb15c55af3831ca95e4e815b16300f8f52dcf9cc7b6bfe34ccd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5661696e462f546f7263682d5072756e696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/VainF/Torch-Pruning?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Towards Any Structural Pruning; LLMs / SAM / Diffusion / Transformers / YOLOv8 / CNNs. \"Towards Any Structural Pruning\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2023/html/Fang_DepGraph_Towards_Any_Structural_Pruning_CVPR_2023_paper.html\" rel=\"nofollow\"\u003eCVPR 2023\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/neuralmagic/sparseml\"\u003eSparseML\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5d22918f22530481a41d0f7a9554e6a0e3d23dbbfdd76c8a1ca6fa9ea1f8aa1c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e657572616c6d616769632f7370617273656d6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5d22918f22530481a41d0f7a9554e6a0e3d23dbbfdd76c8a1ca6fa9ea1f8aa1c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e657572616c6d616769632f7370617273656d6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/neuralmagic/sparseml?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Libraries for applying sparsification recipes to neural networks with a few lines of code, enabling faster and smaller models. \"Inducing and Exploiting Activation Sparsity for Fast Inference on Deep Neural Networks\". (\u003cstrong\u003e\u003ca href=\"http://proceedings.mlr.press/v119/kurtz20a.html\" rel=\"nofollow\"\u003ePMLR 2020\u003c/a\u003e\u003c/strong\u003e). \"Woodfisher: Efficient second-order approximation for neural network compression\". (\u003cstrong\u003e\u003ca href=\"https://proceedings.neurips.cc/paper/2020/hash/d1ff1ec86b62cd5f3903ff19c3a326b2-Abstract.html\" rel=\"nofollow\"\u003eNeurIPS 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/neuralmagic/sparsezoo\"\u003eSparseZoo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0569a447a00a2ae81db6e5cf5268e6b961cf9d651a8b031020b9b131c16ccfc8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e657572616c6d616769632f7370617273657a6f6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0569a447a00a2ae81db6e5cf5268e6b961cf9d651a8b031020b9b131c16ccfc8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e657572616c6d616769632f7370617273657a6f6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/neuralmagic/sparsezoo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Neural network model repository for highly sparse and sparse-quantized models with matching sparsification recipes.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Gumpest/YOLOv5-Multibackbone-Compression\"\u003eGumpest/YOLOv5-Multibackbone-Compression\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/04710cf8e6cdbf63c0ae368af6561c7b847ebc43c77af004d38ec3a0906fcb8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f47756d706573742f594f4c4f76352d4d756c74696261636b626f6e652d436f6d7072657373696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/04710cf8e6cdbf63c0ae368af6561c7b847ebc43c77af004d38ec3a0906fcb8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f47756d706573742f594f4c4f76352d4d756c74696261636b626f6e652d436f6d7072657373696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Gumpest/YOLOv5-Multibackbone-Compression?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 Series Multi-backbone(TPH-YOLOv5, Ghostnet, ShuffleNetv2, Mobilenetv3Small, EfficientNetLite, PP-LCNet, SwinTransformer YOLO), Module(CBAM, DCN), Pruning (EagleEye, Network Slimming) and Quantization (MQBench) Compression Tool Box.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PengyiZhang/SlimYOLOv3\"\u003eSlimYOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/60f1be5d6eb3b7c85ee162255aa9e2da0d54b40f09dc485788f84ce211150617/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f50656e6779695a68616e672f536c696d594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/60f1be5d6eb3b7c85ee162255aa9e2da0d54b40f09dc485788f84ce211150617/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f50656e6779695a68616e672f536c696d594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PengyiZhang/SlimYOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"SlimYOLOv3: Narrower, Faster and Better for UAV Real-Time Applications\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1907.11093\" rel=\"nofollow\"\u003earXiv 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/uyzhang/yolov5_prune\"\u003euyzhang/yolov5_prune\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2bc43c70e9e490bb7714929e1fa7b867f7d772c799805776dda92c87a1888f4b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f75797a68616e672f796f6c6f76355f7072756e653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2bc43c70e9e490bb7714929e1fa7b867f7d772c799805776dda92c87a1888f4b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f75797a68616e672f796f6c6f76355f7072756e653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/uyzhang/yolov5_prune?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov5 pruning on COCO Dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/midasklr/yolov5prune\"\u003emidasklr/yolov5prune\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/106028c0821ae08c806ee81ae19c3a44127d7865a8647cb8bc6dad4fb78d8e37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696461736b6c722f796f6c6f76357072756e653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/106028c0821ae08c806ee81ae19c3a44127d7865a8647cb8bc6dad4fb78d8e37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696461736b6c722f796f6c6f76357072756e653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/midasklr/yolov5prune?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5æ¨¡åž‹å‰ªæžã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZJU-lishuang/yolov5_prune\"\u003eZJU-lishuang/yolov5_prune\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3e77b29a43a54e55e855d0f7f599554fd74ec71ba1de723fe6ad537cbdb2037c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a4a552d6c69736875616e672f796f6c6f76355f7072756e653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3e77b29a43a54e55e855d0f7f599554fd74ec71ba1de723fe6ad537cbdb2037c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a4a552d6c69736875616e672f796f6c6f76355f7072756e653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZJU-lishuang/yolov5_prune?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5 pruneï¼ŒSupport V2, V3, V4 and V6 versions of yolov5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sbbug/yolov5-prune-multi\"\u003esbbug/yolov5-prune-multi\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fdc36aef5293e32de32beb1c725c90385b92bb8aa551a9d7f9f6a993a2fb2776/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73626275672f796f6c6f76352d7072756e652d6d756c74693f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fdc36aef5293e32de32beb1c725c90385b92bb8aa551a9d7f9f6a993a2fb2776/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73626275672f796f6c6f76352d7072756e652d6d756c74693f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sbbug/yolov5-prune-multi?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5-prune-multi æ— äººæœºè§†è§’ã€å¤šæ¨¡æ€ã€æ¨¡åž‹å‰ªæžã€å›½äº§AIèŠ¯ç‰‡éƒ¨ç½²ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Syencil/mobile-yolov5-pruning-distillation\"\u003eSyencil/mobile-yolov5-pruning-distillation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b9c889b2d1a7be771d63520941900575d216b46e622b5e5f09ce30d99f276059/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5379656e63696c2f6d6f62696c652d796f6c6f76352d7072756e696e672d64697374696c6c6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b9c889b2d1a7be771d63520941900575d216b46e622b5e5f09ce30d99f276059/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5379656e63696c2f6d6f62696c652d796f6c6f76352d7072756e696e672d64697374696c6c6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Syencil/mobile-yolov5-pruning-distillation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : mobilev2-yolov5så‰ªæžã€è’¸é¦ï¼Œæ”¯æŒncnnï¼ŒtensorRTéƒ¨ç½²ã€‚ultra-light but better performenceï¼\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Lam1360/YOLOv3-model-pruning\"\u003eLam1360/YOLOv3-model-pruning\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/adab704eefaf5d12126e6be51a92cf853cc859b452670ce1c3fde422cc9ebd0b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c616d313336302f594f4c4f76332d6d6f64656c2d7072756e696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/adab704eefaf5d12126e6be51a92cf853cc859b452670ce1c3fde422cc9ebd0b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c616d313336302f594f4c4f76332d6d6f64656c2d7072756e696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Lam1360/YOLOv3-model-pruning?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åœ¨ oxford hand æ•°æ®é›†ä¸Šå¯¹ YOLOv3 åšæ¨¡åž‹å‰ªæžï¼ˆnetwork slimmingï¼‰ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tanluren/yolov3-channel-and-layer-pruning\"\u003etanluren/yolov3-channel-and-layer-pruning\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e524d748e4584e86cfa9021117c669415dfd55a815f5da09d52d31b4a977c664/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616e6c7572656e2f796f6c6f76332d6368616e6e656c2d616e642d6c617965722d7072756e696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e524d748e4584e86cfa9021117c669415dfd55a815f5da09d52d31b4a977c664/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616e6c7572656e2f796f6c6f76332d6368616e6e656c2d616e642d6c617965722d7072756e696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tanluren/yolov3-channel-and-layer-pruning?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov3 yolov4 channel and layer pruning, Knowledge Distillation å±‚å‰ªæžï¼Œé€šé“å‰ªæžï¼ŒçŸ¥è¯†è’¸é¦ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/coldlarry/YOLOv3-complete-pruning\"\u003ecoldlarry/YOLOv3-complete-pruning\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c88376ed6e4b7d58bccd269446a48fbcfe6614b80d624e48624565565583aea6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636f6c646c617272792f594f4c4f76332d636f6d706c6574652d7072756e696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c88376ed6e4b7d58bccd269446a48fbcfe6614b80d624e48624565565583aea6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636f6c646c617272792f594f4c4f76332d636f6d706c6574652d7072756e696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/coldlarry/YOLOv3-complete-pruning?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : æä¾›å¯¹YOLOv3åŠTinyçš„å¤šç§å‰ªæžç‰ˆæœ¬ï¼Œä»¥é€‚åº”ä¸åŒçš„éœ€æ±‚ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SpursLipu/YOLOv3v4-ModelCompression-MultidatasetTraining-Multibackbone\"\u003eSpursLipu/YOLOv3v4-ModelCompression-MultidatasetTraining-Multibackbone\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fc3ea6513f9e95a4e9df262ed07ef43157f00af1b7d06336e81aa89a12572a52/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53707572734c6970752f594f4c4f763376342d4d6f64656c436f6d7072657373696f6e2d4d756c746964617461736574547261696e696e672d4d756c74696261636b626f6e653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fc3ea6513f9e95a4e9df262ed07ef43157f00af1b7d06336e81aa89a12572a52/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53707572734c6970752f594f4c4f763376342d4d6f64656c436f6d7072657373696f6e2d4d756c746964617461736574547261696e696e672d4d756c74696261636b626f6e653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SpursLipu/YOLOv3v4-ModelCompression-MultidatasetTraining-Multibackbone?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO ModelCompression MultidatasetTraining.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/talebolano/yolov3-network-slimming\"\u003etalebolano/yolov3-network-slimming\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c040e023bec22cadbfb6fe2e3f24500e8a27ebd231e2e16860d65559532613ce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616c65626f6c616e6f2f796f6c6f76332d6e6574776f726b2d736c696d6d696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c040e023bec22cadbfb6fe2e3f24500e8a27ebd231e2e16860d65559532613ce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616c65626f6c616e6f2f796f6c6f76332d6e6574776f726b2d736c696d6d696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/talebolano/yolov3-network-slimming?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov3 network slimmingå‰ªæžçš„ä¸€ç§å®žçŽ°ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Bigtuo/YOLOX-Lite\"\u003eBigtuo/YOLOX-Lite\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7d74cb970e82c96e7157ba474b389b1c859e0f69b910ad8305fc25d5a88ce6e1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42696774756f2f594f4c4f582d4c6974653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7d74cb970e82c96e7157ba474b389b1c859e0f69b910ad8305fc25d5a88ce6e1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42696774756f2f594f4c4f582d4c6974653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Bigtuo/YOLOX-Lite?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : å°†YOLOv5-Liteä»£ç ä¸­çš„headæ›´æ¢ä¸ºYOLOX headã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/YINYIPENG-EN/Pruning_for_YOLOV5_pytorch\"\u003eYINYIPENG-EN/Pruning_for_YOLOV5_pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/00fab67dce2cbcacea577e5852f02db8eb0d86c74f494614f02aecac075df191/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59494e594950454e472d454e2f5072756e696e675f666f725f594f4c4f56355f7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/00fab67dce2cbcacea577e5852f02db8eb0d86c74f494614f02aecac075df191/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59494e594950454e472d454e2f5072756e696e675f666f725f594f4c4f56355f7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/YINYIPENG-EN/Pruning_for_YOLOV5_pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Pruning_for_YOLOV5_pytorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/chumingqian/Model_Compression_For_YOLOV3-V4\"\u003echumingqian/Model_Compression_For_YOLOV3-V4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a92f7de1f7ffce5256b74530ab268db7dcddd760f06d8f52907d7f143a646a7b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368756d696e677169616e2f4d6f64656c5f436f6d7072657373696f6e5f466f725f594f4c4f56332d56343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a92f7de1f7ffce5256b74530ab268db7dcddd760f06d8f52907d7f143a646a7b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368756d696e677169616e2f4d6f64656c5f436f6d7072657373696f6e5f466f725f594f4c4f56332d56343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/chumingqian/Model_Compression_For_YOLOV3-V4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : In this repository using the dynamic sparse training( variable sparse rate s which can speed up the sparse training process), channel pruning and knowledge distilling for YOLOV3 and YOLOV4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xhwNobody/yolov5_prune_sfp\"\u003exhwNobody/yolov5_prune_sfp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/408edb28d9c15a203f951733ceb9eb372e1d48676613e1b76176e92c4a57d949/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7868774e6f626f64792f796f6c6f76355f7072756e655f7366703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/408edb28d9c15a203f951733ceb9eb372e1d48676613e1b76176e92c4a57d949/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7868774e6f626f64792f796f6c6f76355f7072756e655f7366703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xhwNobody/yolov5_prune_sfp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽSFPå’ŒFPGMçš„yolov5çš„è½¯å‰ªæžå®žçŽ°ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eQuantization\u003c/h5\u003e\u003ca id=\"user-content-quantization\" class=\"anchor\" aria-label=\"Permalink: Quantization\" href=\"#quantization\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch6 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eé‡åŒ–\u003c/h6\u003e\u003ca id=\"user-content-é‡åŒ–\" class=\"anchor\" aria-label=\"Permalink: é‡åŒ–\" href=\"#é‡åŒ–\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dog-qiuqiu/FastestDet\"\u003edog-qiuqiu/FastestDet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/53f603509725d740b5bddfcecc71a9b3195d0747d56418f449d98457c60df25d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f672d7169757169752f466173746573744465743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/53f603509725d740b5bddfcecc71a9b3195d0747d56418f449d98457c60df25d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f672d7169757169752f466173746573744465743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dog-qiuqiu/FastestDet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : âš¡ A newly designed ultra lightweight anchor free target detection algorithmï¼Œ weight only 250K parametersï¼Œ reduces the time consumption by 10% compared with yolo-fastest, and the post-processing is simpler. \"çŸ¥ä¹Žã€Œé©¬é›ªæµ©ã€ã€Š\u003ca href=\"https://zhuanlan.zhihu.com/p/536500269\" rel=\"nofollow\"\u003eFastestDet: æ¯”yolo-fastestæ›´å¿«ï¼æ›´å¼ºï¼æ›´ç®€å•ï¼å…¨æ–°è®¾è®¡çš„è¶…å®žæ—¶Anchor-freeç›®æ ‡æ£€æµ‹ç®—æ³•\u003c/a\u003eã€‹\"ã€‚ \"å¾®ä¿¡å…¬ä¼—å·ã€Œè®¡ç®—æœºè§†è§‰ç ”ç©¶é™¢ã€ã€Š\u003ca href=\"https://mp.weixin.qq.com/s/Bskc5WQd8ujy16Jl4qekjQ\" rel=\"nofollow\"\u003eFastestDetï¼šæ¯”yolov5æ›´å¿«ï¼æ›´å¼ºï¼å…¨æ–°è®¾è®¡çš„è¶…å®žæ—¶Anchor-freeç›®æ ‡æ£€æµ‹ç®—æ³•ï¼ˆé™„æºä»£ç ä¸‹è½½ï¼‰\u003c/a\u003eã€‹\"ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dog-qiuqiu/Yolo-Fastest\"\u003edog-qiuqiu/Yolo-Fastest\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7e83a9551c56e26ead9bca9a8358587750c98f2398466b9b09a02a09c8afb800/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f672d7169757169752f596f6c6f2d466173746573743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7e83a9551c56e26ead9bca9a8358587750c98f2398466b9b09a02a09c8afb800/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f672d7169757169752f596f6c6f2d466173746573743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dog-qiuqiu/Yolo-Fastest?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo-Fastestï¼šè¶…è¶…è¶…å¿«çš„å¼€æºARMå®žæ—¶ç›®æ ‡æ£€æµ‹ç®—æ³•ã€‚ \u003ca href=\"http://doi.org/10.5281/zenodo.5131532\" rel=\"nofollow\"\u003eZenodo 2021\u003c/a\u003e. \"çŸ¥ä¹Žã€Œé©¬é›ªæµ©ã€ã€Š\u003ca href=\"https://zhuanlan.zhihu.com/p/234506503\" rel=\"nofollow\"\u003eYolo-Fastestï¼šè¶…è¶…è¶…å¿«çš„å¼€æºARMå®žæ—¶ç›®æ ‡æ£€æµ‹ç®—æ³•\u003c/a\u003eã€‹\"ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dog-qiuqiu/Yolo-FastestV2\"\u003edog-qiuqiu/Yolo-FastestV2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4b0ff101ff8457436ab8bc45e422f7fd467e968a956376c5f0364c0042f9fe38/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f672d7169757169752f596f6c6f2d4661737465737456323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4b0ff101ff8457436ab8bc45e422f7fd467e968a956376c5f0364c0042f9fe38/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f672d7169757169752f596f6c6f2d4661737465737456323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dog-qiuqiu/Yolo-FastestV2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo-FastestV2:æ›´å¿«ï¼Œæ›´è½»ï¼Œç§»åŠ¨ç«¯å¯è¾¾300FPSï¼Œå‚æ•°é‡ä»…250kã€‚ \"çŸ¥ä¹Žã€Œé©¬é›ªæµ©ã€ã€Š\u003ca href=\"https://zhuanlan.zhihu.com/p/400474142\" rel=\"nofollow\"\u003eYolo-FastestV2:æ›´å¿«ï¼Œæ›´è½»ï¼Œç§»åŠ¨ç«¯å¯è¾¾300FPSï¼Œå‚æ•°é‡ä»…250k\u003c/a\u003eã€‹\"ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nightsnack/YOLObile\"\u003eYOLObile\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/867866669c1fa1a72547c272bd96b4d1083bf0a84fe75e855118ead5d60b2bd5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e69676874736e61636b2f594f4c4f62696c653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/867866669c1fa1a72547c272bd96b4d1083bf0a84fe75e855118ead5d60b2bd5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e69676874736e61636b2f594f4c4f62696c653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nightsnack/YOLObile?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLObile: Real-Time Object Detection on Mobile Devices via Compression-Compilation Co-Design\". (\u003cstrong\u003e\u003ca href=\"https://www.aaai.org/AAAI21Papers/AAAI-7561.CaiY.pdf\" rel=\"nofollow\"\u003eAAAI 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PaddlePaddle/PaddleSlim\"\u003ePaddleSlim\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/50e1dc85cbb577e409532041fb7724eb255d21186318b9ccf63e37b82ee9d9d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506164646c65506164646c652f506164646c65536c696d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/50e1dc85cbb577e409532041fb7724eb255d21186318b9ccf63e37b82ee9d9d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506164646c65506164646c652f506164646c65536c696d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PaddlePaddle/PaddleSlim?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PaddleSlim is an open-source library for deep model compression and architecture search. PaddleSlimæ˜¯ä¸€ä¸ªä¸“æ³¨äºŽæ·±åº¦å­¦ä¹ æ¨¡åž‹åŽ‹ç¼©çš„å·¥å…·åº“ï¼Œæä¾›ä½Žæ¯”ç‰¹é‡åŒ–ã€çŸ¥è¯†è’¸é¦ã€ç¨€ç–åŒ–å’Œæ¨¡åž‹ç»“æž„æœç´¢ç­‰æ¨¡åž‹åŽ‹ç¼©ç­–ç•¥ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿå®žçŽ°æ¨¡åž‹çš„å°åž‹åŒ–ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/openppl-public/ppq\"\u003ePPLé‡åŒ–å·¥å…·\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/595ea2f61dc569ac82b26d2f88e4fbdd4bfb4cb76977bf2d2903f75c8e16744d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e70706c2d7075626c69632f7070713f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/595ea2f61dc569ac82b26d2f88e4fbdd4bfb4cb76977bf2d2903f75c8e16744d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e70706c2d7075626c69632f7070713f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/openppl-public/ppq?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PPL Quantization Tool (PPQ) is a powerful offline neural network quantization tool. PPL QuantTool æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„å·¥ä¸šçº§ç¥žç»ç½‘ç»œé‡åŒ–å·¥å…·ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PINTO0309/PINTO_model_zoo\"\u003ePINTO_model_zoo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a07bbba10382a37793334c5ef7e0bd772fa44a34bf98307a494c8713e820770f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f50494e544f303330392f50494e544f5f6d6f64656c5f7a6f6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a07bbba10382a37793334c5ef7e0bd772fa44a34bf98307a494c8713e820770f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f50494e544f303330392f50494e544f5f6d6f64656c5f7a6f6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PINTO0309/PINTO_model_zoo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A repository for storing models that have been inter-converted between various frameworks. Supported frameworks are TensorFlow, PyTorch, ONNX, OpenVINO, TFJS, TFTRT, TensorFlowLite (Float32/16/INT8), EdgeTPU, CoreML.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ppogg/YOLOv5-Lite\"\u003eppogg/YOLOv5-Lite\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/810011f170f0e6bfd755f8cd0912178ae5422cf71aa5dcf3364ccddf3033b541/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70706f67672f594f4c4f76352d4c6974653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/810011f170f0e6bfd755f8cd0912178ae5422cf71aa5dcf3364ccddf3033b541/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70706f67672f594f4c4f76352d4c6974653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ppogg/YOLOv5-Lite?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ…ðŸ…ðŸ…YOLOv5-Lite: lighter, faster and easier to deploy. Evolved from yolov5 and the size of model is only 930+kb (int8) and 1.7M (fp16). It can reach 10+ FPS on the Raspberry Pi 4B when the input size is 320Ã—320~\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlexeyAB/yolo2_light\"\u003eAlexeyAB/yolo2_light\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f390aefef82d381043eed0ef21785c38158335acf13cb84f9809daf987d705a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f796f6c6f325f6c696768743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f390aefef82d381043eed0ef21785c38158335acf13cb84f9809daf987d705a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f796f6c6f325f6c696768743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlexeyAB/yolo2_light?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Light version of convolutional neural network Yolo v3 \u0026amp; v2 for objects detection with a minimum of dependencies (INT8-inference, BIT1-XNOR-inference).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eKnoweldge-Distillation\u003c/h5\u003e\u003ca id=\"user-content-knoweldge-distillation\" class=\"anchor\" aria-label=\"Permalink: Knoweldge-Distillation\" href=\"#knoweldge-distillation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch6 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eçŸ¥è¯†è’¸é¦\u003c/h6\u003e\u003ca id=\"user-content-çŸ¥è¯†è’¸é¦\" class=\"anchor\" aria-label=\"Permalink: çŸ¥è¯†è’¸é¦\" href=\"#çŸ¥è¯†è’¸é¦\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yoshitomo-matsubara/torchdistill\"\u003etorchdistill\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5b5846f149878674f9c644a2257422625e0ec1de4c9ff0d40387323a3cb3cb07/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796f736869746f6d6f2d6d61747375626172612f746f72636864697374696c6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5b5846f149878674f9c644a2257422625e0ec1de4c9ff0d40387323a3cb3cb07/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796f736869746f6d6f2d6d61747375626172612f746f72636864697374696c6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yoshitomo-matsubara/torchdistill?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : torchdistill: A Modular, Configuration-Driven Framework for Knowledge Distillation. A coding-free framework built on PyTorch for reproducible deep learning studies. ðŸ†20 knowledge distillation methods presented at CVPR, ICLR, ECCV, NeurIPS, ICCV, etc are implemented so far. ðŸŽ Trained models, training logs and configurations are available for ensuring the reproducibiliy and benchmark.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wonbeomjang/yolov5-knowledge-distillation\"\u003ewonbeomjang/yolov5-knowledge-distillation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/beeb3670caaa59c35563e76d082f96fa4b2fa47e952052f475f732a9b66fe269/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776f6e62656f6d6a616e672f796f6c6f76352d6b6e6f776c656467652d64697374696c6c6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/beeb3670caaa59c35563e76d082f96fa4b2fa47e952052f475f732a9b66fe269/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776f6e62656f6d6a616e672f796f6c6f76352d6b6e6f776c656467652d64697374696c6c6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wonbeomjang/yolov5-knowledge-distillation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : implementation of \u003ca href=\"https://github.com/twangnh/Distilling-Object-Detectors\"\u003eDistilling Object Detectors with Fine-grained Feature Imitation\u003c/a\u003e on yolov5. \"Distilling Object Detectors with Fine-grained Feature Imitation\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Distilling_Object_Detectors_With_Fine-Grained_Feature_Imitation_CVPR_2019_paper.html\" rel=\"nofollow\"\u003eCVPR 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Sharpiless/Yolov5-distillation-train-inference\"\u003eSharpiless/Yolov5-distillation-train-inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/de1d76e255ad6ecde1ccb5f8cdeb3d18144e73662b288e2976550d7eae0500d5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76352d64697374696c6c6174696f6e2d747261696e2d696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/de1d76e255ad6ecde1ccb5f8cdeb3d18144e73662b288e2976550d7eae0500d5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76352d64697374696c6c6174696f6e2d747261696e2d696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Sharpiless/Yolov5-distillation-train-inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov5 distillation training | Yolov5çŸ¥è¯†è’¸é¦è®­ç»ƒï¼Œæ”¯æŒè®­ç»ƒè‡ªå·±çš„æ•°æ®ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Sharpiless/yolov5-distillation-5.0\"\u003eSharpiless/yolov5-distillation-5.0\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4aa5226cf817d0a2dff9f0e8b3a27a11cf6509fd828504735506e0350baff1f6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f796f6c6f76352d64697374696c6c6174696f6e2d352e303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4aa5226cf817d0a2dff9f0e8b3a27a11cf6509fd828504735506e0350baff1f6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f796f6c6f76352d64697374696c6c6174696f6e2d352e303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Sharpiless/yolov5-distillation-5.0?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5 5.0 version distillation || yolov5 5.0ç‰ˆæœ¬çŸ¥è¯†è’¸é¦ï¼Œyolov5l \u0026gt;\u0026gt; yolov5sã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Sharpiless/yolov5-knowledge-distillation\"\u003eSharpiless/yolov5-knowledge-distillation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/717fc578c3953101bdb27a1381134602bbeb77574906b54d0aafe9193086e21d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f796f6c6f76352d6b6e6f776c656467652d64697374696c6c6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/717fc578c3953101bdb27a1381134602bbeb77574906b54d0aafe9193086e21d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f796f6c6f76352d6b6e6f776c656467652d64697374696c6c6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Sharpiless/yolov5-knowledge-distillation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5ç›®æ ‡æ£€æµ‹æ¨¡åž‹çš„çŸ¥è¯†è’¸é¦ï¼ˆåŸºäºŽå“åº”çš„è’¸é¦ï¼‰ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/chengpanghu/Knowledge-Distillation-yolov5\"\u003echengpanghu/Knowledge-Distillation-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1d65cdf969ee884c5fa568b477bbff223af2de7878f96d9b8834bf49ed6afd22/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368656e6770616e6768752f4b6e6f776c656467652d44697374696c6c6174696f6e2d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1d65cdf969ee884c5fa568b477bbff223af2de7878f96d9b8834bf49ed6afd22/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368656e6770616e6768752f4b6e6f776c656467652d44697374696c6c6174696f6e2d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/chengpanghu/Knowledge-Distillation-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Knowledge-Distillation-yolov5 åŸºäºŽyolov5çš„çŸ¥è¯†è’¸é¦ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/magicshuang/yolov5_distillation\"\u003emagicshuang/yolov5_distillation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/781285810e9cd348d53c3c5168c8ca0997a30a093a9099a5b291ef6c2fcbed07/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61676963736875616e672f796f6c6f76355f64697374696c6c6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/781285810e9cd348d53c3c5168c8ca0997a30a093a9099a5b291ef6c2fcbed07/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61676963736875616e672f796f6c6f76355f64697374696c6c6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/magicshuang/yolov5_distillation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5 çŸ¥è¯†è’¸é¦ï¼Œyolov5-læ¨¡åž‹åŽ‹ç¼©è‡³yolov5-s åŽ‹ç¼©ç®—æ³•æ˜¯ \u003ca href=\"https://github.com/twangnh/Distilling-Object-Detectors\"\u003eDistilling Object Detectors with Fine-grained Feature Imitation\u003c/a\u003eã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Sharpiless/Yolov3-MobileNet-Distillation\"\u003eSharpiless/Yolov3-MobileNet-Distillation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/599629a4733ff83bb060c15d165bbf6d5aebb8549bb60498c76a3841a77ad086/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76332d4d6f62696c654e65742d44697374696c6c6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/599629a4733ff83bb060c15d165bbf6d5aebb8549bb60498c76a3841a77ad086/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76332d4d6f62696c654e65742d44697374696c6c6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Sharpiless/Yolov3-MobileNet-Distillation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åœ¨Yolov3-MobileNetä¸Šè¿›è¡Œæ¨¡åž‹è’¸é¦è®­ç»ƒã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SsisyphusTao/Object-Detection-Knowledge-Distillation\"\u003eSsisyphusTao/Object-Detection-Knowledge-Distillation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a2e33e15723a8af896a4a072998b69fc1e7be3b9c244b82f95980574d57d2bd7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53736973797068757354616f2f4f626a6563742d446574656374696f6e2d4b6e6f776c656467652d44697374696c6c6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a2e33e15723a8af896a4a072998b69fc1e7be3b9c244b82f95980574d57d2bd7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53736973797068757354616f2f4f626a6563742d446574656374696f6e2d4b6e6f776c656467652d44697374696c6c6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SsisyphusTao/Object-Detection-Knowledge-Distillation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An Object Detection Knowledge Distillation framework powered by pytorch, now having SSD and yolov5.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eLightweight Backbones and FPN\u003c/h3\u003e\u003ca id=\"user-content-lightweight-backbones-and-fpn\" class=\"anchor\" aria-label=\"Permalink: Lightweight Backbones and FPN\" href=\"#lightweight-backbones-and-fpn\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eè½»é‡çº§éª¨å¹²ç½‘ç»œå’Œç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ\u003c/h4\u003e\u003ca id=\"user-content-è½»é‡çº§éª¨å¹²ç½‘ç»œå’Œç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ\" class=\"anchor\" aria-label=\"Permalink: è½»é‡çº§éª¨å¹²ç½‘ç»œå’Œç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ\" href=\"#è½»é‡çº§éª¨å¹²ç½‘ç»œå’Œç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/murufeng/awesome_lightweight_networks\"\u003emurufeng/awesome_lightweight_networks\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/42b4a396a81640b052d774b0786f60802012712a742d0870a2b670d41f26d0bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d75727566656e672f617765736f6d655f6c696768747765696768745f6e6574776f726b733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/42b4a396a81640b052d774b0786f60802012712a742d0870a2b670d41f26d0bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d75727566656e672f617765736f6d655f6c696768747765696768745f6e6574776f726b733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/murufeng/awesome_lightweight_networks?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The implementation of various lightweight networks by using PyTorch. such asï¼šMobileNetV2ï¼ŒMobileNeXtï¼ŒGhostNetï¼ŒParNetï¼ŒMobileViTã€AdderNetï¼ŒShuffleNetV1-V2ï¼ŒLCNetï¼ŒConvNeXtï¼Œetc. â­â­â­â­â­\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Bobo-y/flexible-yolov5\"\u003eBobo-y/flexible-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fde02dadf059148334f69cec7d7b9b6676fa9e2b3960adfc66fbcb7f7a58f1ec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f626f2d792f666c657869626c652d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fde02dadf059148334f69cec7d7b9b6676fa9e2b3960adfc66fbcb7f7a58f1ec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f626f2d792f666c657869626c652d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Bobo-y/flexible-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : More readable and flexible yolov5 with more backbone(resnet, shufflenet, moblienet, efficientnet, hrnet, swin-transformer) and (cbamï¼Œdcn and so on), and tensorrt.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/XingZeng307/YOLOv5_with_BiFPN\"\u003eXingZeng307/YOLOv5_with_BiFPN\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/70ad03a07b43ac9f545087306ff63dadc9e076282313f4af07944f1e302dac8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f58696e675a656e673330372f594f4c4f76355f776974685f426946504e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/70ad03a07b43ac9f545087306ff63dadc9e076282313f4af07944f1e302dac8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f58696e675a656e673330372f594f4c4f76355f776974685f426946504e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/XingZeng307/YOLOv5_with_BiFPN?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repo is mainly for replacing PANet with BiFPN in YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dog-qiuqiu/MobileNet-Yolo\"\u003edog-qiuqiu/MobileNet-Yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6ab014d426fbf9d3c657e76bd24f2ca51bf73248649cd4251ff02e2010e32ad8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f672d7169757169752f4d6f62696c654e65742d596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6ab014d426fbf9d3c657e76bd24f2ca51bf73248649cd4251ff02e2010e32ad8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f672d7169757169752f4d6f62696c654e65742d596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dog-qiuqiu/MobileNet-Yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : MobileNetV2-YoloV3-Nano: 0.5BFlops 3MB HUAWEI P40: 6ms/img, YoloFace-500k:0.1Bflops 420KBðŸ”¥ðŸ”¥ðŸ”¥.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/eric612/MobileNet-YOLO\"\u003eeric612/MobileNet-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5e8bd9cb86f0aaf1f477ea7791832f5759110c16103b59847e85641daca5138c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657269633631322f4d6f62696c654e65742d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5e8bd9cb86f0aaf1f477ea7791832f5759110c16103b59847e85641daca5138c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657269633631322f4d6f62696c654e65742d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/eric612/MobileNet-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A caffe implementation of MobileNet-YOLO detection network.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/eric612/Mobilenet-YOLO-Pytorch\"\u003eeric612/Mobilenet-YOLO-Pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/962a8376b4dc7598d16a6c50b234e07c2bdfcecb72b953909ca135987fa33bc4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657269633631322f4d6f62696c656e65742d594f4c4f2d5079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/962a8376b4dc7598d16a6c50b234e07c2bdfcecb72b953909ca135987fa33bc4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657269633631322f4d6f62696c656e65742d594f4c4f2d5079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/eric612/Mobilenet-YOLO-Pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Include mobilenet series (v1,v2,v3...) and yolo series (yolov3,yolov4,...) .\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Adamdad/keras-YOLOv3-mobilenet\"\u003eAdamdad/keras-YOLOv3-mobilenet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f730e4f48532d4bb905c0e95825ac40a2ae934f69183d6c69a6ca0d296998413/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4164616d6461642f6b657261732d594f4c4f76332d6d6f62696c656e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f730e4f48532d4bb905c0e95825ac40a2ae934f69183d6c69a6ca0d296998413/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4164616d6461642f6b657261732d594f4c4f76332d6d6f62696c656e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Adamdad/keras-YOLOv3-mobilenet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Keras implementation of YOLOv3 (Tensorflow backend) inspired by \u003ca href=\"https://github.com/allanzelener/YAD2K\"\u003eallanzelener/YAD2K\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fsx950223/mobilenetv2-yolov3\"\u003efsx950223/mobilenetv2-yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a35ecc0d599d11b6c6ca08ce00feebae15ff70a4adf1c6f71b12ed4099d0fc37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6673783935303232332f6d6f62696c656e657476322d796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a35ecc0d599d11b6c6ca08ce00feebae15ff70a4adf1c6f71b12ed4099d0fc37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6673783935303232332f6d6f62696c656e657476322d796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/fsx950223/mobilenetv2-yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov3 with mobilenetv2 and efficientnet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/liux0614/yolo_nano\"\u003eliux0614/yolo_nano\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0cd3985c3a3d57a2d0f7703dc467dca412a23ed845da9ccec9c74bc78a46ed5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c697578303631342f796f6c6f5f6e616e6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0cd3985c3a3d57a2d0f7703dc467dca412a23ed845da9ccec9c74bc78a46ed5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c697578303631342f796f6c6f5f6e616e6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/liux0614/yolo_nano?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Unofficial implementation of yolo nano.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lingtengqiu/Yolo_Nano\"\u003elingtengqiu/Yolo_Nano\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/486d6441b54fca785fb038bfd080ffe27b79de3ee18603247ed1b2ef0c82287e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c696e6774656e677169752f596f6c6f5f4e616e6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/486d6441b54fca785fb038bfd080ffe27b79de3ee18603247ed1b2ef0c82287e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c696e6774656e677169752f596f6c6f5f4e616e6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lingtengqiu/Yolo_Nano?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Pytorch implementation of yolo_Nano for pedestrian detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/mobilenet-yolov4-pytorch\"\u003ebubbliiiing/mobilenet-yolov4-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fce79962418fd5707a61f62bfb8ca03b2f7af1f827fb1cb3027b29b27152081e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f6d6f62696c656e65742d796f6c6f76342d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fce79962418fd5707a61f62bfb8ca03b2f7af1f827fb1cb3027b29b27152081e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f6d6f62696c656e65742d796f6c6f76342d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/mobilenet-yolov4-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¿™æ˜¯ä¸€ä¸ªmobilenet-yolov4çš„åº“ï¼ŒæŠŠyolov4ä¸»å¹²ç½‘ç»œä¿®æ”¹æˆäº†mobilenetï¼Œä¿®æ”¹äº†Panetçš„å·ç§¯ç»„æˆï¼Œä½¿å‚æ•°é‡å¤§å¹…åº¦ç¼©å°ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/efficientnet-yolo3-pytorch\"\u003ebubbliiiing/efficientnet-yolo3-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/524f02a8e7f73a374007c6b8286968e910a5df8a6644c0f829ceb047447b4fd8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f656666696369656e746e65742d796f6c6f332d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/524f02a8e7f73a374007c6b8286968e910a5df8a6644c0f829ceb047447b4fd8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f656666696369656e746e65742d796f6c6f332d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/efficientnet-yolo3-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¿™æ˜¯ä¸€ä¸ªefficientnet-yolo3-pytorchçš„æºç ï¼Œå°†yolov3çš„ä¸»å¹²ç‰¹å¾æå–ç½‘ç»œä¿®æ”¹æˆäº†efficientnetã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HuKai97/YOLOv5-ShuffleNetv2\"\u003eHuKai97/YOLOv5-ShuffleNetv2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/041bd348b33d0ee5a7d44260464edbf80ef349d906128d1fb06929ab64ee3eeb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48754b616939372f594f4c4f76352d53687566666c654e657476323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/041bd348b33d0ee5a7d44260464edbf80ef349d906128d1fb06929ab64ee3eeb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48754b616939372f594f4c4f76352d53687566666c654e657476323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HuKai97/YOLOv5-ShuffleNetv2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5çš„è½»é‡åŒ–æ”¹è¿›(èœ‚å·¢æ£€æµ‹é¡¹ç›®)ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/guotao0628/yoloret\"\u003eYOLO-ReT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5c860b5c6ff5c9dede35d04f5f4951e7b23a71479aa5455d329347f280569c1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67756f74616f303632382f796f6c6f7265743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5c860b5c6ff5c9dede35d04f5f4951e7b23a71479aa5455d329347f280569c1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67756f74616f303632382f796f6c6f7265743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/guotao0628/yoloret?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLO-ReT: Towards High Accuracy Real-time Object Detection on Edge GPUs\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/WACV2022/html/Ganesh_YOLO-ReT_Towards_High_Accuracy_Real-Time_Object_Detection_on_Edge_GPUs_WACV_2022_paper.html\" rel=\"nofollow\"\u003eWACV 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eObject Detection Applications\u003c/h2\u003e\u003ca id=\"user-content-object-detection-applications\" class=\"anchor\" aria-label=\"Permalink: Object Detection Applications\" href=\"#object-detection-applications\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOpen World Object Detection\u003c/h3\u003e\u003ca id=\"user-content-open-world-object-detection\" class=\"anchor\" aria-label=\"Permalink: Open World Object Detection\" href=\"#open-world-object-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eå¼€æ”¾ä¸–ç•Œç›®æ ‡æ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-å¼€æ”¾ä¸–ç•Œç›®æ ‡æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: å¼€æ”¾ä¸–ç•Œç›®æ ‡æ£€æµ‹\" href=\"#å¼€æ”¾ä¸–ç•Œç›®æ ‡æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AILab-CVC/YOLO-World\"\u003eYOLO-World\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4df4362f165830998e6956b59d1a08fcce2aa5a7c5018206bd948a4ecba4e178/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41494c61622d4356432f594f4c4f2d576f726c643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4df4362f165830998e6956b59d1a08fcce2aa5a7c5018206bd948a4ecba4e178/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41494c61622d4356432f594f4c4f2d576f726c643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AILab-CVC/YOLO-World?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLO-World: Real-Time Open-Vocabulary Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2401.17270\" rel=\"nofollow\"\u003eCVPR 2024\u003c/a\u003e\u003c/strong\u003e). \u003ca href=\"https://www.yoloworld.cc/\" rel=\"nofollow\"\u003ewww.yoloworld.cc\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eFlorence-2 : \"Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2311.06242\" rel=\"nofollow\"\u003eCVPR 2024\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/roboflow/maestro\"\u003emaestro\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3809d33b5bd6d0de50380b668f794c9e27a8d01a46fd303435cf426181fff8f1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626f666c6f772f6d61657374726f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3809d33b5bd6d0de50380b668f794c9e27a8d01a46fd303435cf426181fff8f1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626f666c6f772f6d61657374726f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/roboflow/maestro?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : VLM fine-tuning for everyone. maestro is a streamlined tool to accelerate the fine-tuning of multimodal models. By encapsulating best practices from our core modules, maestro handles configuration, data loading, reproducibility, and training loop setup. It currently offers ready-to-use recipes for popular vision-language models such as \u003ca href=\"https://arxiv.org/abs/2311.06242\" rel=\"nofollow\"\u003eFlorence-2\u003c/a\u003e, PaliGemma 2, and \u003ca href=\"https://github.com/QwenLM/Qwen2.5-VL\"\u003eQwen2.5-VL\u003c/a\u003e. \u003ca href=\"https://maestro.roboflow.com/latest/\" rel=\"nofollow\"\u003emaestro.roboflow.com\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/autodistill/autodistill\"\u003eAutodistill\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c62d847952be21af33a3611f569579505b739360aa218da771156aec4b408990/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6175746f64697374696c6c2f6175746f64697374696c6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c62d847952be21af33a3611f569579505b739360aa218da771156aec4b408990/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6175746f64697374696c6c2f6175746f64697374696c6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/autodistill/autodistill?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Images to inference with no labeling (use foundation models to train supervised models). Autodistill uses big, slower foundation models to train small, faster supervised models. Using autodistill, you can go from unlabeled images to inference on a custom model running at the edge with no human intervention in between. \u003ca href=\"https://docs.autodistill.com/\" rel=\"nofollow\"\u003edocs.autodistill.com\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/D-Robotics-AI-Lab/DOSOD\"\u003eDOSOD\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/15b23797d9c6e7c6effe5e64d3bd6b2111c0e9b6e4a293f9619033da7bc3c9e9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f442d526f626f746963732d41492d4c61622f444f534f443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/15b23797d9c6e7c6effe5e64d3bd6b2111c0e9b6e4a293f9619033da7bc3c9e9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f442d526f626f746963732d41492d4c61622f444f534f443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/D-Robotics-AI-Lab/DOSOD?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"A Light-Weight Framework for Open-Set Object Detection with Decoupled Feature Alignment in Joint Space\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2412.14680\" rel=\"nofollow\"\u003earXiv 2024\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/IDEA-Research/DINO\"\u003eDINO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/17073ac7af4a5232b8652ef3b492f099a110784cc8b717523588714bc6553cb3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f44494e4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/17073ac7af4a5232b8652ef3b492f099a110784cc8b717523588714bc6553cb3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f44494e4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/IDEA-Research/DINO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2203.03605\" rel=\"nofollow\"\u003eICLR 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/IDEA-Research/GroundingDINO\"\u003eGroundingDINO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c6a434d03c84765d1ca6368c83522ccc7b0b5178349b2d0e2de3ef764d9be71e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f47726f756e64696e6744494e4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c6a434d03c84765d1ca6368c83522ccc7b0b5178349b2d0e2de3ef764d9be71e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f47726f756e64696e6744494e4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/IDEA-Research/GroundingDINO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2303.05499\" rel=\"nofollow\"\u003eECCV 2024\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zhenyuw16/UniDetector\"\u003eUniDetector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/58ae5622601625368069e0d1b06a68ccaa4a18fdc272f5b36fb849d1c0dfd42c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68656e79757731362f556e694465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/58ae5622601625368069e0d1b06a68ccaa4a18fdc272f5b36fb849d1c0dfd42c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68656e79757731362f556e694465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zhenyuw16/UniDetector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Detecting Everything in the Open World: Towards Universal Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2303.11749\" rel=\"nofollow\"\u003eCVPR 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/buxihuo/OW-YOLO\"\u003ebuxihuo/OW-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8bdcb3cfecabef094af4c81e104dd73d7f8040fd5e61639941c6f04615f73047/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6275786968756f2f4f572d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8bdcb3cfecabef094af4c81e104dd73d7f8040fd5e61639941c6f04615f73047/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6275786968756f2f4f572d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/buxihuo/OW-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detect known and unknown objects in the open worldï¼ˆå…·æœ‰åŒºåˆ†å·²çŸ¥ä¸ŽæœªçŸ¥èƒ½åŠ›çš„å…¨æ–°æ£€æµ‹å™¨ï¼‰ï¼‰.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFew-shot Object Detection\u003c/h3\u003e\u003ca id=\"user-content-few-shot-object-detection\" class=\"anchor\" aria-label=\"Permalink: Few-shot Object Detection\" href=\"#few-shot-object-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eå°‘æ ·æœ¬ç›®æ ‡æ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-å°‘æ ·æœ¬ç›®æ ‡æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: å°‘æ ·æœ¬ç›®æ ‡æ£€æµ‹\" href=\"#å°‘æ ·æœ¬ç›®æ ‡æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/autodistill/autodistill\"\u003eAutodistill\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c62d847952be21af33a3611f569579505b739360aa218da771156aec4b408990/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6175746f64697374696c6c2f6175746f64697374696c6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c62d847952be21af33a3611f569579505b739360aa218da771156aec4b408990/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6175746f64697374696c6c2f6175746f64697374696c6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/autodistill/autodistill?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Images to inference with no labeling (use foundation models to train supervised models). Autodistill uses big, slower foundation models to train small, faster supervised models. Using autodistill, you can go from unlabeled images to inference on a custom model running at the edge with no human intervention in between. \u003ca href=\"https://docs.autodistill.com/\" rel=\"nofollow\"\u003edocs.autodistill.com\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bingykang/Fewshot_Detection\"\u003ebingykang/Fewshot_Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ff3bd1752b702fd71ab5433db12e2ce136024c3cd6aeac02e402bac82fcbb106/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62696e67796b616e672f46657773686f745f446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ff3bd1752b702fd71ab5433db12e2ce136024c3cd6aeac02e402bac82fcbb106/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62696e67796b616e672f46657773686f745f446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bingykang/Fewshot_Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Few-shot Object Detection via Feature Reweighting\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_ICCV_2019/html/Kang_Few-Shot_Object_Detection_via_Feature_Reweighting_ICCV_2019_paper.html\" rel=\"nofollow\"\u003eICCV 2019\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hnuzhy/SSDA-YOLO\"\u003eSSDA-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a592456d1dcfc5c9b4056b758191146a428eb323181c6cf5d1c5f3ddcbc6ddc0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686e757a68792f535344412d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a592456d1dcfc5c9b4056b758191146a428eb323181c6cf5d1c5f3ddcbc6ddc0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686e757a68792f535344412d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hnuzhy/SSDA-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Codes for my paper \"SSDA-YOLO: Semi-supervised Domain Adaptive YOLO for Cross-Domain Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S1077314223000292\" rel=\"nofollow\"\u003eComputer Vision and Image Understanding, 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/luogen1996/OneTeacher\"\u003eOneTeacher\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/caf44931e6c0e962b40cdabe4a0a6ad74bfdf31e5dabcc28d0f700c911cbe9a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c756f67656e313939362f4f6e65546561636865723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/caf44931e6c0e962b40cdabe4a0a6ad74bfdf31e5dabcc28d0f700c911cbe9a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c756f67656e313939362f4f6e65546561636865723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/luogen1996/OneTeacher?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Towards End-to-end Semi-supervised Learning for One-stage Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2302.11299\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlibabaResearch/efficientteacher\"\u003eEfficient Teacher\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/34f23fd4f117eaa9d99740069ba8a198b3e7b930748069a5f87a6a1ec54f8feb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c696261626152657365617263682f656666696369656e74746561636865723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/34f23fd4f117eaa9d99740069ba8a198b3e7b930748069a5f87a6a1ec54f8feb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c696261626152657365617263682f656666696369656e74746561636865723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlibabaResearch/efficientteacher?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Efficient Teacher: Semi-Supervised Object Detection for YOLOv5\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2302.07577\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSmall Object Detection\u003c/h3\u003e\u003ca id=\"user-content-small-object-detection\" class=\"anchor\" aria-label=\"Permalink: Small Object Detection\" href=\"#small-object-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eå°ç›®æ ‡æ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-å°ç›®æ ‡æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: å°ç›®æ ‡æ£€æµ‹\" href=\"#å°ç›®æ ‡æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Koldim2001/YOLO-Patch-Based-Inference\"\u003eYOLO-Patch-Based-Inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c113ee896699b5158b20748e67a7e6bf0cd0f321761dbe9aaee6ce95d8f3274a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6f6c64696d323030312f594f4c4f2d50617463682d42617365642d496e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c113ee896699b5158b20748e67a7e6bf0cd0f321761dbe9aaee6ce95d8f3274a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6f6c64696d323030312f594f4c4f2d50617463682d42617365642d496e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Koldim2001/YOLO-Patch-Based-Inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Python library for YOLO small object detection and instance segmentation. This Python library simplifies SAHI-like inference for instance segmentation tasks, enabling the detection of small objects in images. It caters to both object detection and instance segmentation tasks, supporting a wide range of Ultralytics models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/obss/sahi\"\u003eSAHI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0347894aaa55676cf2eafc5e350d024001d939b4875da57fe15c527b93fa2111/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6273732f736168693f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0347894aaa55676cf2eafc5e350d024001d939b4875da57fe15c527b93fa2111/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6273732f736168693f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/obss/sahi?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Slicing Aided Hyper Inference and Fine-tuning for Small Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2202.06934v2\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e, \u003ca href=\"https://doi.org/10.5281/zenodo.5718950\" rel=\"nofollow\"\u003eZenodo 2021\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlanLi1997/slim-neck-by-gsconv\"\u003eSlim-neck by GSConv\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a0ad2237c66afe91f4eab95f5eed4c06d4e27bdc8bf1c26c27ccd2f564da26d1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c616e4c69313939372f736c696d2d6e65636b2d62792d6773636f6e763f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a0ad2237c66afe91f4eab95f5eed4c06d4e27bdc8bf1c26c27ccd2f564da26d1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c616e4c69313939372f736c696d2d6e65636b2d62792d6773636f6e763f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlanLi1997/slim-neck-by-gsconv?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Slim-neck by GSConv: A better design paradigm of detector architectures for autonomous vehicles\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2206.02424\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hustvl/TinyDet\"\u003ehustvl/TinyDet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bde524dc482931323c1ff205f953f527a03249a55210764a92e8c16cd921dbd8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68757374766c2f54696e794465743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bde524dc482931323c1ff205f953f527a03249a55210764a92e8c16cd921dbd8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68757374766c2f54696e794465743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hustvl/TinyDet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"TinyDet: accurately detecting small objects within 1 GFLOPs\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/article/10.1007/s11432-021-3504-4\" rel=\"nofollow\"\u003eScience China Information Sciences, 2023\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ChenhongyiYang/QueryDet-PyTorch\"\u003eQueryDet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/365213e1e4ed5e0ea6f18927aeedcd457f67a9c219b9a92a702ce51a92fae275/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368656e686f6e67796959616e672f51756572794465742d5079546f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/365213e1e4ed5e0ea6f18927aeedcd457f67a9c219b9a92a702ce51a92fae275/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368656e686f6e67796959616e672f51756572794465742d5079546f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ChenhongyiYang/QueryDet-PyTorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"QueryDet: Cascaded Sparse Query for Accelerating High-Resolution Small Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2022/html/Yang_QueryDet_Cascaded_Sparse_Query_for_Accelerating_High-Resolution_Small_Object_Detection_CVPR_2022_paper.html\" rel=\"nofollow\"\u003eCVPR 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Chasel-Tsui/mmdet-rfla\"\u003eRFLA\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7225d15c9a1134cf367788ba6b729250f40a1adf817fe7b62c98ddab71dccbe5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43686173656c2d547375692f6d6d6465742d72666c613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7225d15c9a1134cf367788ba6b729250f40a1adf817fe7b62c98ddab71dccbe5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43686173656c2d547375692f6d6d6465742d72666c613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Chasel-Tsui/mmdet-rfla?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"RFLA: Gaussian Receptive Field based Label Assignment for Tiny Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2208.08738\" rel=\"nofollow\"\u003eECCV 2022\u003c/a\u003e\u003c/strong\u003e). \"å¾®ä¿¡å…¬ä¼—å·ã€ŒCVæŠ€æœ¯æŒ‡å—ã€ã€Š\u003ca href=\"https://mp.weixin.qq.com/s/h0J775I3D6zoTIeaJRnFgQ\" rel=\"nofollow\"\u003eECCV 2022 | RFLAï¼šåŸºäºŽé«˜æ–¯æ„Ÿå—é‡Žçš„å¾®å°ç›®æ ‡æ£€æµ‹æ ‡ç­¾åˆ†é…\u003c/a\u003eã€‹\"\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/avanetten/yolt\"\u003eYOLT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/91674c1daee2804a6afeaba83e4592e7096952eebe32875ee4178203bf6d235c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6176616e657474656e2f796f6c743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/91674c1daee2804a6afeaba83e4592e7096952eebe32875ee4178203bf6d235c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6176616e657474656e2f796f6c743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/avanetten/yolt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"You Only Look Twice: Rapid Multi-Scale Object Detection In Satellite Imagery\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1805.09512\" rel=\"nofollow\"\u003earXiv 2018\u003c/a\u003e\u003c/strong\u003e). \"å¾®ä¿¡å…¬ä¼—å·ã€Œæ±Ÿå¤§ç™½ã€ã€Š\u003ca href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NzgyNTU2Mg==\u0026amp;mid=2247498265\u0026amp;idx=1\u0026amp;sn=1eee95f8f4d09d761dc7b94f4ac55c34\u0026amp;source=41#wechat_redirect\" rel=\"nofollow\"\u003eåŸºäºŽå¤§å°ºå¯¸å›¾åƒçš„å°ç›®æ ‡æ£€æµ‹ç«žèµ›ç»éªŒæ€»ç»“\u003c/a\u003eã€‹\"\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/avanetten/simrdwn\"\u003eSIMRDWN\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5e1465428d22615cd49772d2b5698d72e5796e2058ee97eb6512b0024fe01606/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6176616e657474656e2f73696d7264776e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5e1465428d22615cd49772d2b5698d72e5796e2058ee97eb6512b0024fe01606/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6176616e657474656e2f73696d7264776e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/avanetten/simrdwn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Satellite Imagery Multiscale Rapid Detection with Windowed Networks\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1809.09978\" rel=\"nofollow\"\u003earXiv 2018\u003c/a\u003e, \u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8659155\" rel=\"nofollow\"\u003eWACV 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/avanetten/yoltv5\"\u003eYOLTv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ba9684ab5c71202355e65cb0fbc38811aba475102bb9862a1ac1319126c3f9e3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6176616e657474656e2f796f6c7476353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ba9684ab5c71202355e65cb0fbc38811aba475102bb9862a1ac1319126c3f9e3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6176616e657474656e2f796f6c7476353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/avanetten/yoltv5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLTv5 builds upon \u003ca href=\"https://github.com/avanetten/yolt\"\u003eYOLT\u003c/a\u003e and \u003ca href=\"https://github.com/avanetten/simrdwn\"\u003eSIMRDWN\u003c/a\u003e, and updates these frameworks to use the \u003ca href=\"https://github.com/ultralytics/yolov5\"\u003eultralytics/yolov5\u003c/a\u003e version of the YOLO object detection family.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cv516Buaa/tph-yolov5\"\u003eTPH-YOLOv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8626cd4a31f48c11b165d9ac4281c6d6bca0ff85cdc1036101d9bb869775dedd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6376353136427561612f7470682d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8626cd4a31f48c11b165d9ac4281c6d6bca0ff85cdc1036101d9bb869775dedd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6376353136427561612f7470682d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cv516Buaa/tph-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"TPH-YOLOv5: Improved YOLOv5 Based on Transformer Prediction Head for Object Detection on Drone-Captured Scenarios\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/ICCV2021W/VisDrone/html/Zhu_TPH-YOLOv5_Improved_YOLOv5_Based_on_Transformer_Prediction_Head_for_Object_ICCVW_2021_paper.html\" rel=\"nofollow\"\u003eICCV 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mwaseema/Drone-Detection\"\u003emwaseema/Drone-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0af7d58fc7c4b7ef6b14646ff7493257c1be7694d270baec5f911edae4338565/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d77617365656d612f44726f6e652d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0af7d58fc7c4b7ef6b14646ff7493257c1be7694d270baec5f911edae4338565/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d77617365656d612f44726f6e652d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mwaseema/Drone-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Dogfight: Detecting Drones from Drones Videos\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2021/html/Ashraf_Dogfight_Detecting_Drones_From_Drones_Videos_CVPR_2021_paper.html\" rel=\"nofollow\"\u003eCVPR 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cuogeihong/ceasc\"\u003eCEASA\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/11187a27838b6354a6dc208c0c5a2ab7224b394ca104f61563262e1be332a6af/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63756f676569686f6e672f63656173633f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/11187a27838b6354a6dc208c0c5a2ab7224b394ca104f61563262e1be332a6af/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63756f676569686f6e672f63656173633f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cuogeihong/ceasc?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Adaptive Sparse Convolutional Networks with Global Context Enhancement for Faster Object Detection on Drone Images\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2303.14488\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e). \"å¾®ä¿¡å…¬ä¼—å·ã€Œé›†æ™ºä¹¦ç«¥ã€ã€Š\u003ca href=\"https://mp.weixin.qq.com/s/-a4Wz04jLHFiAU88pUyDNQ\" rel=\"nofollow\"\u003eå³æ’å³ç”¨ | CEASAæ¨¡å—ç»™ä½ æ‰€æœ‰ï¼Œå°ç›®æ ‡ç²¾åº¦æå‡çš„åŒæ—¶é€Ÿåº¦ä¹Ÿå˜å¿«äº†\u003c/a\u003eã€‹\"\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/KevinMuyaoGuo/yolov5s_for_satellite_imagery\"\u003eKevinMuyaoGuo/yolov5s_for_satellite_imagery\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d8681860d1b13aae5cefa0837349304ae8dabfa48463e2e95115f98d22900acf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6576696e4d7579616f47756f2f796f6c6f7635735f666f725f736174656c6c6974655f696d61676572793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d8681860d1b13aae5cefa0837349304ae8dabfa48463e2e95115f98d22900acf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6576696e4d7579616f47756f2f796f6c6f7635735f666f725f736174656c6c6974655f696d61676572793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/KevinMuyaoGuo/yolov5s_for_satellite_imagery?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽYOLOv5çš„å«æ˜Ÿå›¾åƒç›®æ ‡æ£€æµ‹demo | A demo for satellite imagery object detection based on YOLOv5ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Hongyu-Yue/yoloV5_modify_smalltarget\"\u003eHongyu-Yue/yoloV5_modify_smalltarget\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5e8076db6759ed618c69b1242dacdd35b6c58dc52a41609a9bec67f2b297869c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f486f6e6779752d5975652f796f6c6f56355f6d6f646966795f736d616c6c7461726765743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5e8076db6759ed618c69b1242dacdd35b6c58dc52a41609a9bec67f2b297869c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f486f6e6779752d5975652f796f6c6f56355f6d6f646966795f736d616c6c7461726765743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Hongyu-Yue/yoloV5_modify_smalltarget?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOV5 å°ç›®æ ‡æ£€æµ‹ä¿®æ”¹ç‰ˆã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/muyuuuu/Self-Supervise-Object-Detection\"\u003emuyuuuu/Self-Supervise-Object-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/736ee4551e02c94c5a567097163adc1445505e2944121fdab7a864f615c9d57f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d7579757575752f53656c662d5375706572766973652d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/736ee4551e02c94c5a567097163adc1445505e2944121fdab7a864f615c9d57f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d7579757575752f53656c662d5375706572766973652d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/muyuuuu/Self-Supervise-Object-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Self-Supervised Object Detection. æ°´é¢æ¼‚æµ®åžƒåœ¾ç›®æ ‡æ£€æµ‹ï¼Œåˆ†æžæºç æ”¹å–„ yolox æ£€æµ‹å°ç›®æ ‡çš„ç¼ºé™·ï¼Œæå‡ºè‡ªç›‘ç£ç®—æ³•é¢„è®­ç»ƒæ— æ ‡ç­¾æ•°æ®ï¼Œæå‡æ£€æµ‹æ€§èƒ½ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/swricci/small-boat-detector\"\u003eswricci/small-boat-detector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/287aed9d6868fddb89f72c21be57cb9eff113b4e987dde7134ecf92984fa0c2c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737772696363692f736d616c6c2d626f61742d6465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/287aed9d6868fddb89f72c21be57cb9eff113b4e987dde7134ecf92984fa0c2c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737772696363692f736d616c6c2d626f61742d6465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/swricci/small-boat-detector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Trained yolo v3 model weights and configuration file to detect small boats in satellite imagery.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Resham-Sundar/sahi-yolox\"\u003eResham-Sundar/sahi-yolox\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/07d6e35167b89f4d031ee0ae977ab3cd745e8dbed85f6fb29706ee2ee094eb2a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52657368616d2d53756e6461722f736168692d796f6c6f783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/07d6e35167b89f4d031ee0ae977ab3cd745e8dbed85f6fb29706ee2ee094eb2a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52657368616d2d53756e6461722f736168692d796f6c6f783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Resham-Sundar/sahi-yolox?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloX with SAHI Implementation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eYOLO-Z : \"YOLO-Z: Improving small object detection in YOLOv5 for autonomous vehicles\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2112.11798\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e). \"å¾®ä¿¡å…¬ä¼—å·ã€Œè®¡ç®—æœºè§†è§‰ç ”ç©¶é™¢ã€ã€Š\u003ca href=\"https://mp.weixin.qq.com/s/ehkUapLOMdDghF2kAoAV4w\" rel=\"nofollow\"\u003eYolo-Zï¼šæ”¹è¿›çš„YOLOv5ç”¨äºŽå°ç›®æ ‡æ£€æµ‹ï¼ˆé™„åŽŸè®ºæ–‡ä¸‹è½½ï¼‰\u003c/a\u003eã€‹\".\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eM2S : \"A novel Multi to Single Module for small object detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2303.14977\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e). \"å¾®ä¿¡å…¬ä¼—å·ã€Œé›†æ™ºä¹¦ç«¥ã€ã€Š\u003ca href=\"https://mp.weixin.qq.com/s/FlKgYYGUHtJAxCF2wrh4NA\" rel=\"nofollow\"\u003eåŸºäºŽYOLOv5æ”¹è¿›å†è®¾è®¡ | M2Så…¨é¢æå‡å°ç›®æ ‡ç²¾åº¦\u003c/a\u003eã€‹\".\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ultralytics/xview-yolov3\"\u003eultralytics/xview-yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9f2418011fc394590fcc348571beaeaae3eb4f7a5bb4c227618357888b04ecf7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f78766965772d796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9f2418011fc394590fcc348571beaeaae3eb4f7a5bb4c227618357888b04ecf7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f78766965772d796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ultralytics/xview-yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : xView 2018 Object Detection Challenge: YOLOv3 Training and Inference.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/inderpreet1390/yolov5-small-target\"\u003einderpreet1390/yolov5-small-target\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bb318824c02d38bbe9978d44916a6e592454825c6d3f26fcf7688f19e3924223/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e6465727072656574313339302f796f6c6f76352d736d616c6c2d7461726765743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bb318824c02d38bbe9978d44916a6e592454825c6d3f26fcf7688f19e3924223/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e6465727072656574313339302f796f6c6f76352d736d616c6c2d7461726765743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/inderpreet1390/yolov5-small-target?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Repository for improved yolov5 for small target detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AllenSquirrel/YOLOv3_ReSAM\"\u003eAllenSquirrel/YOLOv3_ReSAM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/baa6c30681dc79baeb1b21feecc693edc1ba655e5fcd26ee843aff0fb323b737/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6c656e537175697272656c2f594f4c4f76335f526553414d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/baa6c30681dc79baeb1b21feecc693edc1ba655e5fcd26ee843aff0fb323b737/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6c656e537175697272656c2f594f4c4f76335f526553414d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AllenSquirrel/YOLOv3_ReSAM?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv3_ReSAM:A Small Target Detection Method With Spatial Attention Module.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kadirnar/yolov5-sahi\"\u003ekadirnar/yolov5-sahi\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f5d105c527c1f5bcc6cf0f7fc3abcdd00e68952df6c6a85372b0adc1ca395120/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f796f6c6f76352d736168693f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f5d105c527c1f5bcc6cf0f7fc3abcdd00e68952df6c6a85372b0adc1ca395120/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f796f6c6f76352d736168693f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kadirnar/yolov5-sahi?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov5 Modelini Kullanarak Ã–zel Nesne EÄŸitimi ve SAHI KullanÄ±mÄ±.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kadirnar/Yolov6-SAHI\"\u003ekadirnar/Yolov6-SAHI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5d37638321fc4ff76dcc37d68565ecc02474c6c643f0539efdb25d8fc33dda4c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f596f6c6f76362d534148493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5d37638321fc4ff76dcc37d68565ecc02474c6c643f0539efdb25d8fc33dda4c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f596f6c6f76362d534148493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kadirnar/Yolov6-SAHI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov6-SAHI.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zRzRzRzRzRzRzR/Mult-YOLO-alogorithm-of-RoboMaster-Radar-Detection-2023\"\u003ezRzRzRzRzRzRzR/Mult-YOLO-alogorithm-of-RoboMaster-Radar-Detection-2023\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/66898487c38cb2969eaed16838702747518e5b0e9316331c7202b43609fb70a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a527a527a527a527a527a527a522f4d756c742d594f4c4f2d616c6f676f726974686d2d6f662d526f626f4d61737465722d52616461722d446574656374696f6e2d323032333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/66898487c38cb2969eaed16838702747518e5b0e9316331c7202b43609fb70a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a527a527a527a527a527a527a522f4d756c742d594f4c4f2d616c6f676f726974686d2d6f662d526f626f4d61737465722d52616461722d446574656374696f6e2d323032333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zRzRzRzRzRzRzR/Mult-YOLO-alogorithm-of-RoboMaster-Radar-Detection-2023?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 2023å¹´è¥¿äº¤åˆ©ç‰©æµ¦å¤§å­¦åŠ¨äº‘ç§‘æŠ€GMasteræˆ˜é˜Ÿé›·è¾¾yoloå°ç›®æ ‡æ£€æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/quantumxiaol/yolov8-small-target-detection\"\u003equantumxiaol/yolov8-small-target-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/54daf01eed476a8bfef85cd4a71151fdbd794bcee8c09bdd4e1399c92f6e777e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7175616e74756d7869616f6c2f796f6c6f76382d736d616c6c2d7461726765742d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/54daf01eed476a8bfef85cd4a71151fdbd794bcee8c09bdd4e1399c92f6e777e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7175616e74756d7869616f6c2f796f6c6f76382d736d616c6c2d7461726765742d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/quantumxiaol/yolov8-small-target-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽyolov8å®žçŽ°å°ç›®æ ‡æ£€æµ‹ï¼Œåœ¨NWPU VHR-10å’ŒDOTAä¸Šæµ‹è¯•ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/shaunyuan22/SODA\"\u003eshaunyuan22/SODA\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2522ec1b30d33adacbf6b9403af2e9e9805b17668301baaa217ffc9de439f311/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736861756e7975616e32322f534f44413f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2522ec1b30d33adacbf6b9403af2e9e9805b17668301baaa217ffc9de439f311/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736861756e7975616e32322f534f44413f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/shaunyuan22/SODA?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Official code library for SODA: A Large-scale Benchmark for Small Object Detection. \"Towards Large-Scale Small Object Detection: Survey and Benchmarks\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2207.14096\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/qunshansj/Small-Object-Detection-Head-Improved-YOLOv5-Infrared-Sensing-System\"\u003equnshansj/Small-Object-Detection-Head-Improved-YOLOv5-Infrared-Sensing-System\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/69f84785318f43a940036f9c9da384de955d99d14a703770deaba718c9626a99/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f71756e7368616e736a2f536d616c6c2d4f626a6563742d446574656374696f6e2d486561642d496d70726f7665642d594f4c4f76352d496e6672617265642d53656e73696e672d53797374656d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/69f84785318f43a940036f9c9da384de955d99d14a703770deaba718c9626a99/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f71756e7368616e736a2f536d616c6c2d4f626a6563742d446574656374696f6e2d486561642d496d70726f7665642d594f4c4f76352d496e6672617265642d53656e73696e672d53797374656d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/qunshansj/Small-Object-Detection-Head-Improved-YOLOv5-Infrared-Sensing-System?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽå°ç›®æ ‡æ£€æµ‹å¤´çš„æ”¹è¿›YOLOv5çº¢å¤–é¥æ„Ÿå›¾åƒå°ç›®æ ‡æ£€æµ‹ç³»ç»Ÿã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eMultimodal Image Detection\u003c/h4\u003e\u003ca id=\"user-content-multimodal-image-detection\" class=\"anchor\" aria-label=\"Permalink: Multimodal Image Detection\" href=\"#multimodal-image-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eå¤šæ¨¡æ€å›¾åƒæ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-å¤šæ¨¡æ€å›¾åƒæ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: å¤šæ¨¡æ€å›¾åƒæ£€æµ‹\" href=\"#å¤šæ¨¡æ€å›¾åƒæ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NVIDIA-AI-IOT/Lidar_AI_Solution\"\u003eNVIDIA-AI-IOT/Lidar_AI_Solution\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4e3fe9c882102e5b25a1aa742a409a63a5b01f404efc2e9761b23e369209c8cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f4c696461725f41495f536f6c7574696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4e3fe9c882102e5b25a1aa742a409a63a5b01f404efc2e9761b23e369209c8cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f4c696461725f41495f536f6c7574696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NVIDIA-AI-IOT/Lidar_AI_Solution?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a highly optimized solution for self-driving 3D-lidar repository. It does a great job of speeding up sparse convolution/CenterPoint/BEVFusion/OSD/Conversion. A project demonstrating Lidar related AI solutions, including three GPU accelerated Lidar/camera DL networks (PointPillars, CenterPoint, BEVFusion) and the related libs (cuPCL, 3D SparseConvolution, YUV2RGB, cuOSD,).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/remaro-network/KD-YOLOX-ViT\"\u003eremaro-network/KD-YOLOX-ViT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ede49c18cb9c8cb1eef28b362ebb68919e18dc8fc9e6217c9b218cdb18412eb8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72656d61726f2d6e6574776f726b2f4b442d594f4c4f582d5669543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ede49c18cb9c8cb1eef28b362ebb68919e18dc8fc9e6217c9b218cdb18412eb8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72656d61726f2d6e6574776f726b2f4b442d594f4c4f582d5669543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/remaro-network/KD-YOLOX-ViT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository holds the code for the Python implementation of YOLOX-ViT. Furthermore, it has the implementation of the Knowledge Distillation (KD) method, evaluation metrics of the object detector and the side-scan sonar image dataset for underwater wall detection. \"Knowledge Distillation in YOLOX-ViT for Side-Scan Sonar Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2403.09313\" rel=\"nofollow\"\u003earXiv 2024\u003c/a\u003e\u003c/strong\u003e). The Sonar Wall Detection Dataset (SWDD) is publicly accessible at \u003ca href=\"https://zenodo.org/records/10528135\" rel=\"nofollow\"\u003ehttps://zenodo.org/records/10528135\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wandahangFY/YOLO-MIF\"\u003ewandahangFY/YOLO-MIF\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/725e5885eb87c0012ced0b09fe4665c67256641aec2f3090541a399708c2980f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e646168616e6746592f594f4c4f2d4d49463f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/725e5885eb87c0012ced0b09fe4665c67256641aec2f3090541a399708c2980f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e646168616e6746592f594f4c4f2d4d49463f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wandahangFY/YOLO-MIF?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO-MIF(YOLOv8-RGBT) is an improved version of YOLOv8 for object detection in gray-scale images, incorporating multi-information fusion to enhance detection accuracy. The detection of RGBT mode is also added. YOLO-MIFæ˜¯åœ¨ç°åº¦å›¾åƒä¸­è¿›è¡Œç›®æ ‡æ£€æµ‹çš„æ”¹è¿›åž‹YOLOv8æ¨¡åž‹ï¼Œå¼•å…¥äº†å¤šä¿¡æ¯èžåˆç­–ç•¥ï¼Œæé«˜äº†æ£€æµ‹å‡†ç¡®æ€§ã€‚ å¹¶æ·»åŠ äº†RGBTæ¨¡å¼çš„æ£€æµ‹,åˆ†å‰²ä»¥åŠå…³èŠ‚ç‚¹ä»»åŠ¡ã€‚ \"YOLO-MIF: Improved YOLOv8 with Multi-Information fusion for object detection in Gray-Scale images\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S1474034624003574\" rel=\"nofollow\"\u003eAdvanced Engineering Informatics, 2024\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wandahangFY/YOLOv11-RGBT\"\u003ewandahangFY/YOLOv11-RGBT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/76ccef5c047bcd9ae18c06b5629ee6d18341c7b435186500270070d990f80da8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e646168616e6746592f594f4c4f7631312d524742543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/76ccef5c047bcd9ae18c06b5629ee6d18341c7b435186500270070d990f80da8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e646168616e6746592f594f4c4f7631312d524742543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wandahangFY/YOLOv11-RGBT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv11-RGBT: Towards a Comprehensive Multispectral Object Detection Frameworkï¼ˆSupports RGBT detection for all YOLO series from YOLOv3 to YOLOv12, as well as RTDETR.ï¼‰ï¼‰\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mcw1217/Triple_YOLOv8\"\u003emcw1217/Triple_YOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fd41786685a592351551fa5af9d9304afb7a6228ea066aa2b87f6d7ece2f5737/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6377313231372f547269706c655f594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fd41786685a592351551fa5af9d9304afb7a6228ea066aa2b87f6d7ece2f5737/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6377313231372f547269706c655f594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mcw1217/Triple_YOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This project uses three types of images as inputs RGB, Depth, and thermal images to perform object detection with YOLOv8.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ljcuestc/YoloMultispectralFusion-Coarse-to-fine-Registration\"\u003eljcuestc/YoloMultispectralFusion-Coarse-to-fine-Registration\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2b8817f3036cc4bd73ecd239afd5c65812ae73bd53b01fc7662085023a91d3e9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6a6375657374632f596f6c6f4d756c7469737065637472616c467573696f6e2d436f617273652d746f2d66696e652d526567697374726174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2b8817f3036cc4bd73ecd239afd5c65812ae73bd53b01fc7662085023a91d3e9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6a6375657374632f596f6c6f4d756c7469737065637472616c467573696f6e2d436f617273652d746f2d66696e652d526567697374726174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ljcuestc/YoloMultispectralFusion-Coarse-to-fine-Registration?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"A Novel Multispectral Fusion Defect Detection Framework With Coarse-to-Fine Multispectral Registration\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/document/10365549\" rel=\"nofollow\"\u003eIEEE Transactions on Instrumentation and Measurement, 2023\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/icey-zhang/SuperYOLO\"\u003eSuperYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/304eaf2a7e371e4963897079f02bc3dddf2c6b13c44d963d28496fd082a67ce0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696365792d7a68616e672f5375706572594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/304eaf2a7e371e4963897079f02bc3dddf2c6b13c44d963d28496fd082a67ce0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696365792d7a68616e672f5375706572594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/icey-zhang/SuperYOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"SuperYOLO: Super Resolution Assisted Object Detection in Multimodal Remote Sensing Imagery\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2209.13351\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/QuincyQAQ/YOLOv8-Multi-Modal-Fusion-Network-RGB-IR\"\u003eQuincyQAQ/YOLOv8-Multi-Modal-Fusion-Network-RGB-IR\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/414b76fdd5ac317ef0bd589c30524ae1d2021a0624f206c5117e51f06366dc89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5175696e63795141512f594f4c4f76382d4d756c74692d4d6f64616c2d467573696f6e2d4e6574776f726b2d5247422d49523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/414b76fdd5ac317ef0bd589c30524ae1d2021a0624f206c5117e51f06366dc89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5175696e63795141512f594f4c4f76382d4d756c74692d4d6f64616c2d467573696f6e2d4e6574776f726b2d5247422d49523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/QuincyQAQ/YOLOv8-Multi-Modal-Fusion-Network-RGB-IR?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv8-Multi-Modal-Fusion-Network-RGB-IR.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mangoggul/YOLO-MultiModal\"\u003emangoggul/YOLO-MultiModal\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a43db68601a2fe6f8e80285c16efa8fd49e7e43b70e74842486a7a3e1905abf6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d616e676f6767756c2f594f4c4f2d4d756c74694d6f64616c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a43db68601a2fe6f8e80285c16efa8fd49e7e43b70e74842486a7a3e1905abf6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d616e676f6767756c2f594f4c4f2d4d756c74694d6f64616c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mangoggul/YOLO-MultiModal?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Multi-Modal-YOLO detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DocF/multispectral-object-detection\"\u003eDocF/multispectral-object-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/936e95a4953f076cc5dd404514dcb073ba7fc1b0ed6ee480c1599ac76fbd5077/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f446f63462f6d756c7469737065637472616c2d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/936e95a4953f076cc5dd404514dcb073ba7fc1b0ed6ee480c1599ac76fbd5077/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f446f63462f6d756c7469737065637472616c2d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DocF/multispectral-object-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Multispectral Object Detection with Yolov5 and Transformer.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ye-zixiao/Double-YOLO-Kaist\"\u003eYe-zixiao/Double-YOLO-Kaist\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d1fdd398abc7f304a58874ed3d5edb9c595ce6b667bbcd1c430447664db9c14f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59652d7a697869616f2f446f75626c652d594f4c4f2d4b616973743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d1fdd398abc7f304a58874ed3d5edb9c595ce6b667bbcd1c430447664db9c14f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59652d7a697869616f2f446f75626c652d594f4c4f2d4b616973743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ye-zixiao/Double-YOLO-Kaist?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä¸€ç§åŸºäºŽYOLOv3/4çš„åŒæµæ··åˆæ¨¡æ€é“è·¯è¡Œäººæ£€æµ‹æ–¹æ³•ðŸŒŠðŸ’§ðŸ’¦ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lzhihan/yolov5_Visible_Infrared_Vehicle_Detection\"\u003elzhihan/yolov5_Visible_Infrared_Vehicle_Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/417e97b4768b267e25606ac287cc5b0704c67f4f1ca2fe33a14f8fdd5b4d2841/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c7a686968616e2f796f6c6f76355f56697369626c655f496e6672617265645f56656869636c655f446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/417e97b4768b267e25606ac287cc5b0704c67f4f1ca2fe33a14f8fdd5b4d2841/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c7a686968616e2f796f6c6f76355f56697369626c655f496e6672617265645f56656869636c655f446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lzhihan/yolov5_Visible_Infrared_Vehicle_Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽå¯è§å…‰å’Œçº¢å¤–å›¾åƒçš„æ·±åº¦å­¦ä¹ è½¦è¾†ç›®æ ‡æ£€æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jere357/yolov5-RGBD\"\u003ejere357/yolov5-RGBD\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/236b96f7913b4e7e691afbfd0d54ca49847d9bd83beff23343c460fbe99e1dba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a6572653335372f796f6c6f76352d524742443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/236b96f7913b4e7e691afbfd0d54ca49847d9bd83beff23343c460fbe99e1dba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a6572653335372f796f6c6f76352d524742443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jere357/yolov5-RGBD?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"fork\" from yolov5 with the possibility of running inferences on RGBD(C) images, work in progress. This repo is not a fork of the original repo bcs i already have 1 fork with a PR pending, this is still messy code and a work in progress.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/huashu996/dual_result_fusion_yolov5\"\u003ehuashu996/dual_result_fusion_yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7f9e40f6e802f219ec419f29f61e06d26826bf676d9c5ee41bc3da1204f6aa64/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6875617368753939362f6475616c5f726573756c745f667573696f6e5f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7f9e40f6e802f219ec419f29f61e06d26826bf676d9c5ee41bc3da1204f6aa64/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6875617368753939362f6475616c5f726573756c745f667573696f6e5f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/huashu996/dual_result_fusion_yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : result set fusion for visible-light and infrared images. æ­¤åŒæ¨¡æ€æ£€æµ‹æ˜¯é€šè¿‡å¯¹å¯è§å…‰å’Œçº¢å¤–å›¾åƒåˆ†åˆ«è®­ç»ƒï¼Œå¾—åˆ°ä¸¤ä¸ªweightï¼Œåœ¨è¿è¡Œæ—¶ä¼šå¯¹ä¸¤ç§å›¾åƒåˆ†åˆ«æ£€æµ‹ï¼Œæœ€åŽå¯¹æ£€æµ‹ç»“æžœæ±‚æžå¤§ä¼¼ç„¶ï¼Œå¹¶ä¸”èƒ½å¤Ÿå¯¹ç›®æ ‡è¿›è¡Œæµ‹è·ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MAli-Farooq/Thermal-YOLO\"\u003eMAli-Farooq/Thermal-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4c4db31ab25351234bed488e6aa327763248240df649cf8900ad6223eca1e8fc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736965727072696e736b792f596f6c6f56355f626c6f6f645f63656c6c733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4c4db31ab25351234bed488e6aa327763248240df649cf8900ad6223eca1e8fc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736965727072696e736b792f596f6c6f56355f626c6f6f645f63656c6c733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sierprinsky/YoloV5_blood_cells?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This study is related to object detection in thermal infrared spectrum using YOLO-V5 framework for ADAS application.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/OrangeSodahub/CRLFnet\"\u003eOrangeSodahub/CRLFnet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/208a096b4363a94b078ab0040d548001315b316a0f8bf054b948d0e16fb0cf02/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f72616e6765536f64616875622f43524c466e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/208a096b4363a94b078ab0040d548001315b316a0f8bf054b948d0e16fb0cf02/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f72616e6765536f64616875622f43524c466e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/OrangeSodahub/CRLFnet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Camera-Radar-Lidar Fusion detection net based on ROS, YOLOv3, OpenPCDet integration.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mjoshi07/Visual-Sensor-Fusion\"\u003emjoshi07/Visual-Sensor-Fusion\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e6961d9a14e474aa8b68eaffaf1fda90e4e4c7fd9b6ac0647c6314b39a36ea5c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6a6f73686930372f56697375616c2d53656e736f722d467573696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e6961d9a14e474aa8b68eaffaf1fda90e4e4c7fd9b6ac0647c6314b39a36ea5c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6a6f73686930372f56697375616c2d53656e736f722d467573696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mjoshi07/Visual-Sensor-Fusion?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : LiDAR Fusion with Vision.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Arrowes/CEAM-YOLOv7\"\u003eArrowes/CEAM-YOLOv7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/34b80f920cb805ab8b35fec2f29e19abfc8cde8acc22a6a0b21f56f476fae139/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4172726f7765732f4345414d2d594f4c4f76373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/34b80f920cb805ab8b35fec2f29e19abfc8cde8acc22a6a0b21f56f476fae139/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4172726f7765732f4345414d2d594f4c4f76373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Arrowes/CEAM-YOLOv7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : CEAM-YOLOv7: Improved YOLOv7 Based on Channel Expansion and Attention Mechanism for Driver Distraction Behavior Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eVideo Object Detection\u003c/h3\u003e\u003ca id=\"user-content-video-object-detection\" class=\"anchor\" aria-label=\"Permalink: Video Object Detection\" href=\"#video-object-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eè§†é¢‘ç›®æ ‡æ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-è§†é¢‘ç›®æ ‡æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: è§†é¢‘ç›®æ ‡æ£€æµ‹\" href=\"#è§†é¢‘ç›®æ ‡æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/YuHengsss/YOLOV\"\u003eYOLOV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/29749d69e78c07f86e15ba82ec1117db69fa40de8de42dee85bf704c7c017c01/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f597548656e677373732f594f4c4f563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/29749d69e78c07f86e15ba82ec1117db69fa40de8de42dee85bf704c7c017c01/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f597548656e677373732f594f4c4f563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/YuHengsss/YOLOV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOV: Making Still Image Object Detectors Great at Video Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2208.09686\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yancie-yjr/StreamYOLO\"\u003eStreamYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fa4b133d00493b4cb23f96578c9a1666bb89bfc36162dbe771877cdbc4420b9e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f79616e6369652d796a722f53747265616d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fa4b133d00493b4cb23f96578c9a1666bb89bfc36162dbe771877cdbc4420b9e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f79616e6369652d796a722f53747265616d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yancie-yjr/StreamYOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Real-time Object Detection for Streaming Perception\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2203.12338v1\" rel=\"nofollow\"\u003eCVPR 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlbertoSabater/Robust-and-efficient-post-processing-for-video-object-detection\"\u003eREPP\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ba12fc9fcd83bc7e798363c9f713e28aa5e42f3d13819045b5dee33b30529139/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c626572746f536162617465722f526f627573742d616e642d656666696369656e742d706f73742d70726f63657373696e672d666f722d766964656f2d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ba12fc9fcd83bc7e798363c9f713e28aa5e42f3d13819045b5dee33b30529139/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c626572746f536162617465722f526f627573742d616e642d656666696369656e742d706f73742d70726f63657373696e672d666f722d766964656f2d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlbertoSabater/Robust-and-efficient-post-processing-for-video-object-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Robust and efficient post-processing for video object detection\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9341600\" rel=\"nofollow\"\u003eIROS 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/stanford-futuredata/noscope\"\u003eNoScope\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a25729920b662998ba4375a4956a43ef151046005e7394e838cf31cb5ad9f6da/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374616e666f72642d667574757265646174612f6e6f73636f70653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a25729920b662998ba4375a4956a43ef151046005e7394e838cf31cb5ad9f6da/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374616e666f72642d667574757265646174612f6e6f73636f70653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/stanford-futuredata/noscope?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Noscope: optimizing neural network queries over video at scale\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1703.02529\" rel=\"nofollow\"\u003earXiv 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eObject Tracking\u003c/h3\u003e\u003ca id=\"user-content-object-tracking\" class=\"anchor\" aria-label=\"Permalink: Object Tracking\" href=\"#object-tracking\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eç›®æ ‡è·Ÿè¸ª\u003c/h4\u003e\u003ca id=\"user-content-ç›®æ ‡è·Ÿè¸ª\" class=\"anchor\" aria-label=\"Permalink: ç›®æ ‡è·Ÿè¸ª\" href=\"#ç›®æ ‡è·Ÿè¸ª\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eMulti-Object Tracking\u003c/h4\u003e\u003ca id=\"user-content-multi-object-tracking\" class=\"anchor\" aria-label=\"Permalink: Multi-Object Tracking\" href=\"#multi-object-tracking\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eå¤šç›®æ ‡è·Ÿè¸ª\u003c/h5\u003e\u003ca id=\"user-content-å¤šç›®æ ‡è·Ÿè¸ª\" class=\"anchor\" aria-label=\"Permalink: å¤šç›®æ ‡è·Ÿè¸ª\" href=\"#å¤šç›®æ ‡è·Ÿè¸ª\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nmhaddad/fast-track\"\u003enmhaddad/fast-track\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/206139bfa856faf333cc5952a4ee99d72427e5dfaa2ed518f0128182e490b6f4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e6d6861646461642f666173742d747261636b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/206139bfa856faf333cc5952a4ee99d72427e5dfaa2ed518f0128182e490b6f4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e6d6861646461642f666173742d747261636b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nmhaddad/fast-track?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object tracking pipelines complete with RF-DETR, YOLOv9, YOLO-NAS, YOLOv8, and YOLOv7 detection and BYTETracker tracking.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sujanshresstha/YOLOv10_DeepSORT\"\u003esujanshresstha/YOLOv10_DeepSORT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/71f98f3c54a70cf1b011de9d566a61bd388d649c09d6087a2a7844214050b203/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756a616e7368726573737468612f594f4c4f7631305f44656570534f52543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/71f98f3c54a70cf1b011de9d566a61bd388d649c09d6087a2a7844214050b203/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756a616e7368726573737468612f594f4c4f7631305f44656570534f52543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sujanshresstha/YOLOv10_DeepSORT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository contains code for object detection and tracking in videos using the YOLOv10 object detection model and the DeepSORT algorithm.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eBoxMOT \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4e1908be92e0371c6e69e6359845324f20c53fe568e9a9dd8dc281c296156f6d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696b656c2d62726f7374726f6d2f626f786d6f743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4e1908be92e0371c6e69e6359845324f20c53fe568e9a9dd8dc281c296156f6d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696b656c2d62726f7374726f6d2f626f786d6f743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mikel-brostrom/boxmot?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : BoxMOT: pluggable SOTA tracking modules for segmentation, object detection and pose estimation models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mikel-brostrom/Yolov7_StrongSORT_OSNet\"\u003emikel-brostrom/Yolov7_StrongSORT_OSNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/04ca3ecdf3b56d65c545d1dcf6e281fd9e2d301d03c1beedd1f9693459c14c1a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696b656c2d62726f7374726f6d2f596f6c6f76375f5374726f6e67534f52545f4f534e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/04ca3ecdf3b56d65c545d1dcf6e281fd9e2d301d03c1beedd1f9693459c14c1a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696b656c2d62726f7374726f6d2f596f6c6f76375f5374726f6e67534f52545f4f534e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mikel-brostrom/Yolov7_StrongSORT_OSNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time multi-camera multi-object tracker using \u003ca href=\"https://github.com/WongKinYiu/yolov7\"\u003eYOLOv7\u003c/a\u003e and \u003ca href=\"https://github.com/dyhBUPT/StrongSORT\"\u003eStrongSORT\u003c/a\u003e with \u003ca href=\"https://github.com/KaiyangZhou/deep-person-reid\"\u003eOSNet\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RizwanMunawar/yolov8-object-tracking\"\u003eRizwanMunawar/yolov8-object-tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1b7145a0b64b60ceae3e4777ea142b1eefd9785d06cec3f3b033d696e8fe7736/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76382d6f626a6563742d747261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1b7145a0b64b60ceae3e4777ea142b1eefd9785d06cec3f3b033d696e8fe7736/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76382d6f626a6563742d747261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RizwanMunawar/yolov8-object-tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv8 Object Tracking Using PyTorch, OpenCV and Ultralytics.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xuarehere/yolo_series_deepsort_pytorch\"\u003exuarehere/yolo_series_deepsort_pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/48c4dd02b79e58f597757fac19d31056ec2a49ceb90859425ba85c6abaf58392/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7875617265686572652f796f6c6f5f7365726965735f64656570736f72745f7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/48c4dd02b79e58f597757fac19d31056ec2a49ceb90859425ba85c6abaf58392/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7875617265686572652f796f6c6f5f7365726965735f64656570736f72745f7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xuarehere/yolo_series_deepsort_pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Deepsort with yolo series. This project support the existing yolo detection model algorithm (YOLOv3, YOLOV4, YOLOV4Scaled, YOLOV5, YOLOV6, YOLOV7, YOLOV8, YOLOX, YOLOR, PPYOLOE ).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/JackWoo0831/Yolov7-tracker\"\u003eJackWoo0831/Yolov7-tracker\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/10af1ee3fbb719533a4e8827a28635e2cdf9ccf4c2ca54e159de21fefc308728/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61636b576f6f303833312f596f6c6f76372d747261636b65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/10af1ee3fbb719533a4e8827a28635e2cdf9ccf4c2ca54e159de21fefc308728/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61636b576f6f303833312f596f6c6f76372d747261636b65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/JackWoo0831/Yolov7-tracker?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo v7 and several Multi-Object Tracker(SORT, DeepSORT, ByteTrack, BoT-SORT, etc.) in VisDrone2019 Dataset. It uses a unified style and integrated tracker for easy embedding in your own projects. YOLOv7 + å„ç§trackerå®žçŽ°å¤šç›®æ ‡è·Ÿè¸ªã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NirAharon/BoT-SORT\"\u003eBoT-SORT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/22e644dce08636e4c7b0777ecf5cc208a3cefd481d129dc3453ee408d9469522/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e6972416861726f6e2f426f542d534f52543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/22e644dce08636e4c7b0777ecf5cc208a3cefd481d129dc3453ee408d9469522/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e6972416861726f6e2f426f542d534f52543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NirAharon/BoT-SORT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"BoT-SORT: Robust Associations Multi-Pedestrian Tracking\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2206.14651\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dyhBUPT/StrongSORT\"\u003eStrongSORT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/80c3c741d4a52e68aac9aaafe2c0dc1f9bef2c9f7b24f4643dfe3098cc6b2efe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f647968425550542f5374726f6e67534f52543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/80c3c741d4a52e68aac9aaafe2c0dc1f9bef2c9f7b24f4643dfe3098cc6b2efe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f647968425550542f5374726f6e67534f52543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dyhBUPT/StrongSORT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"StrongSORT: Make DeepSORT Great Again\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2202.13514\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LiuShuaiyr/UAVMOT\"\u003eUAVMOT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c506c1e7ebf954a4ae43e6a7171e6af9e9a1020d517c120f7642a995e8600b1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c6975536875616979722f5541564d4f543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c506c1e7ebf954a4ae43e6a7171e6af9e9a1020d517c120f7642a995e8600b1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c6975536875616979722f5541564d4f543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LiuShuaiyr/UAVMOT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Multi-Object Tracking Meets Moving UAV\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Multi-Object_Tracking_Meets_Moving_UAV_CVPR_2022_paper.html\" rel=\"nofollow\"\u003eCVPR 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HKPolyU-UAV/AUTO\"\u003eHKPolyU-UAV/AUTO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/df039f9b564a95ca0cdc6315bfc809ea13c1780909bedf40a0888abe7424f875/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f484b506f6c79552d5541562f4155544f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/df039f9b564a95ca0cdc6315bfc809ea13c1780909bedf40a0888abe7424f875/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f484b506f6c79552d5541562f4155544f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HKPolyU-UAV/AUTO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Dynamic Object Tracking on Autonomous UAV System for Surveillance Applications\". (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/1424-8220/21/23/7888\" rel=\"nofollow\"\u003eSensors 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bharath5673/StrongSORT-YOLO\"\u003ebharath5673/StrongSORT-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c0094918a516c63ab169944d2f5475e563b327711c707996277bc5e810374901/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62686172617468353637332f5374726f6e67534f52542d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c0094918a516c63ab169944d2f5475e563b327711c707996277bc5e810374901/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62686172617468353637332f5374726f6e67534f52542d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bharath5673/StrongSORT-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time multi-camera multi-object tracker using (YOLOv5, YOLOv7) and \u003ca href=\"https://github.com/dyhBUPT/StrongSORT\"\u003eStrongSORT\u003c/a\u003e with OSNet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mikel-brostrom/Yolov7_StrongSORT_OSNet\"\u003emikel-brostrom/Yolov7_StrongSORT_OSNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/04ca3ecdf3b56d65c545d1dcf6e281fd9e2d301d03c1beedd1f9693459c14c1a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696b656c2d62726f7374726f6d2f596f6c6f76375f5374726f6e67534f52545f4f534e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/04ca3ecdf3b56d65c545d1dcf6e281fd9e2d301d03c1beedd1f9693459c14c1a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696b656c2d62726f7374726f6d2f596f6c6f76375f5374726f6e67534f52545f4f534e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mikel-brostrom/Yolov7_StrongSORT_OSNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time multi-camera multi-object tracker using YOLOv7 and StrongSORT with OSNet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kadirnar/yolov5-strongsort\"\u003ekadirnar/yolov5-strongsort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/60b2705e9e6c79bec2aa96070d62e9292c77906485be098d0121d2bfd97f3116/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f796f6c6f76352d7374726f6e67736f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/60b2705e9e6c79bec2aa96070d62e9292c77906485be098d0121d2bfd97f3116/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f796f6c6f76352d7374726f6e67736f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kadirnar/yolov5-strongsort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Minimal PyTorch implementation of YOLOv5 and \u003ca href=\"https://github.com/dyhBUPT/StrongSORT\"\u003eStrongSORT\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZQPei/deep_sort_pytorch\"\u003eZQPei/deep_sort_pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e49a7dddf46fb80d2ecf977929eb53eeba5c008d64ef2ef40659403a420e0d7a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a515065692f646565705f736f72745f7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e49a7dddf46fb80d2ecf977929eb53eeba5c008d64ef2ef40659403a420e0d7a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a515065692f646565705f736f72745f7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZQPei/deep_sort_pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : MOT using deepsort and yolov3 with pytorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qidian213/deep_sort_yolov3\"\u003eQidian213/deep_sort_yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/26f8b901a4328b0c940ed55bfeff7d0a5d25968fca6f6ff6513ff4ef3f445289/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51696469616e3231332f646565705f736f72745f796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/26f8b901a4328b0c940ed55bfeff7d0a5d25968fca6f6ff6513ff4ef3f445289/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51696469616e3231332f646565705f736f72745f796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qidian213/deep_sort_yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time Multi-person tracker using YOLO v3 and deep_sort with tensorflow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/JudasDie/SOTS\"\u003eCSTrack\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0417c1714faac932571dea60a379cc09db465c35950eaaa15d40830b07632f16/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a756461734469652f534f54533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0417c1714faac932571dea60a379cc09db465c35950eaaa15d40830b07632f16/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a756461734469652f534f54533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/JudasDie/SOTS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Rethinking the competition between detection and ReID in Multi-Object Tracking\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2010.12138\" rel=\"nofollow\"\u003earXiv 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Guanghan/ROLO\"\u003eROLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0d8540e70b225bc7601aba0d72612ebfba89516cbaa938103f3e72622efb09ec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4775616e6768616e2f524f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0d8540e70b225bc7601aba0d72612ebfba89516cbaa938103f3e72622efb09ec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4775616e6768616e2f524f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Guanghan/ROLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ROLO is short for Recurrent YOLO, aimed at simultaneous object detection and tracking.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/GeekAlexis/FastMOT\"\u003eFastMOT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e5b45e39d63fb400e7b0d007cc35310eccdef6975f4adcab8c3f6124250cfa26/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4765656b416c657869732f466173744d4f543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e5b45e39d63fb400e7b0d007cc35310eccdef6975f4adcab8c3f6124250cfa26/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4765656b416c657869732f466173744d4f543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/GeekAlexis/FastMOT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"FastMOT: High-Performance Multiple Object Tracking Based on Deep SORT and KLT\". (\u003cstrong\u003e\u003ca href=\"https://doi.org/10.5281/zenodo.4294717\" rel=\"nofollow\"\u003eZenodo 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Sharpiless/Yolov5-deepsort-inference\"\u003eSharpiless/Yolov5-deepsort-inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9329eb8975820f5bc7edf10dc3b3560d6aa018750ce60723726c6296cfd1ec48/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76352d64656570736f72742d696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9329eb8975820f5bc7edf10dc3b3560d6aa018750ce60723726c6296cfd1ec48/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76352d64656570736f72742d696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Sharpiless/Yolov5-deepsort-inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä½¿ç”¨YOLOv5+Deepsortå®žçŽ°è½¦è¾†è¡Œäººè¿½è¸ªå’Œè®¡æ•°ï¼Œä»£ç å°è£…æˆä¸€ä¸ªDetectorç±»ï¼Œæ›´å®¹æ˜“åµŒå…¥åˆ°è‡ªå·±çš„é¡¹ç›®ä¸­ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Sharpiless/Yolov5-Deepsort\"\u003eSharpiless/Yolov5-Deepsort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4e0987e19a04a04855db73d5f86122ea86423fe36a8798be2ab10e3590a61d6c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76352d44656570736f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4e0987e19a04a04855db73d5f86122ea86423fe36a8798be2ab10e3590a61d6c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76352d44656570736f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Sharpiless/Yolov5-Deepsort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : æœ€æ–°ç‰ˆæœ¬yolov5+deepsortç›®æ ‡æ£€æµ‹å’Œè¿½è¸ªï¼Œèƒ½å¤Ÿæ˜¾ç¤ºç›®æ ‡ç±»åˆ«ï¼Œæ”¯æŒ5.0ç‰ˆæœ¬å¯è®­ç»ƒè‡ªå·±æ•°æ®é›†ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LeonLok/Multi-Camera-Live-Object-Tracking\"\u003eLeonLok/Multi-Camera-Live-Object-Tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f12c7f3f0a8f1e6eebd2a985d116f1cfaedd8433f24866adeac40375f6940227/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c656f6e4c6f6b2f4d756c74692d43616d6572612d4c6976652d4f626a6563742d547261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f12c7f3f0a8f1e6eebd2a985d116f1cfaedd8433f24866adeac40375f6940227/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c656f6e4c6f6b2f4d756c74692d43616d6572612d4c6976652d4f626a6563742d547261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LeonLok/Multi-Camera-Live-Object-Tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Multi-camera live traffic and object counting with YOLO v4, Deep SORT, and Flask.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LeonLok/Deep-SORT-YOLOv4\"\u003eLeonLok/Deep-SORT-YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e2ccc7a646fd5ae0bf0e458fdeefb06e9dea5630fb7c848feccac5826773fa82/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c656f6e4c6f6b2f446565702d534f52542d594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e2ccc7a646fd5ae0bf0e458fdeefb06e9dea5630fb7c848feccac5826773fa82/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c656f6e4c6f6b2f446565702d534f52542d594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LeonLok/Deep-SORT-YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : People detection and optional tracking with Tensorflow backend.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/obendidi/Tracking-with-darkflow\"\u003eobendidi/Tracking-with-darkflow\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2c0aa7376d70e4883db9a106d067075cfec9de623e2d76b1ad8c8489ef031264/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f62656e646964692f547261636b696e672d776974682d6461726b666c6f773f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2c0aa7376d70e4883db9a106d067075cfec9de623e2d76b1ad8c8489ef031264/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f62656e646964692f547261636b696e672d776974682d6461726b666c6f773f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/obendidi/Tracking-with-darkflow?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time people Multitracker using YOLO v2 and deep_sort with tensorflow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DrewNF/Tensorflow_Object_Tracking_Video\"\u003eDrewNF/Tensorflow_Object_Tracking_Video\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b07d17b586a58352238796f028c345f363a060d7af794d174d4f249e96de461a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f447265774e462f54656e736f72666c6f775f4f626a6563745f547261636b696e675f566964656f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b07d17b586a58352238796f028c345f363a060d7af794d174d4f249e96de461a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f447265774e462f54656e736f72666c6f775f4f626a6563745f547261636b696e675f566964656f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DrewNF/Tensorflow_Object_Tracking_Video?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object Tracking in Tensorflow ( Localization Detection Classification ) developed to partecipate to ImageNET VID competition.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dyh/unbox_yolov5_deepsort_counting\"\u003edyh/unbox_yolov5_deepsort_counting\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/811fc3285b0629b539c49da1cb3c99036a8e60dda7674e2a7664420e1b8155e1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6479682f756e626f785f796f6c6f76355f64656570736f72745f636f756e74696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/811fc3285b0629b539c49da1cb3c99036a8e60dda7674e2a7664420e1b8155e1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6479682f756e626f785f796f6c6f76355f64656570736f72745f636f756e74696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dyh/unbox_yolov5_deepsort_counting?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5 deepsort è¡Œäºº è½¦è¾† è·Ÿè¸ª æ£€æµ‹ è®¡æ•°ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/theAIGuysCode/yolov3_deepsort\"\u003etheAIGuysCode/yolov3_deepsort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/30d37a7b57424be6b33cfca88989b7342b545f6455a7446146a69285a70f0d5f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746865414947757973436f64652f796f6c6f76335f64656570736f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/30d37a7b57424be6b33cfca88989b7342b545f6455a7446146a69285a70f0d5f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746865414947757973436f64652f796f6c6f76335f64656570736f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/theAIGuysCode/yolov3_deepsort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object tracking implemented with YOLOv3, Deep Sort and Tensorflow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/weixu000/libtorch-yolov3-deepsort\"\u003eweixu000/libtorch-yolov3-deepsort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/849460b5d0c6f920aa3840d83f19d59015f8e6cfb3c3897ba5e985b1a354d913/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77656978753030302f6c6962746f7263682d796f6c6f76332d64656570736f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/849460b5d0c6f920aa3840d83f19d59015f8e6cfb3c3897ba5e985b1a354d913/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77656978753030302f6c6962746f7263682d796f6c6f76332d64656570736f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/weixu000/libtorch-yolov3-deepsort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : libtorch-yolov3-deepsort.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pmj110119/YOLOX_deepsort_tracker\"\u003epmj110119/YOLOX_deepsort_tracker\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c51199a74fd0dc140bd2971c4e2fe2557a6e1c4d7c22c06e1400883bc5078efd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706d6a3131303131392f594f4c4f585f64656570736f72745f747261636b65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c51199a74fd0dc140bd2971c4e2fe2557a6e1c4d7c22c06e1400883bc5078efd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706d6a3131303131392f594f4c4f585f64656570736f72745f747261636b65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pmj110119/YOLOX_deepsort_tracker?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : using yolox+deepsort for object-tracking.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/abhyantrika/nanonets_object_tracking\"\u003eabhyantrika/nanonets_object_tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9eb415453040721d3563b2284f87645fc2ec08f93d86797f47ebc5b28bf7f012/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61626879616e7472696b612f6e616e6f6e6574735f6f626a6563745f747261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9eb415453040721d3563b2284f87645fc2ec08f93d86797f47ebc5b28bf7f012/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61626879616e7472696b612f6e616e6f6e6574735f6f626a6563745f747261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/abhyantrika/nanonets_object_tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : nanonets_object_tracking.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mattzheng/keras-yolov3-KF-objectTracking\"\u003emattzheng/keras-yolov3-KF-objectTracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/71cdf67fe4fe9d5f6ba36e2ec506c0ca6f12a2fc5d1aee7f6d2ffe7da7443ecd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6174747a68656e672f6b657261732d796f6c6f76332d4b462d6f626a656374547261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/71cdf67fe4fe9d5f6ba36e2ec506c0ca6f12a2fc5d1aee7f6d2ffe7da7443ecd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6174747a68656e672f6b657261732d796f6c6f76332d4b462d6f626a656374547261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mattzheng/keras-yolov3-KF-objectTracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä»¥kears-yolov3åšdetectorï¼Œä»¥Kalman-Filterç®—æ³•åštrackerï¼Œè¿›è¡Œå¤šäººç‰©ç›®æ ‡è¿½è¸ªã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/rohanchandra30/TrackNPred\"\u003erohanchandra30/TrackNPred\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4670ffc4d659cc580390012512bbf7304316e323a32c7b0e14928566cfdc9ece/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f68616e6368616e64726133302f547261636b4e507265643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4670ffc4d659cc580390012512bbf7304316e323a32c7b0e14928566cfdc9ece/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f68616e6368616e64726133302f547261636b4e507265643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/rohanchandra30/TrackNPred?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Software Framework for End-to-End Trajectory Prediction.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RichardoMrMu/yolov5-deepsort-tensorrt\"\u003eRichardoMrMu/yolov5-deepsort-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a8f933159d9398c0a5357add7b3465ede4bd09ef0369c6672f6817febb12b4f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f526963686172646f4d724d752f796f6c6f76352d64656570736f72742d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a8f933159d9398c0a5357add7b3465ede4bd09ef0369c6672f6817febb12b4f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f526963686172646f4d724d752f796f6c6f76352d64656570736f72742d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RichardoMrMu/yolov5-deepsort-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A c++ implementation of yolov5 and deepsort.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bamwani/car-counting-and-speed-estimation-yolo-sort-python\"\u003ebamwani/car-counting-and-speed-estimation-yolo-sort-python\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7038cf4fe7d5ad687f7e6c96dc649239e3a84b6ac098fd069a0d49e1e4108308/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62616d77616e692f6361722d636f756e74696e672d616e642d73706565642d657374696d6174696f6e2d796f6c6f2d736f72742d707974686f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7038cf4fe7d5ad687f7e6c96dc649239e3a84b6ac098fd069a0d49e1e4108308/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62616d77616e692f6361722d636f756e74696e672d616e642d73706565642d657374696d6174696f6e2d796f6c6f2d736f72742d707974686f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bamwani/car-counting-and-speed-estimation-yolo-sort-python?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This project imlements the following tasks in the project: 1. Vehicle counting, 2. Lane detection. 3.Lane change detection and 4.speed estimation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ArtLabss/tennis-tracking\"\u003eArtLabss/tennis-tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4f87c977d889e021c49a4bbf105a148468b965911ab385d2f25093f0322d725c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4172744c616273732f74656e6e69732d747261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4f87c977d889e021c49a4bbf105a148468b965911ab385d2f25093f0322d725c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4172744c616273732f74656e6e69732d747261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ArtLabss/tennis-tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Open-source Monocular Python HawkEye for Tennis.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CaptainEven/YOLOV4_MCMOT\"\u003eCaptainEven/YOLOV4_MCMOT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a2034011cc4e3f8b30282201c639ce1d8442f2eaaf6622401113cfdade1d014c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4361707461696e4576656e2f594f4c4f56345f4d434d4f543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a2034011cc4e3f8b30282201c639ce1d8442f2eaaf6622401113cfdade1d014c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4361707461696e4576656e2f594f4c4f56345f4d434d4f543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CaptainEven/YOLOV4_MCMOT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Using YOLOV4 as detector for MCMOT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/opendatacam/node-moving-things-tracker\"\u003eopendatacam/node-moving-things-tracker\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/46fa9cb9a0f90a0ed982c7694bcd021fce4fc51d74eecc8419012f5b2667474f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e6461746163616d2f6e6f64652d6d6f76696e672d7468696e67732d747261636b65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/46fa9cb9a0f90a0ed982c7694bcd021fce4fc51d74eecc8419012f5b2667474f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e6461746163616d2f6e6f64652d6d6f76696e672d7468696e67732d747261636b65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/opendatacam/node-moving-things-tracker?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : javascript implementation of \"tracker by detections\" for realtime multiple object tracking (MOT).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lanmengyiyu/yolov5-deepmar\"\u003elanmengyiyu/yolov5-deepmar\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e2698e1e58c1f96c287d4398621a3409cb6cd80b87d5f5a3d490cd30c72bd284/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c616e6d656e67796979752f796f6c6f76352d646565706d61723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e2698e1e58c1f96c287d4398621a3409cb6cd80b87d5f5a3d490cd30c72bd284/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c616e6d656e67796979752f796f6c6f76352d646565706d61723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lanmengyiyu/yolov5-deepmar?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¡Œäººè½¨è¿¹å’Œå±žæ€§åˆ†æžã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zengwb-lx/Yolov5-Deepsort-Fastreid\"\u003ezengwb-lx/Yolov5-Deepsort-Fastreid\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/13f3a37dc4717ab14b686ea63419ea9b14a3875db5ea633c2bee28919b7e4cac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a656e6777622d6c782f596f6c6f76352d44656570736f72742d46617374726569643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/13f3a37dc4717ab14b686ea63419ea9b14a3875db5ea633c2bee28919b7e4cac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a656e6777622d6c782f596f6c6f76352d44656570736f72742d46617374726569643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zengwb-lx/Yolov5-Deepsort-Fastreid?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV5 + deepsort + Fast-ReID å®Œæ•´è¡Œäººé‡è¯†åˆ«ç³»ç»Ÿã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tensorturtle/classy-sort-yolov5\"\u003etensorturtle/classy-sort-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a3e0ebefd361ea0bb2e883d7ac105fbd0bc67e6192534631f628b1ca70787233/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74656e736f72747572746c652f636c617373792d736f72742d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a3e0ebefd361ea0bb2e883d7ac105fbd0bc67e6192534631f628b1ca70787233/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74656e736f72747572746c652f636c617373792d736f72742d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tensorturtle/classy-sort-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Ready-to-use realtime multi-object tracker that works for any object category. YOLOv5 + SORT implementation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/supperted825/FairMOT-X\"\u003esupperted825/FairMOT-X\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b4def26ffefb7c772395f004f30fd2a693ea4b9b2f4afda1bb8570edeecc2442/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7375707065727465643832352f466169724d4f542d583f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b4def26ffefb7c772395f004f30fd2a693ea4b9b2f4afda1bb8570edeecc2442/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7375707065727465643832352f466169724d4f542d583f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/supperted825/FairMOT-X?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : FairMOT for Multi-Class MOT using YOLOX as Detector.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/deyiwang89/pytorch-yolov7-deepsort\"\u003edeyiwang89/pytorch-yolov7-deepsort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c1ac3640086c592912c2586ed612dc94369d02eed2176c3d9a421ada4194fa2a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6465796977616e6738392f7079746f7263682d796f6c6f76372d64656570736f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c1ac3640086c592912c2586ed612dc94369d02eed2176c3d9a421ada4194fa2a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6465796977616e6738392f7079746f7263682d796f6c6f76372d64656570736f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/deyiwang89/pytorch-yolov7-deepsort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : an implentation of yolov7-deepsort based on pytorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xuarehere/yolovx_deepsort_pytorch\"\u003exuarehere/yolovx_deepsort_pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/dc5d2d943abd157cdc0df39eaf7dfcc6641e75063320653aca6e40e287e7895d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7875617265686572652f796f6c6f76785f64656570736f72745f7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dc5d2d943abd157cdc0df39eaf7dfcc6641e75063320653aca6e40e287e7895d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7875617265686572652f796f6c6f76785f64656570736f72745f7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xuarehere/yolovx_deepsort_pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : this project support the existing yolo detection model algorithm (YOLOv3, YOLOV4, YOLOV4Scaled, YOLOV5, YOLOV6, YOLOV7 ).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/deshwalmahesh/yolov7-deepsort-tracking\"\u003edeshwalmahesh/yolov7-deepsort-tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1782a46c0153a9bb32e17e8d712a0697f78705b018fe20183ad23f649fe98631/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6465736877616c6d61686573682f796f6c6f76372d64656570736f72742d747261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1782a46c0153a9bb32e17e8d712a0697f78705b018fe20183ad23f649fe98631/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6465736877616c6d61686573682f796f6c6f76372d64656570736f72742d747261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/deshwalmahesh/yolov7-deepsort-tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Modular and ready to deploy code to detect and track videos using YOLO-v7 and DeepSORT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RizwanMunawar/yolov7-object-tracking\"\u003eRizwanMunawar/yolov7-object-tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/21f5047a24dcec36ae6bc0b1d80895e127659dbd2ef1b5960057dac6e9689326/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d6f626a6563742d747261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/21f5047a24dcec36ae6bc0b1d80895e127659dbd2ef1b5960057dac6e9689326/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d6f626a6563742d747261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RizwanMunawar/yolov7-object-tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv7 Object Tracking Using PyTorch, OpenCV and Sort Tracking.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RizwanMunawar/yolov5-object-tracking\"\u003eRizwanMunawar/yolov5-object-tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7327b5cf88409de11a1d898aa5a0e57479ef580171fcae5813ec2bcca48c8d39/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76352d6f626a6563742d747261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7327b5cf88409de11a1d898aa5a0e57479ef580171fcae5813ec2bcca48c8d39/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76352d6f626a6563742d747261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RizwanMunawar/yolov5-object-tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 Object Tracking + Detection + Object Blurring + Streamlit Dashboard Using OpenCV, PyTorch and Streamlit.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Smorodov/Multitarget-tracker\"\u003eSmorodov/Multitarget-tracker\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9872c2cce9a4ad31051d24617d7d7afa9f56003d5c3864061875c2083ddf65d4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536d6f726f646f762f4d756c74697461726765742d747261636b65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9872c2cce9a4ad31051d24617d7d7afa9f56003d5c3864061875c2083ddf65d4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536d6f726f646f762f4d756c74697461726765742d747261636b65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Smorodov/Multitarget-tracker?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Multiple Object Tracker, Based on Hungarian algorithm + Kalman filter.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Naughty-Galileo/YoloV5_MCMOT\"\u003eNaughty-Galileo/YoloV5_MCMOT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/446b0f7dcb0ad8091a9cfc77ea5b129a82174c627f02a18b1bb7b80efe4530ac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e6175676874792d47616c696c656f2f596f6c6f56355f4d434d4f543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/446b0f7dcb0ad8091a9cfc77ea5b129a82174c627f02a18b1bb7b80efe4530ac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e6175676874792d47616c696c656f2f596f6c6f56355f4d434d4f543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Naughty-Galileo/YoloV5_MCMOT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : å¤šç±»åˆ«å¤šç›®æ ‡è·Ÿè¸ªYoloV5+sort/deepsort/bytetrack/BotSort/motdt.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MuhammadMoinFaisal/YOLOv8-DeepSORT-Object-Tracking\"\u003eMuhammadMoinFaisal/YOLOv8-DeepSORT-Object-Tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/018dc7fafc1d62d25317d39fcc12c0a2472d0bef26a92814de088555080fec03/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d7568616d6d61644d6f696e46616973616c2f594f4c4f76382d44656570534f52542d4f626a6563742d547261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/018dc7fafc1d62d25317d39fcc12c0a2472d0bef26a92814de088555080fec03/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d7568616d6d61644d6f696e46616973616c2f594f4c4f76382d44656570534f52542d4f626a6563742d547261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MuhammadMoinFaisal/YOLOv8-DeepSORT-Object-Tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv8 Object Tracking using PyTorch, OpenCV and DeepSORT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sujanshresstha/YOLO-NAS_DeepSORT\"\u003esujanshresstha/YOLO-NAS_DeepSORT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8e769fcf0c31a4d641d5edb643ea1b3526fb6100ee9e5ef9e6fd4f9a986918c3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756a616e7368726573737468612f594f4c4f2d4e41535f44656570534f52543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8e769fcf0c31a4d641d5edb643ea1b3526fb6100ee9e5ef9e6fd4f9a986918c3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756a616e7368726573737468612f594f4c4f2d4e41535f44656570534f52543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sujanshresstha/YOLO-NAS_DeepSORT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository contains code for object tracking in videos using the YOLO-NAS object detection model and the DeepSORT algorithm.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eDynamic Object Tracking\u003c/h4\u003e\u003ca id=\"user-content-dynamic-object-tracking\" class=\"anchor\" aria-label=\"Permalink: Dynamic Object Tracking\" href=\"#dynamic-object-tracking\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eåŠ¨æ€ç›®æ ‡è·Ÿè¸ª\u003c/h5\u003e\u003ca id=\"user-content-åŠ¨æ€ç›®æ ‡è·Ÿè¸ª\" class=\"anchor\" aria-label=\"Permalink: åŠ¨æ€ç›®æ ‡è·Ÿè¸ª\" href=\"#åŠ¨æ€ç›®æ ‡è·Ÿè¸ª\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/PolyU-AIRO-Lab/AUTO\"\u003ePolyU-AIRO-Lab/AUTO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6deaf090abd7080177b1581953d345170dd8610b06239131dd93d2b2d91eb4c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506f6c79552d4149524f2d4c61622f4155544f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6deaf090abd7080177b1581953d345170dd8610b06239131dd93d2b2d91eb4c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506f6c79552d4149524f2d4c61622f4155544f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PolyU-AIRO-Lab/AUTO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Dynamic Object Tracking on Autonomous UAV System for Surveillance Applications\". (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/1424-8220/21/23/7888\" rel=\"nofollow\"\u003eSensors 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eDeep Reinforcement Learning\u003c/h4\u003e\u003ca id=\"user-content-deep-reinforcement-learning\" class=\"anchor\" aria-label=\"Permalink: Deep Reinforcement Learning\" href=\"#deep-reinforcement-learning\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eæ·±åº¦å¼ºåŒ–å­¦ä¹ \u003c/h4\u003e\u003ca id=\"user-content-æ·±åº¦å¼ºåŒ–å­¦ä¹ \" class=\"anchor\" aria-label=\"Permalink: æ·±åº¦å¼ºåŒ–å­¦ä¹ \" href=\"#æ·±åº¦å¼ºåŒ–å­¦ä¹ \"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/uzkent/EfficientObjectDetection\"\u003euzkent/EfficientObjectDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0e44dc6bdfe533c1e9480a596644652a5aef1cbbf59b7872670372ef1c34abbb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f757a6b656e742f456666696369656e744f626a656374446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0e44dc6bdfe533c1e9480a596644652a5aef1cbbf59b7872670372ef1c34abbb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f757a6b656e742f456666696369656e744f626a656374446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/uzkent/EfficientObjectDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Efficient Object Detection in Large Images with Deep Reinforcement Learning\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_WACV_2020/html/Uzkent_Efficient_Object_Detection_in_Large_Images_Using_Deep_Reinforcement_Learning_WACV_2020_paper.html\" rel=\"nofollow\"\u003eWACV 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eMotion Control Field\u003c/h4\u003e\u003ca id=\"user-content-motion-control-field\" class=\"anchor\" aria-label=\"Permalink: Motion Control Field\" href=\"#motion-control-field\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eè¿åŠ¨æŽ§åˆ¶é¢†åŸŸ\u003c/h4\u003e\u003ca id=\"user-content-è¿åŠ¨æŽ§åˆ¶é¢†åŸŸ\" class=\"anchor\" aria-label=\"Permalink: è¿åŠ¨æŽ§åˆ¶é¢†åŸŸ\" href=\"#è¿åŠ¨æŽ§åˆ¶é¢†åŸŸ\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/icns-distributed-cloud/adaptive-cruise-control\"\u003eicns-distributed-cloud/adaptive-cruise-control\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/31e21e3d3f47ed0227e040f6bf2334b4430563ba34f41b10f272b937fbb2c1db/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69636e732d64697374726962757465642d636c6f75642f61646170746976652d6372756973652d636f6e74726f6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/31e21e3d3f47ed0227e040f6bf2334b4430563ba34f41b10f272b937fbb2c1db/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69636e732d64697374726962757465642d636c6f75642f61646170746976652d6372756973652d636f6e74726f6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/icns-distributed-cloud/adaptive-cruise-control?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO-v5 ê¸°ë°˜ \"ë‹¨ì•ˆ ì¹´ë©”ë¼\"ì˜ ì˜ìƒì„ í™œìš©í•´ ì°¨ê°„ ê±°ë¦¬ë¥¼ ì¼ì •í•˜ê²Œ ìœ ì§€í•˜ë©° ì£¼í–‰í•˜ëŠ” Adaptive Cruise Control ê¸°ëŠ¥ êµ¬í˜„.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LeBronLiHD/ZJU2021_MotionControl_PID_YOLOv5\"\u003eLeBronLiHD/ZJU2021_MotionControl_PID_YOLOv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d50da264fbc427b07f5e5b3083d990ad22327ecfd941c43ecb2206dc62211860/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c6542726f6e4c6948442f5a4a55323032315f4d6f74696f6e436f6e74726f6c5f5049445f594f4c4f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d50da264fbc427b07f5e5b3083d990ad22327ecfd941c43ecb2206dc62211860/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c6542726f6e4c6948442f5a4a55323032315f4d6f74696f6e436f6e74726f6c5f5049445f594f4c4f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LeBronLiHD/ZJU2021_MotionControl_PID_YOLOv5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ZJU2021_MotionControl_PID_YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SananSuleymanov/PID_YOLOv5s_ROS_Diver_Tracking\"\u003eSananSuleymanov/PID_YOLOv5s_ROS_Diver_Tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fa71ca94fdb7ee0e0486e55860d60311fdd1ab595d3d6cdb78969e68fee64916/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53616e616e53756c65796d616e6f762f5049445f594f4c4f7635735f524f535f44697665725f547261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fa71ca94fdb7ee0e0486e55860d60311fdd1ab595d3d6cdb78969e68fee64916/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53616e616e53756c65796d616e6f762f5049445f594f4c4f7635735f524f535f44697665725f547261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SananSuleymanov/PID_YOLOv5s_ROS_Diver_Tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PID_YOLOv5s_ROS_Diver_Tracking.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sumght-z/apex_yolov5\"\u003esumght-z/apex_yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ba77efd812f1d40955bd08010cdc4afc044438aaa74b8b52a501bd954944a9a6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756d6768742d7a2f617065785f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ba77efd812f1d40955bd08010cdc4afc044438aaa74b8b52a501bd954944a9a6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756d6768742d7a2f617065785f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sumght-z/apex_yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : something by yolov5 and PID.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSuper-Resolution Field\u003c/h4\u003e\u003ca id=\"user-content-super-resolution-field\" class=\"anchor\" aria-label=\"Permalink: Super-Resolution Field\" href=\"#super-resolution-field\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eè¶…åˆ†è¾¨çŽ‡é¢†åŸŸ\u003c/h4\u003e\u003ca id=\"user-content-è¶…åˆ†è¾¨çŽ‡é¢†åŸŸ\" class=\"anchor\" aria-label=\"Permalink: è¶…åˆ†è¾¨çŽ‡é¢†åŸŸ\" href=\"#è¶…åˆ†è¾¨çŽ‡é¢†åŸŸ\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/Fireboltz/Psychic-CCTV\"\u003eFireboltz/Psychic-CCTV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b4a0523234bbf50f90d87f13709ae100437484457815c6523f4d79b488092a75/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46697265626f6c747a2f507379636869632d434354563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b4a0523234bbf50f90d87f13709ae100437484457815c6523f4d79b488092a75/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46697265626f6c747a2f507379636869632d434354563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Fireboltz/Psychic-CCTV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A video analysis tool built completely in python.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSpiking Neural Network\u003c/h4\u003e\u003ca id=\"user-content-spiking-neural-network\" class=\"anchor\" aria-label=\"Permalink: Spiking Neural Network\" href=\"#spiking-neural-network\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSNN, è„‰å†²ç¥žç»ç½‘ç»œ\u003c/h4\u003e\u003ca id=\"user-content-snn-è„‰å†²ç¥žç»ç½‘ç»œ\" class=\"anchor\" aria-label=\"Permalink: SNN, è„‰å†²ç¥žç»ç½‘ç»œ\" href=\"#snn-è„‰å†²ç¥žç»ç½‘ç»œ\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BICLab/SpikeYOLO\"\u003eSpikeYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/41a0050325c28ee3f18f80d7c7b5ebe9cf4505b2ddf3838c99fe9eb5648a51c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f5370696b65594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/41a0050325c28ee3f18f80d7c7b5ebe9cf4505b2ddf3838c99fe9eb5648a51c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f5370696b65594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BICLab/SpikeYOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Offical implementation of \"Integer-Valued Training and Spike-Driven Inference Spiking Neural Network for High-performance and Energy-efficient Object Detection\" (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2407.20708\" rel=\"nofollow\"\u003eECCV 2024 Oral\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BICLab/EMS-YOLO\"\u003eEMS-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8897198d23a8f79c45c3d4156f7537b42f0540dc212dfc741a71f37cf2fa8d95/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f454d532d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8897198d23a8f79c45c3d4156f7537b42f0540dc212dfc741a71f37cf2fa8d95/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f454d532d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BICLab/EMS-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Offical implementation of \"Deep Directly-Trained Spiking Neural Networks for Object Detection\" (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/ICCV2023/html/Su_Deep_Directly-Trained_Spiking_Neural_Networks_for_Object_Detection_ICCV_2023_paper.html\" rel=\"nofollow\"\u003eICCV 2023\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BICLab/Attention-SNN\"\u003eAttention-SNN\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/be6c15e9a289cc50c46a51964acba8a0d7607c3b2cdb7635dc98cc6b75152abf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f417474656e74696f6e2d534e4e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/be6c15e9a289cc50c46a51964acba8a0d7607c3b2cdb7635dc98cc6b75152abf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f417474656e74696f6e2d534e4e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BICLab/Attention-SNN?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Offical implementation of \"Attention Spiking Neural Networks\" (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/10032591\" rel=\"nofollow\"\u003eIEEE TPAMI 2023\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BICLab/Spike-Driven-Transformer\"\u003eSpike-Driven-Transformer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/334f77eed46cdea5ba7e395ae56bb5033f93d21645a71b90639bd1bff7b54887/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f5370696b652d44726976656e2d5472616e73666f726d65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/334f77eed46cdea5ba7e395ae56bb5033f93d21645a71b90639bd1bff7b54887/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f5370696b652d44726976656e2d5472616e73666f726d65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BICLab/Spike-Driven-Transformer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Offical implementation of \"Spike-driven Transformer\" (\u003cstrong\u003e\u003ca href=\"https://openreview.net/forum?id=9FmolyOHi5\" rel=\"nofollow\"\u003eNeurIPS 2023\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BICLab/Spike-Driven-Transformer-V2\"\u003eSpike-Driven-Transformer-V2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/10d2ea5bc789cf7b780cc3fca3a4dcdc28f302d20cf45b2e18def7b96f78b40f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f5370696b652d44726976656e2d5472616e73666f726d65722d56323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/10d2ea5bc789cf7b780cc3fca3a4dcdc28f302d20cf45b2e18def7b96f78b40f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f5370696b652d44726976656e2d5472616e73666f726d65722d56323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BICLab/Spike-Driven-Transformer-V2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Offical implementation of \"Spike-driven Transformer V2: Meta Spiking Neural Network Architecture Inspiring the Design of Next-generation Neuromorphic Chips\" (\u003cstrong\u003e\u003ca href=\"https://openreview.net/forum?id=1SIBN5Xyw7\" rel=\"nofollow\"\u003eICLR 2024\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cwq159/PyTorch-Spiking-YOLOv3\"\u003eSpiking-YOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/71c7028763ccd0ce46c8757d0a13422483ac5a7019de0437c1bd91f8f0413bc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6377713135392f5079546f7263682d5370696b696e672d594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/71c7028763ccd0ce46c8757d0a13422483ac5a7019de0437c1bd91f8f0413bc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6377713135392f5079546f7263682d5370696b696e672d594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cwq159/PyTorch-Spiking-YOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A PyTorch implementation of Spiking-YOLOv3. Two branches are provided, based on two common PyTorch implementation of YOLOv3(\u003ca href=\"https://github.com/ultralytics/yolov3\"\u003eultralytics/yolov3\u003c/a\u003e \u0026amp; \u003ca href=\"https://github.com/eriklindernoren/PyTorch-YOLOv3\"\u003eeriklindernoren/PyTorch-YOLOv3\u003c/a\u003e), with support for Spiking-YOLOv3-Tiny at present. (\u003cstrong\u003e\u003ca href=\"https://ojs.aaai.org/index.php/AAAI/article/view/6787\" rel=\"nofollow\"\u003eAAAI 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fjcu-ee-islab/Spiking_Converted_YOLOv4\"\u003efjcu-ee-islab/Spiking_Converted_YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e6d346e5d914106b0ce88895ef1b7ed9b1f7fd4d7b9aca19b5e904bc5e0f5a76/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666a63752d65652d69736c61622f5370696b696e675f436f6e7665727465645f594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e6d346e5d914106b0ce88895ef1b7ed9b1f7fd4d7b9aca19b5e904bc5e0f5a76/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666a63752d65652d69736c61622f5370696b696e675f436f6e7665727465645f594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/fjcu-ee-islab/Spiking_Converted_YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object Detection Based on Dynamic Vision Sensor with Spiking Neural Network.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Zaabon/spiking_yolo\"\u003eZaabon/spiking_yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/804493d306470af6971dea8b70a9ff32414748ac56a60cc21aef6b3afa4b7a6a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a6161626f6e2f7370696b696e675f796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/804493d306470af6971dea8b70a9ff32414748ac56a60cc21aef6b3afa4b7a6a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a6161626f6e2f7370696b696e675f796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Zaabon/spiking_yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This project is a combined neural network utilizing an spiking CNN with backpropagation and YOLOv3 for object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Dignity-ghost/PyTorch-Spiking-YOLOv3\"\u003eDignity-ghost/PyTorch-Spiking-YOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5b1d3c06a4d9c751c551c6365468a64af4cb0f1ed1fed85c70092a4f447b5735/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4469676e6974792d67686f73742f5079546f7263682d5370696b696e672d594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5b1d3c06a4d9c751c551c6365468a64af4cb0f1ed1fed85c70092a4f447b5735/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4469676e6974792d67686f73742f5079546f7263682d5370696b696e672d594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Dignity-ghost/PyTorch-Spiking-YOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A modified repository based on \u003ca href=\"https://github.com/cwq159/PyTorch-Spiking-YOLOv3\"\u003eSpiking-YOLOv3\u003c/a\u003e and \u003ca href=\"https://pjreddie.com/darknet/yolo\" rel=\"nofollow\"\u003eYOLOv3\u003c/a\u003e, which makes it suitable for VOC-dataset and YOLOv2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/beauty-girl-cxy/spiking-yolov5\"\u003ebeauty-girl-cxy/spiking-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1186151c1028620e7494a9646e9d34e66e07f7111028755240f55945fe96a235/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6265617574792d6769726c2d6378792f7370696b696e672d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1186151c1028620e7494a9646e9d34e66e07f7111028755240f55945fe96a235/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6265617574792d6769726c2d6378792f7370696b696e672d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/beauty-girl-cxy/spiking-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : spiking-yolov5.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAttention and Transformer\u003c/h4\u003e\u003ca id=\"user-content-attention-and-transformer\" class=\"anchor\" aria-label=\"Permalink: Attention and Transformer\" href=\"#attention-and-transformer\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eæ³¨æ„åŠ›æœºåˆ¶\u003c/h4\u003e\u003ca id=\"user-content-æ³¨æ„åŠ›æœºåˆ¶\" class=\"anchor\" aria-label=\"Permalink: æ³¨æ„åŠ›æœºåˆ¶\" href=\"#æ³¨æ„åŠ›æœºåˆ¶\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xmu-xiaoma666/External-Attention-pytorch\"\u003exmu-xiaoma666/External-Attention-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0887e57d805705f73c1fecb4d4ed81ad30e39ecb36486deed4a2606efcbd7fd0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f786d752d7869616f6d613636362f45787465726e616c2d417474656e74696f6e2d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0887e57d805705f73c1fecb4d4ed81ad30e39ecb36486deed4a2606efcbd7fd0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f786d752d7869616f6d613636362f45787465726e616c2d417474656e74696f6e2d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xmu-xiaoma666/External-Attention-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ€ Pytorch implementation of various Attention Mechanisms, MLP, Re-parameter, Convolution, which is helpful to further understand papers.â­â­â­.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MenghaoGuo/Awesome-Vision-Attentions\"\u003eMenghaoGuo/Awesome-Vision-Attentions\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d65d130c14de8312a4e4d17311bdd340eafbdb3a02a2520f872e648fcfd6085c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d656e6768616f47756f2f417765736f6d652d566973696f6e2d417474656e74696f6e733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d65d130c14de8312a4e4d17311bdd340eafbdb3a02a2520f872e648fcfd6085c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d656e6768616f47756f2f417765736f6d652d566973696f6e2d417474656e74696f6e733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MenghaoGuo/Awesome-Vision-Attentions?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Summary of related papers on visual attention. Related code will be released based on Jittor gradually. \"Attention Mechanisms in Computer Vision: A Survey\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2111.07624\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pprp/awesome-attention-mechanism-in-cv\"\u003epprp/awesome-attention-mechanism-in-cv\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/49500e7c2920ff7778564c00d590a0d3c820bb53a559ba7eeb6380805ca44d6c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f707072702f617765736f6d652d617474656e74696f6e2d6d656368616e69736d2d696e2d63763f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/49500e7c2920ff7778564c00d590a0d3c820bb53a559ba7eeb6380805ca44d6c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f707072702f617765736f6d652d617474656e74696f6e2d6d656368616e69736d2d696e2d63763f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pprp/awesome-attention-mechanism-in-cv?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ‘Š CVä¸­å¸¸ç”¨æ³¨æ„åŠ›æ¨¡å—;å³æ’å³ç”¨æ¨¡å—;ViTæ¨¡åž‹. PyTorch Implementation Collection of Attention Module and Plug\u0026amp;Play Module.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bfshi/AbSViT\"\u003eAbSViT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a84aa393bbc6b480e4f0182eb775e352849c360c1f05b8c2ea5a57d6fab97261/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62667368692f4162535669543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a84aa393bbc6b480e4f0182eb775e352849c360c1f05b8c2ea5a57d6fab97261/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62667368692f4162535669543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bfshi/AbSViT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Top-Down Visual Attention from Analysis by Synthesis\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2303.13043\" rel=\"nofollow\"\u003eCVPR 2023\u003c/a\u003e\u003c/strong\u003e). \"å¾®ä¿¡å…¬ä¼—å·ã€Œäººå·¥æ™ºèƒ½å‰æ²¿è®²ä¹ ã€ã€Š\u003ca href=\"https://mp.weixin.qq.com/s/FtVd37tOXMfu92eDSvdvbg\" rel=\"nofollow\"\u003eã€æºå¤´æ´»æ°´ã€‘CVPR 2023 | AbSViTï¼šæ‹¥æœ‰è‡ªä¸Šè€Œä¸‹æ³¨æ„åŠ›æœºåˆ¶çš„è§†è§‰Transformer\u003c/a\u003eã€‹\"ã€‚ \"å¾®ä¿¡å…¬ä¼—å·ã€Œæžå¸‚å¹³å°ã€ã€Š\u003ca href=\"https://mp.weixin.qq.com/s/UMA3Vk9L71zUEtNkCshYBg\" rel=\"nofollow\"\u003eCVPR23 Highlightï½œæ‹¥æœ‰top-down attentionèƒ½åŠ›çš„vision transformer\u003c/a\u003eã€‹\"ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HaloTrouvaille/YOLO-Multi-Backbones-Attention\"\u003eHaloTrouvaille/YOLO-Multi-Backbones-Attention\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/08faf0c8b6c0aa04dc2c771b4d3ac11a36bfed368b582663b04a481ca378dcb7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48616c6f54726f757661696c6c652f594f4c4f2d4d756c74692d4261636b626f6e65732d417474656e74696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/08faf0c8b6c0aa04dc2c771b4d3ac11a36bfed368b582663b04a481ca378dcb7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48616c6f54726f757661696c6c652f594f4c4f2d4d756c74692d4261636b626f6e65732d417474656e74696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HaloTrouvaille/YOLO-Multi-Backbones-Attention?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This Repository includes YOLOv3 with some lightweight backbones (ShuffleNetV2, GhostNet, VoVNet), some computer vision attention mechanism (SE Block, CBAM Block, ECA Block), pruning,quantization and distillation for GhostNet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kay-cottage/CoordAttention_YOLOX_Pytorch\"\u003ekay-cottage/CoordAttention_YOLOX_Pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7fa5da34a8ffd9988914ff42e50b7724c4986ca8ffb046dd2ae90717703befde/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b61792d636f74746167652f436f6f7264417474656e74696f6e5f594f4c4f585f5079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7fa5da34a8ffd9988914ff42e50b7724c4986ca8ffb046dd2ae90717703befde/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b61792d636f74746167652f436f6f7264417474656e74696f6e5f594f4c4f585f5079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kay-cottage/CoordAttention_YOLOX_Pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : CoordAttention_YOLOX(åŸºäºŽCoordAttentionåæ ‡æ³¨æ„åŠ›æœºåˆ¶çš„æ”¹è¿›ç‰ˆYOLOXç›®æ ‡æ£€æµ‹å¹³å°ï¼‰ã€‚ \"Coordinate Attention for Efficient Mobile Network Design\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Coordinate_Attention_for_Efficient_Mobile_Network_Design_CVPR_2021_paper.html\" rel=\"nofollow\"\u003eCVPR 2021\u003c/a\u003e, \u003ca href=\"https://github.com/Andrew-Qibin/CoordAttention\"\u003e Andrew-Qibin/CoordAttention\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/liangzhendong123/Attention-yolov5\"\u003eliangzhendong123/Attention-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/90e9149d693c82a2b030c7fc2b7d8757b91d2000efbee7b20f42c757f048698e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c69616e677a68656e646f6e673132332f417474656e74696f6e2d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/90e9149d693c82a2b030c7fc2b7d8757b91d2000efbee7b20f42c757f048698e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c69616e677a68656e646f6e673132332f417474656e74696f6e2d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/liangzhendong123/Attention-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽæ³¨æ„åŠ›æœºåˆ¶æ”¹è¿›çš„yolov5æ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/e96031413/AA-YOLO\"\u003ee96031413/AA-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7984c9687ad284d360bd4ccc7f3d0fe127c4db863b4c99a2e428ddb57ef84428/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6539363033313431332f41412d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7984c9687ad284d360bd4ccc7f3d0fe127c4db863b4c99a2e428ddb57ef84428/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6539363033313431332f41412d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/e96031413/AA-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Attention ALL-CNN Twin Head YOLO (AA -YOLO). \"Improving Tiny YOLO with Fewer Model Parameters\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9643269/\" rel=\"nofollow\"\u003eIEEE BigMM 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/anonymoussss/YOLOX-SwinTransformer\"\u003eanonymoussss/YOLOX-SwinTransformer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9bebcc34b289a647b87f898c74e10f6e8fd30375c412d1866eda8a4658643a56/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616e6f6e796d6f75737373732f594f4c4f582d5377696e5472616e73666f726d65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9bebcc34b289a647b87f898c74e10f6e8fd30375c412d1866eda8a4658643a56/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616e6f6e796d6f75737373732f594f4c4f582d5377696e5472616e73666f726d65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/anonymoussss/YOLOX-SwinTransformer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOX with Swin-Transformer backbone.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/GuanRunwei/MAN-and-CAT\"\u003eGuanRunwei/MAN-and-CAT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6a04407121cce96b2506fd2074723d3e51e97e378493a4930505c32639762fa6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4775616e52756e7765692f4d414e2d616e642d4341543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6a04407121cce96b2506fd2074723d3e51e97e378493a4930505c32639762fa6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4775616e52756e7765692f4d414e2d616e642d4341543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/GuanRunwei/MAN-and-CAT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"MAN and CAT: mix attention to nn and concatenate attention to YOLO\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/article/10.1007/s11227-022-04726-7\" rel=\"nofollow\"\u003e The Journal of Supercomputing, 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOriented Object Detection\u003c/h3\u003e\u003ca id=\"user-content-oriented-object-detection\" class=\"anchor\" aria-label=\"Permalink: Oriented Object Detection\" href=\"#oriented-object-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eæ—‹è½¬ç›®æ ‡æ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-æ—‹è½¬ç›®æ ‡æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: æ—‹è½¬ç›®æ ‡æ£€æµ‹\" href=\"#æ—‹è½¬ç›®æ ‡æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yangxue0827/RotationDetection\"\u003eAlphaRotate\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/41112f1983c41f2de4c34cfeb65a93a8590220fd6f28ed1d385c35d560644573/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f79616e67787565303832372f526f746174696f6e446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/41112f1983c41f2de4c34cfeb65a93a8590220fd6f28ed1d385c35d560644573/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f79616e67787565303832372f526f746174696f6e446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"AlphaRotate: A Rotation Detection Benchmark using TensorFlow\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2111.06677\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hukaixuan19970627/yolov5_obb\"\u003ehukaixuan19970627/yolov5_obb\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e9fe5fdf7c9a8b61d9451d5ff326e88b0861bac8fcb7af3f326b7b5298ad134a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756b61697875616e31393937303632372f796f6c6f76355f6f62623f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e9fe5fdf7c9a8b61d9451d5ff326e88b0861bac8fcb7af3f326b7b5298ad134a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756b61697875616e31393937303632372f796f6c6f76355f6f62623f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hukaixuan19970627/yolov5_obb?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5 + csl_label.(Oriented Object Detection)ï¼ˆRotation Detectionï¼‰ï¼ˆRotated BBoxï¼‰åŸºäºŽyolov5çš„æ—‹è½¬ç›®æ ‡æ£€æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BossZard/rotation-yolov5\"\u003eBossZard/rotation-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a35ec3fedaa6879f5cb1fecb7723572b0597ba69b0935885ac2eb43a7ede5e0b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f73735a6172642f726f746174696f6e2d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a35ec3fedaa6879f5cb1fecb7723572b0597ba69b0935885ac2eb43a7ede5e0b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f73735a6172642f726f746174696f6e2d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BossZard/rotation-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : rotation detection based on yolov5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/acai66/yolov5_rotation\"\u003eacai66/yolov5_rotation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0bd159beded6b8fb1185351a399156ffee972a215ec9fbf48965bb179f0cb64a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6163616936362f796f6c6f76355f726f746174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0bd159beded6b8fb1185351a399156ffee972a215ec9fbf48965bb179f0cb64a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6163616936362f796f6c6f76355f726f746174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/acai66/yolov5_rotation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : rotated bbox detection. inspired by \u003ca href=\"https://github.com/hukaixuan19970627/yolov5_obb\"\u003ehukaixuan19970627/yolov5_obb\u003c/a\u003e, thanks hukaixuan19970627.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ming71/rotate-yolov3\"\u003eming71/rotate-yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e2c510accffc368312c44787609c2f986e379350fd7747801e39b19e50a1567e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696e6737312f726f746174652d796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e2c510accffc368312c44787609c2f986e379350fd7747801e39b19e50a1567e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696e6737312f726f746174652d796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ming71/rotate-yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Arbitrary oriented object detection implemented with yolov3 (attached with some tricks).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ming71/yolov3-polygon\"\u003eming71/yolov3-polygon\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/47e6b51244f178af5139b817ace3ac434b26863b1f3b3c12b90cdd6d39bba6fd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696e6737312f796f6c6f76332d706f6c79676f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/47e6b51244f178af5139b817ace3ac434b26863b1f3b3c12b90cdd6d39bba6fd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696e6737312f796f6c6f76332d706f6c79676f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ming71/yolov3-polygon?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Arbitrary-oriented object detection based on yolov3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kunnnnethan/R-YOLOv4\"\u003ekunnnnethan/R-YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cc3d29dfdfaec77ee17ec13575e9757f7caf600b61d93edb2d39a0a01a9aada8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b756e6e6e6e657468616e2f522d594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cc3d29dfdfaec77ee17ec13575e9757f7caf600b61d93edb2d39a0a01a9aada8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b756e6e6e6e657468616e2f522d594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kunnnnethan/R-YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a PyTorch-based R-YOLOv4 implementation which combines YOLOv4 model and loss function from R3Det for arbitrary oriented object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/XinzeLee/PolygonObjectDetection\"\u003eXinzeLee/PolygonObjectDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/96240edc0d6c0ec2ad319a476dbf633907407b649ee8ea4fe843e311746da2a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f58696e7a654c65652f506f6c79676f6e4f626a656374446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/96240edc0d6c0ec2ad319a476dbf633907407b649ee8ea4fe843e311746da2a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f58696e7a654c65652f506f6c79676f6e4f626a656374446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/XinzeLee/PolygonObjectDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository is based on Ultralytics/yolov5, with adjustments to enable polygon prediction boxes.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hukaixuan19970627/DOTA_devkit_YOLO\"\u003ehukaixuan19970627/DOTA_devkit_YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8d887a1059dd354b9f195e0eab2090df12da6d6b20d9a58ca69dba2c1991b2bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756b61697875616e31393937303632372f444f54415f6465766b69745f594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8d887a1059dd354b9f195e0eab2090df12da6d6b20d9a58ca69dba2c1991b2bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756b61697875616e31393937303632372f444f54415f6465766b69745f594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hukaixuan19970627/DOTA_devkit_YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Trans DOTA OBB format(poly format) to YOLO format.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hpc203/rotate-yolov5-opencv-onnxrun\"\u003ehpc203/rotate-yolov5-opencv-onnxrun\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8e33cb3bec04e1fc67f631757f2819a117660378a217997f37b0afd0acbdd0f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f726f746174652d796f6c6f76352d6f70656e63762d6f6e6e7872756e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8e33cb3bec04e1fc67f631757f2819a117660378a217997f37b0afd0acbdd0f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f726f746174652d796f6c6f76352d6f70656e63762d6f6e6e7872756e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hpc203/rotate-yolov5-opencv-onnxrun?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åˆ†åˆ«ä½¿ç”¨OpenCVã€ONNXRuntimeéƒ¨ç½²yolov5æ—‹è½¬ç›®æ ‡æ£€æµ‹ï¼ŒåŒ…å«C++å’ŒPythonä¸¤ä¸ªç‰ˆæœ¬çš„ç¨‹åºã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hpc203/rotateyolov5-opencv-onnxrun\"\u003ehpc203/rotateyolov5-opencv-onnxrun\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d66bd312942fcfcd8ed8255b80d3b4e062c2c9552f5c15badbcb734f802a0139/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f726f74617465796f6c6f76352d6f70656e63762d6f6e6e7872756e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d66bd312942fcfcd8ed8255b80d3b4e062c2c9552f5c15badbcb734f802a0139/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f726f74617465796f6c6f76352d6f70656e63762d6f6e6e7872756e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hpc203/rotateyolov5-opencv-onnxrun?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åˆ†åˆ«ä½¿ç”¨OpenCVï¼ŒONNXRuntimeéƒ¨ç½²yolov5æ—‹è½¬ç›®æ ‡æ£€æµ‹ï¼ŒåŒ…å«C++å’ŒPythonä¸¤ä¸ªç‰ˆæœ¬çš„ç¨‹åºã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kunnnnethan/R-YOLOv4\"\u003ekunnnnethan/R-YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cc3d29dfdfaec77ee17ec13575e9757f7caf600b61d93edb2d39a0a01a9aada8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b756e6e6e6e657468616e2f522d594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cc3d29dfdfaec77ee17ec13575e9757f7caf600b61d93edb2d39a0a01a9aada8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b756e6e6e6e657468616e2f522d594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kunnnnethan/R-YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a PyTorch-based R-YOLOv4 implementation which combines YOLOv4 model and loss function from R3Det for arbitrary oriented object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DDGRCF/YOLOX_OBB\"\u003eDDGRCF/YOLOX_OBB\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a03ee927d8a7c3326152b2dc45ddb6e5bb44a6145f38b930d0602ef9eafee64c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4444475243462f594f4c4f585f4f42423f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a03ee927d8a7c3326152b2dc45ddb6e5bb44a6145f38b930d0602ef9eafee64c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4444475243462f594f4c4f585f4f42423f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DDGRCF/YOLOX_OBB?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOX OBB -- YOLOX æ—‹è½¬æ¡† | å®žä¾‹åˆ†å‰²ã€‚ \"çŸ¥ä¹Žã€Œåˆ€åˆ€ç‹—ã€ã€Š\u003ca href=\"https://zhuanlan.zhihu.com/p/430850089\" rel=\"nofollow\"\u003eYOLOX OBB -- YOLOX æ—‹è½¬æ¡†æ£€æµ‹ è¶…è¯¦ç»†ï¼ï¼ï¼\u003c/a\u003eã€‹\"ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFace Detection and Recognition\u003c/h3\u003e\u003ca id=\"user-content-face-detection-and-recognition\" class=\"anchor\" aria-label=\"Permalink: Face Detection and Recognition\" href=\"#face-detection-and-recognition\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eäººè„¸æ£€æµ‹ä¸Žè¯†åˆ«\u003c/h4\u003e\u003ca id=\"user-content-äººè„¸æ£€æµ‹ä¸Žè¯†åˆ«\" class=\"anchor\" aria-label=\"Permalink: äººè„¸æ£€æµ‹ä¸Žè¯†åˆ«\" href=\"#äººè„¸æ£€æµ‹ä¸Žè¯†åˆ«\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFace Detection\u003c/h4\u003e\u003ca id=\"user-content-face-detection\" class=\"anchor\" aria-label=\"Permalink: Face Detection\" href=\"#face-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eäººè„¸æ£€æµ‹\u003c/h5\u003e\u003ca id=\"user-content-äººè„¸æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: äººè„¸æ£€æµ‹\" href=\"#äººè„¸æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/deepcam-cn/yolov5-face\"\u003eYOLO5Face\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4c32e6a91c4985713558371cdd4ffe7ac8118ef1ff65091c6ee141d208f2a3ea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6465657063616d2d636e2f796f6c6f76352d666163653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4c32e6a91c4985713558371cdd4ffe7ac8118ef1ff65091c6ee141d208f2a3ea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6465657063616d2d636e2f796f6c6f76352d666163653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/deepcam-cn/yolov5-face?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLO5Face: Why Reinventing a Face Detector\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2105.12931\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/derronqi/yolov7-face\"\u003ederronqi/yolov7-face\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/17ae4027ac3419236d1513be25e5f6941d2af70754d6b74f2dc30fcfbac60a1c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646572726f6e71692f796f6c6f76372d666163653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/17ae4027ac3419236d1513be25e5f6941d2af70754d6b74f2dc30fcfbac60a1c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646572726f6e71692f796f6c6f76372d666163653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/derronqi/yolov7-face?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov7 face detection with landmark.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/derronqi/yolov8-face\"\u003ederronqi/yolov8-face\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cceecedda4966f36ee97fd68f8038795e869181c79c492aaddee25e607096eea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646572726f6e71692f796f6c6f76382d666163653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cceecedda4966f36ee97fd68f8038795e869181c79c492aaddee25e607096eea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646572726f6e71692f796f6c6f76382d666163653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/derronqi/yolov8-face?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov8 face detection with landmark.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/we0091234/yolov7-face-tensorrt\"\u003ewe0091234/yolov7-face-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2418af45fe283c1c274583e2fa41dba27dd91c0ad2a467856dfd527d7b18dab7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7765303039313233342f796f6c6f76372d666163652d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2418af45fe283c1c274583e2fa41dba27dd91c0ad2a467856dfd527d7b18dab7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7765303039313233342f796f6c6f76372d666163652d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/we0091234/yolov7-face-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov7-face TensorRT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Krasjet-Yu/YOLO-FaceV2\"\u003eYOLO-FaceV2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5782c769c2cc4c0b8544e79871a22d7e82121ec9fd9a724394b543fceea7cf4e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b7261736a65742d59752f594f4c4f2d4661636556323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5782c769c2cc4c0b8544e79871a22d7e82121ec9fd9a724394b543fceea7cf4e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b7261736a65742d59752f594f4c4f2d4661636556323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Krasjet-Yu/YOLO-FaceV2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLO-FaceV2: A Scale and Occlusion Aware Face Detector \". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2208.02019\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e). \"å¾®ä¿¡å…¬ä¼—å·ã€Œæ±Ÿå¤§ç™½ã€ã€Š\u003ca href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NzgyNTU2Mg==\u0026amp;mid=2247498561\u0026amp;idx=1\u0026amp;sn=b7ff0592644ab6bc5b716e07294e1c0a\u0026amp;source=41#wechat_redirect\" rel=\"nofollow\"\u003eè¶…è¶ŠYolo5-Faceï¼ŒYolo-Facev2å¼€æºï¼Œå„ç±»Trickä¼˜åŒ–ï¼Œå€¼å¾—å­¦ä¹ ï¼\u003c/a\u003eã€‹\"\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/OAID/TengineKit\"\u003eOAID/TengineKit\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/220a8a434643f00b6c4f196539df6d1018417bfa13b1beb38f461a82d299021b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f4149442f54656e67696e654b69743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/220a8a434643f00b6c4f196539df6d1018417bfa13b1beb38f461a82d299021b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f4149442f54656e67696e654b69743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/OAID/TengineKit?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TengineKit - Free, Fast, Easy, Real-Time Face Detection \u0026amp; Face Landmarks \u0026amp; Face Attributes \u0026amp; Hand Detection \u0026amp; Hand Landmarks \u0026amp; Body Detection \u0026amp; Body Landmarks \u0026amp; Iris Landmarks \u0026amp; Yolov5 SDK On Mobile.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xialuxi/yolov5_face_landmark\"\u003exialuxi/yolov5_face_landmark\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c06761e25c69b83809153b5b05572d8e461133c13abbcc0e7d72a33cb5ececf8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616c7578692f796f6c6f76355f666163655f6c616e646d61726b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c06761e25c69b83809153b5b05572d8e461133c13abbcc0e7d72a33cb5ececf8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616c7578692f796f6c6f76355f666163655f6c616e646d61726b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xialuxi/yolov5_face_landmark?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽyolov5çš„äººè„¸æ£€æµ‹ï¼Œå¸¦å…³é”®ç‚¹æ£€æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sthanhng/yoloface\"\u003esthanhng/yoloface\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a8eab5898fb592aaa838b4e1e4b3bc7be446d16deb1217d7153133b1647e7270/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737468616e686e672f796f6c6f666163653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a8eab5898fb592aaa838b4e1e4b3bc7be446d16deb1217d7153133b1647e7270/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737468616e686e672f796f6c6f666163653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sthanhng/yoloface?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Deep learning-based Face detection using the YOLOv3 algorithm.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DayBreak-u/yolo-face-with-landmark\"\u003eDayBreak-u/yolo-face-with-landmark\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5c5ef4e269674c01280fee750aa0988252ea82714bcb75db841e91d46be00c14/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f446179427265616b2d752f796f6c6f2d666163652d776974682d6c616e646d61726b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5c5ef4e269674c01280fee750aa0988252ea82714bcb75db841e91d46be00c14/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f446179427265616b2d752f796f6c6f2d666163652d776974682d6c616e646d61726b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DayBreak-u/yolo-face-with-landmark?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolofaceå¤§ç¤¼åŒ… ä½¿ç”¨pytrochå®žçŽ°çš„åŸºäºŽyolov3çš„è½»é‡çº§äººè„¸æ£€æµ‹ï¼ˆåŒ…å«å…³é”®ç‚¹ï¼‰ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/abars/YoloKerasFaceDetection\"\u003eabars/YoloKerasFaceDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bdf9e9f5bc17cc911d8ad32812723301bf8b22c0e52d94c00d89820d0eda65c0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61626172732f596f6c6f4b6572617346616365446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bdf9e9f5bc17cc911d8ad32812723301bf8b22c0e52d94c00d89820d0eda65c0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61626172732f596f6c6f4b6572617346616365446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/abars/YoloKerasFaceDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Face Detection and Gender and Age Classification using Keras.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dannyblueliu/YOLO-Face-detection\"\u003edannyblueliu/YOLO-Face-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c42e99f69e11984caf6d0992f28293a81147f7fd2041d1ea8e70de1b95af7474/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64616e6e79626c75656c69752f594f4c4f2d466163652d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c42e99f69e11984caf6d0992f28293a81147f7fd2041d1ea8e70de1b95af7474/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64616e6e79626c75656c69752f594f4c4f2d466163652d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dannyblueliu/YOLO-Face-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Face detection based on YOLO darknet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wmylxmj/YOLO-V3-IOU\"\u003ewmylxmj/YOLO-V3-IOU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/42d860822d2f0cdd665a860131b57f44de8d6ea48641a0b8b6a6d1303cc971c0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776d796c786d6a2f594f4c4f2d56332d494f553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/42d860822d2f0cdd665a860131b57f44de8d6ea48641a0b8b6a6d1303cc971c0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776d796c786d6a2f594f4c4f2d56332d494f553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wmylxmj/YOLO-V3-IOU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO3 åŠ¨æ¼«äººè„¸æ£€æµ‹ (Based on keras and tensorflow) 2019-1-19.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pranoyr/head-detection-using-yolo\"\u003epranoyr/head-detection-using-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3d1b4d4e076a5d6c1017b73291c99f3185e871d8e3702f83a39b2188ffe3c261/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7072616e6f79722f686561642d646574656374696f6e2d7573696e672d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3d1b4d4e076a5d6c1017b73291c99f3185e871d8e3702f83a39b2188ffe3c261/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7072616e6f79722f686561642d646574656374696f6e2d7573696e672d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pranoyr/head-detection-using-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detection of head using YOLO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/grapeot/AnimeHeadDetector\"\u003egrapeot/AnimeHeadDetector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/56c2a76bd05bb26be118cc7efb3efa51d2d57e67d02d9e2a3164524b81552b60/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67726170656f742f416e696d65486561644465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/56c2a76bd05bb26be118cc7efb3efa51d2d57e67d02d9e2a3164524b81552b60/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67726170656f742f416e696d65486561644465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/grapeot/AnimeHeadDetector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An object detector for character heads in animes, based on Yolo V3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Chenyang-ZHU/YOLOv3-Based-Face-Detection-Tracking\"\u003eChenyang-ZHU/YOLOv3-Based-Face-Detection-Tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9ffc474bfda63a106b02e87dcdfe9350eae787ea1d0484a624c145b4e0c85aa3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368656e79616e672d5a48552f594f4c4f76332d42617365642d466163652d446574656374696f6e2d547261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9ffc474bfda63a106b02e87dcdfe9350eae787ea1d0484a624c145b4e0c85aa3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368656e79616e672d5a48552f594f4c4f76332d42617365642d466163652d446574656374696f6e2d547261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Chenyang-ZHU/YOLOv3-Based-Face-Detection-Tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a robot project for television live. System will tracking the host's face, making the face in the middle of the screen.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zdfb/Yolov5_face\"\u003ezdfb/Yolov5_face\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ae37f09960c89b77332c355d3d87a86a577dc6d9cedbed389ae97062c0b127fb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6466622f596f6c6f76355f666163653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ae37f09960c89b77332c355d3d87a86a577dc6d9cedbed389ae97062c0b127fb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6466622f596f6c6f76355f666163653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zdfb/Yolov5_face?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽpytorchçš„Yolov5äººè„¸æ£€æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jinfagang/yolov7-face\"\u003ejinfagang/yolov7-face\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f563dde904a8331e83fa742852680bd981059969ba9cec82658abdeeb880b4dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a696e666167616e672f796f6c6f76372d666163653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f563dde904a8331e83fa742852680bd981059969ba9cec82658abdeeb880b4dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a696e666167616e672f796f6c6f76372d666163653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jinfagang/yolov7-face?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Next Gen Face detection based on YOLOv7.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Yusepp/YOLOv8-Face\"\u003eYusepp/YOLOv8-Face\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ca7c8a73f6678ceed1f1f639b8f4a18667a9950fe04245310cacad83c04c45b4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5975736570702f594f4c4f76382d466163653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ca7c8a73f6678ceed1f1f639b8f4a18667a9950fe04245310cacad83c04c45b4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5975736570702f594f4c4f76382d466163653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Yusepp/YOLOv8-Face?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv8 for Face Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFace Recognition\u003c/h4\u003e\u003ca id=\"user-content-face-recognition\" class=\"anchor\" aria-label=\"Permalink: Face Recognition\" href=\"#face-recognition\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eäººè„¸è¯†åˆ«\u003c/h5\u003e\u003ca id=\"user-content-äººè„¸è¯†åˆ«\" class=\"anchor\" aria-label=\"Permalink: äººè„¸è¯†åˆ«\" href=\"#äººè„¸è¯†åˆ«\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ChanChiChoi/awesome-Face_Recognition\"\u003eChanChiChoi/awesome-Face_Recognition\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/06d3239db8341b54aff6f1edcd772c2b4601f091bbfd40591ecd3e03e35db0b9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368616e43686943686f692f617765736f6d652d466163655f5265636f676e6974696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/06d3239db8341b54aff6f1edcd772c2b4601f091bbfd40591ecd3e03e35db0b9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368616e43686943686f692f617765736f6d652d466163655f5265636f676e6974696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ChanChiChoi/awesome-Face_Recognition?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : papers about Face Detection; Face Alignment; Face Recognition \u0026amp;\u0026amp; Face Identification \u0026amp;\u0026amp; Face Verification \u0026amp;\u0026amp; Face Representation; Face Reconstruction; Face Tracking; Face Super-Resolution \u0026amp;\u0026amp; Face Deblurring; Face Generation \u0026amp;\u0026amp; Face Synthesis; Face Transfer; Face Anti-Spoofing; Face Retrieval.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hpc203/10kinds-light-face-detector-align-recognition\"\u003ehpc203/10kinds-light-face-detector-align-recognition\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/69def8b705327a0a7348d08a647456a614ff7959f173b9ba6e7d436ca3517439/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f31306b696e64732d6c696768742d666163652d6465746563746f722d616c69676e2d7265636f676e6974696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/69def8b705327a0a7348d08a647456a614ff7959f173b9ba6e7d436ca3517439/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f31306b696e64732d6c696768742d666163652d6465746563746f722d616c69676e2d7265636f676e6974696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hpc203/10kinds-light-face-detector-align-recognition?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 10ç§è½»é‡çº§äººè„¸æ£€æµ‹ç®—æ³•çš„æ¯”æ‹¼ï¼Œå…¶ä¸­è¿˜åŒ…å«äººè„¸å…³é”®ç‚¹æ£€æµ‹ä¸Žå¯¹é½ï¼Œäººè„¸ç‰¹å¾å‘é‡æå–å’Œè®¡ç®—è·ç¦»ç›¸ä¼¼åº¦ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ooooxianyu/yoloV5-arcface_forlearn\"\u003eooooxianyu/yoloV5-arcface_forlearn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/92ccdd7bbc57216f0f9c763fa8ededef6e99627cbca3e0d74ae6b480308512ae/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6f6f6f7869616e79752f796f6c6f56352d617263666163655f666f726c6561726e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/92ccdd7bbc57216f0f9c763fa8ededef6e99627cbca3e0d74ae6b480308512ae/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6f6f6f7869616e79752f796f6c6f56352d617263666163655f666f726c6561726e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ooooxianyu/yoloV5-arcface_forlearn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ç®€å•æ‹¼æŽ¥ä¸€äº›æºç ï¼Œå®žçŽ°çš„äººè„¸è¯†åˆ«é¡¹ç›®ã€‚å¯ä¾›å­¦ä¹ å‚è€ƒã€‚å…·ä½“ä½¿ç”¨åˆ°ï¼šyolov5äººè„¸æ£€æµ‹ã€arcfaceäººè„¸è¯†åˆ«ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zhouyuchong/face-recognition-deepstream\"\u003ezhouyuchong/face-recognition-deepstream\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ef44b73c47518019c700215367d77db0160708255c7e4dcf2bbe84538a01cc15/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a686f75797563686f6e672f666163652d7265636f676e6974696f6e2d6465657073747265616d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ef44b73c47518019c700215367d77db0160708255c7e4dcf2bbe84538a01cc15/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a686f75797563686f6e672f666163652d7265636f676e6974696f6e2d6465657073747265616d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zhouyuchong/face-recognition-deepstream?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Deepstream app use YOLO, retinaface and arcface for face recognition.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/duckzhao/face_detection_and_recognition_yolov5\"\u003educkzhao/face_detection_and_recognition_yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7b54ed9646e4a3295ef7f39b34270405b709cd5cdca3d19eb2385a85a26f5350/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6475636b7a68616f2f666163655f646574656374696f6e5f616e645f7265636f676e6974696f6e5f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7b54ed9646e4a3295ef7f39b34270405b709cd5cdca3d19eb2385a85a26f5350/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6475636b7a68616f2f666163655f646574656374696f6e5f616e645f7265636f676e6974696f6e5f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/duckzhao/face_detection_and_recognition_yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä½¿ç”¨yolov5æž„å»ºäººè„¸æ£€æµ‹æ¨¡åž‹ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„Arcfaceå®Œæˆäººè„¸ç‰¹å¾æå–å’Œè¯†åˆ«ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PhucNDA/FaceID--YOLOV5.ArcFace\"\u003ePhucNDA/FaceID--YOLOV5.ArcFace\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3e00f31aafad33384ce2f22e209066d96ffb5fb5b83784a3cece88e6c894a2aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506875634e44412f4661636549442d2d594f4c4f56352e417263466163653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3e00f31aafad33384ce2f22e209066d96ffb5fb5b83784a3cece88e6c894a2aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506875634e44412f4661636549442d2d594f4c4f56352e417263466163653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PhucNDA/FaceID--YOLOV5.ArcFace?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ONNX implementation of YOLOv5 and Siamese Network (ResNet100) with ArcFace loss for Face Detection and Recognition.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFace Mask Detection\u003c/h3\u003e\u003ca id=\"user-content-face-mask-detection\" class=\"anchor\" aria-label=\"Permalink: Face Mask Detection\" href=\"#face-mask-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eå£ç½©æ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-å£ç½©æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: å£ç½©æ£€æµ‹\" href=\"#å£ç½©æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Bil369/MaskDetect-YOLOv4-PyTorch\"\u003eBil369/MaskDetect-YOLOv4-PyTorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5251edbe64b25d393b860f0665c2e1fa1970a221f5da8f2b50eed62111140bc2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42696c3336392f4d61736b4465746563742d594f4c4f76342d5079546f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5251edbe64b25d393b860f0665c2e1fa1970a221f5da8f2b50eed62111140bc2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42696c3336392f4d61736b4465746563742d594f4c4f76342d5079546f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Bil369/MaskDetect-YOLOv4-PyTorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽPyTorch\u0026amp;YOLOv4å®žçŽ°çš„å£ç½©ä½©æˆ´æ£€æµ‹ â­ è‡ªå»ºå£ç½©æ•°æ®é›†åˆ†äº«ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/adityap27/face-mask-detector\"\u003eadityap27/face-mask-detector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/251c17876b211701da249c1923c09306be7ce2ae2f71beb6b2ca53803775cf82/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6164697479617032372f666163652d6d61736b2d6465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/251c17876b211701da249c1923c09306be7ce2ae2f71beb6b2ca53803775cf82/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6164697479617032372f666163652d6d61736b2d6465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/adityap27/face-mask-detector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ð‘ðžðšð¥-ð“ð¢ð¦ðž ð…ðšðœðž ð¦ðšð¬ð¤ ððžð­ðžðœð­ð¢ð¨ð§ ð®ð¬ð¢ð§ð  ððžðžð©ð¥ðžðšð«ð§ð¢ð§ð  ð°ð¢ð­ð¡ ð€ð¥ðžð«ð­ ð¬ð²ð¬ð­ðžð¦ ðŸ’»ðŸ””.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/VictorLin000/YOLOv3_mask_detect\"\u003eVictorLin000/YOLOv3_mask_detect\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/195b6b63fdfa74ff1634fe414656a4f9aa061f70ab7bf08241016749e1ac1bda/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f566963746f724c696e3030302f594f4c4f76335f6d61736b5f6465746563743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/195b6b63fdfa74ff1634fe414656a4f9aa061f70ab7bf08241016749e1ac1bda/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f566963746f724c696e3030302f594f4c4f76335f6d61736b5f6465746563743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/VictorLin000/YOLOv3_mask_detect?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Face mask detection using YOLOv3 on GoogleColab.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/amh28/IBM-Data-Science-Capstone-Alejandra-Marquez\"\u003eamh28/IBM-Data-Science-Capstone-Alejandra-Marquez\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ebbf6df43b658c3ee69a0d249074829586f5058bf7307301534991c20e93e209/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616d6832382f49424d2d446174612d536369656e63652d43617073746f6e652d416c656a616e6472612d4d61727175657a3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ebbf6df43b658c3ee69a0d249074829586f5058bf7307301534991c20e93e209/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616d6832382f49424d2d446174612d536369656e63652d43617073746f6e652d416c656a616e6472612d4d61727175657a3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/amh28/IBM-Data-Science-Capstone-Alejandra-Marquez?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Homemade face mask detector fine-tuning a Yolo-v3 network.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LorenRd/JetsonYolov4\"\u003eLorenRd/JetsonYolov4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8fe419fddf7bf1d74c2e1f7b28430a591d464371d05c03531ba792923c57ff7e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c6f72656e52642f4a6574736f6e596f6c6f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8fe419fddf7bf1d74c2e1f7b28430a591d464371d05c03531ba792923c57ff7e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c6f72656e52642f4a6574736f6e596f6c6f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LorenRd/JetsonYolov4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Face Mask Yolov4 detector - Nvidia Jetson Nano.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Backl1ght/yolov4_face_mask_detection\"\u003eBackl1ght/yolov4_face_mask_detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/35db2468de8514dc5e8b11448cbe736bf6ebcb8451381e507b571a2f7260eb56/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4261636b6c316768742f796f6c6f76345f666163655f6d61736b5f646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/35db2468de8514dc5e8b11448cbe736bf6ebcb8451381e507b571a2f7260eb56/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4261636b6c316768742f796f6c6f76345f666163655f6d61736b5f646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Backl1ght/yolov4_face_mask_detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽyolov4å®žçŽ°å£ç½©ä½©æˆ´æ£€æµ‹ï¼Œåœ¨éªŒè¯é›†ä¸Šåšåˆ°äº†0.954çš„mAPã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pritul2/yolov5_FaceMask\"\u003epritul2/yolov5_FaceMask\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b06c3c3e612112c465566e4c9d0ad8932345fff59602a24e9be747ac918b5a32/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70726974756c322f796f6c6f76355f466163654d61736b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b06c3c3e612112c465566e4c9d0ad8932345fff59602a24e9be747ac918b5a32/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70726974756c322f796f6c6f76355f466163654d61736b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pritul2/yolov5_FaceMask?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detecting person with or without face mask. Trained using YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NisargPethani/FACE-MASK-DETECTION-USING-YOLO-V3\"\u003eNisargPethani/FACE-MASK-DETECTION-USING-YOLO-V3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bec259109be63699bf6869631d14c4d8e365b4cf0ce7e95dada103066f21e1f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e697361726750657468616e692f464143452d4d41534b2d444554454354494f4e2d5553494e472d594f4c4f2d56333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bec259109be63699bf6869631d14c4d8e365b4cf0ce7e95dada103066f21e1f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e697361726750657468616e692f464143452d4d41534b2d444554454354494f4e2d5553494e472d594f4c4f2d56333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NisargPethani/FACE-MASK-DETECTION-USING-YOLO-V3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : FACE-MASK DETECTION.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/waittim/mask-detector\"\u003ewaittim/mask-detector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/89e430cdea37c3522241e177d4e04e9e339814872ce4301b219123c0defbf25a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7761697474696d2f6d61736b2d6465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/89e430cdea37c3522241e177d4e04e9e339814872ce4301b219123c0defbf25a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7761697474696d2f6d61736b2d6465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/waittim/mask-detector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time video streaming mask detection based on Python. Designed to defeat COVID-19.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BogdanMarghescu/Face-Mask-Detection-Using-YOLOv4\"\u003eBogdanMarghescu/Face-Mask-Detection-Using-YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5f96c57cf463ac8f099d6a7b5d7a3aa8e96e4deeddb404bce4e653fcea744cdc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f6764616e4d61726768657363752f466163652d4d61736b2d446574656374696f6e2d5573696e672d594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5f96c57cf463ac8f099d6a7b5d7a3aa8e96e4deeddb404bce4e653fcea744cdc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f6764616e4d61726768657363752f466163652d4d61736b2d446574656374696f6e2d5573696e672d594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BogdanMarghescu/Face-Mask-Detection-Using-YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Face Mask Detector using YOLOv4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xinghanliuying/yolov5_bus\"\u003exinghanliuying/yolov5_bus\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5a8350cef98d3682398b5c4d45bd6b766e6865f68aa5b136ec0131bbffcd1419/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78696e6768616e6c697579696e672f796f6c6f76355f6275733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5a8350cef98d3682398b5c4d45bd6b766e6865f68aa5b136ec0131bbffcd1419/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78696e6768616e6c697579696e672f796f6c6f76355f6275733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xinghanliuying/yolov5_bus?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : æ‰‹æŠŠæ‰‹æ•™ä½ ä½¿ç”¨YOLOV5è®­ç»ƒè‡ªå·±çš„ç›®æ ‡æ£€æµ‹æ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://gitee.com/song-laogou/yolov5-mask-42\" rel=\"nofollow\"\u003esong-laogou/yolov5-mask-42\u003c/a\u003e : åŸºäºŽYOLOV5çš„å£ç½©æ£€æµ‹ç³»ç»Ÿ-æä¾›æ•™å­¦è§†é¢‘ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSocial Distance Detection\u003c/h3\u003e\u003ca id=\"user-content-social-distance-detection\" class=\"anchor\" aria-label=\"Permalink: Social Distance Detection\" href=\"#social-distance-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eç¤¾äº¤è·ç¦»æ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-ç¤¾äº¤è·ç¦»æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: ç¤¾äº¤è·ç¦»æ£€æµ‹\" href=\"#ç¤¾äº¤è·ç¦»æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ank-Cha/Social-Distancing-Analyser-COVID-19\"\u003eAnk-Cha/Social-Distancing-Analyser-COVID-19\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/16a8e03f33ee6b87e4db7f40dd43304fcd679cabd6907d929b4415f1ae3bf4e3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e6b2d4368612f536f6369616c2d44697374616e63696e672d416e616c797365722d434f5649442d31393f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/16a8e03f33ee6b87e4db7f40dd43304fcd679cabd6907d929b4415f1ae3bf4e3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e6b2d4368612f536f6369616c2d44697374616e63696e672d416e616c797365722d434f5649442d31393f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ank-Cha/Social-Distancing-Analyser-COVID-19?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Social Distancing Analyser to prevent COVID19.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/abd-shoumik/Social-distance-detection\"\u003eabd-shoumik/Social-distance-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a69753f50e65ed2ad495f71c135c0078ed36dd88c17a9d2188c04b769ff90844/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6162642d73686f756d696b2f536f6369616c2d64697374616e63652d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a69753f50e65ed2ad495f71c135c0078ed36dd88c17a9d2188c04b769ff90844/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6162642d73686f756d696b2f536f6369616c2d64697374616e63652d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/abd-shoumik/Social-distance-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Social distance detection, a deep learning computer vision project with yolo object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ChargedMonk/Social-Distancing-using-YOLOv5\"\u003eChargedMonk/Social-Distancing-using-YOLOv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/792853596cf77ba7e60c244df32b79116019f3879b5f90df9e898c9440f1cb54/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436861726765644d6f6e6b2f536f6369616c2d44697374616e63696e672d7573696e672d594f4c4f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/792853596cf77ba7e60c244df32b79116019f3879b5f90df9e898c9440f1cb54/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436861726765644d6f6e6b2f536f6369616c2d44697374616e63696e672d7573696e672d594f4c4f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ChargedMonk/Social-Distancing-using-YOLOv5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Classifying people as high risk and low risk based on their distance to other people.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/JohnBetaCode/Social-Distancing-Analyser\"\u003eJohnBetaCode/Social-Distancing-Analyser\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/99ba378ccfdd6abc5c3070eb036981cf37adefd233897c91fd001d15896cd17c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a6f686e42657461436f64652f536f6369616c2d44697374616e63696e672d416e616c797365723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/99ba378ccfdd6abc5c3070eb036981cf37adefd233897c91fd001d15896cd17c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a6f686e42657461436f64652f536f6369616c2d44697374616e63696e672d416e616c797365723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/JohnBetaCode/Social-Distancing-Analyser?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Social Distancing Analyzer.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ashamaria/Safe-distance-tracker-using-YOLOv3-v3\"\u003eAshamaria/Safe-distance-tracker-using-YOLOv3-v3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/40b6d4cb8aaa832cf45b66328068e1ae21e740053b95b5df117aab7a49284591/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f417368616d617269612f536166652d64697374616e63652d747261636b65722d7573696e672d594f4c4f76332d76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/40b6d4cb8aaa832cf45b66328068e1ae21e740053b95b5df117aab7a49284591/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f417368616d617269612f536166652d64697374616e63652d747261636b65722d7573696e672d594f4c4f76332d76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ashamaria/Safe-distance-tracker-using-YOLOv3-v3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Safe Distance Tracker.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAutonomous Driving Field Detection\u003c/h3\u003e\u003ca id=\"user-content-autonomous-driving-field-detection\" class=\"anchor\" aria-label=\"Permalink: Autonomous Driving Field Detection\" href=\"#autonomous-driving-field-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eè‡ªåŠ¨é©¾é©¶é¢†åŸŸæ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-è‡ªåŠ¨é©¾é©¶é¢†åŸŸæ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: è‡ªåŠ¨é©¾é©¶é¢†åŸŸæ£€æµ‹\" href=\"#è‡ªåŠ¨é©¾é©¶é¢†åŸŸæ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eVehicle Detection\u003c/h4\u003e\u003ca id=\"user-content-vehicle-detection\" class=\"anchor\" aria-label=\"Permalink: Vehicle Detection\" href=\"#vehicle-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eè½¦è¾†æ£€æµ‹\u003c/h5\u003e\u003ca id=\"user-content-è½¦è¾†æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: è½¦è¾†æ£€æµ‹\" href=\"#è½¦è¾†æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jason-li-831202/Vehicle-CV-ADAS\"\u003ejason-li-831202/Vehicle-CV-ADAS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ad08e46a654f7db16cad8ddc03240ed4b12aeedb3bfaed517712b53e7460e18e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a61736f6e2d6c692d3833313230322f56656869636c652d43562d414441533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ad08e46a654f7db16cad8ddc03240ed4b12aeedb3bfaed517712b53e7460e18e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a61736f6e2d6c692d3833313230322f56656869636c652d43562d414441533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jason-li-831202/Vehicle-CV-ADAS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The project can achieve FCWS, LDWS, and LKAS functions solely using only visual sensors. using YOLOv5 / YOLOv5-lite / YOLOv6 / YOLOv7 / YOLOv8 / YOLOv9 / EfficientDet and Ultra-Fast-Lane-Detection-v2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/williamhyin/yolov5s_bdd100k\"\u003ewilliamhyin/yolov5s_bdd100k\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/682d58b5754c2d789a56a7489946f15db8db1637ee1071f84b88186e7c92ed61/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77696c6c69616d6879696e2f796f6c6f7635735f6264643130306b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/682d58b5754c2d789a56a7489946f15db8db1637ee1071f84b88186e7c92ed61/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77696c6c69616d6879696e2f796f6c6f7635735f6264643130306b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/williamhyin/yolov5s_bdd100k?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Train a yolo v5 object detection model on Bdd100k dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jwchoi384/Gaussian_YOLOv3\"\u003eGaussian_YOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a16e0f4f2d1eb8a554227a7f348794caf4552c07a8b438c607b3cb9ff92431ef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a7763686f693338342f476175737369616e5f594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a16e0f4f2d1eb8a554227a7f348794caf4552c07a8b438c607b3cb9ff92431ef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a7763686f693338342f476175737369616e5f594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jwchoi384/Gaussian_YOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Gaussian YOLOv3: An Accurate and Fast Object Detector Using Localization Uncertainty for Autonomous Driving\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_ICCV_2019/html/Choi_Gaussian_YOLOv3_An_Accurate_and_Fast_Object_Detector_Using_Localization_ICCV_2019_paper.html\" rel=\"nofollow\"\u003eICCV 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/streamlit/demo-self-driving\"\u003estreamlit/demo-self-driving\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e2b9f558f65a83043627968313a89b1bcbf741461c012d074e84037b68a4ff08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73747265616d6c69742f64656d6f2d73656c662d64726976696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e2b9f558f65a83043627968313a89b1bcbf741461c012d074e84037b68a4ff08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73747265616d6c69742f64656d6f2d73656c662d64726976696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/streamlit/demo-self-driving?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Streamlit app demonstrating an image browser for the Udacity self-driving-car dataset with realtime object detection using YOLO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/JunshengFu/vehicle-detection\"\u003eJunshengFu/vehicle-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f72ea8464e996ea73439936b07ee505f2af9b38ebb26d76e6a8ffd050d5fc9a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a756e7368656e6746752f76656869636c652d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f72ea8464e996ea73439936b07ee505f2af9b38ebb26d76e6a8ffd050d5fc9a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a756e7368656e6746752f76656869636c652d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/JunshengFu/vehicle-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Created vehicle detection pipeline with two approaches: (1) deep neural networks (YOLO framework) and (2) support vector machines ( OpenCV + HOG).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xslittlegrass/CarND-Vehicle-Detection\"\u003exslittlegrass/CarND-Vehicle-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e9bf8708866e8051e45a2772a67b522d18b54bfc475b32a1dc40b6e0c8709795/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78736c6974746c6567726173732f4361724e442d56656869636c652d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e9bf8708866e8051e45a2772a67b522d18b54bfc475b32a1dc40b6e0c8709795/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78736c6974746c6567726173732f4361724e442d56656869636c652d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xslittlegrass/CarND-Vehicle-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Vehicle detection using YOLO in Keras runs at 21FPS.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Kevinnan-teen/Intelligent-Traffic-Based-On-CV\"\u003eKevinnan-teen/Intelligent-Traffic-Based-On-CV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6e3d2150cd25e7c5e9099144b3266cab1be80ee327eb9ca222241567e7023ab0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6576696e6e616e2d7465656e2f496e74656c6c6967656e742d547261666669632d42617365642d4f6e2d43563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6e3d2150cd25e7c5e9099144b3266cab1be80ee327eb9ca222241567e7023ab0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6576696e6e616e2d7465656e2f496e74656c6c6967656e742d547261666669632d42617365642d4f6e2d43563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Kevinnan-teen/Intelligent-Traffic-Based-On-CV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽè®¡ç®—æœºè§†è§‰çš„äº¤é€šè·¯å£æ™ºèƒ½ç›‘æŽ§ç³»ç»Ÿã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/subodh-malgonde/vehicle-detection\"\u003esubodh-malgonde/vehicle-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d98375ad194a34e7aa356cea13803fbf149801a8c1b27691eb9d0f59efc4b347/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7375626f64682d6d616c676f6e64652f76656869636c652d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d98375ad194a34e7aa356cea13803fbf149801a8c1b27691eb9d0f59efc4b347/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7375626f64682d6d616c676f6e64652f76656869636c652d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/subodh-malgonde/vehicle-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detect vehicles in a video.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CaptainEven/Vehicle-Car-detection-and-multilabel-classification\"\u003eCaptainEven/Vehicle-Car-detection-and-multilabel-classification\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4b8b64e714f8562e217601dbe2e81995af97e2d8efa4d703251e9d54b9aaa9d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4361707461696e4576656e2f56656869636c652d4361722d646574656374696f6e2d616e642d6d756c74696c6162656c2d636c617373696669636174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4b8b64e714f8562e217601dbe2e81995af97e2d8efa4d703251e9d54b9aaa9d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4361707461696e4576656e2f56656869636c652d4361722d646574656374696f6e2d616e642d6d756c74696c6162656c2d636c617373696669636174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CaptainEven/Vehicle-Car-detection-and-multilabel-classification?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä½¿ç”¨YOLO_v3_tinyå’ŒB-CNNå®žçŽ°è¡—å¤´è½¦è¾†çš„æ£€æµ‹å’Œè½¦è¾†å±žæ€§çš„å¤šæ ‡ç­¾è¯†åˆ« Using yolo_v3_tiny to do vehicle or car detection and attribute's multilabel classification or recognizeã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kaylode/vehicle-counting\"\u003ekaylode/vehicle-counting\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8bd2068118be8e6bf1f0f77cd9223d4a07e3551d4dcdbca6b84d276f35c2b140/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b61796c6f64652f76656869636c652d636f756e74696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8bd2068118be8e6bf1f0f77cd9223d4a07e3551d4dcdbca6b84d276f35c2b140/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b61796c6f64652f76656869636c652d636f756e74696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kaylode/vehicle-counting?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Vehicle counting using Pytorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MaryamBoneh/Vehicle-Detection\"\u003eMaryamBoneh/Vehicle-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/637bdfa8fab5fc1ae6f7b30b659f7b946f92260e9050b89db3039c96d6252ac1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d617279616d426f6e65682f56656869636c652d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/637bdfa8fab5fc1ae6f7b30b659f7b946f92260e9050b89db3039c96d6252ac1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d617279616d426f6e65682f56656869636c652d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MaryamBoneh/Vehicle-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Vehicle Detection Using Deep Learning and YOLO Algorithm.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/JeffWang0325/Image-Identification-for-Self-Driving-Cars\"\u003eJeffWang0325/Image-Identification-for-Self-Driving-Cars\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/54070c3f234c071d1238401f753c4536ebe48b0e8f802a21bb82660d3c9876e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a65666657616e67303332352f496d6167652d4964656e74696669636174696f6e2d666f722d53656c662d44726976696e672d436172733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/54070c3f234c071d1238401f753c4536ebe48b0e8f802a21bb82660d3c9876e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a65666657616e67303332352f496d6167652d4964656e74696669636174696f6e2d666f722d53656c662d44726976696e672d436172733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/JeffWang0325/Image-Identification-for-Self-Driving-Cars?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e :  This project achieves some functions of image identification for Self-Driving Cars.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AnarbekovAlt/Traffic-analysis\"\u003eAnarbekovAlt/Traffic-analysis\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/88e3539c68ed35225228429682f528a0d01a7b61499c127bb79f12e6e11be604/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e617262656b6f76416c742f547261666669632d616e616c797369733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/88e3539c68ed35225228429682f528a0d01a7b61499c127bb79f12e6e11be604/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e617262656b6f76416c742f547261666669632d616e616c797369733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AnarbekovAlt/Traffic-analysis?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A traffic analysis system is built on the basis of the YOLO network.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ruhyadi/yolov5-nodeflux\"\u003eruhyadi/yolov5-nodeflux\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1177ed116afbe4843ae75eea02faca9d6ff8aa7adfc3cec62a85e3847d6019f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f727568796164692f796f6c6f76352d6e6f6465666c75783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1177ed116afbe4843ae75eea02faca9d6ff8aa7adfc3cec62a85e3847d6019f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f727568796164692f796f6c6f76352d6e6f6465666c75783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ruhyadi/yolov5-nodeflux?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 Nodeflux Vehicle Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Daheer/Driving-Environment-Detector\"\u003eDaheer/Driving-Environment-Detector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e38d0a870a1f20ade0c22aeb6baaaa8db38359e6ec8168084b94dc9fd40790b3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461686565722f44726976696e672d456e7669726f6e6d656e742d4465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e38d0a870a1f20ade0c22aeb6baaaa8db38359e6ec8168084b94dc9fd40790b3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461686565722f44726976696e672d456e7669726f6e6d656e742d4465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Daheer/Driving-Environment-Detector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detecting road objects using YOLO CNN Architecture.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/georgia-tech-db/eva\"\u003egeorgia-tech-db/eva\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cc26bb797654ec37a208409242a8f202d4776f008a1a72e1e438afeec0ebe42e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67656f726769612d746563682d64622f6576613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cc26bb797654ec37a208409242a8f202d4776f008a1a72e1e438afeec0ebe42e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67656f726769612d746563682d64622f6576613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/georgia-tech-db/eva?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Exploratory Video Analytics System.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/heathhenley/RhodyCarCounter\"\u003eheathhenley/RhodyCarCounter\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/792754789b750fa417aa43a0b7287c6bcc5f3ceb775d2f5b3cc0858085560834/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686561746868656e6c65792f52686f6479436172436f756e7465723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/792754789b750fa417aa43a0b7287c6bcc5f3ceb775d2f5b3cc0858085560834/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686561746868656e6c65792f52686f6479436172436f756e7465723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/heathhenley/RhodyCarCounter?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An app that uses Yolo to count the cars passing by traffic cams mostly in the Providence, RI area.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zehengl/yyc-traffic-cam\"\u003ezehengl/yyc-traffic-cam\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c3d6abadc0cb52e5826686e625df51c47f49bd299be1d65151fc52ab0eacfcef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6568656e676c2f7979632d747261666669632d63616d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c3d6abadc0cb52e5826686e625df51c47f49bd299be1d65151fc52ab0eacfcef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6568656e676c2f7979632d747261666669632d63616d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zehengl/yyc-traffic-cam?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A demo to detect vehicles in traffic cam. \u003ca href=\"https://zehengl.github.io/yyc-traffic-cam/\" rel=\"nofollow\"\u003ezehengl.github.io/yyc-traffic-cam/\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ruhyadi/vehicle-detection-yolov8\"\u003eruhyadi/vehicle-detection-yolov8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4d55326180b77c58c79e58d3163b8282d45a38615ebe9c0f76e6678ae19f6e2a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f727568796164692f76656869636c652d646574656374696f6e2d796f6c6f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4d55326180b77c58c79e58d3163b8282d45a38615ebe9c0f76e6678ae19f6e2a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f727568796164692f76656869636c652d646574656374696f6e2d796f6c6f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ruhyadi/vehicle-detection-yolov8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Vehicle Detection with YOLOv8.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eLicense Plate Detection and Recognition\u003c/h4\u003e\u003ca id=\"user-content-license-plate-detection-and-recognition\" class=\"anchor\" aria-label=\"Permalink: License Plate Detection and Recognition\" href=\"#license-plate-detection-and-recognition\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eè½¦ç‰Œæ£€æµ‹ä¸Žè¯†åˆ«\u003c/h5\u003e\u003ca id=\"user-content-è½¦ç‰Œæ£€æµ‹ä¸Žè¯†åˆ«\" class=\"anchor\" aria-label=\"Permalink: è½¦ç‰Œæ£€æµ‹ä¸Žè¯†åˆ«\" href=\"#è½¦ç‰Œæ£€æµ‹ä¸Žè¯†åˆ«\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zeusees/License-Plate-Detector\"\u003ezeusees/License-Plate-Detector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/77fb7de6ad8270e1cf5c07b4a7af8b1b8d6b3835fd3d18d454e14ab45dc5914e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6575736565732f4c6963656e73652d506c6174652d4465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/77fb7de6ad8270e1cf5c07b4a7af8b1b8d6b3835fd3d18d454e14ab45dc5914e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6575736565732f4c6963656e73652d506c6174652d4465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zeusees/License-Plate-Detector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : License Plate Detection with Yolov5ï¼ŒåŸºäºŽYolov5è½¦ç‰Œæ£€æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TheophileBuy/LicensePlateRecognition\"\u003eTheophileBuy/LicensePlateRecognition\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/028e9321c771b1a7e43f3699ef71d9c858308344ed172a2a1e6b5d579421e8f3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5468656f7068696c654275792f4c6963656e7365506c6174655265636f676e6974696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/028e9321c771b1a7e43f3699ef71d9c858308344ed172a2a1e6b5d579421e8f3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5468656f7068696c654275792f4c6963656e7365506c6174655265636f676e6974696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TheophileBuy/LicensePlateRecognition?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : License Plate Recognition.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/alitourani/yolo-license-plate-detection\"\u003ealitourani/yolo-license-plate-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/42e8ecd73f05a175ef20bab34c572e1ee9d4de008127cf6595a071488c7356f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69746f7572616e692f796f6c6f2d6c6963656e73652d706c6174652d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/42e8ecd73f05a175ef20bab34c572e1ee9d4de008127cf6595a071488c7356f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69746f7572616e692f796f6c6f2d6c6963656e73652d706c6174652d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/alitourani/yolo-license-plate-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A License-Plate detecttion application based on YOLO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HuKai97/YOLOv5-LPRNet-Licence-Recognition\"\u003eHuKai97/YOLOv5-LPRNet-Licence-Recognition\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/62368b1329067a8e5ca6e2ee68b1b8d444c4bef32659753d7708ae9ba86be713/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48754b616939372f594f4c4f76352d4c50524e65742d4c6963656e63652d5265636f676e6974696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/62368b1329067a8e5ca6e2ee68b1b8d444c4bef32659753d7708ae9ba86be713/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48754b616939372f594f4c4f76352d4c50524e65742d4c6963656e63652d5265636f676e6974696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HuKai97/YOLOv5-LPRNet-Licence-Recognition?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä½¿ç”¨YOLOv5å’ŒLPRNetè¿›è¡Œè½¦ç‰Œæ£€æµ‹+è¯†åˆ«ï¼ˆCCPDæ•°æ®é›†ï¼‰ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xialuxi/yolov5-car-plate\"\u003exialuxi/yolov5-car-plate\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5b1476715ba3bdc4b50cd75fc80caa3cc3e634c243faa09186c1552e8b69a03e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616c7578692f796f6c6f76352d6361722d706c6174653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5b1476715ba3bdc4b50cd75fc80caa3cc3e634c243faa09186c1552e8b69a03e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616c7578692f796f6c6f76352d6361722d706c6174653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xialuxi/yolov5-car-plate?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽyolov5çš„è½¦ç‰Œæ£€æµ‹ï¼ŒåŒ…å«è½¦ç‰Œè§’ç‚¹æ£€æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kyrielw24/License_Plate_Recognition\"\u003ekyrielw24/License_Plate_Recognition\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/01e2559555318ae1fe294f0f44ea72ce364d3fafdfe0ebb98a6cf46364089f8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b797269656c7732342f4c6963656e73655f506c6174655f5265636f676e6974696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/01e2559555318ae1fe294f0f44ea72ce364d3fafdfe0ebb98a6cf46364089f8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b797269656c7732342f4c6963656e73655f506c6174655f5265636f676e6974696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kyrielw24/License_Plate_Recognition?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽYolo\u0026amp;CNNçš„è½¦ç‰Œè¯†åˆ«å¯è§†åŒ–é¡¹ç›®ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/we0091234/yolov7_plate\"\u003ewe0091234/yolov7_plate\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3efeb36b7ad350ca2f0d90021f895de911b4571a4e1047ca0edbf2da54b4d768/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7765303039313233342f796f6c6f76375f706c6174653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3efeb36b7ad350ca2f0d90021f895de911b4571a4e1047ca0edbf2da54b4d768/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7765303039313233342f796f6c6f76375f706c6174653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/we0091234/yolov7_plate?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov7 è½¦ç‰Œæ£€æµ‹ è½¦ç‰Œè¯†åˆ« ä¸­æ–‡è½¦ç‰Œè¯†åˆ« æ£€æµ‹ æ”¯æŒåŒå±‚è½¦ç‰Œ æ”¯æŒ13ç§ä¸­æ–‡è½¦ç‰Œã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MuhammadMoinFaisal/Automatic_Number_Plate_Detection_Recognition_YOLOv8\"\u003eMuhammadMoinFaisal/Automatic_Number_Plate_Detection_Recognition_YOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a5eea0eb8abfbe1ccd54f3f5a95bf6dbc7f1aa272c3653922833af8d66f565bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d7568616d6d61644d6f696e46616973616c2f4175746f6d617469635f4e756d6265725f506c6174655f446574656374696f6e5f5265636f676e6974696f6e5f594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a5eea0eb8abfbe1ccd54f3f5a95bf6dbc7f1aa272c3653922833af8d66f565bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d7568616d6d61644d6f696e46616973616c2f4175746f6d617469635f4e756d6265725f506c6174655f446574656374696f6e5f5265636f676e6974696f6e5f594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MuhammadMoinFaisal/Automatic_Number_Plate_Detection_Recognition_YOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Automatic Number Plate Detection YOLOv8.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eLane Detection\u003c/h4\u003e\u003ca id=\"user-content-lane-detection\" class=\"anchor\" aria-label=\"Permalink: Lane Detection\" href=\"#lane-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eè½¦é“çº¿æ£€æµ‹\u003c/h5\u003e\u003ca id=\"user-content-è½¦é“çº¿æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: è½¦é“çº¿æ£€æµ‹\" href=\"#è½¦é“çº¿æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hustvl/YOLOP\"\u003eYOLOP\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/268baea33e613c8c60abf4ca4c71ec1a019404f571c6e058abb36ed456b42beb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68757374766c2f594f4c4f503f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/268baea33e613c8c60abf4ca4c71ec1a019404f571c6e058abb36ed456b42beb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68757374766c2f594f4c4f503f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hustvl/YOLOP?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOP: You Only Look Once for Panoptic Driving Perception\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2108.11250\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CAIC-AD/YOLOPv2\"\u003eYOLOPv2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/40001fdf143ca900f598d41962f44567c94fa5d71fed814b50d95986f8c87e36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f434149432d41442f594f4c4f5076323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/40001fdf143ca900f598d41962f44567c94fa5d71fed814b50d95986f8c87e36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f434149432d41442f594f4c4f5076323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CAIC-AD/YOLOPv2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOPv2: Better, Faster, Stronger for Panoptic Driving Perception\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2208.11434\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e). \"å¾®ä¿¡å…¬ä¼—å·ã€Œé›†æ™ºä¹¦ç«¥ã€ã€Š\u003ca href=\"https://mp.weixin.qq.com/s/XTD32JCu_YbZjV2Br3KXCA\" rel=\"nofollow\"\u003eYOLOP v2æ¥å•¦ | YOLOv7ç»“åˆYOLOPçš„å¤šä»»åŠ¡ç‰ˆæœ¬ï¼Œè¶…è¶ŠYOLOPä»¥åŠHybridNets\u003c/a\u003eã€‹\"\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FeiGeChuanShu/YOLOPv2-ncnn\"\u003eFeiGeChuanShu/YOLOPv2-ncnn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8ffeb1682287a1ecebc0c1cf6415b80db9d25a41a375da3bdb21324c09cf2ae4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4665694765436875616e5368752f594f4c4f5076322d6e636e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8ffeb1682287a1ecebc0c1cf6415b80db9d25a41a375da3bdb21324c09cf2ae4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4665694765436875616e5368752f594f4c4f5076322d6e636e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FeiGeChuanShu/YOLOPv2-ncnn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOPv2-ncnn.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/visualbuffer/copilot\"\u003evisualbuffer/copilot\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6b794c7c1f832d360a1746bdb6010600f335d2d32fb20d3ecb1685eaf2706b59/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76697375616c6275666665722f636f70696c6f743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6b794c7c1f832d360a1746bdb6010600f335d2d32fb20d3ecb1685eaf2706b59/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76697375616c6275666665722f636f70696c6f743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/visualbuffer/copilot?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Lane and obstacle detection for active assistance during driving.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hpc203/YOLOP-opencv-dnn\"\u003ehpc203/YOLOP-opencv-dnn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/007f0ed071c2f6ec2819b7851878b93165efc9ddad8b789d333aa112472483f6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f594f4c4f502d6f70656e63762d646e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/007f0ed071c2f6ec2819b7851878b93165efc9ddad8b789d333aa112472483f6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f594f4c4f502d6f70656e63762d646e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hpc203/YOLOP-opencv-dnn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä½¿ç”¨OpenCVéƒ¨ç½²å…¨æ™¯é©¾é©¶æ„ŸçŸ¥ç½‘ç»œYOLOPï¼Œå¯åŒæ—¶å¤„ç†äº¤é€šç›®æ ‡æ£€æµ‹ã€å¯é©¾é©¶åŒºåŸŸåˆ†å‰²ã€è½¦é“çº¿æ£€æµ‹ï¼Œä¸‰é¡¹è§†è§‰æ„ŸçŸ¥ä»»åŠ¡ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/EdVince/YOLOP-NCNN\"\u003eEdVince/YOLOP-NCNN\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/27628443aebc13440931d96431fbb7e4c7d4b85c0989c35cb89e9c5f810601e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f456456696e63652f594f4c4f502d4e434e4e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/27628443aebc13440931d96431fbb7e4c7d4b85c0989c35cb89e9c5f810601e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f456456696e63652f594f4c4f502d4e434e4e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/EdVince/YOLOP-NCNN?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOP running in Android by ncnn.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eDriving Behavior Detection\u003c/h4\u003e\u003ca id=\"user-content-driving-behavior-detection\" class=\"anchor\" aria-label=\"Permalink: Driving Behavior Detection\" href=\"#driving-behavior-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eé©¾é©¶è¡Œä¸ºæ£€æµ‹\u003c/h5\u003e\u003ca id=\"user-content-é©¾é©¶è¡Œä¸ºæ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: é©¾é©¶è¡Œä¸ºæ£€æµ‹\" href=\"#é©¾é©¶è¡Œä¸ºæ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/JingyibySUTsoftware/Yolov5-deepsort-driverDistracted-driving-behavior-detection\"\u003eJingyibySUTsoftware/Yolov5-deepsort-driverDistracted-driving-behavior-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a58f3f2596965457bd6a5f32a5925662ef0f6286ee4359fd2b2112c3c1686dbc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a696e6779696279535554736f6674776172652f596f6c6f76352d64656570736f72742d647269766572446973747261637465642d64726976696e672d6265686176696f722d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a58f3f2596965457bd6a5f32a5925662ef0f6286ee4359fd2b2112c3c1686dbc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a696e6779696279535554736f6674776172652f596f6c6f76352d64656570736f72742d647269766572446973747261637465642d64726976696e672d6265686176696f722d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/JingyibySUTsoftware/Yolov5-deepsort-driverDistracted-driving-behavior-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽæ·±åº¦å­¦ä¹ çš„é©¾é©¶å‘˜åˆ†å¿ƒé©¾é©¶è¡Œä¸ºï¼ˆç–²åŠ³+å±é™©è¡Œä¸ºï¼‰é¢„è­¦ç³»ç»Ÿä½¿ç”¨YOLOv5+Deepsortå®žçŽ°é©¾é©¶å‘˜çš„å±é™©é©¾é©¶è¡Œä¸ºçš„é¢„è­¦ç›‘æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Arrowes/CEAM-YOLOv7\"\u003eArrowes/CEAM-YOLOv7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/34b80f920cb805ab8b35fec2f29e19abfc8cde8acc22a6a0b21f56f476fae139/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4172726f7765732f4345414d2d594f4c4f76373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/34b80f920cb805ab8b35fec2f29e19abfc8cde8acc22a6a0b21f56f476fae139/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4172726f7765732f4345414d2d594f4c4f76373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Arrowes/CEAM-YOLOv7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"CEAM-YOLOv7:Improved YOLOv7 Based on Channel Expansion and Attention Mechanism for Driver Distraction Behavior Detection\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9980374/\" rel=\"nofollow\"\u003eIEEE Access, 2022\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eParking Slot Detection\u003c/h4\u003e\u003ca id=\"user-content-parking-slot-detection\" class=\"anchor\" aria-label=\"Permalink: Parking Slot Detection\" href=\"#parking-slot-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eåœè½¦ä½æ£€æµ‹\u003c/h5\u003e\u003ca id=\"user-content-åœè½¦ä½æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: åœè½¦ä½æ£€æµ‹\" href=\"#åœè½¦ä½æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/visualbuffer/parkingslot\"\u003evisualbuffer/parkingslot\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7480e5bcb53c9f3f459e620ef400bf8a59977e852a31cd3fd7802481d45ab961/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76697375616c6275666665722f7061726b696e67736c6f743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7480e5bcb53c9f3f459e620ef400bf8a59977e852a31cd3fd7802481d45ab961/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76697375616c6275666665722f7061726b696e67736c6f743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/visualbuffer/parkingslot?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Automated parking occupancy detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/anil2k/smart-car-parking-yolov5\"\u003eanil2k/smart-car-parking-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7f14973dd8ef0945d19a38347472793ca9ab136e699fa2e67cd9e69eca7c4ce5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616e696c326b2f736d6172742d6361722d7061726b696e672d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7f14973dd8ef0945d19a38347472793ca9ab136e699fa2e67cd9e69eca7c4ce5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616e696c326b2f736d6172742d6361722d7061726b696e672d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/anil2k/smart-car-parking-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detect free parking lot available for cars.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eTraffic Light Detection\u003c/h4\u003e\u003ca id=\"user-content-traffic-light-detection\" class=\"anchor\" aria-label=\"Permalink: Traffic Light Detection\" href=\"#traffic-light-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eäº¤é€šç¯æ£€æµ‹\u003c/h5\u003e\u003ca id=\"user-content-äº¤é€šç¯æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: äº¤é€šç¯æ£€æµ‹\" href=\"#äº¤é€šç¯æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/berktepebag/Traffic-light-detection-with-YOLOv3-BOSCH-traffic-light-dataset\"\u003eberktepebag/Traffic-light-detection-with-YOLOv3-BOSCH-traffic-light-dataset\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/66b591afcc784b21063bacf8740003aa1644c7dbff7523fc6102a210099e3c30/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6265726b746570656261672f547261666669632d6c696768742d646574656374696f6e2d776974682d594f4c4f76332d424f5343482d747261666669632d6c696768742d646174617365743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/66b591afcc784b21063bacf8740003aa1644c7dbff7523fc6102a210099e3c30/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6265726b746570656261672f547261666669632d6c696768742d646574656374696f6e2d776974682d594f4c4f76332d424f5343482d747261666669632d6c696768742d646174617365743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/berktepebag/Traffic-light-detection-with-YOLOv3-BOSCH-traffic-light-dataset?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detecting Traffic Lights in Real-time with YOLOv3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mihir-m-gandhi/Adaptive-Traffic-Signal-Timer\"\u003emihir-m-gandhi/Adaptive-Traffic-Signal-Timer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8e3f9c7009484cbc53eb059ca999955b2d57dc8e8e34dafb2bad78a594a2b764/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696869722d6d2d67616e6468692f41646170746976652d547261666669632d5369676e616c2d54696d65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8e3f9c7009484cbc53eb059ca999955b2d57dc8e8e34dafb2bad78a594a2b764/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696869722d6d2d67616e6468692f41646170746976652d547261666669632d5369676e616c2d54696d65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mihir-m-gandhi/Adaptive-Traffic-Signal-Timer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This Adaptive Traffic Signal Timer uses live images from the cameras at traffic junctions for real-time traffic density calculation using YOLO object detection and sets the signal timers accordingly.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wade0125/Traffic_Light_Detection_Yolo\"\u003ewade0125/Traffic_Light_Detection_Yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e9574a96800f53b64856ffcf140c7c71fda7509da28389202ca80429d17dfd97/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616465303132352f547261666669635f4c696768745f446574656374696f6e5f596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e9574a96800f53b64856ffcf140c7c71fda7509da28389202ca80429d17dfd97/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616465303132352f547261666669635f4c696768745f446574656374696f6e5f596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wade0125/Traffic_Light_Detection_Yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Traffic Light Detection Yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LIU42/PassingRules\"\u003eLIU42/PassingRules\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/aabdd3a66444d723af05bde9791f8f97e802501420750f0907928592389391d4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c495534322f50617373696e6752756c65733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/aabdd3a66444d723af05bde9791f8f97e802501420750f0907928592389391d4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c495534322f50617373696e6752756c65733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LIU42/PassingRules?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä¸€ç§åŸºäºŽ YOLOv8 çš„è·¯å£äº¤é€šä¿¡å·ç¯é€šè¡Œè§„åˆ™è¯†åˆ«æ¨¡åž‹åŠç®—æ³•.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eTraffic Sign Detection\u003c/h4\u003e\u003ca id=\"user-content-traffic-sign-detection\" class=\"anchor\" aria-label=\"Permalink: Traffic Sign Detection\" href=\"#traffic-sign-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eäº¤é€šæ ‡å¿—æ£€æµ‹\u003c/h5\u003e\u003ca id=\"user-content-äº¤é€šæ ‡å¿—æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: äº¤é€šæ ‡å¿—æ£€æµ‹\" href=\"#äº¤é€šæ ‡å¿—æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ai-trainee/Traffic-Sign-Recognition-PyQt5-YOLOv5-GUI\"\u003eAi-trainee/Traffic-Sign-Recognition-PyQt5-YOLOv5-GUI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/90c72d4f35e2e36b19db9ea449b487cede52d7ca82c29f3f6dddb31914d294c1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41692d747261696e65652f547261666669632d5369676e2d5265636f676e6974696f6e2d50795174352d594f4c4f76352d4755493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/90c72d4f35e2e36b19db9ea449b487cede52d7ca82c29f3f6dddb31914d294c1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41692d747261696e65652f547261666669632d5369676e2d5265636f676e6974696f6e2d50795174352d594f4c4f76352d4755493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ai-trainee/Traffic-Sign-Recognition-PyQt5-YOLOv5-GUI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Road Sign Recognition Project Based on YOLOv5. This is a road sign recognition project based on YOLOv5, developed with a PyQt5 interface, YOLOv5 trained model, and MySQL database. è¿™æ˜¯ä¸€ä¸ªåŸºäºŽYOLOv5ðŸš€çš„é“è·¯æ ‡å¿—è¯†åˆ«ç³»ç»ŸðŸ˜Šï¼Œä½¿ç”¨äº†MySQLæ•°æ®åº“ðŸ’½ï¼ŒPyQt5è¿›è¡Œç•Œé¢è®¾è®¡ðŸŽ¨ï¼ŒPyTorchæ·±åº¦å­¦ä¹ æ¡†æž¶å’ŒTensorRTè¿›è¡ŒåŠ é€Ÿâš¡ï¼ŒåŒæ—¶åŒ…å«äº†CSSæ ·å¼ðŸŒˆã€‚ç³»ç»Ÿç”±äº”ä¸ªä¸»è¦æ¨¡å—ç»„æˆï¼šç³»ç»Ÿç™»å½•æ¨¡å—ðŸ”‘è´Ÿè´£ç”¨æˆ·ç™»é™†ï¼›åˆå§‹åŒ–å‚æ•°æ¨¡å—ðŸ“‹æä¾›YOLOv5æ¨¡åž‹çš„åˆå§‹åŒ–å‚æ•°è®¾ç½®ï¼›æ ‡å¿—è¯†åˆ«æ¨¡å—ðŸ”æ˜¯ç³»ç»Ÿçš„æ ¸å¿ƒï¼Œè´Ÿè´£å¯¹é“è·¯æ ‡å¿—è¿›è¡Œè¯†åˆ«å¹¶å°†ç»“æžœå¯¼å…¥æ•°æ®åº“ï¼›æ•°æ®åº“æ¨¡å—ðŸ’¾åŒ…å«åŸºæœ¬æ•°æ®åº“æ“ä½œå’Œæ•°æ®åˆ†æžä¸¤ä¸ªå­æ¨¡å—ï¼›å›¾åƒå¤„ç†æ¨¡å—ðŸ–¼ï¸è´Ÿè´£å•ä¸ªå›¾åƒçš„å¤„ç†å’Œæ•°æ®å¢žå¼ºã€‚æ•´ä¸ªç³»ç»Ÿæ”¯æŒå¤šç§æ•°æ®è¾“å…¥å’Œæ¨¡åž‹åˆ‡æ¢ï¼Œæä¾›äº†åŒ…æ‹¬mossicå’Œmixupåœ¨å†…çš„å›¾åƒå¢žå¼ºæ–¹æ³•ðŸ“ˆã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/halftop/TT100K_YOLO_Label\"\u003ehalftop/TT100K_YOLO_Label\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4717196de267dd63c40b11e726ee486da531aa67ab558baeb107d4f18f51ec2e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68616c66746f702f54543130304b5f594f4c4f5f4c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4717196de267dd63c40b11e726ee486da531aa67ab558baeb107d4f18f51ec2e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68616c66746f702f54543130304b5f594f4c4f5f4c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/halftop/TT100K_YOLO_Label?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tsinghua-Tencent 100K dataset XML and TXT Label.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/amazingcodeLYL/Traffic_signs_detection_darket\"\u003eamazingcodeLYL/Traffic_signs_detection_darket\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2033727f268d06cf6bbf3e60617ec047e0c9cc3acc90a80118e9286ea8f01c99/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616d617a696e67636f64654c594c2f547261666669635f7369676e735f646574656374696f6e5f6461726b65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2033727f268d06cf6bbf3e60617ec047e0c9cc3acc90a80118e9286ea8f01c99/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616d617a696e67636f64654c594c2f547261666669635f7369676e735f646574656374696f6e5f6461726b65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/amazingcodeLYL/Traffic_signs_detection_darket?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : darknetäº¤é€šæ ‡å¿—æ£€æµ‹\u0026amp;TT100Kæ•°æ®é›†ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TalkUHulk/yolov3-TT100k\"\u003eTalkUHulk/yolov3-TT100k\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5e164fd63189c1e9e400c32d6a166bdaf81f2f35e9302c7defc7d9a864aa15b6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54616c6b5548756c6b2f796f6c6f76332d54543130306b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5e164fd63189c1e9e400c32d6a166bdaf81f2f35e9302c7defc7d9a864aa15b6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54616c6b5548756c6b2f796f6c6f76332d54543130306b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TalkUHulk/yolov3-TT100k?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä½¿ç”¨yolov3è®­ç»ƒçš„TT100k(äº¤é€šæ ‡å¿—)æ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TalkUHulk/yolov4-TT100k\"\u003eTalkUHulk/yolov4-TT100k\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c3d8db4c4c6cdad96f24f627023fe2742ffa45fba547b1f38578c99fb6cb990f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54616c6b5548756c6b2f796f6c6f76342d54543130306b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c3d8db4c4c6cdad96f24f627023fe2742ffa45fba547b1f38578c99fb6cb990f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54616c6b5548756c6b2f796f6c6f76342d54543130306b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TalkUHulk/yolov4-TT100k?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä½¿ç”¨yolov4è®­ç»ƒçš„TT100k(äº¤é€šæ ‡å¿—)æ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sarah-antillia/YOLO_Realistic_USA_RoadSigns_160classes\"\u003esarah-antillia/YOLO_Realistic_USA_RoadSigns_160classes\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cf7fca7ae480ce780fb231f43bc15783f0289abacd4e20c8d5aa25a1c9903f60/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73617261682d616e74696c6c69612f594f4c4f5f5265616c69737469635f5553415f526f61645369676e735f313630636c61737365733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cf7fca7ae480ce780fb231f43bc15783f0289abacd4e20c8d5aa25a1c9903f60/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73617261682d616e74696c6c69612f594f4c4f5f5265616c69737469635f5553415f526f61645369676e735f313630636c61737365733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sarah-antillia/YOLO_Realistic_USA_RoadSigns_160classes?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : USA RoadSigns Dataset 160classes annotated by YOLO format.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DickensKP/yolov3-vehicle-pedestrian-trafficsign-detection-system\"\u003eDickensKP/yolov3-vehicle-pedestrian-trafficsign-detection-system\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b011a4b70f48f96314a21465b8f75bce73c69452469fe4288a559d8760de6b86/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4469636b656e734b502f796f6c6f76332d76656869636c652d7065646573747269616e2d747261666669637369676e2d646574656374696f6e2d73797374656d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b011a4b70f48f96314a21465b8f75bce73c69452469fe4288a559d8760de6b86/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4469636b656e734b502f796f6c6f76332d76656869636c652d7065646573747269616e2d747261666669637369676e2d646574656374696f6e2d73797374656d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DickensKP/yolov3-vehicle-pedestrian-trafficsign-detection-system?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽbubbliiiingçš„yolov3-pytorchæ¡†æž¶ï¼Œè‡ªä¸»è®­ç»ƒçš„è½¦è¾†ã€è¡Œäººã€äº¤é€šæ ‡å¿—è¯†åˆ«ç³»ç»Ÿ.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mkrupczak3/Coneslayer\"\u003emkrupczak3/Coneslayer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d7f3a609b1320de19a872cb0ce00798babc42406495246d144dba4ca2f17697d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6b727570637a616b332f436f6e65736c617965723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d7f3a609b1320de19a872cb0ce00798babc42406495246d144dba4ca2f17697d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6b727570637a616b332f436f6e65736c617965723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mkrupczak3/Coneslayer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A lightweight neural-network for rapid detection of traffic cones.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCrosswalk Detection\u003c/h4\u003e\u003ca id=\"user-content-crosswalk-detection\" class=\"anchor\" aria-label=\"Permalink: Crosswalk Detection\" href=\"#crosswalk-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eäººè¡Œæ¨ªé“/æ–‘é©¬çº¿æ£€æµ‹\u003c/h5\u003e\u003ca id=\"user-content-äººè¡Œæ¨ªé“æ–‘é©¬çº¿æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: äººè¡Œæ¨ªé“/æ–‘é©¬çº¿æ£€æµ‹\" href=\"#äººè¡Œæ¨ªé“æ–‘é©¬çº¿æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zhangzhengde0225/CDNet\"\u003eCDNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/73b9ca8f4904da16f05b56fecd7d561409a3b95839b44789d2c9a2cd8347c4aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68616e677a68656e676465303232352f43444e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/73b9ca8f4904da16f05b56fecd7d561409a3b95839b44789d2c9a2cd8347c4aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68616e677a68656e676465303232352f43444e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zhangzhengde0225/CDNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"CDNet: a real-time and robust crosswalk detection network on Jetson nano based on YOLOv5\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/article/10.1007/s00521-022-07007-9\" rel=\"nofollow\"\u003eNeural Computing and Applications 2022\u003c/a\u003e\u003c/strong\u003e). \"å¾®ä¿¡å…¬ä¼—å·ã€ŒCVerã€ã€Š\u003ca href=\"https://mp.weixin.qq.com/s/2F3WBtfN_7DkhERMOH8-QA\" rel=\"nofollow\"\u003eä¸Šæµ·äº¤å¤§æå‡ºCDNetï¼šåŸºäºŽæ”¹è¿›YOLOv5çš„æ–‘é©¬çº¿å’Œæ±½è½¦è¿‡çº¿è¡Œä¸ºæ£€æµ‹\u003c/a\u003eã€‹\"ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xN1ckuz/Crosswalks-Detection-using-YoloV5\"\u003exN1ckuz/Crosswalks-Detection-using-YoloV5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/413e971284333cfb2256ac7b1570b47dcd99b68370082aa20b245e107e34abd4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f784e31636b757a2f43726f737377616c6b732d446574656374696f6e2d7573696e672d596f6c6f56353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/413e971284333cfb2256ac7b1570b47dcd99b68370082aa20b245e107e34abd4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f784e31636b757a2f43726f737377616c6b732d446574656374696f6e2d7573696e672d596f6c6f56353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xN1ckuz/Crosswalks-Detection-using-YoloV5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Crosswalks Detection using YOLO, project for Computer Vision and Machine Perception course at University of Basilicata, Computer Science and Engineering.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eTraffic Accidents Detection\u003c/h4\u003e\u003ca id=\"user-content-traffic-accidents-detection\" class=\"anchor\" aria-label=\"Permalink: Traffic Accidents Detection\" href=\"#traffic-accidents-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eäº¤é€šäº‹æ•…æ£€æµ‹\u003c/h5\u003e\u003ca id=\"user-content-äº¤é€šäº‹æ•…æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: äº¤é€šäº‹æ•…æ£€æµ‹\" href=\"#äº¤é€šäº‹æ•…æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/khaledsabry97/Argus\"\u003ekhaledsabry97/Argus\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8881ba679e60d084423cc05f79ef02b5c49be34207ed4c944b6b360c69b9f6da/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b68616c6564736162727939372f41726775733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8881ba679e60d084423cc05f79ef02b5c49be34207ed4c944b6b360c69b9f6da/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b68616c6564736162727939372f41726775733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/khaledsabry97/Argus?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Road Traffic Accidents Detection Based On Crash Estimation\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/document/9698968\" rel=\"nofollow\"\u003eIEEE ICENCO 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eRoad Damage Detection\u003c/h4\u003e\u003ca id=\"user-content-road-damage-detection\" class=\"anchor\" aria-label=\"Permalink: Road Damage Detection\" href=\"#road-damage-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eé“è·¯æŸä¼¤æ£€æµ‹\u003c/h5\u003e\u003ca id=\"user-content-é“è·¯æŸä¼¤æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: é“è·¯æŸä¼¤æ£€æµ‹\" href=\"#é“è·¯æŸä¼¤æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/adnanmushtaq1996/Yolov4_Road_Damage_Detection\"\u003eadnanmushtaq1996/Yolov4_Road_Damage_Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8917757e1cfca085709f5845ec0324b5a442b7087727a88ae141a3484e5104eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61646e616e6d757368746171313939362f596f6c6f76345f526f61645f44616d6167655f446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8917757e1cfca085709f5845ec0324b5a442b7087727a88ae141a3484e5104eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61646e616e6d757368746171313939362f596f6c6f76345f526f61645f44616d6167655f446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/adnanmushtaq1996/Yolov4_Road_Damage_Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Repository to Train a Custom Yolov4 based object detector for road damage detection using the RDD2020 dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/E-Kozyreva/detection_potholes_yolov8n\"\u003eE-Kozyreva/detection_potholes_yolov8n\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c42f6b4edf5a82621f645c9429299c0d6c05abc0c0860d49e9a8ab9079431ae8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f452d4b6f7a79726576612f646574656374696f6e5f706f74686f6c65735f796f6c6f76386e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c42f6b4edf5a82621f645c9429299c0d6c05abc0c0860d49e9a8ab9079431ae8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f452d4b6f7a79726576612f646574656374696f6e5f706f74686f6c65735f796f6c6f76386e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/E-Kozyreva/detection_potholes_yolov8n?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ÐŸÐ¾Ð¸ÑÐº Ð²Ñ‹Ð±Ð¾Ð¸Ð½ Ð½Ð° Ð´Ð¾Ñ€Ð¾Ð³Ð°Ñ… Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ YOLOv8 Nano.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mounishvatti/pothole_detection_yolov8\"\u003emounishvatti/pothole_detection_yolov8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6ba8a39451f4ca80e57a046aec75ac4101b3249bff2d8d0063f2593f39528366/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6f756e69736876617474692f706f74686f6c655f646574656374696f6e5f796f6c6f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6ba8a39451f4ca80e57a046aec75ac4101b3249bff2d8d0063f2593f39528366/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6f756e69736876617474692f706f74686f6c655f646574656374696f6e5f796f6c6f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mounishvatti/pothole_detection_yolov8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Pothole Detection using Ultralytics YOLOv8\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAnimal Detection\u003c/h3\u003e\u003ca id=\"user-content-animal-detection\" class=\"anchor\" aria-label=\"Permalink: Animal Detection\" href=\"#animal-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eåŠ¨ç‰©æ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-åŠ¨ç‰©æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: åŠ¨ç‰©æ£€æµ‹\" href=\"#åŠ¨ç‰©æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SaiSwarup27/Animal-Intrusion-Detection\"\u003eSaiSwarup27/Animal-Intrusion-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1e2c1ab0d3544c1990548e3cca3001ab870078a842bb867247c0ace9f15ba0a7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53616953776172757032372f416e696d616c2d496e74727573696f6e2d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1e2c1ab0d3544c1990548e3cca3001ab870078a842bb867247c0ace9f15ba0a7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53616953776172757032372f416e696d616c2d496e74727573696f6e2d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SaiSwarup27/Animal-Intrusion-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Animal Detection using YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xcapt0/animal_recognition\"\u003excapt0/animal_recognition\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6fc614ba453018a29831e562e3959d305f792090bc0bee150a0409f2f26a54dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7863617074302f616e696d616c5f7265636f676e6974696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6fc614ba453018a29831e562e3959d305f792090bc0bee150a0409f2f26a54dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7863617074302f616e696d616c5f7265636f676e6974696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xcapt0/animal_recognition?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ¦ Let the robot recognize the animal instead of you | YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PhamDangNguyen/YOLOv5_Animals\"\u003ePhamDangNguyen/YOLOv5_Animals\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/46bc3ff562b5f8ba27f117a75a8f7c35814ddc9d0f25c3de4a7c710bef2d2090/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5068616d44616e674e677579656e2f594f4c4f76355f416e696d616c733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/46bc3ff562b5f8ba27f117a75a8f7c35814ddc9d0f25c3de4a7c710bef2d2090/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5068616d44616e674e677579656e2f594f4c4f76355f416e696d616c733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PhamDangNguyen/YOLOv5_Animals?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 for detection Animals.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Sabuj-CSE11/AnimalDetection\"\u003eSabuj-CSE11/AnimalDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4c3aeba6da79f1d198437140a8092282f7430c3a4df2fa60f7a7ca8d6d791566/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536162756a2d43534531312f416e696d616c446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4c3aeba6da79f1d198437140a8092282f7430c3a4df2fa60f7a7ca8d6d791566/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536162756a2d43534531312f416e696d616c446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Sabuj-CSE11/AnimalDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Cat and Dogs detection using YoloV5.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eHelmet Detection\u003c/h3\u003e\u003ca id=\"user-content-helmet-detection\" class=\"anchor\" aria-label=\"Permalink: Helmet Detection\" href=\"#helmet-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eå¤´ç›”/å®‰å…¨å¸½æ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-å¤´ç›”å®‰å…¨å¸½æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: å¤´ç›”/å®‰å…¨å¸½æ£€æµ‹\" href=\"#å¤´ç›”å®‰å…¨å¸½æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PeterH0323/Smart_Construction\"\u003ePeterH0323/Smart_Construction\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c01d4f71125def99db5fb613f9716bdc085984bcd0caa56e25f74b338bba1c66/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506574657248303332332f536d6172745f436f6e737472756374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c01d4f71125def99db5fb613f9716bdc085984bcd0caa56e25f74b338bba1c66/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506574657248303332332f536d6172745f436f6e737472756374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PeterH0323/Smart_Construction?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Head Person Helmet Detection on Construction Sitesï¼ŒåŸºäºŽç›®æ ‡æ£€æµ‹å·¥åœ°å®‰å…¨å¸½å’Œç¦å…¥å±é™©åŒºåŸŸè¯†åˆ«ç³»ç»Ÿã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Byronnar/tensorflow-serving-yolov3\"\u003eByronnar/tensorflow-serving-yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bf42033c7a95e46bf918f33729ec1897d1f9a2fa2a961513347103676c3e12a7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4279726f6e6e61722f74656e736f72666c6f772d73657276696e672d796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bf42033c7a95e46bf918f33729ec1897d1f9a2fa2a961513347103676c3e12a7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4279726f6e6e61722f74656e736f72666c6f772d73657276696e672d796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Byronnar/tensorflow-serving-yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : å¯¹åŽŸtensorflow-yolov3ç‰ˆæœ¬åšäº†è®¸å¤šç»†èŠ‚ä¸Šçš„æ”¹è¿›ï¼Œå¢žåŠ äº†TensorFlow-Servingå·¥ç¨‹éƒ¨ç½²ï¼Œè®­ç»ƒäº†å¤šä¸ªæ•°æ®é›†ï¼ŒåŒ…æ‹¬Visdrone2019, å®‰å…¨å¸½ç­‰ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/gengyanlei/reflective-clothes-detect-yolov5\"\u003egengyanlei/reflective-clothes-detect-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6b39427a1bac6fe9dd0ec0e992822d1dc5552807c642eb32aa4f9670a94215d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67656e6779616e6c65692f7265666c6563746976652d636c6f746865732d6465746563742d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6b39427a1bac6fe9dd0ec0e992822d1dc5552807c642eb32aa4f9670a94215d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67656e6779616e6c65692f7265666c6563746976652d636c6f746865732d6465746563742d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/gengyanlei/reflective-clothes-detect-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : reflective-clothes-detect-datasetã€helemet detection yolov5ã€å·¥ä½œæœ(åå…‰è¡£)æ£€æµ‹æ•°æ®é›†ã€å®‰å…¨å¸½æ£€æµ‹ã€æ–½å·¥äººå‘˜ç©¿æˆ´æ£€æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DataXujing/YOLO-V3-Tensorflow\"\u003eDataXujing/YOLO-V3-Tensorflow\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/237c316a53bc527c4b634612637bb77b320ac2d1bd2efafd8c068854e415bc8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f2d56332d54656e736f72666c6f773f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/237c316a53bc527c4b634612637bb77b320ac2d1bd2efafd8c068854e415bc8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f2d56332d54656e736f72666c6f773f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DataXujing/YOLO-V3-Tensorflow?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ‘· ðŸ‘·ðŸ‘· YOLO V3(Tensorflow 1.x) å®‰å…¨å¸½ è¯†åˆ« | æä¾›æ•°æ®é›†ä¸‹è½½å’Œä¸Žé¢„è®­ç»ƒæ¨¡åž‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/rafiuddinkhan/Yolo-Training-GoogleColab\"\u003erafiuddinkhan/Yolo-Training-GoogleColab\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/18823f9533fbc515bfb18d6e4c1e23c59c216007c06ef6d86a46e8387ed1e498/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616669756464696e6b68616e2f596f6c6f2d547261696e696e672d476f6f676c65436f6c61623f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/18823f9533fbc515bfb18d6e4c1e23c59c216007c06ef6d86a46e8387ed1e498/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616669756464696e6b68616e2f596f6c6f2d547261696e696e672d476f6f676c65436f6c61623f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/rafiuddinkhan/Yolo-Training-GoogleColab?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Helmet Detection using tiny-yolo-v3 by training using your own dataset and testing the results in the google colaboratory.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BlcaKHat/yolov3-Helmet-Detection\"\u003eBlcaKHat/yolov3-Helmet-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b24cfe1cd35a36a8f943bc85dda487385f0e7c3299987791442b27b0728c6236/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426c63614b4861742f796f6c6f76332d48656c6d65742d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b24cfe1cd35a36a8f943bc85dda487385f0e7c3299987791442b27b0728c6236/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426c63614b4861742f796f6c6f76332d48656c6d65742d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BlcaKHat/yolov3-Helmet-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Training a YOLOv3 model to detect the presence of helmet for intrusion or traffic monitoring.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yumulinfeng1/YOLOv4-Hat-detection\"\u003eyumulinfeng1/YOLOv4-Hat-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/24d6018c8f1565e555dc30662dc07018e573a43a3e74bf8a7b3e5ba95a14c095/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f79756d756c696e66656e67312f594f4c4f76342d4861742d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/24d6018c8f1565e555dc30662dc07018e573a43a3e74bf8a7b3e5ba95a14c095/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f79756d756c696e66656e67312f594f4c4f76342d4861742d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yumulinfeng1/YOLOv4-Hat-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽYOLOv4çš„å®‰å…¨å¸½ä½©æˆ´æ£€æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FanDady/Helmet-Detection-YoloV5\"\u003eFanDady/Helmet-Detection-YoloV5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/73e01d7ba3874a54f80a6dda46c0f424a001612124b23c8a0a2fd9dac7299185/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46616e446164792f48656c6d65742d446574656374696f6e2d596f6c6f56353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/73e01d7ba3874a54f80a6dda46c0f424a001612124b23c8a0a2fd9dac7299185/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46616e446164792f48656c6d65742d446574656374696f6e2d596f6c6f56353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FanDady/Helmet-Detection-YoloV5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Safety helmet wearing detection on construction site based on YoloV5s-V5.0 including helmet datasetï¼ˆåŸºäºŽYoloV5-V5.0çš„å·¥åœ°å®‰å…¨å¸½æ£€æµ‹å¹¶ä¸”åŒ…å«å¼€æºçš„å®‰å…¨å¸½æ•°æ®é›†ï¼‰ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RUI-LIU7/Helmet_Detection\"\u003eRUI-LIU7/Helmet_Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/dd2ab3d00b90389dc30a8e5a626bf73f40e787e2b6399e75ac71817d39aabaac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5255492d4c4955372f48656c6d65745f446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dd2ab3d00b90389dc30a8e5a626bf73f40e787e2b6399e75ac71817d39aabaac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5255492d4c4955372f48656c6d65745f446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RUI-LIU7/Helmet_Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä½¿ç”¨yolov5ç®—æ³•å®žçŽ°å®‰å…¨å¸½ä»¥åŠå±é™©åŒºåŸŸçš„ç›‘æµ‹ï¼ŒåŒæ—¶æŽ¥å…¥æµ·åº·æ‘„åƒå¤´å®žçŽ°å®žæ—¶ç›‘æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZijianWang1995/PPE_detection\"\u003eZijianWang1995/PPE_detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e1a25011715873e62509aea06a36f468be4cb31d839b81e1a46e4af59ab3eba3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a696a69616e57616e67313939352f5050455f646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e1a25011715873e62509aea06a36f468be4cb31d839b81e1a46e4af59ab3eba3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a696a69616e57616e67313939352f5050455f646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZijianWang1995/PPE_detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time PPE detection based on YOLO. Open high-quality dataset. \"Fast Personal Protective Equipment Detection for Real Construction Sites Using Deep Learning Approaches\". (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/1424-8220/21/10/3478\" rel=\"nofollow\"\u003eSensors 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eHand Detection\u003c/h3\u003e\u003ca id=\"user-content-hand-detection\" class=\"anchor\" aria-label=\"Permalink: Hand Detection\" href=\"#hand-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eæ‰‹éƒ¨æ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-æ‰‹éƒ¨æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: æ‰‹éƒ¨æ£€æµ‹\" href=\"#æ‰‹éƒ¨æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/cansik/yolo-hand-detection\"\u003ecansik/yolo-hand-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b979a323cee0755fd5a178051b98bd2ef5c075615082820aa62f2d703974df24/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63616e73696b2f796f6c6f2d68616e642d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b979a323cee0755fd5a178051b98bd2ef5c075615082820aa62f2d703974df24/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63616e73696b2f796f6c6f2d68616e642d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cansik/yolo-hand-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A pre-trained YOLO based hand detection network.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eGesture Recognition\u003c/h3\u003e\u003ca id=\"user-content-gesture-recognition\" class=\"anchor\" aria-label=\"Permalink: Gesture Recognition\" href=\"#gesture-recognition\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eæ‰‹åŠ¿/æ‰‹è¯­è¯†åˆ«\u003c/h4\u003e\u003ca id=\"user-content-æ‰‹åŠ¿æ‰‹è¯­è¯†åˆ«\" class=\"anchor\" aria-label=\"Permalink: æ‰‹åŠ¿/æ‰‹è¯­è¯†åˆ«\" href=\"#æ‰‹åŠ¿æ‰‹è¯­è¯†åˆ«\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MahmudulAlam/Unified-Gesture-and-Fingertip-Detection\"\u003eMahmudulAlam/Unified-Gesture-and-Fingertip-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b801be0b59f8246c5c19475fa572c5f527d52927da44758e415fd8d04d1c6c08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d61686d7564756c416c616d2f556e69666965642d476573747572652d616e642d46696e6765727469702d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b801be0b59f8246c5c19475fa572c5f527d52927da44758e415fd8d04d1c6c08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d61686d7564756c416c616d2f556e69666965642d476573747572652d616e642d46696e6765727469702d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MahmudulAlam/Unified-Gesture-and-Fingertip-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Unified learning approach for egocentric hand gesture recognition and fingertip detection\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S0031320321003824\" rel=\"nofollow\"\u003eElsevier 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/insigh1/Interactive_ABCs_with_American_Sign_Language_using_Yolov5\"\u003einsigh1/Interactive_ABCs_with_American_Sign_Language_using_Yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c219186fb0ab1c5da121915be8c4f0f635af8ed41966a62d27497f60673930ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e73696768312f496e7465726163746976655f414243735f776974685f416d65726963616e5f5369676e5f4c616e67756167655f7573696e675f596f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c219186fb0ab1c5da121915be8c4f0f635af8ed41966a62d27497f60673930ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e73696768312f496e7465726163746976655f414243735f776974685f416d65726963616e5f5369676e5f4c616e67756167655f7573696e675f596f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/insigh1/Interactive_ABCs_with_American_Sign_Language_using_Yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Interactive ABC's with American Sign Language.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Dreaming-future/YOLO-Object-Detection\"\u003eDreaming-future/YOLO-Object-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6dcb15889d5d8a5cd1f2fc4da9dce94a66f6b0cb904fd32b698f489f15797431/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f447265616d696e672d6675747572652f594f4c4f2d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6dcb15889d5d8a5cd1f2fc4da9dce94a66f6b0cb904fd32b698f489f15797431/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f447265616d696e672d6675747572652f594f4c4f2d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Dreaming-future/YOLO-Object-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e :  YOLO-Object-Detection é›†æˆå¤šç§yoloæ¨¡åž‹ï¼Œä½œä¸ºä¸€ä¸ªæ¨¡æ¿è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAction Detection\u003c/h3\u003e\u003ca id=\"user-content-action-detection\" class=\"anchor\" aria-label=\"Permalink: Action Detection\" href=\"#action-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eè¡Œä¸ºæ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-è¡Œä¸ºæ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: è¡Œä¸ºæ£€æµ‹\" href=\"#è¡Œä¸ºæ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/wufan-tb/yolo_slowfast\"\u003ewufan-tb/yolo_slowfast\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a692976db9bbe3f0541fcbbdef1c2a29e953eaba62142b61fd8b31ed8d68a340/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f777566616e2d74622f796f6c6f5f736c6f77666173743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a692976db9bbe3f0541fcbbdef1c2a29e953eaba62142b61fd8b31ed8d68a340/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f777566616e2d74622f796f6c6f5f736c6f77666173743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wufan-tb/yolo_slowfast?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A realtime action detection frame work based on PytorchVideo.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eEmotion Recognition\u003c/h3\u003e\u003ca id=\"user-content-emotion-recognition\" class=\"anchor\" aria-label=\"Permalink: Emotion Recognition\" href=\"#emotion-recognition\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eæƒ…æ„Ÿè¯†åˆ«\u003c/h4\u003e\u003ca id=\"user-content-æƒ…æ„Ÿè¯†åˆ«\" class=\"anchor\" aria-label=\"Permalink: æƒ…æ„Ÿè¯†åˆ«\" href=\"#æƒ…æ„Ÿè¯†åˆ«\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/Tandon-A/emotic\"\u003eTandon-A/emotic\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b8cc2d06695b1944643cf76b6f89e11e53e7e8d1f6c1fdc54f71e3f36c412650/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54616e646f6e2d412f656d6f7469633f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b8cc2d06695b1944643cf76b6f89e11e53e7e8d1f6c1fdc54f71e3f36c412650/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54616e646f6e2d412f656d6f7469633f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Tandon-A/emotic?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Context based emotion recognition using emotic dataset\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2003.13401\" rel=\"nofollow\"\u003earXiv 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eHuman Pose Estimation\u003c/h3\u003e\u003ca id=\"user-content-human-pose-estimation\" class=\"anchor\" aria-label=\"Permalink: Human Pose Estimation\" href=\"#human-pose-estimation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eäººä½“å§¿æ€ä¼°è®¡\u003c/h4\u003e\u003ca id=\"user-content-äººä½“å§¿æ€ä¼°è®¡\" class=\"anchor\" aria-label=\"Permalink: äººä½“å§¿æ€ä¼°è®¡\" href=\"#äººä½“å§¿æ€ä¼°è®¡\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wmcnally/kapao\"\u003ewmcnally/kapao\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e7a853285fe26109f5beb31c4a3381d8425796fee9c99e3b3cf8b13ac924806f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776d636e616c6c792f6b6170616f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e7a853285fe26109f5beb31c4a3381d8425796fee9c99e3b3cf8b13ac924806f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776d636e616c6c792f6b6170616f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wmcnally/kapao?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : KAPAO is a state-of-the-art single-stage human pose estimation model that detects keypoints and poses as objects and fuses the detections to predict human poses. \"Rethinking Keypoint Representations: Modeling Keypoints and Poses as Objects for Multi-Person Human Pose Estimation\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2111.08557\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TexasInstruments/edgeai-yolov5\"\u003eTexasInstruments/edgeai-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e62031557ee76a2ca62cac054c28b747295d20a1eef167c2d092f0e4d23d6102/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5465786173496e737472756d656e74732f6564676561692d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e62031557ee76a2ca62cac054c28b747295d20a1eef167c2d092f0e4d23d6102/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5465786173496e737472756d656e74732f6564676561692d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TexasInstruments/edgeai-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLO-Pose: Enhancing YOLO for Multi Person Pose Estimation Using Object Keypoint Similarity Loss\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2204.06806\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TexasInstruments/edgeai-yolox\"\u003eTexasInstruments/edgeai-yolox\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/213b6398624215a716010c173b6a75ab209108dca03e0b6b4bba1448b87af8d0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5465786173496e737472756d656e74732f6564676561692d796f6c6f783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/213b6398624215a716010c173b6a75ab209108dca03e0b6b4bba1448b87af8d0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5465786173496e737472756d656e74732f6564676561692d796f6c6f783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TexasInstruments/edgeai-yolox?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLO-Pose: Enhancing YOLO for Multi Person Pose Estimation Using Object Keypoint Similarity Loss\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2204.06806\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jinfagang/VIBE_yolov5\"\u003ejinfagang/VIBE_yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/06360061dd2ee2531f39027468d49d24292179108f70ac1b4735b7a1ed5605d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a696e666167616e672f564942455f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/06360061dd2ee2531f39027468d49d24292179108f70ac1b4735b7a1ed5605d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a696e666167616e672f564942455f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jinfagang/VIBE_yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Using YOLOv5 as detection on VIBE. \"VIBE: Video Inference for Human Body Pose and Shape Estimation\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_CVPR_2020/html/Kocabas_VIBE_Video_Inference_for_Human_Body_Pose_and_Shape_Estimation_CVPR_2020_paper.html\" rel=\"nofollow\"\u003eCVPR 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zhuoxiangpang/ism_person_openpose\"\u003ezhuoxiangpang/ism_person_openpose\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/02e2c5f313360414a8a318ce36064618ca086c35a4f1126043e045c8801aba77/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68756f7869616e6770616e672f69736d5f706572736f6e5f6f70656e706f73653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/02e2c5f313360414a8a318ce36064618ca086c35a4f1126043e045c8801aba77/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68756f7869616e6770616e672f69736d5f706572736f6e5f6f70656e706f73653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zhuoxiangpang/ism_person_openpose?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5äººä½“æ£€æµ‹+openposeå§¿æ€æ£€æµ‹ å®žçŽ°æ‘”å€’æ£€æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pengyang1225/yolov5_person_pose\"\u003epengyang1225/yolov5_person_pose\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b75a6f672e61c1edca09514ada8bf2d7d7a3a9c4c1f8fc0508f2d3fd83a3776a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70656e6779616e67313232352f796f6c6f76355f706572736f6e5f706f73653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b75a6f672e61c1edca09514ada8bf2d7d7a3a9c4c1f8fc0508f2d3fd83a3776a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70656e6779616e67313232352f796f6c6f76355f706572736f6e5f706f73653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pengyang1225/yolov5_person_pose?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽyolov5çš„personâ€”poseã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hpc203/yolov5_pose_opencv\"\u003ehpc203/yolov5_pose_opencv\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b2edc2f4299262e8f271926d8f7b8fed8eb46e7828851e2acd637e559b251626/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f796f6c6f76355f706f73655f6f70656e63763f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b2edc2f4299262e8f271926d8f7b8fed8eb46e7828851e2acd637e559b251626/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f796f6c6f76355f706f73655f6f70656e63763f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hpc203/yolov5_pose_opencv?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä½¿ç”¨OpenCVéƒ¨ç½²yolov5-poseç›®æ ‡æ£€æµ‹+äººä½“å§¿æ€ä¼°è®¡ï¼ŒåŒ…å«C++å’ŒPythonä¸¤ä¸ªç‰ˆæœ¬çš„ç¨‹åºã€‚æ”¯æŒyolov5sï¼Œyolov5mï¼Œyolov5lã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RizwanMunawar/yolov7-pose-estimation\"\u003eRizwanMunawar/yolov7-pose-estimation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8e4176534f85d94c924d8ba21b62a474b12af86b118d37d9a9bec9a065564434/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d706f73652d657374696d6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8e4176534f85d94c924d8ba21b62a474b12af86b118d37d9a9bec9a065564434/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d706f73652d657374696d6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RizwanMunawar/yolov7-pose-estimation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv7 Pose estimation using OpenCV, PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nanmi/yolov7-pose\"\u003enanmi/yolov7-pose\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e8415b0bcd3e46d104f4cd1fd98cf4f1cc7e86035bb29a64751ec0ecb0c9e0f9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e616e6d692f796f6c6f76372d706f73653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e8415b0bcd3e46d104f4cd1fd98cf4f1cc7e86035bb29a64751ec0ecb0c9e0f9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e616e6d692f796f6c6f76372d706f73653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nanmi/yolov7-pose?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : pose detection base on yolov7.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eDistance Measurement\u003c/h3\u003e\u003ca id=\"user-content-distance-measurement\" class=\"anchor\" aria-label=\"Permalink: Distance Measurement\" href=\"#distance-measurement\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eè·ç¦»æµ‹é‡\u003c/h4\u003e\u003ca id=\"user-content-è·ç¦»æµ‹é‡\" class=\"anchor\" aria-label=\"Permalink: è·ç¦»æµ‹é‡\" href=\"#è·ç¦»æµ‹é‡\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/davidfrz/yolov5_distance_count\"\u003edavidfrz/yolov5_distance_count\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6f3c7e22bb883258ad3fe5ea0533096fbf1b3007b446c905182b62bfabf3eade/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646176696466727a2f796f6c6f76355f64697374616e63655f636f756e743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6f3c7e22bb883258ad3fe5ea0533096fbf1b3007b446c905182b62bfabf3eade/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646176696466727a2f796f6c6f76355f64697374616e63655f636f756e743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/davidfrz/yolov5_distance_count?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : é€šè¿‡yolov5å®žçŽ°ç›®æ ‡æ£€æµ‹+åŒç›®æ‘„åƒå¤´å®žçŽ°è·ç¦»æµ‹é‡ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wenyishengkingkong/realsense-D455-YOLOV5\"\u003ewenyishengkingkong/realsense-D455-YOLOV5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f411b21110b2810bf35aaaa912d369756d86f1c4110ebaf2b9e9f8a6cf047733/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77656e79697368656e676b696e676b6f6e672f7265616c73656e73652d443435352d594f4c4f56353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f411b21110b2810bf35aaaa912d369756d86f1c4110ebaf2b9e9f8a6cf047733/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77656e79697368656e676b696e676b6f6e672f7265616c73656e73652d443435352d594f4c4f56353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wenyishengkingkong/realsense-D455-YOLOV5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åˆ©ç”¨realsenseæ·±åº¦ç›¸æœºå®žçŽ°yolov5ç›®æ ‡æ£€æµ‹çš„åŒæ—¶æµ‹å‡ºè·ç¦»ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Thinkin99/yolov5_d435i_detection\"\u003eThinkin99/yolov5_d435i_detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/957c91192103378751f7d562a3434e9a84d0ac6e58033d8fca708b282d57298e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5468696e6b696e39392f796f6c6f76355f64343335695f646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/957c91192103378751f7d562a3434e9a84d0ac6e58033d8fca708b282d57298e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5468696e6b696e39392f796f6c6f76355f64343335695f646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Thinkin99/yolov5_d435i_detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä½¿ç”¨realsense d435iç›¸æœºï¼ŒåŸºäºŽpytorchå®žçŽ°yolov5ç›®æ ‡æ£€æµ‹ï¼Œè¿”å›žæ£€æµ‹ç›®æ ‡ç›¸æœºåæ ‡ç³»ä¸‹çš„ä½ç½®ä¿¡æ¯ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MUCHWAY/detect_distance_gazebo\"\u003eMUCHWAY/detect_distance_gazebo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9670e1862ee077150962c6dca7dec4a2f6b16a47d0fb3ea42ba3e6daa699eb34/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d5543485741592f6465746563745f64697374616e63655f67617a65626f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9670e1862ee077150962c6dca7dec4a2f6b16a47d0fb3ea42ba3e6daa699eb34/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d5543485741592f6465746563745f64697374616e63655f67617a65626f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MUCHWAY/detect_distance_gazebo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5+camera_distance+gazebo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/magisystem0408/yolov5-DeepSort-RealSenseD435i\"\u003emagisystem0408/yolov5-DeepSort-RealSenseD435i\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4cf406cb1a1ae78ef70a1c8eb7e7ad8448bbca98c9b0481b4bd4c1e3e157c490/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61676973797374656d303430382f796f6c6f76352d44656570536f72742d5265616c53656e736544343335693f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4cf406cb1a1ae78ef70a1c8eb7e7ad8448bbca98c9b0481b4bd4c1e3e157c490/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61676973797374656d303430382f796f6c6f76352d44656570536f72742d5265616c53656e736544343335693f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/magisystem0408/yolov5-DeepSort-RealSenseD435i?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5+Realsence+DeepSense D435i.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eInstance and Semantic Segmentation\u003c/h3\u003e\u003ca id=\"user-content-instance-and-semantic-segmentation\" class=\"anchor\" aria-label=\"Permalink: Instance and Semantic Segmentation\" href=\"#instance-and-semantic-segmentation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eå®žä¾‹å’Œè¯­ä¹‰åˆ†å‰²\u003c/h4\u003e\u003ca id=\"user-content-å®žä¾‹å’Œè¯­ä¹‰åˆ†å‰²\" class=\"anchor\" aria-label=\"Permalink: å®žä¾‹å’Œè¯­ä¹‰åˆ†å‰²\" href=\"#å®žä¾‹å’Œè¯­ä¹‰åˆ†å‰²\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/facebookresearch/segment-anything\"\u003eSAM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fda9f7bfbe5462db4c5ea420348ca3592c669a0d5b92eca51d8bb1044b5c11b5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66616365626f6f6b72657365617263682f7365676d656e742d616e797468696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fda9f7bfbe5462db4c5ea420348ca3592c669a0d5b92eca51d8bb1044b5c11b5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66616365626f6f6b72657365617263682f7365676d656e742d616e797468696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/facebookresearch/segment-anything?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The repository provides code for running inference with the SegmentAnything Model (SAM), links for downloading the trained model checkpoints, and example notebooks that show how to use the model. \"Segment Anything\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2304.02643\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/IDEA-Research/Grounded-Segment-Anything\"\u003eGrounded-SAM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a6feb0326dc5825bc17354675a5c5cf4e0b32f66fe541a0634748c4923204f75/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f47726f756e6465642d5365676d656e742d416e797468696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a6feb0326dc5825bc17354675a5c5cf4e0b32f66fe541a0634748c4923204f75/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f47726f756e6465642d5365676d656e742d416e797468696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/IDEA-Research/Grounded-Segment-Anything?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Marrying Grounding DINO with Segment Anything \u0026amp; Stable Diffusion \u0026amp; Tag2Text \u0026amp; BLIP \u0026amp; Whisper \u0026amp; ChatBot - Automatically Detect , Segment and Generate Anything with Image, Text, and Audio Inputs. We plan to create a very interesting demo by combining \u003ca href=\"https://github.com/IDEA-Research/GroundingDINO\"\u003eGrounding DINO\u003c/a\u003e and \u003ca href=\"https://github.com/facebookresearch/segment-anything\"\u003eSegment Anything\u003c/a\u003e which aims to detect and segment Anything with text inputs!\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Laughing-q/yolov5-q\"\u003eLaughing-q/yolov5-q\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7152dcf3d7f3dc6ec308d1cc6441248634db62a1695ce2bd2af0e043033b0899/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c61756768696e672d712f796f6c6f76352d713f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7152dcf3d7f3dc6ec308d1cc6441248634db62a1695ce2bd2af0e043033b0899/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c61756768696e672d712f796f6c6f76352d713f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Laughing-q/yolov5-q?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repo is plan for instance segmentation based on yolov5-6.0 and yolact.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TomMao23/multiyolov5\"\u003eTomMao23/multiyolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/830e87a96d9638b31369440988efaed266e83ef08ae0f9595d89e2d292d5967d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f546f6d4d616f32332f6d756c7469796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/830e87a96d9638b31369440988efaed266e83ef08ae0f9595d89e2d292d5967d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f546f6d4d616f32332f6d756c7469796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TomMao23/multiyolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Multi YOLO V5â€”â€”Detection and Semantic Segmentation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ArtyZe/yolo_segmentation\"\u003eArtyZe/yolo_segmentation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/be357a9a771a1ef145ef780243f076b7e0c20d52c5f826d850b3bbb3fcc72648/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f417274795a652f796f6c6f5f7365676d656e746174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/be357a9a771a1ef145ef780243f076b7e0c20d52c5f826d850b3bbb3fcc72648/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f417274795a652f796f6c6f5f7365676d656e746174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ArtyZe/yolo_segmentation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : image (semantic segmentation) instance segmentation by darknet or yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/midasklr/yolov5ds\"\u003emidasklr/yolov5ds\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2b968f05e1ed8c5793fb87c3cde8af8d72fa60617703e6e1e2008dfc82119c14/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696461736b6c722f796f6c6f763564733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2b968f05e1ed8c5793fb87c3cde8af8d72fa60617703e6e1e2008dfc82119c14/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696461736b6c722f796f6c6f763564733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/midasklr/yolov5ds?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : multi-task yolov5 with detection and segmentation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RizwanMunawar/yolov7-segmentation\"\u003eRizwanMunawar/yolov7-segmentation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/71369aff60351deee25a900ac1ae7973a432ac0031faafe731f0e5b7db3f28b4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d7365676d656e746174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/71369aff60351deee25a900ac1ae7973a432ac0031faafe731f0e5b7db3f28b4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d7365676d656e746174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RizwanMunawar/yolov7-segmentation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv7 Instance Segmentation using OpenCV and PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/leandro-svg/Yolov7_Segmentation_Tensorrt\"\u003eleandro-svg/Yolov7_Segmentation_Tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/edb17dbd904dda379f84e43da090ffdac40eb9d2c6d93868026791b982653480/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c65616e64726f2d7376672f596f6c6f76375f5365676d656e746174696f6e5f54656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/edb17dbd904dda379f84e43da090ffdac40eb9d2c6d93868026791b982653480/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c65616e64726f2d7376672f596f6c6f76375f5365676d656e746174696f6e5f54656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/leandro-svg/Yolov7_Segmentation_Tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The real-time Instance Segmentation Algorithm Yolov7 running on TensoRT and ONNX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/akashAD98/YOLOV8_SAM\"\u003eakashAD98/YOLOV8_SAM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3e431c9fcef5989feedf5872782e2c0155d6c5ce08162fb01c2cd9686b69338e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616b617368414439382f594f4c4f56385f53414d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3e431c9fcef5989feedf5872782e2c0155d6c5ce08162fb01c2cd9686b69338e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616b617368414439382f594f4c4f56385f53414d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/akashAD98/YOLOV8_SAM?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Use yolov8 \u0026amp; SAM model to get segmention for custom model.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e3D Object Detection\u003c/h3\u003e\u003ca id=\"user-content-3d-object-detection\" class=\"anchor\" aria-label=\"Permalink: 3D Object Detection\" href=\"#3d-object-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eä¸‰ç»´ç›®æ ‡æ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-ä¸‰ç»´ç›®æ ‡æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: ä¸‰ç»´ç›®æ ‡æ£€æµ‹\" href=\"#ä¸‰ç»´ç›®æ ‡æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ADLab-AutoDrive/BEVFusion\"\u003eADLab-AutoDrive/BEVFusion\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4f0facc8e862e6934dd4b26eccc46c632fe40779d334bf4c9a7c9633b89baa05/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41444c61622d4175746f44726976652f424556467573696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4f0facc8e862e6934dd4b26eccc46c632fe40779d334bf4c9a7c9633b89baa05/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41444c61622d4175746f44726976652f424556467573696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ADLab-AutoDrive/BEVFusion?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"BEVFusion: A Simple and Robust LiDAR-Camera Fusion Framework\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2205.13790\" rel=\"nofollow\"\u003eNeurIPS 2022\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mit-han-lab/bevfusion\"\u003emit-han-lab/bevfusion\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4ecb9355993b34f1c7c4d5c4ef89a339c77f00158f1e82c48eb65a207a00ebe0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69742d68616e2d6c61622f626576667573696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4ecb9355993b34f1c7c4d5c4ef89a339c77f00158f1e82c48eb65a207a00ebe0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69742d68616e2d6c61622f626576667573696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mit-han-lab/bevfusion?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird's-Eye View Representation\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2205.13542\" rel=\"nofollow\"\u003eICRA 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DYZhang09/SAM3D\"\u003eSAM3D\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d134f81b80fe55343cee290353aa2a7fdc669531e096c9070ddbf40711cd0323/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44595a68616e6730392f53414d33443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d134f81b80fe55343cee290353aa2a7fdc669531e096c9070ddbf40711cd0323/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44595a68616e6730392f53414d33443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DYZhang09/SAM3D?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"SAM3D: Zero-Shot 3D Object Detection via \u003ca href=\"https://github.com/facebookresearch/segment-anything\"\u003eSegment Anything\u003c/a\u003e Model\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2306.02245\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/maudzung/YOLO3D-YOLOv4-PyTorch\"\u003emaudzung/YOLO3D-YOLOv4-PyTorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b55d59b598e1346a1e42417d4ec33526784aa0277164afbb7c4fe0be3dae223c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6175647a756e672f594f4c4f33442d594f4c4f76342d5079546f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b55d59b598e1346a1e42417d4ec33526784aa0277164afbb7c4fe0be3dae223c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6175647a756e672f594f4c4f33442d594f4c4f76342d5079546f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/maudzung/YOLO3D-YOLOv4-PyTorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The PyTorch Implementation based on YOLOv4 of the paper: \"YOLO3D: End-to-end real-time 3D Oriented Object Bounding Box Detection from LiDAR Point Cloud\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_eccv_2018_workshops/w18/html/Ali_YOLO3D_End-to-end_real-time_3D_Oriented_Object_Bounding_Box_Detection_from_ECCVW_2018_paper.html\" rel=\"nofollow\"\u003eECCV 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/maudzung/Complex-YOLOv4-Pytorch\"\u003emaudzung/Complex-YOLOv4-Pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0367af3f9db012be0ff10c588e535bdb35e2dae11ce4244023bc7603cef32c6f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6175647a756e672f436f6d706c65782d594f4c4f76342d5079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0367af3f9db012be0ff10c588e535bdb35e2dae11ce4244023bc7603cef32c6f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6175647a756e672f436f6d706c65782d594f4c4f76342d5079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/maudzung/Complex-YOLOv4-Pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The PyTorch Implementation based on YOLOv4 of the paper: \"Complex-YOLO: Real-time 3D Object Detection on Point Clouds\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1803.06199\" rel=\"nofollow\"\u003earXiv 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AI-liu/Complex-YOLO\"\u003eAI-liu/Complex-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bf5f504a4eb84723010be1cc872585dbce791942f67e308b28333dc8f3dca662/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41492d6c69752f436f6d706c65782d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bf5f504a4eb84723010be1cc872585dbce791942f67e308b28333dc8f3dca662/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41492d6c69752f436f6d706c65782d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AI-liu/Complex-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is an unofficial implementation of \"Complex-YOLO: Real-time 3D Object Detection on Point Clouds in pytorch\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1803.06199\" rel=\"nofollow\"\u003earXiv 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ghimiredhikura/Complex-YOLOv3\"\u003eghimiredhikura/Complex-YOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fd7ef8509c09b1b14c9ad5f709dc970afea821ae593088d7b0f9b11b550242cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6768696d6972656468696b7572612f436f6d706c65782d594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fd7ef8509c09b1b14c9ad5f709dc970afea821ae593088d7b0f9b11b550242cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6768696d6972656468696b7572612f436f6d706c65782d594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ghimiredhikura/Complex-YOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Complete but Unofficial PyTorch Implementation of \"Complex-YOLO: Real-time 3D Object Detection on Point Clouds with YoloV3\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1803.06199\" rel=\"nofollow\"\u003earXiv 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ruhyadi/YOLO3D\"\u003eruhyadi/YOLO3D\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6c8234eb7af33de41de806cffa55f847978cb8f8fd1eac9dd3c47ecfd4198739/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f727568796164692f594f4c4f33443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6c8234eb7af33de41de806cffa55f847978cb8f8fd1eac9dd3c47ecfd4198739/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f727568796164692f594f4c4f33443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ruhyadi/YOLO3D?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO 3D Object Detection for Autonomous Driving Vehicle. Reference by \u003ca href=\"https://github.com/skhadem/3D-BoundingBox\"\u003eskhadem/3D-BoundingBox\u003c/a\u003e, \"3D Bounding Box Estimation Using Deep Learning and Geometry\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_cvpr_2017/html/Mousavian_3D_Bounding_Box_CVPR_2017_paper.html\" rel=\"nofollow\"\u003eCVPR 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ruhyadi/yolo3d-lightning\"\u003eruhyadi/yolo3d-lightning\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6c8234eb7af33de41de806cffa55f847978cb8f8fd1eac9dd3c47ecfd4198739/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f727568796164692f594f4c4f33443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6c8234eb7af33de41de806cffa55f847978cb8f8fd1eac9dd3c47ecfd4198739/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f727568796164692f594f4c4f33443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ruhyadi/YOLO3D?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO for 3D Object Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Yuanchu/YOLO3D\"\u003eYuanchu/YOLO3D\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a025024ff0a9d1dc69c8adbdaf1ef5a430bc1a88ad7c9daffb77c25a09eb47f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5975616e6368752f594f4c4f33443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a025024ff0a9d1dc69c8adbdaf1ef5a430bc1a88ad7c9daffb77c25a09eb47f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5975616e6368752f594f4c4f33443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Yuanchu/YOLO3D?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Implementation of a basic YOLO model for object detection in 3D.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/EmiyaNing/3D-YOLO\"\u003eEmiyaNing/3D-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/83960daa29d8ae0ec81f2f111e4c3ed6ab3d70f6812d2ddffce291225a864867/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f456d6979614e696e672f33442d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/83960daa29d8ae0ec81f2f111e4c3ed6ab3d70f6812d2ddffce291225a864867/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f456d6979614e696e672f33442d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/EmiyaNing/3D-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO v5 for Lidar-based 3D BEV Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSLAM Field Detection\u003c/h3\u003e\u003ca id=\"user-content-slam-field-detection\" class=\"anchor\" aria-label=\"Permalink: SLAM Field Detection\" href=\"#slam-field-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSLAMé¢†åŸŸæ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-slamé¢†åŸŸæ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: SLAMé¢†åŸŸæ£€æµ‹\" href=\"#slamé¢†åŸŸæ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bijustin/YOLO-DynaSLAM\"\u003ebijustin/YOLO-DynaSLAM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fef880c17702d2e5c090183099c2bcb6e10472f6ce8a445b83c00276b99bea58/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62696a757374696e2f594f4c4f2d44796e61534c414d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fef880c17702d2e5c090183099c2bcb6e10472f6ce8a445b83c00276b99bea58/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62696a757374696e2f594f4c4f2d44796e61534c414d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bijustin/YOLO-DynaSLAM?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO Dynamic ORB_SLAM is a visual SLAM system that is robust in dynamic scenarios for RGB-D configuration.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BzdTaisa/YoloPlanarSLAM\"\u003eBzdTaisa/YoloPlanarSLAM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/35574c7fc2d732c8ed1919e3e65241a48e971ac52bb920573079d0497ba47ed6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427a6454616973612f596f6c6f506c616e6172534c414d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/35574c7fc2d732c8ed1919e3e65241a48e971ac52bb920573079d0497ba47ed6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427a6454616973612f596f6c6f506c616e6172534c414d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BzdTaisa/YoloPlanarSLAM?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO-Planar-SLAM.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/saransapmaz/cv-slam-object-determination\"\u003esaransapmaz/cv-slam-object-determination\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c9b683e6262df15b55150fb6f84dcb712bf8ed67ace610be643bf9b7dff6f14d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736172616e7361706d617a2f63762d736c616d2d6f626a6563742d64657465726d696e6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c9b683e6262df15b55150fb6f84dcb712bf8ed67ace610be643bf9b7dff6f14d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736172616e7361706d617a2f63762d736c616d2d6f626a6563742d64657465726d696e6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/saransapmaz/cv-slam-object-determination?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object detection with hector slam and YOLO v3 computer vision algorithm.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eIndustrial Defect Detection\u003c/h3\u003e\u003ca id=\"user-content-industrial-defect-detection\" class=\"anchor\" aria-label=\"Permalink: Industrial Defect Detection\" href=\"#industrial-defect-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eå·¥ä¸šç¼ºé™·æ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-å·¥ä¸šç¼ºé™·æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: å·¥ä¸šç¼ºé™·æ£€æµ‹\" href=\"#å·¥ä¸šç¼ºé™·æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/annsonic/Steel_defect\"\u003eannsonic/Steel_defect\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5db29d69c135d3872bcb125f4f92a51ab767e75df0296f17861101630d4e02a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616e6e736f6e69632f537465656c5f6465666563743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5db29d69c135d3872bcb125f4f92a51ab767e75df0296f17861101630d4e02a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616e6e736f6e69632f537465656c5f6465666563743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/annsonic/Steel_defect?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Exercise: Use YOLO to detect hot-rolled steel strip surface defects (NEU-DET dataset).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/VanillaHours/pcbDefectDetectionYOLO\"\u003eVanillaHours/pcbDefectDetectionYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0aa3c7f87fcac4b519c6ffd5c773bab0b5ebbbb2b81efbe537368dee3e625cdf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f56616e696c6c61486f7572732f706362446566656374446574656374696f6e594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0aa3c7f87fcac4b519c6ffd5c773bab0b5ebbbb2b81efbe537368dee3e625cdf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f56616e696c6c61486f7572732f706362446566656374446574656374696f6e594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/VanillaHours/pcbDefectDetectionYOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PCB defect detection using YOLOv3, on DeepPCB dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/talisma-cassoma/pcb-components-detection-recognition\"\u003etalisma-cassoma/pcb-components-detection-recognition\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/50184ae7044e67026044e4cf40acd96afca74e0e40c13851112a2c2d797fe71f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616c69736d612d636173736f6d612f7063622d636f6d706f6e656e74732d646574656374696f6e2d7265636f676e6974696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/50184ae7044e67026044e4cf40acd96afca74e0e40c13851112a2c2d797fe71f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616c69736d612d636173736f6d612f7063622d636f6d706f6e656e74732d646574656374696f6e2d7265636f676e6974696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/talisma-cassoma/pcb-components-detection-recognition?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : this code shows the train and test of a YOLOV5 convolutional neural network for detection of electronics components.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Luckycat518/Yolo-MSAPF\"\u003eLuckycat518/Yolo-MSAPF\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4debe7dc2469da7fc091f76c3fa0e6d17585c297799591e8cdb8fc24e18492f1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c75636b796361743531382f596f6c6f2d4d534150463f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4debe7dc2469da7fc091f76c3fa0e6d17585c297799591e8cdb8fc24e18492f1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c75636b796361743531382f596f6c6f2d4d534150463f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Luckycat518/Yolo-MSAPF?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo-MSAPF: Multi-Scale Alignment fusion with Parallel feature Filtering model for high accuracy weld defect detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/JiaLim98/YOLO-PCB\"\u003eJiaLim98/YOLO-PCB\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a987163daa51a9e05787d1a1daea5c1d3c9d3cf40aa5ce43ffe94e0ab5dd4b09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a69614c696d39382f594f4c4f2d5043423f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a987163daa51a9e05787d1a1daea5c1d3c9d3cf40aa5ce43ffe94e0ab5dd4b09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a69614c696d39382f594f4c4f2d5043423f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/JiaLim98/YOLO-PCB?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Deep Context Learning based PCB Defect Detection Model with Anomalous Trend Alarming System.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSAR Image Detection\u003c/h3\u003e\u003ca id=\"user-content-sar-image-detection\" class=\"anchor\" aria-label=\"Permalink: SAR Image Detection\" href=\"#sar-image-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eåˆæˆå­”å¾„é›·è¾¾å›¾åƒæ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-åˆæˆå­”å¾„é›·è¾¾å›¾åƒæ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: åˆæˆå­”å¾„é›·è¾¾å›¾åƒæ£€æµ‹\" href=\"#åˆæˆå­”å¾„é›·è¾¾å›¾åƒæ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/humblecoder612/SAR_yolov3\"\u003ehumblecoder612/SAR_yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/39a47bc1cb3f0ec40cc1d2606ac82d9739863cbcdb13989fa8092c1d0f19900e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756d626c65636f6465723631322f5341525f796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/39a47bc1cb3f0ec40cc1d2606ac82d9739863cbcdb13989fa8092c1d0f19900e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756d626c65636f6465723631322f5341525f796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/humblecoder612/SAR_yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Best Accruacy:speed ratio SAR Ship detection in the world.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSafety Monitoring Field Detection\u003c/h3\u003e\u003ca id=\"user-content-safety-monitoring-field-detection\" class=\"anchor\" aria-label=\"Permalink: Safety Monitoring Field Detection\" href=\"#safety-monitoring-field-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eå®‰é˜²ç›‘æŽ§é¢†åŸŸæ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-å®‰é˜²ç›‘æŽ§é¢†åŸŸæ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: å®‰é˜²ç›‘æŽ§é¢†åŸŸæ£€æµ‹\" href=\"#å®‰é˜²ç›‘æŽ§é¢†åŸŸæ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/gengyanlei/fire-smoke-detect-yolov4\"\u003egengyanlei/fire-smoke-detect-yolov4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/899d5c2fe809fca1d281c5934cd3deb555cf5d183cf95836c0058a06d6854d72/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67656e6779616e6c65692f666972652d736d6f6b652d6465746563742d796f6c6f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/899d5c2fe809fca1d281c5934cd3deb555cf5d183cf95836c0058a06d6854d72/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67656e6779616e6c65692f666972652d736d6f6b652d6465746563742d796f6c6f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/gengyanlei/fire-smoke-detect-yolov4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : fire-smoke-detect-yolov4-yolov5 and fire-smoke-detection-dataset ç«ç¾æ£€æµ‹ï¼ŒçƒŸé›¾æ£€æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CVUsers/Smoke-Detect-by-YoloV5\"\u003eCVUsers/Smoke-Detect-by-YoloV5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7ac573df71b6e351ec158d7d1650b292f0fc1a1c6200cddc4dc1f3c22f5f5715/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f435655736572732f536d6f6b652d4465746563742d62792d596f6c6f56353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7ac573df71b6e351ec158d7d1650b292f0fc1a1c6200cddc4dc1f3c22f5f5715/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f435655736572732f536d6f6b652d4465746563742d62792d596f6c6f56353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CVUsers/Smoke-Detect-by-YoloV5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov5 real time smoke detection system.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CVUsers/Fire-Detect-by-YoloV5\"\u003eCVUsers/Fire-Detect-by-YoloV5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7094c49a8b61997426da07128ce42e25b100bb6b2594e11ed81a654a66e556a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f435655736572732f466972652d4465746563742d62792d596f6c6f56353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7094c49a8b61997426da07128ce42e25b100bb6b2594e11ed81a654a66e556a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f435655736572732f466972652d4465746563742d62792d596f6c6f56353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CVUsers/Fire-Detect-by-YoloV5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ç«ç¾æ£€æµ‹ï¼Œæµ“çƒŸæ£€æµ‹ï¼Œå¸çƒŸæ£€æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/spacewalk01/Yolov5-Fire-Detection\"\u003espacewalk01/Yolov5-Fire-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/52a3adbb86a0e44b6a9af9dd5c79f43e64869bd42dc937560032c6e07f3e56a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737061636577616c6b30312f596f6c6f76352d466972652d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/52a3adbb86a0e44b6a9af9dd5c79f43e64869bd42dc937560032c6e07f3e56a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737061636577616c6b30312f596f6c6f76352d466972652d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/spacewalk01/Yolov5-Fire-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Train yolov5 to detect fire in an image or video.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/roflcoopter/viseron\"\u003eroflcoopter/viseron\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d81b59d13d5bb2f0f3f020b60dc4faadaa8f0ecad7eda04e793dea4cb61664d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f666c636f6f707465722f76697365726f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d81b59d13d5bb2f0f3f020b60dc4faadaa8f0ecad7eda04e793dea4cb61664d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f666c636f6f707465722f76697365726f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/roflcoopter/viseron?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Viseron - Self-hosted NVR with object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dcmartin/motion-ai\"\u003edcmartin/motion-ai\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8dac5c471352afe3938d28a18d65afdfacf2f850b40a690f0d0b2e65f6c3f1a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64636d617274696e2f6d6f74696f6e2d61693f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8dac5c471352afe3938d28a18d65afdfacf2f850b40a690f0d0b2e65f6c3f1a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64636d617274696e2f6d6f74696f6e2d61693f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dcmartin/motion-ai?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : AI assisted motion detection for Home Assistant.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Nico31415/Drowning-Detector\"\u003eNico31415/Drowning-Detector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6a462073a1f2d6f8d0d2162e8438f3f66aeb1e59cc84c4764ab645b802df6ffb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e69636f33313431352f44726f776e696e672d4465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6a462073a1f2d6f8d0d2162e8438f3f66aeb1e59cc84c4764ab645b802df6ffb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e69636f33313431352f44726f776e696e672d4465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Nico31415/Drowning-Detector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Using YOLO object detection, this program will detect if a person is drowning.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mc-cat-tty/DoorbellCamDaemon\"\u003emc-cat-tty/DoorbellCamDaemon\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4a8fbb6b2fad0019328402a32a1fcae7b9e554f5a550df9610a7e33dac18e394/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d632d6361742d7474792f446f6f7262656c6c43616d4461656d6f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4a8fbb6b2fad0019328402a32a1fcae7b9e554f5a550df9610a7e33dac18e394/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d632d6361742d7474792f446f6f7262656c6c43616d4461656d6f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mc-cat-tty/DoorbellCamDaemon?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Part of DoorbellCam project: daemon for people recognition with YOLO from a RTSP video stream.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Choe-Ji-Hwan/Fire_Detect_Custom_Yolov5\"\u003eChoe-Ji-Hwan/Fire_Detect_Custom_Yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/76aa04024071ae275d3cce45a51489bbce23e7071b22c63ab97116d34461b81c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43686f652d4a692d4877616e2f466972655f4465746563745f437573746f6d5f596f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/76aa04024071ae275d3cce45a51489bbce23e7071b22c63ab97116d34461b81c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43686f652d4a692d4877616e2f466972655f4465746563745f437573746f6d5f596f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Choe-Ji-Hwan/Fire_Detect_Custom_Yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 2022-1 Individual Research Assignment: Using YOLOv5 to simply recognize each type of fire.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bishal116/FireDetection\"\u003ebishal116/FireDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a984cd0f8ab1b9d763280e37017003368b367fd1a9580fba8bfa2054a4b0cb8a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62697368616c3131362f46697265446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a984cd0f8ab1b9d763280e37017003368b367fd1a9580fba8bfa2054a4b0cb8a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62697368616c3131362f46697265446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bishal116/FireDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This project builds fire detecton using YOLO v3 model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Psynosaur/Jetson-SecVision\"\u003ePsynosaur/Jetson-SecVision\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f44949899f3e3571614b5724473c096afd9e6fc9c28307e250539e53cd22a7cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5073796e6f736175722f4a6574736f6e2d536563566973696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f44949899f3e3571614b5724473c096afd9e6fc9c28307e250539e53cd22a7cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5073796e6f736175722f4a6574736f6e2d536563566973696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Psynosaur/Jetson-SecVision?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Person detection for Hikvision DVR with AlarmIO ports, uses TensorRT and yolov4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/robmarkcole/fire-detection-from-images\"\u003erobmarkcole/fire-detection-from-images\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3e4f510173eef696c61cc6fa1b75b2baf65613ba3bc127831579acb7ee91d8d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626d61726b636f6c652f666972652d646574656374696f6e2d66726f6d2d696d616765733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3e4f510173eef696c61cc6fa1b75b2baf65613ba3bc127831579acb7ee91d8d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626d61726b636f6c652f666972652d646574656374696f6e2d66726f6d2d696d616765733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/robmarkcole/fire-detection-from-images?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detect fire in images using neural nets.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/gaiasd/DFireDataset\"\u003egaiasd/DFireDataset\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9079f6548233b8e2e3823ed86ac3e39e2c25ef0323ab0ad25854f41bfcd6cbc3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6761696173642f4446697265446174617365743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9079f6548233b8e2e3823ed86ac3e39e2c25ef0323ab0ad25854f41bfcd6cbc3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6761696173642f4446697265446174617365743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/gaiasd/DFireDataset?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : D-Fire: an image data set for fire and smoke detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MuhammadMoinFaisal/FireDetectionYOLOv8\"\u003eMuhammadMoinFaisal/FireDetectionYOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/50c2ef96c8d2020de79868a7c40881474267901e0a7c1e7af4d7d722a6f0f24d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d7568616d6d61644d6f696e46616973616c2f46697265446574656374696f6e594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/50c2ef96c8d2020de79868a7c40881474267901e0a7c1e7af4d7d722a6f0f24d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d7568616d6d61644d6f696e46616973616c2f46697265446574656374696f6e594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MuhammadMoinFaisal/FireDetectionYOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Fire Detection using YOLOv8.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AI-Expert-04/School_Zone_Eye_Level\"\u003eAI-Expert-04/School_Zone_Eye_Level\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0cde8bf1a1db29c6a82fc82a37b0245d06784ecea2c57be804b5485b4449bade/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41492d4578706572742d30342f5363686f6f6c5f5a6f6e655f4579655f4c6576656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0cde8bf1a1db29c6a82fc82a37b0245d06784ecea2c57be804b5485b4449bade/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41492d4578706572742d30342f5363686f6f6c5f5a6f6e655f4579655f4c6576656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AI-Expert-04/School_Zone_Eye_Level?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Prevention of accidents in school zones using deep learning.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/roboflow/supervision\"\u003eroboflow/supervision\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1b39f8841d1d11b310e911a38b018c9079106a311e56bd8419e0df2defde48f0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626f666c6f772f7375706572766973696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1b39f8841d1d11b310e911a38b018c9079106a311e56bd8419e0df2defde48f0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626f666c6f772f7375706572766973696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/roboflow/supervision?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : We write your reusable computer vision tools. ðŸ’œ \u003ca href=\"https://roboflow.github.io/supervision/\" rel=\"nofollow\"\u003eroboflow.github.io/supervision\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AntroSafin/Fire_Detection_YoloV5\"\u003eAntroSafin/Fire_Detection_YoloV5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/905bfc55ffe4805cd9b0611be38749c26bbb0c3bab626cbfa323381cc1620d4b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e74726f536166696e2f466972655f446574656374696f6e5f596f6c6f56353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/905bfc55ffe4805cd9b0611be38749c26bbb0c3bab626cbfa323381cc1620d4b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e74726f536166696e2f466972655f446574656374696f6e5f596f6c6f56353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AntroSafin/Fire_Detection_YoloV5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is the YoloV5 fire detection application.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/harivams-sai/FireDetectionYOLOv8\"\u003eharivams-sai/FireDetectionYOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b66143e699330776d8178cd239e99e438e30537bdeaaea02f9534d567d7985a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6861726976616d732d7361692f46697265446574656374696f6e594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b66143e699330776d8178cd239e99e438e30537bdeaaea02f9534d567d7985a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6861726976616d732d7361692f46697265446574656374696f6e594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/harivams-sai/FireDetectionYOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A fire detection model based on YOLOv8 Ultralytics model for object detection. Tech: Python, Computer Vision, Colab Notebook, Fire-detection, YOLOv8.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/e-candeloro/SAURUSS-Autonomous-Drone-Surveillance\"\u003ee-candeloro/SAURUSS-Autonomous-Drone-Surveillance\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/32d60b861b65c4cda6b530623189daa88ecb9e31ce41812782a624debe31bb9c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f652d63616e64656c6f726f2f534155525553532d4175746f6e6f6d6f75732d44726f6e652d5375727665696c6c616e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/32d60b861b65c4cda6b530623189daa88ecb9e31ce41812782a624debe31bb9c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f652d63616e64656c6f726f2f534155525553532d4175746f6e6f6d6f75732d44726f6e652d5375727665696c6c616e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/e-candeloro/SAURUSS-Autonomous-Drone-Surveillance?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An autonomous drone and sensor based surveillance system that use a Tello Drone, an Arduino, a Raspberry Pi and an Android smartphone.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pedbrgs/Fire-Detection\"\u003epedbrgs/Fire-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/193bafac51f7e553ab414db2948d1e8bbea6f5ca7f9ecc4e2850f550386411ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706564627267732f466972652d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/193bafac51f7e553ab414db2948d1e8bbea6f5ca7f9ecc4e2850f550386411ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706564627267732f466972652d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pedbrgs/Fire-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Fire and smoke detection using spatial and temporal patterns.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAnti-UAV Field Detection\u003c/h3\u003e\u003ca id=\"user-content-anti-uav-field-detection\" class=\"anchor\" aria-label=\"Permalink: Anti-UAV Field Detection\" href=\"#anti-uav-field-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eåæ— äººæœºé¢†åŸŸæ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-åæ— äººæœºé¢†åŸŸæ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: åæ— äººæœºé¢†åŸŸæ£€æµ‹\" href=\"#åæ— äººæœºé¢†åŸŸæ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZhaoJ9014/Anti-UAV\"\u003eAnti-UAV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f4011264d69ecf9a1839ac7bce6be873eeab7abb74913794ffcf866e7f9c5a36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68616f4a393031342f416e74692d5541563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f4011264d69ecf9a1839ac7bce6be873eeab7abb74913794ffcf866e7f9c5a36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68616f4a393031342f416e74692d5541563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZhaoJ9014/Anti-UAV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ”¥ðŸ”¥Official Repository for Anti-UAVðŸ”¥ðŸ”¥. Anti-UAV300, Anti-UAV410, Anti-UAV600. Please refer to our \u003ca href=\"https://ieeexplore.ieee.org/document/9615243\" rel=\"nofollow\"\u003eAnti-UAV v1\u003c/a\u003e paper and \u003ca href=\"https://arxiv.org/pdf/2306.15767.pdf\" rel=\"nofollow\"\u003eAnti-UAV v3\u003c/a\u003e paper for more details (\u003ca href=\"https://zhaoj9014.github.io/pub/Anti-UAV.pdf\" rel=\"nofollow\"\u003eWeChat News\u003c/a\u003e). \"Anti-UAV: A Large-Scale Benchmark for Vision-Based UAV Tracking\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/document/9615243\" rel=\"nofollow\"\u003eIEEE Transactions on Multimedia, 2022\u003c/a\u003e\u003c/strong\u003e). \"Evidential Detection and Tracking Collaboration: New Problem, Benchmark and Algorithm for Robust Anti-UAV System\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2306.15767\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wangdongdut/DUT-Anti-UAV\"\u003eDUT-Anti-UAV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6d1b7e1210c59ca143ac28ef22b2f92f54acc49ff085b6fab12c5d5385d3dbdc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e67646f6e676475742f4455542d416e74692d5541563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6d1b7e1210c59ca143ac28ef22b2f92f54acc49ff085b6fab12c5d5385d3dbdc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e67646f6e676475742f4455542d416e74692d5541563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wangdongdut/DUT-Anti-UAV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : DUT Anti-UAV Detection and Tracking. \"Vision-based Anti-UAV Detection and Tracking\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2205.10851\" rel=\"nofollow\"\u003eIEEE Transactions on Intelligent Transportation Systems, 2022\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eMedical Field Detection\u003c/h3\u003e\u003ca id=\"user-content-medical-field-detection\" class=\"anchor\" aria-label=\"Permalink: Medical Field Detection\" href=\"#medical-field-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eåŒ»å­¦é¢†åŸŸæ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-åŒ»å­¦é¢†åŸŸæ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: åŒ»å­¦é¢†åŸŸæ£€æµ‹\" href=\"#åŒ»å­¦é¢†åŸŸæ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DataXujing/YOLO-v5\"\u003eDataXujing/YOLO-v5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1af840add24fd1789925f735e6ae328ef1686c368b928e167f15d302b9434a81/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f2d76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1af840add24fd1789925f735e6ae328ef1686c368b928e167f15d302b9434a81/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f2d76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DataXujing/YOLO-v5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO v5åœ¨åŒ»ç–—é¢†åŸŸä¸­æ¶ˆåŒ–å†…é•œç›®æ ‡æ£€æµ‹çš„åº”ç”¨ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Jafar-Abdollahi/Automated-detection-of-COVID-19-cases-using-deep-neural-networks-with-CTS-images\"\u003eJafar-Abdollahi/Automated-detection-of-COVID-19-cases-using-deep-neural-networks-with-CTS-images\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/78ead0d275ad05b47814a1dbd4e56c9e601d198fcf89b5b726074c23a01ec69f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a616661722d4162646f6c6c6168692f4175746f6d617465642d646574656374696f6e2d6f662d434f5649442d31392d63617365732d7573696e672d646565702d6e657572616c2d6e6574776f726b732d776974682d4354532d696d616765733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/78ead0d275ad05b47814a1dbd4e56c9e601d198fcf89b5b726074c23a01ec69f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a616661722d4162646f6c6c6168692f4175746f6d617465642d646574656374696f6e2d6f662d434f5649442d31392d63617365732d7573696e672d646565702d6e657572616c2d6e6574776f726b732d776974682d4354532d696d616765733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Jafar-Abdollahi/Automated-detection-of-COVID-19-cases-using-deep-neural-networks-with-CTS-images?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : In this project, a new model for automatic detection of covid-19 using raw chest X-ray images is presented.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fahriwps/breast-cancer-detection\"\u003efahriwps/breast-cancer-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7b746d706f6d92dc15d621b5545d68402c4a098252171a08520fdefa3681c18e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66616872697770732f6272656173742d63616e6365722d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7b746d706f6d92dc15d621b5545d68402c4a098252171a08520fdefa3681c18e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66616872697770732f6272656173742d63616e6365722d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/fahriwps/breast-cancer-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Breast cancer mass detection using YOLO object detection algorithm and GUI.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/niehusst/YOLO-Cancer-Detection\"\u003eniehusst/YOLO-Cancer-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0f30940184b5c0f933bf47bf6191c946102e24dc200f73012ee6df9dd6701f41/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e696568757373742f594f4c4f2d43616e6365722d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0f30940184b5c0f933bf47bf6191c946102e24dc200f73012ee6df9dd6701f41/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e696568757373742f594f4c4f2d43616e6365722d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/niehusst/YOLO-Cancer-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An implementation of the YOLO algorithm trained to spot tumors in DICOM images.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/safakgunes/Blood-Cancer-Detection-YOLOV5\"\u003esafakgunes/Blood-Cancer-Detection-YOLOV5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fc8d4f88eff3e21ef495e2b7f1a1c9656e4a9931bb49ec91638d5591e99ae39d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736166616b67756e65732f426c6f6f642d43616e6365722d446574656374696f6e2d594f4c4f56353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fc8d4f88eff3e21ef495e2b7f1a1c9656e4a9931bb49ec91638d5591e99ae39d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736166616b67756e65732f426c6f6f642d43616e6365722d446574656374696f6e2d594f4c4f56353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/safakgunes/Blood-Cancer-Detection-YOLOV5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Blood Cancer Detection with YOLOV5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/shchiang0708/YOLOv2_skinCancer\"\u003eshchiang0708/YOLOv2_skinCancer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9bb8845c5f87f30f14a1a547be561e1fc3fd9bfeb30f3b7ef05c7aad54d6e608/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7368636869616e67303730382f594f4c4f76325f736b696e43616e6365723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9bb8845c5f87f30f14a1a547be561e1fc3fd9bfeb30f3b7ef05c7aad54d6e608/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7368636869616e67303730382f594f4c4f76325f736b696e43616e6365723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/shchiang0708/YOLOv2_skinCancer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv2_skinCancer.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/avral1810/parkinsongait\"\u003eavral1810/parkinsongait\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e68f1b36d288985d59e25cf5c8898c639da32a396469433ab2b9f15a27c66e81/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f617672616c313831302f7061726b696e736f6e676169743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e68f1b36d288985d59e25cf5c8898c639da32a396469433ab2b9f15a27c66e81/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f617672616c313831302f7061726b696e736f6e676169743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/avral1810/parkinsongait?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Parkinsonâ€™s Disease.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sierprinsky/YoloV5_blood_cells\"\u003esierprinsky/YoloV5_blood_cells\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4c4db31ab25351234bed488e6aa327763248240df649cf8900ad6223eca1e8fc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736965727072696e736b792f596f6c6f56355f626c6f6f645f63656c6c733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4c4db31ab25351234bed488e6aa327763248240df649cf8900ad6223eca1e8fc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736965727072696e736b792f596f6c6f56355f626c6f6f645f63656c6c733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sierprinsky/YoloV5_blood_cells?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The main idea of this project is to detect blood cells using YOLOV5 over a public roboflow dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LuozyCS/skin_disease_detection_yolov5\"\u003eLuozyCS/skin_disease_detection_yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3ffaf730e6f491bd3efb9c6f0618e0f16ab4337cdb36cf3673db70dbd9485b29/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c756f7a7943532f736b696e5f646973656173655f646574656374696f6e5f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3ffaf730e6f491bd3efb9c6f0618e0f16ab4337cdb36cf3673db70dbd9485b29/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c756f7a7943532f736b696e5f646973656173655f646574656374696f6e5f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LuozyCS/skin_disease_detection_yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : skin_disease_detection_yolov5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Moqixis/object_detection_yolov5_deepsort\"\u003eMoqixis/object_detection_yolov5_deepsort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/25a7e252883372e437a721e96e5a1d9d3a0e6d18355d88da96b66a05cd988ce6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f71697869732f6f626a6563745f646574656374696f6e5f796f6c6f76355f64656570736f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/25a7e252883372e437a721e96e5a1d9d3a0e6d18355d88da96b66a05cd988ce6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f71697869732f6f626a6563745f646574656374696f6e5f796f6c6f76355f64656570736f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Moqixis/object_detection_yolov5_deepsort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽyolov5+deepsortçš„æ¯è‚‰ç›®æ ‡æ£€æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mdciri/YOLOv7-Bone-Fracture-Detection\"\u003emdciri/YOLOv7-Bone-Fracture-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f8afc3efb5e16125a6efb129776d9b045bfc3f1b4b46b6e1955701c84541bf42/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d64636972692f594f4c4f76372d426f6e652d46726163747572652d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f8afc3efb5e16125a6efb129776d9b045bfc3f1b4b46b6e1955701c84541bf42/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d64636972692f594f4c4f76372d426f6e652d46726163747572652d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mdciri/YOLOv7-Bone-Fracture-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv7 to detect bone fractures on X-ray images.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MIRACLE-Center/YOLO_Universal_Anatomical_Landmark_Detection\"\u003eMIRACLE-Center/YOLO_Universal_Anatomical_Landmark_Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fd3fcb3fa1b49cfe960d67ced46e04e262ecc2608d347a23c92c797af5f2d471/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d495241434c452d43656e7465722f594f4c4f5f556e6976657273616c5f416e61746f6d6963616c5f4c616e646d61726b5f446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fd3fcb3fa1b49cfe960d67ced46e04e262ecc2608d347a23c92c797af5f2d471/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d495241434c452d43656e7465722f594f4c4f5f556e6976657273616c5f416e61746f6d6963616c5f4c616e646d61726b5f446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MIRACLE-Center/YOLO_Universal_Anatomical_Landmark_Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : [MICCAI 2021] \u003ca href=\"https://arxiv.org/abs/2103.04657\" rel=\"nofollow\"\u003eYou Only Learn Once: Universal Anatomical Landmark Detection\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fahriwps/breast-cancer-detection\"\u003efahriwps/breast-cancer-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7b746d706f6d92dc15d621b5545d68402c4a098252171a08520fdefa3681c18e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66616872697770732f6272656173742d63616e6365722d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7b746d706f6d92dc15d621b5545d68402c4a098252171a08520fdefa3681c18e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66616872697770732f6272656173742d63616e6365722d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/fahriwps/breast-cancer-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Breast cancer mass detection using YOLO object detection algorithm and GUI.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mkang315/CST-YOLO\"\u003emkang315/CST-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f42f204462a050842f2d1186b1abc7d24e3a0f6551068e8efd7899b97cba0b32/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6b616e673331352f4353542d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f42f204462a050842f2d1186b1abc7d24e3a0f6551068e8efd7899b97cba0b32/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6b616e673331352f4353542d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mkang315/CST-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Official implementation of \"CST-YOLO: A Novel Method for Blood Cell Detection Based on Improved YOLOv7 and CNN-Swin Transformer\".\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mkang315/BGF-YOLO\"\u003emkang315/BGF-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/91cfe276745d8f74aa2a5b28176809054af866a6baa9878d8c8b5ce1b70fd367/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6b616e673331352f4247462d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/91cfe276745d8f74aa2a5b28176809054af866a6baa9878d8c8b5ce1b70fd367/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6b616e673331352f4247462d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mkang315/BGF-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : [MICCAI'24] Official implementation of \"BGF-YOLO: Enhanced YOLOv8 with Multiscale Attentional Feature Fusion for Brain Tumor Detection\".\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eChemistry Field Detection\u003c/h3\u003e\u003ca id=\"user-content-chemistry-field-detection\" class=\"anchor\" aria-label=\"Permalink: Chemistry Field Detection\" href=\"#chemistry-field-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eåŒ–å­¦é¢†åŸŸæ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-åŒ–å­¦é¢†åŸŸæ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: åŒ–å­¦é¢†åŸŸæ£€æµ‹\" href=\"#åŒ–å­¦é¢†åŸŸæ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/xuguodong1999/COCR\"\u003exuguodong1999/COCR\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/491dd0efc3f1ff4ad88b9becc472f3b05945e2854f18c33480ad9c54af22449e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f787567756f646f6e67313939392f434f43523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/491dd0efc3f1ff4ad88b9becc472f3b05945e2854f18c33480ad9c54af22449e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f787567756f646f6e67313939392f434f43523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xuguodong1999/COCR?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : COCR is designed to convert an image of hand-writing chemical structure to graph of that molecule.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAgricultural Field Detection\u003c/h3\u003e\u003ca id=\"user-content-agricultural-field-detection\" class=\"anchor\" aria-label=\"Permalink: Agricultural Field Detection\" href=\"#agricultural-field-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eå†œä¸šé¢†åŸŸæ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-å†œä¸šé¢†åŸŸæ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: å†œä¸šé¢†åŸŸæ£€æµ‹\" href=\"#å†œä¸šé¢†åŸŸæ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/liao1fan/MGA-YOLO-for-apple-leaf-disease-detection\"\u003eliao1fan/MGA-YOLO-for-apple-leaf-disease-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1e6d1cedbe4679ffa1d32c5ae522f3807830b99f587dd68e7b847ab745e60c80/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c69616f3166616e2f4d47412d594f4c4f2d666f722d6170706c652d6c6561662d646973656173652d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1e6d1cedbe4679ffa1d32c5ae522f3807830b99f587dd68e7b847ab745e60c80/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c69616f3166616e2f4d47412d594f4c4f2d666f722d6170706c652d6c6561662d646973656173652d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/liao1fan/MGA-YOLO-for-apple-leaf-disease-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : MGA-YOLO: A Lightweight One-Stage Network for Apple Leaf Disease Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tanmaypandey7/wheat-detection\"\u003etanmaypandey7/wheat-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fc06bc91700bb79848533f2968dbdd4028eb5651da0678a1ee6250fba9c5feae/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616e6d617970616e646579372f77686561742d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fc06bc91700bb79848533f2968dbdd4028eb5651da0678a1ee6250fba9c5feae/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616e6d617970616e646579372f77686561742d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tanmaypandey7/wheat-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detecting wheat heads using YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WoodratTradeCo/crop-rows-detection\"\u003eWoodratTradeCo/crop-rows-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a43d16067576155fdf651ac28deda4ca37c795a555b8ee71e3078a81a72fca95/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6f647261745472616465436f2f63726f702d726f77732d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a43d16067576155fdf651ac28deda4ca37c795a555b8ee71e3078a81a72fca95/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6f647261745472616465436f2f63726f702d726f77732d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WoodratTradeCo/crop-rows-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : It is an real-time crop rows detection method using YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/denghv/Vegetables_Fruit_Detection\"\u003edenghv/Vegetables_Fruit_Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7409a2eaa2d85c3f7b1dbd73e45868c70e80b9b01c1b437ed4f26c9a1da00188/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64656e6768762f566567657461626c65735f46727569745f446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7409a2eaa2d85c3f7b1dbd73e45868c70e80b9b01c1b437ed4f26c9a1da00188/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64656e6768762f566567657461626c65735f46727569745f446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/denghv/Vegetables_Fruit_Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Using YOLOv10 to detect vegetables \u0026amp; fruit.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSports Field Detection\u003c/h3\u003e\u003ca id=\"user-content-sports-field-detection\" class=\"anchor\" aria-label=\"Permalink: Sports Field Detection\" href=\"#sports-field-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eä½“è‚²é¢†åŸŸæ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-ä½“è‚²é¢†åŸŸæ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: ä½“è‚²é¢†åŸŸæ£€æµ‹\" href=\"#ä½“è‚²é¢†åŸŸæ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/tomer-erez/pingpong-referee\"\u003etomer-erez/pingpong-referee\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e977dcbc92e4307137c17c2a71745492e176eaad82f8ce448d63f0a4a2e102ee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746f6d65722d6572657a2f70696e67706f6e672d726566657265653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e977dcbc92e4307137c17c2a71745492e176eaad82f8ce448d63f0a4a2e102ee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746f6d65722d6572657a2f70696e67706f6e672d726566657265653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tomer-erez/pingpong-referee?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : using the YOlO algorithm for an automated pingpong referee.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAerial Imagery Detection\u003c/h3\u003e\u003ca id=\"user-content-aerial-imagery-detection\" class=\"anchor\" aria-label=\"Permalink: Aerial Imagery Detection\" href=\"#aerial-imagery-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eé¥æ„Ÿå›¾åƒæ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-é¥æ„Ÿå›¾åƒæ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: é¥æ„Ÿå›¾åƒæ£€æµ‹\" href=\"#é¥æ„Ÿå›¾åƒæ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/stephansturges/WALDO\"\u003eWALDO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/40e7754098dab06cff72eea934a63b0ed20a613fefa1f2ff7f974d07af57156f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374657068616e737475726765732f57414c444f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/40e7754098dab06cff72eea934a63b0ed20a613fefa1f2ff7f974d07af57156f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374657068616e737475726765732f57414c444f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/stephansturges/WALDO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Whereabouts Ascertainment for Low-lying Detectable Objects. The SOTA in FOSS AI for drones!\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAdverse Weather Conditions\u003c/h3\u003e\u003ca id=\"user-content-adverse-weather-conditions\" class=\"anchor\" aria-label=\"Permalink: Adverse Weather Conditions\" href=\"#adverse-weather-conditions\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eæ¶åŠ£å¤©æ°”æƒ…å†µ\u003c/h4\u003e\u003ca id=\"user-content-æ¶åŠ£å¤©æ°”æƒ…å†µ\" class=\"anchor\" aria-label=\"Permalink: æ¶åŠ£å¤©æ°”æƒ…å†µ\" href=\"#æ¶åŠ£å¤©æ°”æƒ…å†µ\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/wenyyu/Image-Adaptive-YOLO\"\u003eImage-Adaptive YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f07e611e956d4129c185b7b9c603aaec2b1764905dcd86cf8e78fd18733a9c39/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77656e7979752f496d6167652d41646170746976652d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f07e611e956d4129c185b7b9c603aaec2b1764905dcd86cf8e78fd18733a9c39/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77656e7979752f496d6167652d41646170746976652d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wenyyu/Image-Adaptive-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Image-Adaptive YOLO for Object Detection in Adverse Weather Conditions\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2112.08088\" rel=\"nofollow\"\u003eAAAI 2022\u003c/a\u003e\u003c/strong\u003e). \"è®¡ç®—æœºè§†è§‰ç ”ç©¶é™¢ï¼šã€Š\u003ca href=\"https://mp.weixin.qq.com/s/QdM6Dx990VhN97MRIP74XA\" rel=\"nofollow\"\u003eå›¾åƒè‡ªé€‚åº”YOLOï¼šæ¨¡ç³ŠçŽ¯å¢ƒä¸‹çš„ç›®æ ‡æ£€æµ‹ï¼ˆé™„æºä»£ç ï¼‰\u003c/a\u003eã€‹\"\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAdversarial Attack and Defense\u003c/h3\u003e\u003ca id=\"user-content-adversarial-attack-and-defense\" class=\"anchor\" aria-label=\"Permalink: Adversarial Attack and Defense\" href=\"#adversarial-attack-and-defense\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eå¯¹æŠ—æ”»å‡»ä¸Žé˜²å¾¡\u003c/h4\u003e\u003ca id=\"user-content-å¯¹æŠ—æ”»å‡»ä¸Žé˜²å¾¡\" class=\"anchor\" aria-label=\"Permalink: å¯¹æŠ—æ”»å‡»ä¸Žé˜²å¾¡\" href=\"#å¯¹æŠ—æ”»å‡»ä¸Žé˜²å¾¡\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://gitlab.com/EAVISE/adversarial-yolo\" rel=\"nofollow\"\u003eEAVISE/adversarial-yolo\u003c/a\u003e : \"Fooling automated surveillance cameras: adversarial patches to attack person detection\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_CVPRW_2019/html/CV-COPS/Thys_Fooling_Automated_Surveillance_Cameras_Adversarial_Patches_to_Attack_Person_Detection_CVPRW_2019_paper.html\" rel=\"nofollow\"\u003eCVPR 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/git-disl/TOG\"\u003egit-disl/TOG\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6c8f2df8da38991eab313db758e3dbe95a8082cb2b8536567203694f2f4a1c7d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6769742d6469736c2f544f473f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6c8f2df8da38991eab313db758e3dbe95a8082cb2b8536567203694f2f4a1c7d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6769742d6469736c2f544f473f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/git-disl/TOG?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Adversarial Objectness Gradient Attacks on Real-time Object Detection Systems\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9325397\" rel=\"nofollow\"\u003eIEEE TPS-ISA 2020\u003c/a\u003e\u003c/strong\u003e) | \"Understanding Object Detection Through an Adversarial Lens\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/chapter/10.1007/978-3-030-59013-0_23\" rel=\"nofollow\"\u003eESORICS 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/VITA-Group/3D_Adversarial_Logo\"\u003eVITA-Group/3D_Adversarial_Logo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/60da7b1af009c42fbc7394f8692a4ea97678ac3cd196c7009b5e81e989087d48/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f564954412d47726f75702f33445f416476657273617269616c5f4c6f676f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/60da7b1af009c42fbc7394f8692a4ea97678ac3cd196c7009b5e81e989087d48/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f564954412d47726f75702f33445f416476657273617269616c5f4c6f676f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/VITA-Group/3D_Adversarial_Logo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 3D adversarial logo attack on different3D object meshes to fool a YOLOV2 detector. \"Can 3D Adversarial Logos Clock Humans?\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2006.14655\" rel=\"nofollow\"\u003earXiv 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ASGuard-UCI/MSF-ADV\"\u003eASGuard-UCI/MSF-ADV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2d77dda0ec84c933ebbe1058f1b175826813f5401529291dca8d5be6be1993ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f415347756172642d5543492f4d53462d4144563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2d77dda0ec84c933ebbe1058f1b175826813f5401529291dca8d5be6be1993ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f415347756172642d5543492f4d53462d4144563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ASGuard-UCI/MSF-ADV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : MSF-ADV is a novel physical-world adversarial attack method, which can fool the Multi Sensor Fusion (MSF) based autonomous driving (AD) perception in the victim autonomous vehicle (AV) to fail in detecting a front obstacle and thus crash into it. \"Invisible for both Camera and LiDAR: Security of Multi-Sensor Fusion based Perception in Autonomous Driving Under Physical-World Attacks\". (\u003cstrong\u003e\u003ca href=\"https://www.computer.org/csdl/proceedings-article/sp/2021/893400b302/1t0x9btzenu\" rel=\"nofollow\"\u003eIEEE S\u0026amp;P 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/veralauee/DPatch\"\u003everalauee/DPatch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5133bfd4b7f1aa18e4d15d85ba1db96f34db7440211a2d5359df9a8fe1a268fe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f766572616c617565652f4450617463683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5133bfd4b7f1aa18e4d15d85ba1db96f34db7440211a2d5359df9a8fe1a268fe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f766572616c617565652f4450617463683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/veralauee/DPatch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"DPatch: An Adversarial Patch Attack on Object Detectors\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1806.02299\" rel=\"nofollow\"\u003earXiv 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Shudeng/GPAttack\"\u003eShudeng/GPAttack\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b79ddd3249ce967fcad3ec000d411528bfb466712575d5f012fabcb4bd3fbc9b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53687564656e672f475041747461636b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b79ddd3249ce967fcad3ec000d411528bfb466712575d5f012fabcb4bd3fbc9b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53687564656e672f475041747461636b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Shudeng/GPAttack?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Grid Patch Attack for Object Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Wu-Shudeng/DPAttack\"\u003eWu-Shudeng/DPAttack\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/eff5d8d5f57f70829708e7043bc971ca7218f24aaa57ce83735dab039452d3d5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57752d53687564656e672f445041747461636b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/eff5d8d5f57f70829708e7043bc971ca7218f24aaa57ce83735dab039452d3d5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57752d53687564656e672f445041747461636b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Wu-Shudeng/DPAttack?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"DPAttack: Diffused Patch Attacks against Universal Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2010.11679\" rel=\"nofollow\"\u003earXiv 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FenHua/DetDak\"\u003eFenHua/DetDak\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0109a9629428be1e077cb0980fa8f181acd8d3305b09b25cae0f5fae2dc540f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46656e4875612f44657444616b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0109a9629428be1e077cb0980fa8f181acd8d3305b09b25cae0f5fae2dc540f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46656e4875612f44657444616b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FenHua/DetDak?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Patch adversarial attack; object detection; CIKM2020 å®‰å…¨AIæŒ‘æˆ˜è€…è®¡åˆ’ç¬¬å››æœŸï¼šé€šç”¨ç›®æ ‡æ£€æµ‹çš„å¯¹æŠ—æ”»å‡»ã€‚ \"Object Hider: Adversarial Patch Attack Against Object Detectors\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2010.14974\" rel=\"nofollow\"\u003earXiv 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/THUrssq/Tianchi04\"\u003eTHUrssq/Tianchi04\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bf7175d1182d6733378c29cbcc45ee71626752a310008ad65ae3d3958211fff2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f544855727373712f5469616e63686930343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bf7175d1182d6733378c29cbcc45ee71626752a310008ad65ae3d3958211fff2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f544855727373712f5469616e63686930343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/THUrssq/Tianchi04?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is NO.4 solution for \"CIKM-2020 Alibaba-Tsinghua Adversarial Challenge on Object Detection\". \"Sparse Adversarial Attack to Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2012.13692\" rel=\"nofollow\"\u003earXiv 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mesunhlf/UPC-tf\"\u003emesunhlf/UPC-tf\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f261ece22845c344d7919e064092583b2dc2b1ea8432968dad05ea6ae3ff606c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6573756e686c662f5550432d74663f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f261ece22845c344d7919e064092583b2dc2b1ea8432968dad05ea6ae3ff606c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6573756e686c662f5550432d74663f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mesunhlf/UPC-tf?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Universal Physical Camouflage Attacks on Object Detectors\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_CVPR_2020/html/Huang_Universal_Physical_Camouflage_Attacks_on_Object_Detectors_CVPR_2020_paper.html\" rel=\"nofollow\"\u003eCVPR 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/alex96295/YOLOv3_adversarial_defense\"\u003ealex96295/YOLOv3_adversarial_defense\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6f76d4a11fec21a8b0e3bf309e727940ec2a8f0acd9b6a4c04a12c81994e5474/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c657839363239352f594f4c4f76335f616476657273617269616c5f646566656e73653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6f76d4a11fec21a8b0e3bf309e727940ec2a8f0acd9b6a4c04a12c81994e5474/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c657839363239352f594f4c4f76335f616476657273617269616c5f646566656e73653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/alex96295/YOLOv3_adversarial_defense?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv3_adversarial_defense.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/alex96295/YOLO_adversarial_attacks\"\u003ealex96295/YOLO_adversarial_attacks\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3a6b6eb7b762e07d7ef2f527b6e940893a8d05418df1ae1872d8a3de1cf6ae28/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c657839363239352f594f4c4f5f616476657273617269616c5f61747461636b733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3a6b6eb7b762e07d7ef2f527b6e940893a8d05418df1ae1872d8a3de1cf6ae28/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c657839363239352f594f4c4f5f616476657273617269616c5f61747461636b733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/alex96295/YOLO_adversarial_attacks?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO_adversarial_attacks.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/alex96295/Adversarial-Patch-Attacks-TRAINING-YOLO-SSD-Pytorch\"\u003ealex96295/Adversarial-Patch-Attacks-TRAINING-YOLO-SSD-Pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/51d22d689296a61b4a40fd01756de5d910770929a7c33cf0003a1eb8da4b95dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c657839363239352f416476657273617269616c2d50617463682d41747461636b732d545241494e494e472d594f4c4f2d5353442d5079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/51d22d689296a61b4a40fd01756de5d910770929a7c33cf0003a1eb8da4b95dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c657839363239352f416476657273617269616c2d50617463682d41747461636b732d545241494e494e472d594f4c4f2d5353442d5079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/alex96295/Adversarial-Patch-Attacks-TRAINING-YOLO-SSD-Pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository has the code needed to train 'Adversarial Patch Attacks' on YOLO and SSD models for object detection in Pytorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FranBesq/attack-yolo\"\u003eFranBesq/attack-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c464c2654cb1fd03e94c2f4d67755d13316421628c88028cb8312f4f14e7f669/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4672616e426573712f61747461636b2d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c464c2654cb1fd03e94c2f4d67755d13316421628c88028cb8312f4f14e7f669/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4672616e426573712f61747461636b2d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FranBesq/attack-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Developing adversarial attacks on YOLO algorithm for computer vision.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Rushi314/GPR-Object-Detection\"\u003eRushi314/GPR-Object-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3cdc9d17fd0cc862b3a86c11d124aba537d7b36e4c298a1b7188d2aee6a47512/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52757368693331342f4750522d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3cdc9d17fd0cc862b3a86c11d124aba537d7b36e4c298a1b7188d2aee6a47512/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52757368693331342f4750522d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Rushi314/GPR-Object-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detecting Objects in Ground Penetrating Radars Scans.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/realtxy/pso-adversarial-yolo_v3\"\u003erealtxy/pso-adversarial-yolo_v3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e86ccc2bb83ebb652e720749795cea83dd6a04c4453c2732b1e68d5541c1ec75/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7265616c7478792f70736f2d616476657273617269616c2d796f6c6f5f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e86ccc2bb83ebb652e720749795cea83dd6a04c4453c2732b1e68d5541c1ec75/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7265616c7478792f70736f2d616476657273617269616c2d796f6c6f5f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/realtxy/pso-adversarial-yolo_v3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : pso-adversarial-yolo_v3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sowgali/ObjCAM\"\u003esowgali/ObjCAM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1010f8f9001c631df74815d6fc8489452b5692376300544de011443ab8d556e0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736f7767616c692f4f626a43414d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1010f8f9001c631df74815d6fc8489452b5692376300544de011443ab8d556e0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736f7767616c692f4f626a43414d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sowgali/ObjCAM?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Visualizations for adversarial attacks in object detectors like YOLO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/andrewpatrickdu/adversarial-yolov3-cowc\"\u003eandrewpatrickdu/adversarial-yolov3-cowc\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/18a5ed5d6703c4b5929c24b244dc361e191af44145ca3ef1a729fb1c3cdd7cdc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616e647265777061747269636b64752f616476657273617269616c2d796f6c6f76332d636f77633f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/18a5ed5d6703c4b5929c24b244dc361e191af44145ca3ef1a729fb1c3cdd7cdc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616e647265777061747269636b64752f616476657273617269616c2d796f6c6f76332d636f77633f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/andrewpatrickdu/adversarial-yolov3-cowc?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Physical Adversarial Attacks on an Aerial Imagery Object Detector\".  (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/WACV2022/html/Du_Physical_Adversarial_Attacks_on_an_Aerial_Imagery_Object_Detector_WACV_2022_paper.html\" rel=\"nofollow\"\u003eWACV 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/IQTLabs/camolo\"\u003eIQTLabs/camolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bac2def1f59fbf1752378ae11aaea22ba30e77feea16ba425fa89b077a82110d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4951544c6162732f63616d6f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bac2def1f59fbf1752378ae11aaea22ba30e77feea16ba425fa89b077a82110d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4951544c6162732f63616d6f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/IQTLabs/camolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Camouflage YOLO - (CAMOLO) trains adversarial patches to confuse the YOLO family of object detectors.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WhoTHU/Adversarial_Texture\"\u003eAdvTexture\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/09724874f0faa6343ced1dcf350d93c3e631c7a247572b4032397d47bcb4621b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57686f5448552f416476657273617269616c5f546578747572653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/09724874f0faa6343ced1dcf350d93c3e631c7a247572b4032397d47bcb4621b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57686f5448552f416476657273617269616c5f546578747572653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WhoTHU/Adversarial_Texture?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Adversarial Texture for Fooling Person Detectors in the Physical World\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Adversarial_Texture_for_Fooling_Person_Detectors_in_the_Physical_World_CVPR_2022_paper.html\" rel=\"nofollow\"\u003eCVPR 2022\u003c/a\u003e\u003c/strong\u003e).  \"çŸ¥ä¹Žã€ŒWhoTHã€ã€Š\u003ca href=\"https://zhuanlan.zhihu.com/p/499854846\" rel=\"nofollow\"\u003eCVPR2022 Oral ç‰©ç†å¯¹æŠ—æ ·æœ¬ å¦‚ä½•åšä¸€ä»¶â€œéšå½¢è¡£â€\u003c/a\u003eã€‹\"ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SamSamhuns/yolov5_adversarial\"\u003eSamSamhuns/yolov5_adversarial\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5c410d703e6bcd25db5df6d353cd8c6f24db20ca138bb8d02e1ca1ada91900cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53616d53616d68756e732f796f6c6f76355f616476657273617269616c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5c410d703e6bcd25db5df6d353cd8c6f24db20ca138bb8d02e1ca1ada91900cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53616d53616d68756e732f796f6c6f76355f616476657273617269616c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SamSamhuns/yolov5_adversarial?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Generate adversarial patches against YOLOv5 ðŸš€\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCamouflaged Detection\u003c/h3\u003e\u003ca id=\"user-content-camouflaged-detection\" class=\"anchor\" aria-label=\"Permalink: Camouflaged Detection\" href=\"#camouflaged-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eä¼ªè£…ç›®æ ‡æ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-ä¼ªè£…ç›®æ ‡æ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: ä¼ªè£…ç›®æ ‡æ£€æµ‹\" href=\"#ä¼ªè£…ç›®æ ‡æ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/Ap1rate/yolov8-SIM\"\u003eAp1rate/yolov8-SIM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1fee74960c2ff235a900c8fa236e36f47df77c3a7d17a024cd8a6833f32c191d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f417031726174652f796f6c6f76382d53494d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1fee74960c2ff235a900c8fa236e36f47df77c3a7d17a024cd8a6833f32c191d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f417031726174652f796f6c6f76382d53494d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ap1rate/yolov8-SIM?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Link to Journal of Ecological Informatics paper ' Camouflaged Detection: Optimization-Based Computer Vision for Alligator sinensis with Low Detectability in Complex Wild Environments '.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eGame Field Detection\u003c/h3\u003e\u003ca id=\"user-content-game-field-detection\" class=\"anchor\" aria-label=\"Permalink: Game Field Detection\" href=\"#game-field-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eæ¸¸æˆé¢†åŸŸæ£€æµ‹\u003c/h4\u003e\u003ca id=\"user-content-æ¸¸æˆé¢†åŸŸæ£€æµ‹\" class=\"anchor\" aria-label=\"Permalink: æ¸¸æˆé¢†åŸŸæ£€æµ‹\" href=\"#æ¸¸æˆé¢†åŸŸæ£€æµ‹\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SunOner/sunone_aimbot\"\u003eSunOner/sunone_aimbot\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/47a54b8bd5e0336193b2c245d5a78c9aa8c169b422747d7bde7f781eb27976c9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53756e4f6e65722f73756e6f6e655f61696d626f743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/47a54b8bd5e0336193b2c245d5a78c9aa8c169b422747d7bde7f781eb27976c9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53756e4f6e65722f73756e6f6e655f61696d626f743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SunOner/sunone_aimbot?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸŒ²Aim-bot based on AI for all FPS games. \u003ca href=\"https://boosty.to/sunone\" rel=\"nofollow\"\u003eboosty.to/sunone\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Passer1072/RookieAI_yolov8\"\u003ePasser1072/RookieAI_yolov8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1aea46cf4ef865ed76b69f134d089133ee87d56b138e22389e3f6213380eed55/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506173736572313037322f526f6f6b696541495f796f6c6f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1aea46cf4ef865ed76b69f134d089133ee87d56b138e22389e3f6213380eed55/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506173736572313037322f526f6f6b696541495f796f6c6f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Passer1072/RookieAI_yolov8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽyolov8å®žçŽ°çš„AIè‡ªçž„é¡¹ç›® AI self-aiming project based on yolov8.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/petercunha/Pine\"\u003epetercunha/Pine\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d949cb2f037ae47f662336972fb8e1dccb4d3fef6f3fb3229a61430ab8f959e1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706574657263756e68612f50696e653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d949cb2f037ae47f662336972fb8e1dccb4d3fef6f3fb3229a61430ab8f959e1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706574657263756e68612f50696e653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/petercunha/Pine?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸŒ² Aimbot powered by real-time object detection with neural networks, GPU accelerated with Nvidia. Optimized for use with CS:GO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/chaoyu1999/FPSAutomaticAiming\"\u003echaoyu1999/FPSAutomaticAiming\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8176d852683f88b7379886d2ef6bfb0e34742634fe4bc6b5e23c9c5b8dc9eaa9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368616f7975313939392f4650534175746f6d6174696341696d696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8176d852683f88b7379886d2ef6bfb0e34742634fe4bc6b5e23c9c5b8dc9eaa9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368616f7975313939392f4650534175746f6d6174696341696d696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/chaoyu1999/FPSAutomaticAiming?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽyolov5çš„FPSç±»æ¸¸æˆAIè‡ªçž„AIã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Lu-tju/CSGO_AI\"\u003eLu-tju/CSGO_AI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7a16da44bb2dbe7a0565789164a25f121e5d43f8dbd832fd26b8a9dda2fd976f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c752d746a752f4353474f5f41493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7a16da44bb2dbe7a0565789164a25f121e5d43f8dbd832fd26b8a9dda2fd976f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c752d746a752f4353474f5f41493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Lu-tju/CSGO_AI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽYOLOv3çš„csgoè‡ªçž„ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kir486680/csgo_aim\"\u003ekir486680/csgo_aim\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b4258fc43c0311f975dfbdec55c84850f30894372301b0c3e6af83f7485815a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b69723438363638302f6373676f5f61696d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b4258fc43c0311f975dfbdec55c84850f30894372301b0c3e6af83f7485815a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b69723438363638302f6373676f5f61696d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kir486680/csgo_aim?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Aim assist for CSGO with python and yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/c925777075/yolov5-dnf\"\u003ec925777075/yolov5-dnf\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8d955e17c1cbb5e67e5ff07a186374d9957e32aa4e047ac04bc5ff596352cd1c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f633932353737373037352f796f6c6f76352d646e663f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8d955e17c1cbb5e67e5ff07a186374d9957e32aa4e047ac04bc5ff596352cd1c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f633932353737373037352f796f6c6f76352d646e663f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/c925777075/yolov5-dnf?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5-DNF.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/davidhoung2/APEX-yolov5-aim-assist\"\u003edavidhoung2/APEX-yolov5-aim-assist\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6ddd58af92b2dee98fad32bedba7fded5c828782d8762d10e20aae5ecd23ef08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6461766964686f756e67322f415045582d796f6c6f76352d61696d2d6173736973743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6ddd58af92b2dee98fad32bedba7fded5c828782d8762d10e20aae5ecd23ef08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6461766964686f756e67322f415045582d796f6c6f76352d61696d2d6173736973743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/davidhoung2/APEX-yolov5-aim-assist?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : using yolov5 to help you aim enemies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Brednan/CSGO-Aimbot\"\u003eBrednan/CSGO-Aimbot\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f967e80701ff5d3e83a5e812e5baa910b3bb62f63969630c008f39486651515c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427265646e616e2f4353474f2d41696d626f743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f967e80701ff5d3e83a5e812e5baa910b3bb62f63969630c008f39486651515c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427265646e616e2f4353474f2d41696d626f743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Brednan/CSGO-Aimbot?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Aimbot for the FPS game CSGO. It uses YOLOv5 to detect enemy players on my screen, then moves my cursor to the location.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/2319590263/yolov5-csgo\"\u003e2319590263/yolov5-csgo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8b0a90bf7ca375dbf47c43bd5e4940c248534bd8f7f861650b89367374cada33/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f323331393539303236332f796f6c6f76352d6373676f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8b0a90bf7ca375dbf47c43bd5e4940c248534bd8f7f861650b89367374cada33/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f323331393539303236332f796f6c6f76352d6373676f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/2319590263/yolov5-csgo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽyolov5å®žçŽ°çš„csgoè‡ªçž„ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SCRN-VRC/YOLOv4-Tiny-in-UnityCG-HLSL\"\u003eSCRN-VRC/YOLOv4-Tiny-in-UnityCG-HLSL\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8fe4aae69befded56696f7c28268dc37d1494a8d8916c27d1e5db5ae9267be96/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5343524e2d5652432f594f4c4f76342d54696e792d696e2d556e69747943472d484c534c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8fe4aae69befded56696f7c28268dc37d1494a8d8916c27d1e5db5ae9267be96/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5343524e2d5652432f594f4c4f76342d54696e792d696e2d556e69747943472d484c534c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SCRN-VRC/YOLOv4-Tiny-in-UnityCG-HLSL?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A modern object detector inside fragment shaders.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/qcjxs-hn/yolov5-csgo\"\u003eqcjxs-hn/yolov5-csgo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/352ced640f2603465f0ff28860857df170d407664b87334e35af911d6d123df5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f71636a78732d686e2f796f6c6f76352d6373676f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/352ced640f2603465f0ff28860857df170d407664b87334e35af911d6d123df5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f71636a78732d686e2f796f6c6f76352d6373676f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/qcjxs-hn/yolov5-csgo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¿™æ˜¯ä¸€ä¸ªæ ¹æ®æ•™ç¨‹å†™çš„csgo-aiå’Œæˆ‘è‡ªå·±è®­ç»ƒçš„æ¨¡åž‹ï¼Œè¿˜æœ‰æ•°æ®é›†ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/IgaoGuru/Sequoia\"\u003eSequoia\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/965e6326ecd7db86bfe93e3fb47e6ca0a23e4db6c18e80a5daf9e63b873c449d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4967616f477572752f536571756f69613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/965e6326ecd7db86bfe93e3fb47e6ca0a23e4db6c18e80a5daf9e63b873c449d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4967616f477572752f536571756f69613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/IgaoGuru/Sequoia?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A neural network for CounterStrike:GlobalOffensive character detection and classification. Built on a custom-made dataset (csgo-data-collector).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ItGarbager/aimcf_yolov5\"\u003eItGarbager/aimcf_yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3db1d638695a17d1d4c1542007d3511a46651d9f8d50ada958e0b81ed1f83628/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f497447617262616765722f61696d63665f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3db1d638695a17d1d4c1542007d3511a46651d9f8d50ada958e0b81ed1f83628/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f497447617262616765722f61696d63665f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ItGarbager/aimcf_yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä½¿ç”¨yolov5ç®—æ³•å®žçŽ°cfè§’è‰²å¤´éƒ¨é¢„æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jiaran-takeme/Target-Detection-for-CSGO-by-YOLOv5\"\u003ejiaran-takeme/Target-Detection-for-CSGO-by-YOLOv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/92483f60a653254bb62b59e15e1028274738514a5bfae15c2524eae8a3ac808c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a696172616e2d74616b656d652f5461726765742d446574656374696f6e2d666f722d4353474f2d62792d594f4c4f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/92483f60a653254bb62b59e15e1028274738514a5bfae15c2524eae8a3ac808c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a696172616e2d74616b656d652f5461726765742d446574656374696f6e2d666f722d4353474f2d62792d594f4c4f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jiaran-takeme/Target-Detection-for-CSGO-by-YOLOv5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Target Detection for CSGO by YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Lucid1ty/Yolov5ForCSGO\"\u003eLucid1ty/Yolov5ForCSGO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f31cc959f6992f8acee8f88e9539d12105ca11f7a5b92545297083eefef1717c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c756369643174792f596f6c6f7635466f724353474f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f31cc959f6992f8acee8f88e9539d12105ca11f7a5b92545297083eefef1717c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c756369643174792f596f6c6f7635466f724353474f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Lucid1ty/Yolov5ForCSGO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : CSGO character detection and auto aim.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/leo4048111/Yolov5-LabelMaker-For-CSGO\"\u003eleo4048111/Yolov5-LabelMaker-For-CSGO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/16d0363f9ae4319ce5d1742a132363989fe97afb2a5f2b61005afeac7ff0f107/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c656f343034383131312f596f6c6f76352d4c6162656c4d616b65722d466f722d4353474f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/16d0363f9ae4319ce5d1742a132363989fe97afb2a5f2b61005afeac7ff0f107/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c656f343034383131312f596f6c6f76352d4c6162656c4d616b65722d466f722d4353474f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/leo4048111/Yolov5-LabelMaker-For-CSGO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A simple tool for making CSGO dataset in YOLO format.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/soloist-v/AutoStrike\"\u003esoloist-v/AutoStrike\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/57c6cb258dcb31171e11b6398d5d3ba8c4145108f1c73d4430d45410ea87ebbe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736f6c6f6973742d762f4175746f537472696b653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/57c6cb258dcb31171e11b6398d5d3ba8c4145108f1c73d4430d45410ea87ebbe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736f6c6f6973742d762f4175746f537472696b653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/soloist-v/AutoStrike?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä½¿ç”¨yolov5è‡ªåŠ¨çž„å‡†ï¼Œæ”¯æŒfpsæ¸¸æˆ é¼ æ ‡ç§»åŠ¨æŽ§åˆ¶éœ€è¦è‡ªè¡Œè°ƒæ•´ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/slyautomation/osrs_yolov5\"\u003eslyautomation/osrs_yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e7458da7d0c13d1eb126c9d468a78ac34ff524fa5842862562eab09b57032e9b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736c796175746f6d6174696f6e2f6f7372735f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e7458da7d0c13d1eb126c9d468a78ac34ff524fa5842862562eab09b57032e9b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736c796175746f6d6174696f6e2f6f7372735f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/slyautomation/osrs_yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov5 Object Detection In OSRS using Python code, Detecting Cows - Botting.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HarunoWindy/yolo-games-weights\"\u003eHarunoWindy/yolo-games-weights\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/125e86184b562f411f4936bd3007ae79536e2a08f302d9a5f07c56b6055dba91/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f486172756e6f57696e64792f796f6c6f2d67616d65732d776569676874733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/125e86184b562f411f4936bd3007ae79536e2a08f302d9a5f07c56b6055dba91/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f486172756e6f57696e64792f796f6c6f2d67616d65732d776569676874733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HarunoWindy/yolo-games-weights?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 vision deep-learning on detect games UI (current support: onmyoji) YOLOv5æ·±åº¦å­¦ä¹ è¯†åˆ«æ¸¸æˆUI(ç›®å‰æ”¯æŒï¼šé˜´é˜³å¸ˆ).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mrathena/python.yolo.csgo.autoaim.helper\"\u003emrathena/python.yolo.csgo.autoaim.helper\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/45fc1be8bf12e08c7748f668d3e4da5614ffdbd88508dce1715ed26cbeec01b1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d72617468656e612f707974686f6e2e796f6c6f2e6373676f2e6175746f61696d2e68656c7065723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/45fc1be8bf12e08c7748f668d3e4da5614ffdbd88508dce1715ed26cbeec01b1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d72617468656e612f707974686f6e2e796f6c6f2e6373676f2e6175746f61696d2e68656c7065723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mrathena/python.yolo.csgo.autoaim.helper?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Python Yolo v5 6.2 Csgo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Aa-bN/AimYolo\"\u003eAa-bN/AimYolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/35c5053838e99822efe7f81b32338c07bd69f014e182bcc7bd43db49ee6d813e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41612d624e2f41696d596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/35c5053838e99822efe7f81b32338c07bd69f014e182bcc7bd43db49ee6d813e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41612d624e2f41696d596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Aa-bN/AimYolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : AIå¤–æŒ‚â€”â€”åŸºäºŽYOLOv5çš„å°„å‡»ç±»æ¸¸æˆçž„å‡†è¾…åŠ©ã€‚An AI plug-in - targeting aid for shooting games based on YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/suixin1424/cf-yolo-trt\"\u003esuixin1424/cf-yolo-trt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a9cbff54489a8043c5d0835bdfadefac5b798fb745b4c87e4a9296c4767fb648/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756978696e313432342f63662d796f6c6f2d7472743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a9cbff54489a8043c5d0835bdfadefac5b798fb745b4c87e4a9296c4767fb648/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756978696e313432342f63662d796f6c6f2d7472743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/suixin1424/cf-yolo-trt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽyolov5-trtçš„ç©¿è¶Šç«çº¿aiè‡ªçž„ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DuGuYifei/Yolov5_FPS_AICheatPrinciple\"\u003eDuGuYifei/Yolov5_FPS_AICheatPrinciple\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/eeb75c07bdc51a934c236703f2406bd5d56ac4feef48cd72c34774dee64d1154/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4475477559696665692f596f6c6f76355f4650535f414943686561745072696e6369706c653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/eeb75c07bdc51a934c236703f2406bd5d56ac4feef48cd72c34774dee64d1154/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4475477559696665692f596f6c6f76355f4650535f414943686561745072696e6369706c653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DuGuYifei/Yolov5_FPS_AICheatPrinciple?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The AI cheating principle of fps game. (This is only used for learning).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MistyAI/MistyFN\"\u003eMistyAI/MistyFN\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a519603ebb62540c87e788cb68cf3ca2fee806f2b37e5aaf7443708db52a662c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6973747941492f4d69737479464e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a519603ebb62540c87e788cb68cf3ca2fee806f2b37e5aaf7443708db52a662c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6973747941492f4d69737479464e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MistyAI/MistyFN?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Aimbot and Triggerbot for Fortnite based on artificial intelligence.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/suixin1424/crossfire-yolo-TensorRT\"\u003esuixin1424/crossfire-yolo-TensorRT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/40ef63ab9ed0f89ba8a85d3d5ea52caf8410f4ef9db5d2440e00f08860333eee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756978696e313432342f63726f7373666972652d796f6c6f2d54656e736f7252543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/40ef63ab9ed0f89ba8a85d3d5ea52caf8410f4ef9db5d2440e00f08860333eee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756978696e313432342f63726f7373666972652d796f6c6f2d54656e736f7252543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/suixin1424/crossfire-yolo-TensorRT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : crossfire-yolo-TensorRT. åŸºäºŽyolo-trtçš„ç©¿è¶Šç«çº¿aiè‡ªçž„ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/EthanH3514/AL_Yolo\"\u003eEthanH3514/AL_Yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/227efe01e36e3b9d6ed6db141820dd5bed597b8d0e4fa465e7d3a8828d796058/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f457468616e48333531342f414c5f596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/227efe01e36e3b9d6ed6db141820dd5bed597b8d0e4fa465e7d3a8828d796058/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f457468616e48333531342f414c5f596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/EthanH3514/AL_Yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽYolov5çš„Apex Legendæ¸¸æˆ AI è¾…çž„å¤–æŒ‚ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SunOner/yolov8_aimbot\"\u003eSunOner/yolov8_aimbot\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/02df7ac6e3a8e35e0fca97ac0cdb14e06dc0d2589ffc0592d9da3053a97ec7a6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53756e4f6e65722f796f6c6f76385f61696d626f743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/02df7ac6e3a8e35e0fca97ac0cdb14e06dc0d2589ffc0592d9da3053a97ec7a6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53756e4f6e65722f796f6c6f76385f61696d626f743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SunOner/yolov8_aimbot?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Aim-bot based on AI for all FPS games.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bigQY/calabiyau-cheat\"\u003ebigQY/calabiyau-cheat\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/98ae4ad31fe2aa8bb697416ccd53c74e0716b6aefe0c002643e5d5ac471b2816/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62696751592f63616c6162697961752d63686561743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/98ae4ad31fe2aa8bb697416ccd53c74e0716b6aefe0c002643e5d5ac471b2816/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62696751592f63616c6162697961752d63686561743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bigQY/calabiyau-cheat?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽyolov10çš„å¡æ‹‰å½¼ä¸˜è‡ªçž„ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAutomatic Annotation Tools\u003c/h3\u003e\u003ca id=\"user-content-automatic-annotation-tools\" class=\"anchor\" aria-label=\"Permalink: Automatic Annotation Tools\" href=\"#automatic-annotation-tools\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eè‡ªåŠ¨æ ‡æ³¨å·¥å…·\u003c/h4\u003e\u003ca id=\"user-content-è‡ªåŠ¨æ ‡æ³¨å·¥å…·\" class=\"anchor\" aria-label=\"Permalink: è‡ªåŠ¨æ ‡æ³¨å·¥å…·\" href=\"#è‡ªåŠ¨æ ‡æ³¨å·¥å…·\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HumanSignal/label-studio\"\u003eLabel Studio\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/67036dea2546fceffdfc29d776ff2b3735d525e4527ad8ddd6a59b4822cb3ad5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48756d616e5369676e616c2f6c6162656c2d73747564696f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/67036dea2546fceffdfc29d776ff2b3735d525e4527ad8ddd6a59b4822cb3ad5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48756d616e5369676e616c2f6c6162656c2d73747564696f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HumanSignal/label-studio?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Label Studio is a multi-type data labeling and annotation tool with standardized output format. \u003ca href=\"https://labelstud.io/\" rel=\"nofollow\"\u003elabelstud.io\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/vietanhdev/anylabeling\"\u003eAnyLabeling\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fabfde4bb4cc495066df3245b2d5ff1d8e1b95d8f377ab207fcb45588a33f6cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76696574616e686465762f616e796c6162656c696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fabfde4bb4cc495066df3245b2d5ff1d8e1b95d8f377ab207fcb45588a33f6cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76696574616e686465762f616e796c6162656c696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/vietanhdev/anylabeling?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸŒŸ AnyLabeling ðŸŒŸ. Effortless AI-assisted data labeling with AI support from YOLO, Segment Anything, MobileSAM!! \u003ca href=\"https://anylabeling.nrl.ai/\" rel=\"nofollow\"\u003eanylabeling.nrl.ai\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CVHub520/X-AnyLabeling\"\u003eX-AnyLabeling\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/822ce53353585f82ef9fb52ff2b5e2439c18912227c1fe5550a73acaf89ea2e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43564875623532302f582d416e794c6162656c696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/822ce53353585f82ef9fb52ff2b5e2439c18912227c1fe5550a73acaf89ea2e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43564875623532302f582d416e794c6162656c696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CVHub520/X-AnyLabeling?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ’« X-AnyLabeling ðŸ’«. X-AnyLabelingï¼šä¸€æ¬¾å¤š SOTA æ¨¡åž‹é›†æˆçš„é«˜çº§è‡ªåŠ¨æ ‡æ³¨å·¥å…·ï¼ Effortless data labeling with AI support from Segment Anything and other awesome models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/open-mmlab/playground/tree/main/label_anything\"\u003eLabel Anything\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2803dd19ecd3c798e5a6155e46e2aba807950cc13d53136974565447c7b19a47/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d6d6d6c61622f706c617967726f756e643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2803dd19ecd3c798e5a6155e46e2aba807950cc13d53136974565447c7b19a47/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d6d6d6c61622f706c617967726f756e643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/open-mmlab/playground?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : OpenMMLab PlayGround: Semi-Automated Annotation with Label-Studio and SAM.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/heartexlabs/labelImg\"\u003eLabelImg\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/dadc4a6251bef7ddf268b9606b0cccc7a958971ebd9b5f518e5abed8839f42a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686561727465786c6162732f6c6162656c496d673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dadc4a6251bef7ddf268b9606b0cccc7a958971ebd9b5f518e5abed8839f42a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686561727465786c6162732f6c6162656c496d673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/heartexlabs/labelImg?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ–ï¸ LabelImg is a graphical image annotation tool and label object bounding boxes in images.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wkentaro/labelme\"\u003elabelme\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5a182962d92bb16f13a72a6a57003ce19d8d3ec41bcb3e1fea71b9639c9e356f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776b656e7461726f2f6c6162656c6d653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5a182962d92bb16f13a72a6a57003ce19d8d3ec41bcb3e1fea71b9639c9e356f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776b656e7461726f2f6c6162656c6d653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wkentaro/labelme?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Image Polygonal Annotation with Python (polygon, rectangle, circle, line, point and image-level flag annotation).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/darkpgmr/DarkLabel\"\u003eDarkLabel\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/dc1ee184b84c0eddc37bd121b96efe7778dd45f40eb033cc3985d5e8155ea94e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6461726b70676d722f4461726b4c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dc1ee184b84c0eddc37bd121b96efe7778dd45f40eb033cc3985d5e8155ea94e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6461726b70676d722f4461726b4c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/darkpgmr/DarkLabel?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Video/Image Labeling and Annotation Tool.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlexeyAB/Yolo_mark\"\u003eAlexeyAB/Yolo_mark\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5f0d86929b24cadd73bfb672723a507e94cbf9d176b515bfce3b1e918bbbc2e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f596f6c6f5f6d61726b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5f0d86929b24cadd73bfb672723a507e94cbf9d176b515bfce3b1e918bbbc2e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f596f6c6f5f6d61726b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlexeyAB/Yolo_mark?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : GUI for marking bounded boxes of objects in images for training neural network Yolo v3 and v2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Cartucho/OpenLabeling\"\u003eCartucho/OpenLabeling\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/85366566b5f23bcd02b387b80aecfac3e4baa0e1b2735a04b3e551d0486723fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436172747563686f2f4f70656e4c6162656c696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/85366566b5f23bcd02b387b80aecfac3e4baa0e1b2735a04b3e551d0486723fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436172747563686f2f4f70656e4c6162656c696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Cartucho/OpenLabeling?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Label images and video for Computer Vision applications.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cvat-ai/cvat\"\u003eCVAT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fe9a07e7636fde23bdec44e090a5f2f0bbacd2036375694b3be07da38108da77/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f637661742d61692f637661743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fe9a07e7636fde23bdec44e090a5f2f0bbacd2036375694b3be07da38108da77/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f637661742d61692f637661743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cvat-ai/cvat?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Computer Vision Annotation Tool (CVAT). Annotate better with CVAT, the industry-leading data engine for machine learning. Used and trusted by teams at any scale, for data of any scale.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Microsoft/VoTT\"\u003eVoTT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/695897a0062f5aae617295086997957761e99e9042ca2dacaa1259fd6f50b25c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6963726f736f66742f566f54543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/695897a0062f5aae617295086997957761e99e9042ca2dacaa1259fd6f50b25c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6963726f736f66742f566f54543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Microsoft/VoTT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Visual Object Tagging Tool: An electron app for building end to end Object Detection Models from Images and Videos.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WangRongsheng/KDAT\"\u003eWangRongsheng/KDAT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2d66a5d1fa71d78e1b2336df8582396d6bbd610e6ddc39b4d64248c15801274c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57616e67526f6e677368656e672f4b4441543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2d66a5d1fa71d78e1b2336df8582396d6bbd610e6ddc39b4d64248c15801274c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57616e67526f6e677368656e672f4b4441543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WangRongsheng/KDAT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä¸€ä¸ªä¸“ä¸ºè§†è§‰æ–¹å‘ç›®æ ‡æ£€æµ‹å…¨æµç¨‹çš„æ ‡æ³¨å·¥å…·é›†ï¼Œå…¨ç§°ï¼šKill Object Detection Annotation Toolsã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ryouchinsa/Rectlabel-support\"\u003eRectlabel-support\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/81e95ba68beb08b64d183eae8ae23f01dc8ffadb41279118e21cb3e778c5946e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72796f756368696e73612f526563746c6162656c2d737570706f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/81e95ba68beb08b64d183eae8ae23f01dc8ffadb41279118e21cb3e778c5946e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72796f756368696e73612f526563746c6162656c2d737570706f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ryouchinsa/Rectlabel-support?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : RectLabel - An image annotation tool to label images for bounding box object detection and segmentation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cnyvfang/labelGo-Yolov5AutoLabelImg\"\u003ecnyvfang/labelGo-Yolov5AutoLabelImg\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/68e9f1abd14edfe12bc90dabcc941509334ee989db4aa9dc1c338bd3c2744931/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636e797666616e672f6c6162656c476f2d596f6c6f76354175746f4c6162656c496d673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/68e9f1abd14edfe12bc90dabcc941509334ee989db4aa9dc1c338bd3c2744931/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636e797666616e672f6c6162656c476f2d596f6c6f76354175746f4c6162656c496d673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cnyvfang/labelGo-Yolov5AutoLabelImg?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ’•YOLOV5 semi-automatic annotation tool (Based on labelImg)ðŸ’•ä¸€ä¸ªåŸºäºŽlabelImgåŠYOLOV5çš„å›¾å½¢åŒ–åŠè‡ªåŠ¨æ ‡æ³¨å·¥å…·ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CVUsers/Auto_maker\"\u003eCVUsers/Auto_maker\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/31c56c1966068b2cc0840abbd696cb7a7a89afb2ce0c6f4f58e2815531641022/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f435655736572732f4175746f5f6d616b65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/31c56c1966068b2cc0840abbd696cb7a7a89afb2ce0c6f4f58e2815531641022/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f435655736572732f4175746f5f6d616b65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CVUsers/Auto_maker?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : æ·±åº¦å­¦ä¹ æ•°æ®è‡ªåŠ¨æ ‡æ³¨å™¨å¼€æº ç›®æ ‡æ£€æµ‹å’Œå›¾åƒåˆ†ç±»ï¼ˆé«˜ç²¾åº¦é«˜æ•ˆçŽ‡ï¼‰ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/OvidijusParsiunas/myvision\"\u003eMyVision\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/76e9fb38381abef02bffcb05cfd095d4ebed24804cb339470cdb83c69c6cc889/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f766964696a75735061727369756e61732f6d79766973696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/76e9fb38381abef02bffcb05cfd095d4ebed24804cb339470cdb83c69c6cc889/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f766964696a75735061727369756e61732f6d79766973696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/OvidijusParsiunas/myvision?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Computer vision based ML training data generation tool ðŸš€\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wufan-tb/AutoLabelImg\"\u003ewufan-tb/AutoLabelImg\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/64e224ef08aabd2c4751c8501d17ff7a88a4d5f4bffe825f2911e71708fc4202/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f777566616e2d74622f4175746f4c6162656c496d673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/64e224ef08aabd2c4751c8501d17ff7a88a4d5f4bffe825f2911e71708fc4202/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f777566616e2d74622f4175746f4c6162656c496d673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wufan-tb/AutoLabelImg?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : auto-labelimg based on yolov5, with many other useful tools. AutoLabelImg å¤šåŠŸèƒ½è‡ªåŠ¨æ ‡æ³¨å·¥å…·ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MrZander/YoloMarkNet\"\u003eMrZander/YoloMarkNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/07165a8ff9ed22800e62d4daee320cd0cdc47eb042819a83874dbcd99a0ee65f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d725a616e6465722f596f6c6f4d61726b4e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/07165a8ff9ed22800e62d4daee320cd0cdc47eb042819a83874dbcd99a0ee65f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d725a616e6465722f596f6c6f4d61726b4e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MrZander/YoloMarkNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Darknet YOLOv2/3 annotation tool written in C#/WPF.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mahxn0/Yolov3_ForTextLabel\"\u003emahxn0/Yolov3_ForTextLabel\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/50610f6ad79c28ba605e629e99e947f38b8bd2d7a7e3916b66f71e19a4eb0f1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6168786e302f596f6c6f76335f466f72546578744c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/50610f6ad79c28ba605e629e99e947f38b8bd2d7a7e3916b66f71e19a4eb0f1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6168786e302f596f6c6f76335f466f72546578744c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mahxn0/Yolov3_ForTextLabel?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽyolov3çš„ç›®æ ‡/è‡ªç„¶åœºæ™¯æ–‡å­—è‡ªåŠ¨æ ‡æ³¨å·¥å…·ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MNConnor/YoloV5-AI-Label\"\u003eMNConnor/YoloV5-AI-Label\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bae30cda23e2451058ec7422d8233aab8a4ef55d7e8c108bd329e7511fbdb7aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d4e436f6e6e6f722f596f6c6f56352d41492d4c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bae30cda23e2451058ec7422d8233aab8a4ef55d7e8c108bd329e7511fbdb7aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d4e436f6e6e6f722f596f6c6f56352d41492d4c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MNConnor/YoloV5-AI-Label?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV5 AI Assisted Labeling.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LILINOpenGitHub/Labeling-Tool\"\u003eLILINOpenGitHub/Labeling-Tool\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0dda3d9021bae83c1599227cba107851e7fca8ed66964b0409228ebf9925507a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c494c494e4f70656e4769744875622f4c6162656c696e672d546f6f6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0dda3d9021bae83c1599227cba107851e7fca8ed66964b0409228ebf9925507a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c494c494e4f70656e4769744875622f4c6162656c696e672d546f6f6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LILINOpenGitHub/Labeling-Tool?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Free YOLO AI labeling tool. YOLO AI labeling tool is a Windows app for labeling YOLO dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/whs0523003/YOLOv5_6.1_autolabel\"\u003ewhs0523003/YOLOv5_6.1_autolabel\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5945d2dd0cf857c10634ff50faf0a6fa29fab0229b0e836b63142bb5c2b084e8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776873303532333030332f594f4c4f76355f362e315f6175746f6c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5945d2dd0cf857c10634ff50faf0a6fa29fab0229b0e836b63142bb5c2b084e8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776873303532333030332f594f4c4f76355f362e315f6175746f6c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/whs0523003/YOLOv5_6.1_autolabel?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5_6.1 è‡ªåŠ¨æ ‡è®°ç›®æ ‡æ¡†ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/2vin/PyYAT\"\u003e2vin/PyYAT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c7e1064e7dd50959690eef4f38f1d4749dbc5aa325696511fb5a1c72a133073c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3276696e2f50795941543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c7e1064e7dd50959690eef4f38f1d4749dbc5aa325696511fb5a1c72a133073c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3276696e2f50795941543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/2vin/PyYAT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Semi-Automatic Yolo Annotation Tool In Python.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlturosDestinations/Alturos.ImageAnnotation\"\u003eAlturosDestinations/Alturos.ImageAnnotation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b6ba89fc7367ee013a360cdc8eaa6c1c379243f52450f81df24188e7ed826e92/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c7475726f7344657374696e6174696f6e732f416c7475726f732e496d616765416e6e6f746174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b6ba89fc7367ee013a360cdc8eaa6c1c379243f52450f81df24188e7ed826e92/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c7475726f7344657374696e6174696f6e732f416c7475726f732e496d616765416e6e6f746174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlturosDestinations/Alturos.ImageAnnotation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A collaborative tool for labeling image data for yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/stephanecharette/DarkMark\"\u003estephanecharette/DarkMark\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fd2bd5cfcdb3e964e498f8dc1989a07abccac0d267e0f362358a8ae32516fa0f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374657068616e6563686172657474652f4461726b4d61726b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fd2bd5cfcdb3e964e498f8dc1989a07abccac0d267e0f362358a8ae32516fa0f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374657068616e6563686172657474652f4461726b4d61726b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/stephanecharette/DarkMark?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Marking up images for use with Darknet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/2vin/yolo_annotation_tool\"\u003e2vin/yolo_annotation_tool\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8fac3b71b05b60c41d0fc33d10f11fa87124cd2f34af81cd74c00726646a14c6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3276696e2f796f6c6f5f616e6e6f746174696f6e5f746f6f6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8fac3b71b05b60c41d0fc33d10f11fa87124cd2f34af81cd74c00726646a14c6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3276696e2f796f6c6f5f616e6e6f746174696f6e5f746f6f6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/2vin/yolo_annotation_tool?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Annotation tool for YOLO in opencv.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sanfooh/quick_yolo2_label_tool\"\u003esanfooh/quick_yolo2_label_tool\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/601f50b57a84009341cc6308ee832f54eb3e6b6f2feda6bfc4cf9bb8b10525b2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73616e666f6f682f717569636b5f796f6c6f325f6c6162656c5f746f6f6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/601f50b57a84009341cc6308ee832f54eb3e6b6f2feda6bfc4cf9bb8b10525b2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73616e666f6f682f717569636b5f796f6c6f325f6c6162656c5f746f6f6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sanfooh/quick_yolo2_label_tool?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yoloå¿«é€Ÿæ ‡æ³¨å·¥å…· quick yolo2 label tool.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/folkien/yaya\"\u003efolkien/yaya\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a1a5789fd999eac0555317afe1e759db4bf040f715e39e1fbc84f27b931ad01a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666f6c6b69656e2f796179613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a1a5789fd999eac0555317afe1e759db4bf040f715e39e1fbc84f27b931ad01a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666f6c6b69656e2f796179613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/folkien/yaya?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YAYA - Yet annother YOLO annoter for images (in QT5). Support yolo format, image modifications, labeling and detecting with previously trained detector.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pylabel-project/pylabel\"\u003epylabel-project/pylabel\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2391c03e201ec8104ea2aa1b0ef63f6dc5c4818c99c2f9527698a7556db39c09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70796c6162656c2d70726f6a6563742f70796c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2391c03e201ec8104ea2aa1b0ef63f6dc5c4818c99c2f9527698a7556db39c09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70796c6162656c2d70726f6a6563742f70796c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pylabel-project/pylabel?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Python library for computer vision labeling tasks. The core functionality is to translate bounding box annotations between different formats-for example, from coco to yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/opendatalab/labelU\"\u003eopendatalab/labelU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ef37844fb33e54c59b70a193bdb2d3c2afff71b26eb40d3fc8db53abba609e7a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e646174616c61622f6c6162656c553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ef37844fb33e54c59b70a193bdb2d3c2afff71b26eb40d3fc8db53abba609e7a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e646174616c61622f6c6162656c553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/opendatalab/labelU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Uniform, Unlimited, Universal and Unbelievable Annotation Toolbox.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFeature Map Visualization\u003c/h3\u003e\u003ca id=\"user-content-feature-map-visualization\" class=\"anchor\" aria-label=\"Permalink: Feature Map Visualization\" href=\"#feature-map-visualization\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eç‰¹å¾å›¾å¯è§†åŒ–\u003c/h4\u003e\u003ca id=\"user-content-ç‰¹å¾å›¾å¯è§†åŒ–\" class=\"anchor\" aria-label=\"Permalink: ç‰¹å¾å›¾å¯è§†åŒ–\" href=\"#ç‰¹å¾å›¾å¯è§†åŒ–\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pooya-mohammadi/yolov5-gradcam\"\u003epooya-mohammadi/yolov5-gradcam\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4280d20ac758753bf41b1122f5ba2946864bb8faca55530b607cdd0fc298bca8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706f6f79612d6d6f68616d6d6164692f796f6c6f76352d6772616463616d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4280d20ac758753bf41b1122f5ba2946864bb8faca55530b607cdd0fc298bca8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706f6f79612d6d6f68616d6d6164692f796f6c6f76352d6772616463616d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pooya-mohammadi/yolov5-gradcam?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Visualizing Yolov5's layers using GradCam.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/frgfm/torch-cam\"\u003eTorchCAM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/343e418944612501d28790632747a51a2b043a79f11c7816915a117ca2923fce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f667267666d2f746f7263682d63616d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/343e418944612501d28790632747a51a2b043a79f11c7816915a117ca2923fce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f667267666d2f746f7263682d63616d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/frgfm/torch-cam?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Class activation maps for your PyTorch models (CAM, Grad-CAM, Grad-CAM++, Smooth Grad-CAM++, Score-CAM, SS-CAM, IS-CAM, XGrad-CAM, Layer-CAM).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Him-wen/OD_Heatmap\"\u003eHim-wen/OD_Heatmap\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fa5b6a628d2b611fc7202190c85c783536f0d6d1cd8cf91c8e53047e819c82e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48696d2d77656e2f4f445f486561746d61703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fa5b6a628d2b611fc7202190c85c783536f0d6d1cd8cf91c8e53047e819c82e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48696d2d77656e2f4f445f486561746d61703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Him-wen/OD_Heatmap?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Heatmap visualization of the YOLO model using the Grad-CAM heatmap visualization method can Intuitively show which regions in the image contribute the most to the category classification.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eObject Detection Evaluation Metrics\u003c/h3\u003e\u003ca id=\"user-content-object-detection-evaluation-metrics\" class=\"anchor\" aria-label=\"Permalink: Object Detection Evaluation Metrics\" href=\"#object-detection-evaluation-metrics\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eç›®æ ‡æ£€æµ‹æ€§èƒ½è¯„ä»·æŒ‡æ ‡\u003c/h4\u003e\u003ca id=\"user-content-ç›®æ ‡æ£€æµ‹æ€§èƒ½è¯„ä»·æŒ‡æ ‡\" class=\"anchor\" aria-label=\"Permalink: ç›®æ ‡æ£€æµ‹æ€§èƒ½è¯„ä»·æŒ‡æ ‡\" href=\"#ç›®æ ‡æ£€æµ‹æ€§èƒ½è¯„ä»·æŒ‡æ ‡\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/rafaelpadilla/review_object_detection_metrics\"\u003erafaelpadilla/review_object_detection_metrics\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/72c5af5a8d6ea2585a8cc5339b472d8be149b51f0ba8d1d02ae07150c1f5295f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616661656c706164696c6c612f7265766965775f6f626a6563745f646574656374696f6e5f6d6574726963733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/72c5af5a8d6ea2585a8cc5339b472d8be149b51f0ba8d1d02ae07150c1f5295f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616661656c706164696c6c612f7265766965775f6f626a6563745f646574656374696f6e5f6d6574726963733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/rafaelpadilla/review_object_detection_metrics?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object Detection Metrics. 14 object detection metrics: mean Average Precision (mAP), Average Recall (AR), Spatio-Temporal Tube Average Precision (STT-AP). This project supports different bounding box formats as in COCO, PASCAL, Imagenet, etc. \"A Comparative Analysis of Object Detection Metrics with a Companion Open-Source Toolkit\".  (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/2079-9292/10/3/279\" rel=\"nofollow\"\u003eElectronics 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/rafaelpadilla/Object-Detection-Metrics\"\u003erafaelpadilla/Object-Detection-Metrics\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/288b240195b3187c5e918dff44ced4c4198bbbe3a7dd25cb1655626499fcc709/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616661656c706164696c6c612f4f626a6563742d446574656374696f6e2d4d6574726963733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/288b240195b3187c5e918dff44ced4c4198bbbe3a7dd25cb1655626499fcc709/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616661656c706164696c6c612f4f626a6563742d446574656374696f6e2d4d6574726963733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/rafaelpadilla/Object-Detection-Metrics?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Most popular metrics used to evaluate object detection algorithms. \"A Survey on Performance Metrics for Object-Detection Algorithms\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9145130\" rel=\"nofollow\"\u003eIWSSIP 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Cartucho/mAP\"\u003eCartucho/mAP\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e5c472db7996cbd6f7491434e869dc238447a7f6e57d77e13f3720422874a7de/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436172747563686f2f6d41503f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e5c472db7996cbd6f7491434e869dc238447a7f6e57d77e13f3720422874a7de/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436172747563686f2f6d41503f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Cartucho/mAP?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : mean Average Precision - This code evaluates the performance of your neural net for object recognition.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Lightning-AI/metrics\"\u003eLightning-AI/metrics\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3ccd58b7fa845dbc809c0278dd4fb6831fe22660295b1970a3c38276f6b8e8e0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696768746e696e672d41492f6d6574726963733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3ccd58b7fa845dbc809c0278dd4fb6831fe22660295b1970a3c38276f6b8e8e0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696768746e696e672d41492f6d6574726963733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Lightning-AI/metrics?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Machine learning metrics for distributed, scalable PyTorch applications.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/open-mmlab/mmeval\"\u003eopen-mmlab/mmeval\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0ec53f35460e784a3e09c893e449962c7fd4d25e06d6e28b6dfced6d95fdb2f6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d6d6d6c61622f6d6d6576616c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0ec53f35460e784a3e09c893e449962c7fd4d25e06d6e28b6dfced6d95fdb2f6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d6d6d6c61622f6d6d6576616c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/open-mmlab/mmeval?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : MMEval is a machine learning evaluation library that supports efficient and accurate distributed evaluation on a variety of machine learning frameworks.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/laclouis5/globox\"\u003elaclouis5/globox\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/16ab043da9897ec27d25062862d1ad170320751ef6f0767cabab61de07fc0096/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c61636c6f756973352f676c6f626f783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/16ab043da9897ec27d25062862d1ad170320751ef6f0767cabab61de07fc0096/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c61636c6f756973352f676c6f626f783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/laclouis5/globox?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A package to read and convert object detection databases (COCO, YOLO, PascalVOC, LabelMe, CVAT, OpenImage, ...) and evaluate them with COCO and PascalVOC metrics.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eGUI\u003c/h3\u003e\u003ca id=\"user-content-gui\" class=\"anchor\" aria-label=\"Permalink: GUI\" href=\"#gui\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eå›¾å½¢ç”¨æˆ·ç•Œé¢\u003c/h4\u003e\u003ca id=\"user-content-å›¾å½¢ç”¨æˆ·ç•Œé¢\" class=\"anchor\" aria-label=\"Permalink: å›¾å½¢ç”¨æˆ·ç•Œé¢\" href=\"#å›¾å½¢ç”¨æˆ·ç•Œé¢\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSwift-Related\u003c/h4\u003e\u003ca id=\"user-content-swift-related\" class=\"anchor\" aria-label=\"Permalink: Swift-Related\" href=\"#swift-related\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/ultralytics/yolo-ios-app\"\u003eultralytics/yolo-ios-app\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5333c8ce4ac7b23fa150a485831fd6290a792294be97ae8a430797460fbd0797/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f796f6c6f2d696f732d6170703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5333c8ce4ac7b23fa150a485831fd6290a792294be97ae8a430797460fbd0797/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f796f6c6f2d696f732d6170703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ultralytics/yolo-ios-app?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Ultralytics YOLO iOS App source code for running YOLOv8 in your own iOS apps ðŸŒŸ. \u003ca href=\"https://ultralytics.com/yolo\" rel=\"nofollow\"\u003eultralytics.com/yolo\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFlutter-Related\u003c/h4\u003e\u003ca id=\"user-content-flutter-related\" class=\"anchor\" aria-label=\"Permalink: Flutter-Related\" href=\"#flutter-related\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ultralytics/yolo-flutter-app\"\u003eultralytics/yolo-flutter-app\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/09b40faa2198c739a1365a4e510f03b642325a22f1454d0c494f84ae217c34ed/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f796f6c6f2d666c75747465722d6170703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/09b40faa2198c739a1365a4e510f03b642325a22f1454d0c494f84ae217c34ed/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f796f6c6f2d666c75747465722d6170703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ultralytics/yolo-flutter-app?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Flutter plugin for Ultralytics YOLO computer vision models. \u003ca href=\"https://ultralytics.com/\" rel=\"nofollow\"\u003eultralytics.com\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hiennguyen92/flutter_realtime_object_detection\"\u003ehiennguyen92/flutter_realtime_object_detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/933f531f6eab2ccd02343cd44baf9d8503c609ffad56b882c6e7002b9bc4bdfa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6869656e6e677579656e39322f666c75747465725f7265616c74696d655f6f626a6563745f646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/933f531f6eab2ccd02343cd44baf9d8503c609ffad56b882c6e7002b9bc4bdfa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6869656e6e677579656e39322f666c75747465725f7265616c74696d655f6f626a6563745f646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hiennguyen92/flutter_realtime_object_detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Flutter App real-time object detection with Tensorflow Lite.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eStreamlit-Related\u003c/h4\u003e\u003ca id=\"user-content-streamlit-related\" class=\"anchor\" aria-label=\"Permalink: Streamlit-Related\" href=\"#streamlit-related\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wjnwjn59/YOLOv10_Streamlit_Demo\"\u003ewjnwjn59/YOLOv10_Streamlit_Demo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/eb1d0c21da997b29fa4bcce71cecf4d64ee73beb24c53f139966ce7c22a517ce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776a6e776a6e35392f594f4c4f7631305f53747265616d6c69745f44656d6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/eb1d0c21da997b29fa4bcce71cecf4d64ee73beb24c53f139966ce7c22a517ce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776a6e776a6e35392f594f4c4f7631305f53747265616d6c69745f44656d6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wjnwjn59/YOLOv10_Streamlit_Demo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A simple object detection web demo using YOLOv10 and Streamlit.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/rampal-punia/yolov8-streamlit-detection-tracking\"\u003erampal-punia/yolov8-streamlit-detection-tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1320069969991236dd98b023a381124201978cd54e70e0077bdf9d90e6549179/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616d70616c2d70756e69612f796f6c6f76382d73747265616d6c69742d646574656374696f6e2d747261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1320069969991236dd98b023a381124201978cd54e70e0077bdf9d90e6549179/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616d70616c2d70756e69612f796f6c6f76382d73747265616d6c69742d646574656374696f6e2d747261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/rampal-punia/yolov8-streamlit-detection-tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object detection and tracking algorithm implemented for Real-Time video streams and static images.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/JackDance/YOLOv8-streamlit-app\"\u003eJackDance/YOLOv8-streamlit-app\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a757a9c757192604ea34a6ab43d77b043c9826699ea6857bca525e5624088fa4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61636b44616e63652f594f4c4f76382d73747265616d6c69742d6170703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a757a9c757192604ea34a6ab43d77b043c9826699ea6857bca525e5624088fa4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61636b44616e63652f594f4c4f76382d73747265616d6c69742d6170703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/JackDance/YOLOv8-streamlit-app?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ”¥ðŸ”¥ðŸ”¥ Use streamlit framework to increase yolov8 front-end page interaction function. \"çŸ¥ä¹Žã€ŒMr.Luyaoã€ã€Š\u003ca href=\"https://zhuanlan.zhihu.com/p/630029493\" rel=\"nofollow\"\u003eæ·±åº¦å­¦ä¹ /æœºå™¨å­¦ä¹ é¡¹ç›®çš„å‰ç«¯å±•ç¤ºåˆ©å™¨--Streamlit\u003c/a\u003eã€‹\"ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/streamlit/demo-self-driving\"\u003estreamlit/demo-self-driving\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e2b9f558f65a83043627968313a89b1bcbf741461c012d074e84037b68a4ff08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73747265616d6c69742f64656d6f2d73656c662d64726976696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e2b9f558f65a83043627968313a89b1bcbf741461c012d074e84037b68a4ff08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73747265616d6c69742f64656d6f2d73656c662d64726976696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/streamlit/demo-self-driving?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Streamlit app demonstrating an image browser for the Udacity self-driving-car dataset with realtime object detection using YOLO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xugaoxiang/yolov5-streamlit\"\u003exugaoxiang/yolov5-streamlit\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/daf01d051fc6e3abb53860ca735e21fe02ebac5aa9421cb53750dadb756770b9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f787567616f7869616e672f796f6c6f76352d73747265616d6c69743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/daf01d051fc6e3abb53860ca735e21fe02ebac5aa9421cb53750dadb756770b9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f787567616f7869616e672f796f6c6f76352d73747265616d6c69743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xugaoxiang/yolov5-streamlit?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Deploy YOLOv5 detection with Streamlit.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Kedreamix/YoloGesture\"\u003eKedreamix/YoloGesture\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/af65a0a770b62802f1c1c56d6da5934a35bbbebe1a7c6407d5c018c5b31f6d6c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b65647265616d69782f596f6c6f476573747572653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/af65a0a770b62802f1c1c56d6da5934a35bbbebe1a7c6407d5c018c5b31f6d6c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b65647265616d69782f596f6c6f476573747572653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Kedreamix/YoloGesture?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽè®¡ç®—æœºè§†è§‰æ‰‹åŠ¿è¯†åˆ«æŽ§åˆ¶ç³»ç»ŸYoLoGesture (åˆ©ç”¨YOLOå®žçŽ°)ï¼Œåˆ©ç”¨yoloè¿›è¡Œæ‰‹åŠ¿è¯†åˆ«çš„æŽ§åˆ¶ç³»ç»Ÿï¼Œæœ€åŽåˆ©ç”¨streamlitè¿›è¡Œäº†éƒ¨ç½²ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eGradio-Related\u003c/h4\u003e\u003ca id=\"user-content-gradio-related\" class=\"anchor\" aria-label=\"Permalink: Gradio-Related\" href=\"#gradio-related\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zyds/yolov5-code\"\u003ezyds/yolov5-code\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/361aa9c52b30699bb408461dcdef61f59bacdc38a087a45dbb091f4a0ab6f146/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a7964732f796f6c6f76352d636f64653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/361aa9c52b30699bb408461dcdef61f59bacdc38a087a45dbb091f4a0ab6f146/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a7964732f796f6c6f76352d636f64653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zyds/yolov5-code?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : æ‰‹æŠŠæ‰‹å¸¦ä½ å®žæˆ˜ YOLOv5ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/KdaiP/yolov8-deepsort-tracking\"\u003eKdaiP/yolov8-deepsort-tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c005849d8f4fd9218aa95643bdd10a8b6784de030f5586a413b1fdc68fa90ef5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b646169502f796f6c6f76382d64656570736f72742d747261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c005849d8f4fd9218aa95643bdd10a8b6784de030f5586a413b1fdc68fa90ef5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b646169502f796f6c6f76382d64656570736f72742d747261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/KdaiP/yolov8-deepsort-tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : opencv+yolov8+deepsortè¡Œäººæ£€æµ‹ä¸Žè·Ÿè¸ª,ä»¥åŠå¯é€‰çš„WebUIç•Œé¢ï¼ˆåŸºäºŽgradioï¼‰ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pengxiang1998/YOLOv8\"\u003epengxiang1998/YOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ff4a7300727ffe15b8d4a5348339056d35a1cfbf722dd9320c5ed5bc1770d457/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70656e677869616e67313939382f594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ff4a7300727ffe15b8d4a5348339056d35a1cfbf722dd9320c5ed5bc1770d457/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70656e677869616e67313939382f594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pengxiang1998/YOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽGradioæ­å»ºçš„YOLOv8ç›®æ ‡æ£€æµ‹æŽ¨ç†éƒ¨ç½²ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eQT-Related\u003c/h4\u003e\u003ca id=\"user-content-qt-related\" class=\"anchor\" aria-label=\"Permalink: QT-Related\" href=\"#qt-related\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ai-trainee/Traffic-Sign-Recognition-PyQt5-YOLOv5-GUI\"\u003eAi-trainee/Traffic-Sign-Recognition-PyQt5-YOLOv5-GUI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/90c72d4f35e2e36b19db9ea449b487cede52d7ca82c29f3f6dddb31914d294c1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41692d747261696e65652f547261666669632d5369676e2d5265636f676e6974696f6e2d50795174352d594f4c4f76352d4755493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/90c72d4f35e2e36b19db9ea449b487cede52d7ca82c29f3f6dddb31914d294c1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41692d747261696e65652f547261666669632d5369676e2d5265636f676e6974696f6e2d50795174352d594f4c4f76352d4755493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ai-trainee/Traffic-Sign-Recognition-PyQt5-YOLOv5-GUI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Road Sign Recognition Project Based on YOLOv5. This is a road sign recognition project based on YOLOv5, developed with a PyQt5 interface, YOLOv5 trained model, and MySQL database. è¿™æ˜¯ä¸€ä¸ªåŸºäºŽYOLOv5ðŸš€çš„é“è·¯æ ‡å¿—è¯†åˆ«ç³»ç»ŸðŸ˜Šï¼Œä½¿ç”¨äº†MySQLæ•°æ®åº“ðŸ’½ï¼ŒPyQt5è¿›è¡Œç•Œé¢è®¾è®¡ðŸŽ¨ï¼ŒPyTorchæ·±åº¦å­¦ä¹ æ¡†æž¶å’ŒTensorRTè¿›è¡ŒåŠ é€Ÿâš¡ï¼ŒåŒæ—¶åŒ…å«äº†CSSæ ·å¼ðŸŒˆã€‚ç³»ç»Ÿç”±äº”ä¸ªä¸»è¦æ¨¡å—ç»„æˆï¼šç³»ç»Ÿç™»å½•æ¨¡å—ðŸ”‘è´Ÿè´£ç”¨æˆ·ç™»é™†ï¼›åˆå§‹åŒ–å‚æ•°æ¨¡å—ðŸ“‹æä¾›YOLOv5æ¨¡åž‹çš„åˆå§‹åŒ–å‚æ•°è®¾ç½®ï¼›æ ‡å¿—è¯†åˆ«æ¨¡å—ðŸ”æ˜¯ç³»ç»Ÿçš„æ ¸å¿ƒï¼Œè´Ÿè´£å¯¹é“è·¯æ ‡å¿—è¿›è¡Œè¯†åˆ«å¹¶å°†ç»“æžœå¯¼å…¥æ•°æ®åº“ï¼›æ•°æ®åº“æ¨¡å—ðŸ’¾åŒ…å«åŸºæœ¬æ•°æ®åº“æ“ä½œå’Œæ•°æ®åˆ†æžä¸¤ä¸ªå­æ¨¡å—ï¼›å›¾åƒå¤„ç†æ¨¡å—ðŸ–¼ï¸è´Ÿè´£å•ä¸ªå›¾åƒçš„å¤„ç†å’Œæ•°æ®å¢žå¼ºã€‚æ•´ä¸ªç³»ç»Ÿæ”¯æŒå¤šç§æ•°æ®è¾“å…¥å’Œæ¨¡åž‹åˆ‡æ¢ï¼Œæä¾›äº†åŒ…æ‹¬mossicå’Œmixupåœ¨å†…çš„å›¾åƒå¢žå¼ºæ–¹æ³•ðŸ“ˆã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/parker-int64/yolov5-RGBD\"\u003eparker-int64/yolov5-RGBD\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b4f59a7411181b368b586f0510047935d6c8d460dad2835209348d7027bf4470/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7061726b65722d696e7436342f796f6c6f76352d524742443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b4f59a7411181b368b586f0510047935d6c8d460dad2835209348d7027bf4470/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7061726b65722d696e7436342f796f6c6f76352d524742443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/parker-int64/yolov5-RGBD?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Qt QML based yolov5 + RGBD camera program.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Aimol-l/qml_with_yolov7\"\u003eAimol-l/qml_with_yolov7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3c720a4d79f454ea5ff8e03cc92d99f6a5a4884e912355997860a8dc44ec5de1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41696d6f6c2d6c2f716d6c5f776974685f796f6c6f76373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3c720a4d79f454ea5ff8e03cc92d99f6a5a4884e912355997860a8dc44ec5de1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41696d6f6c2d6c2f716d6c5f776974685f796f6c6f76373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Aimol-l/qml_with_yolov7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ç”¨YOLOV7+ByteTrackçš„æ–¹æ³•è¯†åˆ«è§†é¢‘/è§†é¢‘æµï¼Œç”¨QMLç»˜åˆ¶GUIï¼Œå¹¶å¸¦æœ‰ç»Ÿè®¡ä¿¡æ¯ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xietx1995/YOLO-QT-Camera-Tool\"\u003exietx1995/YOLO-QT-Camera-Tool\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3c4eb895165d910d35c10e01de4bf3ed0d291fda8502841a719d321ba77776f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869657478313939352f594f4c4f2d51542d43616d6572612d546f6f6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3c4eb895165d910d35c10e01de4bf3ed0d291fda8502841a719d321ba77776f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869657478313939352f594f4c4f2d51542d43616d6572612d546f6f6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xietx1995/YOLO-QT-Camera-Tool?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detecting objects from camera or local video files vi qt and yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Javacr/PyQt5-YOLOv5\"\u003eJavacr/PyQt5-YOLOv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cf8f9263f26e2bdd44644415877a72da13220c6149c405c6384b4af1db3cf1c0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61766163722f50795174352d594f4c4f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cf8f9263f26e2bdd44644415877a72da13220c6149c405c6384b4af1db3cf1c0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61766163722f50795174352d594f4c4f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Javacr/PyQt5-YOLOv5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5æ£€æµ‹ç•Œé¢-PyQt5å®žçŽ°ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zstar1003/yolov5_pyqt5\"\u003ezstar1003/yolov5_pyqt5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e56d87a5a3f958410049541a97308c52a74b4311f7dc4cfdb4096d268ad0f91c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a73746172313030332f796f6c6f76355f70797174353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e56d87a5a3f958410049541a97308c52a74b4311f7dc4cfdb4096d268ad0f91c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a73746172313030332f796f6c6f76355f70797174353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zstar1003/yolov5_pyqt5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨pyqt5æ­å»ºYOLOv5ç›®æ ‡æ£€æµ‹å¯è§†åŒ–ç¨‹åºã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/scutlrr/Yolov4-QtGUI\"\u003escutlrr/Yolov4-QtGUI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/77df3e2fabbd152f621bd8cc41de15fda6d69bea884f1e5e015d13642698f898/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736375746c72722f596f6c6f76342d51744755493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/77df3e2fabbd152f621bd8cc41de15fda6d69bea884f1e5e015d13642698f898/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736375746c72722f596f6c6f76342d51744755493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/scutlrr/Yolov4-QtGUI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov4-QtGUIæ˜¯åŸºäºŽ\u003ca href=\"https://github.com/jmu201521121021/QtGuiDemo\"\u003eQtGuiDemo\u003c/a\u003eé¡¹ç›®å¼€å‘çš„å¯è§†åŒ–ç›®æ ‡æ£€æµ‹ç•Œé¢ï¼Œå¯ä»¥ç®€ä¾¿é€‰æ‹©æœ¬åœ°å›¾ç‰‡ã€æ‘„åƒå¤´æ¥å±•ç¤ºå›¾åƒå¤„ç†ç®—æ³•çš„ç»“æžœã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xugaoxiang/yolov5-pyqt5\"\u003exugaoxiang/yolov5-pyqt5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bc14ea5e9acf7c2b5e1993f203c78c1cfcfdad0f46b8839e4c67eb095e585dd7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f787567616f7869616e672f796f6c6f76352d70797174353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bc14ea5e9acf7c2b5e1993f203c78c1cfcfdad0f46b8839e4c67eb095e585dd7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f787567616f7869616e672f796f6c6f76352d70797174353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xugaoxiang/yolov5-pyqt5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ç»™yolov5åŠ ä¸ªguiç•Œé¢ï¼Œä½¿ç”¨pyqt5ï¼Œyolov5æ˜¯5.0ç‰ˆæœ¬ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mxy493/YOLOv5-Qt\"\u003emxy493/YOLOv5-Qt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/911ef67eff87b76133a2a14c8051043e2e10f6de55e734e4a6d30383e4c4bd64/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d78793439332f594f4c4f76352d51743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/911ef67eff87b76133a2a14c8051043e2e10f6de55e734e4a6d30383e4c4bd64/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d78793439332f594f4c4f76352d51743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mxy493/YOLOv5-Qt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽYOLOv5çš„GUIç¨‹åºï¼Œæ”¯æŒé€‰æ‹©è¦ä½¿ç”¨çš„æƒé‡æ–‡ä»¶ï¼Œè®¾ç½®æ˜¯å¦ä½¿ç”¨GPUï¼Œè®¾ç½®ç½®ä¿¡åº¦é˜ˆå€¼ç­‰å‚æ•°ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BonesCat/YoloV5_PyQt5\"\u003eBonesCat/YoloV5_PyQt5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b4388a60150c7a21d21fd79be0c311b75ffdc8181b5d8f5f4a2f36ba305aa1cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f6e65734361742f596f6c6f56355f50795174353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b4388a60150c7a21d21fd79be0c311b75ffdc8181b5d8f5f4a2f36ba305aa1cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f6e65734361742f596f6c6f56355f50795174353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BonesCat/YoloV5_PyQt5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Add gui for YoloV5 using PyQt5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LuckyBoy1798/yolov5-pyqt\"\u003eLuckyBoy1798/yolov5-pyqt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/36e04c4ae3eda324b1661b652064f7a484d2ae79a95f9bf646242ca1d7d331c3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c75636b79426f79313739382f796f6c6f76352d707971743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/36e04c4ae3eda324b1661b652064f7a484d2ae79a95f9bf646242ca1d7d331c3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c75636b79426f79313739382f796f6c6f76352d707971743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LuckyBoy1798/yolov5-pyqt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽyolov5+pyqtçš„ç”²éª¨æ–‡å›¾å½¢åŒ–æ£€æµ‹å·¥å…·ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PySimpleGUI/PySimpleGUI-YOLO\"\u003ePySimpleGUI/PySimpleGUI-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f02608b7a1765a48a746f61d9dca151220c3360f5fdf819f9b55b17902eda4e0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f507953696d706c654755492f507953696d706c654755492d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f02608b7a1765a48a746f61d9dca151220c3360f5fdf819f9b55b17902eda4e0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f507953696d706c654755492f507953696d706c654755492d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PySimpleGUI/PySimpleGUI-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A YOLO Artificial Intelligence algorithm demonstration using PySimpleGUI.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/prabindh/qt5-opencv3-darknet\"\u003eprabindh/qt5-opencv3-darknet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cdc12557acfa1b796811a6dafbb426f5c822ff80726db63d3e060c302f3e6634/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70726162696e64682f7174352d6f70656e6376332d6461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cdc12557acfa1b796811a6dafbb426f5c822ff80726db63d3e060c302f3e6634/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70726162696e64682f7174352d6f70656e6376332d6461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/prabindh/qt5-opencv3-darknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Qt5 + Darknet/Yolo + OpenCV3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/GinkgoX/YOLOv3GUI_Pytorch_PyQt5\"\u003eGinkgoX/YOLOv3GUI_Pytorch_PyQt5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1f7e32b433168e1ca1dc64e9e2b6a21f06d96b69ea6bc8699db0be5ad9e25829/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f47696e6b676f582f594f4c4f76334755495f5079746f7263685f50795174353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1f7e32b433168e1ca1dc64e9e2b6a21f06d96b69ea6bc8699db0be5ad9e25829/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f47696e6b676f582f594f4c4f76334755495f5079746f7263685f50795174353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/GinkgoX/YOLOv3GUI_Pytorch_PyQt5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a GUI project for Deep Learning Object Detection based on YOLOv3 model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FatemeZamanian/Yolov5-Fruit-Detector\"\u003eFatemeZamanian/Yolov5-Fruit-Detector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/13fe97c3ef673f2f8e7e10e4a3bb8553a2c582993a6c7471d663a95b522b3ba5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f466174656d655a616d616e69616e2f596f6c6f76352d46727569742d4465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/13fe97c3ef673f2f8e7e10e4a3bb8553a2c582993a6c7471d663a95b522b3ba5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f466174656d655a616d616e69616e2f596f6c6f76352d46727569742d4465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FatemeZamanian/Yolov5-Fruit-Detector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A program to recognize fruits on pictures or videos using yolov5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BioMeasure/PyQt5_YoLoV5_DeepSort\"\u003eBioMeasure/PyQt5_YoLoV5_DeepSort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/575061dcb9b5ddcee79840d67aa997851d173a49cd0e80948c3e44a29114df7f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42696f4d6561737572652f50795174355f596f4c6f56355f44656570536f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/575061dcb9b5ddcee79840d67aa997851d173a49cd0e80948c3e44a29114df7f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42696f4d6561737572652f50795174355f596f4c6f56355f44656570536f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BioMeasure/PyQt5_YoLoV5_DeepSort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a PyQt5 GUI program, which is based on YoloV5 and DeepSort to track person.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DongLizhong/YOLO_SORT_QT\"\u003eDongLizhong/YOLO_SORT_QT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/981c2bbf5998a6e0d49a92ef86600b2cdad87190a264e44023282cff7fc9d670/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f446f6e674c697a686f6e672f594f4c4f5f534f52545f51543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/981c2bbf5998a6e0d49a92ef86600b2cdad87190a264e44023282cff7fc9d670/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f446f6e674c697a686f6e672f594f4c4f5f534f52545f51543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DongLizhong/YOLO_SORT_QT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This code uses the opencv dnn module to load the darknet model for detection and add SORT for multi-object tracking(MOT).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Whu-wxy/yolov5_deepsort_ncnn_qt\"\u003eWhu-wxy/yolov5_deepsort_ncnn_qt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b05eaf831a1579281d1f71a43e3c0fe7a2565ee9e9b6d9fd522a4529f16bfe0c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5768752d7778792f796f6c6f76355f64656570736f72745f6e636e6e5f71743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b05eaf831a1579281d1f71a43e3c0fe7a2565ee9e9b6d9fd522a4529f16bfe0c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5768752d7778792f796f6c6f76355f64656570736f72745f6e636e6e5f71743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Whu-wxy/yolov5_deepsort_ncnn_qt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ç”¨ncnnè°ƒç”¨yolov5å’Œdeep sortæ¨¡åž‹ï¼Œopencvè¯»å–è§†é¢‘ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jeswanthgalla/PyQt4_GUI_darknet_yolov4\"\u003ejeswanthgalla/PyQt4_GUI_darknet_yolov4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bc3abd85b4e7b0a11798cf0bd77564672233de1f3c14a2ea21496b9477873377/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a657377616e746867616c6c612f50795174345f4755495f6461726b6e65745f796f6c6f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bc3abd85b4e7b0a11798cf0bd77564672233de1f3c14a2ea21496b9477873377/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a657377616e746867616c6c612f50795174345f4755495f6461726b6e65745f796f6c6f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jeswanthgalla/PyQt4_GUI_darknet_yolov4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : GUI App using PyQt4. Multithreading to process multiple camera streams and using darknet yolov4 model for object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/barleo01/yoloobjectdetector\"\u003ebarleo01/yoloobjectdetector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/544415cc147fff06d50c8910b8e53cc0a472b32e0997e9d366ee00e38c73cb6b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6261726c656f30312f796f6c6f6f626a6563746465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/544415cc147fff06d50c8910b8e53cc0a472b32e0997e9d366ee00e38c73cb6b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6261726c656f30312f796f6c6f6f626a6563746465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/barleo01/yoloobjectdetector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The pupose of this application is to capture video from a camera, apply a YOLO Object detector and display it on a simple Qt Gui.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Eagle104fred/PyQt5-Yolov5\"\u003eEagle104fred/PyQt5-Yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/165ba40d3b12cdeb26c0b7a7824a601e078a275dc6d9e16b1c137370840919e6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4561676c65313034667265642f50795174352d596f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/165ba40d3b12cdeb26c0b7a7824a601e078a275dc6d9e16b1c137370840919e6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4561676c65313034667265642f50795174352d596f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Eagle104fred/PyQt5-Yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : æŠŠYOLOv5çš„è§†é¢‘æ˜¾ç¤ºåˆ°pyqt5uiä¸Šã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cnyvfang/YOLOv5-GUI\"\u003ecnyvfang/YOLOv5-GUI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/165ba40d3b12cdeb26c0b7a7824a601e078a275dc6d9e16b1c137370840919e6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4561676c65313034667265642f50795174352d596f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/165ba40d3b12cdeb26c0b7a7824a601e078a275dc6d9e16b1c137370840919e6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4561676c65313034667265642f50795174352d596f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Eagle104fred/PyQt5-Yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Qt-GUI implementation of the YOLOv5 algorithm (ver.6 and ver.5). YOLOv5ç®—æ³•(ver.6åŠver.5)çš„Qt-GUIå®žçŽ°ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WeNN-Artificial-Intelligence/PyQT-Object-Detection-App\"\u003eWeNN-Artificial-Intelligence/PyQT-Object-Detection-App\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c4014cb862714b96e82097e8cd853ffe01beb6763b578ae3727ff88b5e017577/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57654e4e2d4172746966696369616c2d496e74656c6c6967656e63652f507951542d4f626a6563742d446574656374696f6e2d4170703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c4014cb862714b96e82097e8cd853ffe01beb6763b578ae3727ff88b5e017577/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57654e4e2d4172746966696369616c2d496e74656c6c6967656e63652f507951542d4f626a6563742d446574656374696f6e2d4170703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WeNN-Artificial-Intelligence/PyQT-Object-Detection-App?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time object detection app with Python and PyQt framework.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Powercube7/YOLOv5-GUI\"\u003ePowercube7/YOLOv5-GUI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f699018c15f74f1636617b24e22b60bec319c4c1147189d3e114ba78d30d0406/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506f77657263756265372f594f4c4f76352d4755493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f699018c15f74f1636617b24e22b60bec319c4c1147189d3e114ba78d30d0406/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506f77657263756265372f594f4c4f76352d4755493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Powercube7/YOLOv5-GUI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A simple GUI made for creating jobs in YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cdmstrong/yolov5-pyqt-moke\"\u003ecdmstrong/yolov5-pyqt-moke\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4c4f72881a04e478a5a8ccd0bcbe578a3a2217d0d2ef5237966190b59f54a398/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63646d7374726f6e672f796f6c6f76352d707971742d6d6f6b653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4c4f72881a04e478a5a8ccd0bcbe578a3a2217d0d2ef5237966190b59f54a398/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63646d7374726f6e672f796f6c6f76352d707971742d6d6f6b653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cdmstrong/yolov5-pyqt-moke?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åˆ©ç”¨yolov5å’Œpyqtåšå¯è§†åŒ–æ£€æµ‹ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/GHigher12/Pyqt5_yolov5_unet_centernet\"\u003eGHigher12/Pyqt5_yolov5_unet_centernet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/34554f50d8cd5943e433e2986c3e74012638bd30e06e9262f874072bb7d1acab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4748696768657231322f50797174355f796f6c6f76355f756e65745f63656e7465726e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/34554f50d8cd5943e433e2986c3e74012638bd30e06e9262f874072bb7d1acab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4748696768657231322f50797174355f796f6c6f76355f756e65745f63656e7465726e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/GHigher12/Pyqt5_yolov5_unet_centernet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : é›†yolov5ã€centernetã€unetç®—æ³•çš„pyqt5ç•Œé¢ï¼Œå¯å®žçŽ°å›¾ç‰‡ç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/chenanga/qt5_yolov5_2.0\"\u003echenanga/qt5_yolov5_2.0\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/81b4d785a1cb00ec600f366ce3ef7eb1b95dc2fa42a123de2fc90cfb2879a4a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368656e616e67612f7174355f796f6c6f76355f322e303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/81b4d785a1cb00ec600f366ce3ef7eb1b95dc2fa42a123de2fc90cfb2879a4a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368656e616e67612f7174355f796f6c6f76355f322e303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/chenanga/qt5_yolov5_2.0?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Pyqtæ­å»ºYOLOV5ç›®æ ‡æ£€æµ‹ç•Œé¢-ç¬¬ä¸€æ¬¡ä¼˜åŒ–åŽçš„ç‰ˆæœ¬ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xun-xh/yolov5-onnx-pyqt-exe\"\u003exun-xh/yolov5-onnx-pyqt-exe\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/552bc5c60fd9c33b9ecf36ab73c350c5f1392f4bdd41bac047019adfb5b5ac91/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78756e2d78682f796f6c6f76352d6f6e6e782d707971742d6578653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/552bc5c60fd9c33b9ecf36ab73c350c5f1392f4bdd41bac047019adfb5b5ac91/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78756e2d78682f796f6c6f76352d6f6e6e782d707971742d6578653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xun-xh/yolov5-onnx-pyqt-exe?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽYolov5 + PyQt5 + onnxruntimeçš„ç›®æ ‡æ£€æµ‹éƒ¨ç½²ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LPC1616/pyqt-yolox-modbus\"\u003eLPC1616/pyqt-yolox-modbus\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d4f39f337c8d15f98fbf31a3ad075985896e3f3e42c1e34a13ffaf7cd245f85e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5043313631362f707971742d796f6c6f782d6d6f646275733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d4f39f337c8d15f98fbf31a3ad075985896e3f3e42c1e34a13ffaf7cd245f85e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5043313631362f707971742d796f6c6f782d6d6f646275733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LPC1616/pyqt-yolox-modbus?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : qtç•Œé¢+yoloxè¯†åˆ«ç®—æ³•+modbusé€šä¿¡ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zawawiAI/yolo_gpt\"\u003ezawawiAI/yolo_gpt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/785e5615ec6b71780e684c109c5a9966cc4ff4b67a3d9b826c663837bb14b89e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a617761776941492f796f6c6f5f6770743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/785e5615ec6b71780e684c109c5a9966cc4ff4b67a3d9b826c663837bb14b89e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a617761776941492f796f6c6f5f6770743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zawawiAI/yolo_gpt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a GUI application that integrates YOLOv8 object recognition with OpenAI's GPT-3 language generation model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LSH9832/yolov5_training_tool\"\u003eLSH9832/yolov5_training_tool\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/123a004edf8e8900de9b462da4caa92b9e6c4b7dbfe6d36d183f610fc5e13d09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5348393833322f796f6c6f76355f747261696e696e675f746f6f6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/123a004edf8e8900de9b462da4caa92b9e6c4b7dbfe6d36d183f610fc5e13d09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5348393833322f796f6c6f76355f747261696e696e675f746f6f6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LSH9832/yolov5_training_tool?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : æœ¬å·¥å…·ä½¿ç”¨PYQT5ç¼–å†™ç•Œé¢ã€‚é€šè¿‡ä½¿ç”¨è¯¥å·¥å…·å¯ä»¥å¿«é€Ÿéƒ¨ç½²ç›¸åº”æ•°æ®é›†å¹¶è®­ç»ƒï¼Œç›®å‰ä»åœ¨ä¸æ–­æ›´æ–°ä¸­ï¼Œè¾ƒå¤§çš„ç¼ºç‚¹æ˜¯ç›®å‰åªæ”¯æŒPascalVOCæ ¼å¼çš„xmlæ ‡ç­¾æ–‡ä»¶ï¼Œæ‰€ä»¥å…¶å®ƒæ ¼å¼çš„æ ‡ç­¾æ–‡ä»¶éœ€è¦å…ˆè½¬æ¢ä¸ºPascalVOCçš„æ ¼å¼ï¼Œä¸”ç›®å‰ä»…é€‚ç”¨äºŽLinuxç³»ç»Ÿä¸”ä»…åœ¨Ubuntu16.04-20.04è¯•è¿è¡Œã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Egrt/YOLO_PyQt5\"\u003eEgrt/YOLO_PyQt5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/08ef6e58b284c7a3616bf928c96cb13bf3d17e26e4b53122b827e655b9a0728b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f456772742f594f4c4f5f50795174353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/08ef6e58b284c7a3616bf928c96cb13bf3d17e26e4b53122b827e655b9a0728b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f456772742f594f4c4f5f50795174353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Egrt/YOLO_PyQt5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä½¿ç”¨Pyqt5æ­å»ºYOLOç³»åˆ—å¤šçº¿ç¨‹ç›®æ ‡æ£€æµ‹ç³»ç»Ÿã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/smartwj/yolov5_pyqt5\"\u003esmartwj/yolov5_pyqt5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9111128202282a000fac12ffa73b55640f278bacf957ccc1c8ca6a08c09fad8f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736d617274776a2f796f6c6f76355f70797174353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9111128202282a000fac12ffa73b55640f278bacf957ccc1c8ca6a08c09fad8f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736d617274776a2f796f6c6f76355f70797174353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/smartwj/yolov5_pyqt5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽyolov5çš„pyqt5ç›®æ ‡æ£€æµ‹å›¾å½¢ä¸Šä½æœºå·¥å…·ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LitChi-bit/YOLOv5-6.0-GUI\"\u003eLitChi-bit/YOLOv5-6.0-GUI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/72c7cd57866dc63ca1f2172c29096ab5752e03554d06ddea75882f8bd147cabf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c69744368692d6269742f594f4c4f76352d362e302d4755493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/72c7cd57866dc63ca1f2172c29096ab5752e03554d06ddea75882f8bd147cabf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c69744368692d6269742f594f4c4f76352d362e302d4755493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LitChi-bit/YOLOv5-6.0-GUI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Qt-GUI implementation of the YOLOv5 algorithm (ver.6).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BraunGe/YOLOv5-GUI\"\u003eBraunGe/YOLOv5-GUI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2fbf973c6367b0291388fed409b60c2ec0a9637fd7330e62211430e60df26aab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427261756e47652f594f4c4f76352d4755493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2fbf973c6367b0291388fed409b60c2ec0a9637fd7330e62211430e60df26aab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427261756e47652f594f4c4f76352d4755493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BraunGe/YOLOv5-GUI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A GUI for YOLOv5, support all the 11 inference formats that YOLOv5 supports.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PetervanLunteren/EcoAssist\"\u003ePetervanLunteren/EcoAssist\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f6e2f88deea7c02dde4dbac83fd123be491d1842567d7a6df50a07be9b9c01dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506574657276616e4c756e746572656e2f45636f4173736973743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f6e2f88deea7c02dde4dbac83fd123be491d1842567d7a6df50a07be9b9c01dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506574657276616e4c756e746572656e2f45636f4173736973743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PetervanLunteren/EcoAssist?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A no-code platform to train and deploy YOLOv5 object detection models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SwimmingLiu/yolov7-Pyside6\"\u003eSwimmingLiu/yolov7-Pyside6\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1dcfae108facc90f77d442aa7a8667aa617ae8634167dcaf7ca78a9e492cd21f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5377696d6d696e674c69752f796f6c6f76372d507973696465363f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1dcfae108facc90f77d442aa7a8667aa617ae8634167dcaf7ca78a9e492cd21f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5377696d6d696e674c69752f796f6c6f76372d507973696465363f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SwimmingLiu/yolov7-Pyside6?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PySide6 implementation of YOLOv7 GUI.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003ePySide-Related\u003c/h4\u003e\u003ca id=\"user-content-pyside-related\" class=\"anchor\" aria-label=\"Permalink: PySide-Related\" href=\"#pyside-related\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SwimmingLiu/YOLOSHOW\"\u003eJSwimmingLiu/YOLOSHOW\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7ad503e07c06579484af1c7bcdf461059d2c47b44f8815f81f489a95867c5e37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5377696d6d696e674c69752f594f4c4f53484f573f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7ad503e07c06579484af1c7bcdf461059d2c47b44f8815f81f489a95867c5e37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5377696d6d696e674c69752f594f4c4f53484f573f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SwimmingLiu/YOLOSHOW?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO SHOW - YOLOv10 / YOLOv9 / YOLOv8 / YOLOv7 / YOLOv5 / RTDETR GUI based on Pyside6.\u003ca href=\"https://swimmingliu.cn/posts/diary/yoloshow\" rel=\"nofollow\"\u003eswimmingliu.cn/posts/diary/yoloshow\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Jai-wei/YOLOv8-PySide6-GUI\"\u003eJai-wei/YOLOv8-PySide6-GUI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a8acc19dc6e5898555fc945e84f002fae86a5022cec9360ca59b253579d8ed43/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61692d7765692f594f4c4f76382d507953696465362d4755493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a8acc19dc6e5898555fc945e84f002fae86a5022cec9360ca59b253579d8ed43/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61692d7765692f594f4c4f76382d507953696465362d4755493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Jai-wei/YOLOv8-PySide6-GUI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloSide - YOLOv8 GUI By PySide6.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOther Applications\u003c/h3\u003e\u003ca id=\"user-content-other-applications\" class=\"anchor\" aria-label=\"Permalink: Other Applications\" href=\"#other-applications\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eå…¶å®ƒåº”ç”¨\u003c/h4\u003e\u003ca id=\"user-content-å…¶å®ƒåº”ç”¨\" class=\"anchor\" aria-label=\"Permalink: å…¶å®ƒåº”ç”¨\" href=\"#å…¶å®ƒåº”ç”¨\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ikomia-dev/IkomiaApi\"\u003eIkomia-dev/IkomiaApi\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3977064d5ec1c7cdcec9c1ca1fd2557e614e209ee8cfe06eb817189fce43f3d2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f496b6f6d69612d6465762f496b6f6d69614170693f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3977064d5ec1c7cdcec9c1ca1fd2557e614e209ee8cfe06eb817189fce43f3d2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f496b6f6d69612d6465762f496b6f6d69614170693f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ikomia-dev/IkomiaApi?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : State-of-the-art algorithms in Computer Vision with a few lines of code.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/penny4860/Yolo-digit-detector\"\u003epenny4860/Yolo-digit-detector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/21dcacbdc0238fa1e64ffd10e75e170ccbbf43e72e2cb0ac609952c3ad8d86a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70656e6e79343836302f596f6c6f2d64696769742d6465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/21dcacbdc0238fa1e64ffd10e75e170ccbbf43e72e2cb0ac609952c3ad8d86a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70656e6e79343836302f596f6c6f2d64696769742d6465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/penny4860/Yolo-digit-detector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Implemented digit detector in natural scene using resnet50 and Yolo-v2. I used SVHN as the training set, and implemented it using tensorflow and keras.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/chineseocr/table-detect\"\u003echineseocr/table-detect\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/492e6efe4313020e7c6f7de8ec2020ee49e29d3fb561d69084e503cc70a4b236/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368696e6573656f63722f7461626c652d6465746563743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/492e6efe4313020e7c6f7de8ec2020ee49e29d3fb561d69084e503cc70a4b236/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368696e6573656f63722f7461626c652d6465746563743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/chineseocr/table-detect?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : table detect(yolo) , table line(unet) ï¼ˆè¡¨æ ¼æ£€æµ‹/è¡¨æ ¼å•å…ƒæ ¼å®šä½ï¼‰ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/thisiszhou/SexyYolo\"\u003ethisiszhou/SexyYolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/32fc9ab6d1f6ed5c777d7515de9e1290e442d3bdeae4a79ce9d3d2c759df4d4c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7468697369737a686f752f53657879596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/32fc9ab6d1f6ed5c777d7515de9e1290e442d3bdeae4a79ce9d3d2c759df4d4c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7468697369737a686f752f53657879596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/thisiszhou/SexyYolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An implementation of Yolov3 with Tensorflow1.x, which could detect COCO and sexy or porn person simultaneously.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/javirk/Person_remover\"\u003ejavirk/Person_remover\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3a850b9f0aeaa290bde5e589683c4eb6b6120826b60ca2531158c318da920919/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a617669726b2f506572736f6e5f72656d6f7665723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3a850b9f0aeaa290bde5e589683c4eb6b6120826b60ca2531158c318da920919/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a617669726b2f506572736f6e5f72656d6f7665723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/javirk/Person_remover?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : People removal in images using Pix2Pix and YOLO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/foschmitz/yolo-python-rtsp\"\u003efoschmitz/yolo-python-rtsp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0663190a12e67d47782aecb085cb6dc95d7044eb0eac43076128dd8af4244272/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666f7363686d69747a2f796f6c6f2d707974686f6e2d727473703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0663190a12e67d47782aecb085cb6dc95d7044eb0eac43076128dd8af4244272/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666f7363686d69747a2f796f6c6f2d707974686f6e2d727473703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/foschmitz/yolo-python-rtsp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object detection using deep learning with Yolo, OpenCV and Python via Real Time Streaming Protocol (RTSP).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ismail-mebsout/Parsing-PDFs-using-YOLOV3\"\u003eismail-mebsout/Parsing-PDFs-using-YOLOV3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/88872e2f9e6d3c37707e958c27a9a8437745a1167e6ea4e5d7c1ddae834fe460/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736d61696c2d6d6562736f75742f50617273696e672d504446732d7573696e672d594f4c4f56333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/88872e2f9e6d3c37707e958c27a9a8437745a1167e6ea4e5d7c1ddae834fe460/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736d61696c2d6d6562736f75742f50617273696e672d504446732d7573696e672d594f4c4f56333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ismail-mebsout/Parsing-PDFs-using-YOLOV3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Parsing pdf tables using YOLOV3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/008karan/PAN_OCR\"\u003e008karan/PAN_OCR\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b69709590848f6464cd2d4a994c778b17a9c95c9d3e0e6e23c16fea2553285d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3030386b6172616e2f50414e5f4f43523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b69709590848f6464cd2d4a994c778b17a9c95c9d3e0e6e23c16fea2553285d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3030386b6172616e2f50414e5f4f43523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/008karan/PAN_OCR?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Building OCR using YOLO and Tesseract.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zeyad-mansour/lunar\"\u003ezeyad-mansour/lunar\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f655eee1b16fc4a5eb3e12e263e4b8d42bec03833a6fc25620526a37f8918045/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a657961642d6d616e736f75722f6c756e61723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f655eee1b16fc4a5eb3e12e263e4b8d42bec03833a6fc25620526a37f8918045/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a657961642d6d616e736f75722f6c756e61723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zeyad-mansour/lunar?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Lunar is a neural network aimbot that uses real-time object detection accelerated with CUDA on Nvidia GPUs.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lannguyen0910/food-recognition\"\u003elannguyen0910/food-recognition\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/beafe827f9701bfc29b0d17f492f07b4bd46b94504eb3dcb95e8cf89d126f098/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c616e6e677579656e303931302f666f6f642d7265636f676e6974696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/beafe827f9701bfc29b0d17f492f07b4bd46b94504eb3dcb95e8cf89d126f098/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c616e6e677579656e303931302f666f6f642d7265636f676e6974696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lannguyen0910/food-recognition?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e :  ðŸ”ðŸŸðŸ— Food analysis baseline with Theseus. Integrate object detection, image classification and multi-class semantic segmentation. ðŸžðŸ–ðŸ•\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/killnice/yolov5-D435i\"\u003ekillnice/yolov5-D435i\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/22b822b9607750f0cd77fdea3499d6e765f30b6604f4cb64c875dceb8bf6929c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b696c6c6e6963652f796f6c6f76352d44343335693f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/22b822b9607750f0cd77fdea3499d6e765f30b6604f4cb64c875dceb8bf6929c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b696c6c6e6963652f796f6c6f76352d44343335693f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/killnice/yolov5-D435i?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : using yolov5 and realsense D435i.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SahilChachra/Video-Analytics-Dashboard\"\u003eSahilChachra/Video-Analytics-Dashboard\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8b883299cdd06c3bd5eb1ad5861977886aea8f34b92b495439d617f08643107c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536168696c436861636872612f566964656f2d416e616c79746963732d44617368626f6172643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8b883299cdd06c3bd5eb1ad5861977886aea8f34b92b495439d617f08643107c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536168696c436861636872612f566964656f2d416e616c79746963732d44617368626f6172643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SahilChachra/Video-Analytics-Dashboard?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Video Analytics dashboard built using YoloV5 and Streamlit.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/isLinXu/YOLOv5_Efficient\"\u003eisLinXu/YOLOv5_Efficient\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4cc0199a0a74adfffe83a6153cf1370b1ebbbfa9efc4585e0581fa7e3977d209/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69734c696e58752f594f4c4f76355f456666696369656e743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4cc0199a0a74adfffe83a6153cf1370b1ebbbfa9efc4585e0581fa7e3977d209/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69734c696e58752f594f4c4f76355f456666696369656e743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/isLinXu/YOLOv5_Efficient?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Use yolov5 efficiently(é«˜æ•ˆåœ°ä½¿ç”¨Yolo v5).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HRan2004/Yolo-ArbV2\"\u003eHRan2004/Yolo-ArbV2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8fc233af084ad50f74a219846a538770a36860e7a4258020a4583d7da144d90f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4852616e323030342f596f6c6f2d41726256323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8fc233af084ad50f74a219846a538770a36860e7a4258020a4583d7da144d90f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4852616e323030342f596f6c6f2d41726256323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HRan2004/Yolo-ArbV2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo-ArbV2 åœ¨å®Œå…¨ä¿æŒYOLOv5åŠŸèƒ½æƒ…å†µä¸‹ï¼Œå®žçŽ°å¯é€‰å¤šè¾¹å½¢ä¿¡æ¯è¾“å‡ºã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Badw0lf613/wmreading_system\"\u003eBadw0lf613/wmreading_system\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a7b0f94f57ae4e0f9f6779173e3acaaf308815d918269aee99d12a24c18c3392/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42616477306c663631332f776d72656164696e675f73797374656d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a7b0f94f57ae4e0f9f6779173e3acaaf308815d918269aee99d12a24c18c3392/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42616477306c663631332f776d72656164696e675f73797374656d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Badw0lf613/wmreading_system?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽYOLOv5çš„æ°´è¡¨è¯»æ•°ç³»ç»Ÿã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zgcr/SimpleAICV-pytorch-ImageNet-COCO-training\"\u003ezgcr/SimpleAICV-pytorch-ImageNet-COCO-training\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/369e51ba8ced65d1e9023ec6c58c84575615b12d83ac9f1b3501fad0dbd76141/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6763722f53696d706c65414943562d7079746f7263682d496d6167654e65742d434f434f2d747261696e696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/369e51ba8ced65d1e9023ec6c58c84575615b12d83ac9f1b3501fad0dbd76141/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6763722f53696d706c65414943562d7079746f7263682d496d6167654e65742d434f434f2d747261696e696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zgcr/SimpleAICV-pytorch-ImageNet-COCO-training?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : SimpleAICV:pytorch training example on ImageNet(ILSVRC2012)/COCO2017/VOC2007+2012 datasets.Include ResNet/DarkNet/RetinaNet/FCOS/CenterNet/TTFNet/YOLOv3/YOLOv4/YOLOv5/YOLOX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ErenKaymakci/Real-Time-QR-Detection-and-Decoding\"\u003eErenKaymakci/Real-Time-QR-Detection-and-Decoding\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/96463682c4ff205ceedd63e748164a30ff4673dfda502d9e946f8539d072a5a7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4572656e4b61796d616b63692f5265616c2d54696d652d51522d446574656374696f6e2d616e642d4465636f64696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/96463682c4ff205ceedd63e748164a30ff4673dfda502d9e946f8539d072a5a7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4572656e4b61796d616b63692f5265616c2d54696d652d51522d446574656374696f6e2d616e642d4465636f64696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ErenKaymakci/Real-Time-QR-Detection-and-Decoding?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repo explain how qr codes works, qr detection and decoding.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LUMAIS/AntDet_YOLOv5\"\u003eLUMAIS/AntDet_YOLOv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/54be26680f5ce50506844af6fd2cde77a8110245c8b3ec0b8de818437afcad18/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c554d4149532f416e744465745f594f4c4f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/54be26680f5ce50506844af6fd2cde77a8110245c8b3ec0b8de818437afcad18/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c554d4149532f416e744465745f594f4c4f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LUMAIS/AntDet_YOLOv5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Ants and their Activiteis (Trophallaxis) Detection using YOLOv5 based on PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Jiseong-Ok/OCR-Yolov5-SwinIR-SVTR\"\u003eJiseong-Ok/OCR-Yolov5-SwinIR-SVTR\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0140f06f5f6872a5cc7e472180f511244e74ed079f328c0713609815905bef9a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a6973656f6e672d4f6b2f4f43522d596f6c6f76352d5377696e49522d535654523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0140f06f5f6872a5cc7e472180f511244e74ed079f328c0713609815905bef9a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a6973656f6e672d4f6b2f4f43522d596f6c6f76352d5377696e49522d535654523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Jiseong-Ok/OCR-Yolov5-SwinIR-SVTR?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : OCR(Korean).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/QIN2DIM/hcaptcha-challenger\"\u003eQIN2DIM/hcaptcha-challenger\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a0905caa7b20a49c88a3d038d5e0138731e1178405b5ec3e9a590f5617576030/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51494e3244494d2f68636170746368612d6368616c6c656e6765723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a0905caa7b20a49c88a3d038d5e0138731e1178405b5ec3e9a590f5617576030/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51494e3244494d2f68636170746368612d6368616c6c656e6765723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/QIN2DIM/hcaptcha-challenger?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ¥‚ Gracefully face hCaptcha challenge with YOLOv6(ONNX) embedded solution.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bobjiangps/vision\"\u003ebobjiangps/vision\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/88206df5589801808faab699feb9d38664133f9480e7319d588c4833b3d12944/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f626f626a69616e6770732f766973696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/88206df5589801808faab699feb9d38664133f9480e7319d588c4833b3d12944/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f626f626a69616e6770732f766973696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bobjiangps/vision?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : UI auto test framework based on YOLO to recognize elements, less code, less maintenance, cross platform, cross project / åŸºäºŽYOLOçš„UIå±‚è‡ªåŠ¨åŒ–æµ‹è¯•æ¡†æž¶, å¯è¯†åˆ«æŽ§ä»¶ç±»åž‹ï¼Œå‡å°‘ä»£ç å’Œç»´æŠ¤ï¼Œä¸€å®šç¨‹åº¦ä¸Šè·¨å¹³å°è·¨é¡¹ç›®ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RizwanMunawar/yolov7-object-cropping\"\u003eRizwanMunawar/yolov7-object-cropping\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bc5f3cb09285882da2f317d66366a4bd116ff7f1e5be422d9ae1fef03bcc234b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d6f626a6563742d63726f7070696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bc5f3cb09285882da2f317d66366a4bd116ff7f1e5be422d9ae1fef03bcc234b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d6f626a6563742d63726f7070696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RizwanMunawar/yolov7-object-cropping?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv7 Object Cropping Using OpenCV.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RizwanMunawar/yolov7-object-blurring\"\u003eRizwanMunawar/yolov7-object-blurring\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ebeaa80277a1679db9722995253a750c1cc5c6010ed64c8c8bfeb62564ce9086/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d6f626a6563742d626c757272696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ebeaa80277a1679db9722995253a750c1cc5c6010ed64c8c8bfeb62564ce9086/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d6f626a6563742d626c757272696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RizwanMunawar/yolov7-object-blurring?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv7 Object Blurring Using PyTorch and OpenCV.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pacocp/YOLOF\"\u003epacocp/YOLOF\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/295db73f942f9d64c5075e2fdca48d5c981e034890134d7440ccd8e58fc23f23/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7061636f63702f594f4c4f463f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/295db73f942f9d64c5075e2fdca48d5c981e034890134d7440ccd8e58fc23f23/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7061636f63702f594f4c4f463f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pacocp/YOLOF?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ“¹ YOLO meets Optical Flow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FabianPlum/OmniTrax\"\u003eFabianPlum/OmniTrax\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4aaef20b0bb1e1bf2bdcb4feebdb8b5d5e984593dea4b787e403828cacb3e923/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46616269616e506c756d2f4f6d6e69547261783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4aaef20b0bb1e1bf2bdcb4feebdb8b5d5e984593dea4b787e403828cacb3e923/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46616269616e506c756d2f4f6d6e69547261783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FabianPlum/OmniTrax?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Deep learning-based multi animal tracking and pose estimation Blender Add-on.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/aweihao/ExDark2Yolo\"\u003eaweihao/ExDark2Yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/aa0b5898087c7ba2b23c25fa7e38fef08cc331d57b482f6026c843d042601021/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6177656968616f2f45784461726b32596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/aa0b5898087c7ba2b23c25fa7e38fef08cc331d57b482f6026c843d042601021/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6177656968616f2f45784461726b32596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/aweihao/ExDark2Yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Convert ExDark annotated format data to YOLO format data. / å°†ExDarkæ ‡æ³¨æ ¼å¼çš„æ•°æ®è½¬æ¢æˆYOLOæ ¼å¼çš„æ•°æ®ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ozankaraali/yolov3-recaptcha\"\u003eozankaraali/yolov3-recaptcha\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fbd417fde95efafaa891d2f35c4027fc67591f75e966c648cc79a0e5af1b148e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f7a616e6b617261616c692f796f6c6f76332d7265636170746368613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fbd417fde95efafaa891d2f35c4027fc67591f75e966c648cc79a0e5af1b148e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f7a616e6b617261616c692f796f6c6f76332d7265636170746368613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ozankaraali/yolov3-recaptcha?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Solve Recaptcha with YoloV3. A proof of concept Recaptcha solver using YOLOv3 on Tensorflow 2.0 and Selenium. This tutorial shows that with a better trained object detection weight file, ReCaptcha can be easily solved.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jyp-studio/Invoice_detection\"\u003ejyp-studio/Invoice_detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3266c2476a037318c90be851dca309cbf63d504013c2d23e7eede35f0cf36c91/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a79702d73747564696f2f496e766f6963655f646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3266c2476a037318c90be851dca309cbf63d504013c2d23e7eede35f0cf36c91/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a79702d73747564696f2f496e766f6963655f646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jyp-studio/Invoice_detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is an AI model for detecting and recognizing invoice information by yolov5 and OCR.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/vmc-7645/YOLOv8-retail\"\u003evmc-7645/YOLOv8-retail\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fab82755f5aebf480f1eea55202fb3415b7f1a15cb4a3830c02decd11ae19789/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f766d632d373634352f594f4c4f76382d72657461696c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fab82755f5aebf480f1eea55202fb3415b7f1a15cb4a3830c02decd11ae19789/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f766d632d373634352f594f4c4f76382d72657461696c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/vmc-7645/YOLOv8-retail?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detect retail products via the YOLOv8 object recognition engine.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TAber-W/RM_4-points_yolov5\"\u003eTAber-W/RM_4-points_yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b3dcaf7c4e17a3dcd897fea7bb6d5a783d698c2a5553f751e7fbc11c7ca0152d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54416265722d572f524d5f342d706f696e74735f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b3dcaf7c4e17a3dcd897fea7bb6d5a783d698c2a5553f751e7fbc11c7ca0152d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54416265722d572f524d5f342d706f696e74735f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TAber-W/RM_4-points_yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Robomaster åŸºäºŽyolofaceå’ŒMobileNetä¿®æ”¹çš„å››ç‚¹æ¨¡åž‹.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/eternal-echo/picking\"\u003eeternal-echo/picking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f3e7201027a78724510a3aeaf1f0d3eb9379f09cd21fd69ab3f1b41376049960/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657465726e616c2d6563686f2f7069636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f3e7201027a78724510a3aeaf1f0d3eb9379f09cd21fd69ab3f1b41376049960/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657465726e616c2d6563686f2f7069636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/eternal-echo/picking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽYOLO v5è§†è§‰åˆ†æ‹£é›¶ä»¶ç³»ç»Ÿè®¾è®¡ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/swordswind/yolo_ocr_api_server\"\u003eswordswind/yolo_ocr_api_server\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e0a1e2b96ad5a363dd84c0875d2360e599df34bc4580d5033b8943ecf53931d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73776f72647377696e642f796f6c6f5f6f63725f6170695f7365727665723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e0a1e2b96ad5a363dd84c0875d2360e599df34bc4580d5033b8943ecf53931d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73776f72647377696e642f796f6c6f5f6f63725f6170695f7365727665723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/swordswind/yolo_ocr_api_server?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv10\u0026amp;EasyOCRèžåˆå›¾åƒè¯†åˆ«APIæœåŠ¡å™¨ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eObject Detection Datasets\u003c/h2\u003e\u003ca id=\"user-content-object-detection-datasets\" class=\"anchor\" aria-label=\"Permalink: Object Detection Datasets\" href=\"#object-detection-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eDatasets Share Platform\u003c/h3\u003e\u003ca id=\"user-content-datasets-share-platform\" class=\"anchor\" aria-label=\"Permalink: Datasets Share Platform\" href=\"#datasets-share-platform\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://opendatalab.org.cn/\" rel=\"nofollow\"\u003eOpenDataLab\u003c/a\u003e : OpenDataLab æ˜¯ä¸Šæµ·äººå·¥æ™ºèƒ½å®žéªŒå®¤çš„å¤§æ¨¡åž‹æ•°æ®åŸºåº§å›¢é˜Ÿæ‰“é€ çš„æ•°æ®å¼€æ”¾å¹³å°ï¼ŒçŽ°å·²æˆä¸ºä¸­å›½å¤§æ¨¡åž‹è¯­æ–™æ•°æ®è”ç›Ÿå¼€æºæ•°æ®æœåŠ¡æŒ‡å®šå¹³å°ï¼Œä¸ºå¼€å‘è€…æä¾›å…¨é“¾æ¡çš„ AI æ•°æ®æ”¯æŒï¼Œåº”å¯¹å’Œè§£å†³æ•°æ®å¤„ç†ä¸­çš„é£Žé™©ä¸ŽæŒ‘æˆ˜ï¼ŒæŽ¨åŠ¨ AI ç ”ç©¶åŠåº”ç”¨ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.scidb.cn/en\" rel=\"nofollow\"\u003eScience Data Bank(ScienceDB)\u003c/a\u003e : Make your research data citable, discoverable and persistently accessible Satisfy flexible data sharing requirements Dedicate to facilitating data dissemination and reusing. Science Data Bank (ScienceDB) is a public, general-purpose data repository aiming to provide data services (e.g. data acquisition, long-term preservation, publishing, sharing and access) for researchers, research projects/teams, journals, institutions, universities, etc. It supports a variety of data acquisition and data licenses. ScienceDB is dedicated to promoting data findable, citable and reusable on the prerequisite of protecting the rights and interests of data owners and it is built and operated by Computer Network Information Center, Chinese Academy of Sciences.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://www.csdata.org/\" rel=\"nofollow\"\u003eä¸­å›½ç§‘å­¦æ•°æ®\u003c/a\u003e : ã€Šä¸­å›½ç§‘å­¦æ•°æ®ï¼ˆä¸­è‹±æ–‡ç½‘ç»œç‰ˆï¼‰ã€‹ï¼ˆChina Scientific Dataï¼‰ï¼ˆCN11-6035/Nï¼ŒISSN 2096-2223ï¼‰æ˜¯ç›®å‰ä¸­å›½å”¯ä¸€çš„ä¸“é—¨é¢å‘å¤šå­¦ç§‘é¢†åŸŸç§‘å­¦æ•°æ®å‡ºç‰ˆçš„å­¦æœ¯æœŸåˆŠï¼Œä½œä¸ºå›½å®¶ç½‘ç»œè¿žç»­åž‹å‡ºç‰ˆç‰©çš„é¦–æ‰¹è¯•ç‚¹ä¹‹ä¸€ï¼Œç”±ä¸­å›½ç§‘å­¦é™¢ä¸»ç®¡ï¼Œä¸­å›½ç§‘å­¦é™¢è®¡ç®—æœºç½‘ç»œä¿¡æ¯ä¸­å¿ƒå’ŒISC CODATAä¸­å›½å…¨å›½å§”å‘˜ä¼šåˆåŠžï¼Œå›½å®¶ç§‘æŠ€åŸºç¡€æ¡ä»¶å¹³å°ä¸­å¿ƒã€ä¸­å›½ç§‘å­¦é™¢ç½‘ç»œå®‰å…¨å’Œä¿¡æ¯åŒ–é¢†å¯¼å°ç»„åŠžå…¬å®¤æŒ‡å¯¼ï¼Œå›½å†…å¤–å…¬å¼€å‘è¡Œï¼Œä¸­è‹±æ–‡ï¼Œå­£åˆŠã€‚ ä¸­å›½ç§‘å­¦å¼•æ–‡æ•°æ®åº“ï¼ˆCSCDï¼‰æ¥æºæœŸåˆŠï¼Œä¸­å›½ç§‘æŠ€æ ¸å¿ƒæœŸåˆŠ ï¼Œæ”¶å½•äºŽä¸­å›½ç§‘åé«˜è´¨é‡ç§‘æŠ€æœŸåˆŠåˆ†çº§ç›®å½•ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://aistudio.baidu.com/aistudio/datasetoverview\" rel=\"nofollow\"\u003eé£žæ¡¨AI Studio\u003c/a\u003e : é£žæ¡¨AI Studioå¼€æ”¾æ•°æ®é›†ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.cvmart.net/dataSets\" rel=\"nofollow\"\u003eæžå¸‚å¼€å‘è€…å¹³å°\u003c/a\u003e : æžå¸‚å¼€å‘è€…å¹³å°å¼€æ”¾æ•°æ®é›†ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/openvinotoolkit/datumaro\"\u003eopenvinotoolkit/datumaro\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/926b639d50ef6eb0eb8a038750a38508ced921aecbf66cb880fd137494fed1f3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e76696e6f746f6f6c6b69742f646174756d61726f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/926b639d50ef6eb0eb8a038750a38508ced921aecbf66cb880fd137494fed1f3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e76696e6f746f6f6c6b69742f646174756d61726f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/openvinotoolkit/datumaro?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Dataset Management Framework, a Python library and a CLI tool to build, analyze and manage Computer Vision datasets.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eDatasets Tools\u003c/h3\u003e\u003ca id=\"user-content-datasets-tools\" class=\"anchor\" aria-label=\"Permalink: Datasets Tools\" href=\"#datasets-tools\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eData Annotation\u003c/h4\u003e\u003ca id=\"user-content-data-annotation\" class=\"anchor\" aria-label=\"Permalink: Data Annotation\" href=\"#data-annotation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HumanSignal/label-studio\"\u003eLabel Studio\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/67036dea2546fceffdfc29d776ff2b3735d525e4527ad8ddd6a59b4822cb3ad5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48756d616e5369676e616c2f6c6162656c2d73747564696f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/67036dea2546fceffdfc29d776ff2b3735d525e4527ad8ddd6a59b4822cb3ad5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48756d616e5369676e616c2f6c6162656c2d73747564696f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HumanSignal/label-studio?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Label Studio is a multi-type data labeling and annotation tool with standardized output format. \u003ca href=\"https://labelstud.io/\" rel=\"nofollow\"\u003elabelstud.io\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CVHub520/X-AnyLabeling\"\u003eX-AnyLabeling\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/822ce53353585f82ef9fb52ff2b5e2439c18912227c1fe5550a73acaf89ea2e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43564875623532302f582d416e794c6162656c696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/822ce53353585f82ef9fb52ff2b5e2439c18912227c1fe5550a73acaf89ea2e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43564875623532302f582d416e794c6162656c696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CVHub520/X-AnyLabeling?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Effortless data labeling with AI support from Segment Anything and other awesome models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/vietanhdev/anylabeling\"\u003eAnyLabeling\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fabfde4bb4cc495066df3245b2d5ff1d8e1b95d8f377ab207fcb45588a33f6cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76696574616e686465762f616e796c6162656c696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fabfde4bb4cc495066df3245b2d5ff1d8e1b95d8f377ab207fcb45588a33f6cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76696574616e686465762f616e796c6162656c696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/vietanhdev/anylabeling?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Effortless AI-assisted data labeling with AI support from YOLO, Segment Anything (SAM+SAM2), MobileSAM!! AnyLabeling = LabelImg + Labelme + Improved UI + Auto-labeling. \u003ca href=\"https://anylabeling.nrl.ai/\" rel=\"nofollow\"\u003eanylabeling.nrl.ai\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LSH9832/SAMLabelerPro\"\u003eSAMLabelerPro\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/701c21a16fe00fe13490f7ce369459877a819278e5e89089159f977e8f2d009f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5348393833322f53414d4c6162656c657250726f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/701c21a16fe00fe13490f7ce369459877a819278e5e89089159f977e8f2d009f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5348393833322f53414d4c6162656c657250726f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LSH9832/SAMLabelerPro?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : label your image with Segment Anything Model or MobileSAM, support remote labeling for multiple personsã€‚ä½¿ç”¨Segment Anything Modelæˆ–MobileSAMè¾…åŠ©æ ‡æ³¨çš„å·¥å…·ï¼Œæ”¯æŒå¤šäººè¿œç¨‹æ ‡æ³¨ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/heartexlabs/labelImg\"\u003eLabelImg\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/dadc4a6251bef7ddf268b9606b0cccc7a958971ebd9b5f518e5abed8839f42a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686561727465786c6162732f6c6162656c496d673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dadc4a6251bef7ddf268b9606b0cccc7a958971ebd9b5f518e5abed8839f42a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686561727465786c6162732f6c6162656c496d673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/heartexlabs/labelImg?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ–ï¸ LabelImg is a graphical image annotation tool and label object bounding boxes in images.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wkentaro/labelme\"\u003elabelme\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5a182962d92bb16f13a72a6a57003ce19d8d3ec41bcb3e1fea71b9639c9e356f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776b656e7461726f2f6c6162656c6d653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5a182962d92bb16f13a72a6a57003ce19d8d3ec41bcb3e1fea71b9639c9e356f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776b656e7461726f2f6c6162656c6d653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wkentaro/labelme?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Image Polygonal Annotation with Python (polygon, rectangle, circle, line, point and image-level flag annotation).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/darkpgmr/DarkLabel\"\u003eDarkLabel\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/dc1ee184b84c0eddc37bd121b96efe7778dd45f40eb033cc3985d5e8155ea94e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6461726b70676d722f4461726b4c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dc1ee184b84c0eddc37bd121b96efe7778dd45f40eb033cc3985d5e8155ea94e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6461726b70676d722f4461726b4c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/darkpgmr/DarkLabel?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Video/Image Labeling and Annotation Tool.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlexeyAB/Yolo_mark\"\u003eAlexeyAB/Yolo_mark\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5f0d86929b24cadd73bfb672723a507e94cbf9d176b515bfce3b1e918bbbc2e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f596f6c6f5f6d61726b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5f0d86929b24cadd73bfb672723a507e94cbf9d176b515bfce3b1e918bbbc2e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f596f6c6f5f6d61726b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlexeyAB/Yolo_mark?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : GUI for marking bounded boxes of objects in images for training neural network Yolo v3 and v2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Cartucho/OpenLabeling\"\u003eCartucho/OpenLabeling\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/85366566b5f23bcd02b387b80aecfac3e4baa0e1b2735a04b3e551d0486723fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436172747563686f2f4f70656e4c6162656c696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/85366566b5f23bcd02b387b80aecfac3e4baa0e1b2735a04b3e551d0486723fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436172747563686f2f4f70656e4c6162656c696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Cartucho/OpenLabeling?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Label images and video for Computer Vision applications.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cvat-ai/cvat\"\u003eCVAT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fe9a07e7636fde23bdec44e090a5f2f0bbacd2036375694b3be07da38108da77/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f637661742d61692f637661743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fe9a07e7636fde23bdec44e090a5f2f0bbacd2036375694b3be07da38108da77/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f637661742d61692f637661743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cvat-ai/cvat?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Computer Vision Annotation Tool (CVAT). Annotate better with CVAT, the industry-leading data engine for machine learning. Used and trusted by teams at any scale, for data of any scale.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Microsoft/VoTT\"\u003eVoTT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/695897a0062f5aae617295086997957761e99e9042ca2dacaa1259fd6f50b25c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6963726f736f66742f566f54543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/695897a0062f5aae617295086997957761e99e9042ca2dacaa1259fd6f50b25c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6963726f736f66742f566f54543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Microsoft/VoTT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Visual Object Tagging Tool: An electron app for building end to end Object Detection Models from Images and Videos.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WangRongsheng/KDAT\"\u003eWangRongsheng/KDAT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2d66a5d1fa71d78e1b2336df8582396d6bbd610e6ddc39b4d64248c15801274c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57616e67526f6e677368656e672f4b4441543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2d66a5d1fa71d78e1b2336df8582396d6bbd610e6ddc39b4d64248c15801274c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57616e67526f6e677368656e672f4b4441543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WangRongsheng/KDAT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ä¸€ä¸ªä¸“ä¸ºè§†è§‰æ–¹å‘ç›®æ ‡æ£€æµ‹å…¨æµç¨‹çš„æ ‡æ³¨å·¥å…·é›†ï¼Œå…¨ç§°ï¼šKill Object Detection Annotation Toolsã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ryouchinsa/Rectlabel-support\"\u003eRectlabel-support\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/81e95ba68beb08b64d183eae8ae23f01dc8ffadb41279118e21cb3e778c5946e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72796f756368696e73612f526563746c6162656c2d737570706f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/81e95ba68beb08b64d183eae8ae23f01dc8ffadb41279118e21cb3e778c5946e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72796f756368696e73612f526563746c6162656c2d737570706f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ryouchinsa/Rectlabel-support?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : RectLabel - An image annotation tool to label images for bounding box object detection and segmentation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cnyvfang/labelGo-Yolov5AutoLabelImg\"\u003ecnyvfang/labelGo-Yolov5AutoLabelImg\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/68e9f1abd14edfe12bc90dabcc941509334ee989db4aa9dc1c338bd3c2744931/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636e797666616e672f6c6162656c476f2d596f6c6f76354175746f4c6162656c496d673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/68e9f1abd14edfe12bc90dabcc941509334ee989db4aa9dc1c338bd3c2744931/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636e797666616e672f6c6162656c476f2d596f6c6f76354175746f4c6162656c496d673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cnyvfang/labelGo-Yolov5AutoLabelImg?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ’•YOLOV5 semi-automatic annotation tool (Based on labelImg)ðŸ’•ä¸€ä¸ªåŸºäºŽlabelImgåŠYOLOV5çš„å›¾å½¢åŒ–åŠè‡ªåŠ¨æ ‡æ³¨å·¥å…·ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CVUsers/Auto_maker\"\u003eCVUsers/Auto_maker\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/31c56c1966068b2cc0840abbd696cb7a7a89afb2ce0c6f4f58e2815531641022/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f435655736572732f4175746f5f6d616b65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/31c56c1966068b2cc0840abbd696cb7a7a89afb2ce0c6f4f58e2815531641022/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f435655736572732f4175746f5f6d616b65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CVUsers/Auto_maker?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : æ·±åº¦å­¦ä¹ æ•°æ®è‡ªåŠ¨æ ‡æ³¨å™¨å¼€æº ç›®æ ‡æ£€æµ‹å’Œå›¾åƒåˆ†ç±»ï¼ˆé«˜ç²¾åº¦é«˜æ•ˆçŽ‡ï¼‰ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/OvidijusParsiunas/myvision\"\u003eMyVision\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/76e9fb38381abef02bffcb05cfd095d4ebed24804cb339470cdb83c69c6cc889/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f766964696a75735061727369756e61732f6d79766973696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/76e9fb38381abef02bffcb05cfd095d4ebed24804cb339470cdb83c69c6cc889/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f766964696a75735061727369756e61732f6d79766973696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/OvidijusParsiunas/myvision?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Computer vision based ML training data generation tool ðŸš€\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wufan-tb/AutoLabelImg\"\u003ewufan-tb/AutoLabelImg\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/64e224ef08aabd2c4751c8501d17ff7a88a4d5f4bffe825f2911e71708fc4202/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f777566616e2d74622f4175746f4c6162656c496d673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/64e224ef08aabd2c4751c8501d17ff7a88a4d5f4bffe825f2911e71708fc4202/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f777566616e2d74622f4175746f4c6162656c496d673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wufan-tb/AutoLabelImg?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : auto-labelimg based on yolov5, with many other useful tools. AutoLabelImg å¤šåŠŸèƒ½è‡ªåŠ¨æ ‡æ³¨å·¥å…·ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MrZander/YoloMarkNet\"\u003eMrZander/YoloMarkNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/07165a8ff9ed22800e62d4daee320cd0cdc47eb042819a83874dbcd99a0ee65f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d725a616e6465722f596f6c6f4d61726b4e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/07165a8ff9ed22800e62d4daee320cd0cdc47eb042819a83874dbcd99a0ee65f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d725a616e6465722f596f6c6f4d61726b4e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MrZander/YoloMarkNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Darknet YOLOv2/3 annotation tool written in C#/WPF.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mahxn0/Yolov3_ForTextLabel\"\u003emahxn0/Yolov3_ForTextLabel\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/50610f6ad79c28ba605e629e99e947f38b8bd2d7a7e3916b66f71e19a4eb0f1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6168786e302f596f6c6f76335f466f72546578744c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/50610f6ad79c28ba605e629e99e947f38b8bd2d7a7e3916b66f71e19a4eb0f1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6168786e302f596f6c6f76335f466f72546578744c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mahxn0/Yolov3_ForTextLabel?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : åŸºäºŽyolov3çš„ç›®æ ‡/è‡ªç„¶åœºæ™¯æ–‡å­—è‡ªåŠ¨æ ‡æ³¨å·¥å…·ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MNConnor/YoloV5-AI-Label\"\u003eMNConnor/YoloV5-AI-Label\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bae30cda23e2451058ec7422d8233aab8a4ef55d7e8c108bd329e7511fbdb7aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d4e436f6e6e6f722f596f6c6f56352d41492d4c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bae30cda23e2451058ec7422d8233aab8a4ef55d7e8c108bd329e7511fbdb7aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d4e436f6e6e6f722f596f6c6f56352d41492d4c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MNConnor/YoloV5-AI-Label?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV5 AI Assisted Labeling.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LILINOpenGitHub/Labeling-Tool\"\u003eLILINOpenGitHub/Labeling-Tool\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0dda3d9021bae83c1599227cba107851e7fca8ed66964b0409228ebf9925507a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c494c494e4f70656e4769744875622f4c6162656c696e672d546f6f6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0dda3d9021bae83c1599227cba107851e7fca8ed66964b0409228ebf9925507a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c494c494e4f70656e4769744875622f4c6162656c696e672d546f6f6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LILINOpenGitHub/Labeling-Tool?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Free YOLO AI labeling tool. YOLO AI labeling tool is a Windows app for labeling YOLO dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/whs0523003/YOLOv5_6.1_autolabel\"\u003ewhs0523003/YOLOv5_6.1_autolabel\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5945d2dd0cf857c10634ff50faf0a6fa29fab0229b0e836b63142bb5c2b084e8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776873303532333030332f594f4c4f76355f362e315f6175746f6c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5945d2dd0cf857c10634ff50faf0a6fa29fab0229b0e836b63142bb5c2b084e8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776873303532333030332f594f4c4f76355f362e315f6175746f6c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/whs0523003/YOLOv5_6.1_autolabel?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5_6.1 è‡ªåŠ¨æ ‡è®°ç›®æ ‡æ¡†ã€‚\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/2vin/PyYAT\"\u003e2vin/PyYAT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c7e1064e7dd50959690eef4f38f1d4749dbc5aa325696511fb5a1c72a133073c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3276696e2f50795941543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c7e1064e7dd50959690eef4f38f1d4749dbc5aa325696511fb5a1c72a133073c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3276696e2f50795941543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/2vin/PyYAT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Semi-Automatic Yolo Annotation Tool In Python.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlturosDestinations/Alturos.ImageAnnotation\"\u003eAlturosDestinations/Alturos.ImageAnnotation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b6ba89fc7367ee013a360cdc8eaa6c1c379243f52450f81df24188e7ed826e92/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c7475726f7344657374696e6174696f6e732f416c7475726f732e496d616765416e6e6f746174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b6ba89fc7367ee013a360cdc8eaa6c1c379243f52450f81df24188e7ed826e92/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c7475726f7344657374696e6174696f6e732f416c7475726f732e496d616765416e6e6f746174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlturosDestinations/Alturos.ImageAnnotation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A collaborative tool for labeling image data for yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/stephanecharette/DarkMark\"\u003estephanecharette/DarkMark\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fd2bd5cfcdb3e964e498f8dc1989a07abccac0d267e0f362358a8ae32516fa0f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374657068616e6563686172657474652f4461726b4d61726b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fd2bd5cfcdb3e964e498f8dc1989a07abccac0d267e0f362358a8ae32516fa0f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374657068616e6563686172657474652f4461726b4d61726b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/stephanecharette/DarkMark?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Marking up images for use with Darknet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/2vin/yolo_annotation_tool\"\u003e2vin/yolo_annotation_tool\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8fac3b71b05b60c41d0fc33d10f11fa87124cd2f34af81cd74c00726646a14c6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3276696e2f796f6c6f5f616e6e6f746174696f6e5f746f6f6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8fac3b71b05b60c41d0fc33d10f11fa87124cd2f34af81cd74c00726646a14c6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3276696e2f796f6c6f5f616e6e6f746174696f6e5f746f6f6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/2vin/yolo_annotation_tool?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Annotation tool for YOLO in opencv.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sanfooh/quick_yolo2_label_tool\"\u003esanfooh/quick_yolo2_label_tool\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/601f50b57a84009341cc6308ee832f54eb3e6b6f2feda6bfc4cf9bb8b10525b2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73616e666f6f682f717569636b5f796f6c6f325f6c6162656c5f746f6f6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/601f50b57a84009341cc6308ee832f54eb3e6b6f2feda6bfc4cf9bb8b10525b2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73616e666f6f682f717569636b5f796f6c6f325f6c6162656c5f746f6f6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sanfooh/quick_yolo2_label_tool?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yoloå¿«é€Ÿæ ‡æ³¨å·¥å…· quick yolo2 label tool.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/folkien/yaya\"\u003efolkien/yaya\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a1a5789fd999eac0555317afe1e759db4bf040f715e39e1fbc84f27b931ad01a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666f6c6b69656e2f796179613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a1a5789fd999eac0555317afe1e759db4bf040f715e39e1fbc84f27b931ad01a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666f6c6b69656e2f796179613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/folkien/yaya?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YAYA - Yet annother YOLO annoter for images (in QT5). Support yolo format, image modifications, labeling and detecting with previously trained detector.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pylabel-project/pylabel\"\u003epylabel-project/pylabel\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2391c03e201ec8104ea2aa1b0ef63f6dc5c4818c99c2f9527698a7556db39c09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70796c6162656c2d70726f6a6563742f70796c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2391c03e201ec8104ea2aa1b0ef63f6dc5c4818c99c2f9527698a7556db39c09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70796c6162656c2d70726f6a6563742f70796c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pylabel-project/pylabel?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Python library for computer vision labeling tasks. The core functionality is to translate bounding box annotations between different formats-for example, from coco to yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/opendatalab/labelU\"\u003eopendatalab/labelU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ef37844fb33e54c59b70a193bdb2d3c2afff71b26eb40d3fc8db53abba609e7a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e646174616c61622f6c6162656c553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ef37844fb33e54c59b70a193bdb2d3c2afff71b26eb40d3fc8db53abba609e7a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e646174616c61622f6c6162656c553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/opendatalab/labelU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Uniform, Unlimited, Universal and Unbelievable Annotation Toolbox.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eData Augmentation\u003c/h4\u003e\u003ca id=\"user-content-data-augmentation\" class=\"anchor\" aria-label=\"Permalink: Data Augmentation\" href=\"#data-augmentation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/albumentations-team/albumentations\"\u003eAlbumentations\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/84c7a1c3a26134634d9163e335f0f5413cc53dd7befcd137da96b91aa7b41ed7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c62756d656e746174696f6e732d7465616d2f616c62756d656e746174696f6e733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/84c7a1c3a26134634d9163e335f0f5413cc53dd7befcd137da96b91aa7b41ed7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c62756d656e746174696f6e732d7465616d2f616c62756d656e746174696f6e733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/albumentations-team/albumentations?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Albumentations is a Python library for image augmentation. Image augmentation is used in deep learning and computer vision tasks to increase the quality of trained models. The purpose of image augmentation is to create new training samples from the existing data. \"Albumentations: Fast and Flexible Image Augmentations\". (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/2078-2489/11/2/125\" rel=\"nofollow\"\u003eInformation 2020\u003c/a\u003e\u003c/strong\u003e). \u003ca href=\"https://albumentations.ai/\" rel=\"nofollow\"\u003ealbumentations.ai\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/doubleZ0108/Data-Augmentation\"\u003edoubleZ0108/Data-Augmentation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/aedc1387893882413eb22185722d1e0516af2d2abf95dde86dfdbe432b0aa677/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f75626c655a303130382f446174612d4175676d656e746174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/aedc1387893882413eb22185722d1e0516af2d2abf95dde86dfdbe432b0aa677/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f75626c655a303130382f446174612d4175676d656e746174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/doubleZ0108/Data-Augmentation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : General Data Augmentation Algorithms for Object Detection(esp. Yolo).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eData Management\u003c/h4\u003e\u003ca id=\"user-content-data-management\" class=\"anchor\" aria-label=\"Permalink: Data Management\" href=\"#data-management\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/lancedb/yoloexplorer\"\u003eYOLOExplorer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/507c960895daec4c89d562819404975d61a1557d00935e06873f2270d3a9204e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c616e636564622f796f6c6f6578706c6f7265723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/507c960895daec4c89d562819404975d61a1557d00935e06873f2270d3a9204e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c616e636564622f796f6c6f6578706c6f7265723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lancedb/yoloexplorer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOExplorer : Iterate on your YOLO / CV datasets using SQL, Vector semantic search, and more within seconds. Explore, manipulate and iterate on Computer Vision datasets with precision using simple APIs. Supports SQL filters, vector similarity search, native interface with Pandas and more.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eGeneral Detection and Recognition Datasets\u003c/h3\u003e\u003ca id=\"user-content-general-detection-and-recognition-datasets\" class=\"anchor\" aria-label=\"Permalink: General Detection and Recognition Datasets\" href=\"#general-detection-and-recognition-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eGeneral Object Detection Datasets\u003c/h4\u003e\u003ca id=\"user-content-general-object-detection-datasets\" class=\"anchor\" aria-label=\"Permalink: General Object Detection Datasets\" href=\"#general-object-detection-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://cocodataset.org/\" rel=\"nofollow\"\u003eCOCO\u003c/a\u003e : \"Microsoft COCO: Common Objects in Context\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/chapter/10.1007/978-3-319-10602-1_48\" rel=\"nofollow\"\u003eECCV 2014\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://host.robots.ox.ac.uk/pascal/VOC/\" rel=\"nofollow\"\u003ePASCAL VOC\u003c/a\u003e : \"The Pascal Visual Object Classes Challenge: A Retrospective\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/article/10.1007/s11263-014-0733-5\" rel=\"nofollow\"\u003eIJCV 2015\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://www.objects365.org/overview.html\" rel=\"nofollow\"\u003eObjects365\u003c/a\u003e : \"Objects365: A Large-scale, High-quality Dataset for Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_ICCV_2019/html/Shao_Objects365_A_Large-Scale_High-Quality_Dataset_for_Object_Detection_ICCV_2019_paper.html\" rel=\"nofollow\"\u003eICCV 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://v3det.openxlab.org.cn/\" rel=\"nofollow\"\u003eV3Det\u003c/a\u003e : \"V3Det: Vast Vocabulary Visual Detection Dataset\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2304.03752\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SkyCol/ODverse33\"\u003eODverse33\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ef5f96c2ac827b99fbe9cf71af48c0c784def6d4e1231a0614c5d925e52d2c69/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536b79436f6c2f4f44766572736533333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ef5f96c2ac827b99fbe9cf71af48c0c784def6d4e1231a0614c5d925e52d2c69/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536b79436f6c2f4f44766572736533333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SkyCol/ODverse33?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"ODverse33: Is the New YOLO Version Always Better? A Multi Domain benchmark from YOLO v5 to v11\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2502.14314\" rel=\"nofollow\"\u003earXiv 2025\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eGeneral Object Recognition Datasets\u003c/h4\u003e\u003ca id=\"user-content-general-object-recognition-datasets\" class=\"anchor\" aria-label=\"Permalink: General Object Recognition Datasets\" href=\"#general-object-recognition-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://image-net.org/challenges/LSVRC/\" rel=\"nofollow\"\u003eImageNet\u003c/a\u003e : \"ImageNet Large Scale Visual Recognition Challenge\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/article/10.1007/s11263-015-0816-y\" rel=\"nofollow\"\u003eIJCV 2015\u003c/a\u003e\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAutonomous Driving Datasets\u003c/h3\u003e\u003ca id=\"user-content-autonomous-driving-datasets\" class=\"anchor\" aria-label=\"Permalink: Autonomous Driving Datasets\" href=\"#autonomous-driving-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eDiverse Autonomous Driving Datasets\u003c/h4\u003e\u003ca id=\"user-content-diverse-autonomous-driving-datasets\" class=\"anchor\" aria-label=\"Permalink: Diverse Autonomous Driving Datasets\" href=\"#diverse-autonomous-driving-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://bdd-data.berkeley.edu/\" rel=\"nofollow\"\u003eBDD100K\u003c/a\u003e : \"BDD100K: A Diverse Driving Dataset for Heterogeneous Multitask Learning\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_CVPR_2020/html/Yu_BDD100K_A_Diverse_Driving_Dataset_for_Heterogeneous_Multitask_Learning_CVPR_2020_paper.html\" rel=\"nofollow\"\u003eCVPR 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://coda-dataset.github.io/\" rel=\"nofollow\"\u003eCODA\u003c/a\u003e : \"CODA: A Real-World Road Corner Case Dataset for Object Detection in Autonomous Driving\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/chapter/10.1007/978-3-031-19839-7_24\" rel=\"nofollow\"\u003eECCV 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eTraffic Sign Detection Datasets\u003c/h4\u003e\u003ca id=\"user-content-traffic-sign-detection-datasets\" class=\"anchor\" aria-label=\"Permalink: Traffic Sign Detection Datasets\" href=\"#traffic-sign-detection-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://cg.cs.tsinghua.edu.cn/traffic-sign/\" rel=\"nofollow\"\u003eTT100K\u003c/a\u003e : \"Traffic-Sign Detection and Classification in the Wild\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_cvpr_2016/html/Zhu_Traffic-Sign_Detection_and_CVPR_2016_paper.html\" rel=\"nofollow\"\u003eCVPR 2016\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/csust7zhangjm/CCTSDB\"\u003eCCTSDB\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/84dd116765dd78e1c615b51d2b7e9df9bc592bceaa7e9e2fcb249c0c718b26ef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6373757374377a68616e676a6d2f4343545344423f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/84dd116765dd78e1c615b51d2b7e9df9bc592bceaa7e9e2fcb249c0c718b26ef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6373757374377a68616e676a6d2f4343545344423f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/csust7zhangjm/CCTSDB?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : CSUST Chinese Traffic Sign Detection Benchmark ä¸­å›½äº¤é€šæ•°æ®é›†ç”±é•¿æ²™ç†å·¥å¤§å­¦ç»¼åˆäº¤é€šè¿è¾“å¤§æ•°æ®æ™ºèƒ½å¤„ç†æ¹–å—çœé‡ç‚¹å®žéªŒå®¤å¼ å»ºæ˜Žè€å¸ˆå›¢é˜Ÿåˆ¶ä½œå®Œæˆã€‚ \"A Real-Time Chinese Traffic Sign Detection Algorithm Based on Modified YOLOv2\". (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/1999-4893/10/4/127\" rel=\"nofollow\"\u003eAlgorithms, 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/csust7zhangjm/CCTSDB2021\"\u003eCCTSDB2021\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/38dbaaa691f422bb9fdf34cc8be8c9e90fc39e505d312994cd7cc80f8c082da3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6373757374377a68616e676a6d2f434354534442323032313f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/38dbaaa691f422bb9fdf34cc8be8c9e90fc39e505d312994cd7cc80f8c082da3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6373757374377a68616e676a6d2f434354534442323032313f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/csust7zhangjm/CCTSDB2021?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"CCTSDB 2021: a more comprehensive traffic sign detection benchmark\". (\u003cstrong\u003e\u003ca href=\"https://centaur.reading.ac.uk/106129/\" rel=\"nofollow\"\u003eHuman-centric Computing and Information Sciences, 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eLicense Plate Detection and Recognition Datasets\u003c/h4\u003e\u003ca id=\"user-content-license-plate-detection-and-recognition-datasets\" class=\"anchor\" aria-label=\"Permalink: License Plate Detection and Recognition Datasets\" href=\"#license-plate-detection-and-recognition-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/detectRecog/CCPD\"\u003eCCPD\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/38dbaaa691f422bb9fdf34cc8be8c9e90fc39e505d312994cd7cc80f8c082da3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6373757374377a68616e676a6d2f434354534442323032313f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/38dbaaa691f422bb9fdf34cc8be8c9e90fc39e505d312994cd7cc80f8c082da3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6373757374377a68616e676a6d2f434354534442323032313f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/csust7zhangjm/CCTSDB2021?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Towards End-to-End License Plate Detection and Recognition: A Large Dataset and Baseline\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_ECCV_2018/html/Zhenbo_Xu_Towards_End-to-End_License_ECCV_2018_paper.html\" rel=\"nofollow\"\u003eECCV 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAdverse Weather Datasets\u003c/h3\u003e\u003ca id=\"user-content-adverse-weather-datasets\" class=\"anchor\" aria-label=\"Permalink: Adverse Weather Datasets\" href=\"#adverse-weather-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://sites.google.com/site/boyilics/website-builder/reside\" rel=\"nofollow\"\u003eRESID\u003c/a\u003e : \"Benchmarking Single-Image Dehazing and Beyond\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8451944\" rel=\"nofollow\"\u003eIEEE Transactions on Image Processing 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003ePerson Detection Datasets\u003c/h3\u003e\u003ca id=\"user-content-person-detection-datasets\" class=\"anchor\" aria-label=\"Permalink: Person Detection Datasets\" href=\"#person-detection-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://lear.inrialpes.fr/data\" rel=\"nofollow\"\u003eINRIA Person\u003c/a\u003e : \"Histograms of oriented gradients for human detection\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/1467360\" rel=\"nofollow\"\u003eCVPR 2005\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://www.crowdhuman.org/\" rel=\"nofollow\"\u003eCrowdHuman\u003c/a\u003e : \"CrowdHuman: A Benchmark for Detecting Human in a Crowd\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1805.00123\" rel=\"nofollow\"\u003earXiv 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://www.panda-dataset.com\" rel=\"nofollow\"\u003ePANDA\u003c/a\u003e : \"PANDA: A Gigapixel-Level Human-Centric Video Dataset\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_CVPR_2020/html/Wang_PANDA_A_Gigapixel-Level_Human-Centric_Video_Dataset_CVPR_2020_paper.html\" rel=\"nofollow\"\u003eCVPR 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ucas-vg/PointTinyBenchmark\"\u003eTinyPerson\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e4f3118d42bda5763909ec1f95bcf7182dfccb70c3070e887e0d72d75b6f66c2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756361732d76672f506f696e7454696e7942656e63686d61726b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e4f3118d42bda5763909ec1f95bcf7182dfccb70c3070e887e0d72d75b6f66c2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756361732d76672f506f696e7454696e7942656e63686d61726b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ucas-vg/PointTinyBenchmark?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Scale Match for Tiny Person Detection\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_WACV_2020/html/Yu_Scale_Match_for_Tiny_Person_Detection_WACV_2020_paper.html\" rel=\"nofollow\"\u003eWACV 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ucas-vg/PointTinyBenchmark\"\u003eTinyPerson v2 | SeaPerson\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e4f3118d42bda5763909ec1f95bcf7182dfccb70c3070e887e0d72d75b6f66c2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756361732d76672f506f696e7454696e7942656e63686d61726b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e4f3118d42bda5763909ec1f95bcf7182dfccb70c3070e887e0d72d75b6f66c2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756361732d76672f506f696e7454696e7942656e63686d61726b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ucas-vg/PointTinyBenchmark?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Object Localization Under Single Coarse Point Supervision\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Object_Localization_Under_Single_Coarse_Point_Supervision_CVPR_2022_paper.html\" rel=\"nofollow\"\u003eCVPR 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAnti-UAV Datasets\u003c/h2\u003e\u003ca id=\"user-content-anti-uav-datasets\" class=\"anchor\" aria-label=\"Permalink: Anti-UAV Datasets\" href=\"#anti-uav-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZhaoJ9014/Anti-UAV\"\u003eAnti-UAV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f4011264d69ecf9a1839ac7bce6be873eeab7abb74913794ffcf866e7f9c5a36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68616f4a393031342f416e74692d5541563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f4011264d69ecf9a1839ac7bce6be873eeab7abb74913794ffcf866e7f9c5a36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68616f4a393031342f416e74692d5541563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZhaoJ9014/Anti-UAV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ”¥ðŸ”¥Official Repository for Anti-UAVðŸ”¥ðŸ”¥. Anti-UAV300, Anti-UAV410, Anti-UAV600. Please refer to our \u003ca href=\"https://ieeexplore.ieee.org/document/9615243\" rel=\"nofollow\"\u003eAnti-UAV v1\u003c/a\u003e paper and \u003ca href=\"https://arxiv.org/pdf/2306.15767.pdf\" rel=\"nofollow\"\u003eAnti-UAV v3\u003c/a\u003e paper for more details (\u003ca href=\"https://zhaoj9014.github.io/pub/Anti-UAV.pdf\" rel=\"nofollow\"\u003eWeChat News\u003c/a\u003e). \"Anti-UAV: A Large-Scale Benchmark for Vision-Based UAV Tracking\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/document/9615243\" rel=\"nofollow\"\u003eIEEE Transactions on Multimedia, 2022\u003c/a\u003e\u003c/strong\u003e). \"Evidential Detection and Tracking Collaboration: New Problem, Benchmark and Algorithm for Robust Anti-UAV System\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2306.15767\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wangdongdut/DUT-Anti-UAV\"\u003eDUT-Anti-UAV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6d1b7e1210c59ca143ac28ef22b2f92f54acc49ff085b6fab12c5d5385d3dbdc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e67646f6e676475742f4455542d416e74692d5541563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6d1b7e1210c59ca143ac28ef22b2f92f54acc49ff085b6fab12c5d5385d3dbdc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e67646f6e676475742f4455542d416e74692d5541563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wangdongdut/DUT-Anti-UAV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : DUT Anti-UAV Detection and Tracking. \"Vision-based Anti-UAV Detection and Tracking\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2205.10851\" rel=\"nofollow\"\u003eIEEE Transactions on Intelligent Transportation Systems, 2022\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOptical Aerial Imagery Datasets\u003c/h3\u003e\u003ca id=\"user-content-optical-aerial-imagery-datasets\" class=\"anchor\" aria-label=\"Permalink: Optical Aerial Imagery Datasets\" href=\"#optical-aerial-imagery-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LLNL/cowc\"\u003eCOWC\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e3f1f82b8a44a0c69b2709c2c33e4818fd02fcf0dffabf8222899331a70b7439/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c4c4e4c2f636f77633f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e3f1f82b8a44a0c69b2709c2c33e4818fd02fcf0dffabf8222899331a70b7439/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c4c4e4c2f636f77633f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LLNL/cowc?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"A large contextual dataset for classification, detection and counting of cars with deep learning\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/chapter/10.1007/978-3-319-46487-9_48\" rel=\"nofollow\"\u003eECCV 2016\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RSIA-LIESMARS-WHU/RSOD-Dataset-\"\u003eRSOD\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/60abf6309f4ccbdd708f1fcdc9604b7a6e00b291737094806c2c1909496b228c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f525349412d4c4945534d4152532d5748552f52534f442d446174617365742d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/60abf6309f4ccbdd708f1fcdc9604b7a6e00b291737094806c2c1909496b228c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f525349412d4c4945534d4152532d5748552f52534f442d446174617365742d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RSIA-LIESMARS-WHU/RSOD-Dataset-?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Accurate object localization in remote sensing images based on convolutional neural networks\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/7827088/\" rel=\"nofollow\"\u003eIEEE TGRS 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://levir.buaa.edu.cn/Code.htm\" rel=\"nofollow\"\u003eLEVIR\u003c/a\u003e : \"Random access memories: A new paradigm for target detection in high resolution aerial remote sensing images\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8106808\" rel=\"nofollow\"\u003eIEEE Transactions on Image Processing 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WindVChen/LEVIR-Ship\"\u003eLEVIR-Ship\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/814e0a4515b55437de7dab809dda43bc04f38d8dd7f1d316d2e0878f31076efe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57696e64564368656e2f4c455649522d536869703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/814e0a4515b55437de7dab809dda43bc04f38d8dd7f1d316d2e0878f31076efe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57696e64564368656e2f4c455649522d536869703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WindVChen/LEVIR-Ship?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"A Degraded Reconstruction Enhancement-based Method for Tiny Ship Detection in Remote Sensing Images with A New Large-scale Dataset\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9791363\" rel=\"nofollow\"\u003eIEEE TGRS 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.iuii.ua.es/datasets/masati/\" rel=\"nofollow\"\u003eMASATI\u003c/a\u003e : \"Automatic ship classification from optical aerial images with convolutional neural networks\". (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/2072-4292/10/4/511\" rel=\"nofollow\"\u003eRemote Sensing 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://xviewdataset.org/\" rel=\"nofollow\"\u003exView\u003c/a\u003e : \"xView: Objects in Context in Overhead Imagery\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1802.07856\" rel=\"nofollow\"\u003earXiv 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://captain-whu.github.io/DOTA/\" rel=\"nofollow\"\u003eDOTA\u003c/a\u003e : \"DOTA: A Large-Scale Dataset for Object Detection in Aerial Images\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_cvpr_2018/html/Xia_DOTA_A_Large-Scale_CVPR_2018_paper.html\" rel=\"nofollow\"\u003eCVPR 2018\u003c/a\u003e\u003c/strong\u003e). \"Object Detection in Aerial Images: A Large-Scale Benchmark and Challenges\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9560031\" rel=\"nofollow\"\u003eIEEE TPAMI 2021\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://research.utwente.nl/en/datasets/itcvd-dataset\" rel=\"nofollow\"\u003eITCVD\u003c/a\u003e : \"Deep Learning for Vehicle Detection in Aerial Images\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8451454\" rel=\"nofollow\"\u003eIEEE ICIP 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://www.patreo.dcc.ufmg.br/2019/07/10/bridge-dataset/\" rel=\"nofollow\"\u003eBridge Dataset\u003c/a\u003e : \"A Tool for Bridge Detection in Major Infrastructure Works Using Satellite Images\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8876942\" rel=\"nofollow\"\u003eIEEE ICIP 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://www.escience.cn/people/JunweiHan/DIOR.html\" rel=\"nofollow\"\u003eDIOR\u003c/a\u003e : \"Object detection in optical remote sensing images: A survey and a new benchmark\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S0924271619302825\" rel=\"nofollow\"\u003eISPRS 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mribrahim/PESMOD\"\u003ePESMOD\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/52db5594f0ef78f99079aedf7d472123f38b5b937029df907d72a8627872e1ce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d726962726168696d2f5045534d4f443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/52db5594f0ef78f99079aedf7d472123f38b5b937029df907d72a8627872e1ce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d726962726168696d2f5045534d4f443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mribrahim/PESMOD?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"UAV Images Dataset for Moving Object Detection from Moving Cameras\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2103.11460\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jwwangchn/AI-TOD\"\u003eAI-TOD\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1a8221700f10bb7bfbe2654718272d8cf0a138b705535dbd548193be481548b1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a7777616e6763686e2f41492d544f443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1a8221700f10bb7bfbe2654718272d8cf0a138b705535dbd548193be481548b1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a7777616e6763686e2f41492d544f443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jwwangchn/AI-TOD?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Tiny Object Detection in Aerial Images\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9413340\" rel=\"nofollow\"\u003eIEEE ICPR 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ChaoXiao12/Moving-object-detection-DSFNet\"\u003eRsCarData\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/35e444edbeff61845a84e93a9b7436dc0b723714190ae87c01947d1b92ba1cbe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368616f5869616f31322f4d6f76696e672d6f626a6563742d646574656374696f6e2d4453464e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/35e444edbeff61845a84e93a9b7436dc0b723714190ae87c01947d1b92ba1cbe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368616f5869616f31322f4d6f76696e672d6f626a6563742d646574656374696f6e2d4453464e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ChaoXiao12/Moving-object-detection-DSFNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"DSFNet: Dynamic and Static Fusion Network for Moving Object Detection in Satellite Videos\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9594855\" rel=\"nofollow\"\u003eIEEE GRSL 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/The-Learning-And-Vision-Atelier-LAVA/VISO\"\u003eVISO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8c1d77b068a0e04f227787a44168bf5941c1467433c9e1f53bf2722d0ba192c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5468652d4c6561726e696e672d416e642d566973696f6e2d4174656c6965722d4c4156412f5649534f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8c1d77b068a0e04f227787a44168bf5941c1467433c9e1f53bf2722d0ba192c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5468652d4c6561726e696e672d416e642d566973696f6e2d4174656c6965722d4c4156412f5649534f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/The-Learning-And-Vision-Atelier-LAVA/VISO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Detecting and Tracking Small and Dense Moving Objects in Satellite Videos: A Benchmark\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9625976\" rel=\"nofollow\"\u003eIEEE TGRS 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/VisDrone/VisDrone-Dataset\"\u003eVisDrone\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/28aa20e7816fa7416c5719a987cd92a06c6c6b0c0dc0033067332a3a29be4038/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f56697344726f6e652f56697344726f6e652d446174617365743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/28aa20e7816fa7416c5719a987cd92a06c6c6b0c0dc0033067332a3a29be4038/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f56697344726f6e652f56697344726f6e652d446174617365743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/VisDrone/VisDrone-Dataset?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Detection and Tracking Meet Drones Challenge\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9573394\" rel=\"nofollow\"\u003eIEEE TPAMI 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://gaofen-challenge.com/benchmark\" rel=\"nofollow\"\u003eFAIR1M\u003c/a\u003e : \"FAIR1M: A benchmark dataset for fine-grained object recognition in high-resolution remote sensing imagery\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S0924271621003269\" rel=\"nofollow\"\u003eISPRS 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ben93kie/SeaDronesSee\"\u003eSeaDronesSee\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9ca53b8e673bdc8ba257a00a747be8867fe7b6be14002f1c7ba14f8157483c0d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42656e39336b69652f53656144726f6e65735365653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9ca53b8e673bdc8ba257a00a747be8867fe7b6be14002f1c7ba14f8157483c0d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42656e39336b69652f53656144726f6e65735365653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ben93kie/SeaDronesSee?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"SeaDronesSee: A Maritime Benchmark for Detecting Humans in Open Water\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/WACV2022/html/Varga_SeaDronesSee_A_Maritime_Benchmark_for_Detecting_Humans_in_Open_Water_WACV_2022_paper.html\" rel=\"nofollow\"\u003eWACV 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eLow-light Image Datasets\u003c/h3\u003e\u003ca id=\"user-content-low-light-image-datasets\" class=\"anchor\" aria-label=\"Permalink: Low-light Image Datasets\" href=\"#low-light-image-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.nightowls-dataset.org/\" rel=\"nofollow\"\u003eNightOwls\u003c/a\u003e : \"NightOwls: A Pedestrians at Night Dataset\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/chapter/10.1007/978-3-030-20887-5_43\" rel=\"nofollow\"\u003eACCV 2018\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cs-chan/Exclusively-Dark-Image-Dataset\"\u003eExDark\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/306546bd00feb281e842dbc41e97c23882e42f560bd682431ef337d6b2bf8146/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63732d6368616e2f4578636c75736976656c792d4461726b2d496d6167652d446174617365743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/306546bd00feb281e842dbc41e97c23882e42f560bd682431ef337d6b2bf8146/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63732d6368616e2f4578636c75736976656c792d4461726b2d496d6167652d446174617365743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cs-chan/Exclusively-Dark-Image-Dataset?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Getting to know low-light images with the exclusively dark dataset\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S1077314218304296\" rel=\"nofollow\"\u003eCVIU 2019\u003c/a\u003e\u003c/strong\u003e). \"Low-light image enhancement using Gaussian Process for features retrieval\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S0923596518310452\" rel=\"nofollow\"\u003eSignal Processing: Image Communication, 2019\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://flyywh.github.io/CVPRW2019LowLight/\" rel=\"nofollow\"\u003eDARK FACE\u003c/a\u003e : DARK FACE: Face Detection in Low Light Condition. \"Advancing Image Understanding in Poor Visibility Environments: A Collective Benchmark Study\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9049390/\" rel=\"nofollow\"\u003eIEEE Transactions on Image Processing 2020\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eInfrared Image Datasets\u003c/h3\u003e\u003ca id=\"user-content-infrared-image-datasets\" class=\"anchor\" aria-label=\"Permalink: Infrared Image Datasets\" href=\"#infrared-image-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.scidb.cn/en/detail?dataSetId=720626420933459968\" rel=\"nofollow\"\u003eåœ°/ç©ºèƒŒæ™¯ä¸‹çº¢å¤–å›¾åƒå¼±å°é£žæœºç›®æ ‡æ£€æµ‹è·Ÿè¸ªæ•°æ®é›†\u003c/a\u003e (\u003cstrong\u003e\u003ca href=\"http://www.csdata.org/p/387/\" rel=\"nofollow\"\u003eä¸­å›½ç§‘å­¦æ•°æ®, 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.scidb.cn/en/detail?dataSetId=808025946870251520\" rel=\"nofollow\"\u003eå¤æ‚èƒŒæ™¯ä¸‹çº¢å¤–å¼±å°è¿åŠ¨ç›®æ ‡æ£€æµ‹æ•°æ®é›†\u003c/a\u003e (\u003cstrong\u003e\u003ca href=\"http://www.csdata.org/p/553/\" rel=\"nofollow\"\u003eä¸­å›½ç§‘å­¦æ•°æ®, 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.scidb.cn/en/detail?dataSetId=de971a1898774dc5921b68793817916e\" rel=\"nofollow\"\u003eé¢å‘ç©ºåœ°åº”ç”¨çš„çº¢å¤–æ—¶æ•ç›®æ ‡æ£€æµ‹è·Ÿè¸ªæ•°æ®é›†\u003c/a\u003e (\u003cstrong\u003e\u003ca href=\"http://www.csdata.org/p/673/\" rel=\"nofollow\"\u003eä¸­å›½ç§‘å­¦æ•°æ®, 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SCUT-CV/SCUT_FIR_Pedestrian_Dataset\"\u003eSCUT_FIR_Pedestrian_Dataset\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a46f473a19b758f55ad977e000e8a898f381b46673132f035dae17a8fb905e08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f534355542d43562f534355545f4649525f5065646573747269616e5f446174617365743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a46f473a19b758f55ad977e000e8a898f381b46673132f035dae17a8fb905e08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f534355542d43562f534355545f4649525f5065646573747269616e5f446174617365743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SCUT-CV/SCUT_FIR_Pedestrian_Dataset?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Benchmarking a large-scale FIR dataset for on-road pedestrian detection\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S1350449518305589\" rel=\"nofollow\"\u003eInfrared Physics \u0026amp; Technology, 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/YeRen123455/Infrared-Small-Target-Detection\"\u003eNUDT-SIRST\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9d325c0a32d06813d57035d981abe5c173373c158f43bb0ff886f064595aba68/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f596552656e3132333435352f496e6672617265642d536d616c6c2d5461726765742d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9d325c0a32d06813d57035d981abe5c173373c158f43bb0ff886f064595aba68/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f596552656e3132333435352f496e6672617265642d536d616c6c2d5461726765742d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/YeRen123455/Infrared-Small-Target-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Dense Nested Attention Network for Infrared Small Target Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2106.00487\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/YimianDai/sirst\"\u003eSIRST\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2eb9ee16d25febbfca778ba174d28be46d965b0eee49c0ebb83bf6e1bd60847e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59696d69616e4461692f73697273743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2eb9ee16d25febbfca778ba174d28be46d965b0eee49c0ebb83bf6e1bd60847e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59696d69616e4461692f73697273743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/YimianDai/sirst?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Asymmetric Contextual Modulation for Infrared Small Target Detection\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/WACV2021/html/Dai_Asymmetric_Contextual_Modulation_for_Infrared_Small_Target_Detection_WACV_2021_paper.html\" rel=\"nofollow\"\u003eWACV 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSAR Image Datasets\u003c/h3\u003e\u003ca id=\"user-content-sar-image-datasets\" class=\"anchor\" aria-label=\"Permalink: SAR Image Datasets\" href=\"#sar-image-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.sandia.gov/radar/pathfinder-radar-isr-and-synthetic-aperture-radar-sar-systems/video/\" rel=\"nofollow\"\u003eSNL VideoSAR\u003c/a\u003e : \"Developments in sar and ifsar systems and technologies at sandia national laboratories\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/1235522\" rel=\"nofollow\"\u003eIEEE Aerospace Conference Proceedings, 2003\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.sdms.afrl.af.mil/index.php?collection=mstar\" rel=\"nofollow\"\u003eMSTAR\u003c/a\u003e : MSTAR public dataset. \"Object recognition results using MSTAR synthetic aperture radar data\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/855250/\" rel=\"nofollow\"\u003eIEEE CVBVS 2000\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://opensar.sjtu.edu.cn/\" rel=\"nofollow\"\u003eOpenSARShip\u003c/a\u003e : \"OpenSARShip: A Dataset Dedicated to Sentinel-1 Ship Interpretation\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8067489\" rel=\"nofollow\"\u003eIEEE JSTAEORS 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://opensar.sjtu.edu.cn/\" rel=\"nofollow\"\u003eOpenSARShip 2.0\u003c/a\u003e : \"OpenSARShip 2.0: A large-volume dataset for deeper interpretation of ship targets in Sentinel-1 imagery\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8124929\" rel=\"nofollow\"\u003eIEEE BIGSARDATA 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://aistudio.baidu.com/aistudio/datasetdetail/54806\" rel=\"nofollow\"\u003eSSDD\u003c/a\u003e : \"Ship detection in SAR images based on an improved faster R-CNN\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8124934/\" rel=\"nofollow\"\u003eIEEE BIGSARDATA 2017\u003c/a\u003e\u003c/strong\u003e). \"åŸºäºŽæ·±åº¦å­¦ä¹ çš„SARå›¾åƒèˆ°èˆ¹æ£€æµ‹æ•°æ®é›†åŠæ€§èƒ½åˆ†æž\". (\u003cstrong\u003e\u003ca href=\"https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CPFD\u0026amp;dbname=CPFDLAST2019\u0026amp;filename=ZKZD201810001014\u0026amp;uniplatform=NZKPT\u0026amp;v=yO0QaBvz14EhL7pk2vCZgRGQl9EUK4g_ZLMv--RusqdnPK4jBUFATMtsDuwGc8fzPb9iLY3lVOI%3d\" rel=\"nofollow\"\u003eç¬¬äº”å±Šé«˜åˆ†è¾¨çŽ‡å¯¹åœ°è§‚æµ‹å­¦æœ¯å¹´ä¼š, 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://radars.ac.cn/web/data/getData?newsColumnId=1e6ecbcc-266d-432c-9c8a-0b9a922b5e85\" rel=\"nofollow\"\u003eAIR-SARShip\u003c/a\u003e : \"é«˜åˆ†è¾¨çŽ‡SARèˆ°èˆ¹æ£€æµ‹æ•°æ®é›†-2.0\". \"AIR-SARShip-1.0: é«˜åˆ†è¾¨çŽ‡ SAR èˆ°èˆ¹æ£€æµ‹æ•°æ®é›†\". (\u003cstrong\u003e\u003ca href=\"https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD\u0026amp;dbname=CJFDLAST2020\u0026amp;filename=LDAX201906014\u0026amp;uniplatform=NZKPT\u0026amp;v=pL57X-1uWs_T7QAY3gMTKZ1ZrPt1hdyAPDo3jpXRqPLbyAYbrH6-IAZMrqpRwS3J\" rel=\"nofollow\"\u003eé›·è¾¾å­¦æŠ¥ 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CAESAR-Radi/SAR-Ship-Dataset\"\u003eSAR-Ship-Dataset\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5bda6fc1e48687052d0bc31cca80763346e28bc9697af867a90ba6f7442c2a84/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4341455341522d526164692f5341522d536869702d446174617365743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5bda6fc1e48687052d0bc31cca80763346e28bc9697af867a90ba6f7442c2a84/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4341455341522d526164692f5341522d536869702d446174617365743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CAESAR-Radi/SAR-Ship-Dataset?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"A SAR Dataset of Ship Detection for Deep Learning under Complex Backgrounds\". (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/2072-4292/11/7/765\" rel=\"nofollow\"\u003eRemote Sensing, 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://opensar.sjtu.edu.cn/\" rel=\"nofollow\"\u003eOpenSARUrban\u003c/a\u003e : \"OpenSARUrban: A Sentinel-1 SAR Image Dataset for Urban Interpretation\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8952866/\" rel=\"nofollow\"\u003eIEEE JSTAEORS 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/chaozhong2010/HRSID\"\u003eHRSID\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b161040f3c98f657d52c1fee07f6b3f6e4cc23df6e0b082d3ccaad3ffd9fab60/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368616f7a686f6e67323031302f48525349443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b161040f3c98f657d52c1fee07f6b3f6e4cc23df6e0b082d3ccaad3ffd9fab60/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368616f7a686f6e67323031302f48525349443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/chaozhong2010/HRSID?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"HRSID: A High-Resolution SAR Images Dataset for Ship Detection and Instance Segmentation\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9127939\" rel=\"nofollow\"\u003eIEEE Access 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://emwlab.fudan.edu.cn/resources/\" rel=\"nofollow\"\u003eFUSAR-Ship\u003c/a\u003e : é«˜åˆ†è¾¨çŽ‡èˆ¹åªæ•°æ®é›†FUSAR-Ship1.0. (\u003cstrong\u003e\u003ca href=\"https://radars.ac.cn/web/data/getData?dataType=FUSAR\" rel=\"nofollow\"\u003eé›·è¾¾å­¦æŠ¥\u003c/a\u003e\u003c/strong\u003e). \"FUSAR-Ship: building a high-resolution SAR-AIS matchup dataset of Gaofen-3 for ship detection and recognition\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/article/10.1007/s11432-019-2772-5\" rel=\"nofollow\"\u003eScience China Information Sciences, 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TianwenZhang0825/Official-SSDD\"\u003eOfficial-SSDD\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cfce8cb07ecf20cbbf40ea6bb30ef1ed33872eaa82f341373db4139479c5002e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5469616e77656e5a68616e67303832352f4f6666696369616c2d535344443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cfce8cb07ecf20cbbf40ea6bb30ef1ed33872eaa82f341373db4139479c5002e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5469616e77656e5a68616e67303832352f4f6666696369616c2d535344443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TianwenZhang0825/Official-SSDD?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"SAR Ship Detection Dataset (SSDD): Official Release and Comprehensive Data Analysis \". (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/2072-4292/13/18/3690\" rel=\"nofollow\"\u003eRemote Sensing, 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://radars.ac.cn/web/data/getData?dataType=MSAR\" rel=\"nofollow\"\u003eMSAR\u003c/a\u003e : \"å¤§è§„æ¨¡å¤šç±»SARç›®æ ‡æ£€æµ‹æ•°æ®é›†-1.0\"ã€‚(\u003cstrong\u003e\u003ca href=\"https://radars.ac.cn/web/data/getData?dataType=MSAR\" rel=\"nofollow\"\u003eé›·è¾¾å­¦æŠ¥ 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://radars.ac.cn/web/data/getData?dataType=SDD-SAR\" rel=\"nofollow\"\u003eRSDD-SAR\u003c/a\u003e : \"RSDD-SAR:SARèˆ°èˆ¹æ–œæ¡†æ£€æµ‹æ•°æ®é›†\"ã€‚(\u003cstrong\u003e\u003ca href=\"https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD\u0026amp;dbname=CJFDLAST2022\u0026amp;filename=LDAX202204006\u0026amp;uniplatform=NZKPT\u0026amp;v=J3WR8KUVzuYM6uPXqbI64hl8oRAk3mvWRv3hrBCH9ZBek54uYq_UkJGY0PGaaxDg\" rel=\"nofollow\"\u003eé›·è¾¾å­¦æŠ¥ 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSonar Image Datasets\u003c/h3\u003e\u003ca id=\"user-content-sonar-image-datasets\" class=\"anchor\" aria-label=\"Permalink: Sonar Image Datasets\" href=\"#sonar-image-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://zenodo.org/records/10528135\" rel=\"nofollow\"\u003eSWDD\u003c/a\u003e : SWDD: Sonar Wall Detection Dataset. \"Knowledge Distillation in YOLOX-ViT for Side-Scan Sonar Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2403.09313\" rel=\"nofollow\"\u003earXiv 2024\u003c/a\u003e\u003c/strong\u003e). The Sonar Wall Detection Dataset (SWDD) is publicly accessible at \u003ca href=\"https://zenodo.org/records/10528135\" rel=\"nofollow\"\u003ehttps://zenodo.org/records/10528135\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eMultimodal Image Datasets\u003c/h3\u003e\u003ca id=\"user-content-multimodal-image-datasets\" class=\"anchor\" aria-label=\"Permalink: Multimodal Image Datasets\" href=\"#multimodal-image-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://adas-dataset-v2.flirconservator.com/\" rel=\"nofollow\"\u003eFLIR_ADAS\u003c/a\u003e : Teledyne FLIR Free ADAS Thermal Dataset v2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZhaoJ9014/Anti-UAV\"\u003eAnti-UAV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f4011264d69ecf9a1839ac7bce6be873eeab7abb74913794ffcf866e7f9c5a36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68616f4a393031342f416e74692d5541563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f4011264d69ecf9a1839ac7bce6be873eeab7abb74913794ffcf866e7f9c5a36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68616f4a393031342f416e74692d5541563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZhaoJ9014/Anti-UAV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ðŸ”¥ðŸ”¥Official Repository for Anti-UAVðŸ”¥ðŸ”¥. Anti-UAV300, Anti-UAV410, Anti-UAV600. Please refer to our \u003ca href=\"https://ieeexplore.ieee.org/document/9615243\" rel=\"nofollow\"\u003eAnti-UAV v1\u003c/a\u003e paper and \u003ca href=\"https://arxiv.org/pdf/2306.15767.pdf\" rel=\"nofollow\"\u003eAnti-UAV v3\u003c/a\u003e paper for more details (\u003ca href=\"https://zhaoj9014.github.io/pub/Anti-UAV.pdf\" rel=\"nofollow\"\u003eWeChat News\u003c/a\u003e). \"Anti-UAV: A Large-Scale Benchmark for Vision-Based UAV Tracking\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/document/9615243\" rel=\"nofollow\"\u003eIEEE Transactions on Multimedia, 2022\u003c/a\u003e\u003c/strong\u003e). \"Evidential Detection and Tracking Collaboration: New Problem, Benchmark and Algorithm for Robust Anti-UAV System\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2306.15767\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://downloads.greyc.fr/vedai/\" rel=\"nofollow\"\u003eVEDAI\u003c/a\u003e : \"Vehicle Detection in Aerial Imagery: A small target detection benchmark\". (\u003cstrong\u003e\u003ca href=\"https://hal.archives-ouvertes.fr/hal-01122605v2/document\" rel=\"nofollow\"\u003eJournal of Visual Communication and Image Representation 2015\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SoonminHwang/rgbt-ped-detection\"\u003eKAIST_rgbt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ba8ca8ddc6e139b98771a9a144e6d0199a58061fb8dd659b8ac064f880fa5847/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536f6f6e6d696e4877616e672f726762742d7065642d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ba8ca8ddc6e139b98771a9a144e6d0199a58061fb8dd659b8ac064f880fa5847/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536f6f6e6d696e4877616e672f726762742d7065642d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SoonminHwang/rgbt-ped-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Multispectral Pedestrian Detection: Benchmark Dataset and Baseline\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_cvpr_2015/html/Hwang_Multispectral_Pedestrian_Detection_2015_CVPR_paper.html\" rel=\"nofollow\"\u003eCVPR 2015\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bupt-ai-cz/LLVIP\"\u003eLLVIP\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/edb01f770fad6d847b683c3ee5bd2bc4a3e46e4f9fbe0f318b2568c8f70b07a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627570742d61692d637a2f4c4c5649503f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/edb01f770fad6d847b683c3ee5bd2bc4a3e46e4f9fbe0f318b2568c8f70b07a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627570742d61692d637a2f4c4c5649503f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bupt-ai-cz/LLVIP?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"LLVIP: A Visible-Infrared Paired Dataset for Low-Light Vision\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/ICCV2021W/RLQ/html/Jia_LLVIP_A_Visible-Infrared_Paired_Dataset_for_Low-Light_Vision_ICCVW_2021_paper.html\" rel=\"nofollow\"\u003eICCV 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://figshare.com/articles/dataset/TNO_Image_Fusion_Dataset/1008029\" rel=\"nofollow\"\u003eTNO\u003c/a\u003e : \"The TNO multiband image data collection\". (\u003cstrong\u003e\u003ca href=\"https://www.data-in-brief.com/article/S2352-3409(17)30469-9/abstract\" rel=\"nofollow\"\u003eData in brief, 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/haqishen/MFNet-pytorch\"\u003eMFNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/22493584dc2707c3407f06381751243e96fa906d51c6924b399b455959824f47/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686171697368656e2f4d464e65742d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/22493584dc2707c3407f06381751243e96fa906d51c6924b399b455959824f47/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686171697368656e2f4d464e65742d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/haqishen/MFNet-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : MFNet-pytorch, image semantic segmentation using RGB-Thermal images. \"MFNet: Towards real-time semantic segmentation for autonomous vehicles with multi-spectral scenes\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8206396/\" rel=\"nofollow\"\u003eIROS 2017\u003c/a\u003e\u003c/strong\u003e). (\u003ca href=\"https://www.mi.t.u-tokyo.ac.jp/static/projects/mil_multispectral/\" rel=\"nofollow\"\u003eMFNet Dataset\u003c/a\u003e : Multi-spectral Object Detection and Semantic Segmentation Datasets)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Linfeng-Tang/MSRS\"\u003eMSRS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/40ea7a9f195a9053f2db9564e5820e89435cb9ec7e959de58e0e91bb39f2cf71/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696e66656e672d54616e672f4d5352533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/40ea7a9f195a9053f2db9564e5820e89435cb9ec7e959de58e0e91bb39f2cf71/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696e66656e672d54616e672f4d5352533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Linfeng-Tang/MSRS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : MSRS: Multi-Spectral Road Scenarios for Practical Infrared and Visible Image Fusion. \"\u003ca href=\"https://github.com/Linfeng-Tang/PIAFusion\"\u003ePIAFusion\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/031252273c764b9a4d09d7ca9cc6667ca1a90e223141013f9a1aeabce05278d4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696e66656e672d54616e672f504941467573696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/031252273c764b9a4d09d7ca9cc6667ca1a90e223141013f9a1aeabce05278d4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696e66656e672d54616e672f504941467573696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Linfeng-Tang/PIAFusion?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e: A progressive infrared and visible image fusion network based on illumination aware\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S156625352200032X\" rel=\"nofollow\"\u003eInformation Fusion, 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/JinyuanLiu-CV/TarDAL\"\u003eTarDAL\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c7ce2deea252ddae517148e9b649b660ef312762782f7d171a3a9cc0c25a6441/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a696e7975616e4c69752d43562f54617244414c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c7ce2deea252ddae517148e9b649b660ef312762782f7d171a3a9cc0c25a6441/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a696e7975616e4c69752d43562f54617244414c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/JinyuanLiu-CV/TarDAL?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Target-Aware Dual Adversarial Learning and a Multi-Scenario Multi-Modality Benchmark To Fuse Infrared and Visible for Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Target-Aware_Dual_Adversarial_Learning_and_a_Multi-Scenario_Multi-Modality_Benchmark_To_CVPR_2022_paper.html\" rel=\"nofollow\"\u003eCVPR 2022\u003c/a\u003e\u003c/strong\u003e). (\u003ca href=\"https://drive.google.com/drive/folders/1H-oO7bgRuVFYDcMGvxstT1nmy0WF_Y_6?usp=sharing\" rel=\"nofollow\"\u003eM3FD Dataset\u003c/a\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/VisDrone/DroneVehicle\"\u003eDroneVehicle\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9161421ac43049de32620b71a608434ea519c4d29f6849316fe4dec17acf878d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f56697344726f6e652f44726f6e6556656869636c653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9161421ac43049de32620b71a608434ea519c4d29f6849316fe4dec17acf878d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f56697344726f6e652f44726f6e6556656869636c653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/VisDrone/DroneVehicle?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Drone-based RGB-Infrared Cross-Modality Vehicle Detection via Uncertainty-Aware Learning\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9759286/\" rel=\"nofollow\"\u003eIEEE TCSVT 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e3D Object Detection Datasets\u003c/h3\u003e\u003ca id=\"user-content-3d-object-detection-datasets\" class=\"anchor\" aria-label=\"Permalink: 3D Object Detection Datasets\" href=\"#3d-object-detection-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/google-research-datasets/Objectron\"\u003eObjectron\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ddfba5e9f93c1728525eb632bc9b9305d3227d2fab08062a5bef6832179de626/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f676f6f676c652d72657365617263682d64617461736574732f4f626a656374726f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ddfba5e9f93c1728525eb632bc9b9305d3227d2fab08062a5bef6832179de626/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f676f6f676c652d72657365617263682d64617461736574732f4f626a656374726f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/google-research-datasets/Objectron?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Objectron: A Large Scale Dataset of Object-Centric Videos in the Wild with Pose Annotations\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2021/html/Ahmadyan_Objectron_A_Large_Scale_Dataset_of_Object-Centric_Videos_in_the_CVPR_2021_paper.html?ref=https://githubhelp.com\" rel=\"nofollow\"\u003eCVPR, 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eVehicle-to-Everything Field Datasets\u003c/h3\u003e\u003ca id=\"user-content-vehicle-to-everything-field-datasets\" class=\"anchor\" aria-label=\"Permalink: Vehicle-to-Everything Field Datasets\" href=\"#vehicle-to-everything-field-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DerrickXuNu/OpenCOOD\"\u003eOpenCOOD|OPV2V\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b1f93ee81a31dffd275a77cbaf785c5de34ef59a207f325b16d2b565a0bcbb50/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465727269636b58754e752f4f70656e434f4f443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b1f93ee81a31dffd275a77cbaf785c5de34ef59a207f325b16d2b565a0bcbb50/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465727269636b58754e752f4f70656e434f4f443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DerrickXuNu/OpenCOOD?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : OpenCOOD is an Open COOperative Detection framework for autonomous driving. It is also the official implementation of the ICRA 2022 paper \u003ca href=\"https://mobility-lab.seas.ucla.edu/opv2v/\" rel=\"nofollow\"\u003eOPV2V\u003c/a\u003e. \"OPV2V: An Open Benchmark Dataset and Fusion Pipeline for Perception with Vehicle-to-Vehicle Communication\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9812038/\" rel=\"nofollow\"\u003eICRA, 2022\u003c/a\u003e\u003c/strong\u003e). \u003ca href=\"https://mobility-lab.seas.ucla.edu/opv2v/\" rel=\"nofollow\"\u003emobility-lab.seas.ucla.edu/opv2v/\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DerrickXuNu/CoBEVT\"\u003eCoBEVT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/981eb5d07c0fceddea3439d9ba6318cf9e5dd802a6d2681c8c2e799bade9bcea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465727269636b58754e752f436f424556543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/981eb5d07c0fceddea3439d9ba6318cf9e5dd802a6d2681c8c2e799bade9bcea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465727269636b58754e752f436f424556543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DerrickXuNu/CoBEVT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2207.02202\" rel=\"nofollow\"\u003eCoRL, 2022\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MediaBrain-SJTU/where2comm\"\u003eWhere2comm\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/790569a66ce9fe78100cc3fe65140302ecdfeeb95930b0cb9549c6da0f9ce800/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d65646961427261696e2d534a54552f776865726532636f6d6d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/790569a66ce9fe78100cc3fe65140302ecdfeeb95930b0cb9549c6da0f9ce800/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d65646961427261696e2d534a54552f776865726532636f6d6d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MediaBrain-SJTU/where2comm?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Where2comm: Communication-Efficient Collaborative Perception via Spatial Confidence Maps\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2209.12836\" rel=\"nofollow\"\u003eNeurips, 2022\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PJLab-ADG/LiDARSimLib-and-Placement-Evaluation\"\u003ePJLab-ADG/LiDARSimLib-and-Placement-Evaluation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d31b9608ba153953cc2288a9ce5724e510386db2ccff024a080dee39b1a9d06c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f504a4c61622d4144472f4c6944415253696d4c69622d616e642d506c6163656d656e742d4576616c756174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d31b9608ba153953cc2288a9ce5724e510386db2ccff024a080dee39b1a9d06c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f504a4c61622d4144472f4c6944415253696d4c69622d616e642d506c6163656d656e742d4576616c756174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PJLab-ADG/LiDARSimLib-and-Placement-Evaluation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Analyzing Infrastructure LiDAR Placement with Realistic LiDAR Simulation Library\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2211.15975\" rel=\"nofollow\"\u003eICRA, 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yifanlu0227/CoAlign\"\u003eCoAlign\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7afeff9fff21beb199ccf6c830e09ed2c5fd55fb385d6ebb2c8fa758dfe7cea7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796966616e6c75303232372f436f416c69676e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7afeff9fff21beb199ccf6c830e09ed2c5fd55fb385d6ebb2c8fa758dfe7cea7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796966616e6c75303232372f436f416c69676e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yifanlu0227/CoAlign?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Robust Collaborative 3D Object Detection in Presence of Pose Errors\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2211.07214\" rel=\"nofollow\"\u003eICRA, 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ucla-mobility/V2V4Real\"\u003eV2V4Real\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0b9de56e3c3a33bb2dcfcd4308cbb82fede97c35b723dc596f6fc11f34c24e01/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f75636c612d6d6f62696c6974792f563256345265616c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0b9de56e3c3a33bb2dcfcd4308cbb82fede97c35b723dc596f6fc11f34c24e01/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f75636c612d6d6f62696c6974792f563256345265616c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ucla-mobility/V2V4Real?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"V2V4Real: A Real-World Large-Scale Dataset for Vehicle-to-Vehicle Cooperative Perception\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2023/html/Xu_V2V4Real_A_Real-World_Large-Scale_Dataset_for_Vehicle-to-Vehicle_Cooperative_Perception_CVPR_2023_paper.html\" rel=\"nofollow\"\u003eCVPR, 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DerrickXuNu/v2x-vit\"\u003eV2X-ViT|V2XSet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/85c04a98f5eaa98b4ec6c8035168ce0dddef1bc75d138d1dcddf01f4df9d3b48/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465727269636b58754e752f7632782d7669743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/85c04a98f5eaa98b4ec6c8035168ce0dddef1bc75d138d1dcddf01f4df9d3b48/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465727269636b58754e752f7632782d7669743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DerrickXuNu/v2x-vit?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"V2X-ViT: Vehicle-to-Everything Cooperative Perception with Vision Transformer\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/chapter/10.1007/978-3-031-19842-7_7\" rel=\"nofollow\"\u003eECCV, 2022\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AIR-THU/DAIR-V2X\"\u003eDAIR-V2X\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cac158228171b79bb69210ff145290bfc06cc4895b981fb335051cf8cc5f8c5d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4149522d5448552f444149522d5632583f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cac158228171b79bb69210ff145290bfc06cc4895b981fb335051cf8cc5f8c5d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4149522d5448552f444149522d5632583f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AIR-THU/DAIR-V2X?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"DAIR-V2X: A Large-Scale Dataset for Vehicle-Infrastructure Cooperative 3D Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2022/html/Yu_DAIR-V2X_A_Large-Scale_Dataset_for_Vehicle-Infrastructure_Cooperative_3D_Object_Detection_CVPR_2022_paper.html\" rel=\"nofollow\"\u003eCVPR, 2022\u003c/a\u003e\u003c/strong\u003e). \u003ca href=\"https://thudair.baai.ac.cn\" rel=\"nofollow\"\u003eå…¨çƒé¦–ä¸ªè½¦è·¯ååŒè‡ªåŠ¨é©¾é©¶æ•°æ®é›†å‘å¸ƒ\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AIR-THU/DAIR-V2X-Seq\"\u003eV2X-Seq\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9667030a51278c578149979ef904b1413bf40291d2748518873098698c9bfa4a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4149522d5448552f444149522d5632582d5365713f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9667030a51278c578149979ef904b1413bf40291d2748518873098698c9bfa4a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4149522d5448552f444149522d5632582d5365713f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AIR-THU/DAIR-V2X-Seq?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"V2X-Seq: A Large-Scale Sequential Dataset for Vehicle-Infrastructure Cooperative Perception and Forecasting\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2023/html/Yu_V2X-Seq_A_Large-Scale_Sequential_Dataset_for_Vehicle-Infrastructure_Cooperative_Perception_and_CVPR_2023_paper.html\" rel=\"nofollow\"\u003eCVPR, 2023\u003c/a\u003e\u003c/strong\u003e). \u003ca href=\"https://thudair.baai.ac.cn\" rel=\"nofollow\"\u003eå…¨çƒé¦–ä¸ªå¤§è§„æ¨¡æ—¶åºè½¦è·¯ååŒè‡ªåŠ¨é©¾é©¶æ•°æ®é›†å‘å¸ƒ\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSuper-Resolution Field Datasets\u003c/h3\u003e\u003ca id=\"user-content-super-resolution-field-datasets\" class=\"anchor\" aria-label=\"Permalink: Super-Resolution Field Datasets\" href=\"#super-resolution-field-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/ckkelvinchan/RealBasicVSR\"\u003eVideoLQ\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c1dac845df8e87ded36638c141bea69fea50f6c27b71c5af00a944a7a46e1d0b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636b6b656c76696e6368616e2f5265616c42617369635653523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c1dac845df8e87ded36638c141bea69fea50f6c27b71c5af00a944a7a46e1d0b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636b6b656c76696e6368616e2f5265616c42617369635653523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ckkelvinchan/RealBasicVSR?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Investigating Tradeoffs in Real-World Video Super-Resolution\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2022/html/Chan_Investigating_Tradeoffs_in_Real-World_Video_Super-Resolution_CVPR_2022_paper.html\" rel=\"nofollow\"\u003eCVPR, 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFace Detection and Recognition Datasets\u003c/h3\u003e\u003ca id=\"user-content-face-detection-and-recognition-datasets\" class=\"anchor\" aria-label=\"Permalink: Face Detection and Recognition Datasets\" href=\"#face-detection-and-recognition-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFace Detection Datasets\u003c/h4\u003e\u003ca id=\"user-content-face-detection-datasets\" class=\"anchor\" aria-label=\"Permalink: Face Detection Datasets\" href=\"#face-detection-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://shuoyang1213.me/WIDERFACE/\" rel=\"nofollow\"\u003eWIDER FACE\u003c/a\u003e : \"WIDER FACE: A Face Detection Benchmark\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_cvpr_2016/html/Yang_WIDER_FACE_A_CVPR_2016_paper.html\" rel=\"nofollow\"\u003eCVPR 2016\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://ufdd.info/\" rel=\"nofollow\"\u003eUFDD\u003c/a\u003e : Unconstrained Face Detection Dataset(UFDD). \"Pushing the Limits of Unconstrained Face Detection: a Challenge Dataset and Baseline Results\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8698561l\" rel=\"nofollow\"\u003eIEEE BTAS 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HCIILAB/SCUT-HEAD-Dataset-Release\"\u003eHCIILAB/SCUT-HEAD-Dataset-Release\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a0bea223e25580aa0ae042a659ec0a6ed3c41e71fdc400c9a87a76ea52e2d79d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f484349494c41422f534355542d484541442d446174617365742d52656c656173653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a0bea223e25580aa0ae042a659ec0a6ed3c41e71fdc400c9a87a76ea52e2d79d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f484349494c41422f534355542d484541442d446174617365742d52656c656173653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HCIILAB/SCUT-HEAD-Dataset-Release?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : SCUT HEAD is a large-scale head detection dataset, including 4405 images labeld with 111251 heads. \"Detecting Heads using Feature Refine Net and Cascaded Multi-scale Architecture\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1803.09256\" rel=\"nofollow\"\u003earXiv, 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFace Recognition Datasets\u003c/h4\u003e\u003ca id=\"user-content-face-recognition-datasets\" class=\"anchor\" aria-label=\"Permalink: Face Recognition Datasets\" href=\"#face-recognition-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://vis-www.cs.umass.edu/lfw/\" rel=\"nofollow\"\u003eLFW\u003c/a\u003e : Labeled Faces in the Wild(LFW). \"Labeled Faces in the Wild: A Database forStudying Face Recognition in Unconstrained Environments\". (\u003cstrong\u003e\u003ca href=\"https://hal.inria.fr/inria-00321923/\" rel=\"nofollow\"\u003eWorkshop on faces in'Real-Life'Images: detection, alignment, and recognition. 2008\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://www.cs.tau.ac.il/~wolf/ytfaces/\" rel=\"nofollow\"\u003eYouTube Faces (YTF)\u003c/a\u003e : \"Face recognition in unconstrained videos with matched background similarity\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/5995566\" rel=\"nofollow\"\u003eCVPR 2011\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://pan.baidu.com/s/1k3Cel2wSHQxHO9NkNi3rkg\" rel=\"nofollow\"\u003eCASIA-WebFace\u003c/a\u003e : \"Learning Face Representation from Scratch\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1411.7923\" rel=\"nofollow\"\u003earXiv 2014\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.nist.gov/programs-projects/face-challenges\" rel=\"nofollow\"\u003eIJB-A\u003c/a\u003e : \"Pushing the Frontiers of Unconstrained Face Detection and Recognition: IARPA Janus Benchmark A\". (\u003cstrong\u003e\u003ca href=\"https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Klare_Pushing_the_Frontiers_2015_CVPR_paper.html\" rel=\"nofollow\"\u003eCVPR 2015\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://academictorrents.com/details/9e67eb7cc23c9417f39778a8e06cca5e26196a97/tech\u0026amp;hit=1\u0026amp;filelist=1\" rel=\"nofollow\"\u003eMS-Celeb-1M\u003c/a\u003e : \"MS-Celeb-1M: A Dataset and Benchmark for Large-Scale Face Recognition\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/chapter/10.1007/978-3-319-46487-9_6\" rel=\"nofollow\"\u003eECCV 2016\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://megaface.cs.washington.edu/\" rel=\"nofollow\"\u003eMegaFace\u003c/a\u003e : \"The MegaFace Benchmark: 1 Million Faces for Recognition at Scale\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_cvpr_2016/html/Kemelmacher-Shlizerman_The_MegaFace_Benchmark_CVPR_2016_paper.html\" rel=\"nofollow\"\u003eCVPR 2016\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.umdfaces.io/\" rel=\"nofollow\"\u003eUMDFaces\u003c/a\u003e : \"UMDFaces: An annotated face dataset for training deep networks\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8272731\" rel=\"nofollow\"\u003eIJCB 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.nist.gov/programs-projects/face-challenges\" rel=\"nofollow\"\u003eIJB-B\u003c/a\u003e : \"IARPA Janus Benchmark-B Face Dataset\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_cvpr_2017_workshops/w6/html/Whitelam_IARPA_Janus_Benchmark-B_CVPR_2017_paper.html\" rel=\"nofollow\"\u003eCVPR 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.nist.gov/programs-projects/face-challenges\" rel=\"nofollow\"\u003eIJB-C\u003c/a\u003e : \"IARPA Janus Benchmark - C: Face Dataset and Protocol\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8411217\" rel=\"nofollow\"\u003eICB 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"/coderonion/awesome-yolo-object-detection/blob/main\"\u003eVGGFace2\u003c/a\u003e : \"VGGFace2: A Dataset for Recognising Faces across Pose and Age\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8373813\" rel=\"nofollow\"\u003eFG 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eBlogs\u003c/h2\u003e\u003ca id=\"user-content-blogs\" class=\"anchor\" aria-label=\"Permalink: Blogs\" href=\"#blogs\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒIDEAæ•°å­—ç»æµŽç ”ç©¶é™¢ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/bT_SbHlkyGaas-J6MkugPw\" rel=\"nofollow\"\u003e2024-11-22ï¼ŒIDEAç ”ç©¶é™¢å‘å¸ƒDINO-Xç›®æ ‡æ£€æµ‹è§†è§‰å¤§æ¨¡åž‹ï¼šä¸‡ç‰©è¯†åˆ«ï¼Œå¼€æ”¾ä¸–ç•Œ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.zhihu.com/people/nan-yang-8-13\" rel=\"nofollow\"\u003eçŸ¥ä¹Žã€Œæ±Ÿå¤§ç™½ã€| å¾®ä¿¡å…¬ä¼—å·ã€Œæ±Ÿå¤§ç™½ã€\u003c/a\u003e\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/143747206\" rel=\"nofollow\"\u003e2020-05-27ï¼Œæ·±å…¥æµ…å‡ºYoloç³»åˆ—ä¹‹Yolov3\u0026amp;Yolov4\u0026amp;Yolov5\u0026amp;Yoloxæ ¸å¿ƒåŸºç¡€çŸ¥è¯†å®Œæ•´è®²è§£\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/172121380\" rel=\"nofollow\"\u003e2020-08-10ï¼Œæ·±å…¥æµ…å‡ºYoloç³»åˆ—ä¹‹Yolov5æ ¸å¿ƒåŸºç¡€çŸ¥è¯†å®Œæ•´è®²è§£\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/397499216\" rel=\"nofollow\"\u003e2021-08-09ï¼Œæ·±å…¥æµ…å‡ºYoloxä¹‹è‡ªæœ‰æ•°æ®é›†è®­ç»ƒè¶…è¯¦ç»†æ•™ç¨‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/397993315\" rel=\"nofollow\"\u003e2021-08-11ï¼Œæ·±å…¥æµ…å‡ºYoloç³»åˆ—ä¹‹Yoloxæ ¸å¿ƒåŸºç¡€å®Œæ•´è®²è§£\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/463221190\" rel=\"nofollow\"\u003e2022-01-30ï¼Œæ·±å…¥æµ…å‡º0åŸºç¡€å…¥é—¨AIåŠç›®æ ‡æ£€æµ‹è¯¦ç»†å­¦ä¹ è·¯å¾„\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/463176500\" rel=\"nofollow\"\u003e2022-01-30ï¼Œæ·±å…¥æµ…å‡ºYolov5ä¹‹è‡ªæœ‰æ•°æ®é›†è®­ç»ƒè¶…è¯¦ç»†æ•™ç¨‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/HqXJov5fWIlgKhMp2_Ca7g\" rel=\"nofollow\"\u003e2022-11-03ï¼Œå®žè·µæ•™ç¨‹ | åœ¨yolov5ä¸ŠéªŒè¯çš„ä¸€äº›æƒ³æ³•å°è¯•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/lm77Fe4e6e_cx_gJYhp8QA\" rel=\"nofollow\"\u003e2022-12-17ï¼ŒYOLOv6ç²¾åº¦æ·±åº¦ä¼˜åŒ–ï¼Œæ„ŸçŸ¥é‡åŒ–çš„é‡å‚å†è®¾è®¡\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/QZnpo24537fhGeFj7-MR_Q\" rel=\"nofollow\"\u003e2022-12-28ï¼ŒRepvggé‡å‚æ•°åŒ–ï¼ŒYOLOæ£€æµ‹ç®—æ³•æ¶¨ç‚¹å®žè·µï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/zhoFAKvFOHh0T1R2fvwZxQ\" rel=\"nofollow\"\u003e2023-01-16ï¼ŒYOLOv8è‡ªæœ‰æ•°æ®é›†è®­ç»ƒï¼ŒåŠå¤šä»»åŠ¡ä½¿ç”¨è¯¦ç»†æ•™ç¨‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/rDpbzIG95TmgpJQH71QY8g\" rel=\"nofollow\"\u003e2023-01-28ï¼ŒYOLOv8+DeepSORTåŽŸç†è®²è§£åŠå®žçŽ°ï¼ˆé™„æºç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/C3O3QeSUnu4LUBxHZtur7A\" rel=\"nofollow\"\u003e2023-02-23ï¼Œæ·±å…¥æµ…å‡ºTensorRTä¸­ONNXæ¨¡åž‹è§£æžè¿‡ç¨‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/AdnfJ48mnwFejTtHN4v70w\" rel=\"nofollow\"\u003e2023-02-24ï¼Œæ¨¡åž‹éƒ¨ç½² | TensorRTåŠ é€ŸPyTorchå®žæˆ˜éƒ¨ç½²æ•™ç¨‹ï¼Œå€¼å¾—æ”¶è—å­¦ä¹ ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/DZcVdwFZP3TKaTk0n98oeg\" rel=\"nofollow\"\u003e2023-02-25ï¼ŒYOLOv8+ByteTrackï¼Œä½œè€…å¼€æºå¤šç›®æ ‡è·Ÿè¸ªç®—æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/9qpuLCvgaQjc_JOdZchxjQ\" rel=\"nofollow\"\u003e2023-02-27ï¼ŒåŸºäºŽYOLOv5çš„åŠç›‘ç£ç›®æ ‡æ£€æµ‹ï¼Œç®—æ³•è¿›é˜¶ä¹‹è·¯ï¼Œé˜¿é‡Œå›¢é˜Ÿæ–°ä½œï¼ï¼ˆé™„è®ºæ–‡åŠæºç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/3YnNAx_2PFqpxLUZZWoYAg\" rel=\"nofollow\"\u003e2023-03-18ï¼ŒEfficient Teacherï¼Œé’ˆå¯¹YOLOv5çš„åŠç›‘ç£ç›®æ ‡æ£€æµ‹ç®—æ³•ï¼ˆé™„è®ºæ–‡åŠæºç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qkktjhALMKgRwSSiq6n5bA\" rel=\"nofollow\"\u003e2023-03-20ï¼Œonnxæ¨¡åž‹è½¬æ¢ï¼Œopä¸æ”¯æŒæ—¶çš„å¿ƒå¾—ç»éªŒåˆ†äº«\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/xyCNXUBE2rTjTUnK6bBm7g\" rel=\"nofollow\"\u003e2023-03-24ï¼Œæ·±åº¦å­¦ä¹ æ¨¡åž‹è®­ç»ƒä¸­ï¼ŒGPUå’Œæ˜¾å­˜åˆ†æž\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/54FaTRh8dUXwI4JqO9LAsQ\" rel=\"nofollow\"\u003e2023-03-25ï¼ŒPyTorchæ¨¡åž‹è®­ç»ƒï¼Œå¹¶è¡ŒåŠ é€Ÿæ–¹æ³•æ¢³ç†æ±‡æ€»\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/sTL6aATIDOh8RpicU2B9tA\" rel=\"nofollow\"\u003e2023-03-27ï¼ŒåŸºäºŽYOLOçš„é“åž‹æè¡¨é¢ç¼ºé™·è¯†åˆ« \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/fXV3rdB_YtSVap0FtK_AeQ\" rel=\"nofollow\"\u003e2023-03-31ï¼Œå°ç›®æ ‡æ£€æµ‹ç²¾åº¦ä¼˜åŒ–æ–¹å¼ï¼ŒCEASAæ¨¡å—ï¼Œå³æ’å³ç”¨ï¼ˆé™„è®ºæ–‡åŠæºç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/LCJZqnNB6C15EEMPB1X-hQ\" rel=\"nofollow\"\u003e2023-04-01ï¼ŒGPU åˆ©ç”¨çŽ‡ä½Žå¸¸è§åŽŸå› åˆ†æžåŠä¼˜åŒ–\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/KEdsJO1z19sq7rTtwyC4Rg\" rel=\"nofollow\"\u003e2023-04-03ï¼Œå°ç›®æ ‡æ£€æµ‹ç®—æ³•ï¼ŒYolov5ä¼˜åŒ–å‡çº§ ï¼Œå³æ’å³ç”¨ï¼Œå€¼å¾—å°è¯•ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/3rQQ31LWxvDli_1uwGsHIw\" rel=\"nofollow\"\u003e2023-04-22ï¼ŒCUDAå·ç§¯ç®—å­ï¼Œæ‰‹å†™è¯¦ç»†å®žçŽ°æµç¨‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/pij3APMt_wtyS6St89lbdQ\" rel=\"nofollow\"\u003e2023-04-28ï¼Œæ·±å…¥æµ…å‡ºPyTorchæ¨¡åž‹ï¼Œint8é‡åŒ–åŠåŽŸç†æµç¨‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/SvgTQfKqGlI5DsrsmfKUhA\" rel=\"nofollow\"\u003e2023-04-29ï¼ŒAIè§†è§‰é¡¹ç›®ï¼Œå›¾åƒæ ‡æ³¨å·¥å…·æ¢³ç†æ±‡æ€»\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/f-sD8ukV3Nm28_-yHi44BA\" rel=\"nofollow\"\u003e2023-05-08ï¼ŒLabel-Studio X SAMï¼ŒåŠè‡ªåŠ¨åŒ–æ ‡æ³¨ç¥žå™¨ï¼ˆé™„æºç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/aYam5aQXJTZ1ysubEfewYA\" rel=\"nofollow\"\u003e2023-05-09ï¼Œæ·±å…¥æµ…å‡ºå¤šç›®æ ‡è·Ÿè¸ªæŠ€æœ¯çš„ç ”ç©¶ä¸ŽæŽ¢ç´¢\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/NfUWJ5cBTXvuB45l1hnSfw\" rel=\"nofollow\"\u003e2023-05-10ï¼Œè¶…å¼ºç›®æ ‡æ£€æµ‹å™¨RT-DETRï¼Œä¿å§†çº§éƒ¨ç½²æ•™ç¨‹ï¼Œä»Žå…¥é—¨åˆ°ç²¾é€šï¼ˆé™„è®ºæ–‡åŠæºç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/exo2JkLluChvLDSif2JvMQ\" rel=\"nofollow\"\u003e2023-05-13ï¼ŒYOLOCSç›®æ ‡æ£€æµ‹ç®—æ³•ï¼ŒYOLOv5çš„Backbone/Neck/Headå…¨é¢æ”¹è¿›\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/PkzzElN1uk2Yzu1DsYnOdQ\" rel=\"nofollow\"\u003e2023-05-17ï¼Œä¸€æ–‡çœ‹å°½æ·±åº¦å­¦ä¹ å„ç§æ³¨æ„åŠ›æœºåˆ¶ï¼Œå­¦ä¹ æŽ¨èï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/a9LK35lLE4yfQkqvBp6ujQ\" rel=\"nofollow\"\u003e2023-05-26ï¼Œä¸€æ–‡è¯»æ‡‚PyTorchæ˜¾å­˜ç®¡ç†æœºåˆ¶ï¼ŒæŽ¨èå­¦ä¹ ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/EBc1JrR5n4BlWGBx8kuiXw\" rel=\"nofollow\"\u003e2023-06-05ï¼Œä¸¤ä¸‡å­—é•¿æ–‡ï¼Œç›®æ ‡æ£€æµ‹å…¥é—¨çœ‹è¿™ç¯‡å°±å¤Ÿäº†ï¼ŒæŽ¨èæ”¶è—ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/-8A_XaOwHyg653UyRbArQQ\" rel=\"nofollow\"\u003e2023-06-07ï¼Œæ‰‹æŠŠæ‰‹å¸¦ä½ ï¼Œè‡ªå·±è®¾è®¡å®žçŽ°ä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¡†æž¶ï¼ˆé™„ä»£ç å®žçŽ°ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/U3irSW9UTKt0gY0HCV9slQ\" rel=\"nofollow\"\u003e2023-06-12ï¼ŒMMDetectionç›®æ ‡æ£€æµ‹æ¡†æž¶è¯¦è§£ï¼ŒåŠè®­ç»ƒè‡ªæœ‰æ•°æ®é›†æ•™ç¨‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/vXIx7dBRxgxnvh5BoIRQZw\" rel=\"nofollow\"\u003e2023-06-19ï¼Œä¸‡å­—é•¿æ–‡ï¼Œå½»åº•æžæ‡‚YOLOv8ç½‘ç»œç»“æž„åŠä»£ç å®žæˆ˜ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/E-Iebdd4Es5UK-TrBUJcjA\" rel=\"nofollow\"\u003e2023-06-27ï¼ŒTensorRTæ¨¡åž‹éƒ¨ç½²ï¼Œæ·»åŠ è‡ªå·±æ’ä»¶çš„è½åœ°æ–¹å¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/znxT8nsfkq0s5NHRnAxYaw\" rel=\"nofollow\"\u003e2023-06-29ï¼ŒYOLOv7+Transformeréƒ¨ç½²ï¼ŒTensorRTåº”ç”¨å®žæˆ˜ï¼ˆé™„ä»£ç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/TQ88Oex6YTKAkUZL3kLu3A\" rel=\"nofollow\"\u003e2023-07-06ï¼Œä¸‡å­—é•¿æ–‡ï¼ŒåŸºäºŽPyTorchçš„å¤šç§å·ç§¯ç¥žç»ç½‘ç»œBackBoneä»£ç å®žçŽ°\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/1yvJIObEs9H4C9Qd3tb9kA\" rel=\"nofollow\"\u003e2023-07-21ï¼Œä¸‡å­—é•¿æ–‡ï¼ŒYOLOv5æ‰‹åŠ¿è¯†åˆ«è®­ç»ƒè½¬æ¢åŠæ¨¡åž‹éƒ¨ç½²ï¼ï¼ˆé™„ä»£ç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Phu7UmPKuSrUOhCQDV2xEQ\" rel=\"nofollow\"\u003e2023-08-03ï¼ŒTensorRTæ¨¡åž‹INT8é‡åŒ–ï¼ŒPythonä»£ç éƒ¨ç½²å®žçŽ°\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/_JDPP7Yq8E4bXxZtWlOy6Q\" rel=\"nofollow\"\u003e2023-08-12ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•ï¼Œæ£€æµ‹æ¡†ä½ç½®ä¼˜åŒ–æ€»ç»“\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/plWUuEVkbK-nDycqVDFU8A\" rel=\"nofollow\"\u003e2023-09-01ï¼ŒåŸºäºŽYoloç®—æ³•çš„AIæ•°é’¢ç­‹ï¼Œæ•´ä½“è§£å†³æ–¹æ¡ˆæ±‡æ€»\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/9naZZ7wXugppelcmPHGVlQ\" rel=\"nofollow\"\u003e2024-01-26ï¼Œæ·±å…¥æµ…å‡ºï¼ŒYOLOv8ç®—æ³•ä½¿ç”¨æŒ‡å—\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/RVG-9h8zKsWACMr6dDRpUQ\" rel=\"nofollow\"\u003e2024-02-23ï¼Œç›®æ ‡æ£€æµ‹YOLOv9ç®—æ³•ï¼Œé‡ç£…å¼€æºï¼ï¼ˆé™„è®ºæ–‡åŠæºç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/FC9KtCPpwEraYuj4qnw_oQ\" rel=\"nofollow\"\u003e2024-04-04ï¼ŒCPUæŽ¨ç†1msçš„Backboneå¼€æºï¼Œç²¾åº¦é€Ÿåº¦ç¢¾åŽ‹MobileNet/ShuffleNetç­‰è½»é‡æ¨¡åž‹ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/j2QS3LdudrrlyZYQkVrl5Q\" rel=\"nofollow\"\u003e2024-04-12ï¼Œæ·±å…¥æµ…å‡ºï¼ŒPyTorchæ¨¡åž‹int8é‡åŒ–åŽŸç†æ‹†è§£\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/UREcCHvyl7yIEv_si9KOjQ\" rel=\"nofollow\"\u003e2024-06-18ï¼ŒMamba-YOLOå¼€æºï¼Œè¶…è¶Š YOLO ï¼Œåˆ›æ–°SSM æŠ€æœ¯ï¼Œæå‡ç›®æ ‡æ£€æµ‹æ€§èƒ½ï¼ï¼ˆé™„è®ºæ–‡åŠæºç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/wTwjDESVipFg2Tnh9Mgp6A\" rel=\"nofollow\"\u003e2024-07-13ï¼ŒYOLOv5ã€YOLOv8ä¸ŽYOLOv10ï¼Œæ€§èƒ½åˆ†æžä¸Žè¾¹ç¼˜éƒ¨ç½²æ¢³ç†ï¼ŒYOLOç®—æ³•è¿›åŒ–å²ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/aYWq8CDXATrk4KAwWQqvIg\" rel=\"nofollow\"\u003e2024-09-07ï¼ŒYOLOv8ç®—æ³•æ¨¡åž‹æ·±åº¦è§£æžï¼šæž¶æž„åˆ›æ–°ã€æ€§èƒ½æå‡ä¸Žç”¨æˆ·å‹å¥½æ€§æ”¹è¿›ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/UQeB-Opy46bMQ1eTg1ZzRg\" rel=\"nofollow\"\u003e2025-04-14ï¼ŒTPAMI 2025ï¼Œå›½é˜²ç§‘å¤§æå‡ºRGBT-Tinyæ•°æ®é›†ï¼ŒåŠ©åŠ›å°ç›®æ ‡æ£€æµ‹å‘å±•ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/wETR_rxbe5hYiyVLT1Qo8w\" rel=\"nofollow\"\u003e2025-04-16ï¼ŒTPAMI 2025ï¼ŒYOLOv12-BoT-SORT-ReIDï¼Œæ— äººæœºæ£€æµ‹åŠè¿½è¸ªç®—æ³•ï¼Œé—®é¼Žæ— äººæœºæŒ‘æˆ˜èµ›ï¼ˆé™„è®ºæ–‡ä¸Žæºç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.zhihu.com/people/nemofeng95\" rel=\"nofollow\"\u003eçŸ¥ä¹Žã€Œè¿ªè¿¦å¥¥ç‰¹æ›¼ã€\u003c/a\u003e\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/550057480\" rel=\"nofollow\"\u003e2022-08-12ï¼Œä»Žç™¾åº¦é£žæ¡¨YOLOSeriesåº“çœ‹å„ä¸ªYOLOæ¨¡åž‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/566469003\" rel=\"nofollow\"\u003e2022-09-21ï¼ŒYOLOå†…å·æ—¶æœŸè¯¥å¦‚ä½•é€‰æ¨¡åž‹ï¼Ÿ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.zhihu.com/people/LEYM2\" rel=\"nofollow\"\u003eçŸ¥ä¹Žã€ŒPoemAIã€\u003c/a\u003e\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/539932517\" rel=\"nofollow\"\u003e2022-07-10ï¼ŒYOLOå®¶æ—è¿›åŒ–å²ï¼ˆv1-v7ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.zhihu.com/people/wang-jia-hao-53-3\" rel=\"nofollow\"\u003eçŸ¥ä¹Žã€Œç§‘æŠ€çŒ›å…½ã€\u003c/a\u003e\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/183261974\" rel=\"nofollow\"\u003e2020-08-14ï¼Œä½ ä¸€å®šä»Žæœªçœ‹è¿‡å¦‚æ­¤é€šä¿—æ˜“æ‡‚çš„YOLOç³»åˆ—(ä»Žv1åˆ°v5)æ¨¡åž‹è§£è¯» (ä¸Š)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/183781646\" rel=\"nofollow\"\u003e2020-08-21ï¼Œä½ ä¸€å®šä»Žæœªçœ‹è¿‡å¦‚æ­¤é€šä¿—æ˜“æ‡‚çš„YOLOç³»åˆ—(ä»Žv1åˆ°v5)æ¨¡åž‹è§£è¯» (ä¸­)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/186014243\" rel=\"nofollow\"\u003e2020-08-17ï¼Œä½ ä¸€å®šä»Žæœªçœ‹è¿‡å¦‚æ­¤é€šä¿—æ˜“æ‡‚çš„YOLOç³»åˆ—(ä»Žv1åˆ°v5)æ¨¡åž‹è§£è¯» (ä¸‹)\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.zhihu.com/people/cvji-zhu-zhi-nan\" rel=\"nofollow\"\u003eçŸ¥ä¹Žã€ŒCVæŠ€æœ¯æŒ‡å—ã€| å¾®ä¿¡å…¬ä¼—å·ã€ŒCVæŠ€æœ¯æŒ‡å—ã€\u003c/a\u003e\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/gpr7JZMRgp8B5RxhVzt_mQ\" rel=\"nofollow\"\u003e2021-08-26ï¼Œç›®æ ‡æ£€æµ‹mAPçš„è®¡ç®— \u0026amp; COCOçš„è¯„ä»·æŒ‡æ ‡\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/494572914\" rel=\"nofollow\"\u003e2022-04-07ï¼ŒYOLOç³»åˆ—æ¢³ç†ï¼ˆä¸€ï¼‰YOLOv1-YOLOv3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/2lndImcah5QJJJiEujGOsA\" rel=\"nofollow\"\u003e2022-04-15ï¼ŒYOLOç³»åˆ—æ¢³ç†ä¸Žå¤ä¹ ï¼ˆäºŒï¼‰YOLOv4 \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/503971609\" rel=\"nofollow\"\u003e2022-04-24ï¼ŒYOLOç³»åˆ—æ¢³ç†ï¼ˆä¸‰ï¼‰YOLOv5\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/534090250\" rel=\"nofollow\"\u003e2022-06-26ï¼ŒYOLOç³»åˆ—æ¢³ç†ï¼ˆä¹ï¼‰åˆå°æ–°é²œå‡ºç‚‰çš„YOLOv6\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/543574708\" rel=\"nofollow\"\u003e2022-07-19ï¼ŒYOLOç³»åˆ—æ¢³ç†ï¼ˆåï¼‰YOLOå®˜æ–¹é‡å›žæ±Ÿæ¹– å¹¶å¸¦æ¥äº†YOLOv7\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/DKHOlLtjO2OBtIWlA3cpzg\" rel=\"nofollow\"\u003e2023-03-11ï¼Œç›®æ ‡è·Ÿè¸ªä¸“æ ï¼ˆä¸€ï¼‰åŸºæœ¬ä»»åŠ¡ã€å¸¸ç”¨æ–¹æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/N50tOvJwNRZhyoVq6Fc-ig\" rel=\"nofollow\"\u003e2023-04-17ï¼Œç›®æ ‡è·Ÿè¸ªï¼ˆäºŒï¼‰å•ã€å¤šç›®æ ‡è·Ÿè¸ªçš„åŸºæœ¬æ¦‚å¿µä¸Žå¸¸ç”¨æ•°æ®é›†\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/wnxOd-DukIpea5j2Dqcpbw\" rel=\"nofollow\"\u003e2023-05-11ï¼Œå…¨æ–°YOLOæ¨¡åž‹YOLOCSæ¥å•¦ | é¢é¢ä¿±åˆ°åœ°æ”¹è¿›YOLOv5çš„Backbone/Neck/Head\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cCegxKb1VWxmhpZZwCk1WA\" rel=\"nofollow\"\u003e2024-04-16ï¼ŒYOLC æ¥è¢­ | é¥é¥é¢†å…ˆ ï¼YOLOä¸ŽCenterNetæ€æƒ³ç«èŠ±ç¢°æ’žï¼Œè®©å°ç›®æ ‡çš„æ£€æµ‹æ€§èƒ½åŽŸåœ°èµ·é£žï¼Œè½åœ°ä»·å€¼æžå¤§ !\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.zhihu.com/org/ji-shi-jiao-14\" rel=\"nofollow\"\u003eçŸ¥ä¹Žã€Œæžå¸‚å¹³å°ã€| å¾®ä¿¡å…¬ä¼—å·ã€Œæžå¸‚å¹³å°ã€\u003c/a\u003e\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/297965943\" rel=\"nofollow\"\u003e2020-11-17ï¼ŒYOLOç®—æ³•æœ€å…¨ç»¼è¿°ï¼šä»ŽYOLOv1åˆ°YOLOv5\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/31Fb3WSBtRUNu8oUkMrBrg\" rel=\"nofollow\"\u003e2022-08-04ï¼ŒåŽä¸ºè½»é‡çº§ç¥žç»ç½‘ç»œæž¶æž„GhostNetå†å‡çº§ï¼ŒGPUä¸Šå¤§æ˜¾èº«æ‰‹çš„G-GhostNetï¼ˆIJCV22ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/SQ-ojaRlinLY5PsLTZhz2w\" rel=\"nofollow\"\u003e2022-10-17ï¼ŒBackboneç¯‡ï½œYOLOv1-v7å…¨ç³»åˆ—å¤§è§£æž\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/RBpC-0HqzgtHy5xsoBce8Q\" rel=\"nofollow\"\u003e2022-11-15ï¼ŒNeurIPS'22 Spotlightï½œåŽä¸ºè¯ºäºšGhostNetV2å‡ºç‚‰ï¼šé•¿è·ç¦»æ³¨æ„åŠ›æœºåˆ¶å¢žå¼ºå»‰ä»·æ“ä½œ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/mV2Bl4tBZwZ7n-YleMUE4g\" rel=\"nofollow\"\u003e2022-11-21ï¼Œè½»é‡çº§çš„CNNæ¨¡å—ï¼RepGhostï¼šé‡å‚æ•°åŒ–æŠ€æœ¯æž„å»ºç¡¬ä»¶é«˜æ•ˆçš„ Ghost æ¨¡å—\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/HAfCpECOxccPfj5b7Pprfw\" rel=\"nofollow\"\u003e2023-02-26ï¼ŒåŽ¦å¤§çºªè£åµ˜å›¢é˜Ÿæ–°ä½œï½œOneTeacher: è§£é” YOLOv5 çš„æ­£ç¡®æ‰“å¼€æ–¹å¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/2Md30QdqgWnWwVR7d4sx1Q\" rel=\"nofollow\"\u003e2023-04-18ï¼ŒRepvgg-style ConvNetsï¼Œç¡¬ä»¶å‹å¥½ï¼è¯¦è§£YOLOv6çš„é«˜æ•ˆbackboneï¼šEfficientRep\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/UMA3Vk9L71zUEtNkCshYBg\" rel=\"nofollow\"\u003e2023-04-19ï¼ŒCVPR23 Highlightï½œæ‹¥æœ‰top-down attentionèƒ½åŠ›çš„vision transformer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/JYsJRo8l5-nTFrGwBV-BFA\" rel=\"nofollow\"\u003e2023-04-26ï¼Œä¸‡å­—é•¿æ–‡ï¼Œæ·±åº¦å…¨é¢è§£è¯»PyTorchå†…éƒ¨æœºåˆ¶\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/VG9itVaOwCpmb48ZAa8Mjw\" rel=\"nofollow\"\u003e2023-05-28ï¼ŒYOLOv10å¼€æºï½œæ¸…åŽç”¨ç«¯åˆ°ç«¯YOLOv10åœ¨é€Ÿåº¦ç²¾åº¦ä¸Šéƒ½ç”ŸåƒYOLOv8å’ŒYOLOv9\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/raTAXapLK0mquvC1c6S2Iw\" rel=\"nofollow\"\u003e2023-10-27ï¼Œã€Œé¡¹ç›®ç»éªŒæŽå¿ƒçªã€ç¬¬äºŒæœŸï¼šçœŸå®žä¸Šæ‰‹ç®—æ³•å¼€å‘åŽçš„ç»éªŒæ€»ç»“\u0026amp;å¿ƒå¾—ä½“ä¼š\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/UawQkuRqo-phGvtbC5stQg\" rel=\"nofollow\"\u003e2024-12-03ï¼Œæ³¨æ„åŠ›æœºåˆ¶æ¯”çŸ©é˜µåˆ†è§£æ›´å¥½å—ï¼Ÿ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒWeThinklnã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/JLYFP8IA7RcIMSeBKekQlw\" rel=\"nofollow\"\u003e2022-09-18ï¼Œã€Make YOLO Great Againã€‘YOLOv1-v7å…¨ç³»åˆ—å¤§è§£æžï¼ˆè¾“å…¥ä¾§ç¯‡ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/nEWL9ZAYuVngoejf-muFRw\" rel=\"nofollow\"\u003e2022-07-31ï¼Œã€Make YOLO Great Againã€‘YOLOv1-v7å…¨ç³»åˆ—å¤§è§£æžï¼ˆNeckç¯‡ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/JDaSWyNdLoHc6j6cOmNIWw\" rel=\"nofollow\"\u003e2022-08-14ï¼Œã€Make YOLO Great Againã€‘YOLOv1-v7å…¨ç³»åˆ—å¤§è§£æžï¼ˆHeadç¯‡ï¼‰ï¼ˆå°é²œç‰ˆï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/85Xh4l_t65HrGx25ByD_iw\" rel=\"nofollow\"\u003e2022-08-28ï¼Œã€Make YOLO Great Againã€‘YOLOv1-v7å…¨ç³»åˆ—å¤§è§£æžï¼ˆHeadç¯‡ï¼‰ï¼ˆå®Œæ•´ç‰ˆï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/T76JkDf82ZPF5WWVDvJ6GA\" rel=\"nofollow\"\u003e2022-10-16ï¼Œã€Make YOLO Great Againã€‘YOLOv1-v7å…¨ç³»åˆ—å¤§è§£æžï¼ˆBackboneç¯‡ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/xJDMKcS9SRQIWKCAbUpMaQ\" rel=\"nofollow\"\u003e2022-11-13ï¼Œã€Make YOLO Great Againã€‘YOLOv1-v7å…¨ç³»åˆ—å¤§è§£æžï¼ˆTricksç¯‡ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/etaaojeNv8lbBy586FjtQw\" rel=\"nofollow\"\u003e2022-12-11ï¼Œã€Make YOLO Great Againã€‘YOLOv1-v7å…¨ç³»åˆ—å¤§è§£æžï¼ˆæ±‡æ€»ç¯‡ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒGiantPandaCVã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/tZ7swUd0biz7G3CiRkHHfw\" rel=\"nofollow\"\u003e2022-10-26ï¼ŒOne-YOLOv5 å‘å¸ƒï¼Œä¸€ä¸ªè®­å¾—æ›´å¿«çš„YOLOv5\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/N2Xp4IKJAATCmmmQqQ6new\" rel=\"nofollow\"\u003e2022-12-04ï¼ŒOne-YOLOv5 v1.1.0å‘å¸ƒï¼Œå¤§å¹…ä¼˜åŒ–Eager FP32å•å¡æ€§èƒ½\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qR2ODIMidsNR_Eznxry5pg\" rel=\"nofollow\"\u003e2022-10-28ï¼Œã€ŠYOLOv5å…¨é¢è§£æžæ•™ç¨‹ã€‹ä¸€ï¼Œç½‘ç»œç»“æž„é€è¡Œä»£ç è§£æž\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qDNjLKhkjDT54l06SQ_yEA\" rel=\"nofollow\"\u003e2022-11-06ï¼Œã€ŠYOLOv5å…¨é¢è§£æžæ•™ç¨‹ã€‹äºŒï¼ŒYOLOv5æ•°æ®é›†ç»“æž„è§£æž\u0026amp;å¦‚ä½•åˆ¶ä½œä¸€ä¸ªå¯ä»¥èŽ·å¾—æ›´å¥½è®­ç»ƒæ•ˆæžœçš„æ•°æ®é›†\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/1DYz8sp1xR91rr7Q5_X4Qw\" rel=\"nofollow\"\u003e2022-11-10ï¼Œã€ŠYOLOv5å…¨é¢è§£æžæ•™ç¨‹ã€‹ä¸‰ï¼ŒIoUæ·±å…¥è§£æž\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/n6ziYYc3BBsobcRkMS9tsQ\" rel=\"nofollow\"\u003e2022-11-12ï¼Œã€ŠYOLOv5å…¨é¢è§£æžæ•™ç¨‹ã€‹å››ï¼Œç›®æ ‡æ£€æµ‹æ¨¡åž‹ç²¾ç¡®åº¦è¯„ä¼°\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/i8Ygm9BCWNQfyBya7f1Z8Q\" rel=\"nofollow\"\u003e2022-11-18ï¼Œã€ŠYOLOv5å…¨é¢è§£æžæ•™ç¨‹ã€‹äº”ï¼Œè®¡ç®—mAPç”¨åˆ°çš„numpyå‡½æ•°è¯¦è§£\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/B1q_XsvXpf-fI3vDedoWjA\" rel=\"nofollow\"\u003e2022-11-20ï¼Œã€ŠYOLOv5å…¨é¢è§£æžæ•™ç¨‹ã€‹å…­ï¼ŒYOLOv5ä½¿ç”¨æ•™ç¨‹è¯¦è§£ï¼ˆå•å¡ï¼Œå¤šå¡ï¼Œå¤šæœºè®­ç»ƒï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/6UvHK0bRxHGk__B8YMQhiw\" rel=\"nofollow\"\u003e2022-11-22ï¼Œã€ŠYOLOv5å…¨é¢è§£æžæ•™ç¨‹ã€‹ä¸ƒï¼Œä½¿ç”¨æ¨¡åž‹èžåˆæå‡mAPå’ŒmAR\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/UoPY_0E0D5g0R5o5eVmbdA\" rel=\"nofollow\"\u003e2022-11-27ï¼Œã€ŠYOLOv5å…¨é¢è§£æžæ•™ç¨‹ã€‹å…«ï¼Œå°†è®­ç»ƒå¥½çš„YOLOv5æƒé‡å¯¼å‡ºä¸ºå…¶å®ƒæ¡†æž¶æ ¼å¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/4jOg6De01Yxl1uW-v9Zydg\" rel=\"nofollow\"\u003e2022-11-29ï¼Œã€ŠYOLOv5å…¨é¢è§£æžæ•™ç¨‹ã€‹ä¹ï¼Œtrain.py é€ä»£ç è§£æž\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/CZ1btWU9cpbJWC2eVLBVQQ\" rel=\"nofollow\"\u003e2022-12-07ï¼Œã€ŠYOLOv5å…¨é¢è§£æžæ•™ç¨‹ã€‹åï¼ŒYOLOv5 çš„ W \u0026amp; B ç§‘å­¦å®žéªŒå·¥å…·æ•™ç¨‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/uouLlV1G35L8_DQaUm8ogg\" rel=\"nofollow\"\u003e2022-12-08ï¼Œã€ŠYOLOv5å…¨é¢è§£æžæ•™ç¨‹ã€‹åä¸€ï¼ŒYOLOv5 æ•°æ®å¢žå¼ºæ¨¡å— utils/augmentations.py é€è¡Œè§£æž\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/WfXSQFHgF6Ouwq5re4n1Vw\" rel=\"nofollow\"\u003e2022-12-14ï¼Œã€ŠYOLOv5å…¨é¢è§£æžæ•™ç¨‹ã€‹â€‹åäºŒï¼ŒLoss è®¡ç®—è¯¦ç»†è§£æž\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Efa44D7PiwaZkN0jlf4R_w\" rel=\"nofollow\"\u003e2022-12-29ï¼Œã€ŠYOLOv5å…¨é¢è§£æžæ•™ç¨‹ã€‹â€‹åä¸‰ï¼Œdownloads.py è¯¦ç»†è§£æž\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qC-E2UbjNZT-c04IpXfoYA\" rel=\"nofollow\"\u003e2023-01-10ï¼Œã€ŠYOLOv5å…¨é¢è§£æžæ•™ç¨‹ã€‹â€‹åå››ï¼ŒYOLOv5 autoanchor æœºåˆ¶è¯¦è§£\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/osGwscIawS9q07g21rTQcA\" rel=\"nofollow\"\u003e2023-02-07ï¼Œã€ŠYOLOv5å…¨é¢è§£æžæ•™ç¨‹ã€‹â€‹åäº”ï¼ŒYOLOv5 Callbackæœºåˆ¶è§£è¯»\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/sa2MQIaPIkHHxoVRGYMTAw\" rel=\"nofollow\"\u003e2023-02-18ï¼Œã€ŠYOLOv5å…¨é¢è§£æžæ•™ç¨‹ã€‹â€‹åå…­ï¼Œval.py æºç è§£è¯»\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/gF_qfXPMvPKWGNoEFdnpHw\" rel=\"nofollow\"\u003e2023-04-24ï¼Œç®€å•èŠèŠç›®æ ‡æ£€æµ‹æ–°èŒƒå¼RT-DETRçš„éª¨å¹²ï¼šHGNetv2\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒPandaCVerã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/1iP4H3Ri6uBkq24eOO-viw\" rel=\"nofollow\"\u003e2022-10-18ï¼Œæ”¹è¿›YOLOv5â€”â€”é­”æ”¹YOLOv5æå‡æ£€æµ‹ç²¾åº¦\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/X6MIRbE4ZD9xA-c-UtAa_A\" rel=\"nofollow\"\u003e2022-10-23ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•â€”â€”YOLOv5\u0026amp;æ— å‚SimAMï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/NVkHPBv8Ps2fCB2QvNz59Q\" rel=\"nofollow\"\u003e2022-10-25ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•â€”â€”YOLOv5æ”¹è¿›ç»“åˆBotNetï¼ˆTransformerï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/4KmjOSGAHHFdp6jYZI_QFw\" rel=\"nofollow\"\u003e2022-10-27ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•â€”â€”YOLOv5/YOLOv7æ›´æ¢FReLUæ¿€æ´»å‡½æ•°\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/CdNvKCL6fsQD012zrzZNFA\" rel=\"nofollow\"\u003e2022-10-29ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•â€”â€”YOLOv5/YOLOv7æ”¹è¿›ä¹‹GSConv+Slim Neck\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/vnqnNW5y47XThOmodEWHYA\" rel=\"nofollow\"\u003e2022-11-02ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•â€”â€”YOLOv5/YOLOv7æ”¹è¿›ä¹‹ç»“åˆCBAM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/9gGOO66I1kFpyZcRayjF_Q\" rel=\"nofollow\"\u003e2022-11-07ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•â€”â€”YOLOv5/YOLOv7æ”¹è¿›ä¹‹ç»“åˆGAMAttention\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ETkGaGNLx5VqJVSCSsTJNw\" rel=\"nofollow\"\u003e2022-11-08ï¼Œäººå·¥æ™ºèƒ½å‰æ²¿â€”â€”æ·±åº¦å­¦ä¹ çƒ­é—¨é¢†åŸŸï¼ˆç¡®å®šé€‰é¢˜åŠç ”ç©¶æ–¹å‘ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ithO0S7R-D8kXH1ZQlpRRQ\" rel=\"nofollow\"\u003e2022-11-10ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•â€”â€”YOLOv5/YOLOv7æ”¹è¿›ä¹‹ç»“åˆâ€‹SOCAï¼ˆå•å¹…å›¾åƒè¶…åˆ†è¾¨çŽ‡ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/QgL2UxbVvXwrfmGxK7uolQ\" rel=\"nofollow\"\u003e2022-11-12ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•â€”â€”YOLOv5/YOLOv7æ”¹è¿›ä¹‹ç»“åˆâ€‹ASPPï¼ˆç©ºæ´žç©ºé—´å·ç§¯æ± åŒ–é‡‘å­—å¡”ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/4TnHyiG88h5oDhD6NZoq2Q\" rel=\"nofollow\"\u003e2022-11-16ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•â€”â€”YOLOv5/YOLOv7æ”¹è¿›ä¹‹ç»“åˆâ€‹RepVGGï¼ˆé€Ÿåº¦é£™å‡ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/9qTFFu7HImaF8t6ozG_NWw\" rel=\"nofollow\"\u003e2022-11-20ï¼ŒçŸ¥è¯†ç»éªŒåˆ†äº«â€”â€”YOLOv5-6.0è®­ç»ƒå‡ºé”™åŠè§£å†³æ–¹æ³•ï¼ˆRuntimeErrorï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qB8G_pf3oCYBstYyFPrcrw\" rel=\"nofollow\"\u003e2022-11-23ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•â€”â€”YOLOv5/YOLOv7æ”¹è¿›ä¹‹ç»“åˆNAMAttentionï¼ˆæå‡æ¶¨ç‚¹ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/v3pOvqz6ZewPR3fjnA5SIg\" rel=\"nofollow\"\u003e2022-11-25ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•â€”â€”YOLOv5/YOLOv7æ”¹è¿›ä¹‹ç»“åˆCriss-Cross Attention\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cFzcJLOG_1_TzS-Ckg6hGA\" rel=\"nofollow\"\u003e2022-11-29ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•â€”â€”YOLOv7æ”¹è¿›|å¢žåŠ å°ç›®æ ‡æ£€æµ‹å±‚\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/RwthaHf5d7-dT31Cqco6MA\" rel=\"nofollow\"\u003e2022-11-14ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•â€”â€”æ”¶è—|å°ç›®æ ‡æ£€æµ‹çš„å®šä¹‰ï¼ˆä¸€ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/E2ZRBPZjobhlLspJK_DTfA\" rel=\"nofollow\"\u003e2022-11-17ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•â€”â€”æ”¶è—|å°ç›®æ ‡æ£€æµ‹éš¾ç‚¹åˆ†æžï¼ˆäºŒï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/nuIfgFX_krLtN9EQGNrn2w\" rel=\"nofollow\"\u003e2022-11-18ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•â€”â€”æ”¶è—|å°ç›®æ ‡æ£€æµ‹è§£å†³æ–¹æ¡ˆï¼ˆä¸‰ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œäººå·¥æ™ºèƒ½AIç®—æ³•å·¥ç¨‹å¸ˆã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/mi4BIyITyifl7QRhAKqPjg\" rel=\"nofollow\"\u003e2023-03-25ï¼ŒæŠ•ç¨¿æŒ‡å—ï¼šç›®æ ‡æ£€æµ‹è®ºæ–‡å†™ä½œæ¨¡æ¿ï¼ˆåˆç¨¿ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/QwY5C2y7HZ6LPRHC5gScFg\" rel=\"nofollow\"\u003e2022-06-26ï¼ŒYOLOv5æ”¹è¿›ä¹‹ä¸€ï¼šæ·»åŠ SEæ³¨æ„åŠ›æœºåˆ¶\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/pFQEH4zpYogDOMdMQqugcg\" rel=\"nofollow\"\u003e2022-07-11ï¼ŒYOLOv5æ”¹è¿›ä¹‹äºŒï¼šæ·»åŠ CBAMæ³¨æ„åŠ›æœºåˆ¶\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/NzN88Vtkb3rVjsyPi60edQ\" rel=\"nofollow\"\u003e2022-07-13ï¼ŒYOLOv5æ”¹è¿›ä¹‹ä¸‰ï¼šæ·»åŠ Coordinateæ³¨æ„åŠ›æœºåˆ¶\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/4tnD0OZrOn0RdRSY-1XAxw\" rel=\"nofollow\"\u003e2022-07-14ï¼ŒYOLOv5æ”¹è¿›ä¹‹å››ï¼šæ·»åŠ ECAé€šé“æ³¨æ„åŠ›æœºåˆ¶\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/CgvdOqRC9JLrWa4mIDT_zA\" rel=\"nofollow\"\u003e2022-07-15ï¼ŒYOLOv5æ”¹è¿›ä¹‹äº”ï¼šæ”¹è¿›ç‰¹å¾èžåˆç½‘ç»œPANETä¸ºBIFPN\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/0IsvGgxhE5USP0c37HzeAQ\" rel=\"nofollow\"\u003e2022-07-16ï¼ŒYOLOv5æ”¹è¿›ä¹‹å…­ï¼šå¢žåŠ å°ç›®æ ‡æ£€æµ‹å±‚\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/0U4Y_ZEI2YvW1sMHxRfwMQ\" rel=\"nofollow\"\u003e2022-07-17ï¼ŒYOLOv5æ”¹è¿›ä¹‹ä¸ƒï¼šæŸå¤±å‡½æ•°æ”¹è¿›\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Q35jjU6qCKhwsVpF_JkFGw\" rel=\"nofollow\"\u003e2022-07-18ï¼ŒYOLOv5æ”¹è¿›ä¹‹å…«ï¼šéžæžå¤§å€¼æŠ‘åˆ¶NMSç®—æ³•æ”¹è¿›Soft-nms\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/8tfw3l_qy8IyKKh3njsN_w\" rel=\"nofollow\"\u003e2022-07-19ï¼ŒYOLOv5æ”¹è¿›ä¹‹ä¹ï¼šé”šæ¡†K-Meansç®—æ³•æ”¹è¿›K-Means++\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/JMbiPaQKHwIULKLE2jeQNA\" rel=\"nofollow\"\u003e2022-07-20ï¼ŒYOLOv5æ”¹è¿›ä¹‹åï¼šæŸå¤±å‡½æ•°æ”¹è¿›ä¸ºSIOU\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/b3v2zNU4Ek6eO5AajuPI5A\" rel=\"nofollow\"\u003e2022-07-21ï¼ŒYOLOv5æ”¹è¿›ä¹‹åä¸€ï¼šä¸»å¹²ç½‘ç»œC3æ›¿æ¢ä¸ºè½»é‡åŒ–ç½‘ç»œMobileNetV3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/9E9U64Wl8C02etSE19Q1iw\" rel=\"nofollow\"\u003e2022-07-27ï¼ŒYOLOv5æ”¹è¿›ä¹‹åäºŒï¼šä¸»å¹²ç½‘ç»œC3æ›¿æ¢ä¸ºè½»é‡åŒ–ç½‘ç»œShuffleNetV2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/SIqZyXfpx67uRxL7OSHqDg\" rel=\"nofollow\"\u003e2022-07-28ï¼ŒYOLOv5æ”¹è¿›ä¹‹åä¸‰ï¼šä¸»å¹²ç½‘ç»œC3æ›¿æ¢ä¸ºè½»é‡åŒ–ç½‘ç»œEfficientNetv2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/IVR6kJodBWStFcVoVHArEw\" rel=\"nofollow\"\u003e2022-07-31ï¼ŒYOLOv5æ”¹è¿›ä¹‹åå››ï¼šä¸»å¹²ç½‘ç»œC3æ›¿æ¢ä¸ºè½»é‡åŒ–ç½‘ç»œGhostnet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/l3F9vGE2DHxz2otrlM1kfw\" rel=\"nofollow\"\u003e2022-08-01ï¼ŒYOLOv5æ”¹è¿›ä¹‹åäº”ï¼šç½‘ç»œè½»é‡åŒ–æ–¹æ³•æ·±åº¦å¯åˆ†ç¦»å·ç§¯\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/sHCpHtgcMurvgaXjnQX5HQ\" rel=\"nofollow\"\u003e2022-08-03ï¼ŒYOLOv5æ”¹è¿›ä¹‹åå…­ï¼šä¸»å¹²ç½‘ç»œC3æ›¿æ¢ä¸ºè½»é‡åŒ–ç½‘ç»œPP-LCNet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/-hEjujFJuK5V-i9jX00iFw\" rel=\"nofollow\"\u003e2022-08-04ï¼ŒYOLOv5æ”¹è¿›ä¹‹åä¸ƒï¼šCNN+Transformerâ€”â€”èžåˆBottleneck Transformers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/5mwBdny3xI4vZajfZ_KxjQ\" rel=\"nofollow\"\u003e2022-08-05ï¼ŒYOLOv5æ”¹è¿›ä¹‹åå…«ï¼šæŸå¤±å‡½æ•°æ”¹è¿›ä¸ºAlpha-IoUæŸå¤±å‡½æ•°\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/rW9FuDdpNVnO8yQbRon58g\" rel=\"nofollow\"\u003e2022-08-06ï¼ŒYOLOv5æ”¹è¿›ä¹‹åä¹ï¼šéžæžå¤§å€¼æŠ‘åˆ¶NMSç®—æ³•æ”¹è¿›DIoU NMS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cn7uQtcPN3S_CHJc_INZaQ\" rel=\"nofollow\"\u003e2022-08-07ï¼ŒYOLOv5æ”¹è¿›ä¹‹äºŒåï¼šInvolutionæ–°ç¥žç»ç½‘ç»œç®—å­å¼•å…¥ç½‘ç»œ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/D21iFLFTMFfM--vsfh0T5w\" rel=\"nofollow\"\u003e2022-08-08ï¼ŒYOLOv5æ”¹è¿›ä¹‹äºŒåä¸€ï¼šCNN+Transformerâ€”â€”ä¸»å¹²ç½‘ç»œæ›¿æ¢ä¸ºåˆå¿«åˆå¼ºçš„è½»é‡åŒ–ä¸»å¹²EfficientFormer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qq0M1yaCUysp5L3xap6t9g\" rel=\"nofollow\"\u003e2022-08-09ï¼ŒYOLOv7æ”¹è¿›ä¹‹äºŒåäºŒï¼šæ¶¨ç‚¹ç¥žå™¨â€”â€”å¼•å…¥é€’å½’é—¨æŽ§å·ç§¯ï¼ˆgnConvï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/AfrIRsNDAbwfVzdz8XwgFw\" rel=\"nofollow\"\u003e2022-08-24ï¼ŒYOLOv7æ”¹è¿›ä¹‹äºŒåä¸‰ï¼šå¼•å…¥SimAMæ— å‚æ•°æ³¨æ„åŠ›\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/O78PFirnfdfuGlmQRpf9rw\" rel=\"nofollow\"\u003e2022-08-27ï¼ŒYOLOv7æ”¹è¿›ä¹‹äºŒåå››ï¼šå¼•å…¥é‡å­å¯å‘çš„æ–°åž‹è§†è§‰ä¸»å¹²æ¨¡åž‹WaveMLP\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/s4RfXjW17mxUSIuK9QvTxg\" rel=\"nofollow\"\u003e2022-09-03ï¼ŒYOLOv7æ”¹è¿›ä¹‹äºŒåäº”ï¼šå¼•å…¥Swin Transformer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Ty8Eo_qbJZMxjTULVVi-xA\" rel=\"nofollow\"\u003e2022-09-19ï¼ŒYOLOv5ã€v7æ”¹è¿›ä¹‹äºŒåå…­ï¼šæ”¹è¿›ç‰¹å¾èžåˆç½‘ç»œPANetä¸ºASFFè‡ªé€‚åº”ç‰¹å¾èžåˆç½‘ç»œ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/o23-u-B2I23bttzp14FJTg\" rel=\"nofollow\"\u003e2022-09-21ï¼ŒYOLOv5ã€v7æ”¹è¿›ä¹‹äºŒåä¸ƒï¼šè§£å†³å°ç›®æ ‡é—®é¢˜â€”â€”æ ¡æ­£å·ç§¯å–ä»£ç‰¹å¾æå–ç½‘ç»œä¸­çš„å¸¸è§„å·ç§¯\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/-wH_N4-pXY08XdbJ-Iu8zA\" rel=\"nofollow\"\u003e2022-09-24ï¼ŒYOLOv5ã€v7æ”¹è¿›ä¹‹äºŒåå…«ï¼šICLR 2022æ¶¨ç‚¹ç¥žå™¨â€”â€”å³æ’å³ç”¨çš„åŠ¨æ€å·ç§¯ODConv\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/9g-JMK44YQDd3feTBwCYjA\" rel=\"nofollow\"\u003e2022-10-08ï¼ŒYOLOv5ã€YOLOv7æ”¹è¿›ä¹‹äºŒåä¹ï¼šv2.0ç‰ˆæœ¬çš„Swin Transformer èžå…¥\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Y2kOLVbU5ZnNzPIoiv4voA\" rel=\"nofollow\"\u003e2022-10-13ï¼ŒYOLOv5ã€YOLOv7æ”¹è¿›ä¹‹ä¸‰åï¼šå¼•å…¥10æœˆ4å·å‘è¡¨æœ€æ–°çš„Transformerè§†è§‰æ¨¡åž‹MOATç»“æž„\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/sSZfmjJHS3USGkqFd5N-Nw\" rel=\"nofollow\"\u003e2022-10-14ï¼ŒYOLOv5ã€v7æ”¹è¿›ä¹‹ä¸‰åä¸€ï¼šCrissCrossAttentionæ³¨æ„åŠ›æœºåˆ¶\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/fgTTylKkDe36Z45MxMV_ig\" rel=\"nofollow\"\u003e2022-10-16ï¼ŒYOLOv5ã€v7æ”¹è¿›ä¹‹ä¸‰åäºŒï¼šSKAttentionæ³¨æ„åŠ›æœºåˆ¶\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Tl5q7TEEPphXvzWQM_f61Q\" rel=\"nofollow\"\u003e2022-10-17ï¼ŒYOLOv5ã€v7æ”¹è¿›ä¹‹ä¸‰åä¸‰ï¼šå¼•å…¥GAMAttentionæ³¨æ„åŠ›æœºåˆ¶\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/k1FIIcaEZxSjuR6aRzotHg\" rel=\"nofollow\"\u003e2022-10-18ï¼ŒYOLOv5ã€v7æ”¹è¿›ä¹‹ä¸‰åå››ï¼šæ›´æ¢æ¿€æ´»å‡½æ•°ä¸ºFReLU\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/rFe2pex6-YsUpRj8K-pw3g\" rel=\"nofollow\"\u003e2022-10-19ï¼ŒYOLOv5ã€v7æ”¹è¿›ä¹‹ä¸‰åäº”ï¼šå¼•å…¥NAMAttentionæ³¨æ„åŠ›æœºåˆ¶\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/5MuJiodqJ4ixOSdogr5ebw\" rel=\"nofollow\"\u003e2022-10-20ï¼ŒYOLOv5ã€v7æ”¹è¿›ä¹‹ä¸‰åå…­ï¼šå¼•å…¥S2-MLPv2æ³¨æ„åŠ›æœºåˆ¶\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/f9rjpRkeqBCWeTFkadLZpQ\" rel=\"nofollow\"\u003e2022-10-21ï¼ŒYOLOv5ã€v7æ”¹è¿›ä¹‹ä¸‰åä¸ƒï¼šç»“åˆCVPR2022æ–°ä½œConvNeXtç½‘ç»œ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/7UhjzSwjR2U2h-FC7ZFbCw\" rel=\"nofollow\"\u003e2022-10-22ï¼ŒYOLOv5ã€v7æ”¹è¿›ä¹‹ä¸‰åå…«ï¼šå¼•å…¥æœ€æ–°RepVGG\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/X0f0MLhDYMrMZzx72vyGPg\" rel=\"nofollow\"\u003e2022-10-23ï¼ŒYOLOv5ã€v7æ”¹è¿›ä¹‹ä¸‰åä¹ï¼šå¼•å…¥æ”¹è¿›é®æŒ¡æ£€æµ‹çš„Tri-Layeræ’ä»¶ | BMVC 2022\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/rHTYQW5aRucVe8MoWUlA4Q\" rel=\"nofollow\"\u003e2022-10-27ï¼ŒYOLOv5ã€v7æ”¹è¿›ä¹‹å››åï¼šè½»é‡åŒ–mobileoneä¸»å¹²ç½‘ç»œå¼•å…¥\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/TrB7-B-ppU2JkuQ5G46a8Q\" rel=\"nofollow\"\u003e2022-11-01ï¼ŒYOLOv5ã€v7æ”¹è¿›ä¹‹å››åä¸€ï¼šå¼•å…¥SPD-Convå¤„ç†ä½Žåˆ†è¾¨çŽ‡å›¾åƒå’Œå°å¯¹è±¡é—®é¢˜\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cg4KinN-vEhcnoiQlN_tfw\" rel=\"nofollow\"\u003e2022-11-02ï¼ŒYOLOv5æ”¹è¿›ä¹‹å››åäºŒï¼šå¼•å…¥V7ä¸­çš„ELANç½‘ç»œï¼Œé™ä½Žç½‘ç»œå‚æ•°\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/P9TCtm6d_x6sRXtENTwY_A\" rel=\"nofollow\"\u003e2022-11-03ï¼ŒYOLOv7ã€v5æ”¹è¿›ä¹‹å››åä¸‰ï¼šç»“åˆæœ€æ–°Non-local Networks and Attentionç»“æž„\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/vS7Lm73tgVbQZ6WdKT9J4Q\" rel=\"nofollow\"\u003e2022-11-19ï¼ŒYOLOç³»åˆ—æ”¹è¿›ä¹‹å››åå››â€”â€”èžå…¥é€‚é…GPUçš„è½»é‡çº§ G-GhostNet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/akrldqppGT6oyf89BnJe2Q\" rel=\"nofollow\"\u003e2022-11-10ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹ä¸€ï¼šåŸºäºŽæ”¹è¿›YOLOv5çš„æ•´è½¦åŽŸæœ¨æ•°é‡æ£€æµ‹æ–¹æ³•â€”â€”TWD-YOLOv5\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/fOAzM-1_b29B79E8gxTP1Q\" rel=\"nofollow\"\u003e2022-11-12ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹äºŒï¼šåŸºäºŽæ”¹è¿›YOLOv5çš„è½»é‡åŒ–èˆªç©ºç›®æ ‡æ£€æµ‹æ–¹æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/6R9g3D2Xd-TZJ_DAiRcBzQ\" rel=\"nofollow\"\u003e2022-11-14ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹ä¸‰ï¼šåŸºäºŽæ”¹è¿›YOLOv7çš„Xå…‰å›¾åƒæ—‹è½¬ç›®æ ‡æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/LcImelrj1hbRHlP_QvLd6g\" rel=\"nofollow\"\u003e2022-11-15ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹å››ï¼šæ”¹è¿›YOLOv5ç®—æ³•åœ¨åœè½¦åœºç«ç¾æ£€æµ‹ä¸­çš„åº”ç”¨\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/UwmamMFM0jnzt1sG-CX6iQ\" rel=\"nofollow\"\u003e2022-11-16ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹äº”ï¼šæ”¹è¿›YOLOv5çš„SARå›¾åƒèˆ°èˆ¹ç›®æ ‡æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Qnw_krVnZGxlWUgG8z6q_g\" rel=\"nofollow\"\u003e2022-11-17ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹å…­ï¼šåŸºäºŽYOLOv5çš„é¥æ„Ÿå›¾åƒèˆ°èˆ¹çš„æ£€æµ‹æ–¹æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/jZI93jPaLtsCFK-kljjppw\" rel=\"nofollow\"\u003e2022-11-20ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹ä¸ƒï¼šåŸºäºŽSE-YOLOv5sçš„ç»ç¼˜å­æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/47YVYj4svWnkbPrvrfOqmw\" rel=\"nofollow\"\u003e2022-11-21ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹å…«ï¼šåŸºäºŽYOLOv5sçš„æ»‘é›ªäººå‘˜æ£€æµ‹ç ”ç©¶\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/8VUZ5RX84krFgBdCO7qMhQ\" rel=\"nofollow\"\u003e2022-11-22ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹ä¹ï¼šåŸºäºŽæ”¹è¿›YOLOv5çš„å¤æ‚åœºæ™¯ä¸‹SARå›¾åƒèˆ¹èˆ¶æ£€æµ‹æ–¹æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/xEzrjEe8CGfgdttJevFbFw\" rel=\"nofollow\"\u003e2022-11-23ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹åï¼šåŸºäºŽYOLOv5çš„é¥æ„Ÿå›¾åƒç›®æ ‡æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/uPwcji5mGSstxI9gWnAXCQ\" rel=\"nofollow\"\u003e2022-11-25ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹åä¸€ï¼šåŸºäºŽç‰¹å¾èžåˆä¸Žæ³¨æ„åŠ›çš„é¥æ„Ÿå›¾åƒå°ç›®æ ‡æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Ii98povs_xjfUdSxe2WYsQ\" rel=\"nofollow\"\u003e2022-11-26ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹åäºŒï¼šåŸºäºŽæ³¨æ„åŠ›æœºåˆ¶å’Œä¸Šä¸‹æ–‡ä¿¡æ¯çš„ç›®æ ‡æ£€æµ‹ç®—æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/MByqnwl2YiujOCyWrgMMKg\" rel=\"nofollow\"\u003e2022-11-27ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹åä¸‰ï¼šæ”¹è¿›YOLOv5sçš„é¥æ„Ÿå›¾åƒç›®æ ‡æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/M2ilkFpP5VwBHa2bY8BLyw\" rel=\"nofollow\"\u003e2022-12-12ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹åå››ï¼šä¸€ç§åŸºäºŽæ®‹å·®ç½‘ç»œä¼˜åŒ–çš„èˆªæ‹å°ç›®æ ‡æ£€æµ‹ç®—æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qy0hMDcPyKsl5p28E7q30w\" rel=\"nofollow\"\u003e2022-12-13ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹åäº”ï¼šåŸºäºŽYOLOv5çš„å…‰å­¦é¥æ„Ÿå›¾åƒèˆ°èˆ¹ç›®æ ‡æ£€æµ‹ç®—æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Z-FIlLzVE9obCM-YdtGpxg\" rel=\"nofollow\"\u003e2022-12-14ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹åå…­ï¼šåŸºäºŽæ”¹è¿›YOLOv5çš„å°ç›®æ ‡æ£€æµ‹ç®—æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cQHDZkvyw7bYMRCaXUcPKQ\" rel=\"nofollow\"\u003e2022-12-15ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹åä¸ƒï¼šèžåˆæ³¨æ„åŠ›æœºåˆ¶çš„YOLOv5å£ç½©æ£€æµ‹ç®—æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Kxe6CGs8hR6vrYgagMVdPQ\" rel=\"nofollow\"\u003e2022-12-16ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹åå…«ï¼šåŸºäºŽæ³¨æ„åŠ›æœºåˆ¶çš„å…‰çº¿æ˜æš—æ¡ä»¶ä¸‹å£ç½©ä½©æˆ´æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/67KIqrl1xSFzUmI6vjjAkw\" rel=\"nofollow\"\u003e2022-12-17ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹åä¹ï¼šåŸºäºŽYOLOv5ç½‘ç»œæ¨¡åž‹çš„äººå‘˜å£ç½©ä½©æˆ´å®žæ—¶æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/2TXXKXsWFDJG2t48rPWGqQ\" rel=\"nofollow\"\u003e2022-12-18ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹äºŒåï¼šåŸºäºŽæ”¹è¿›Yolov5çš„åœ°é“éš§é“é™„å±žè®¾æ–½ä¸Žè¡¬ç Œè¡¨è§‚ç—…å®³æ£€æµ‹æ–¹æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qlVnBh2FFw5yBOvCsP2G-g\" rel=\"nofollow\"\u003e2022-12-19ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹äºŒåä¸€:åŸºäºŽæ”¹è¿›YOLOv7çš„å°ç›®æ ‡æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/LH7IqfyXLGbmRXCq_SxDJQ\" rel=\"nofollow\"\u003e2022-12-20ï¼Œç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°ä¹‹äºŒåäºŒï¼šå¤šå°ºåº¦ä¸‹é¥æ„Ÿå°ç›®æ ‡å¤šå¤´æ³¨æ„åŠ›æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qe_LV_8W4hzUxxgax2O4_g\" rel=\"nofollow\"\u003e2023-01-16ï¼ŒYOLOv7/YOLOv5ç³»åˆ—æ”¹è¿›ä¹‹å››åå››ï¼šèžå…¥YOLOv8ä¸­çš„C2fæ¨¡å—\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/HwPwI-nwl8elbiZfDsqHKg\" rel=\"nofollow\"\u003e2023-01-17ï¼ŒYOLOv7/YOLOv5ç³»åˆ—æ”¹è¿›ä¹‹å››åäº”ï¼šèžå…¥CFPNetç½‘ç»œä¸­çš„ECVBlockæ¨¡å—ï¼Œæå‡å°ç›®æ ‡æ£€æµ‹èƒ½åŠ›\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/B0WVnNYrRDXcX0pw_2cLjg\" rel=\"nofollow\"\u003e2023-01-18ï¼Œå­¦ä¹ ç»éªŒåˆ†äº«ä¹‹åä¸‰ï¼šé¦–å‘å…¨ç½‘è®²è§£YOLOv8\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Zrth5ANIYOrjVaU0p2eRZQ\" rel=\"nofollow\"\u003e2023-01-24ï¼Œã€ç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°NO.25ã€‘åŸºäºŽæ”¹è¿›Yolov5çš„åœ°é“éš§é“é™„å±žè®¾æ–½ä¸Žè¡¬ç Œè¡¨è§‚ç—…å®³æ£€æµ‹æ–¹æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/URWmI6OVVtDkvxSEfroVVg\" rel=\"nofollow\"\u003e2023-01-25ï¼Œã€ç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°NO.26ã€‘åŸºäºŽæ”¹è¿›YOLOv5sç½‘ç»œçš„å®žæ—¶è¾“æ¶²ç›‘æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/nToaAvSgSViP4pQrD_Gfgg\" rel=\"nofollow\"\u003e2023-01-28ï¼ŒåŸºäºŽæ”¹è¿›YOLOv5çš„èžºçº¹é’¢è¡¨é¢ç¼ºé™·æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/mtMA87mMQGLA2f4jXlXiUw\" rel=\"nofollow\"\u003e2023-01-30ï¼Œã€ç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°NO.28ã€‘åŸºäºŽæ”¹è¿›YOLO v5çš„ç”µåŽ‚ç®¡é“æ²¹æ¶²æ³„æ¼æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/_tDSg2J3JopTBjQtawnycg\" rel=\"nofollow\"\u003e2023-01-31ï¼Œã€ç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°NO.29ã€‘åŸºäºŽYOLO-STçš„å®‰å…¨å¸½ä½©æˆ´ç²¾ç¡®æ£€æµ‹ç®—æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/UYdTR8axfUSCFEOiTN5wMw\" rel=\"nofollow\"\u003e2023-02-03ï¼Œã€ç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°NO.30ã€‘åŸºäºŽæ”¹è¿›YOLOv5çš„å®å¤è‰åŽŸè—è™«è¯†åˆ«æ¨¡åž‹ç ”ç©¶\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/fMfsXIJ6v2cC18eWjrIbKw\" rel=\"nofollow\"\u003e2023-02-05ï¼Œã€ç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°NO.31ã€‘åŸºäºŽæ”¹è¿›YOLO v5å¤æ‚åœºæ™¯ä¸‹è‚‰é¹…å§¿æ€çš„æ£€æµ‹ç®—æ³•ç ”ç©¶\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/jycEm-pwYhMkihvfS66YIg\" rel=\"nofollow\"\u003e2023-02-04ï¼Œã€ç›®æ ‡æ£€æµ‹è®ºæ–‡è§£è¯»å¤çŽ°NO.32ã€‘åŸºäºŽæ”¹è¿›YOLOçš„é£žæœºèµ·é™é˜¶æ®µè·Ÿè¸ªæ–¹æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/WvHoB5zSPPH1SHRahMLL8g\" rel=\"nofollow\"\u003e2023-03-04ï¼Œã€YOLOv8/YOLOv7/YOLOv5ç³»åˆ—ç®—æ³•æ”¹è¿›NO.55ã€‘èžå…¥ç¾Žå›¢æœ€æ–°QARepVGG\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/T_v7QM_9P20vT5mjFg07xw\" rel=\"nofollow\"\u003e2023-03-07ï¼Œã€YOLOv8/YOLOv7/YOLOv5ç³»åˆ—ç®—æ³•æ”¹è¿›NO.56ã€‘å¼•å…¥Contextual Transformeræ¨¡å—\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/XVl6o2-xK8BfT4BWbmqxxA\" rel=\"nofollow\"\u003e2023-03-10ï¼Œã€YOLOv8/YOLOv7/YOLOv5/YOLOv4/Faster-rcnnç³»åˆ—ç®—æ³•æ”¹è¿›NO.57ã€‘å¼•å…¥å¯å½¢å˜å·ç§¯\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/GgN_Y9Kxkz0YP7dxtoMUsA\" rel=\"nofollow\"\u003e2023-03-14ï¼Œã€YOLOv8/YOLOv7/YOLOv5/YOLOv4/Faster-rcnnç³»åˆ—ç®—æ³•æ”¹è¿›ã€‘å¼•å…¥DRconvåŠ¨æ€åŒºåŸŸæ„ŸçŸ¥å·ç§¯\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/_YjOXjxggHGPLg9T5bE2YQ\" rel=\"nofollow\"\u003e2023-03-15ï¼Œã€YOLOv8/YOLOv7/YOLOv5/YOLOv4/Faster-rcnnç³»åˆ—ç®—æ³•æ”¹è¿›NO.59ã€‘å¼•å…¥ASPPæ¨¡å—\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/YgR-hc1aimba3ij9tfaBAw\" rel=\"nofollow\"\u003e2023-03-30ï¼Œã€YOLOv8/YOLOv7/YOLOv5/YOLOv4ç³»åˆ—ç®—æ³•æ”¹è¿›ã€‘ç»“åˆNeurIPS 2022å¹´GhostnetV2ç½‘ç»œæ¨¡å—\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/JqDIRqM5XAMzqz-Un2yw8Q\" rel=\"nofollow\"\u003e2023-04-08ï¼ŒYOLOv8/YOLOv7/YOLOv5/YOLOv4ç®—æ³•-ç»“åˆCVPR 2023 å³æ’å³ç”¨åŠ¨æ€ç¨€ç–æ³¨æ„åŠ›BiFormeræ¨¡å—\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/4Xu9UIwcpgGvqOkXVDhoYA\" rel=\"nofollow\"\u003e2023-05-05ï¼Œè‹±æ–‡è®ºæ–‡ï¼ˆsciï¼‰è§£è¯»å¤çŽ°ï¼šåŸºäºŽæ³¨æ„æœºåˆ¶çš„æ”¹è¿›YOLOv5sç›®æ ‡æ£€æµ‹ç®—æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/D2yC4Qiztg1FH64f89iJ_A\" rel=\"nofollow\"\u003e2023-05-10ï¼Œè‹±æ–‡è®ºæ–‡ï¼ˆsciï¼‰è§£è¯»å¤çŽ°ï¼šåŸºäºŽæ³¨æ„æœºåˆ¶å’Œæ„Ÿå—é‡Žçš„YOLOv5åœ¨å”å¡å›¾åƒç¼ºé™·è¯†åˆ«ä¸­çš„åº”ç”¨\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/T6VWbQJOWoE3kVTQp0cf7w\" rel=\"nofollow\"\u003e2023-06-10ï¼Œç®—æ³•æ”¹è¿›ï¼šé’ˆå¯¹é¥æ„Ÿå›¾åƒç›®æ ‡æ£€æµ‹ä¸­çš„å°ç›®æ ‡è¿›è¡Œæ”¹è¿›CATnetï¼ˆContextAggregationæ¨¡å—ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/itgOWmlFID6KwDfiOcQ9Ag\" rel=\"nofollow\"\u003e2023-06-27ï¼ŒYOLOv8/YOLOv7/YOLOv5/YOLO/Faster-rcnnv4ç³»åˆ—ç®—æ³•æ”¹è¿›ï¼šæ³¨æ„åŠ›æœºåˆ¶ï¼ˆEMAï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/sdZq3AGcqc4rVywqaEmlYw\" rel=\"nofollow\"\u003e2023-07-18ï¼ŒYOLOv8/YOLOv7/YOLOv5/YOLOv4/Faster-rcnnç³»åˆ—ç®—æ³•æ”¹è¿›ï¼šæ·»åŠ æ¸è¿‘ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/7_6wCWbjqLsv09pd_m2NIQ\" rel=\"nofollow\"\u003e2023-07-27ï¼Œä¸­ç§‘å¤§æå‡ºPE-YOLO | è®©YOLOå®¶æ—ç®—æ³•ç›´å‡»é»‘å¤œç›®æ ‡æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/hKdFzeEvgOI-IkZebDxORQ\" rel=\"nofollow\"\u003e2023-07-28ï¼ŒYOLOv8/YOLOv7/YOLOv5/YOLOv4ç­‰ç³»åˆ—ç®—æ³•æ”¹è¿›ï¼šæ”¹è¿›è¾¹æ¡†ä½ç½®å›žå½’æŸå¤±å‡½æ•°ï¼ˆMPDIoUæŸå¤±å‡½æ•°ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qXFQeYOrdBNWEblVgodcfg\" rel=\"nofollow\"\u003e2023-07-31ï¼Œè¿œè¶…YOLOP | è¶…è½»è¶…å¿«çš„TwinLiteNetå®žçŽ°å¤šä»»åŠ¡è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/0ZT4YxAInMAy_3dy5YJ5-A\" rel=\"nofollow\"\u003e2024-05-22ï¼ŒYOLOv8ç®—æ³•æ”¹è¿›ã€NO.132ã€‘åˆ©ç”¨HCANetä¸­å…·æœ‰å…¨å±€å’Œå±€éƒ¨ä¿¡æ¯çš„æ³¨æ„åŠ›æœºåˆ¶CAFMè¿›è¡ŒDEA-Netå½¢æˆäºŒæ¬¡åˆ›æ–°æ¨¡å—\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ua3vW4MSdWk0Mc15q3bvJg\" rel=\"nofollow\"\u003e2024-05-23ï¼ŒYOLOv9/YOLOv8ç®—æ³•æ”¹è¿›ã€NO.133ã€‘2024å¹´æœ€æ–°MobileNetV4è½»é‡ç®—æ³•ä½œä¸ºYOLOç®—æ³•çš„ä¸»å¹²ç‰¹å¾æå–ç½‘ç»œ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œæ‰€å‘æŠ«é¡çš„å¼ å¤§åˆ€ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/q308cHT0XliCK3NtIRjyqA\" rel=\"nofollow\"\u003e2022-04-24ï¼Œã€å°ç™½å…¥å‘ç¯‡ã€‘ç›®æ ‡æ£€æµ‹çš„è¯„ä»·æŒ‡æ ‡map\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/DFSROue8InARk-96I_Kptg\" rel=\"nofollow\"\u003e2022-07-02ï¼Œã€yolov6ç³»åˆ—ã€‘ç»†èŠ‚æ‹†è§£ç½‘ç»œæ¡†æž¶\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/VEcUIaDrhc1ETIPr39l4rg\" rel=\"nofollow\"\u003e2022-07-13ï¼Œã€yolov7ç³»åˆ—ã€‘ç½‘ç»œæ¡†æž¶ç»†èŠ‚æ‹†è§£\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/nhZ3Q1NHm3op8abdVIGmLA\" rel=\"nofollow\"\u003e2022-07-23ï¼Œã€yolov7ç³»åˆ—äºŒã€‘æ­£è´Ÿæ ·æœ¬åˆ†é…ç­–ç•¥\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/S80mMimu4YpHwClHIH07eA\" rel=\"nofollow\"\u003e2022-07-29ï¼Œã€yolov7ç³»åˆ—ä¸‰ã€‘å®žæˆ˜ä»Ž0æž„å»ºè®­ç»ƒè‡ªå·±çš„æ•°æ®é›†\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/kt3iIuOD3lsZBTIbOSGN0g\" rel=\"nofollow\"\u003e2022-10-23ï¼Œä¸‡å­—é•¿æ–‡è§£æžcvä¸­çš„æ³¨æ„åŠ›æœºåˆ¶\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/YiK5kT-Yd-9k_V_aiSVYqw\" rel=\"nofollow\"\u003e2022-11-23ï¼Œyolov5çš„æŒç»­å‘åŠ›|åˆ†ç±»ä»»åŠ¡\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/JrkRpIgTDtq6WN-hM8NwSA\" rel=\"nofollow\"\u003e2023-07-12ï¼Œç®—æ³•éƒ¨ç½²æœåŠ¡å®žæˆ˜--ä»£ç ç¯‡\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œé›†æ™ºä¹¦ç«¥ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/5SeD09vG6nv46-YuN_uU1w\" rel=\"nofollow\"\u003e2022-07-07ï¼ŒYOLOv7å®˜æ–¹å¼€æº | Alexey Bochkovskiyç«™å°ï¼Œç²¾åº¦é€Ÿåº¦è¶…è¶Šæ‰€æœ‰YOLOï¼Œè¿˜å¾—æ˜¯AB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/clupheQ8iHnhR4FJcTtB8A\" rel=\"nofollow\"\u003e2022-07-27ï¼ŒYOLOUå¼€æº | æ±‡é›†YOLOç³»åˆ—æ‰€æœ‰ç®—æ³•ï¼Œé›†ç®—æ³•å­¦ä¹ ã€ç§‘ç ”æ”¹è¿›ã€è½åœ°äºŽä¸€èº«ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/2XErHzw9hWrrBry9Ij2pjA\" rel=\"nofollow\"\u003e2022-09-25ï¼Œè¿žå¤œå·å‡º | è¶…è¶Šæ‰€æœ‰YOLOæ£€æµ‹æ¨¡åž‹ï¼Œmmdetå¼€æºå½“ä»Šæœ€å¼ºæœ€å¿«ç›®æ ‡æ£€æµ‹æ¨¡åž‹ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/l3fzlPzMFIxXK18rhqX-kg\" rel=\"nofollow\"\u003e2023-01-09ï¼ŒYOLOv8æ¥å•¦ | è¯¦ç»†è§£è¯»YOLOv8çš„æ”¹è¿›æ¨¡å—ï¼YOLOv5å®˜æ–¹å‡ºå“YOLOv8ï¼Œå¿…å·ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/rIi1XBUh_SZuNqKz473tcQ\" rel=\"nofollow\"\u003e2023-01-10ï¼Œä»Žæ ‡æ³¨åˆ°éƒ¨ç½²ï¼ŒMMYOLO ä¿å§†çº§æ•™ç¨‹ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/vUXOX71rcqb3IzDca0nKVQ\" rel=\"nofollow\"\u003e2023-01-13ï¼ŒYOLOv8å®žè·µ | æ‰‹æŠŠæ‰‹æ•™ä½ ç”¨YOLOv8è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†ä»¥åŠYOLOv8çš„å¤šä»»åŠ¡ä½¿ç”¨\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/AClsBD7jJPDUjJ_svwRplQ\" rel=\"nofollow\"\u003e2023-01-16ï¼ŒYOLOv8 + DeepSORT | YOLOä¸ŽDeepSORTè·Ÿè¸ªçš„éš¾åˆ†éš¾èˆï¼Œç›´æŽ¥ç”¨å§ï¼ˆé™„æºç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/8TS70TpbqgQ5GB37zVgERA\" rel=\"nofollow\"\u003e2023-02-01ï¼ŒYOLOæ¶¨ç‚¹Trick | è¶…è¶ŠCIOU/SIOUï¼ŒWise-IOUè®©Yolov7å†æ¶¨1.5ä¸ªç‚¹ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/BK3IRiJdKfPE53KFpvjTCg\" rel=\"nofollow\"\u003e2023-02-17ï¼ŒEdgeYOLOæ¥è¢­ | Xaiverè¶…å®žæ—¶ï¼Œç²¾åº¦å’Œé€Ÿåº¦å®Œç¾Žè¶…è¶ŠYOLOXã€v4ã€v5ã€v6\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/m09WRKRqC1bngCOzip_hFA\" rel=\"nofollow\"\u003e2023-02-22ï¼ŒYOLOv5æŠ›å¼ƒAnchor-Baseæ–¹æ³• | YOLOv5uæ­£å¼åŠ å…¥Anchor-Freeå¤§å®¶åº­\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/p_c0w43ns7rFOzamtOSPVg\" rel=\"nofollow\"\u003e2023-03-08ï¼Œå…¨æ–°å‰ªæžæ¡†æž¶ | YOLOv5æ¨¡åž‹ç¼©å‡4å€ï¼ŒæŽ¨ç†é€Ÿåº¦æå‡2å€\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/vgg_m80A06xFWQGgw2WhHg\" rel=\"nofollow\"\u003e2023-03-31 ï¼Œå°ç›®æ ‡æ£€æµ‹ | å³æ’å³ç”¨ | YOLOv5å¯ä»¥è¿™æ ·å‡çº§\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/L-TpXpBJI7y0wKmBr9arjQ\" rel=\"nofollow\"\u003e2023-03-14ï¼Œå®žè·µæ•™ç¨‹ï½œTensorRTä¸­å¯¹ONNXæ¨¡åž‹è§£æžè¿‡ç¨‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/spEL2hYmYykkQkc4aNxJAg\" rel=\"nofollow\"\u003e2023-03-24ï¼Œç›®æ ‡æ£€æµ‹Trick | SEAæ–¹æ³•è½»æ¾æŠ¹å¹³One-Stageä¸ŽTwo-Stageç›®æ ‡æ£€æµ‹ä¹‹é—´çš„å·®è·\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/-a4Wz04jLHFiAU88pUyDNQ\" rel=\"nofollow\"\u003e2023-03-30ï¼Œå³æ’å³ç”¨ | CEASAæ¨¡å—ç»™ä½ æ‰€æœ‰ï¼Œå°ç›®æ ‡ç²¾åº¦æå‡çš„åŒæ—¶é€Ÿåº¦ä¹Ÿå˜å¿«äº†\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/3_2Dcm8VpoGFksFZE6n2kQ\" rel=\"nofollow\"\u003e2023-04-05ï¼Œéƒ¨ç½²æŠ€å·§ä¹‹PAGCPå‰ªæž | Yolov5/ResNetå‚æ•°é™ä½Ž50%é€Ÿåº¦ç¿»å€ç²¾åº¦ä¸å‡\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/-AtF3B_A0rzvS8cUcZQ6Hw\" rel=\"nofollow\"\u003e2023-04-12ï¼ŒFaster RCNNè¶…å¿«ç‰ˆæœ¬æ¥å•¦ | TinyDetç”¨å°äºŽ1GFLOPSå®žçŽ°30+APï¼Œå°ç›®æ ‡ç‚¸è£‚\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/lsOQiq9wXHxagE_uQ_yOiw\" rel=\"nofollow\"\u003e2023-04-13ï¼Œå³æ’å³ç”¨æ¨¡å— | RFAConvåŠ©åŠ›YOLOv8å†æ¶¨2ä¸ªç‚¹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/V3MUXinJhpq8J4UWTUL17w\" rel=\"nofollow\"\u003e2023-04-19ï¼ŒYOLOè¶…å¿«æ—¶ä»£ç»ˆç»“äº† | RT-DETRç”¨114FPSå®žçŽ°54.8APï¼Œè¿œè¶…YOLOv8\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/FlKgYYGUHtJAxCF2wrh4NA\" rel=\"nofollow\"\u003e2023-04-21ï¼ŒåŸºäºŽYOLOv5æ”¹è¿›å†è®¾è®¡ | M2Så…¨é¢æå‡å°ç›®æ ‡ç²¾åº¦\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/4eE5kWGF5FekHHCZOg9rNA\" rel=\"nofollow\"\u003e2023-06-06ï¼Œä¸€æ–‡å…¨è§ˆ | 2023æœ€æ–°çŽ¯è§†è‡ªåŠ¨é©¾é©¶3Dæ£€æµ‹ç»¼è¿°ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/kdxz3zn77031MDNxVm_k0Q\" rel=\"nofollow\"\u003e2023-06-21ï¼ŒAIæ¨¡åž‹éƒ¨ç½²å®žæˆ˜ | åˆ©ç”¨CV-CUDAåŠ é€Ÿè§†è§‰æ¨¡åž‹éƒ¨ç½²æµç¨‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/kaAoqp-8af0bUA7byYKKPA\" rel=\"nofollow\"\u003e2023-07-20ï¼ŒQ-YOLOPæ¥å•¦ | ä¸€ä¸ªå…·æœ‰é‡åŒ–æ„ŸçŸ¥å…¨æ™¯é©¾é©¶æ„ŸçŸ¥æ¨¡åž‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/F0ZV9yTW8_UHJrvNew8qOA\" rel=\"nofollow\"\u003e2023-07-29ï¼ŒTensorRTéƒ¨ç½²ç³»åˆ— | å¦‚ä½•å°†æ¨¡åž‹ä»Ž PyTorch è½¬æ¢ä¸º TensorRT å¹¶åŠ é€ŸæŽ¨ç†ï¼Ÿ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/AzwdSKNs8SnIIRsdG0cZAg\" rel=\"nofollow\"\u003e2023-08-03ï¼ŒYOLOè½åœ°éƒ¨ç½² | ä¸€æ–‡å…¨è§ˆYOLOv5æœ€æ–°çš„å‰ªæžã€é‡åŒ–çš„è¿›å±•ã€å¿…è¯»ã€‘\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/erkyca0OtJoyXAXI_I6RmQ\" rel=\"nofollow\"\u003e2023-08-11ï¼ŒYOLODä¹Ÿæ¥å•¦ | ä¼˜åŒ–YOLOv5æ ·æœ¬åŒ¹é…ï¼Œé¡ºå¸¦è®¾è®¡äº†å…¨æ–°çš„æ¨¡å—\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/B1iFf936wAORB53QboTXjg\" rel=\"nofollow\"\u003e2023-09-05ï¼ŒYOLO ä¸Ž BEV ä»¥åŠ3Dç›®æ ‡æ£€æµ‹ç®—æ³•ç©¶ç«Ÿåº”è¯¥æ€Žä¹ˆæ‰å¯ä»¥æ›´å¥½çš„è½åœ°ï¼Ÿ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Fj6wzARTo1l7UEwKxDAh6w\" rel=\"nofollow\"\u003e2024-02-01ï¼Œå¤ªå¼ºï¼AIæ²¡æœ‰è½ä¸‹çš„è…¾è®¯å‡ºYOLO-Worldçˆ†æ¬¾ | å¼€é›†ç›®æ ‡æ£€æµ‹é€Ÿåº¦æå‡20å€ï¼Œæ•ˆæžœä¸å‡\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/8Lkl3aMwjESRyeZfLMu7Tw\" rel=\"nofollow\"\u003e2024-02-14ï¼ŒYOLOPointå¼€æº | æ–°å¹´YOLOä¾ç„¶åšæŒºï¼Œé€šè¿‡ç»“åˆYOLOv5\u0026amp;SuperPointï¼Œæˆå°±å¤šä»»åŠ¡SOTA\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/A_BABGHKp5Icdmlk3q3lIA\" rel=\"nofollow\"\u003e2024-02-23ï¼ŒFocaler-IoUå¼€æº | é«˜äºŽSIoU+å…³æ³¨å›°éš¾æ ·æœ¬ï¼Œè®©YOLOv5å†æ¶¨1.9%ï¼ŒYOLOv8å†æ¶¨ç‚¹0.3%\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/31NlBknx4PcXipfuV2w6hw\" rel=\"nofollow\"\u003e2024-02-23ï¼ŒYOLOv9å¼€æº | æž¶æž„å›¾\u0026amp;æ¨¡å—æ”¹è¿›\u0026amp;æ­£è´Ÿæ ·æœ¬åŒ¹é…\u0026amp;æŸå¤±å‡½æ•°è§£è¯»ï¼Œ5åˆ†é’Ÿå³å¯ç†è§£YOLOv9\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/2Hlp_zaHN8TKyzk-1f1yjw\" rel=\"nofollow\"\u003e2024-03-18ï¼ŒD-YOLOè§£å†³è½åœ°å›°éš¾ | å…³æ³¨ç‰¹å¾èžåˆæ¨¡å—+æ— é›¾ç‰¹å¾å­ç½‘ç»œï¼Œè®©YOLOå®¶æ—æ— æƒ§é›¨é›¾å’Œé£Žé›ª\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/6UzdFFKeNOCLK8YdhPYCaQ\" rel=\"nofollow\"\u003e2024-04-15ï¼ŒYOLC æ¥è¢­ | é¥é¥é¢†å…ˆ ï¼YOLOä¸ŽCenterNetæ€æƒ³ç«èŠ±ç¢°æ’žï¼Œè®©å°ç›®æ ‡çš„æ£€æµ‹æ€§èƒ½åŽŸåœ°èµ·é£žï¼Œè½åœ°ä»·å€¼æžå¤§ !\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/6h7FY0U4hwbpOQ6AkH4IEg\" rel=\"nofollow\"\u003e2024-12-14ï¼Œé«˜æ•ˆå°ç›®æ ‡è¯†åˆ«ï¼Œå¤šå¸§è¿åŠ¨æ£€æµ‹ä¸ŽYOLOç»“åˆæé«˜ UAV æ£€æµ‹ç²¾åº¦ !\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œè®¡ç®—æœºè§†è§‰ç ”ç©¶é™¢ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Ytr1m2EOJMWF6WmHDmai2A\" rel=\"nofollow\"\u003e2022-10-30ï¼ŒYoloVï¼šè§†é¢‘ä¸­ç›®æ ‡å®žæ—¶æ£€æµ‹ä¾ç„¶å¾ˆæ£’ï¼ˆé™„æºä»£ç ä¸‹è½½ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/JVr1C9nPTYlHS4aei-Zqrg\" rel=\"nofollow\"\u003e2022-11-04ï¼Œæ”¹è¿›çš„YOLOï¼šAF-FPNæ›¿æ¢é‡‘å­—å¡”æ¨¡å—æå‡ç›®æ ‡æ£€æµ‹ç²¾åº¦\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/0_sF3U232i0PEw1NHE2Efw\" rel=\"nofollow\"\u003e2022-12-31ï¼ŒMicro-YOLOï¼šæŽ¢ç´¢ç›®æ ‡æ£€æµ‹åŽ‹ç¼©æ¨¡åž‹çš„æœ‰æ•ˆæ–¹æ³•ï¼ˆé™„è®ºæ–‡ä¸‹è½½ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cQo7HMcWcbZgk7XIzj1q2A\" rel=\"nofollow\"\u003e2023-02-25ï¼Œä½¿ç”¨ONNXRuntimeéƒ¨ç½²é˜¿é‡Œè¾¾æ‘©é™¢å¼€æºDAMO-YOLOç›®æ ‡æ£€æµ‹ï¼Œä¸€å…±åŒ…å«27ä¸ªonnxæ¨¡åž‹(ä»£ç å¼€æº)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/g8yUdF0SP-81VpVfFjTqNw\" rel=\"nofollow\"\u003e2023-04-03ï¼ŒCVPR 2023 è®ºæ–‡åˆ†ç±»æ±‡æ€»ï¼šä¸€ä¸ªä¸“ä¸ºè®¡ç®—æœºè§†è§‰é¢†åŸŸç ”ç©¶è€…æ‰“é€ çš„å­¦æœ¯èµ„æºå®åº“\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/xMq10ZZQnFyXaob0H-Z1qw\" rel=\"nofollow\"\u003e2023-04-07ï¼ŒMicro-YOLOï¼šæŽ¢ç´¢ç›®æ ‡æ£€æµ‹åŽ‹ç¼©æ¨¡åž‹çš„æœ‰æ•ˆæ–¹æ³•ï¼ˆé™„è®ºæ–‡ä¸‹è½½ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ny98FTagPQB1-GnHKFu2MA\" rel=\"nofollow\"\u003e2023-04-07ï¼Œå®žç”¨æ•™ç¨‹è¯¦è§£ï¼šæ¨¡åž‹éƒ¨ç½²ï¼Œç”¨DNNæ¨¡å—éƒ¨ç½²YOLOç›®æ ‡æ£€æµ‹ï¼ˆé™„æºä»£ç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/FPG44PhAxNi7cy_ALcNXmA\" rel=\"nofollow\"\u003e2023-04-20ï¼Œå…¨è‡ªåŠ¨å®žæ—¶ç§»åŠ¨ç«¯AIæ¡†æž¶ | YOLO-v4ç›®æ ‡æ£€æµ‹å®žæ—¶æ‰‹æœºç«¯å®žçŽ°\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/5sTxdjhKIPpQ-rCsWfe80A\" rel=\"nofollow\"\u003e2023-04-22ï¼ŒCVPRç›®æ ‡æ£€æµ‹æ–°æ¡†æž¶ï¼šä¸å†æ˜¯YOLOï¼Œè€Œæ˜¯åªéœ€è¦ä¸€å±‚ç‰¹å¾ï¼ˆå¹²è´§æ»¡æ»¡ï¼Œå»ºè®®æ”¶è—ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/wK-5i30X06SfLgASlRdqJw\" rel=\"nofollow\"\u003e2023-04-25ï¼ŒGPT-CVï¼šåŸºäºŽYolov5çš„åŠç›‘ç£ç›®æ ‡æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/zEFjvUKnrm5Iwa6e9Fy29Q\" rel=\"nofollow\"\u003e2023-04-25ï¼ŒEdgeYOLOï¼šè¾¹ç¼˜è®¾å¤‡ä¸Šå®žæ—¶è¿è¡Œçš„ç›®æ ‡æ£€æµ‹å™¨åŠPytorchå®žçŽ°\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/xocZNuIOCgGynjZxX_xKgw\" rel=\"nofollow\"\u003e2023-04-26ï¼Œæ”¹è¿›çš„YOLOï¼šAF-FPNæ›¿æ¢é‡‘å­—å¡”æ¨¡å—æå‡ç›®æ ‡æ£€æµ‹ç²¾åº¦\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/FqBq9gy-NKfp3W2qgKHb5w\" rel=\"nofollow\"\u003e2023-06-22ï¼ŒRestoreDetï¼šä½Žåˆ†è¾¨çŽ‡å›¾åƒä¸­ç›®æ ‡æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/N4x0_Bu078g1zSMIDPwzZg\" rel=\"nofollow\"\u003e2023-07-12ï¼ŒGPTç†è§£çš„CVï¼šåŸºäºŽYolov5çš„åŠç›‘ç£ç›®æ ‡æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ODIFRyvfbZOiEORLdWGc_A\" rel=\"nofollow\"\u003e2023-07-12ï¼ŒYoloV8ä¸ŽChatGPTäº’é€šï¼Œè¿™åŠŸèƒ½æ˜¯çœŸçš„å¼ºå¤§ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/-G2TpQOOhLyYDw5wPODBkw\" rel=\"nofollow\"\u003e2023-07-24ï¼ŒYOLO-Sé¢„å‘Šï¼šä¸€ç§ç”¨äºŽå°ç›®æ ‡æ£€æµ‹çš„è½»é‡çº§ã€ç²¾ç¡®çš„ç±»YOLOç½‘ç»œ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/e0EJVHKW7nkfkMVurMgR2Q\" rel=\"nofollow\"\u003e2023-08-20ï¼ŒYoloæ¡†æž¶ä¼˜åŒ–ï¼šé»‘å¤œä¸­ä¹Ÿå¯ä»¥å®žæ—¶ç›®æ ‡æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ztdYjDbWzpx2LnWTiVWdrQ\" rel=\"nofollow\"\u003e2023-09-04ï¼ŒCRAS-YOLOï¼šå¤šç±»åˆ«èˆ¹èˆ¶æ£€æµ‹ä¸Žåˆ†ç±»æ¨¡åž‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/X4HGQhWaxy1bQssrQIYBmQ\" rel=\"nofollow\"\u003e2023-09-04ï¼ŒDrone-YOLOï¼šä¸€ç§æœ‰æ•ˆçš„æ— äººæœºå›¾åƒç›®æ ‡æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/BaqXo4uTeqoY5FhD2jVuxA\" rel=\"nofollow\"\u003e2023-09-05ï¼ŒBFD-YOLOï¼šåŸºäºŽYOLOv7çš„å»ºç­‘å¤–å¢™ç¼ºé™·æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/damt3VWade0we1MSCe9_QA\" rel=\"nofollow\"\u003e2024-05-26ï¼ŒYolov10ï¼šè¯¦è§£ã€éƒ¨ç½²ã€åº”ç”¨ä¸€ç«™å¼é½å…¨ï¼\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œæ–°æœºå™¨è§†è§‰ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/0ALtok0vleMif-5_rgCycQ\" rel=\"nofollow\"\u003eâ€‹2023-03-22ï¼ŒYOLOç³»åˆ—çš„æ¼”è¿›ï¼Œä»Žv1åˆ°v7\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/_aVWQ-NxGwZthA_D_drTRw\" rel=\"nofollow\"\u003e2023-03-23ï¼Œâ€‹YOLOç³»åˆ—çš„æ¼”è¿›ï¼Œä»Žv1åˆ°v7ï¼ˆäºŒï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Ngz7SYEtQ8jsejKG0IknXg\" rel=\"nofollow\"\u003e2023-03-24ï¼ŒYOLOç³»åˆ—çš„æ¼”è¿›ï¼Œä»Žv1åˆ°v7ï¼ˆä¸‰ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/UaqBSCWnGbLLCuy8cvJpkQ\" rel=\"nofollow\"\u003e2023-05-20ï¼Œæœºå™¨è§†è§‰å’Œæ¨¡å¼è¯†åˆ«åº“æ±‡æ€»\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒOpenMMLabã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ZK1hzp6QJarS1xiqkBWcrg\" rel=\"nofollow\"\u003e2022-10-20ï¼Œç¤¾åŒºåä½œï¼Œç®€æ´æ˜“ç”¨ï¼Œå¿«æ¥å¼€ç®±æ–°ä¸€ä»£ YOLO ç³»åˆ—å¼€æºåº“\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/iF2Upd2ThMBlWPim8Gj13g\" rel=\"nofollow\"\u003e2023-03-28ï¼Œå»ºè®®æ”¶è—ï¼è¶…å®žç”¨çš„ YOLO è®­ç»ƒ\u0026amp;æµ‹è¯•æŠ€å·§åˆé›†\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/_RNmB3KtYEt7UuDsCOJ3rQ\" rel=\"nofollow\"\u003eâ€‹2023-01-12ï¼ŒYOLOv8 æ·±åº¦è¯¦è§£ï¼ä¸€æ–‡çœ‹æ‡‚ï¼Œå¿«é€Ÿä¸Šæ‰‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ilCMYZmG_XpvJ_ysB1cgkw\" rel=\"nofollow\"\u003e2023-04-04ï¼Œæ˜¾è‘—æå‡æ¨¡åž‹ç²¾åº¦ï¼ä»¥ MMYOLO ä¸ºä¾‹ ï¼Œå·§ç”¨ MMRazor è½»é‡çº§éª¨å¹²ç½‘ç»œ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œè‡ªåŠ¨é©¾é©¶ä¹‹å¿ƒã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/M47rwwbU0FRrgd-Xg9c7ww\" rel=\"nofollow\"\u003e2022-10-26ï¼Œæ‰‹æŠŠæ‰‹æ•™å­¦ï¼TensorRTéƒ¨ç½²å®žæˆ˜ï¼šYOLOv5çš„ONNXæ¨¡åž‹éƒ¨ç½²\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/FFRsxSaTeGvs1ssKGCD6lg\" rel=\"nofollow\"\u003e2022-11-12ï¼ŒSSDA-YOLOï¼šç”¨äºŽè·¨åŸŸç›®æ ‡æ£€æµ‹çš„åŠç›‘ç£åŸŸè‡ªé€‚åº”YOLOæ–¹æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/QYsCzgMhW9Mfsa6CYolVuQ\" rel=\"nofollow\"\u003e2022-11-30ï¼Œè¾¾æ‘©é™¢ | DAMO-YOLOï¼šå…¼é¡¾é€Ÿåº¦ä¸Žç²¾åº¦çš„æ–°ç›®æ ‡æ£€æµ‹æ¡†æž¶\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/WRVjub3ePxWoCBQXKhS__w\" rel=\"nofollow\"\u003e2022-12-23ï¼Œé€šç”¨å°ç›®æ ‡Trick | æ·±åº¦å­¦ä¹ æ£€æµ‹å°ç›®æ ‡å¸¸ç”¨æ–¹æ³•ç›˜ç‚¹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/esGe2o3_pPXUlrysZoCQKQ\" rel=\"nofollow\"\u003e2023-01-12ï¼Œçº¯é‡äº§ç»éªŒ | è°ˆè°ˆç›®æ ‡æ£€æµ‹ä¸­æ­£è´Ÿæ ·æœ¬çš„é—®é¢˜\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/EHTXisVDv7SV4UEbo7sdbQ\" rel=\"nofollow\"\u003e2023-05-15ï¼Œæœ€æ–°ï¼è‡ªåŠ¨é©¾é©¶ä¸­ç”¨äºŽç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²çš„Radar-Cameraèžåˆç»¼è¿°\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/79DskdwwSghyldvQF43l6A\" rel=\"nofollow\"\u003e2023-05-19ï¼Œ25FPSï¼è‹±ä¼Ÿè¾¾é¦–å‘BEVFusionéƒ¨ç½²æºä»£ç ï¼Œè¾¹ç¼˜ç«¯å®žæ—¶è¿è¡Œï¼ï¼ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/AhPaSVl2Gh8zWtJ74IUyzw\" rel=\"nofollow\"\u003e2023-05-21ï¼Œä¿å§†çº§å¼€æºæ•™ç¨‹ | æ‰‹æŠŠæ‰‹æ•™ä½ éƒ¨ç½²FreeYOLO\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/i3lLadD3_Q5RX5D0JUocPQ\" rel=\"nofollow\"\u003e2023-05-29ï¼Œæœ€æ–°SOTAï¼BEVFusion4Dï¼šBEVFusionå‡çº§ç‰ˆ3Dæ£€æµ‹æ—¶ç©ºæ–°æ¡†æž¶ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/sEWfs2C62cuThZBXSM0fZA\" rel=\"nofollow\"\u003e2023-06-04ï¼Œä¸‡å­—é•¿æ–‡ | Transformeråœ¨BEVã€2D/3Dæ£€æµ‹ä¸Šçš„åº”ç”¨ã€é‡åŒ–ä¸ŽåŠ é€Ÿï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/WjBvj6hCWEYs7IL9DlrK2Q\" rel=\"nofollow\"\u003e2023-06-15ï¼Œå…¨æžå®šï¼åŸºäºŽTensorRTçš„CNN/Transformer/æ£€æµ‹/BEVæ¨¡åž‹å››å¤§éƒ¨ç½²ä»£ç +CUDAåŠ é€Ÿï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/KsPb80tf_zxPyP0xu8ZmHA\" rel=\"nofollow\"\u003e2023-08-23ï¼Œæ¨¡åž‹éƒ¨ç½²ï¼Œä»Šå¹´çš„é¦™é¥½é¥½ï¼TensorRTè¯¦ç»†å…¥é—¨æŒ‡åŒ—\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/8pceyAzzGvwKNnRE9OJEOA\" rel=\"nofollow\"\u003e2024-01-10ï¼ŒYOLOè¿›å†›BEVæ„ŸçŸ¥ï¼YOLO+BEVåœ¨å®žæ—¶æ£€æµ‹ä¸Šçš„å°è¯•\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒCVHubã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/22rRzyZj93-Y4msYwa_LKQ\" rel=\"nofollow\"\u003e2023-01-07ï¼ŒçŽ°ä»£ç›®æ ‡æ£€æµ‹æ•…äº‹ | 40+ç§ç½‘ç»œæž¶æž„å¤§ç›˜ç‚¹ï¼ä»ŽåŸºç¡€æž¶æž„ResNetåˆ°æœ€å¼ºæ£€æµ‹å™¨Yolov7å†åˆ°æœ€æ–°éƒ¨ç½²ç¥žå™¨GhostNetV2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/B0yHtFMTO5gwt0B-ra18QA\" rel=\"nofollow\"\u003e2023-02-19ï¼Œé˜¿é‡Œå›¢é˜Ÿæ–°ä½œ | æŽ¢è®¨ YOLOv5 çš„é«˜æ•ˆè¿›é˜¶ä¹‹è·¯ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/W56LHZbZEqqoCPFVf612FA\" rel=\"nofollow\"\u003e2023-05-05ï¼Œè¶…å¼ºç›®æ ‡æ£€æµ‹å™¨ RT-DETR | Python/C++ ä¿å§†çº§éƒ¨ç½²æ•™ç¨‹ï¼Œä»Žå…¥é—¨åˆ°ç²¾é€š\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qPbxjDuPOFSD2zsWAGmLQw\" rel=\"nofollow\"\u003e2023-06-04ï¼Œä¸­ç§‘é™¢ä¸€åŒºé¡¶åˆŠ TCSVT 2023 | DIAL-Filters: æ˜¾è‘—æå‡æ¨¡ç³Šå¤œè§†åœºæ™¯ä¸‹çš„æ£€æµ‹å’Œåˆ†å‰²æ€§èƒ½ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Us7IiYXFtUoQJ6btpcG1lw\" rel=\"nofollow\"\u003e2023-07-12ï¼ŒåŒ—èˆªæ–°ä½œ | Q-YOLO: åŸºäºŽ TensorRT å’Œ OpenVIVO çš„ç›®æ ‡æ£€æµ‹é‡åŒ–å®žæˆ˜æ–¹æ¡ˆ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Jl2mr7tszulZX19Fx4ZNgw\" rel=\"nofollow\"\u003e2023-07-30ï¼Œå¤§è¿žç†å·¥è”åˆé˜¿é‡Œè¾¾æ‘©é™¢å‘å¸ƒHQTrack | é«˜ç²¾åº¦è§†é¢‘å¤šç›®æ ‡è·Ÿè¸ªå¤§æ¨¡åž‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/foF9JDyAIk5pLN5F_6dw2g\" rel=\"nofollow\"\u003e2024-03-24ï¼ŒSeeClick: æ‰‹æŠŠæ‰‹æ•™ä½ å¦‚ä½•åŸºäºŽQwen-VLæ­å»ºä¸€ä¸ªå¤šæ¨¡æ€æ™ºèƒ½ä½“ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/IfOCnuvFCTIzKIQEFWFLdA\" rel=\"nofollow\"\u003e2024-09-30ï¼ŒUltrylytics å®˜å®£: YOLO11 å…¨æ–°å‘å¸ƒï¼\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œäººå·¥æ™ºèƒ½æ„ŸçŸ¥ä¿¡æ¯å¤„ç†ç®—æ³•ç ”ç©¶é™¢ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/GJza38BBYTl6XAWiiEzpHA\" rel=\"nofollow\"\u003e2023-06-15ï¼Œæ”¹è¿›YOLOV5å°ç›®æ ‡æ£€æµ‹ä¹‹VisDrone2019æ•°æ®é›†\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/BXueTqerYFtGg9MOhJ7YYA\" rel=\"nofollow\"\u003e2023-06-16ï¼Œæ”¹è¿›YOLOV5å°ç›®æ ‡æ£€æµ‹ä¹‹æ•°æ®é¢„å¤„ç†ä¹‹ä¸€\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/NblhcYo-JWZuJkMS5015sw\" rel=\"nofollow\"\u003e2023-06-17ï¼Œæ”¹è¿›YOLOV5å°ç›®æ ‡æ£€æµ‹ä¹‹æ•°æ®é¢„å¤„ç†ä¹‹äºŒ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/3_03EmF0wo4hmbes5o37NQ\" rel=\"nofollow\"\u003e2023-06-22ï¼Œæ”¹è¿›YOLOV5å°ç›®æ ‡æ£€æµ‹æ¶ˆèžå®žéªŒä¹‹ä¸€\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/iEEGkLFICJT03kXWQwR_sA\" rel=\"nofollow\"\u003e2023-06-23ï¼Œæ”¹è¿›YOLOV5å°ç›®æ ‡æ£€æµ‹æ¶ˆèžå®žéªŒä¹‹äºŒ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ZIH6Y1d6yeUV-zE6AnEvuQ\" rel=\"nofollow\"\u003e2023-07-04ï¼ŒåŸºäºŽæ”¹è¿›YOLOv5å’Œå¯å˜å½¢å·ç§¯çš„æ°´ä¸‹ç¾¤ä½“ç›®æ ‡æ£€æµ‹æ¦‚è¿°ä¹‹ä¸€\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ptkTsyG2_mOFb6lGUCSkVA\" rel=\"nofollow\"\u003e2023-07-05ï¼ŒåŸºäºŽæ”¹è¿›YOLOv5å’Œå¯å˜å½¢å·ç§¯çš„æ°´ä¸‹ç¾¤ä½“ç›®æ ‡æ£€æµ‹æ¦‚è¿°ä¹‹äºŒ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/XSBtVbtcQTrMf13E_HEeWw\" rel=\"nofollow\"\u003e2023-07-07ï¼ŒYOLOV5ç®—æ³•æ”¹è¿›ä¹‹è‡ªé€‚åº”é˜ˆå€¼æ¨¡å—\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/-0ZsO9D4o4UXuIy_a2gt0w\" rel=\"nofollow\"\u003e2023-07-10ï¼Œæ”¹è¿›YOLOV5ç®—æ³•ä¹‹ä¸åŒæ•°æ®é›†æµ‹è¯•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/KIxhlNBuTnCLnqzKqD_GPA\" rel=\"nofollow\"\u003e2023-07-11ï¼Œæ”¹è¿›YOLOV5ç®—æ³•ä¸ŽåŒç±»ç®—æ³•çš„æ¯”è¾ƒ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/WffWRa6MzaRN4oMF3BvOWg\" rel=\"nofollow\"\u003e2023-07-12ï¼Œæ”¹è¿›YOLOV5è‡ªé€‚åº”é˜ˆå€¼æ¨¡å—å®žéªŒåˆ†æž \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/rYrdJPHYE57Kc8QzVDxUfg\" rel=\"nofollow\"\u003e2023-07-15ï¼ŒKAYOLOç½‘ç»œæ¨¡åž‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/x1WRIC9MNQWMTup9XHkwWg\" rel=\"nofollow\"\u003e2023-07-19ï¼ŒYolov8n-IOUæŸå¤±å‡½æ•°çš„æ”¹è¿›\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/KnLwHIWqespSxO0v82cJ3A\" rel=\"nofollow\"\u003e2023-07-26ï¼ŒYOLOV7ç®—æ³•åŽŸç†\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/9dwrXEAi5tht4-tNyZ4tYw\" rel=\"nofollow\"\u003e2023-07-30ï¼ŒFlask éƒ¨ç½² YOLOV5\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cX1WlVJqDNePZW18Jlf_Kg\" rel=\"nofollow\"\u003e2023-08-13ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•çš„åº”ç”¨\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒOneFlowã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qfZIKgBdHNwPDp5ng0Y_Qw\" rel=\"nofollow\"\u003e2022-12-13ï¼ŒYOLOv5å…¨é¢è§£æžæ•™ç¨‹â‘ ï¼šç½‘ç»œç»“æž„é€è¡Œä»£ç è§£è¯»\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/t4Ppf2qokpClRwCN52zF-g\" rel=\"nofollow\"\u003e2022-12-22ï¼ŒYOLOv5å…¨é¢è§£æžæ•™ç¨‹â‘¡ï¼šå¦‚ä½•åˆ¶ä½œè®­ç»ƒæ•ˆæžœæ›´å¥½çš„æ•°æ®é›†\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/LIOnJqJj_GrpakKbLeWEDQ\" rel=\"nofollow\"\u003e2023-02-02ï¼ŒYOLOv5å…¨é¢è§£æžæ•™ç¨‹â‘¢ï¼šæ›´å¿«æ›´å¥½çš„è¾¹ç•Œæ¡†å›žå½’æŸå¤±\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/nvfAU6TwTDoZhF8zFpCaOw\" rel=\"nofollow\"\u003e2023-02-17ï¼ŒYOLOv5å…¨é¢è§£æžæ•™ç¨‹â‘£ï¼šç›®æ ‡æ£€æµ‹æ¨¡åž‹ç²¾ç¡®åº¦è¯„ä¼°\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ag7PkcRRSTppEG0GOysqpg\" rel=\"nofollow\"\u003e2023-02-24ï¼ŒYOLOv5å…¨é¢è§£æžæ•™ç¨‹â‘¤ï¼šè®¡ç®—mAPç”¨åˆ°çš„Numpyå‡½æ•°è¯¦è§£\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/RriWDozw7ZHTBg7Rr38dNw\" rel=\"nofollow\"\u003e2023-03-09ï¼ŒYOLOv5å…¨é¢è§£æžæ•™ç¨‹â‘¥ï¼šæ¨¡åž‹è®­ç»ƒæµç¨‹è¯¦è§£\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/6PjD5k5o1GQO8v7jIydZ_w\" rel=\"nofollow\"\u003e2023-05-23ï¼ŒYOLOv5å…¨é¢è§£æžæ•™ç¨‹â‘¦ï¼šä½¿ç”¨æ¨¡åž‹èžåˆæå‡mAPå’ŒmAR\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/4yiN7JZrvAvMi4m5eusbMw\" rel=\"nofollow\"\u003e2023-05-23ï¼ŒYOLOv5å…¨é¢è§£æžæ•™ç¨‹â‘§ï¼šå°†è®­ç»ƒå¥½çš„YOLOv5æƒé‡å¯¼ä¸ºå…¶å®ƒæ¡†æž¶æ ¼å¼\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒAIWalkerã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/E-TNeTKK5EV70zAenRVbwQ\" rel=\"nofollow\"\u003e2023-03-29ï¼ŒChatGPTæ˜¯å¦‚ä½•çœ‹å¾…YOLOç³»åˆ—ç®—æ³•çš„è´¡çŒ®å‘¢ï¼Ÿ\u003cdel\u003eå“ˆå“ˆ\u003c/del\u003e \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/FsWSRguAn2WZKtmPhMbc6g\" rel=\"nofollow\"\u003e2023-05-07ï¼ŒYOLO-NAS | YOLOæ–°é«˜åº¦ï¼Œå¼•å…¥NASï¼Œå‡ºäºŽYOLOv8è€Œä¼˜äºŽYOLOv8\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Wk1sHIQKUe01PqMnpzcCfQ\" rel=\"nofollow\"\u003e2023-05-16ï¼Œå…¨ç½‘å”¯ä¸€å¤çŽ°ï¼æ‰‹æœºç«¯ 1ms çº§å»¶è¿Ÿçš„ä¸»å¹²ç½‘æ¨¡åž‹ MobileOne\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/FfG9vNM_a2k_zflWfuimsw\" rel=\"nofollow\"\u003e2023-08-15ï¼Œå—å¼€å¤§å­¦æå‡ºYOLO-MS | è¶…è¶ŠYOLOv8ä¸ŽRTMDetï¼Œå³æ’å³ç”¨æ‰“ç ´æ€§èƒ½ç“¶é¢ˆ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/yepStVzyrOE4MsgFFuwo0Q\" rel=\"nofollow\"\u003e2024-02-19ï¼ŒUç‰ˆYOLO-Worldæ¥äº†ï¼ŒYOLOv8å†åº¦å‡çº§ï¼Œä¸‰è¡Œä»£ç ä¸Šæ‰‹YOLO-World\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/tFavH5_Sqtnq1_NMRt_AUg\" rel=\"nofollow\"\u003e2024-02-23ï¼ŒYOLOv9æ¥äº†ï¼Œå¯ç¼–ç¨‹æ¢¯åº¦ä¿¡æ¯ä¸Žå¹¿ä¹‰é«˜æ•ˆå±‚èšåˆç½‘ç»œ åŠ©åŠ›å…¨æ–°æ£€æµ‹SOTAå‰æ²¿\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œè‘£è‘£ç¿æ˜¯ä¸ªæ”»åŸŽç‹®ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/pA86udkaFzCogi2Qw8vBEA\" rel=\"nofollow\"\u003e2023-03-20ï¼Œä¸‡å­—é•¿æ–‡è§£æžResnet50çš„ç®—æ³•åŽŸç†\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/3aNVGIPf5pLzEv67KI8M5w\" rel=\"nofollow\"\u003e2023-04-17ï¼Œä¸‡å­—é•¿æ–‡å…¥é—¨ç¥žç»ç½‘ç»œç¡¬ä»¶åŠ é€Ÿ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/VlrglazJE54Xnm3tjM0uCg\" rel=\"nofollow\"\u003e2023-04-19ï¼ŒCUDAå·ç§¯ç®—å­æ‰‹å†™è¯¦ç»†å®žçŽ°\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œè®¡ç®—æœºè§†è§‰æ¼«è°ˆã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/EElv2Tc73JKS8jpejEGB1w\" rel=\"nofollow\"\u003e2020-02-22ï¼ŒYOLO v3å®žæˆ˜ä¹‹é’¢ç­‹æ•°é‡AIè¯†åˆ«ï¼ˆä¸€ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/lOeRqD2orcLw5FR496r4uw\" rel=\"nofollow\"\u003e2020-03-07ï¼ŒYOLO v3å®žæˆ˜ä¹‹é’¢ç­‹æ™ºèƒ½è¯†åˆ«æ”¹è¿›æ–¹æ¡ˆåˆ†äº«ï¼ˆäºŒï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œæ™ºé€ æƒ…æŠ¥å±€ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/IzMabvYts2BEa5IvAwUfrg\" rel=\"nofollow\"\u003e2022-11-07ï¼Œé¡¹ç›®å®žæ“ï¼šåŸºäºŽyolov5çš„PCBè¡¨é¢ç¼ºé™·æ£€æµ‹ã€é™„å®Œæ•´ä»£ç ã€‘\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œå­¦å§å¸¦ä½ çŽ©AIã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/52Woexamu697tozevSiyQQ\" rel=\"nofollow\"\u003e2022-11-21ï¼ŒYOLOv5+Tesseract-OCR å®žçŽ°è½¦ç‰Œå·æ–‡æœ¬è¯†åˆ«ã€å®žæˆ˜ã€‘\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œé‡å­ä½ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/_ccYfjWm6CsH_vxpACUWEA\" rel=\"nofollow\"\u003e2023-01-12ï¼ŒYOLOv8å·²è‡³ï¼Œç²¾åº¦å¤§æ¶¨ï¼æ•™ä½ å¦‚ä½•åœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸Šè®­ç»ƒå®ƒ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œç¬‘å‚²ç®—æ³•æ±Ÿæ¹–ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/i_bF6_77MxKqEy7-y7LQdQ\" rel=\"nofollow\"\u003e2023-02-08ï¼Œä»£ç å®žæˆ˜ï¼šYOLOv5å®žçŽ°é’¢æè¡¨é¢ç¼ºé™·æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒOpenCVä¸­æ–‡ç½‘ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/wF93AAVnGsQtHdB-DkSTPQ\" rel=\"nofollow\"\u003e2023-04-07ï¼ŒYOLOv8 å…¨å®¶æ¡¶å†è¿Žæ–°æˆå‘˜ï¼æ–°å¢žPose Estimationæ¨¡åž‹!\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œæ·±åº¦å­¦ä¹ ä¸Žè®¡ç®—æœºè§†è§‰ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/vthdOoy3etZmybMLaGzoFg\" rel=\"nofollow\"\u003e2023-03-28ï¼Œä½¿ç”¨ YOLO è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼šå¦‚ä½•æå–äººç‰©å›¾åƒ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œæœºå™¨å­¦ä¹ ç®—æ³•å·¥ç¨‹å¸ˆã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/wgBaZ-CTB7B4nvYnobMDvw\" rel=\"nofollow\"\u003e2023-04-19ï¼ŒæƒŠå‘†äº†ï¼åŸºäºŽTransformerçš„æ£€æµ‹æ¨¡åž‹RT-DETRç«Ÿç„¶æ¯”YOLOè¿˜å¿«ï¼\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œè®¡ç®—æœºè§†è§‰ä¸Žæœºå™¨å­¦ä¹ ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/oflfbPkhj3ka2ExK7ZZ0VA\" rel=\"nofollow\"\u003e2023-04-19ï¼ŒRT-DETR | åŠæ‰“YOLOç³»åˆ—çš„ DETRéƒ¨ç½²æ•™ç¨‹æ¥å•¦ï¼Œä¼˜é›…è€Œç®€æ´ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/XwmQILnaLtWPfo-dysLeAA\" rel=\"nofollow\"\u003e2023-05-16ï¼Œè¶…å¼ºç›®æ ‡æ£€æµ‹å™¨ RT-DETR | Python/C++ ä¿å§†çº§éƒ¨ç½²æ•™ç¨‹ï¼Œä»Žå…¥é—¨åˆ°ç²¾é€š\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œäººå·¥æ™ºèƒ½å‰æ²¿è®²ä¹ ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/FtVd37tOXMfu92eDSvdvbg\" rel=\"nofollow\"\u003e2023-04-19ï¼Œã€æºå¤´æ´»æ°´ã€‘CVPR 2023 | AbSViTï¼šæ‹¥æœ‰è‡ªä¸Šè€Œä¸‹æ³¨æ„åŠ›æœºåˆ¶çš„è§†è§‰Transformer\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒAIç§‘æŠ€ä¸Žç®—æ³•ç¼–ç¨‹ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ofokLwCwgN1GNTqy3NuYmg\" rel=\"nofollow\"\u003e2023-04-11, YOLOv8 AS-Oneï¼šç›®æ ‡æ£€æµ‹AS-One æ¥äº†ï¼ï¼ˆYOLOå°±æ˜¯åå‰¯å…¶å®žçš„å·çŽ‹ä¹‹çŽ‹ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œæ·±åº¦å­¦ä¹ ä¸ŽNLPã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/RmM9ay4arJWBoNP11Bfbsw\" rel=\"nofollow\"\u003e2023-04-24ï¼Œ[ä¸‡å­—å¹²è´§]-å¦‚ä½•ç»™æ¨¡åž‹åŠ å…¥å…ˆéªŒçŸ¥è¯†ï¼Ÿ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒOpenCVä¸ŽAIæ·±åº¦å­¦ä¹ ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/NrT7aFurdz5IRr3bCFsHQA\" rel=\"nofollow\"\u003e2023-04-23ï¼ŒåŸºäºŽ YOLOv8 çš„è‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/HldcdtBXzh5YawcS0Bb4KQ\" rel=\"nofollow\"\u003e2023-06-19ï¼Œä¸€æ–‡å½»åº•æžæ‡‚YOLOv8ã€ç½‘ç»œç»“æž„+ä»£ç +å®žæ“ã€‘\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/g6jEP5Y2R_DhrI30DBol5Q\" rel=\"nofollow\"\u003e2023-07-04ï¼Œä¿å§†æ•™ç¨‹ | YOLOv5åœ¨å»ºç­‘å·¥åœ°ä¸­å®‰å…¨å¸½ä½©æˆ´æ£€æµ‹çš„åº”ç”¨\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/3WSmGP7xdQJc-5YdQXBPFg\" rel=\"nofollow\"\u003e2024-06-05ï¼Œå®žæˆ˜ | YOLOv10 è‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒå®žçŽ°è½¦ç‰Œæ£€æµ‹ (æ•°æ®é›†+è®­ç»ƒ+é¢„æµ‹ ä¿å§†çº§æ•™ç¨‹)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/xZ4HlfBPXFbf8OPxmXwbrQ\" rel=\"nofollow\"\u003e2024-06-21ï¼ŒYOLOv10åœ¨PyTorchå’ŒOpenVINOä¸­æŽ¨ç†å¯¹æ¯”\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/VcUifHycY9aw99d3WD1h1w\" rel=\"nofollow\"\u003e2024-07-08ï¼Œå®žæˆ˜ | YOLOv8ä½¿ç”¨TensorRTåŠ é€ŸæŽ¨ç†æ•™ç¨‹ï¼ˆæ­¥éª¤ + ä»£ç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/o-AECBLDucxVLr1Q0yxZ_g\" rel=\"nofollow\"\u003e2024-07-10ï¼ŒOpenCVä½¿ç”¨CUDAåŠ é€Ÿèµ„æ–™æ±‡æ€»(pdf+è§†é¢‘+æºç )\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/S_yjuxHb8PD3B472mvizfg\" rel=\"nofollow\"\u003e2024-09-30ï¼ŒYOLOv11æ¥äº†ï¼šå°†é‡æ–°å®šä¹‰AIçš„å¯èƒ½æ€§\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒåµŒå…¥å¼è§†è§‰ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/m4gZ1beM8QRzNegFPf3Mbg\" rel=\"nofollow\"\u003e2023-04-28ï¼Œæ·±åº¦å­¦ä¹ æ¨¡åž‹åŽ‹ç¼©æ–¹æ³•æ¦‚è¿°\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/7BCQD1s_1AZJoowivTnxOg\" rel=\"nofollow\"\u003e2023-05-12ï¼Œæ¨¡åž‹åŽ‹ç¼©-å‰ªæžç®—æ³•è¯¦è§£\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œæœºå™¨å­¦ä¹ ç®—æ³•é‚£äº›äº‹ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/4EFTj6RxOCvX2Wn5euhSAQ\" rel=\"nofollow\"\u003e2023-05-02ï¼ŒlabelGoï¼šåŸºäºŽ YOLOv5 çš„è¾…åŠ©æ ‡æ³¨å·¥å…·\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œäººå·¥æ™ºèƒ½æŠ€æœ¯ä¸Žå’¨è¯¢ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Mic_wLbfjQrtX7wLwW1SiA\" rel=\"nofollow\"\u003e2023-05-19ï¼ŒåŸºäºŽYOLOv5çš„å…‰å­¦é¥æ„Ÿå›¾åƒèˆ°èˆ¹ç›®æ ‡æ£€æµ‹ç®—æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/pBXUnMpSmLg1BTDrJ19tgQ\" rel=\"nofollow\"\u003e2023-06-06ï¼Œé¢å‘å¼¹è½½å›¾åƒçš„æ·±åº¦å­¦ä¹ ç½‘ç»œåŽ‹ç¼©æ–¹æ³•ç ”ç©¶\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒStrongerTangã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/g3KpWyc0QpLseN5-0CKySQ\" rel=\"nofollow\"\u003e2022-10-07ï¼Œè‡ªåŠ¨é©¾é©¶å¤šæ¨¡æ€èžåˆæ„ŸçŸ¥è¯¦è§£ï¼ˆç ”ç©¶çŽ°çŠ¶åŠæŒ‘æˆ˜ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒåŒ—äº¬å¤§å­¦çŽ‹é€‰è®¡ç®—æœºç ”ç©¶æ‰€ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/anth7mIqTGpJ4QWvTDbiSQ\" rel=\"nofollow\"\u003e2022-10-12ï¼ŒNeurIPS 2022 | é¢å‘è‡ªåŠ¨é©¾é©¶å¤šæ¨¡æ€æ„ŸçŸ¥çš„æ¿€å…‰é›·è¾¾-ç›¸æœºèžåˆæ¡†æž¶\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œè®¡ç®—æœºè§†è§‰æ·±åº¦å­¦ä¹ å’Œè‡ªåŠ¨é©¾é©¶ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/maKDU3sXbPxlEFz372qZTA\" rel=\"nofollow\"\u003e2022-05-31ï¼ŒBEVFusion: åŸºäºŽç»Ÿä¸€BEVè¡¨å¾çš„å¤šä»»åŠ¡å¤šä¼ æ„Ÿå™¨èžåˆ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œå†…æŽ¨å›SIRã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/3pUMSOq4-eS2N7WNtbv02A\" rel=\"nofollow\"\u003e2023-07-28ï¼Œé¢ç» | è®¡ç®—æœºè§†è§‰ é¢ç»22\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œå¤æœˆå±…ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/UshIczcC8l7eHNf2CSrMKw\" rel=\"nofollow\"\u003e2023-07-06ï¼ŒYOLOv5è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†(è¶…è¯¦ç»†)\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒStreamlitã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/I1HQ_E4UerZLkDT2-ch2SQ\" rel=\"nofollow\"\u003e2023-05-18ï¼ŒStreamlit+Opencvæ‰“é€ äººè„¸å®žæ—¶è¯†åˆ«åŠŸèƒ½\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒFightingCVã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/smwx-Ievs3rWMw_D4lSwqg\" rel=\"nofollow\"\u003e2022-08-17ï¼ŒYOLOAir | é¢å‘å°ç™½çš„ç›®æ ‡æ£€æµ‹åº“ï¼Œæ›´å¿«æ›´æ–¹ä¾¿æ›´å®Œæ•´çš„YOLOåº“\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/bCUMjzc-Ws0_qjusFjM5Xw\" rel=\"nofollow\"\u003e2023-07-29ï¼Œè‡ªåŠ¨é©¾é©¶æ–°æ–¹æ³•ç™»Natureå°é¢ï¼šè®©é»‘å¤œå¦‚ç™½æ˜¼èˆ¬æ¸…æ™°ï¼Œæµ™å¤§åšå£«ä¸€ä½œ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒAILabç¬”è®°ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/zCbFEl8pvPIfjnfIgv8Hqw\" rel=\"nofollow\"\u003e2023-06-08ï¼Œã€æ–‡çŒ®ã€‘è§†è§‰transformerç ”ç©¶è¿›å±•â€”â€”å²ä¸Šæœ€å…¨ç»¼è¿°\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒCVerã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/t7jlTyUP6UxplpythX0dOw\" rel=\"nofollow\"\u003e2023-08-02ï¼ŒICCV 2023ï½œç›®æ ‡æ£€æµ‹æ–°çªç ´ï¼AlignDetï¼šæ”¯æŒå„ç±»æ£€æµ‹å™¨å®Œå…¨è‡ªç›‘ç£é¢„è®­ç»ƒçš„æ¡†æž¶\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œæˆ‘çˆ±è®¡ç®—æœºè§†è§‰ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/jWZuNKpVM4k5aDe2JmB-Tg\" rel=\"nofollow\"\u003e2023-06-09ï¼Œ[å®žè·µ]YOLOv5æå‡10å€æŽ¨ç†é€Ÿåº¦ï¼šåˆ©ç”¨TensorRT åœ¨Jetson NXä¸Šçš„æ¨¡åž‹éƒ¨ç½²\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/LhodjnA87KrmqXV1ioUIng\" rel=\"nofollow\"\u003e2025-01-08ï¼Œå¼€æ”¾è¯æ±‡æ£€æµ‹æ–°æ™‹SOTAï¼šåœ°ç“œæœºå™¨äººå¼€æºDOSODå®žæ—¶æ£€æµ‹ç®—æ³•\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œè‹±ç‰¹å°”ç‰©è”ç½‘ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/DTXVXwf_tPxwsWbSxBv9Sw\" rel=\"nofollow\"\u003e2022-08-11ï¼ŒåŸºäºŽ OpenVINOâ„¢ï¸ 2022.1 POT API å®žçŽ° YOLOv5 æ¨¡åž‹ INT8 é‡åŒ– | å¼€å‘è€…å®žæˆ˜\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œæ•°æ®ç§‘å­¦ä¸ŽAIã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/v4y-vjsUrlow5EaP_VrF0A\" rel=\"nofollow\"\u003e2023-06-22ï¼ŒWin10çŽ¯å¢ƒä¸‹OpenVINOéƒ¨ç½²YOLOv5æ¨¡åž‹ï¼šä»Žç†è®ºåˆ°å®žè·µ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œéƒ­å°å–µçŽ©AIã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/v4y-vjsUrlow5EaP_VrF0A\" rel=\"nofollow\"\u003e2023-06-22ï¼ŒWin10çŽ¯å¢ƒä¸‹OpenVINOéƒ¨ç½²YOLOv5æ¨¡åž‹ï¼šä»Žç†è®ºåˆ°å®žè·µ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/KdoZnQArI95eWvqHMeqO0A\" rel=\"nofollow\"\u003e2023-09-04ï¼Œè¶…è¯¦ç»† | ä½¿ç”¨Yolov8è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œéƒ­å°å–µçŽ©AIã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/CroC5jiTh6OXGtFUbWLZwQ\" rel=\"nofollow\"\u003e2023-02-13ï¼Œå¦‚ä½•ç”¨OpenVINOâ„¢è®©YOLOv8èŽ·å¾—1000+ FPSæ€§èƒ½ï¼Ÿ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒAIè§†ç•Œå¼•æ“Žã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ypL9_QYcCFjxpdF9CrS2dw\" rel=\"nofollow\"\u003e2023-08-20ï¼ŒFast-BEVçš„CUDAè½åœ° | 5.9mså³å¯å®žçŽ°çŽ¯è§†BEV 3Dæ£€æµ‹è½åœ°ï¼ä»£ç å¼€æº\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/sDOtseu4icePW2oQObMoWQ\" rel=\"nofollow\"\u003e2024-01-03ï¼ŒShape-IoUå¼€æº | åŒæ—¶å…³æ³¨Boxå½¢çŠ¶å’Œå°ºå¯¸ï¼Œå®Œç¾Žè¶…è¶ŠSIoU/EIoU/CIoUç­‰ï¼ŒYOLOåˆæœ‰ç¦äº†\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/N-5nYylqOTx7tEISJYOuuw\" rel=\"nofollow\"\u003e2024-01-19ï¼ŒYOLOv4ä¸Žå·ç§¯æ³¨æ„åŠ›ä»¥åŠViTç»“åˆçš„è¿›åŒ–ç‰ˆæœ¬YOLO-Formerï¼Œç²¾åº¦ç¨³æ­¥æå‡ï¼\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œå°ç™½çŽ©è½¬Pythonã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/L_-Ii5QvnGgJwo5WYSUcVg\" rel=\"nofollow\"\u003e2023-12-22ï¼ŒåŸºäºŽ YOLOv8 çš„ç–²åŠ³çŠ¶æ€æ£€æµ‹ | é™„æºç \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/pc7TzlZSULNJwIS-liCdzg\" rel=\"nofollow\"\u003e2024-01-22ï¼ŒYOLO-NAS å¦‚ä½•å°† YOLO-v8 ç”©åœ¨èº«åŽï¼Ÿ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/42TqNGeaYpoZLBvBmeeAkg\" rel=\"nofollow\"\u003e2024-04-28ï¼Œå°ç›®æ ‡æ£€æµ‹å®žæˆ˜\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œæœºå™¨ä¹‹å¿ƒã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/HFyADfWKkyw0TivsqH6kXA\" rel=\"nofollow\"\u003e2024-02-23ï¼Œç›®æ ‡æ£€æµ‹æ–°SOTAï¼šYOLOv9é—®ä¸–ï¼Œæ–°æž¶æž„è®©ä¼ ç»Ÿå·ç§¯é‡ç„•ç”Ÿæœº\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œç ç§‘æ™ºèƒ½ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cWRObjaRvL6RgabSdSxVBQ\" rel=\"nofollow\"\u003e2024-01-30ï¼Œæ¨¡åž‹éƒ¨ç½²ç³»åˆ—ï¼š10xé€Ÿåº¦æå‡ï¼ŒYoloV8ç›®æ ‡æ£€æµ‹æ¨¡åž‹ç¨€ç–åŒ–â€”CPUä¸Šè¶…500FPS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/u4QBbOeNR48aF9YHWdCQsw\" rel=\"nofollow\"\u003e2024-02-19ï¼ŒåŸºäºŽYOLO-World+EfficientSAMçš„é›¶æ ·æœ¬ç›®æ ‡æ£€æµ‹ä¸Žå®žä¾‹åˆ†å‰²Demo\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/TAv_GY3d-tPOX9fKZNBwig\" rel=\"nofollow\"\u003e2024-02-23ï¼ŒYOLOv9æ¥äº†! æŠ›å¼€æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æž„ï¼Œæ¢ä¸ªå¯ç¼–ç¨‹æ¢¯åº¦ä¿¡æ¯è§’åº¦ç»§ç»­å‡çº§ï¼Œç›®æ ‡æ£€æµ‹æ–°SOTAï¼\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œè‡ªåŠ¨é©¾é©¶Dailyã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/1i76NbtC5DD1lPMIMa9f8w\" rel=\"nofollow\"\u003e2024-02-23ï¼ŒYOLOv9ç»ˆäºŽæ¥äº†ï¼è¿œè¶…çŽ°æœ‰å®žæ—¶ç›®æ ‡æ£€æµ‹å™¨ï¼ä½¿ç”¨PGIå­¦ä½ æƒ³å­¦ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/xxgvub-Y4RJLjbpY6YNxCQ\" rel=\"nofollow\"\u003e2024-05-25ï¼ŒYOLOv10æ¥å•¦ï¼çœŸæ­£å®žæ—¶ç«¯åˆ°ç«¯ç›®æ ‡æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œ3Dè§†è§‰å·¥åŠã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Fbd-jarVO4LyjlhdxgmnsA\" rel=\"nofollow\"\u003e2024-02-23ï¼ŒYOLOv9éœ‡æ’¼æ¥è¢­ï¼ä½¿ç”¨å¯ç¼–ç¨‹æ¢¯åº¦ä¿¡æ¯å­¦ä¹ ä½ æƒ³å­¦ä¹ çš„å†…å®¹ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/MeFXqAyU_OAGnh7qEIb3yQ\" rel=\"nofollow\"\u003e2024-06-18ï¼ŒYOLOè·Œè½ç¥žå›ï¼ŸMamba YOLOå¹²ç¿»YOLOç³»åˆ—æ¨¡åž‹ï¼\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒDeepDrivingã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/IQTCUs8CcfgHxJCyV6cm3w\" rel=\"nofollow\"\u003e2023-07-21ï¼ŒAIæ¨¡åž‹éƒ¨ç½² | TensorRTæ¨¡åž‹INT8é‡åŒ–çš„Pythonå®žçŽ°\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/w0Ss9vcseNCEoK2UWugCNw\" rel=\"nofollow\"\u003e2024-05-29ï¼ŒYOLOv10æ¥å•¦ï¼ONNXæ¨¡åž‹éƒ¨ç½²å’Œæ€§èƒ½å¯¹æ¯”äº†è§£ä¸€ä¸‹\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒCSharpä¸Žè¾¹ç¼˜æ¨¡åž‹éƒ¨ç½²ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/yijeZtkRhbQxuSE1AsyUhA\" rel=\"nofollow\"\u003e2024-06-04ï¼Œä½¿ç”¨ TensorRT C++ API è°ƒç”¨GPUåŠ é€Ÿéƒ¨ç½² YOLOv10 å®žçŽ° 500FPS æŽ¨ç†é€Ÿåº¦â€”â€”å¿«åˆ°é£žèµ·ï¼ï¼\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒBestSongCã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/STAVjII8kAk3MMPbB9vJfQ\" rel=\"nofollow\"\u003e2024-05-24ï¼ŒåŸºäºŽYOLOç³»åˆ—ç®—æ³•ï¼ˆYOLOv5ã€YOLOv6ã€YOLOv8ä»¥åŠYOLOv9ï¼‰å’ŒStreamlitæ¡†æž¶çš„è¡Œäººå¤´ç›”æ£€æµ‹ç³»ç»Ÿ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Cuhwf2exVWFmoyZPQE_HmQ\" rel=\"nofollow\"\u003e2024-05-29ï¼ŒåŸºäºŽYOLOç³»åˆ—ç®—æ³•YOLOv5ã€YOLOv6ã€YOLOv8ä»¥åŠYOLOv9å’ŒStreamlitæ¡†æž¶çš„å·¥äººå¤´ç›”å’Œå®‰å…¨èƒŒå¿ƒæ£€æµ‹ç³»ç»Ÿ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ZIH1afBpKBa5DgvtHZU1Vg\" rel=\"nofollow\"\u003e2024-05-30ï¼ŒåŸºäºŽYOLOç³»åˆ—ç®—æ³•å’ŒStreamlitæ¡†æž¶çš„å…­ç±»æ°´æžœç›®æ ‡æ£€æµ‹ç³»ç»Ÿ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cEhgZYp7rUBFz2BukacQQg\" rel=\"nofollow\"\u003e2024-06-11ï¼ŒåŸºäºŽYOLOç³»åˆ—ç®—æ³•ï¼ˆYOLOv5ã€YOLOv6ã€YOLOv8)ä»¥åŠYOLOv9ï¼‰å’ŒStreamlitæ¡†æž¶çš„äº”ç±»åŠ¨ç‰©ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/zPNGWQGNWDaMJHjxzlhRGA\" rel=\"nofollow\"\u003e2024-08-18ï¼ŒåŸºäºŽYOLOç³»åˆ—ç®—æ³•å’ŒStreamlitæ¡†æž¶çš„è½¦è½½æ‘„åƒå¤´ä¸‹è½¦è¾†æ£€æµ‹ç³»ç»Ÿ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œäººå·¥æ™ºèƒ½å­¦ä¹ æŒ‡å—ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/JlGvYGvPa5NyxjEXHLO6uA\" rel=\"nofollow\"\u003e2024-05-28ï¼Œç”¨è‡ªå·±çš„æ•°æ®é›†å®žæµ‹YOLOv10æ•ˆæžœï¼\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œè·¨æ¨¡æ€AGIã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ASahqSAHoMFvRvBlnq5OzQ\" rel=\"nofollow\"\u003e2024-06-12ï¼ŒYOLO-NASï¼šå¼€å¯å®žæ—¶ç›®æ ‡æ£€æµ‹æ–°çºªå…ƒ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/JMPBJfMhUHg0472javPlpg\" rel=\"nofollow\"\u003e2024-07-02ï¼ŒYOLOv10ï¼šå®žæ—¶ç›®æ ‡æ£€æµ‹çš„æ–°æ˜Ÿï¼Œå¼•é¢†AIè§†è§‰è¯†åˆ«æ–°çºªå…ƒ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/WGMNf4u8bA-t534avapJQw\" rel=\"nofollow\"\u003e2024-07-05ï¼Œæ­ç§˜YOLO-Worldï¼šé¢ è¦†ä¼ ç»Ÿï¼Œå¼€å¯å®žæ—¶å¼€æ”¾è¯æ±‡æ£€æµ‹æ–°æ—¶ä»£\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œé­”æ–¹AIç©ºé—´ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/yQlkvlYnCz1H3JWTXCKc_A\" rel=\"nofollow\"\u003e2024-05-26ï¼ŒCVå†æ”¾å¤§æ‹› | YOLOv10ï¼šæ¯«ç§’çº§å®žæ—¶ç«¯åˆ°ç«¯ç›®æ ‡æ£€æµ‹å¼€æºæ¨¡åž‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/1DYhy-flED1HwUX8YCQUPg\" rel=\"nofollow\"\u003e2024-07-03ï¼Œ2ä¸‡å­—é•¿æ–‡ï½œYOLOv10çš„èµ·æºï¼šYOLOç³»åˆ—çš„åå¹´å…¨é¢ç»¼è¿°ã€YOLOv1-YOLOv10ã€‘(å»ºè®®æ”¶è—)\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œæ§¿å¢¨AIã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/2DkhzmEllF5tom9FWHPz3g\" rel=\"nofollow\"\u003e2024-06-05ï¼Œæ¸…åŽæŽ¥æ£’YOLOv10å¼€æºï¼Œå·å‡ºæ¯«ç§’çº§å®žæ—¶æ£€æµ‹ï¼\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/XQh4MxPwfsWzDnUoiW4jww\" rel=\"nofollow\"\u003e2024-06-12ï¼Œã€è¶…å…¨è§£è¯»ã€‘Drone-YOLOï¼šæ— äººæœºå›¾åƒä¸­çš„å®žæ—¶ç›®æ ‡æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œè®¡ç®—æœºè§†è§‰å·¥åŠã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/64HnNUs7r133hTFsmgWpEA\" rel=\"nofollow\"\u003e2024-06-21ï¼Œç›®æ ‡æ£€æµ‹çš„æžé™åœ¨å“ªé‡Œï¼ŸLW-DETRï¼šå¹²ç¿»YOLOv10ï¼\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œé¥æ„Ÿä¸Žæ·±åº¦å­¦ä¹ ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/FqFDS2Ih0uA9nuWMpbBDEA\" rel=\"nofollow\"\u003e2024-06-28ï¼Œè®ºæ–‡èµè¯» | ç»“åˆYOLOv9å’ŒMambaçš„é¥æ„Ÿå°ç›®æ ‡æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Td-hwr-4UkIUheF7RJAi7Q\" rel=\"nofollow\"\u003e2024-07-11ï¼Œè®ºæ–‡èµè¯» | Mamba YOLO: åŸºäºŽSSMçš„YOLO ç”¨äºŽç›®æ ‡æ£€æµ‹\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œç®—æ³•ç¾Žé£Ÿå±‹ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/A1TCBqRJxXWzZKG1_KauMA\" rel=\"nofollow\"\u003e2024-06-08ï¼Œ30åˆ†é’ŸåƒæŽ‰pytorchè½¬onnxåŠæŽ¨ç†\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œäººå·¥æ™ºèƒ½å­¦èµ·æ¥ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/xbUKj3mHOyou5KpCi-04xw\" rel=\"nofollow\"\u003e2024-06-25ï¼Œå°ç›®æ ‡æ£€æµ‹é‡å¤§è¿›å±•ï¼é€Ÿåº¦æå‡10å€ï¼ŒGPUå†…å­˜å ç”¨å°‘73.4ï¼…\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒæŸ´ç«åˆ›å®¢ç©ºé—´ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/uzvWMoMndwPmyLyDMnDqOQ\" rel=\"nofollow\"\u003e2023-04-07ï¼Œè¾¹ç¼˜è®¡ç®— | è‹±ä¼Ÿè¾¾Jetsonè®¾å¤‡ä¸Šçš„YOLOv8æ€§èƒ½åŸºå‡†æµ‹è¯•\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œå°å°cvç¬”è®°ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/0wOmtfkQNt9VpdlOPHgnkA\" rel=\"nofollow\"\u003e2024-08-12ï¼Œå¾®å°ç›®æ ‡æ£€æµ‹ä¸­åŸºäºŽç›¸ä¼¼è·ç¦»çš„æ ‡ç­¾åˆ†é…(arxiv2024ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œé˜¿æ—­ç®—æ³•ä¸Žæœºå™¨å­¦ä¹ ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/GUmql-aIgiFuJ9ll6dFucg\" rel=\"nofollow\"\u003e2024-06-28ï¼Œã€YOLOv8æ¨¡åž‹onnxéƒ¨ç½²è¯¦è§£ã€‘YOLOv8æ¨¡åž‹è½¬onnxæ ¼å¼å¹¶ä½¿ç”¨onnxruntime è¿›è¡ŒæŽ¨ç†éƒ¨ç½²\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/3ZkVmxpIcB036mAvvYWbow\" rel=\"nofollow\"\u003e2024-10-14ï¼ŒYOLOv11ä¸ŽYOLOv8è¯¦ç»†å¯¹æ¯”åˆ†æžï¼šmAPã€Speedã€Paramsã€FLOPs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/K-kvKCl_yNclL8qTOrgCFA\" rel=\"nofollow\"\u003e2024-10-29ï¼ŒYOLOå‘å±•åŽ†ç¨‹ä»¥åŠYOLOv8è¯¦è§£:åŸºæœ¬æž¶æž„ã€åˆ›æ–°ç‚¹ä¸Žåº”ç”¨é¢†åŸŸ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cnpmKr04E1imBBnmx6VTQw\" rel=\"nofollow\"\u003e2024-11-19ï¼Œã€æ¨¡åž‹çº§è”ã€‘YOLO-Worldä¸ŽSAM2é€šè¿‡æ–‡æœ¬å®žçŽ°æŒ‡å®šç›®æ ‡çš„é›¶æ ·æœ¬åˆ†å‰²\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/gnoknU8iBjfbLo77vIbasw\" rel=\"nofollow\"\u003e2024-11-23ï¼Œè¶…è¯¦ç»†ï¼YOLO11æ¨¡åž‹æž¶æž„è¯¦è§£ã€æ€§èƒ½å¯¹æ¯”\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/-1q0SMdUkklGu7PsrOKpGQ\" rel=\"nofollow\"\u003e2024-11-24ï¼Œã€æ·±åº¦å¥½æ–‡ã€‘ç›®æ ‡æ£€æµ‹æŠ€æœ¯æ·±åº¦å‰–æžï¼šå‘å±•åŽ†ç¨‹ã€å…³é”®æŠ€æœ¯ã€å¸¸ç”¨ç›®æ ‡æ£€æµ‹ç®—æ³•è¯´æ˜ŽåŠåº”ç”¨\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/dH5wFyOhevz37Lt4frVp0w\" rel=\"nofollow\"\u003e2024-12-02ï¼Œã€å®žæˆ˜ã€‘ä½¿ç”¨GroundingDinoå®žçŽ°é›¶æ ·æœ¬è‡ªåŠ¨æ ‡æ³¨ã€é™„æºç ã€‘\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/KTL-NeFO-eVmSm2RaLxYsw\" rel=\"nofollow\"\u003e2024-12-04ï¼Œã€å®žæˆ˜æ•™ç¨‹ã€‘å°ç›®æ ‡æ£€æµ‹åˆ©å™¨ï¼šä½¿ç”¨YOLOv8å’ŒSAHIè¿›è¡Œè§†é¢‘æ£€æµ‹ï¼Œæ£€æµ‹æ•ˆæžœçœŸå¿ƒä¸é”™\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/LOD1xCKY08HVraxM-UDxvQ\" rel=\"nofollow\"\u003e2024-12-07ï¼Œã€å®žæˆ˜æ•™ç¨‹ã€‘ä½¿ç”¨YOLOv8 OBBè¿›è¡Œæ—‹è½¬æ¡†ç›®æ ‡æ£€æµ‹çš„æ•°æ®é›†å®šä¹‰ä¸Žè®­ç»ƒã€é™„æºç ã€‘\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œäººå·¥æ™ºèƒ½ä¸Žå›¾åƒå¤„ç†ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/lfulLTp5SDrpim7nU1ZebA\" rel=\"nofollow\"\u003e2023-05-26ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•-YOLOV5è§£æžï¼ˆé™„è®ºæ–‡ä¸Žæºç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/bG8KkDhs0ex8QZYS6QO5NA\" rel=\"nofollow\"\u003e2023-05-27ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•-YOLOV6è§£æžï¼ˆé™„è®ºæ–‡ä¸Žæºç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/58XnV1Dy-1gc1ZYuY1XsVQ\" rel=\"nofollow\"\u003e2023-05-28ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•-YOLOV7è§£æžï¼ˆé™„è®ºæ–‡ä¸Žæºç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/QwQhpEFX4Pxfik7PNOpwIA\" rel=\"nofollow\"\u003e2023-05-29ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•-YOLOV8è§£æžï¼ˆé™„è®ºæ–‡å’Œæºç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/u8x6ePRmWV6z_FFnGUfUYA\" rel=\"nofollow\"\u003e2024-04-13ï¼Œç›®æ ‡æ£€æµ‹ç®—æ³•-YOLOV9è§£æžï¼ˆé™„è®ºæ–‡å’Œæºç ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/3fffqlYLit30dI34TRZ5dw\" rel=\"nofollow\"\u003e2024-10-28ï¼Œæ¨¡åž‹è½»é‡åŒ–ä¹‹æ¨¡åž‹å‰ªæž-Pruning\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œåœ°ç“œæœºå™¨äººã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/IroAN_R7IvIxKHw8i-_1XQ\" rel=\"nofollow\"\u003e2023-12-28ï¼ŒæŠ€æœ¯æ•²é»‘æ¿ | åŸºäºŽåœ°å¹³çº¿RDK X3é«˜æ•ˆéƒ¨ç½²YOLOv5\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/zq4wLfEP3k5cns7xK4iSOg\" rel=\"nofollow\"\u003e2024-06-27ï¼ŒæŠ€æœ¯æ•²é»‘æ¿ | YOLOv8ç›®æ ‡æ£€æµ‹ç®—æ³•åœ¨åœ°å¹³çº¿RDK X3ä¸Šé«˜æ•ˆéƒ¨ç½²\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œæ·±åº¦AIè§†é‡Žã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/jYPJ5JsJL0LWSlXMkvzBtA\" rel=\"nofollow\"\u003e2025-01-07ï¼ŒYolo11æ¡†æž¶è§£æžä¸Žä»£ç é‡æž„â€”å¼€ç¯‡\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€ŒPandaCVerã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/8eDJ86rPA-0cWnLQKHxfjw\" rel=\"nofollow\"\u003e2022-11-01, ç›®æ ‡æ£€æµ‹ç®—æ³•â€”â€”è¡Œäººæ£€æµ‹\u0026amp;äººç¾¤è®¡æ•°æ•°æ®é›†æ±‡æ€»(é™„ä¸‹è½½é“¾æŽ¥)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/oRmPDF1YhIqYYdrgU7sTUQ\" rel=\"nofollow\"\u003e2022-11-21, ç›®æ ‡æ£€æµ‹ç®—æ³•â€”â€”å·¥ä¸šç¼ºé™·æ•°æ®é›†æ±‡æ€»1ï¼ˆé™„ä¸‹è½½é“¾æŽ¥ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/9tGzWDAxp--42ofmKLlJRg\" rel=\"nofollow\"\u003e2022-12-01, ç›®æ ‡æ£€æµ‹ç®—æ³•â€”â€”å›¾åƒåˆ†ç±»å¼€æºæ•°æ®é›†æ±‡æ€»ï¼ˆé™„ä¸‹è½½é“¾æŽ¥ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œè‡ªåŠ¨é©¾é©¶ä¹‹å¿ƒã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/dCwtc-DI0KaPB4meJqewwA\" rel=\"nofollow\"\u003e2023-03-27, ç›®æ ‡è·Ÿè¸ªæ–¹å‘å¼€æºæ•°æ®é›†èµ„æºæ±‡æ€»\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/A-4ze7B3yQ-AYCe0DgHv-A\" rel=\"nofollow\"\u003e2023-04-12, åŒ…ç½—ä¸‡è±¡ï¼V3Detï¼š1.3Wç±»å…¨æ–°ç›®æ ‡æ£€æµ‹æ•°æ®é›†ï¼ˆæ¸¯ä¸­æ–‡\u0026amp;ä¸Šæµ·AI Labï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eå¾®ä¿¡å…¬ä¼—å·ã€Œæ•´æ•°æ™ºèƒ½AIç ”ç©¶é™¢ã€\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/eoMa1eUXPaZBlHeZReR77A\" rel=\"nofollow\"\u003e2022-03-10, æœ€å…¨è‡ªåŠ¨é©¾é©¶æ•°æ®é›†åˆ†äº«ç³»åˆ—ä¸€ï½œç›®æ ‡æ£€æµ‹æ•°æ®é›†ï¼ˆ1/3ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/nJFG6GHw60pRODoEKWj3bg\" rel=\"nofollow\"\u003e2022-03-21, æœ€å…¨è‡ªåŠ¨é©¾é©¶æ•°æ®é›†åˆ†äº«ç³»åˆ—ä¸€ï½œç›®æ ‡æ£€æµ‹æ•°æ®é›†ï¼ˆ2/3ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/r9d7NmcA3dymKRUhWoIPzw\" rel=\"nofollow\"\u003e2022-04-24, æœ€å…¨è‡ªåŠ¨é©¾é©¶æ•°æ®é›†åˆ†äº«ç³»åˆ—ä¸€ï½œç›®æ ‡æ£€æµ‹æ•°æ®é›†ï¼ˆ3/3ï¼‰\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eVideos\u003c/h2\u003e\u003ca id=\"user-content-videos\" class=\"anchor\" aria-label=\"Permalink: Videos\" href=\"#videos\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003ebilibiliã€Œæˆ‘æ˜¯å‚…å‚…çŒªã€\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://www.bilibili.com/video/BV1HV4y1A7H8\" rel=\"nofollow\"\u003e2022-12-14ï¼Œè‡ªåˆ¶æ·±åº¦å­¦ä¹ æŽ¨ç†æ¡†æž¶\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.bilibili.com/video/BV118411f7yM/\" rel=\"nofollow\"\u003e2023-06-02ï¼Œä»Žé›¶è‡ªåˆ¶æ·±åº¦å­¦ä¹ æŽ¨ç†æ¡†æž¶\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eStar History\u003c/h2\u003e\u003ca id=\"user-content-star-history\" class=\"anchor\" aria-label=\"Permalink: Star History\" href=\"#star-history\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/259a042401ab87b4596f31c2f486a7a6082f7f19ca98b7f4069a27536f2f7a10/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d636f6465726f6e696f6e2f617765736f6d652d796f6c6f2d6f626a6563742d646574656374696f6e26747970653d44617465\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/259a042401ab87b4596f31c2f486a7a6082f7f19ca98b7f4069a27536f2f7a10/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d636f6465726f6e696f6e2f617765736f6d652d796f6c6f2d6f626a6563742d646574656374696f6e26747970653d44617465\" alt=\"Star History Chart\" data-canonical-src=\"https://api.star-history.com/svg?repos=coderonion/awesome-yolo-object-detection\u0026amp;type=Date\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/article\u003e","loaded":true,"timedOut":false,"errorMessage":null,"headerInfo":{"toc":[{"level":1,"text":"Awesome-YOLO-Object-Detection","anchor":"awesome-yolo-object-detection","htmlText":"Awesome-YOLO-Object-Detection"},{"level":2,"text":"Contents","anchor":"contents","htmlText":"Contents"},{"level":2,"text":"Summary","anchor":"summary","htmlText":"Summary"},{"level":3,"text":"Famous YOLO","anchor":"famous-yolo","htmlText":"Famous YOLO"},{"level":3,"text":"Extensional Frameworks","anchor":"extensional-frameworks","htmlText":"Extensional Frameworks"},{"level":3,"text":"Awesome List","anchor":"awesome-list","htmlText":"Awesome List"},{"level":3,"text":"Paper and Code Overview","anchor":"paper-and-code-overview","htmlText":"Paper and Code Overview"},{"level":4,"text":"Paper Review","anchor":"paper-review","htmlText":"Paper Review"},{"level":4,"text":"Code Review","anchor":"code-review","htmlText":"Code Review"},{"level":3,"text":"Learning Resources","anchor":"learning-resources","htmlText":"Learning Resources"},{"level":2,"text":"Other Versions of YOLO","anchor":"other-versions-of-yolo","htmlText":"Other Versions of YOLO"},{"level":3,"text":"PyTorch Implementation","anchor":"pytorch-implementation","htmlText":"PyTorch Implementation"},{"level":3,"text":"C Implementation","anchor":"c-implementation","htmlText":"C Implementation"},{"level":3,"text":"CPP Implementation","anchor":"cpp-implementation","htmlText":"CPP Implementation"},{"level":3,"text":"ROS Implementation","anchor":"ros-implementation","htmlText":"ROS Implementation"},{"level":3,"text":"Mojo Implementation","anchor":"mojo-implementation","htmlText":"Mojo Implementation"},{"level":3,"text":"Rust Implementation","anchor":"rust-implementation","htmlText":"Rust Implementation"},{"level":3,"text":"Go Implementation","anchor":"go-implementation","htmlText":"Go Implementation"},{"level":3,"text":"CSharp Implementation","anchor":"csharp-implementation","htmlText":"CSharp Implementation"},{"level":3,"text":"Tensorflow and Keras Implementation","anchor":"tensorflow-and-keras-implementation","htmlText":"Tensorflow and Keras Implementation"},{"level":3,"text":"PaddlePaddle Implementation","anchor":"paddlepaddle-implementation","htmlText":"PaddlePaddle Implementation"},{"level":3,"text":"Caffe Implementation","anchor":"caffe-implementation","htmlText":"Caffe Implementation"},{"level":3,"text":"MXNet Implementation","anchor":"mxnet-implementation","htmlText":"MXNet Implementation"},{"level":3,"text":"Web Implementation","anchor":"web-implementation","htmlText":"Web Implementation"},{"level":3,"text":"Others","anchor":"others","htmlText":"Others"},{"level":2,"text":"Lighter and Deployment Frameworks","anchor":"lighter-and-deployment-frameworks","htmlText":"Lighter and Deployment Frameworks"},{"level":3,"text":"High-performance Inference Engine","anchor":"high-performance-inference-engine","htmlText":"High-performance Inference Engine"},{"level":4,"text":"é«˜æ€§èƒ½æŽ¨ç†å¼•æ“Ž","anchor":"é«˜æ€§èƒ½æŽ¨ç†å¼•æ“Ž","htmlText":"é«˜æ€§èƒ½æŽ¨ç†å¼•æ“Ž"},{"level":5,"text":"ONNX","anchor":"onnx","htmlText":"ONNX"},{"level":5,"text":"TensorRT","anchor":"tensorrt","htmlText":"TensorRT"},{"level":5,"text":"DeepStream","anchor":"deepstream","htmlText":"DeepStream"},{"level":5,"text":"OpenVINO","anchor":"openvino","htmlText":"OpenVINO"},{"level":5,"text":"NCNN","anchor":"ncnn","htmlText":"NCNN"},{"level":5,"text":"MNN","anchor":"mnn","htmlText":"MNN"},{"level":5,"text":"Other Engine","anchor":"other-engine","htmlText":"Other Engine"},{"level":3,"text":"NPU and FPGA Hardware Deployment","anchor":"npu-and-fpga-hardware-deployment","htmlText":"NPU and FPGA Hardware Deployment"},{"level":4,"text":"NPU å’Œ FPGA ç¡¬ä»¶éƒ¨ç½²","anchor":"npu-å’Œ-fpga-ç¡¬ä»¶éƒ¨ç½²","htmlText":"NPU å’Œ FPGA ç¡¬ä»¶éƒ¨ç½²"},{"level":5,"text":"RK3588","anchor":"rk3588","htmlText":"RK3588"},{"level":5,"text":"FPGA","anchor":"fpga","htmlText":"FPGA"},{"level":5,"text":"Other Hardware","anchor":"other-hardware","htmlText":"Other Hardware"},{"level":3,"text":"Pruning Knoweldge-Distillation Quantization","anchor":"pruning-knoweldge-distillation-quantization","htmlText":"Pruning Knoweldge-Distillation Quantization"},{"level":5,"text":"Pruning","anchor":"pruning","htmlText":"Pruning"},{"level":6,"text":"å‰ªæž","anchor":"å‰ªæž","htmlText":"å‰ªæž"},{"level":5,"text":"Quantization","anchor":"quantization","htmlText":"Quantization"},{"level":6,"text":"é‡åŒ–","anchor":"é‡åŒ–","htmlText":"é‡åŒ–"},{"level":5,"text":"Knoweldge-Distillation","anchor":"knoweldge-distillation","htmlText":"Knoweldge-Distillation"},{"level":6,"text":"çŸ¥è¯†è’¸é¦","anchor":"çŸ¥è¯†è’¸é¦","htmlText":"çŸ¥è¯†è’¸é¦"},{"level":3,"text":"Lightweight Backbones and FPN","anchor":"lightweight-backbones-and-fpn","htmlText":"Lightweight Backbones and FPN"},{"level":4,"text":"è½»é‡çº§éª¨å¹²ç½‘ç»œå’Œç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ","anchor":"è½»é‡çº§éª¨å¹²ç½‘ç»œå’Œç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ","htmlText":"è½»é‡çº§éª¨å¹²ç½‘ç»œå’Œç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ"},{"level":2,"text":"Object Detection Applications","anchor":"object-detection-applications","htmlText":"Object Detection Applications"},{"level":3,"text":"Open World Object Detection","anchor":"open-world-object-detection","htmlText":"Open World Object Detection"},{"level":4,"text":"å¼€æ”¾ä¸–ç•Œç›®æ ‡æ£€æµ‹","anchor":"å¼€æ”¾ä¸–ç•Œç›®æ ‡æ£€æµ‹","htmlText":"å¼€æ”¾ä¸–ç•Œç›®æ ‡æ£€æµ‹"},{"level":3,"text":"Few-shot Object Detection","anchor":"few-shot-object-detection","htmlText":"Few-shot Object Detection"},{"level":4,"text":"å°‘æ ·æœ¬ç›®æ ‡æ£€æµ‹","anchor":"å°‘æ ·æœ¬ç›®æ ‡æ£€æµ‹","htmlText":"å°‘æ ·æœ¬ç›®æ ‡æ£€æµ‹"},{"level":3,"text":"Small Object Detection","anchor":"small-object-detection","htmlText":"Small Object Detection"},{"level":4,"text":"å°ç›®æ ‡æ£€æµ‹","anchor":"å°ç›®æ ‡æ£€æµ‹","htmlText":"å°ç›®æ ‡æ£€æµ‹"},{"level":4,"text":"Multimodal Image Detection","anchor":"multimodal-image-detection","htmlText":"Multimodal Image Detection"},{"level":4,"text":"å¤šæ¨¡æ€å›¾åƒæ£€æµ‹","anchor":"å¤šæ¨¡æ€å›¾åƒæ£€æµ‹","htmlText":"å¤šæ¨¡æ€å›¾åƒæ£€æµ‹"},{"level":3,"text":"Video Object Detection","anchor":"video-object-detection","htmlText":"Video Object Detection"},{"level":4,"text":"è§†é¢‘ç›®æ ‡æ£€æµ‹","anchor":"è§†é¢‘ç›®æ ‡æ£€æµ‹","htmlText":"è§†é¢‘ç›®æ ‡æ£€æµ‹"},{"level":3,"text":"Object Tracking","anchor":"object-tracking","htmlText":"Object Tracking"},{"level":4,"text":"ç›®æ ‡è·Ÿè¸ª","anchor":"ç›®æ ‡è·Ÿè¸ª","htmlText":"ç›®æ ‡è·Ÿè¸ª"},{"level":4,"text":"Multi-Object Tracking","anchor":"multi-object-tracking","htmlText":"Multi-Object Tracking"},{"level":5,"text":"å¤šç›®æ ‡è·Ÿè¸ª","anchor":"å¤šç›®æ ‡è·Ÿè¸ª","htmlText":"å¤šç›®æ ‡è·Ÿè¸ª"},{"level":4,"text":"Dynamic Object Tracking","anchor":"dynamic-object-tracking","htmlText":"Dynamic Object Tracking"},{"level":5,"text":"åŠ¨æ€ç›®æ ‡è·Ÿè¸ª","anchor":"åŠ¨æ€ç›®æ ‡è·Ÿè¸ª","htmlText":"åŠ¨æ€ç›®æ ‡è·Ÿè¸ª"},{"level":4,"text":"Deep Reinforcement Learning","anchor":"deep-reinforcement-learning","htmlText":"Deep Reinforcement Learning"},{"level":4,"text":"æ·±åº¦å¼ºåŒ–å­¦ä¹ ","anchor":"æ·±åº¦å¼ºåŒ–å­¦ä¹ ","htmlText":"æ·±åº¦å¼ºåŒ–å­¦ä¹ "},{"level":4,"text":"Motion Control Field","anchor":"motion-control-field","htmlText":"Motion Control Field"},{"level":4,"text":"è¿åŠ¨æŽ§åˆ¶é¢†åŸŸ","anchor":"è¿åŠ¨æŽ§åˆ¶é¢†åŸŸ","htmlText":"è¿åŠ¨æŽ§åˆ¶é¢†åŸŸ"},{"level":4,"text":"Super-Resolution Field","anchor":"super-resolution-field","htmlText":"Super-Resolution Field"},{"level":4,"text":"è¶…åˆ†è¾¨çŽ‡é¢†åŸŸ","anchor":"è¶…åˆ†è¾¨çŽ‡é¢†åŸŸ","htmlText":"è¶…åˆ†è¾¨çŽ‡é¢†åŸŸ"},{"level":4,"text":"Spiking Neural Network","anchor":"spiking-neural-network","htmlText":"Spiking Neural Network"},{"level":4,"text":"SNN, è„‰å†²ç¥žç»ç½‘ç»œ","anchor":"snn-è„‰å†²ç¥žç»ç½‘ç»œ","htmlText":"SNN, è„‰å†²ç¥žç»ç½‘ç»œ"},{"level":4,"text":"Attention and Transformer","anchor":"attention-and-transformer","htmlText":"Attention and Transformer"},{"level":4,"text":"æ³¨æ„åŠ›æœºåˆ¶","anchor":"æ³¨æ„åŠ›æœºåˆ¶","htmlText":"æ³¨æ„åŠ›æœºåˆ¶"},{"level":3,"text":"Oriented Object Detection","anchor":"oriented-object-detection","htmlText":"Oriented Object Detection"},{"level":4,"text":"æ—‹è½¬ç›®æ ‡æ£€æµ‹","anchor":"æ—‹è½¬ç›®æ ‡æ£€æµ‹","htmlText":"æ—‹è½¬ç›®æ ‡æ£€æµ‹"},{"level":3,"text":"Face Detection and Recognition","anchor":"face-detection-and-recognition","htmlText":"Face Detection and Recognition"},{"level":4,"text":"äººè„¸æ£€æµ‹ä¸Žè¯†åˆ«","anchor":"äººè„¸æ£€æµ‹ä¸Žè¯†åˆ«","htmlText":"äººè„¸æ£€æµ‹ä¸Žè¯†åˆ«"},{"level":4,"text":"Face Detection","anchor":"face-detection","htmlText":"Face Detection"},{"level":5,"text":"äººè„¸æ£€æµ‹","anchor":"äººè„¸æ£€æµ‹","htmlText":"äººè„¸æ£€æµ‹"},{"level":4,"text":"Face Recognition","anchor":"face-recognition","htmlText":"Face Recognition"},{"level":5,"text":"äººè„¸è¯†åˆ«","anchor":"äººè„¸è¯†åˆ«","htmlText":"äººè„¸è¯†åˆ«"},{"level":3,"text":"Face Mask Detection","anchor":"face-mask-detection","htmlText":"Face Mask Detection"},{"level":4,"text":"å£ç½©æ£€æµ‹","anchor":"å£ç½©æ£€æµ‹","htmlText":"å£ç½©æ£€æµ‹"},{"level":3,"text":"Social Distance Detection","anchor":"social-distance-detection","htmlText":"Social Distance Detection"},{"level":4,"text":"ç¤¾äº¤è·ç¦»æ£€æµ‹","anchor":"ç¤¾äº¤è·ç¦»æ£€æµ‹","htmlText":"ç¤¾äº¤è·ç¦»æ£€æµ‹"},{"level":3,"text":"Autonomous Driving Field Detection","anchor":"autonomous-driving-field-detection","htmlText":"Autonomous Driving Field Detection"},{"level":4,"text":"è‡ªåŠ¨é©¾é©¶é¢†åŸŸæ£€æµ‹","anchor":"è‡ªåŠ¨é©¾é©¶é¢†åŸŸæ£€æµ‹","htmlText":"è‡ªåŠ¨é©¾é©¶é¢†åŸŸæ£€æµ‹"},{"level":4,"text":"Vehicle Detection","anchor":"vehicle-detection","htmlText":"Vehicle Detection"},{"level":5,"text":"è½¦è¾†æ£€æµ‹","anchor":"è½¦è¾†æ£€æµ‹","htmlText":"è½¦è¾†æ£€æµ‹"},{"level":4,"text":"License Plate Detection and Recognition","anchor":"license-plate-detection-and-recognition","htmlText":"License Plate Detection and Recognition"},{"level":5,"text":"è½¦ç‰Œæ£€æµ‹ä¸Žè¯†åˆ«","anchor":"è½¦ç‰Œæ£€æµ‹ä¸Žè¯†åˆ«","htmlText":"è½¦ç‰Œæ£€æµ‹ä¸Žè¯†åˆ«"},{"level":4,"text":"Lane Detection","anchor":"lane-detection","htmlText":"Lane Detection"},{"level":5,"text":"è½¦é“çº¿æ£€æµ‹","anchor":"è½¦é“çº¿æ£€æµ‹","htmlText":"è½¦é“çº¿æ£€æµ‹"},{"level":4,"text":"Driving Behavior Detection","anchor":"driving-behavior-detection","htmlText":"Driving Behavior Detection"},{"level":5,"text":"é©¾é©¶è¡Œä¸ºæ£€æµ‹","anchor":"é©¾é©¶è¡Œä¸ºæ£€æµ‹","htmlText":"é©¾é©¶è¡Œä¸ºæ£€æµ‹"},{"level":4,"text":"Parking Slot Detection","anchor":"parking-slot-detection","htmlText":"Parking Slot Detection"},{"level":5,"text":"åœè½¦ä½æ£€æµ‹","anchor":"åœè½¦ä½æ£€æµ‹","htmlText":"åœè½¦ä½æ£€æµ‹"},{"level":4,"text":"Traffic Light Detection","anchor":"traffic-light-detection","htmlText":"Traffic Light Detection"},{"level":5,"text":"äº¤é€šç¯æ£€æµ‹","anchor":"äº¤é€šç¯æ£€æµ‹","htmlText":"äº¤é€šç¯æ£€æµ‹"},{"level":4,"text":"Traffic Sign Detection","anchor":"traffic-sign-detection","htmlText":"Traffic Sign Detection"},{"level":5,"text":"äº¤é€šæ ‡å¿—æ£€æµ‹","anchor":"äº¤é€šæ ‡å¿—æ£€æµ‹","htmlText":"äº¤é€šæ ‡å¿—æ£€æµ‹"},{"level":4,"text":"Crosswalk Detection","anchor":"crosswalk-detection","htmlText":"Crosswalk Detection"},{"level":5,"text":"äººè¡Œæ¨ªé“/æ–‘é©¬çº¿æ£€æµ‹","anchor":"äººè¡Œæ¨ªé“æ–‘é©¬çº¿æ£€æµ‹","htmlText":"äººè¡Œæ¨ªé“/æ–‘é©¬çº¿æ£€æµ‹"},{"level":4,"text":"Traffic Accidents Detection","anchor":"traffic-accidents-detection","htmlText":"Traffic Accidents Detection"},{"level":5,"text":"äº¤é€šäº‹æ•…æ£€æµ‹","anchor":"äº¤é€šäº‹æ•…æ£€æµ‹","htmlText":"äº¤é€šäº‹æ•…æ£€æµ‹"},{"level":4,"text":"Road Damage Detection","anchor":"road-damage-detection","htmlText":"Road Damage Detection"},{"level":5,"text":"é“è·¯æŸä¼¤æ£€æµ‹","anchor":"é“è·¯æŸä¼¤æ£€æµ‹","htmlText":"é“è·¯æŸä¼¤æ£€æµ‹"},{"level":3,"text":"Animal Detection","anchor":"animal-detection","htmlText":"Animal Detection"},{"level":4,"text":"åŠ¨ç‰©æ£€æµ‹","anchor":"åŠ¨ç‰©æ£€æµ‹","htmlText":"åŠ¨ç‰©æ£€æµ‹"},{"level":3,"text":"Helmet Detection","anchor":"helmet-detection","htmlText":"Helmet Detection"},{"level":4,"text":"å¤´ç›”/å®‰å…¨å¸½æ£€æµ‹","anchor":"å¤´ç›”å®‰å…¨å¸½æ£€æµ‹","htmlText":"å¤´ç›”/å®‰å…¨å¸½æ£€æµ‹"},{"level":3,"text":"Hand Detection","anchor":"hand-detection","htmlText":"Hand Detection"},{"level":4,"text":"æ‰‹éƒ¨æ£€æµ‹","anchor":"æ‰‹éƒ¨æ£€æµ‹","htmlText":"æ‰‹éƒ¨æ£€æµ‹"},{"level":3,"text":"Gesture Recognition","anchor":"gesture-recognition","htmlText":"Gesture Recognition"},{"level":4,"text":"æ‰‹åŠ¿/æ‰‹è¯­è¯†åˆ«","anchor":"æ‰‹åŠ¿æ‰‹è¯­è¯†åˆ«","htmlText":"æ‰‹åŠ¿/æ‰‹è¯­è¯†åˆ«"},{"level":3,"text":"Action Detection","anchor":"action-detection","htmlText":"Action Detection"},{"level":4,"text":"è¡Œä¸ºæ£€æµ‹","anchor":"è¡Œä¸ºæ£€æµ‹","htmlText":"è¡Œä¸ºæ£€æµ‹"},{"level":3,"text":"Emotion Recognition","anchor":"emotion-recognition","htmlText":"Emotion Recognition"},{"level":4,"text":"æƒ…æ„Ÿè¯†åˆ«","anchor":"æƒ…æ„Ÿè¯†åˆ«","htmlText":"æƒ…æ„Ÿè¯†åˆ«"},{"level":3,"text":"Human Pose Estimation","anchor":"human-pose-estimation","htmlText":"Human Pose Estimation"},{"level":4,"text":"äººä½“å§¿æ€ä¼°è®¡","anchor":"äººä½“å§¿æ€ä¼°è®¡","htmlText":"äººä½“å§¿æ€ä¼°è®¡"},{"level":3,"text":"Distance Measurement","anchor":"distance-measurement","htmlText":"Distance Measurement"},{"level":4,"text":"è·ç¦»æµ‹é‡","anchor":"è·ç¦»æµ‹é‡","htmlText":"è·ç¦»æµ‹é‡"},{"level":3,"text":"Instance and Semantic Segmentation","anchor":"instance-and-semantic-segmentation","htmlText":"Instance and Semantic Segmentation"},{"level":4,"text":"å®žä¾‹å’Œè¯­ä¹‰åˆ†å‰²","anchor":"å®žä¾‹å’Œè¯­ä¹‰åˆ†å‰²","htmlText":"å®žä¾‹å’Œè¯­ä¹‰åˆ†å‰²"},{"level":3,"text":"3D Object Detection","anchor":"3d-object-detection","htmlText":"3D Object Detection"},{"level":4,"text":"ä¸‰ç»´ç›®æ ‡æ£€æµ‹","anchor":"ä¸‰ç»´ç›®æ ‡æ£€æµ‹","htmlText":"ä¸‰ç»´ç›®æ ‡æ£€æµ‹"},{"level":3,"text":"SLAM Field Detection","anchor":"slam-field-detection","htmlText":"SLAM Field Detection"},{"level":4,"text":"SLAMé¢†åŸŸæ£€æµ‹","anchor":"slamé¢†åŸŸæ£€æµ‹","htmlText":"SLAMé¢†åŸŸæ£€æµ‹"},{"level":3,"text":"Industrial Defect Detection","anchor":"industrial-defect-detection","htmlText":"Industrial Defect Detection"},{"level":4,"text":"å·¥ä¸šç¼ºé™·æ£€æµ‹","anchor":"å·¥ä¸šç¼ºé™·æ£€æµ‹","htmlText":"å·¥ä¸šç¼ºé™·æ£€æµ‹"},{"level":3,"text":"SAR Image Detection","anchor":"sar-image-detection","htmlText":"SAR Image Detection"},{"level":4,"text":"åˆæˆå­”å¾„é›·è¾¾å›¾åƒæ£€æµ‹","anchor":"åˆæˆå­”å¾„é›·è¾¾å›¾åƒæ£€æµ‹","htmlText":"åˆæˆå­”å¾„é›·è¾¾å›¾åƒæ£€æµ‹"},{"level":3,"text":"Safety Monitoring Field Detection","anchor":"safety-monitoring-field-detection","htmlText":"Safety Monitoring Field Detection"},{"level":4,"text":"å®‰é˜²ç›‘æŽ§é¢†åŸŸæ£€æµ‹","anchor":"å®‰é˜²ç›‘æŽ§é¢†åŸŸæ£€æµ‹","htmlText":"å®‰é˜²ç›‘æŽ§é¢†åŸŸæ£€æµ‹"},{"level":3,"text":"Anti-UAV Field Detection","anchor":"anti-uav-field-detection","htmlText":"Anti-UAV Field Detection"},{"level":4,"text":"åæ— äººæœºé¢†åŸŸæ£€æµ‹","anchor":"åæ— äººæœºé¢†åŸŸæ£€æµ‹","htmlText":"åæ— äººæœºé¢†åŸŸæ£€æµ‹"},{"level":3,"text":"Medical Field Detection","anchor":"medical-field-detection","htmlText":"Medical Field Detection"},{"level":4,"text":"åŒ»å­¦é¢†åŸŸæ£€æµ‹","anchor":"åŒ»å­¦é¢†åŸŸæ£€æµ‹","htmlText":"åŒ»å­¦é¢†åŸŸæ£€æµ‹"},{"level":3,"text":"Chemistry Field Detection","anchor":"chemistry-field-detection","htmlText":"Chemistry Field Detection"},{"level":4,"text":"åŒ–å­¦é¢†åŸŸæ£€æµ‹","anchor":"åŒ–å­¦é¢†åŸŸæ£€æµ‹","htmlText":"åŒ–å­¦é¢†åŸŸæ£€æµ‹"},{"level":3,"text":"Agricultural Field Detection","anchor":"agricultural-field-detection","htmlText":"Agricultural Field Detection"},{"level":4,"text":"å†œä¸šé¢†åŸŸæ£€æµ‹","anchor":"å†œä¸šé¢†åŸŸæ£€æµ‹","htmlText":"å†œä¸šé¢†åŸŸæ£€æµ‹"},{"level":3,"text":"Sports Field Detection","anchor":"sports-field-detection","htmlText":"Sports Field Detection"},{"level":4,"text":"ä½“è‚²é¢†åŸŸæ£€æµ‹","anchor":"ä½“è‚²é¢†åŸŸæ£€æµ‹","htmlText":"ä½“è‚²é¢†åŸŸæ£€æµ‹"},{"level":3,"text":"Aerial Imagery Detection","anchor":"aerial-imagery-detection","htmlText":"Aerial Imagery Detection"},{"level":4,"text":"é¥æ„Ÿå›¾åƒæ£€æµ‹","anchor":"é¥æ„Ÿå›¾åƒæ£€æµ‹","htmlText":"é¥æ„Ÿå›¾åƒæ£€æµ‹"},{"level":3,"text":"Adverse Weather Conditions","anchor":"adverse-weather-conditions","htmlText":"Adverse Weather Conditions"},{"level":4,"text":"æ¶åŠ£å¤©æ°”æƒ…å†µ","anchor":"æ¶åŠ£å¤©æ°”æƒ…å†µ","htmlText":"æ¶åŠ£å¤©æ°”æƒ…å†µ"},{"level":3,"text":"Adversarial Attack and Defense","anchor":"adversarial-attack-and-defense","htmlText":"Adversarial Attack and Defense"},{"level":4,"text":"å¯¹æŠ—æ”»å‡»ä¸Žé˜²å¾¡","anchor":"å¯¹æŠ—æ”»å‡»ä¸Žé˜²å¾¡","htmlText":"å¯¹æŠ—æ”»å‡»ä¸Žé˜²å¾¡"},{"level":3,"text":"Camouflaged Detection","anchor":"camouflaged-detection","htmlText":"Camouflaged Detection"},{"level":4,"text":"ä¼ªè£…ç›®æ ‡æ£€æµ‹","anchor":"ä¼ªè£…ç›®æ ‡æ£€æµ‹","htmlText":"ä¼ªè£…ç›®æ ‡æ£€æµ‹"},{"level":3,"text":"Game Field Detection","anchor":"game-field-detection","htmlText":"Game Field Detection"},{"level":4,"text":"æ¸¸æˆé¢†åŸŸæ£€æµ‹","anchor":"æ¸¸æˆé¢†åŸŸæ£€æµ‹","htmlText":"æ¸¸æˆé¢†åŸŸæ£€æµ‹"},{"level":3,"text":"Automatic Annotation Tools","anchor":"automatic-annotation-tools","htmlText":"Automatic Annotation Tools"},{"level":4,"text":"è‡ªåŠ¨æ ‡æ³¨å·¥å…·","anchor":"è‡ªåŠ¨æ ‡æ³¨å·¥å…·","htmlText":"è‡ªåŠ¨æ ‡æ³¨å·¥å…·"},{"level":3,"text":"Feature Map Visualization","anchor":"feature-map-visualization","htmlText":"Feature Map Visualization"},{"level":4,"text":"ç‰¹å¾å›¾å¯è§†åŒ–","anchor":"ç‰¹å¾å›¾å¯è§†åŒ–","htmlText":"ç‰¹å¾å›¾å¯è§†åŒ–"},{"level":3,"text":"Object Detection Evaluation Metrics","anchor":"object-detection-evaluation-metrics","htmlText":"Object Detection Evaluation Metrics"},{"level":4,"text":"ç›®æ ‡æ£€æµ‹æ€§èƒ½è¯„ä»·æŒ‡æ ‡","anchor":"ç›®æ ‡æ£€æµ‹æ€§èƒ½è¯„ä»·æŒ‡æ ‡","htmlText":"ç›®æ ‡æ£€æµ‹æ€§èƒ½è¯„ä»·æŒ‡æ ‡"},{"level":3,"text":"GUI","anchor":"gui","htmlText":"GUI"},{"level":4,"text":"å›¾å½¢ç”¨æˆ·ç•Œé¢","anchor":"å›¾å½¢ç”¨æˆ·ç•Œé¢","htmlText":"å›¾å½¢ç”¨æˆ·ç•Œé¢"},{"level":4,"text":"Swift-Related","anchor":"swift-related","htmlText":"Swift-Related"},{"level":4,"text":"Flutter-Related","anchor":"flutter-related","htmlText":"Flutter-Related"},{"level":4,"text":"Streamlit-Related","anchor":"streamlit-related","htmlText":"Streamlit-Related"},{"level":4,"text":"Gradio-Related","anchor":"gradio-related","htmlText":"Gradio-Related"},{"level":4,"text":"QT-Related","anchor":"qt-related","htmlText":"QT-Related"},{"level":4,"text":"PySide-Related","anchor":"pyside-related","htmlText":"PySide-Related"},{"level":3,"text":"Other Applications","anchor":"other-applications","htmlText":"Other Applications"},{"level":4,"text":"å…¶å®ƒåº”ç”¨","anchor":"å…¶å®ƒåº”ç”¨","htmlText":"å…¶å®ƒåº”ç”¨"},{"level":2,"text":"Object Detection Datasets","anchor":"object-detection-datasets","htmlText":"Object Detection Datasets"},{"level":3,"text":"Datasets Share Platform","anchor":"datasets-share-platform","htmlText":"Datasets Share Platform"},{"level":3,"text":"Datasets Tools","anchor":"datasets-tools","htmlText":"Datasets Tools"},{"level":4,"text":"Data Annotation","anchor":"data-annotation","htmlText":"Data Annotation"},{"level":4,"text":"Data Augmentation","anchor":"data-augmentation","htmlText":"Data Augmentation"},{"level":4,"text":"Data Management","anchor":"data-management","htmlText":"Data Management"},{"level":3,"text":"General Detection and Recognition Datasets","anchor":"general-detection-and-recognition-datasets","htmlText":"General Detection and Recognition Datasets"},{"level":4,"text":"General Object Detection Datasets","anchor":"general-object-detection-datasets","htmlText":"General Object Detection Datasets"},{"level":4,"text":"General Object Recognition Datasets","anchor":"general-object-recognition-datasets","htmlText":"General Object Recognition Datasets"},{"level":3,"text":"Autonomous Driving Datasets","anchor":"autonomous-driving-datasets","htmlText":"Autonomous Driving Datasets"},{"level":4,"text":"Diverse Autonomous Driving Datasets","anchor":"diverse-autonomous-driving-datasets","htmlText":"Diverse Autonomous Driving Datasets"},{"level":4,"text":"Traffic Sign Detection Datasets","anchor":"traffic-sign-detection-datasets","htmlText":"Traffic Sign Detection Datasets"},{"level":4,"text":"License Plate Detection and Recognition Datasets","anchor":"license-plate-detection-and-recognition-datasets","htmlText":"License Plate Detection and Recognition Datasets"},{"level":3,"text":"Adverse Weather Datasets","anchor":"adverse-weather-datasets","htmlText":"Adverse Weather Datasets"},{"level":3,"text":"Person Detection Datasets","anchor":"person-detection-datasets","htmlText":"Person Detection Datasets"},{"level":2,"text":"Anti-UAV Datasets","anchor":"anti-uav-datasets","htmlText":"Anti-UAV Datasets"},{"level":3,"text":"Optical Aerial Imagery Datasets","anchor":"optical-aerial-imagery-datasets","htmlText":"Optical Aerial Imagery Datasets"},{"level":3,"text":"Low-light Image Datasets","anchor":"low-light-image-datasets","htmlText":"Low-light Image Datasets"},{"level":3,"text":"Infrared Image Datasets","anchor":"infrared-image-datasets","htmlText":"Infrared Image Datasets"},{"level":3,"text":"SAR Image Datasets","anchor":"sar-image-datasets","htmlText":"SAR Image Datasets"},{"level":3,"text":"Sonar Image Datasets","anchor":"sonar-image-datasets","htmlText":"Sonar Image Datasets"},{"level":3,"text":"Multimodal Image Datasets","anchor":"multimodal-image-datasets","htmlText":"Multimodal Image Datasets"},{"level":3,"text":"3D Object Detection Datasets","anchor":"3d-object-detection-datasets","htmlText":"3D Object Detection Datasets"},{"level":3,"text":"Vehicle-to-Everything Field Datasets","anchor":"vehicle-to-everything-field-datasets","htmlText":"Vehicle-to-Everything Field Datasets"},{"level":3,"text":"Super-Resolution Field Datasets","anchor":"super-resolution-field-datasets","htmlText":"Super-Resolution Field Datasets"},{"level":3,"text":"Face Detection and Recognition Datasets","anchor":"face-detection-and-recognition-datasets","htmlText":"Face Detection and Recognition Datasets"},{"level":4,"text":"Face Detection Datasets","anchor":"face-detection-datasets","htmlText":"Face Detection Datasets"},{"level":4,"text":"Face Recognition Datasets","anchor":"face-recognition-datasets","htmlText":"Face Recognition Datasets"},{"level":2,"text":"Blogs","anchor":"blogs","htmlText":"Blogs"},{"level":2,"text":"Videos","anchor":"videos","htmlText":"Videos"},{"level":2,"text":"Star History","anchor":"star-history","htmlText":"Star History"}],"siteNavLoginPath":"/login?return_to=https%3A%2F%2Fgithub.com%2Fcoderonion%2Fawesome-yolo-object-detection"}}],"overviewFilesProcessingTime":0,"copilotSWEAgentEnabled":false}},"appPayload":{"helpUrl":"https://docs.github.com","findFileWorkerPath":"/assets-cdn/worker/find-file-worker-9bd411a8e273.js","findInFileWorkerPath":"/assets-cdn/worker/find-in-file-worker-4747241b1152.js","githubDevUrl":null,"enabled_features":{"copilot_workspace":null,"code_nav_ui_events":false,"react_blob_overlay":false,"accessible_code_button":true}}}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>


      <input type="hidden" data-csrf="true" value="JuRQRXwLVB3oT/hbh8H50CIzu2kAZoiSPfgCWqd+mKbJs2B72Lkgw+dhwiIGr35Ro//UcEpTdxwWbWNlf5l4sg==" />
</div>
  <div data-view-component="true" class="Layout-sidebar">      

      <div class="BorderGrid about-margin" data-pjax>
        <div class="BorderGrid-row">
          <div class="BorderGrid-cell">
            <div class="hide-sm hide-md">
  <h2 class="mb-3 h4">About</h2>

      <p class="f4 my-3">
        ðŸš€ðŸš€ðŸš€ A collection of some awesome public YOLO object detection series projects and the related object detection datasets.
      </p>

    <h3 class="sr-only">Topics</h3>
    <div class="my-3">
        <div class="f6">
      <a href="/topics/gui" title="Topic: gui" data-view-component="true" class="topic-tag topic-tag-link">
  gui
</a>
      <a href="/topics/cuda" title="Topic: cuda" data-view-component="true" class="topic-tag topic-tag-link">
  cuda
</a>
      <a href="/topics/yolo" title="Topic: yolo" data-view-component="true" class="topic-tag topic-tag-link">
  yolo
</a>
      <a href="/topics/llama" title="Topic: llama" data-view-component="true" class="topic-tag topic-tag-link">
  llama
</a>
      <a href="/topics/object-detection" title="Topic: object-detection" data-view-component="true" class="topic-tag topic-tag-link">
  object-detection
</a>
      <a href="/topics/datasets" title="Topic: datasets" data-view-component="true" class="topic-tag topic-tag-link">
  datasets
</a>
      <a href="/topics/vlm" title="Topic: vlm" data-view-component="true" class="topic-tag topic-tag-link">
  vlm
</a>
      <a href="/topics/tensorrt" title="Topic: tensorrt" data-view-component="true" class="topic-tag topic-tag-link">
  tensorrt
</a>
      <a href="/topics/snn" title="Topic: snn" data-view-component="true" class="topic-tag topic-tag-link">
  snn
</a>
      <a href="/topics/spiking-neural-network" title="Topic: spiking-neural-network" data-view-component="true" class="topic-tag topic-tag-link">
  spiking-neural-network
</a>
      <a href="/topics/few-shot-object-detection" title="Topic: few-shot-object-detection" data-view-component="true" class="topic-tag topic-tag-link">
  few-shot-object-detection
</a>
      <a href="/topics/yolov5" title="Topic: yolov5" data-view-component="true" class="topic-tag topic-tag-link">
  yolov5
</a>
      <a href="/topics/object-detection-datasets" title="Topic: object-detection-datasets" data-view-component="true" class="topic-tag topic-tag-link">
  object-detection-datasets
</a>
      <a href="/topics/rknn" title="Topic: rknn" data-view-component="true" class="topic-tag topic-tag-link">
  rknn
</a>
      <a href="/topics/llm" title="Topic: llm" data-view-component="true" class="topic-tag topic-tag-link">
  llm
</a>
      <a href="/topics/yolov8" title="Topic: yolov8" data-view-component="true" class="topic-tag topic-tag-link">
  yolov8
</a>
      <a href="/topics/mllm" title="Topic: mllm" data-view-component="true" class="topic-tag topic-tag-link">
  mllm
</a>
      <a href="/topics/open-world-object-detection" title="Topic: open-world-object-detection" data-view-component="true" class="topic-tag topic-tag-link">
  open-world-object-detection
</a>
      <a href="/topics/qwen" title="Topic: qwen" data-view-component="true" class="topic-tag topic-tag-link">
  qwen
</a>
      <a href="/topics/deepseek" title="Topic: deepseek" data-view-component="true" class="topic-tag topic-tag-link">
  deepseek
</a>
  </div>

    </div>

    <h3 class="sr-only">Resources</h3>
    <div class="mt-2">
      <a class="Link--muted" data-analytics-event="{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:readme&quot;}" href="#readme-ov-file">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-book mr-2">
    <path d="M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z"></path>
</svg>
        Readme
</a>    </div>

  





  <include-fragment src="/coderonion/awesome-yolo-object-detection/hovercards/citation/sidebar_partial?tree_name=main" data-nonce="v2:515a6721-8eb7-ba0a-7b66-e450a60aff90" data-view-component="true">
  

  <div data-show-on-forbidden-error hidden>
    <div class="Box">
  <div class="blankslate-container">
    <div data-view-component="true" class="blankslate blankslate-spacious color-bg-default rounded-2">
      

      <h3 data-view-component="true" class="blankslate-heading">        Uh oh!
</h3>
      <p data-view-component="true">        <p class="color-fg-muted my-2 mb-2 ws-normal">There was an error while loading. <a class="Link--inTextBlock" data-turbo="false" href="" aria-label="Please reload this page">Please reload this page</a>.</p>
</p>

</div>  </div>
</div>  </div>
</include-fragment>
  <div class="mt-2">
    <a href="/coderonion/awesome-yolo-object-detection/activity" data-view-component="true" class="Link Link--muted"><svg text="gray" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-pulse mr-2">
    <path d="M6 2c.306 0 .582.187.696.471L10 10.731l1.304-3.26A.751.751 0 0 1 12 7h3.25a.75.75 0 0 1 0 1.5h-2.742l-1.812 4.528a.751.751 0 0 1-1.392 0L6 4.77 4.696 8.03A.75.75 0 0 1 4 8.5H.75a.75.75 0 0 1 0-1.5h2.742l1.812-4.529A.751.751 0 0 1 6 2Z"></path>
</svg>
      <span class="color-fg-muted">Activity</span></a>  </div>


  <h3 class="sr-only">Stars</h3>
  <div class="mt-2">
    <a href="/coderonion/awesome-yolo-object-detection/stargazers" data-view-component="true" class="Link Link--muted"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-star mr-2">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
      <strong>1.6k</strong>
      stars</a>  </div>

  <h3 class="sr-only">Watchers</h3>
  <div class="mt-2">
    <a href="/coderonion/awesome-yolo-object-detection/watchers" data-view-component="true" class="Link Link--muted"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-eye mr-2">
    <path d="M8 2c1.981 0 3.671.992 4.933 2.078 1.27 1.091 2.187 2.345 2.637 3.023a1.62 1.62 0 0 1 0 1.798c-.45.678-1.367 1.932-2.637 3.023C11.67 13.008 9.981 14 8 14c-1.981 0-3.671-.992-4.933-2.078C1.797 10.83.88 9.576.43 8.898a1.62 1.62 0 0 1 0-1.798c.45-.677 1.367-1.931 2.637-3.022C4.33 2.992 6.019 2 8 2ZM1.679 7.932a.12.12 0 0 0 0 .136c.411.622 1.241 1.75 2.366 2.717C5.176 11.758 6.527 12.5 8 12.5c1.473 0 2.825-.742 3.955-1.715 1.124-.967 1.954-2.096 2.366-2.717a.12.12 0 0 0 0-.136c-.412-.621-1.242-1.75-2.366-2.717C10.824 4.242 9.473 3.5 8 3.5c-1.473 0-2.825.742-3.955 1.715-1.124.967-1.954 2.096-2.366 2.717ZM8 10a2 2 0 1 1-.001-3.999A2 2 0 0 1 8 10Z"></path>
</svg>
      <strong>34</strong>
      watching</a>  </div>

  <h3 class="sr-only">Forks</h3>
  <div class="mt-2">
    <a href="/coderonion/awesome-yolo-object-detection/forks" data-view-component="true" class="Link Link--muted"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo-forked mr-2">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>
      <strong>220</strong>
      forks</a>  </div>


    <div class="mt-2">
      <a class="Link--muted" href="/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fcoderonion%2Fawesome-yolo-object-detection&amp;report=coderonion+%28user%29">
          Report repository
</a>    </div>
</div>

          </div>
        </div>

        
            <div class="BorderGrid-row">
              <div class="BorderGrid-cell">
                <h2 class="h4 mb-3" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame">
  <a href="/coderonion/awesome-yolo-object-detection/releases" data-view-component="true" class="Link--primary no-underline Link">Releases</a></h2>

    <div class="text-small color-fg-muted">No releases published</div>

              </div>
            </div>

        
        
            <div class="BorderGrid-row">
              <div class="BorderGrid-cell">
                
  <h2 class="h4 mb-3">
  <a href="/users/coderonion/packages?repo_name=awesome-yolo-object-detection" data-view-component="true" class="Link--primary no-underline Link d-flex flex-items-center">Packages
      <span title="0" hidden="hidden" data-view-component="true" class="Counter ml-1">0</span></a></h2>


      <div class="text-small color-fg-muted" >
        No packages published <br>
      </div>



              </div>
            </div>

        
        
            <div class="BorderGrid-row">
              <div class="BorderGrid-cell">
                <h2 class="h4 mb-3">
  <a href="/coderonion/awesome-yolo-object-detection/graphs/contributors" data-view-component="true" class="Link--primary no-underline Link d-flex flex-items-center">Contributors
      <span title="5" data-view-component="true" class="Counter ml-1">5</span></a></h2>


    
  <ul class="list-style-none d-flex flex-wrap mb-n2">
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/coderonion"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/coderonion/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/99076655?s=64&amp;v=4" alt="@coderonion" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/kadirnar"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/kadirnar/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/36204372?s=64&amp;v=4" alt="@kadirnar" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/WangQvQ"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/WangQvQ/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/58406737?s=64&amp;v=4" alt="@WangQvQ" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/Shaing"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/Shaing/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/19544390?s=64&amp;v=4" alt="@Shaing" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/PetervanLunteren"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/PetervanLunteren/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/85185478?s=64&amp;v=4" alt="@PetervanLunteren" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
</ul>





              </div>
            </div>

        
        
              </div>
</div>
  
</div></div>

  </div>


  </div>

</turbo-frame>


    </main>
  </div>

  </div>

          <footer class="footer pt-8 pb-6 f6 color-fg-muted p-responsive" role="contentinfo" >
  <h2 class='sr-only'>Footer</h2>

  


  <div class="d-flex flex-justify-center flex-items-center flex-column-reverse flex-lg-row flex-wrap flex-lg-nowrap">
    <div class="d-flex flex-items-center flex-shrink-0 mx-2">
      <a aria-label="GitHub Homepage" class="footer-octicon mr-2" href="https://github.com">
        <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-mark-github">
    <path d="M12 1C5.923 1 1 5.923 1 12c0 4.867 3.149 8.979 7.521 10.436.55.096.756-.233.756-.522 0-.262-.013-1.128-.013-2.049-2.764.509-3.479-.674-3.699-1.292-.124-.317-.66-1.293-1.127-1.554-.385-.207-.936-.715-.014-.729.866-.014 1.485.797 1.691 1.128.99 1.663 2.571 1.196 3.204.907.096-.715.385-1.196.701-1.471-2.448-.275-5.005-1.224-5.005-5.432 0-1.196.426-2.186 1.128-2.956-.111-.275-.496-1.402.11-2.915 0 0 .921-.288 3.024 1.128a10.193 10.193 0 0 1 2.75-.371c.936 0 1.871.123 2.75.371 2.104-1.43 3.025-1.128 3.025-1.128.605 1.513.221 2.64.111 2.915.701.77 1.127 1.747 1.127 2.956 0 4.222-2.571 5.157-5.019 5.432.399.344.743 1.004.743 2.035 0 1.471-.014 2.654-.014 3.025 0 .289.206.632.756.522C19.851 20.979 23 16.854 23 12c0-6.077-4.922-11-11-11Z"></path>
</svg>
</a>
      <span>
        &copy; 2025 GitHub,&nbsp;Inc.
      </span>
    </div>

    <nav aria-label="Footer">
      <h3 class="sr-only" id="sr-footer-heading">Footer navigation</h3>

      <ul class="list-style-none d-flex flex-justify-center flex-wrap mb-2 mb-lg-0" aria-labelledby="sr-footer-heading">

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to Terms&quot;,&quot;label&quot;:&quot;text:terms&quot;}" href="https://docs.github.com/site-policy/github-terms/github-terms-of-service" data-view-component="true" class="Link--secondary Link">Terms</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to privacy&quot;,&quot;label&quot;:&quot;text:privacy&quot;}" href="https://docs.github.com/site-policy/privacy-policies/github-privacy-statement" data-view-component="true" class="Link--secondary Link">Privacy</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to security&quot;,&quot;label&quot;:&quot;text:security&quot;}" href="https://github.com/security" data-view-component="true" class="Link--secondary Link">Security</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to status&quot;,&quot;label&quot;:&quot;text:status&quot;}" href="https://www.githubstatus.com/" data-view-component="true" class="Link--secondary Link">Status</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to community&quot;,&quot;label&quot;:&quot;text:community&quot;}" href="https://github.community/" data-view-component="true" class="Link--secondary Link">Community</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to docs&quot;,&quot;label&quot;:&quot;text:docs&quot;}" href="https://docs.github.com/" data-view-component="true" class="Link--secondary Link">Docs</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to contact&quot;,&quot;label&quot;:&quot;text:contact&quot;}" href="https://support.github.com?tags=dotcom-footer" data-view-component="true" class="Link--secondary Link">Contact</a>
          </li>

          <li class="mx-2" >
  <cookie-consent-link>
    <button
      type="button"
      class="Link--secondary underline-on-hover border-0 p-0 color-bg-transparent"
      data-action="click:cookie-consent-link#showConsentManagement"
      data-analytics-event="{&quot;location&quot;:&quot;footer&quot;,&quot;action&quot;:&quot;cookies&quot;,&quot;context&quot;:&quot;subfooter&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;cookies_link_subfooter_footer&quot;}"
    >
       Manage cookies
    </button>
  </cookie-consent-link>
</li>

<li class="mx-2">
  <cookie-consent-link>
    <button
      type="button"
      class="Link--secondary underline-on-hover border-0 p-0 color-bg-transparent text-left"
      data-action="click:cookie-consent-link#showConsentManagement"
      data-analytics-event="{&quot;location&quot;:&quot;footer&quot;,&quot;action&quot;:&quot;dont_share_info&quot;,&quot;context&quot;:&quot;subfooter&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;dont_share_info_link_subfooter_footer&quot;}"
    >
      Do not share my personal information
    </button>
  </cookie-consent-link>
</li>

      </ul>
    </nav>
  </div>
</footer>



    <ghcc-consent id="ghcc" class="position-fixed bottom-0 left-0" style="z-index: 999999"
      data-locale="en"
      data-initial-cookie-consent-allowed=""
      data-cookie-consent-required="false"
    ></ghcc-consent>




  <div id="ajax-error-message" class="ajax-error-message flash flash-error" hidden>
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
    <button type="button" class="flash-close js-ajax-error-dismiss" aria-label="Dismiss error">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
    </button>
    You canâ€™t perform that action at this time.
  </div>

    <template id="site-details-dialog">
  <details class="details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm" open>
    <summary role="button" aria-label="Close dialog"></summary>
    <details-dialog class="Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal">
      <button class="Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0" type="button" aria-label="Close dialog" data-close-dialog>
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
      </button>
      <div class="octocat-spinner my-6 js-details-dialog-spinner"></div>
    </details-dialog>
  </details>
</template>

    <div class="Popover js-hovercard-content position-absolute" style="display: none; outline: none;">
  <div class="Popover-message Popover-message--bottom-left Popover-message--large Box color-shadow-large" style="width:360px;">
  </div>
</div>

    <template id="snippet-clipboard-copy-button">
  <div class="zeroclipboard-container position-absolute right-0 top-0">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn js-clipboard-copy m-2 p-0" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon m-2">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>
<template id="snippet-clipboard-copy-button-unpositioned">
  <div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>




    </div>
    <div id="js-global-screen-reader-notice" class="sr-only mt-n1" aria-live="polite" aria-atomic="true" ></div>
    <div id="js-global-screen-reader-notice-assertive" class="sr-only mt-n1" aria-live="assertive" aria-atomic="true"></div>
  </body>
</html>

