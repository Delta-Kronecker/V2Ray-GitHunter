






<!DOCTYPE html>
<html
  lang="en"
  
  data-color-mode="auto" data-light-theme="light" data-dark-theme="dark"
  data-a11y-animated-images="system" data-a11y-link-underlines="true"
  
  >




  <head>
    <meta charset="utf-8">
  <link rel="dns-prefetch" href="https://github.githubassets.com">
  <link rel="dns-prefetch" href="https://avatars.githubusercontent.com">
  <link rel="dns-prefetch" href="https://github-cloud.s3.amazonaws.com">
  <link rel="dns-prefetch" href="https://user-images.githubusercontent.com/">
  <link rel="preconnect" href="https://github.githubassets.com" crossorigin>
  <link rel="preconnect" href="https://avatars.githubusercontent.com">

  

  <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/light-44e67b0cd5d5.css" /><link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/light_high_contrast-b51c2fae25e8.css" /><link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/dark-cb035ed575b8.css" /><link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/dark_high_contrast-99e9b1169976.css" /><link data-color-theme="light" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light-44e67b0cd5d5.css" /><link data-color-theme="light_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light_high_contrast-b51c2fae25e8.css" /><link data-color-theme="light_colorblind" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light_colorblind-dadcba82130c.css" /><link data-color-theme="light_colorblind_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light_colorblind_high_contrast-cdc36145225e.css" /><link data-color-theme="light_tritanopia" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light_tritanopia-0ca195e3b5f3.css" /><link data-color-theme="light_tritanopia_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light_tritanopia_high_contrast-f9fb5556a83f.css" /><link data-color-theme="dark" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark-cb035ed575b8.css" /><link data-color-theme="dark_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_high_contrast-99e9b1169976.css" /><link data-color-theme="dark_colorblind" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_colorblind-9541c4141757.css" /><link data-color-theme="dark_colorblind_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_colorblind_high_contrast-bc604fc65912.css" /><link data-color-theme="dark_tritanopia" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_tritanopia-384776200fd7.css" /><link data-color-theme="dark_tritanopia_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_tritanopia_high_contrast-489c70dedd0a.css" /><link data-color-theme="dark_dimmed" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_dimmed-1545a2e9e540.css" /><link data-color-theme="dark_dimmed_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_dimmed_high_contrast-4c1792a987c3.css" />

  <style type="text/css">
    :root {
      --tab-size-preference: 4;
    }

    pre, code {
      tab-size: var(--tab-size-preference);
    }
  </style>

    <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-primitives-15839d47b75d.css" />
    <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-a5c85403da8c.css" />
    <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/global-4d11e88b2383.css" />
    <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/github-6aeb6451a33d.css" />
  <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/repository-5d735668c600.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/code-9c9b8dc61e74.css" />

  

  <script type="application/json" id="client-env">{"locale":"en","featureFlags":["alternate_user_config_repo","api_insights_show_missing_data_banner","attestations_filtering","attestations_sorting","billing_unfiltered_discounts","client_version_header","codespaces_prebuild_region_target_update","contentful_lp_footnotes","copilot_agent_cli_public_preview","copilot_agent_task_list_v2","copilot_agent_tasks_btn_code_nav","copilot_agent_tasks_btn_code_view","copilot_agent_tasks_btn_code_view_lines","copilot_api_agentic_issue_marshal_yaml","copilot_api_github_draft_update_issue_skill","copilot_chat_attach_multiple_images","copilot_chat_file_redirect","copilot_chat_reduce_quota_checks","copilot_chat_search_bar_redirect","copilot_chat_selection_attachments","copilot_chat_vision_in_claude","copilot_chat_vision_skip_thread_create","copilot_custom_copilots","copilot_custom_copilots_feature_preview","copilot_duplicate_thread","copilot_extensions_deprecation_notice","copilot_features_raycast_logo","copilot_file_block_ref_matching","copilot_free_to_paid_telem","copilot_ftp_hyperspace_upgrade_prompt","copilot_ftp_settings_upgrade","copilot_ftp_upgrade_to_pro_from_models","copilot_ftp_your_copilot_settings","copilot_generate_commit_message_dry_regenerate","copilot_immersive_structured_model_picker","copilot_immersive_task_within_chat_thread","copilot_insights_column_chart_axis_legibility_fix","copilot_insights_usage_export_ndjson","copilot_mission_control_feedback","copilot_mission_control_session_feedback","copilot_no_floating_button","copilot_read_shared_conversation","copilot_spaces_as_attachments","copilot_spaces_ga","copilot_spark_loading_webgl","copilot_spark_progressive_error_handling","copilot_spark_read_iteration_history_from_git_v2","copilot_spark_use_billing_headers","copilot_spark_write_iteration_history_to_git","copilot_stable_conversation_view","copilot_workbench_agent_seed_tool","copilot_workbench_cache","copilot_workbench_connection_reload_banner","copilot_workbench_preview_analytics","copilot_workbench_skip_repo_on_codespace","copilot_workbench_use_single_prompt","direct_to_salesforce","disable_dashboard_universe_2025_private_preview","dotcom_chat_client_side_skills","failbot_report_error_react_apps_on_page","ghost_pilot_confidence_truncation_25","ghost_pilot_confidence_truncation_40","global_search_multi_orgs","hpc_improve_dom_insertion_observer","inp_reduced_threshold","insert_before_patch","issue_fields_report_usage","issues_copilot_cross_repo_assign","issues_react_blur_item_picker_on_close","issues_react_bots_timeline_pagination","issues_react_prohibit_title_fallback","issues_react_remove_placeholders","issues_sticky_sidebar","kb_convert_to_space","lifecycle_label_name_updates","link_contact_sales_swp_marketo","marketing_pages_search_explore_provider","mcp_registry_install","memex_mwl_filter_field_delimiter","migrate_toasts_to_banners_web_notifications","new_traffic_page_banner","open_agent_session_in_vscode_insiders","pinned_issue_fields","primer_react_segmented_control_tooltip","primer_react_unified_portal_root","record_sso_banner_metrics","ref_selector_create_tag_dialog","remove_child_patch","report_hydro_web_vitals","repos_insights_remove_new_url","sample_network_conn_type","scheduled_reminders_updated_limits","site_homepage_collaborate_video","site_homepage_contentful","site_msbuild_webgl_hero","spark_fix_rename","spark_force_push_after_checkout","spark_kv_encocoded_keys","spark_show_data_access_on_publish","spark_sync_repository_after_iteration","viewscreen_sandbox","webp_support","workbench_store_readonly"],"copilotApiOverrideUrl":"https://api.githubcopilot.com"}</script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/high-contrast-cookie-f3788027bd8d.js"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/wp-runtime-b73258c5aaae.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_oddbird_popover-polyfill_dist_popover-fn_js-468bf7cab607.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_stacktrace-parser_dist_stack-trace-parser_esm_js-node_modules_github_bro-2f4e04-280c10ec004d.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/environment-b4e74adb6411.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_primer_behaviors_dist_esm_index_mjs-3eee64e5ddf0.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_selector-observer_dist_index_esm_js-9ab93471824e.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_relative-time-element_dist_index_js-ef89d23fcc0a.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_auto-complete-element_dist_index_js-node_modules_github_catalyst_-0d7d60-ad3a87b2f0eb.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_text-expander-element_dist_index_js-754f5b5e9e7e.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_filter-input-element_dist_index_js-node_modules_github_remote-inp-665e70-ac788066c220.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_markdown-toolbar-element_dist_index_js-d41270eb61be.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_file-attachment-element_dist_index_js-node_modules_primer_view-co-777ce2-9ec8c103bf42.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/github-elements-9e1d42c09c62.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/element-registry-212230e65885.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_braintree_browser-detection_dist_browser-detection_js-node_modules_githu-bb80ec-f11c694928ba.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_lit-html_lit-html_js-9012bef51135.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_mini-throttle_dist_index_js-node_modules_morphdom_dist_morphdom-e-c1896e-ba47f43192a8.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_remote-form_dist_index_js-node_modules_delegated-events_dist_inde-893f9f-9ba0881c72fb.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_turbo_dist_turbo_es2017-esm_js-8eb9b2209bcd.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_hotkey_dist_index_js-node_modules_github_hydro-analytics-client_d-dd3ec8-1f3d5f90de2b.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_quote-selection_dist_index_js-node_modules_github_session-resume_-31b9f3-9021ed20220b.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/packages_document-metadata_document-metadata_ts-packages_failbot_failbot_ts-06156f7d8d1a.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/packages_updatable-content_updatable-content_ts-38f5e2f7c2a7.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/app_assets_modules_github_behaviors_ajax-error_ts-app_assets_modules_github_behaviors_details-6493f1-cecb020e2bb7.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/app_assets_modules_github_behaviors_task-list_ts-app_assets_modules_github_throttled-input_ts-047775-cfe8770908d1.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/app_assets_modules_github_behaviors_commenting_edit_ts-app_assets_modules_github_behaviors_ht-83c235-d8c5bfe37d1d.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/behaviors-d431b500aedc.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_delegated-events_dist_index_js-node_modules_github_catalyst_lib_index_js-ef6d0f-20d6767cecc0.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/notifications-global-d89a4ddd4532.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_virtualized-list_es_index_js-node_modules_github_template-parts_lib_inde-f69fd1-ead47121f2f7.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_remote-form_dist_index_js-node_modules_delegated-events_dist_inde-0d71a9-129b4f34d384.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/app_assets_modules_github_ref-selector_ts-63ecfa2887c1.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/codespaces-8cfd06ba3e39.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_filter-input-element_dist_index_js-node_modules_github_remote-inp-3eebbd-7f6bf4b8b391.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_mini-throttle_dist_decorators_js-node_modules_delegated-events_di-e161aa-9086b9aee9d1.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_file-attachment-element_dist_index_js-node_modules_github_remote--abdaf7-71f92102de66.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/repositories-7c2a36f9c401.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_mini-throttle_dist_index_js-node_modules_github_catalyst_lib_inde-96937f-70732ff56a20.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/code-menu-614eb4e0c016.js" defer="defer"></script>
  
  <script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/primer-react-cdd6dd11a475.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/react-lib-25ef56e89e94.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/react-core-26c9e2751844.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/octicons-react-dfcd3f5e8531.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_emotion_is-prop-valid_dist_emotion-is-prop-valid_esm_js-node_modules_emo-825c28-cdae255a4bbc.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_mini-throttle_dist_index_js-node_modules_github_hydro-analytics-c-c228f9-e9af1d9bff76.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_tanstack_query-core_build_modern_mutation_js-node_modules_tanstack_query-9bf7e4-2246c69bea10.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_swc_helpers_esm__class_private_method_get_js-node_modules_swc_helpers_es-d6b1a6-13297632eddc.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/packages_notifications-subscriptions-menu_entry_ts-packages_promise-with-resolvers-polyfill_p-15cb60-9c0f034a796f.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/notifications-subscriptions-menu-c28df4f8626e.js" defer="defer"></script>
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.f595f41454298e934d3c.module.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/notifications-subscriptions-menu.bab8822ac328fb95c70d.module.css" />

  <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.f595f41454298e934d3c.module.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/notifications-subscriptions-menu.bab8822ac328fb95c70d.module.css" />


  <title>GitHub - coderonion/awesome-yolo-object-detection: 🚀🚀🚀 A collection of some awesome public YOLO object detection series projects and the related object detection datasets.</title>



  <meta name="route-pattern" content="/:user_id/:repository" data-turbo-transient>
  <meta name="route-controller" content="files" data-turbo-transient>
  <meta name="route-action" content="disambiguate" data-turbo-transient>
  <meta name="fetch-nonce" content="v2:515a6721-8eb7-ba0a-7b66-e450a60aff90">

    
  <meta name="current-catalog-service-hash" content="f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb">


  <meta name="request-id" content="DC02:1A434F:BBDD2F:102D5A8:68FB563D" data-pjax-transient="true"/><meta name="html-safe-nonce" content="6c5b79325121764f3e7b2f56b9c435114922256726d86663d3013d53b5286b15" data-pjax-transient="true"/><meta name="visitor-payload" content="eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiJEQzAyOjFBNDM0RjpCQkREMkY6MTAyRDVBODo2OEZCNTYzRCIsInZpc2l0b3JfaWQiOiIxNzM1NDgyNjc5ODk0OTU1NTQ1IiwicmVnaW9uX2VkZ2UiOiJpYWQiLCJyZWdpb25fcmVuZGVyIjoiaWFkIn0=" data-pjax-transient="true"/><meta name="visitor-hmac" content="3b1b408113ffae2575a6091d8fdfc2a9b1f31eb125b6a77b0ecc8f942595d433" data-pjax-transient="true"/>


    <meta name="hovercard-subject-tag" content="repository:461270746" data-turbo-transient>


  <meta name="github-keyboard-shortcuts" content="repository,copilot" data-turbo-transient="true" />
  

  <meta name="selected-link" value="repo_source" data-turbo-transient>
  <link rel="assets" href="https://github.githubassets.com/">

    <meta name="google-site-verification" content="Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I">

<meta name="octolytics-url" content="https://collector.github.com/github/collect" />

  <meta name="analytics-location" content="/&lt;user-name&gt;/&lt;repo-name&gt;" data-turbo-transient="true" />

  




    <meta name="user-login" content="">

  

    <meta name="viewport" content="width=device-width">

    

      <meta name="description" content="🚀🚀🚀 A collection of some awesome public YOLO object detection series projects and the related object detection datasets. - coderonion/awesome-yolo-object-detection">

      <link rel="search" type="application/opensearchdescription+xml" href="/opensearch.xml" title="GitHub">

    <link rel="fluid-icon" href="https://github.com/fluidicon.png" title="GitHub">
    <meta property="fb:app_id" content="1401488693436528">
    <meta name="apple-itunes-app" content="app-id=1477376905, app-argument=https://github.com/coderonion/awesome-yolo-object-detection" />

      <meta name="twitter:image" content="https://opengraph.githubassets.com/35910d5b1c76bcd0169b4fb1bc83b8c2324a4caeef65559bac5ad6c45cf5ec13/coderonion/awesome-yolo-object-detection" /><meta name="twitter:site" content="@github" /><meta name="twitter:card" content="summary_large_image" /><meta name="twitter:title" content="GitHub - coderonion/awesome-yolo-object-detection: 🚀🚀🚀 A collection of some awesome public YOLO object detection series projects and the related object detection datasets." /><meta name="twitter:description" content="🚀🚀🚀 A collection of some awesome public YOLO object detection series projects and the related object detection datasets. - coderonion/awesome-yolo-object-detection" />
  <meta property="og:image" content="https://opengraph.githubassets.com/35910d5b1c76bcd0169b4fb1bc83b8c2324a4caeef65559bac5ad6c45cf5ec13/coderonion/awesome-yolo-object-detection" /><meta property="og:image:alt" content="🚀🚀🚀 A collection of some awesome public YOLO object detection series projects and the related object detection datasets. - coderonion/awesome-yolo-object-detection" /><meta property="og:image:width" content="1200" /><meta property="og:image:height" content="600" /><meta property="og:site_name" content="GitHub" /><meta property="og:type" content="object" /><meta property="og:title" content="GitHub - coderonion/awesome-yolo-object-detection: 🚀🚀🚀 A collection of some awesome public YOLO object detection series projects and the related object detection datasets." /><meta property="og:url" content="https://github.com/coderonion/awesome-yolo-object-detection" /><meta property="og:description" content="🚀🚀🚀 A collection of some awesome public YOLO object detection series projects and the related object detection datasets. - coderonion/awesome-yolo-object-detection" />
  




      <meta name="hostname" content="github.com">



        <meta name="expected-hostname" content="github.com">


  <meta http-equiv="x-pjax-version" content="edb0d926ab1906770550b20a43d9b38dd31aa9f43125e46b0f03b199f9f5ffc9" data-turbo-track="reload">
  <meta http-equiv="x-pjax-csp-version" content="21a43568025709b66240454fc92d4f09335a96863f8ab1c46b4a07f6a5b67102" data-turbo-track="reload">
  <meta http-equiv="x-pjax-css-version" content="9a5723604920ed305ee49e39cb1005f635d72600a9d3ee8570586b8be07865c3" data-turbo-track="reload">
  <meta http-equiv="x-pjax-js-version" content="e219e7f22a568c92e2760b3fa72fe03f661aed0635cfdd507899c28619d497b7" data-turbo-track="reload">

  <meta name="turbo-cache-control" content="no-preview" data-turbo-transient="">

      <meta data-hydrostats="publish">
  <meta name="go-import" content="github.com/coderonion/awesome-yolo-object-detection git https://github.com/coderonion/awesome-yolo-object-detection.git">

  <meta name="octolytics-dimension-user_id" content="99076655" /><meta name="octolytics-dimension-user_login" content="coderonion" /><meta name="octolytics-dimension-repository_id" content="461270746" /><meta name="octolytics-dimension-repository_nwo" content="coderonion/awesome-yolo-object-detection" /><meta name="octolytics-dimension-repository_public" content="true" /><meta name="octolytics-dimension-repository_is_fork" content="false" /><meta name="octolytics-dimension-repository_network_root_id" content="461270746" /><meta name="octolytics-dimension-repository_network_root_nwo" content="coderonion/awesome-yolo-object-detection" />



      <link rel="canonical" href="https://github.com/coderonion/awesome-yolo-object-detection" data-turbo-transient>


    <meta name="turbo-body-classes" content="logged-out env-production page-responsive">


  <meta name="browser-stats-url" content="https://api.github.com/_private/browser/stats">

  <meta name="browser-errors-url" content="https://api.github.com/_private/browser/errors">

  <meta name="release" content="52b212fa9d89c9c0399bcd8a7727377c16297ef9">
  <meta name="ui-target" content="full">

  <link rel="mask-icon" href="https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg" color="#000000">
  <link rel="alternate icon" class="js-site-favicon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png">
  <link rel="icon" class="js-site-favicon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" data-base-href="https://github.githubassets.com/favicons/favicon">

<meta name="theme-color" content="#1e2327">
<meta name="color-scheme" content="light dark" />


  <link rel="manifest" href="/manifest.json" crossOrigin="use-credentials">

  </head>

  <body class="logged-out env-production page-responsive" style="word-wrap: break-word;">
    <div data-turbo-body class="logged-out env-production page-responsive" style="word-wrap: break-word;">
      



    <div class="position-relative header-wrapper js-header-wrapper ">
      <a href="#start-of-content" data-skip-target-assigned="false" class="px-2 py-4 color-bg-accent-emphasis color-fg-on-emphasis show-on-focus js-skip-to-content">Skip to content</a>

      <span data-view-component="true" class="progress-pjax-loader Progress position-fixed width-full">
    <span style="width: 0%;" data-view-component="true" class="Progress-item progress-pjax-loader-bar left-0 top-0 color-bg-accent-emphasis"></span>
</span>      
      
      <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.f595f41454298e934d3c.module.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/keyboard-shortcuts-dialog.2de9c7d6456a311fce49.module.css" />

<react-partial
  partial-name="keyboard-shortcuts-dialog"
  data-ssr="false"
  data-attempted-ssr="false"
  data-react-profiling="false"
>
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{"docsUrl":"https://docs.github.com/get-started/accessibility/keyboard-shortcuts"}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>





      

          

              
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_gsap_index_js-6265bea06e74.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_remote-form_dist_index_js-node_modules_delegated-events_dist_inde-94fd67-dc050877d1bf.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/sessions-917229b8a853.js" defer="defer"></script>

<header class="HeaderMktg header-logged-out js-details-container js-header Details f4 py-3" role="banner" data-is-top="true" data-color-mode=light data-light-theme=light data-dark-theme=dark>
  <h2 class="sr-only">Navigation Menu</h2>

  <button type="button" class="HeaderMktg-backdrop d-lg-none border-0 position-fixed top-0 left-0 width-full height-full js-details-target" aria-label="Toggle navigation">
    <span class="d-none">Toggle navigation</span>
  </button>

  <div class="d-flex flex-column flex-lg-row flex-items-center px-3 px-md-4 px-lg-5 height-full position-relative z-1">
    <div class="d-flex flex-justify-between flex-items-center width-full width-lg-auto">
      <div class="flex-1">
        <button aria-label="Toggle navigation" aria-expanded="false" type="button" data-view-component="true" class="js-details-target js-nav-padding-recalculate js-header-menu-toggle Button--link Button--medium Button d-lg-none color-fg-inherit p-1">  <span class="Button-content">
    <span class="Button-label"><div class="HeaderMenu-toggle-bar rounded my-1"></div>
            <div class="HeaderMenu-toggle-bar rounded my-1"></div>
            <div class="HeaderMenu-toggle-bar rounded my-1"></div></span>
  </span>
</button>
      </div>

      <a class="mr-lg-3 color-fg-inherit flex-order-2 js-prevent-focus-on-mobile-nav"
        href="/"
        aria-label="Homepage"
        data-analytics-event="{&quot;category&quot;:&quot;Marketing nav&quot;,&quot;action&quot;:&quot;click to go to homepage&quot;,&quot;label&quot;:&quot;ref_page:Marketing;ref_cta:Logomark;ref_loc:Header&quot;}">
        <svg height="32" aria-hidden="true" viewBox="0 0 24 24" version="1.1" width="32" data-view-component="true" class="octicon octicon-mark-github">
    <path d="M12 1C5.923 1 1 5.923 1 12c0 4.867 3.149 8.979 7.521 10.436.55.096.756-.233.756-.522 0-.262-.013-1.128-.013-2.049-2.764.509-3.479-.674-3.699-1.292-.124-.317-.66-1.293-1.127-1.554-.385-.207-.936-.715-.014-.729.866-.014 1.485.797 1.691 1.128.99 1.663 2.571 1.196 3.204.907.096-.715.385-1.196.701-1.471-2.448-.275-5.005-1.224-5.005-5.432 0-1.196.426-2.186 1.128-2.956-.111-.275-.496-1.402.11-2.915 0 0 .921-.288 3.024 1.128a10.193 10.193 0 0 1 2.75-.371c.936 0 1.871.123 2.75.371 2.104-1.43 3.025-1.128 3.025-1.128.605 1.513.221 2.64.111 2.915.701.77 1.127 1.747 1.127 2.956 0 4.222-2.571 5.157-5.019 5.432.399.344.743 1.004.743 2.035 0 1.471-.014 2.654-.014 3.025 0 .289.206.632.756.522C19.851 20.979 23 16.854 23 12c0-6.077-4.922-11-11-11Z"></path>
</svg>
      </a>

      <div class="d-flex flex-1 flex-order-2 text-right d-lg-none gap-2 flex-justify-end">
          <a
            href="/login?return_to=https%3A%2F%2Fgithub.com%2Fcoderonion%2Fawesome-yolo-object-detection"
            class="HeaderMenu-link HeaderMenu-button d-inline-flex f5 no-underline border color-border-default rounded-2 px-2 py-1 color-fg-inherit js-prevent-focus-on-mobile-nav"
            data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/coderonion/awesome-yolo-object-detection&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="58d2cabbb70ca01d75dca7c221ecbb07ba8bbb2e720c6b8e354fda024d7f8087"
            data-analytics-event="{&quot;category&quot;:&quot;Marketing nav&quot;,&quot;action&quot;:&quot;click to Sign in&quot;,&quot;label&quot;:&quot;ref_page:Marketing;ref_cta:Sign in;ref_loc:Header&quot;}"
          >
            Sign in
          </a>
              <div class="AppHeader-appearanceSettings">
    <react-partial-anchor>
      <button data-target="react-partial-anchor.anchor" id="icon-button-8127f96d-bcfd-417c-a05b-2e27b4b687f5" aria-labelledby="tooltip-f2a1ef8d-96d0-4b8e-85bd-6f6a5df3e496" type="button" disabled="disabled" data-view-component="true" class="Button Button--iconOnly Button--invisible Button--medium AppHeader-button HeaderMenu-link border cursor-wait">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-sliders Button-visual">
    <path d="M15 2.75a.75.75 0 0 1-.75.75h-4a.75.75 0 0 1 0-1.5h4a.75.75 0 0 1 .75.75Zm-8.5.75v1.25a.75.75 0 0 0 1.5 0v-4a.75.75 0 0 0-1.5 0V2H1.75a.75.75 0 0 0 0 1.5H6.5Zm1.25 5.25a.75.75 0 0 0 0-1.5h-6a.75.75 0 0 0 0 1.5h6ZM15 8a.75.75 0 0 1-.75.75H11.5V10a.75.75 0 1 1-1.5 0V6a.75.75 0 0 1 1.5 0v1.25h2.75A.75.75 0 0 1 15 8Zm-9 5.25v-2a.75.75 0 0 0-1.5 0v1.25H1.75a.75.75 0 0 0 0 1.5H4.5v1.25a.75.75 0 0 0 1.5 0v-2Zm9 0a.75.75 0 0 1-.75.75h-6a.75.75 0 0 1 0-1.5h6a.75.75 0 0 1 .75.75Z"></path>
</svg>
</button><tool-tip id="tooltip-f2a1ef8d-96d0-4b8e-85bd-6f6a5df3e496" for="icon-button-8127f96d-bcfd-417c-a05b-2e27b4b687f5" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.f595f41454298e934d3c.module.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.6c63a6de228d6520804d.module.css" />

<react-partial
  partial-name="appearance-settings"
  data-ssr="false"
  data-attempted-ssr="false"
  data-react-profiling="false"
>
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>


      </template>
    </react-partial-anchor>
  </div>

      </div>
    </div>


    <div class="HeaderMenu js-header-menu height-fit position-lg-relative d-lg-flex flex-column flex-auto top-0">
      <div class="HeaderMenu-wrapper d-flex flex-column flex-self-start flex-lg-row flex-auto rounded rounded-lg-0">
            <nav class="HeaderMenu-nav" aria-label="Global">
              <ul class="d-lg-flex list-style-none">
                  <li class="HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item">
      <button type="button" class="HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target" aria-expanded="false">
        Platform
        <svg opacity="0.5" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-down HeaderMenu-icon ml-1">
    <path d="M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z"></path>
</svg>
      </button>

      <div class="HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 pt-2 pt-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 dropdown-menu-wide">
        <div class="d-lg-flex dropdown-menu-wide">
            <div class="HeaderMenu-column px-lg-4">
                <div class="">

                  <ul class="list-style-none f5" >
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_platform_navbar&quot;}" href="https://github.com/features/copilot">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-copilot color-fg-subtle mr-3">
    <path d="M23.922 16.992c-.861 1.495-5.859 5.023-11.922 5.023-6.063 0-11.061-3.528-11.922-5.023A.641.641 0 0 1 0 16.736v-2.869a.841.841 0 0 1 .053-.22c.372-.935 1.347-2.292 2.605-2.656.167-.429.414-1.055.644-1.517a10.195 10.195 0 0 1-.052-1.086c0-1.331.282-2.499 1.132-3.368.397-.406.89-.717 1.474-.952 1.399-1.136 3.392-2.093 6.122-2.093 2.731 0 4.767.957 6.166 2.093.584.235 1.077.546 1.474.952.85.869 1.132 2.037 1.132 3.368 0 .368-.014.733-.052 1.086.23.462.477 1.088.644 1.517 1.258.364 2.233 1.721 2.605 2.656a.832.832 0 0 1 .053.22v2.869a.641.641 0 0 1-.078.256ZM12.172 11h-.344a4.323 4.323 0 0 1-.355.508C10.703 12.455 9.555 13 7.965 13c-1.725 0-2.989-.359-3.782-1.259a2.005 2.005 0 0 1-.085-.104L4 11.741v6.585c1.435.779 4.514 2.179 8 2.179 3.486 0 6.565-1.4 8-2.179v-6.585l-.098-.104s-.033.045-.085.104c-.793.9-2.057 1.259-3.782 1.259-1.59 0-2.738-.545-3.508-1.492a4.323 4.323 0 0 1-.355-.508h-.016.016Zm.641-2.935c.136 1.057.403 1.913.878 2.497.442.544 1.134.938 2.344.938 1.573 0 2.292-.337 2.657-.751.384-.435.558-1.15.558-2.361 0-1.14-.243-1.847-.705-2.319-.477-.488-1.319-.862-2.824-1.025-1.487-.161-2.192.138-2.533.529-.269.307-.437.808-.438 1.578v.021c0 .265.021.562.063.893Zm-1.626 0c.042-.331.063-.628.063-.894v-.02c-.001-.77-.169-1.271-.438-1.578-.341-.391-1.046-.69-2.533-.529-1.505.163-2.347.537-2.824 1.025-.462.472-.705 1.179-.705 2.319 0 1.211.175 1.926.558 2.361.365.414 1.084.751 2.657.751 1.21 0 1.902-.394 2.344-.938.475-.584.742-1.44.878-2.497Z"></path><path d="M14.5 14.25a1 1 0 0 1 1 1v2a1 1 0 0 1-2 0v-2a1 1 0 0 1 1-1Zm-5 0a1 1 0 0 1 1 1v2a1 1 0 0 1-2 0v-2a1 1 0 0 1 1-1Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          GitHub Copilot

        </div>

        Write better code with AI
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_spark&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_spark_link_platform_navbar&quot;}" href="https://github.com/features/spark">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-sparkle-fill color-fg-subtle mr-3">
    <path d="M11.296 1.924c.24-.656 1.168-.656 1.408 0l.717 1.958a11.25 11.25 0 0 0 6.697 6.697l1.958.717c.657.24.657 1.168 0 1.408l-1.958.717a11.25 11.25 0 0 0-6.697 6.697l-.717 1.958c-.24.657-1.168.657-1.408 0l-.717-1.958a11.25 11.25 0 0 0-6.697-6.697l-1.958-.717c-.656-.24-.656-1.168 0-1.408l1.958-.717a11.25 11.25 0 0 0 6.697-6.697l.717-1.958Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          GitHub Spark

            <span class="HeaderMenu-label">
              New
            </span>
        </div>

        Build and deploy intelligent apps
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_models&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_models_link_platform_navbar&quot;}" href="https://github.com/features/models">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-ai-model color-fg-subtle mr-3">
    <path d="M19.375 8.5a3.25 3.25 0 1 1-3.163 4h-3a3.252 3.252 0 0 1-4.443 2.509L7.214 17.76a3.25 3.25 0 1 1-1.342-.674l1.672-2.957A3.238 3.238 0 0 1 6.75 12c0-.907.371-1.727.97-2.316L6.117 6.846A3.253 3.253 0 0 1 1.875 3.75a3.25 3.25 0 1 1 5.526 2.32l1.603 2.836A3.25 3.25 0 0 1 13.093 11h3.119a3.252 3.252 0 0 1 3.163-2.5ZM10 10.25a1.75 1.75 0 1 0-.001 3.499A1.75 1.75 0 0 0 10 10.25ZM5.125 2a1.75 1.75 0 1 0 0 3.5 1.75 1.75 0 0 0 0-3.5Zm12.5 9.75a1.75 1.75 0 1 0 3.5 0 1.75 1.75 0 0 0-3.5 0Zm-14.25 8.5a1.75 1.75 0 1 0 3.501-.001 1.75 1.75 0 0 0-3.501.001Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          GitHub Models

            <span class="HeaderMenu-label">
              New
            </span>
        </div>

        Manage and compare prompts
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_platform_navbar&quot;}" href="https://github.com/security/advanced-security">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-shield-check color-fg-subtle mr-3">
    <path d="M16.53 9.78a.75.75 0 0 0-1.06-1.06L11 13.19l-1.97-1.97a.75.75 0 0 0-1.06 1.06l2.5 2.5a.75.75 0 0 0 1.06 0l5-5Z"></path><path d="m12.54.637 8.25 2.675A1.75 1.75 0 0 1 22 4.976V10c0 6.19-3.771 10.704-9.401 12.83a1.704 1.704 0 0 1-1.198 0C5.77 20.705 2 16.19 2 10V4.976c0-.758.489-1.43 1.21-1.664L11.46.637a1.748 1.748 0 0 1 1.08 0Zm-.617 1.426-8.25 2.676a.249.249 0 0 0-.173.237V10c0 5.46 3.28 9.483 8.43 11.426a.199.199 0 0 0 .14 0C17.22 19.483 20.5 15.461 20.5 10V4.976a.25.25 0 0 0-.173-.237l-8.25-2.676a.253.253 0 0 0-.154 0Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          GitHub Advanced Security

        </div>

        Find and fix vulnerabilities
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_platform_navbar&quot;}" href="https://github.com/features/actions">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-workflow color-fg-subtle mr-3">
    <path d="M1 3a2 2 0 0 1 2-2h6.5a2 2 0 0 1 2 2v6.5a2 2 0 0 1-2 2H7v4.063C7 16.355 7.644 17 8.438 17H12.5v-2.5a2 2 0 0 1 2-2H21a2 2 0 0 1 2 2V21a2 2 0 0 1-2 2h-6.5a2 2 0 0 1-2-2v-2.5H8.437A2.939 2.939 0 0 1 5.5 15.562V11.5H3a2 2 0 0 1-2-2Zm2-.5a.5.5 0 0 0-.5.5v6.5a.5.5 0 0 0 .5.5h6.5a.5.5 0 0 0 .5-.5V3a.5.5 0 0 0-.5-.5ZM14.5 14a.5.5 0 0 0-.5.5V21a.5.5 0 0 0 .5.5H21a.5.5 0 0 0 .5-.5v-6.5a.5.5 0 0 0-.5-.5Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Actions

        </div>

        Automate any workflow
      </div>

    
</a></li>

                  </ul>
                </div>
            </div>
            <div class="HeaderMenu-column px-lg-4 pb-3 pb-lg-0 border-lg-right">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 pb-3">

                  <ul class="list-style-none f5" >
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_platform_navbar&quot;}" href="https://github.com/features/codespaces">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-codespaces color-fg-subtle mr-3">
    <path d="M3.5 3.75C3.5 2.784 4.284 2 5.25 2h13.5c.966 0 1.75.784 1.75 1.75v7.5A1.75 1.75 0 0 1 18.75 13H5.25a1.75 1.75 0 0 1-1.75-1.75Zm-2 12c0-.966.784-1.75 1.75-1.75h17.5c.966 0 1.75.784 1.75 1.75v4a1.75 1.75 0 0 1-1.75 1.75H3.25a1.75 1.75 0 0 1-1.75-1.75ZM5.25 3.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h13.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Zm-2 12a.25.25 0 0 0-.25.25v4c0 .138.112.25.25.25h17.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25Z"></path><path d="M10 17.75a.75.75 0 0 1 .75-.75h6.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1-.75-.75Zm-4 0a.75.75 0 0 1 .75-.75h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1-.75-.75Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Codespaces

        </div>

        Instant dev environments
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_platform_navbar&quot;}" href="https://github.com/features/issues">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-issue-opened color-fg-subtle mr-3">
    <path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1ZM2.5 12a9.5 9.5 0 0 0 9.5 9.5 9.5 9.5 0 0 0 9.5-9.5A9.5 9.5 0 0 0 12 2.5 9.5 9.5 0 0 0 2.5 12Zm9.5 2a2 2 0 1 1-.001-3.999A2 2 0 0 1 12 14Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Issues

        </div>

        Plan and track work
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_platform_navbar&quot;}" href="https://github.com/features/code-review">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-code-review color-fg-subtle mr-3">
    <path d="M10.3 6.74a.75.75 0 0 1-.04 1.06l-2.908 2.7 2.908 2.7a.75.75 0 1 1-1.02 1.1l-3.5-3.25a.75.75 0 0 1 0-1.1l3.5-3.25a.75.75 0 0 1 1.06.04Zm3.44 1.06a.75.75 0 1 1 1.02-1.1l3.5 3.25a.75.75 0 0 1 0 1.1l-3.5 3.25a.75.75 0 1 1-1.02-1.1l2.908-2.7-2.908-2.7Z"></path><path d="M1.5 4.25c0-.966.784-1.75 1.75-1.75h17.5c.966 0 1.75.784 1.75 1.75v12.5a1.75 1.75 0 0 1-1.75 1.75h-9.69l-3.573 3.573A1.458 1.458 0 0 1 5 21.043V18.5H3.25a1.75 1.75 0 0 1-1.75-1.75ZM3.25 4a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h2.5a.75.75 0 0 1 .75.75v3.19l3.72-3.72a.749.749 0 0 1 .53-.22h10a.25.25 0 0 0 .25-.25V4.25a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Code Review

        </div>

        Manage code changes
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_platform_navbar&quot;}" href="https://github.com/features/discussions">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-comment-discussion color-fg-subtle mr-3">
    <path d="M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v9.5A1.75 1.75 0 0 1 14.25 14H8.061l-2.574 2.573A1.458 1.458 0 0 1 3 15.543V14H1.75A1.75 1.75 0 0 1 0 12.25v-9.5C0 1.784.784 1 1.75 1ZM1.5 2.75v9.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-9.5a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Z"></path><path d="M22.5 8.75a.25.25 0 0 0-.25-.25h-3.5a.75.75 0 0 1 0-1.5h3.5c.966 0 1.75.784 1.75 1.75v9.5A1.75 1.75 0 0 1 22.25 20H21v1.543a1.457 1.457 0 0 1-2.487 1.03L15.939 20H10.75A1.75 1.75 0 0 1 9 18.25v-1.465a.75.75 0 0 1 1.5 0v1.465c0 .138.112.25.25.25h5.5a.75.75 0 0 1 .53.22l2.72 2.72v-2.19a.75.75 0 0 1 .75-.75h2a.25.25 0 0 0 .25-.25v-9.5Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Discussions

        </div>

        Collaborate outside of code
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_platform_navbar&quot;}" href="https://github.com/features/code-search">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-code-square color-fg-subtle mr-3">
    <path d="M10.3 8.24a.75.75 0 0 1-.04 1.06L7.352 12l2.908 2.7a.75.75 0 1 1-1.02 1.1l-3.5-3.25a.75.75 0 0 1 0-1.1l3.5-3.25a.75.75 0 0 1 1.06.04Zm3.44 1.06a.75.75 0 1 1 1.02-1.1l3.5 3.25a.75.75 0 0 1 0 1.1l-3.5 3.25a.75.75 0 1 1-1.02-1.1l2.908-2.7-2.908-2.7Z"></path><path d="M2 3.75C2 2.784 2.784 2 3.75 2h16.5c.966 0 1.75.784 1.75 1.75v16.5A1.75 1.75 0 0 1 20.25 22H3.75A1.75 1.75 0 0 1 2 20.25Zm1.75-.25a.25.25 0 0 0-.25.25v16.5c0 .138.112.25.25.25h16.5a.25.25 0 0 0 .25-.25V3.75a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Code Search

        </div>

        Find more, search less
      </div>

    
</a></li>

                  </ul>
                </div>
            </div>
            <div class="HeaderMenu-column px-lg-4">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 mb-3 pb-3">

                      <span class="d-block h4 color-fg-default my-1" id="platform-explore-heading">Explore</span>

                  <ul class="list-style-none f5" aria-labelledby="platform-explore-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;why_github&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;why_github_link_platform_navbar&quot;}" href="https://github.com/why-github">
      Why GitHub

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary Link--external" target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;documentation&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;documentation_link_platform_navbar&quot;}" href="https://docs.github.com">
      Documentation

    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle">
    <path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path>
</svg>
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary Link--external" target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_skills&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_skills_link_platform_navbar&quot;}" href="https://skills.github.com">
      GitHub Skills

    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle">
    <path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path>
</svg>
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary Link--external" target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;blog&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;blog_link_platform_navbar&quot;}" href="https://github.blog">
      Blog

    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle">
    <path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path>
</svg>
</a></li>

                  </ul>
                </div>
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 pb-3">

                      <span class="d-block h4 color-fg-default my-1" id="platform-integrations-heading">Integrations</span>

                  <ul class="list-style-none f5" aria-labelledby="platform-integrations-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_marketplace&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_marketplace_link_platform_navbar&quot;}" href="https://github.com/marketplace">
      GitHub Marketplace

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;mcp_registry&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;mcp_registry_link_platform_navbar&quot;}" href="https://github.com/mcp">
      MCP Registry

    
</a></li>

                  </ul>
                </div>
            </div>
        </div>

          <div class="HeaderMenu-trailing-link rounded-bottom-2 mt-lg-4 px-lg-4 py-4 py-lg-3 f5 text-semibold">
            <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all_features&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_features_link_platform_navbar&quot;}" href="https://github.com/features">
              View all features
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-right HeaderMenu-trailing-link-icon">
    <path d="M6.22 3.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L9.94 8 6.22 4.28a.75.75 0 0 1 0-1.06Z"></path>
</svg>
</a>          </div>
      </div>
</li>


                  <li class="HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item">
      <button type="button" class="HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target" aria-expanded="false">
        Solutions
        <svg opacity="0.5" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-down HeaderMenu-icon ml-1">
    <path d="M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z"></path>
</svg>
      </button>

      <div class="HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 pt-2 pt-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 dropdown-menu-wide">
        <div class="d-lg-flex dropdown-menu-wide">
            <div class="HeaderMenu-column px-lg-4 pb-3 pb-lg-0 border-lg-right">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 pb-3">

                      <span class="d-block h4 color-fg-default my-1" id="solutions-by-company-size-heading">By company size</span>

                  <ul class="list-style-none f5" aria-labelledby="solutions-by-company-size-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprises&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprises_link_solutions_navbar&quot;}" href="https://github.com/enterprise">
      Enterprises

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;small_and_medium_teams&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;small_and_medium_teams_link_solutions_navbar&quot;}" href="https://github.com/team">
      Small and medium teams

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;startups&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;startups_link_solutions_navbar&quot;}" href="https://github.com/enterprise/startups">
      Startups

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;nonprofits&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;nonprofits_link_solutions_navbar&quot;}" href="/solutions/industry/nonprofits">
      Nonprofits

    
</a></li>

                  </ul>
                </div>
            </div>
            <div class="HeaderMenu-column px-lg-4 pb-3 pb-lg-0 border-lg-right">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 pb-3">

                      <span class="d-block h4 color-fg-default my-1" id="solutions-by-use-case-heading">By use case</span>

                  <ul class="list-style-none f5" aria-labelledby="solutions-by-use-case-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;app_modernization&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;app_modernization_link_solutions_navbar&quot;}" href="/solutions/use-case/app-modernization">
      App Modernization

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;devsecops&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;devsecops_link_solutions_navbar&quot;}" href="/solutions/use-case/devsecops">
      DevSecOps

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;devops&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;devops_link_solutions_navbar&quot;}" href="/solutions/use-case/devops">
      DevOps

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ci_cd&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ci_cd_link_solutions_navbar&quot;}" href="/solutions/use-case/ci-cd">
      CI/CD

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all_use_cases&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_use_cases_link_solutions_navbar&quot;}" href="/solutions/use-case">
      View all use cases

    
</a></li>

                  </ul>
                </div>
            </div>
            <div class="HeaderMenu-column px-lg-4">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 pb-3">

                      <span class="d-block h4 color-fg-default my-1" id="solutions-by-industry-heading">By industry</span>

                  <ul class="list-style-none f5" aria-labelledby="solutions-by-industry-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;healthcare&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;healthcare_link_solutions_navbar&quot;}" href="/solutions/industry/healthcare">
      Healthcare

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;financial_services&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;financial_services_link_solutions_navbar&quot;}" href="/solutions/industry/financial-services">
      Financial services

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;manufacturing&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;manufacturing_link_solutions_navbar&quot;}" href="/solutions/industry/manufacturing">
      Manufacturing

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;government&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;government_link_solutions_navbar&quot;}" href="/solutions/industry/government">
      Government

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all_industries&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_industries_link_solutions_navbar&quot;}" href="/solutions/industry">
      View all industries

    
</a></li>

                  </ul>
                </div>
            </div>
        </div>

          <div class="HeaderMenu-trailing-link rounded-bottom-2 mt-lg-4 px-lg-4 py-4 py-lg-3 f5 text-semibold">
            <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all_solutions&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_solutions_link_solutions_navbar&quot;}" href="/solutions">
              View all solutions
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-right HeaderMenu-trailing-link-icon">
    <path d="M6.22 3.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L9.94 8 6.22 4.28a.75.75 0 0 1 0-1.06Z"></path>
</svg>
</a>          </div>
      </div>
</li>


                  <li class="HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item">
      <button type="button" class="HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target" aria-expanded="false">
        Resources
        <svg opacity="0.5" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-down HeaderMenu-icon ml-1">
    <path d="M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z"></path>
</svg>
      </button>

      <div class="HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 pt-2 pt-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 pb-2 pb-lg-4 dropdown-menu-wide">
        <div class="d-lg-flex dropdown-menu-wide">
            <div class="HeaderMenu-column px-lg-4 pb-3 pb-lg-0 border-lg-right">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 pb-3">

                      <span class="d-block h4 color-fg-default my-1" id="resources-topics-heading">Topics</span>

                  <ul class="list-style-none f5" aria-labelledby="resources-topics-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ai&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ai_link_resources_navbar&quot;}" href="/resources/articles?topic=ai">
      AI

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;devops&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;devops_link_resources_navbar&quot;}" href="/resources/articles?topic=devops">
      DevOps

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;security&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;security_link_resources_navbar&quot;}" href="/resources/articles?topic=security">
      Security

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;software_development&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;software_development_link_resources_navbar&quot;}" href="/resources/articles?topic=software-development">
      Software Development

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_link_resources_navbar&quot;}" href="/resources/articles">
      View all

    
</a></li>

                  </ul>
                </div>
            </div>
            <div class="HeaderMenu-column px-lg-4">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 border-bottom-0">

                      <span class="d-block h4 color-fg-default my-1" id="resources-explore-heading">Explore</span>

                  <ul class="list-style-none f5" aria-labelledby="resources-explore-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary Link--external" target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle">
    <path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path>
</svg>
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;events_amp_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;events_amp_webinars_link_resources_navbar&quot;}" href="https://github.com/resources/events">
      Events &amp; Webinars

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ebooks_amp_whitepapers&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ebooks_amp_whitepapers_link_resources_navbar&quot;}" href="https://github.com/resources/whitepapers">
      Ebooks &amp; Whitepapers

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://github.com/partners">
      Partners

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                  </ul>
                </div>
            </div>
        </div>

      </div>
</li>


                  <li class="HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item">
      <button type="button" class="HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target" aria-expanded="false">
        Open Source
        <svg opacity="0.5" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-down HeaderMenu-icon ml-1">
    <path d="M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z"></path>
</svg>
      </button>

      <div class="HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 pt-2 pt-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 pb-2 pb-lg-4">
        <div class="d-lg-flex dropdown-menu-wide">
            <div class="HeaderMenu-column px-lg-4">
                <div class="border-bottom mb-3 mb-lg-3 pb-3">

                  <ul class="list-style-none f5" >
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="/sponsors">
      
      <div>
        <div class="color-fg-default h4">
          GitHub Sponsors

        </div>

        Fund open source developers
      </div>

    
</a></li>

                  </ul>
                </div>
                <div class="border-bottom mb-3 mb-lg-3 pb-3">

                  <ul class="list-style-none f5" >
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
        <div class="color-fg-default h4">
          The ReadME Project

        </div>

        GitHub community articles
      </div>

    
</a></li>

                  </ul>
                </div>
                <div class="border-bottom border-bottom-0">

                      <span class="d-block h4 color-fg-default my-1" id="open-source-repositories-heading">Repositories</span>

                  <ul class="list-style-none f5" aria-labelledby="open-source-repositories-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;topics&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;topics_link_open_source_navbar&quot;}" href="https://github.com/topics">
      Topics

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;trending&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;trending_link_open_source_navbar&quot;}" href="https://github.com/trending">
      Trending

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;collections&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;collections_link_open_source_navbar&quot;}" href="https://github.com/collections">
      Collections

    
</a></li>

                  </ul>
                </div>
            </div>
        </div>

      </div>
</li>


                  <li class="HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item">
      <button type="button" class="HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target" aria-expanded="false">
        Enterprise
        <svg opacity="0.5" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-down HeaderMenu-icon ml-1">
    <path d="M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z"></path>
</svg>
      </button>

      <div class="HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 pt-2 pt-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 pb-2 pb-lg-4">
        <div class="d-lg-flex dropdown-menu-wide">
            <div class="HeaderMenu-column px-lg-4">
                <div class="border-bottom mb-3 mb-lg-3 pb-3">

                  <ul class="list-style-none f5" >
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="/enterprise">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-stack color-fg-subtle mr-3">
    <path d="M11.063 1.456a1.749 1.749 0 0 1 1.874 0l8.383 5.316a1.751 1.751 0 0 1 0 2.956l-8.383 5.316a1.749 1.749 0 0 1-1.874 0L2.68 9.728a1.751 1.751 0 0 1 0-2.956Zm1.071 1.267a.25.25 0 0 0-.268 0L3.483 8.039a.25.25 0 0 0 0 .422l8.383 5.316a.25.25 0 0 0 .268 0l8.383-5.316a.25.25 0 0 0 0-.422Z"></path><path d="M1.867 12.324a.75.75 0 0 1 1.035-.232l8.964 5.685a.25.25 0 0 0 .268 0l8.964-5.685a.75.75 0 0 1 .804 1.267l-8.965 5.685a1.749 1.749 0 0 1-1.874 0l-8.965-5.685a.75.75 0 0 1-.231-1.035Z"></path><path d="M1.867 16.324a.75.75 0 0 1 1.035-.232l8.964 5.685a.25.25 0 0 0 .268 0l8.964-5.685a.75.75 0 0 1 .804 1.267l-8.965 5.685a1.749 1.749 0 0 1-1.874 0l-8.965-5.685a.75.75 0 0 1-.231-1.035Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Enterprise platform

        </div>

        AI-powered developer platform
      </div>

    
</a></li>

                  </ul>
                </div>
                <div class="border-bottom border-bottom-0">

                      <span class="d-block h4 color-fg-default my-1" id="enterprise-available-add-ons-heading">Available add-ons</span>

                  <ul class="list-style-none f5" aria-labelledby="enterprise-available-add-ons-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_enterprise_navbar&quot;}" href="https://github.com/security/advanced-security">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-shield-check color-fg-subtle mr-3">
    <path d="M16.53 9.78a.75.75 0 0 0-1.06-1.06L11 13.19l-1.97-1.97a.75.75 0 0 0-1.06 1.06l2.5 2.5a.75.75 0 0 0 1.06 0l5-5Z"></path><path d="m12.54.637 8.25 2.675A1.75 1.75 0 0 1 22 4.976V10c0 6.19-3.771 10.704-9.401 12.83a1.704 1.704 0 0 1-1.198 0C5.77 20.705 2 16.19 2 10V4.976c0-.758.489-1.43 1.21-1.664L11.46.637a1.748 1.748 0 0 1 1.08 0Zm-.617 1.426-8.25 2.676a.249.249 0 0 0-.173.237V10c0 5.46 3.28 9.483 8.43 11.426a.199.199 0 0 0 .14 0C17.22 19.483 20.5 15.461 20.5 10V4.976a.25.25 0 0 0-.173-.237l-8.25-2.676a.253.253 0 0 0-.154 0Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          GitHub Advanced Security

        </div>

        Enterprise-grade security features
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;copilot_for_business&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;copilot_for_business_link_enterprise_navbar&quot;}" href="/features/copilot/copilot-business">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-copilot color-fg-subtle mr-3">
    <path d="M23.922 16.992c-.861 1.495-5.859 5.023-11.922 5.023-6.063 0-11.061-3.528-11.922-5.023A.641.641 0 0 1 0 16.736v-2.869a.841.841 0 0 1 .053-.22c.372-.935 1.347-2.292 2.605-2.656.167-.429.414-1.055.644-1.517a10.195 10.195 0 0 1-.052-1.086c0-1.331.282-2.499 1.132-3.368.397-.406.89-.717 1.474-.952 1.399-1.136 3.392-2.093 6.122-2.093 2.731 0 4.767.957 6.166 2.093.584.235 1.077.546 1.474.952.85.869 1.132 2.037 1.132 3.368 0 .368-.014.733-.052 1.086.23.462.477 1.088.644 1.517 1.258.364 2.233 1.721 2.605 2.656a.832.832 0 0 1 .053.22v2.869a.641.641 0 0 1-.078.256ZM12.172 11h-.344a4.323 4.323 0 0 1-.355.508C10.703 12.455 9.555 13 7.965 13c-1.725 0-2.989-.359-3.782-1.259a2.005 2.005 0 0 1-.085-.104L4 11.741v6.585c1.435.779 4.514 2.179 8 2.179 3.486 0 6.565-1.4 8-2.179v-6.585l-.098-.104s-.033.045-.085.104c-.793.9-2.057 1.259-3.782 1.259-1.59 0-2.738-.545-3.508-1.492a4.323 4.323 0 0 1-.355-.508h-.016.016Zm.641-2.935c.136 1.057.403 1.913.878 2.497.442.544 1.134.938 2.344.938 1.573 0 2.292-.337 2.657-.751.384-.435.558-1.15.558-2.361 0-1.14-.243-1.847-.705-2.319-.477-.488-1.319-.862-2.824-1.025-1.487-.161-2.192.138-2.533.529-.269.307-.437.808-.438 1.578v.021c0 .265.021.562.063.893Zm-1.626 0c.042-.331.063-.628.063-.894v-.02c-.001-.77-.169-1.271-.438-1.578-.341-.391-1.046-.69-2.533-.529-1.505.163-2.347.537-2.824 1.025-.462.472-.705 1.179-.705 2.319 0 1.211.175 1.926.558 2.361.365.414 1.084.751 2.657.751 1.21 0 1.902-.394 2.344-.938.475-.584.742-1.44.878-2.497Z"></path><path d="M14.5 14.25a1 1 0 0 1 1 1v2a1 1 0 0 1-2 0v-2a1 1 0 0 1 1-1Zm-5 0a1 1 0 0 1 1 1v2a1 1 0 0 1-2 0v-2a1 1 0 0 1 1-1Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Copilot for business

        </div>

        Enterprise-grade AI features
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;premium_support&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;premium_support_link_enterprise_navbar&quot;}" href="/premium-support">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-comment-discussion color-fg-subtle mr-3">
    <path d="M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v9.5A1.75 1.75 0 0 1 14.25 14H8.061l-2.574 2.573A1.458 1.458 0 0 1 3 15.543V14H1.75A1.75 1.75 0 0 1 0 12.25v-9.5C0 1.784.784 1 1.75 1ZM1.5 2.75v9.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-9.5a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Z"></path><path d="M22.5 8.75a.25.25 0 0 0-.25-.25h-3.5a.75.75 0 0 1 0-1.5h3.5c.966 0 1.75.784 1.75 1.75v9.5A1.75 1.75 0 0 1 22.25 20H21v1.543a1.457 1.457 0 0 1-2.487 1.03L15.939 20H10.75A1.75 1.75 0 0 1 9 18.25v-1.465a.75.75 0 0 1 1.5 0v1.465c0 .138.112.25.25.25h5.5a.75.75 0 0 1 .53.22l2.72 2.72v-2.19a.75.75 0 0 1 .75-.75h2a.25.25 0 0 0 .25-.25v-9.5Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Premium Support

        </div>

        Enterprise-grade 24/7 support
      </div>

    
</a></li>

                  </ul>
                </div>
            </div>
        </div>

      </div>
</li>


                  <li class="HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item">
    <a class="HeaderMenu-link no-underline px-0 px-lg-2 py-3 py-lg-2 d-block d-lg-inline-block" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;platform&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;platform_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

              </ul>
            </nav>

        <div class="d-flex flex-column flex-lg-row width-full flex-justify-end flex-lg-items-center text-center mt-3 mt-lg-0 text-lg-left ml-lg-3">
                


<qbsearch-input class="search-input" data-scope="repo:coderonion/awesome-yolo-object-detection" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="yF9D9nowakYSBfHXKQDeErtfylK2HB4LICcFgM52zzjkM19wpdvwJXrT4e7gnluHtjUn0nPRawiHKjhSjBZ_1A" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="coderonion/awesome-yolo-object-detection" data-current-org="" data-current-owner="coderonion" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div
    class="search-input-container search-with-dialog position-relative d-flex flex-row flex-items-center mr-4 rounded"
    data-action="click:qbsearch-input#searchInputContainerClicked"
  >
      <button
        type="button"
        class="header-search-button placeholder  input-button form-control d-flex flex-1 flex-self-stretch flex-items-center no-wrap width-full py-0 pl-2 pr-0 text-left border-0 box-shadow-none"
        data-target="qbsearch-input.inputButton"
        aria-label="Search or jump to…"
        aria-haspopup="dialog"
        placeholder="Search or jump to..."
        data-hotkey=s,/
        autocapitalize="off"
        data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;searchbar&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;input&quot;,&quot;label&quot;:&quot;searchbar_input_global_navbar&quot;}"
        data-action="click:qbsearch-input#handleExpand"
      >
        <div class="mr-2 color-fg-muted">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-search">
    <path d="M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z"></path>
</svg>
        </div>
        <span class="flex-1" data-target="qbsearch-input.inputButtonText">Search or jump to...</span>
          <div class="d-flex" data-target="qbsearch-input.hotkeyIndicator">
            <svg xmlns="http://www.w3.org/2000/svg" width="22" height="20" aria-hidden="true" class="mr-1"><path fill="none" stroke="#979A9C" opacity=".4" d="M3.5.5h12c1.7 0 3 1.3 3 3v13c0 1.7-1.3 3-3 3h-12c-1.7 0-3-1.3-3-3v-13c0-1.7 1.3-3 3-3z"></path><path fill="#979A9C" d="M11.8 6L8 15.1h-.9L10.8 6h1z"></path></svg>
          </div>
      </button>

    <input type="hidden" name="type" class="js-site-search-type-field">

    
<div class="Overlay--hidden " data-modal-dialog-overlay>
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true" class="Overlay Overlay--width-large Overlay--height-auto">
      <h1 id="search-suggestions-dialog-header" class="sr-only">Search code, repositories, users, issues, pull requests...</h1>
    <div class="Overlay-body Overlay-body--paddingNone">
      
          <div data-view-component="true">        <div class="search-suggestions position-fixed width-full color-shadow-large border color-fg-default color-bg-default overflow-hidden d-flex flex-column query-builder-container"
          style="border-radius: 12px;"
          data-target="qbsearch-input.queryBuilderContainer"
          hidden
        >
          <!-- '"` --><!-- </textarea></xmp> --></option></form><form id="query-builder-test-form" action="" accept-charset="UTF-8" method="get">
  <query-builder data-target="qbsearch-input.queryBuilder" id="query-builder-query-builder-test" data-filter-key=":" data-view-component="true" class="QueryBuilder search-query-builder">
    <div class="FormControl FormControl--fullWidth">
      <label id="query-builder-test-label" for="query-builder-test" class="FormControl-label sr-only">
        Search
      </label>
      <div
        class="QueryBuilder-StyledInput width-fit "
        data-target="query-builder.styledInput"
      >
          <span id="query-builder-test-leadingvisual-wrap" class="FormControl-input-leadingVisualWrap QueryBuilder-leadingVisualWrap">
            <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-search FormControl-input-leadingVisual">
    <path d="M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z"></path>
</svg>
          </span>
        <div data-target="query-builder.styledInputContainer" class="QueryBuilder-StyledInputContainer">
          <div
            aria-hidden="true"
            class="QueryBuilder-StyledInputContent"
            data-target="query-builder.styledInputContent"
          ></div>
          <div class="QueryBuilder-InputWrapper">
            <div aria-hidden="true" class="QueryBuilder-Sizer" data-target="query-builder.sizer"></div>
            <input id="query-builder-test" name="query-builder-test" value="" autocomplete="off" type="text" role="combobox" spellcheck="false" aria-expanded="false" aria-describedby="validation-86f16a7a-2220-4d89-837f-82d3aaaa493e" data-target="query-builder.input" data-action="
          input:query-builder#inputChange
          blur:query-builder#inputBlur
          keydown:query-builder#inputKeydown
          focus:query-builder#inputFocus
        " data-view-component="true" class="FormControl-input QueryBuilder-Input FormControl-medium" />
          </div>
        </div>
          <span class="sr-only" id="query-builder-test-clear">Clear</span>
          <button role="button" id="query-builder-test-clear-button" aria-labelledby="query-builder-test-clear query-builder-test-label" data-target="query-builder.clearButton" data-action="
                click:query-builder#clear
                focus:query-builder#clearButtonFocus
                blur:query-builder#clearButtonBlur
              " variant="small" hidden="hidden" type="button" data-view-component="true" class="Button Button--iconOnly Button--invisible Button--medium mr-1 px-2 py-0 d-flex flex-items-center rounded-1 color-fg-muted">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x-circle-fill Button-visual">
    <path d="M2.343 13.657A8 8 0 1 1 13.658 2.343 8 8 0 0 1 2.343 13.657ZM6.03 4.97a.751.751 0 0 0-1.042.018.751.751 0 0 0-.018 1.042L6.94 8 4.97 9.97a.749.749 0 0 0 .326 1.275.749.749 0 0 0 .734-.215L8 9.06l1.97 1.97a.749.749 0 0 0 1.275-.326.749.749 0 0 0-.215-.734L9.06 8l1.97-1.97a.749.749 0 0 0-.326-1.275.749.749 0 0 0-.734.215L8 6.94Z"></path>
</svg>
</button>

      </div>
      <template id="search-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-search">
    <path d="M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z"></path>
</svg>
</template>

<template id="code-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-code">
    <path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path>
</svg>
</template>

<template id="file-code-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-file-code">
    <path d="M4 1.75C4 .784 4.784 0 5.75 0h5.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v8.586A1.75 1.75 0 0 1 14.25 15h-9a.75.75 0 0 1 0-1.5h9a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 10 4.25V1.5H5.75a.25.25 0 0 0-.25.25v2.5a.75.75 0 0 1-1.5 0Zm1.72 4.97a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734l1.47-1.47-1.47-1.47a.75.75 0 0 1 0-1.06ZM3.28 7.78 1.81 9.25l1.47 1.47a.751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Zm8.22-6.218V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path>
</svg>
</template>

<template id="history-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-history">
    <path d="m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z"></path>
</svg>
</template>

<template id="repo-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo">
    <path d="M2 2.5A2.5 2.5 0 0 1 4.5 0h8.75a.75.75 0 0 1 .75.75v12.5a.75.75 0 0 1-.75.75h-2.5a.75.75 0 0 1 0-1.5h1.75v-2h-8a1 1 0 0 0-.714 1.7.75.75 0 1 1-1.072 1.05A2.495 2.495 0 0 1 2 11.5Zm10.5-1h-8a1 1 0 0 0-1 1v6.708A2.486 2.486 0 0 1 4.5 9h8ZM5 12.25a.25.25 0 0 1 .25-.25h3.5a.25.25 0 0 1 .25.25v3.25a.25.25 0 0 1-.4.2l-1.45-1.087a.249.249 0 0 0-.3 0L5.4 15.7a.25.25 0 0 1-.4-.2Z"></path>
</svg>
</template>

<template id="bookmark-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-bookmark">
    <path d="M3 2.75C3 1.784 3.784 1 4.75 1h6.5c.966 0 1.75.784 1.75 1.75v11.5a.75.75 0 0 1-1.227.579L8 11.722l-3.773 3.107A.751.751 0 0 1 3 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v9.91l3.023-2.489a.75.75 0 0 1 .954 0l3.023 2.49V2.75a.25.25 0 0 0-.25-.25Z"></path>
</svg>
</template>

<template id="plus-circle-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-plus-circle">
    <path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm7.25-3.25v2.5h2.5a.75.75 0 0 1 0 1.5h-2.5v2.5a.75.75 0 0 1-1.5 0v-2.5h-2.5a.75.75 0 0 1 0-1.5h2.5v-2.5a.75.75 0 0 1 1.5 0Z"></path>
</svg>
</template>

<template id="circle-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-dot-fill">
    <path d="M8 4a4 4 0 1 1 0 8 4 4 0 0 1 0-8Z"></path>
</svg>
</template>

<template id="trash-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-trash">
    <path d="M11 1.75V3h2.25a.75.75 0 0 1 0 1.5H2.75a.75.75 0 0 1 0-1.5H5V1.75C5 .784 5.784 0 6.75 0h2.5C10.216 0 11 .784 11 1.75ZM4.496 6.675l.66 6.6a.25.25 0 0 0 .249.225h5.19a.25.25 0 0 0 .249-.225l.66-6.6a.75.75 0 0 1 1.492.149l-.66 6.6A1.748 1.748 0 0 1 10.595 15h-5.19a1.75 1.75 0 0 1-1.741-1.575l-.66-6.6a.75.75 0 1 1 1.492-.15ZM6.5 1.75V3h3V1.75a.25.25 0 0 0-.25-.25h-2.5a.25.25 0 0 0-.25.25Z"></path>
</svg>
</template>

<template id="team-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-people">
    <path d="M2 5.5a3.5 3.5 0 1 1 5.898 2.549 5.508 5.508 0 0 1 3.034 4.084.75.75 0 1 1-1.482.235 4 4 0 0 0-7.9 0 .75.75 0 0 1-1.482-.236A5.507 5.507 0 0 1 3.102 8.05 3.493 3.493 0 0 1 2 5.5ZM11 4a3.001 3.001 0 0 1 2.22 5.018 5.01 5.01 0 0 1 2.56 3.012.749.749 0 0 1-.885.954.752.752 0 0 1-.549-.514 3.507 3.507 0 0 0-2.522-2.372.75.75 0 0 1-.574-.73v-.352a.75.75 0 0 1 .416-.672A1.5 1.5 0 0 0 11 5.5.75.75 0 0 1 11 4Zm-5.5-.5a2 2 0 1 0-.001 3.999A2 2 0 0 0 5.5 3.5Z"></path>
</svg>
</template>

<template id="project-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-project">
    <path d="M1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25V1.75C0 .784.784 0 1.75 0ZM1.5 1.75v12.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25ZM11.75 3a.75.75 0 0 1 .75.75v7.5a.75.75 0 0 1-1.5 0v-7.5a.75.75 0 0 1 .75-.75Zm-8.25.75a.75.75 0 0 1 1.5 0v5.5a.75.75 0 0 1-1.5 0ZM8 3a.75.75 0 0 1 .75.75v3.5a.75.75 0 0 1-1.5 0v-3.5A.75.75 0 0 1 8 3Z"></path>
</svg>
</template>

<template id="pencil-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-pencil">
    <path d="M11.013 1.427a1.75 1.75 0 0 1 2.474 0l1.086 1.086a1.75 1.75 0 0 1 0 2.474l-8.61 8.61c-.21.21-.47.364-.756.445l-3.251.93a.75.75 0 0 1-.927-.928l.929-3.25c.081-.286.235-.547.445-.758l8.61-8.61Zm.176 4.823L9.75 4.81l-6.286 6.287a.253.253 0 0 0-.064.108l-.558 1.953 1.953-.558a.253.253 0 0 0 .108-.064Zm1.238-3.763a.25.25 0 0 0-.354 0L10.811 3.75l1.439 1.44 1.263-1.263a.25.25 0 0 0 0-.354Z"></path>
</svg>
</template>

<template id="copilot-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copilot">
    <path d="M7.998 15.035c-4.562 0-7.873-2.914-7.998-3.749V9.338c.085-.628.677-1.686 1.588-2.065.013-.07.024-.143.036-.218.029-.183.06-.384.126-.612-.201-.508-.254-1.084-.254-1.656 0-.87.128-1.769.693-2.484.579-.733 1.494-1.124 2.724-1.261 1.206-.134 2.262.034 2.944.765.05.053.096.108.139.165.044-.057.094-.112.143-.165.682-.731 1.738-.899 2.944-.765 1.23.137 2.145.528 2.724 1.261.566.715.693 1.614.693 2.484 0 .572-.053 1.148-.254 1.656.066.228.098.429.126.612.012.076.024.148.037.218.924.385 1.522 1.471 1.591 2.095v1.872c0 .766-3.351 3.795-8.002 3.795Zm0-1.485c2.28 0 4.584-1.11 5.002-1.433V7.862l-.023-.116c-.49.21-1.075.291-1.727.291-1.146 0-2.059-.327-2.71-.991A3.222 3.222 0 0 1 8 6.303a3.24 3.24 0 0 1-.544.743c-.65.664-1.563.991-2.71.991-.652 0-1.236-.081-1.727-.291l-.023.116v4.255c.419.323 2.722 1.433 5.002 1.433ZM6.762 2.83c-.193-.206-.637-.413-1.682-.297-1.019.113-1.479.404-1.713.7-.247.312-.369.789-.369 1.554 0 .793.129 1.171.308 1.371.162.181.519.379 1.442.379.853 0 1.339-.235 1.638-.54.315-.322.527-.827.617-1.553.117-.935-.037-1.395-.241-1.614Zm4.155-.297c-1.044-.116-1.488.091-1.681.297-.204.219-.359.679-.242 1.614.091.726.303 1.231.618 1.553.299.305.784.54 1.638.54.922 0 1.28-.198 1.442-.379.179-.2.308-.578.308-1.371 0-.765-.123-1.242-.37-1.554-.233-.296-.693-.587-1.713-.7Z"></path><path d="M6.25 9.037a.75.75 0 0 1 .75.75v1.501a.75.75 0 0 1-1.5 0V9.787a.75.75 0 0 1 .75-.75Zm4.25.75v1.501a.75.75 0 0 1-1.5 0V9.787a.75.75 0 0 1 1.5 0Z"></path>
</svg>
</template>

<template id="copilot-error-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copilot-error">
    <path d="M16 11.24c0 .112-.072.274-.21.467L13 9.688V7.862l-.023-.116c-.49.21-1.075.291-1.727.291-.198 0-.388-.009-.571-.029L6.833 5.226a4.01 4.01 0 0 0 .17-.782c.117-.935-.037-1.395-.241-1.614-.193-.206-.637-.413-1.682-.297-.683.076-1.115.231-1.395.415l-1.257-.91c.579-.564 1.413-.877 2.485-.996 1.206-.134 2.262.034 2.944.765.05.053.096.108.139.165.044-.057.094-.112.143-.165.682-.731 1.738-.899 2.944-.765 1.23.137 2.145.528 2.724 1.261.566.715.693 1.614.693 2.484 0 .572-.053 1.148-.254 1.656.066.228.098.429.126.612.012.076.024.148.037.218.924.385 1.522 1.471 1.591 2.095Zm-5.083-8.707c-1.044-.116-1.488.091-1.681.297-.204.219-.359.679-.242 1.614.091.726.303 1.231.618 1.553.299.305.784.54 1.638.54.922 0 1.28-.198 1.442-.379.179-.2.308-.578.308-1.371 0-.765-.123-1.242-.37-1.554-.233-.296-.693-.587-1.713-.7Zm2.511 11.074c-1.393.776-3.272 1.428-5.43 1.428-4.562 0-7.873-2.914-7.998-3.749V9.338c.085-.628.677-1.686 1.588-2.065.013-.07.024-.143.036-.218.029-.183.06-.384.126-.612-.18-.455-.241-.963-.252-1.475L.31 4.107A.747.747 0 0 1 0 3.509V3.49a.748.748 0 0 1 .625-.73c.156-.026.306.047.435.139l14.667 10.578a.592.592 0 0 1 .227.264.752.752 0 0 1 .046.249v.022a.75.75 0 0 1-1.19.596Zm-1.367-.991L5.635 7.964a5.128 5.128 0 0 1-.889.073c-.652 0-1.236-.081-1.727-.291l-.023.116v4.255c.419.323 2.722 1.433 5.002 1.433 1.539 0 3.089-.505 4.063-.934Z"></path>
</svg>
</template>

<template id="workflow-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-workflow">
    <path d="M0 1.75C0 .784.784 0 1.75 0h3.5C6.216 0 7 .784 7 1.75v3.5A1.75 1.75 0 0 1 5.25 7H4v4a1 1 0 0 0 1 1h4v-1.25C9 9.784 9.784 9 10.75 9h3.5c.966 0 1.75.784 1.75 1.75v3.5A1.75 1.75 0 0 1 14.25 16h-3.5A1.75 1.75 0 0 1 9 14.25v-.75H5A2.5 2.5 0 0 1 2.5 11V7h-.75A1.75 1.75 0 0 1 0 5.25Zm1.75-.25a.25.25 0 0 0-.25.25v3.5c0 .138.112.25.25.25h3.5a.25.25 0 0 0 .25-.25v-3.5a.25.25 0 0 0-.25-.25Zm9 9a.25.25 0 0 0-.25.25v3.5c0 .138.112.25.25.25h3.5a.25.25 0 0 0 .25-.25v-3.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
</template>

<template id="book-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-book">
    <path d="M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z"></path>
</svg>
</template>

<template id="code-review-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-code-review">
    <path d="M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 13H8.061l-2.574 2.573A1.458 1.458 0 0 1 3 14.543V13H1.75A1.75 1.75 0 0 1 0 11.25v-8.5C0 1.784.784 1 1.75 1ZM1.5 2.75v8.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-8.5a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Zm5.28 1.72a.75.75 0 0 1 0 1.06L5.31 7l1.47 1.47a.751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.75.75 0 0 1 1.06 0Zm2.44 0a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L10.69 7 9.22 5.53a.75.75 0 0 1 0-1.06Z"></path>
</svg>
</template>

<template id="codespaces-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-codespaces">
    <path d="M0 11.25c0-.966.784-1.75 1.75-1.75h12.5c.966 0 1.75.784 1.75 1.75v3A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25Zm2-9.5C2 .784 2.784 0 3.75 0h8.5C13.216 0 14 .784 14 1.75v5a1.75 1.75 0 0 1-1.75 1.75h-8.5A1.75 1.75 0 0 1 2 6.75Zm1.75-.25a.25.25 0 0 0-.25.25v5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-5a.25.25 0 0 0-.25-.25Zm-2 9.5a.25.25 0 0 0-.25.25v3c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-3a.25.25 0 0 0-.25-.25Z"></path><path d="M7 12.75a.75.75 0 0 1 .75-.75h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1-.75-.75Zm-4 0a.75.75 0 0 1 .75-.75h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1-.75-.75Z"></path>
</svg>
</template>

<template id="comment-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-comment">
    <path d="M1 2.75C1 1.784 1.784 1 2.75 1h10.5c.966 0 1.75.784 1.75 1.75v7.5A1.75 1.75 0 0 1 13.25 12H9.06l-2.573 2.573A1.458 1.458 0 0 1 4 13.543V12H2.75A1.75 1.75 0 0 1 1 10.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h4.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
</template>

<template id="comment-discussion-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-comment-discussion">
    <path d="M1.75 1h8.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 10.25 10H7.061l-2.574 2.573A1.458 1.458 0 0 1 2 11.543V10h-.25A1.75 1.75 0 0 1 0 8.25v-5.5C0 1.784.784 1 1.75 1ZM1.5 2.75v5.5c0 .138.112.25.25.25h1a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h3.5a.25.25 0 0 0 .25-.25v-5.5a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25Zm13 2a.25.25 0 0 0-.25-.25h-.5a.75.75 0 0 1 0-1.5h.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 14.25 12H14v1.543a1.458 1.458 0 0 1-2.487 1.03L9.22 12.28a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215l2.22 2.22v-2.19a.75.75 0 0 1 .75-.75h1a.25.25 0 0 0 .25-.25Z"></path>
</svg>
</template>

<template id="organization-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-organization">
    <path d="M1.75 16A1.75 1.75 0 0 1 0 14.25V1.75C0 .784.784 0 1.75 0h8.5C11.216 0 12 .784 12 1.75v12.5c0 .085-.006.168-.018.25h2.268a.25.25 0 0 0 .25-.25V8.285a.25.25 0 0 0-.111-.208l-1.055-.703a.749.749 0 1 1 .832-1.248l1.055.703c.487.325.779.871.779 1.456v5.965A1.75 1.75 0 0 1 14.25 16h-3.5a.766.766 0 0 1-.197-.026c-.099.017-.2.026-.303.026h-3a.75.75 0 0 1-.75-.75V14h-1v1.25a.75.75 0 0 1-.75.75Zm-.25-1.75c0 .138.112.25.25.25H4v-1.25a.75.75 0 0 1 .75-.75h2.5a.75.75 0 0 1 .75.75v1.25h2.25a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25ZM3.75 6h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5ZM3 3.75A.75.75 0 0 1 3.75 3h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 3.75Zm4 3A.75.75 0 0 1 7.75 6h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 7 6.75ZM7.75 3h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5ZM3 9.75A.75.75 0 0 1 3.75 9h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 9.75ZM7.75 9h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5Z"></path>
</svg>
</template>

<template id="rocket-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-rocket">
    <path d="M14.064 0h.186C15.216 0 16 .784 16 1.75v.186a8.752 8.752 0 0 1-2.564 6.186l-.458.459c-.314.314-.641.616-.979.904v3.207c0 .608-.315 1.172-.833 1.49l-2.774 1.707a.749.749 0 0 1-1.11-.418l-.954-3.102a1.214 1.214 0 0 1-.145-.125L3.754 9.816a1.218 1.218 0 0 1-.124-.145L.528 8.717a.749.749 0 0 1-.418-1.11l1.71-2.774A1.748 1.748 0 0 1 3.31 4h3.204c.288-.338.59-.665.904-.979l.459-.458A8.749 8.749 0 0 1 14.064 0ZM8.938 3.623h-.002l-.458.458c-.76.76-1.437 1.598-2.02 2.5l-1.5 2.317 2.143 2.143 2.317-1.5c.902-.583 1.74-1.26 2.499-2.02l.459-.458a7.25 7.25 0 0 0 2.123-5.127V1.75a.25.25 0 0 0-.25-.25h-.186a7.249 7.249 0 0 0-5.125 2.123ZM3.56 14.56c-.732.732-2.334 1.045-3.005 1.148a.234.234 0 0 1-.201-.064.234.234 0 0 1-.064-.201c.103-.671.416-2.273 1.15-3.003a1.502 1.502 0 1 1 2.12 2.12Zm6.94-3.935c-.088.06-.177.118-.266.175l-2.35 1.521.548 1.783 1.949-1.2a.25.25 0 0 0 .119-.213ZM3.678 8.116 5.2 5.766c.058-.09.117-.178.176-.266H3.309a.25.25 0 0 0-.213.119l-1.2 1.95ZM12 5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
</template>

<template id="shield-check-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-shield-check">
    <path d="m8.533.133 5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667l5.25-1.68a1.748 1.748 0 0 1 1.066 0Zm-.61 1.429.001.001-5.25 1.68a.251.251 0 0 0-.174.237V7c0 1.36.275 2.666 1.057 3.859.784 1.194 2.121 2.342 4.366 3.298a.196.196 0 0 0 .154 0c2.245-.957 3.582-2.103 4.366-3.297C13.225 9.666 13.5 8.358 13.5 7V3.48a.25.25 0 0 0-.174-.238l-5.25-1.68a.25.25 0 0 0-.153 0ZM11.28 6.28l-3.5 3.5a.75.75 0 0 1-1.06 0l-1.5-1.5a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215l.97.97 2.97-2.97a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z"></path>
</svg>
</template>

<template id="heart-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-heart">
    <path d="m8 14.25.345.666a.75.75 0 0 1-.69 0l-.008-.004-.018-.01a7.152 7.152 0 0 1-.31-.17 22.055 22.055 0 0 1-3.434-2.414C2.045 10.731 0 8.35 0 5.5 0 2.836 2.086 1 4.25 1 5.797 1 7.153 1.802 8 3.02 8.847 1.802 10.203 1 11.75 1 13.914 1 16 2.836 16 5.5c0 2.85-2.045 5.231-3.885 6.818a22.066 22.066 0 0 1-3.744 2.584l-.018.01-.006.003h-.002ZM4.25 2.5c-1.336 0-2.75 1.164-2.75 3 0 2.15 1.58 4.144 3.365 5.682A20.58 20.58 0 0 0 8 13.393a20.58 20.58 0 0 0 3.135-2.211C12.92 9.644 14.5 7.65 14.5 5.5c0-1.836-1.414-3-2.75-3-1.373 0-2.609.986-3.029 2.456a.749.749 0 0 1-1.442 0C6.859 3.486 5.623 2.5 4.25 2.5Z"></path>
</svg>
</template>

<template id="server-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-server">
    <path d="M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v4c0 .372-.116.717-.314 1 .198.283.314.628.314 1v4a1.75 1.75 0 0 1-1.75 1.75H1.75A1.75 1.75 0 0 1 0 12.75v-4c0-.358.109-.707.314-1a1.739 1.739 0 0 1-.314-1v-4C0 1.784.784 1 1.75 1ZM1.5 2.75v4c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Zm.25 5.75a.25.25 0 0 0-.25.25v4c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25ZM7 4.75A.75.75 0 0 1 7.75 4h4.5a.75.75 0 0 1 0 1.5h-4.5A.75.75 0 0 1 7 4.75ZM7.75 10h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5ZM3 4.75A.75.75 0 0 1 3.75 4h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 4.75ZM3.75 10h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5Z"></path>
</svg>
</template>

<template id="globe-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-globe">
    <path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM5.78 8.75a9.64 9.64 0 0 0 1.363 4.177c.255.426.542.832.857 1.215.245-.296.551-.705.857-1.215A9.64 9.64 0 0 0 10.22 8.75Zm4.44-1.5a9.64 9.64 0 0 0-1.363-4.177c-.307-.51-.612-.919-.857-1.215a9.927 9.927 0 0 0-.857 1.215A9.64 9.64 0 0 0 5.78 7.25Zm-5.944 1.5H1.543a6.507 6.507 0 0 0 4.666 5.5c-.123-.181-.24-.365-.352-.552-.715-1.192-1.437-2.874-1.581-4.948Zm-2.733-1.5h2.733c.144-2.074.866-3.756 1.58-4.948.12-.197.237-.381.353-.552a6.507 6.507 0 0 0-4.666 5.5Zm10.181 1.5c-.144 2.074-.866 3.756-1.58 4.948-.12.197-.237.381-.353.552a6.507 6.507 0 0 0 4.666-5.5Zm2.733-1.5a6.507 6.507 0 0 0-4.666-5.5c.123.181.24.365.353.552.714 1.192 1.436 2.874 1.58 4.948Z"></path>
</svg>
</template>

<template id="issue-opened-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-issue-opened">
    <path d="M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z"></path>
</svg>
</template>

<template id="device-mobile-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-device-mobile">
    <path d="M3.75 0h8.5C13.216 0 14 .784 14 1.75v12.5A1.75 1.75 0 0 1 12.25 16h-8.5A1.75 1.75 0 0 1 2 14.25V1.75C2 .784 2.784 0 3.75 0ZM3.5 1.75v12.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25ZM8 13a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path>
</svg>
</template>

<template id="package-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-package">
    <path d="m8.878.392 5.25 3.045c.54.314.872.89.872 1.514v6.098a1.75 1.75 0 0 1-.872 1.514l-5.25 3.045a1.75 1.75 0 0 1-1.756 0l-5.25-3.045A1.75 1.75 0 0 1 1 11.049V4.951c0-.624.332-1.201.872-1.514L7.122.392a1.75 1.75 0 0 1 1.756 0ZM7.875 1.69l-4.63 2.685L8 7.133l4.755-2.758-4.63-2.685a.248.248 0 0 0-.25 0ZM2.5 5.677v5.372c0 .09.047.171.125.216l4.625 2.683V8.432Zm6.25 8.271 4.625-2.683a.25.25 0 0 0 .125-.216V5.677L8.75 8.432Z"></path>
</svg>
</template>

<template id="credit-card-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-credit-card">
    <path d="M10.75 9a.75.75 0 0 0 0 1.5h1.5a.75.75 0 0 0 0-1.5h-1.5Z"></path><path d="M0 3.75C0 2.784.784 2 1.75 2h12.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 14H1.75A1.75 1.75 0 0 1 0 12.25ZM14.5 6.5h-13v5.75c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25Zm0-2.75a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25V5h13Z"></path>
</svg>
</template>

<template id="play-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-play">
    <path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z"></path>
</svg>
</template>

<template id="gift-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-gift">
    <path d="M2 2.75A2.75 2.75 0 0 1 4.75 0c.983 0 1.873.42 2.57 1.232.268.318.497.668.68 1.042.183-.375.411-.725.68-1.044C9.376.42 10.266 0 11.25 0a2.75 2.75 0 0 1 2.45 4h.55c.966 0 1.75.784 1.75 1.75v2c0 .698-.409 1.301-1 1.582v4.918A1.75 1.75 0 0 1 13.25 16H2.75A1.75 1.75 0 0 1 1 14.25V9.332C.409 9.05 0 8.448 0 7.75v-2C0 4.784.784 4 1.75 4h.55c-.192-.375-.3-.8-.3-1.25ZM7.25 9.5H2.5v4.75c0 .138.112.25.25.25h4.5Zm1.5 0v5h4.5a.25.25 0 0 0 .25-.25V9.5Zm0-4V8h5.5a.25.25 0 0 0 .25-.25v-2a.25.25 0 0 0-.25-.25Zm-7 0a.25.25 0 0 0-.25.25v2c0 .138.112.25.25.25h5.5V5.5h-5.5Zm3-4a1.25 1.25 0 0 0 0 2.5h2.309c-.233-.818-.542-1.401-.878-1.793-.43-.502-.915-.707-1.431-.707ZM8.941 4h2.309a1.25 1.25 0 0 0 0-2.5c-.516 0-1 .205-1.43.707-.337.392-.646.975-.879 1.793Z"></path>
</svg>
</template>

<template id="code-square-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-code-square">
    <path d="M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25Zm7.47 3.97a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L10.69 8 9.22 6.53a.75.75 0 0 1 0-1.06ZM6.78 6.53 5.31 8l1.47 1.47a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215l-2-2a.75.75 0 0 1 0-1.06l2-2a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z"></path>
</svg>
</template>

<template id="device-desktop-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-device-desktop">
    <path d="M14.25 1c.966 0 1.75.784 1.75 1.75v7.5A1.75 1.75 0 0 1 14.25 12h-3.727c.099 1.041.52 1.872 1.292 2.757A.752.752 0 0 1 11.25 16h-6.5a.75.75 0 0 1-.565-1.243c.772-.885 1.192-1.716 1.292-2.757H1.75A1.75 1.75 0 0 1 0 10.25v-7.5C0 1.784.784 1 1.75 1ZM1.75 2.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25ZM9.018 12H6.982a5.72 5.72 0 0 1-.765 2.5h3.566a5.72 5.72 0 0 1-.765-2.5Z"></path>
</svg>
</template>

        <div class="position-relative">
                <ul
                  role="listbox"
                  class="ActionListWrap QueryBuilder-ListWrap"
                  aria-label="Suggestions"
                  data-action="
                    combobox-commit:query-builder#comboboxCommit
                    mousedown:query-builder#resultsMousedown
                  "
                  data-target="query-builder.resultsList"
                  data-persist-list=false
                  id="query-builder-test-results"
                  tabindex="-1"
                ></ul>
        </div>
      <div class="FormControl-inlineValidation" id="validation-86f16a7a-2220-4d89-837f-82d3aaaa493e" hidden="hidden">
        <span class="FormControl-inlineValidation--visual">
          <svg aria-hidden="true" height="12" viewBox="0 0 12 12" version="1.1" width="12" data-view-component="true" class="octicon octicon-alert-fill">
    <path d="M4.855.708c.5-.896 1.79-.896 2.29 0l4.675 8.351a1.312 1.312 0 0 1-1.146 1.954H1.33A1.313 1.313 0 0 1 .183 9.058ZM7 7V3H5v4Zm-1 3a1 1 0 1 0 0-2 1 1 0 0 0 0 2Z"></path>
</svg>
        </span>
        <span></span>
</div>    </div>
    <div data-target="query-builder.screenReaderFeedback" aria-live="polite" aria-atomic="true" class="sr-only"></div>
</query-builder></form>
          <div class="d-flex flex-row color-fg-muted px-3 text-small color-bg-default search-feedback-prompt">
            <a target="_blank" href="https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax" data-view-component="true" class="Link color-fg-accent text-normal ml-2">Search syntax tips</a>            <div class="d-flex flex-1"></div>
          </div>
        </div>
</div>

    </div>
</modal-dialog></div>
  </div>
  <div data-action="click:qbsearch-input#retract" class="dark-backdrop position-fixed" hidden data-target="qbsearch-input.darkBackdrop"></div>
  <div class="color-fg-default">
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true" class="Overlay Overlay-whenNarrow Overlay--size-medium Overlay--motion-scaleFade Overlay--disableScroll">
    <div data-view-component="true" class="Overlay-header">
  <div class="Overlay-headerContentWrap">
    <div class="Overlay-titleWrap">
      <h1 class="Overlay-title " id="feedback-dialog-title">
        Provide feedback
      </h1>
        
    </div>
    <div class="Overlay-actionWrap">
      <button data-close-dialog-id="feedback-dialog" aria-label="Close" aria-label="Close" type="button" data-view-component="true" class="close-button Overlay-closeButton"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg></button>
    </div>
  </div>
  
</div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        <div data-view-component="true" class="Overlay-body">        <!-- '"` --><!-- </textarea></xmp> --></option></form><form id="code-search-feedback-form" data-turbo="false" action="/search/feedback" accept-charset="UTF-8" method="post"><input type="hidden" data-csrf="true" name="authenticity_token" value="KoNtYEHV0OvuxFLk0KJy5/lgcGlv4jY21GhLcT2OeNhXwk4YiqzLp35ioTJqH8u6G7Yv36p7HAwGJAKqyVNwHA==" />
          <p>We read every piece of feedback, and take your input very seriously.</p>
          <textarea name="feedback" class="form-control width-full mb-2" style="height: 120px" id="feedback"></textarea>
          <input name="include_email" id="include_email" aria-label="Include my email address so I can be contacted" class="form-control mr-2" type="checkbox">
          <label for="include_email" style="font-weight: normal">Include my email address so I can be contacted</label>
</form></div>
      </scrollable-region>
      <div data-view-component="true" class="Overlay-footer Overlay-footer--alignEnd">          <button data-close-dialog-id="feedback-dialog" type="button" data-view-component="true" class="btn">    Cancel
</button>
          <button form="code-search-feedback-form" data-action="click:qbsearch-input#submitFeedback" type="submit" data-view-component="true" class="btn-primary btn">    Submit feedback
</button>
</div>
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true" class="Overlay Overlay-whenNarrow Overlay--size-medium Overlay--motion-scaleFade Overlay--disableScroll">
    <div data-view-component="true" class="Overlay-header Overlay-header--divided">
  <div class="Overlay-headerContentWrap">
    <div class="Overlay-titleWrap">
      <h1 class="Overlay-title " id="custom-scopes-dialog-title">
        Saved searches
      </h1>
        <h2 id="custom-scopes-dialog-description" class="Overlay-description">Use saved searches to filter your results more quickly</h2>
    </div>
    <div class="Overlay-actionWrap">
      <button data-close-dialog-id="custom-scopes-dialog" aria-label="Close" aria-label="Close" type="button" data-view-component="true" class="close-button Overlay-closeButton"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg></button>
    </div>
  </div>
  
</div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        <div data-view-component="true" class="Overlay-body">        <div data-target="custom-scopes.customScopesModalDialogFlash"></div>

        <div hidden class="create-custom-scope-form" data-target="custom-scopes.createCustomScopeForm">
        <!-- '"` --><!-- </textarea></xmp> --></option></form><form id="custom-scopes-dialog-form" data-turbo="false" action="/search/custom_scopes" accept-charset="UTF-8" method="post"><input type="hidden" data-csrf="true" name="authenticity_token" value="Y4uXKYzvdnJY+5HezcluxZrASOPfUOMFf27GoHftNjSyW4E6xNgZQuag9mxUvWk1tkEZI4iIY2HqtPQY5u43ag==" />
          <div data-target="custom-scopes.customScopesModalDialogFlash"></div>

          <input type="hidden" id="custom_scope_id" name="custom_scope_id" data-target="custom-scopes.customScopesIdField">

          <div class="form-group">
            <label for="custom_scope_name">Name</label>
            <auto-check src="/search/custom_scopes/check_name" required>
              <input
                type="text"
                name="custom_scope_name"
                id="custom_scope_name"
                data-target="custom-scopes.customScopesNameField"
                class="form-control"
                autocomplete="off"
                placeholder="github-ruby"
                required
                maxlength="50">
              <input type="hidden" data-csrf="true" value="VywzX7PfbDA8K5ymHFACYZFMs91ebrKWGf7VS6iegPt0BbefxH7jLWK2ehfWjEW5rM+yft1ehm8CaKPrcrnaUw==" />
            </auto-check>
          </div>

          <div class="form-group">
            <label for="custom_scope_query">Query</label>
            <input
              type="text"
              name="custom_scope_query"
              id="custom_scope_query"
              data-target="custom-scopes.customScopesQueryField"
              class="form-control"
              autocomplete="off"
              placeholder="(repo:mona/a OR repo:mona/b) AND lang:python"
              required
              maxlength="500">
          </div>

          <p class="text-small color-fg-muted">
            To see all available qualifiers, see our <a class="Link--inTextBlock" href="https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax">documentation</a>.
          </p>
</form>        </div>

        <div data-target="custom-scopes.manageCustomScopesForm">
          <div data-target="custom-scopes.list"></div>
        </div>

</div>
      </scrollable-region>
      <div data-view-component="true" class="Overlay-footer Overlay-footer--alignEnd Overlay-footer--divided">          <button data-action="click:custom-scopes#customScopesCancel" type="button" data-view-component="true" class="btn">    Cancel
</button>
          <button form="custom-scopes-dialog-form" data-action="click:custom-scopes#customScopesSubmit" data-target="custom-scopes.customScopesSubmitButton" type="submit" data-view-component="true" class="btn-primary btn">    Create saved search
</button>
</div>
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            <div class="position-relative HeaderMenu-link-wrap d-lg-inline-block">
              <a
                href="/login?return_to=https%3A%2F%2Fgithub.com%2Fcoderonion%2Fawesome-yolo-object-detection"
                class="HeaderMenu-link HeaderMenu-link--sign-in HeaderMenu-button flex-shrink-0 no-underline d-none d-lg-inline-flex border border-lg-0 rounded px-2 py-1"
                style="margin-left: 12px;"
                data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/coderonion/awesome-yolo-object-detection&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="58d2cabbb70ca01d75dca7c221ecbb07ba8bbb2e720c6b8e354fda024d7f8087"
                data-analytics-event="{&quot;category&quot;:&quot;Marketing nav&quot;,&quot;action&quot;:&quot;click to go to homepage&quot;,&quot;label&quot;:&quot;ref_page:Marketing;ref_cta:Sign in;ref_loc:Header&quot;}"
              >
                Sign in
              </a>
            </div>

              <a href="/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=coderonion%2Fawesome-yolo-object-detection"
                class="HeaderMenu-link HeaderMenu-link--sign-up HeaderMenu-button flex-shrink-0 d-flex d-lg-inline-flex no-underline border color-border-default rounded px-2 py-1"
                data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/coderonion/awesome-yolo-object-detection&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="58d2cabbb70ca01d75dca7c221ecbb07ba8bbb2e720c6b8e354fda024d7f8087"
                data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/&lt;user-name&gt;/&lt;repo-name&gt;;ref_cta:Sign up;ref_loc:header logged out&quot;}"
              >
                Sign up
              </a>

                <div class="AppHeader-appearanceSettings">
    <react-partial-anchor>
      <button data-target="react-partial-anchor.anchor" id="icon-button-4bcba3ba-2da3-4adc-b431-723f5590f8b6" aria-labelledby="tooltip-416de22d-5e57-40ac-965c-5562239ab1f9" type="button" disabled="disabled" data-view-component="true" class="Button Button--iconOnly Button--invisible Button--medium AppHeader-button HeaderMenu-link border cursor-wait">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-sliders Button-visual">
    <path d="M15 2.75a.75.75 0 0 1-.75.75h-4a.75.75 0 0 1 0-1.5h4a.75.75 0 0 1 .75.75Zm-8.5.75v1.25a.75.75 0 0 0 1.5 0v-4a.75.75 0 0 0-1.5 0V2H1.75a.75.75 0 0 0 0 1.5H6.5Zm1.25 5.25a.75.75 0 0 0 0-1.5h-6a.75.75 0 0 0 0 1.5h6ZM15 8a.75.75 0 0 1-.75.75H11.5V10a.75.75 0 1 1-1.5 0V6a.75.75 0 0 1 1.5 0v1.25h2.75A.75.75 0 0 1 15 8Zm-9 5.25v-2a.75.75 0 0 0-1.5 0v1.25H1.75a.75.75 0 0 0 0 1.5H4.5v1.25a.75.75 0 0 0 1.5 0v-2Zm9 0a.75.75 0 0 1-.75.75h-6a.75.75 0 0 1 0-1.5h6a.75.75 0 0 1 .75.75Z"></path>
</svg>
</button><tool-tip id="tooltip-416de22d-5e57-40ac-965c-5562239ab1f9" for="icon-button-4bcba3ba-2da3-4adc-b431-723f5590f8b6" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.f595f41454298e934d3c.module.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.6c63a6de228d6520804d.module.css" />

<react-partial
  partial-name="appearance-settings"
  data-ssr="false"
  data-attempted-ssr="false"
  data-react-profiling="false"
>
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>


      </template>
    </react-partial-anchor>
  </div>

          <button type="button" class="sr-only js-header-menu-focus-trap d-block d-lg-none">Resetting focus</button>
        </div>
      </div>
    </div>
  </div>
</header>

      <div hidden="hidden" data-view-component="true" class="js-stale-session-flash stale-session-flash flash flash-warn flash-full">
  
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
        <span class="js-stale-session-flash-signed-in" hidden>You signed in with another tab or window. <a class="Link--inTextBlock" href="">Reload</a> to refresh your session.</span>
        <span class="js-stale-session-flash-signed-out" hidden>You signed out in another tab or window. <a class="Link--inTextBlock" href="">Reload</a> to refresh your session.</span>
        <span class="js-stale-session-flash-switched" hidden>You switched accounts on another tab or window. <a class="Link--inTextBlock" href="">Reload</a> to refresh your session.</span>

    <button id="icon-button-9b7c304d-159b-4ad1-8556-344ec2c04622" aria-labelledby="tooltip-dcc4f593-9297-4f82-82b2-1727d4cfac18" type="button" data-view-component="true" class="Button Button--iconOnly Button--invisible Button--medium flash-close js-flash-close">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x Button-visual">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
</button><tool-tip id="tooltip-dcc4f593-9297-4f82-82b2-1727d4cfac18" for="icon-button-9b7c304d-159b-4ad1-8556-344ec2c04622" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute">Dismiss alert</tool-tip>


  
</div>
    </div>

  <div id="start-of-content" class="show-on-focus"></div>








    <div id="js-flash-container" class="flash-container" data-turbo-replace>




  <template class="js-flash-template">
    
<div class="flash flash-full   {{ className }}">
  <div >
    <button autofocus class="flash-close js-flash-close" type="button" aria-label="Dismiss this message">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
    </button>
    <div aria-atomic="true" role="alert" class="js-flash-alert">
      
      <div>{{ message }}</div>

    </div>
  </div>
</div>
  </template>
</div>


    






  <div
    class="application-main "
    data-commit-hovercards-enabled
    data-discussion-hovercards-enabled
    data-issue-and-pr-hovercards-enabled
    data-project-hovercards-enabled
  >
        <div itemscope itemtype="http://schema.org/SoftwareSourceCode" class="">
    <main id="js-repo-pjax-container" >
      
  





    






  
  <div id="repository-container-header"  class="pt-3 hide-full-screen" style="background-color: var(--page-header-bgColor, var(--color-page-header-bg));" data-turbo-replace>

      <div class="d-flex flex-nowrap flex-justify-end mb-3  px-3 px-lg-5" style="gap: 1rem;">

        <div class="flex-auto min-width-0 width-fit">
            
  <div class=" d-flex flex-wrap flex-items-center wb-break-word f3 text-normal">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo color-fg-muted mr-2">
    <path d="M2 2.5A2.5 2.5 0 0 1 4.5 0h8.75a.75.75 0 0 1 .75.75v12.5a.75.75 0 0 1-.75.75h-2.5a.75.75 0 0 1 0-1.5h1.75v-2h-8a1 1 0 0 0-.714 1.7.75.75 0 1 1-1.072 1.05A2.495 2.495 0 0 1 2 11.5Zm10.5-1h-8a1 1 0 0 0-1 1v6.708A2.486 2.486 0 0 1 4.5 9h8ZM5 12.25a.25.25 0 0 1 .25-.25h3.5a.25.25 0 0 1 .25.25v3.25a.25.25 0 0 1-.4.2l-1.45-1.087a.249.249 0 0 0-.3 0L5.4 15.7a.25.25 0 0 1-.4-.2Z"></path>
</svg>
    
    <span class="author flex-self-stretch" itemprop="author">
      <a class="url fn" rel="author" data-hovercard-type="user" data-hovercard-url="/users/coderonion/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="/coderonion">
        coderonion
</a>    </span>
    <span class="mx-1 flex-self-stretch color-fg-muted">/</span>
    <strong itemprop="name" class="mr-2 flex-self-stretch">
      <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="/coderonion/awesome-yolo-object-detection">awesome-yolo-object-detection</a>
    </strong>

    <span></span><span class="Label Label--secondary v-align-middle mr-1">Public</span>
  </div>


        </div>

        <div id="repository-details-container" class="flex-shrink-0" data-turbo-replace style="max-width: 70%;">
            <ul class="pagehead-actions flex-shrink-0 d-none d-md-inline" style="padding: 2px 0;">
    
      

  <li>
            <a href="/login?return_to=%2Fcoderonion%2Fawesome-yolo-object-detection" rel="nofollow" id="repository-details-watch-button" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/coderonion/awesome-yolo-object-detection&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="5846330545a83d2c5e8014b74dde29b8a0e5a2c6e07de83973a6d43d78bb2b49" aria-label="You must be signed in to change notification settings" data-view-component="true" class="btn-sm btn">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-bell mr-2">
    <path d="M8 16a2 2 0 0 0 1.985-1.75c.017-.137-.097-.25-.235-.25h-3.5c-.138 0-.252.113-.235.25A2 2 0 0 0 8 16ZM3 5a5 5 0 0 1 10 0v2.947c0 .05.015.098.042.139l1.703 2.555A1.519 1.519 0 0 1 13.482 13H2.518a1.516 1.516 0 0 1-1.263-2.36l1.703-2.554A.255.255 0 0 0 3 7.947Zm5-3.5A3.5 3.5 0 0 0 4.5 5v2.947c0 .346-.102.683-.294.97l-1.703 2.556a.017.017 0 0 0-.003.01l.001.006c0 .002.002.004.004.006l.006.004.007.001h10.964l.007-.001.006-.004.004-.006.001-.007a.017.017 0 0 0-.003-.01l-1.703-2.554a1.745 1.745 0 0 1-.294-.97V5A3.5 3.5 0 0 0 8 1.5Z"></path>
</svg>Notifications
</a>    <tool-tip id="tooltip-4423dca0-f8a7-4476-b31a-4997d1f0410b" for="repository-details-watch-button" popover="manual" data-direction="s" data-type="description" data-view-component="true" class="sr-only position-absolute">You must be signed in to change notification settings</tool-tip>

  </li>

  <li>
          <a icon="repo-forked" id="fork-button" href="/login?return_to=%2Fcoderonion%2Fawesome-yolo-object-detection" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:461270746,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/coderonion/awesome-yolo-object-detection&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="5294c62344eb3fa68995e97f3babf7716732ffd34b4f8c110c45095297520480" data-view-component="true" class="btn-sm btn">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo-forked mr-2">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>Fork
    <span id="repo-network-counter" data-pjax-replace="true" data-turbo-replace="true" title="220" data-view-component="true" class="Counter">220</span>
</a>
  </li>

  <li>
        <div data-view-component="true" class="BtnGroup d-flex">
        <a href="/login?return_to=%2Fcoderonion%2Fawesome-yolo-object-detection" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:461270746,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/coderonion/awesome-yolo-object-detection&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="9e69774e9978fdd8ecaf604568d6ce05dff82df73ffcc48affd44df95a91eba8" aria-label="You must be signed in to star a repository" data-view-component="true" class="tooltipped tooltipped-sw btn-sm btn">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-star v-align-text-bottom d-inline-block mr-2">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg><span data-view-component="true" class="d-inline">
          Star
</span>          <span id="repo-stars-counter-star" aria-label="1613 users starred this repository" data-singular-suffix="user starred this repository" data-plural-suffix="users starred this repository" data-turbo-replace="true" title="1,613" data-view-component="true" class="Counter js-social-count">1.6k</span>
</a></div>
  </li>

</ul>

        </div>
      </div>

        <div id="responsive-meta-container" data-turbo-replace>
      <div class="d-block d-md-none mb-2 px-3 px-md-4 px-lg-5">
      <p class="f4 mb-3 ">
        🚀🚀🚀 A collection of some awesome public YOLO object detection series projects and the related object detection datasets.
      </p>

    

    <div class="mb-3">
        <a class="Link--secondary no-underline mr-3" href="/coderonion/awesome-yolo-object-detection/stargazers">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-star mr-1">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
          <span class="text-bold">1.6k</span>
          stars
</a>        <a class="Link--secondary no-underline mr-3" href="/coderonion/awesome-yolo-object-detection/forks">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo-forked mr-1">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>
          <span class="text-bold">220</span>
          forks
</a>        <a class="Link--secondary no-underline mr-3 d-inline-block" href="/coderonion/awesome-yolo-object-detection/branches">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-git-branch mr-1">
    <path d="M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z"></path>
</svg>
          <span>Branches</span>
</a>        <a class="Link--secondary no-underline d-inline-block" href="/coderonion/awesome-yolo-object-detection/tags">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-tag mr-1">
    <path d="M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z"></path>
</svg>
          <span>Tags</span>
</a>        <a class="Link--secondary no-underline d-inline-block" href="/coderonion/awesome-yolo-object-detection/activity">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-pulse mr-1">
    <path d="M6 2c.306 0 .582.187.696.471L10 10.731l1.304-3.26A.751.751 0 0 1 12 7h3.25a.75.75 0 0 1 0 1.5h-2.742l-1.812 4.528a.751.751 0 0 1-1.392 0L6 4.77 4.696 8.03A.75.75 0 0 1 4 8.5H.75a.75.75 0 0 1 0-1.5h2.742l1.812-4.529A.751.751 0 0 1 6 2Z"></path>
</svg>
          <span>Activity</span>
</a>    </div>

      <div class="d-flex flex-wrap gap-2">
        <div class="flex-1">
            <div data-view-component="true" class="BtnGroup d-flex">
        <a href="/login?return_to=%2Fcoderonion%2Fawesome-yolo-object-detection" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:461270746,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/coderonion/awesome-yolo-object-detection&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="9e69774e9978fdd8ecaf604568d6ce05dff82df73ffcc48affd44df95a91eba8" aria-label="You must be signed in to star a repository" data-view-component="true" class="tooltipped tooltipped-sw btn-sm btn btn-block">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-star v-align-text-bottom d-inline-block mr-2">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg><span data-view-component="true" class="d-inline">
          Star
</span>
</a></div>
        </div>
        <div class="flex-1">
                <a href="/login?return_to=%2Fcoderonion%2Fawesome-yolo-object-detection" rel="nofollow" id="files-overview-watch-button" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/coderonion/awesome-yolo-object-detection&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="5846330545a83d2c5e8014b74dde29b8a0e5a2c6e07de83973a6d43d78bb2b49" aria-label="You must be signed in to change notification settings" data-view-component="true" class="btn-sm btn btn-block">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-bell mr-2">
    <path d="M8 16a2 2 0 0 0 1.985-1.75c.017-.137-.097-.25-.235-.25h-3.5c-.138 0-.252.113-.235.25A2 2 0 0 0 8 16ZM3 5a5 5 0 0 1 10 0v2.947c0 .05.015.098.042.139l1.703 2.555A1.519 1.519 0 0 1 13.482 13H2.518a1.516 1.516 0 0 1-1.263-2.36l1.703-2.554A.255.255 0 0 0 3 7.947Zm5-3.5A3.5 3.5 0 0 0 4.5 5v2.947c0 .346-.102.683-.294.97l-1.703 2.556a.017.017 0 0 0-.003.01l.001.006c0 .002.002.004.004.006l.006.004.007.001h10.964l.007-.001.006-.004.004-.006.001-.007a.017.017 0 0 0-.003-.01l-1.703-2.554a1.745 1.745 0 0 1-.294-.97V5A3.5 3.5 0 0 0 8 1.5Z"></path>
</svg>Notifications
</a>    <tool-tip id="tooltip-9d9a00ff-f157-46cb-80db-f44fe1540db8" for="files-overview-watch-button" popover="manual" data-direction="s" data-type="description" data-view-component="true" class="sr-only position-absolute">You must be signed in to change notification settings</tool-tip>

        </div>
        <span>
          

        </span>
      </div>
  </div>

</div>


          <nav data-pjax="#js-repo-pjax-container" aria-label="Repository" data-view-component="true" class="js-repo-nav js-sidenav-container-pjax js-responsive-underlinenav overflow-hidden UnderlineNav px-3 px-md-4 px-lg-5">

  <ul data-view-component="true" class="UnderlineNav-body list-style-none">
      <li data-view-component="true" class="d-inline-flex">
  <a id="code-tab" href="/coderonion/awesome-yolo-object-detection" data-tab-item="i0code-tab" data-selected-links="repo_source repo_downloads repo_commits repo_releases repo_tags repo_branches repo_packages repo_deployments repo_attestations /coderonion/awesome-yolo-object-detection" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g c" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Code&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" aria-current="page" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item selected">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-code UnderlineNav-octicon d-none d-sm-inline">
    <path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path>
</svg>
        <span data-content="Code">Code</span>
          <span id="code-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true" class="Counter"></span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="issues-tab" href="/coderonion/awesome-yolo-object-detection/issues" data-tab-item="i1issues-tab" data-selected-links="repo_issues repo_labels repo_milestones /coderonion/awesome-yolo-object-detection/issues" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g i" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Issues&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-issue-opened UnderlineNav-octicon d-none d-sm-inline">
    <path d="M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z"></path>
</svg>
        <span data-content="Issues">Issues</span>
          <span id="issues-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="0" hidden="hidden" data-view-component="true" class="Counter">0</span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="pull-requests-tab" href="/coderonion/awesome-yolo-object-detection/pulls" data-tab-item="i2pull-requests-tab" data-selected-links="repo_pulls checks /coderonion/awesome-yolo-object-detection/pulls" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g p" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Pull requests&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-git-pull-request UnderlineNav-octicon d-none d-sm-inline">
    <path d="M1.5 3.25a2.25 2.25 0 1 1 3 2.122v5.256a2.251 2.251 0 1 1-1.5 0V5.372A2.25 2.25 0 0 1 1.5 3.25Zm5.677-.177L9.573.677A.25.25 0 0 1 10 .854V2.5h1A2.5 2.5 0 0 1 13.5 5v5.628a2.251 2.251 0 1 1-1.5 0V5a1 1 0 0 0-1-1h-1v1.646a.25.25 0 0 1-.427.177L7.177 3.427a.25.25 0 0 1 0-.354ZM3.75 2.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm0 9.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm8.25.75a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Z"></path>
</svg>
        <span data-content="Pull requests">Pull requests</span>
          <span id="pull-requests-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="0" hidden="hidden" data-view-component="true" class="Counter">0</span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="actions-tab" href="/coderonion/awesome-yolo-object-detection/actions" data-tab-item="i3actions-tab" data-selected-links="repo_actions /coderonion/awesome-yolo-object-detection/actions" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g a" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Actions&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-play UnderlineNav-octicon d-none d-sm-inline">
    <path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z"></path>
</svg>
        <span data-content="Actions">Actions</span>
          <span id="actions-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true" class="Counter"></span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="projects-tab" href="/coderonion/awesome-yolo-object-detection/projects" data-tab-item="i4projects-tab" data-selected-links="repo_projects new_repo_project repo_project /coderonion/awesome-yolo-object-detection/projects" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g b" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Projects&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-table UnderlineNav-octicon d-none d-sm-inline">
    <path d="M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25ZM6.5 6.5v8h7.75a.25.25 0 0 0 .25-.25V6.5Zm8-1.5V1.75a.25.25 0 0 0-.25-.25H6.5V5Zm-13 1.5v7.75c0 .138.112.25.25.25H5v-8ZM5 5V1.5H1.75a.25.25 0 0 0-.25.25V5Z"></path>
</svg>
        <span data-content="Projects">Projects</span>
          <span id="projects-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="0" hidden="hidden" data-view-component="true" class="Counter">0</span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="security-tab" href="/coderonion/awesome-yolo-object-detection/security" data-tab-item="i5security-tab" data-selected-links="security overview alerts policy token_scanning code_scanning /coderonion/awesome-yolo-object-detection/security" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g s" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Security&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-shield UnderlineNav-octicon d-none d-sm-inline">
    <path d="M7.467.133a1.748 1.748 0 0 1 1.066 0l5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667Zm.61 1.429a.25.25 0 0 0-.153 0l-5.25 1.68a.25.25 0 0 0-.174.238V7c0 1.358.275 2.666 1.057 3.86.784 1.194 2.121 2.34 4.366 3.297a.196.196 0 0 0 .154 0c2.245-.956 3.582-2.104 4.366-3.298C13.225 9.666 13.5 8.36 13.5 7V3.48a.251.251 0 0 0-.174-.237l-5.25-1.68ZM8.75 4.75v3a.75.75 0 0 1-1.5 0v-3a.75.75 0 0 1 1.5 0ZM9 10.5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
        <span data-content="Security">Security</span>
          <include-fragment src="/coderonion/awesome-yolo-object-detection/security/overall-count" accept="text/fragment+html" data-nonce="v2:515a6721-8eb7-ba0a-7b66-e450a60aff90" data-view-component="true">
  
  <div data-show-on-forbidden-error hidden>
    <div class="Box">
  <div class="blankslate-container">
    <div data-view-component="true" class="blankslate blankslate-spacious color-bg-default rounded-2">
      

      <h3 data-view-component="true" class="blankslate-heading">        Uh oh!
</h3>
      <p data-view-component="true">        <p class="color-fg-muted my-2 mb-2 ws-normal">There was an error while loading. <a class="Link--inTextBlock" data-turbo="false" href="" aria-label="Please reload this page">Please reload this page</a>.</p>
</p>

</div>  </div>
</div>  </div>
</include-fragment>

    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="insights-tab" href="/coderonion/awesome-yolo-object-detection/pulse" data-tab-item="i6insights-tab" data-selected-links="repo_graphs repo_contributors dependency_graph dependabot_updates pulse people community /coderonion/awesome-yolo-object-detection/pulse" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Insights&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-graph UnderlineNav-octicon d-none d-sm-inline">
    <path d="M1.5 1.75V13.5h13.75a.75.75 0 0 1 0 1.5H.75a.75.75 0 0 1-.75-.75V1.75a.75.75 0 0 1 1.5 0Zm14.28 2.53-5.25 5.25a.75.75 0 0 1-1.06 0L7 7.06 4.28 9.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.25-3.25a.75.75 0 0 1 1.06 0L10 7.94l4.72-4.72a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z"></path>
</svg>
        <span data-content="Insights">Insights</span>
          <span id="insights-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true" class="Counter"></span>


    
</a></li>
</ul>
    <div style="visibility:hidden;" data-view-component="true" class="UnderlineNav-actions js-responsive-underlinenav-overflow position-absolute pr-3 pr-md-4 pr-lg-5 right-0">      <action-menu data-select-variant="none" data-view-component="true">
  <focus-group direction="vertical" mnemonics retain>
    <button id="action-menu-6e714272-20ae-466e-999e-e4d9aa1b3744-button" popovertarget="action-menu-6e714272-20ae-466e-999e-e4d9aa1b3744-overlay" aria-controls="action-menu-6e714272-20ae-466e-999e-e4d9aa1b3744-list" aria-haspopup="true" aria-labelledby="tooltip-5b7699ec-457b-4e21-8f97-be263f879bdc" type="button" data-view-component="true" class="Button Button--iconOnly Button--secondary Button--medium UnderlineNav-item">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-kebab-horizontal Button-visual">
    <path d="M8 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3ZM1.5 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Zm13 0a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path>
</svg>
</button><tool-tip id="tooltip-5b7699ec-457b-4e21-8f97-be263f879bdc" for="action-menu-6e714272-20ae-466e-999e-e4d9aa1b3744-button" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute">Additional navigation options</tool-tip>


<anchored-position data-target="action-menu.overlay" id="action-menu-6e714272-20ae-466e-999e-e4d9aa1b3744-overlay" anchor="action-menu-6e714272-20ae-466e-999e-e4d9aa1b3744-button" align="start" side="outside-bottom" anchor-offset="normal" popover="auto" data-view-component="true">
  <div data-view-component="true" class="Overlay Overlay--size-auto">
    
      <div data-view-component="true" class="Overlay-body Overlay-body--paddingNone">          <action-list>
  <div data-view-component="true">
    <ul aria-labelledby="action-menu-6e714272-20ae-466e-999e-e4d9aa1b3744-button" id="action-menu-6e714272-20ae-466e-999e-e4d9aa1b3744-list" role="menu" data-view-component="true" class="ActionListWrap--inset ActionListWrap">
        <li hidden="hidden" data-menu-item="i0code-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-bf566beb-3206-43a3-946b-7deb5ab1efcd" href="/coderonion/awesome-yolo-object-detection" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-code">
    <path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Code
</span>      
</a>
  
</li>
        <li hidden="hidden" data-menu-item="i1issues-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-6e824c7c-67d1-4c70-aa54-1fdab60d5f02" href="/coderonion/awesome-yolo-object-detection/issues" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-issue-opened">
    <path d="M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Issues
</span>      
</a>
  
</li>
        <li hidden="hidden" data-menu-item="i2pull-requests-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-adf3aa77-8b7c-4eda-852e-355615c3236a" href="/coderonion/awesome-yolo-object-detection/pulls" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-git-pull-request">
    <path d="M1.5 3.25a2.25 2.25 0 1 1 3 2.122v5.256a2.251 2.251 0 1 1-1.5 0V5.372A2.25 2.25 0 0 1 1.5 3.25Zm5.677-.177L9.573.677A.25.25 0 0 1 10 .854V2.5h1A2.5 2.5 0 0 1 13.5 5v5.628a2.251 2.251 0 1 1-1.5 0V5a1 1 0 0 0-1-1h-1v1.646a.25.25 0 0 1-.427.177L7.177 3.427a.25.25 0 0 1 0-.354ZM3.75 2.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm0 9.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm8.25.75a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Pull requests
</span>      
</a>
  
</li>
        <li hidden="hidden" data-menu-item="i3actions-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-fb67ea4b-6fdb-45e1-ac9e-a2bd62d48a04" href="/coderonion/awesome-yolo-object-detection/actions" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-play">
    <path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Actions
</span>      
</a>
  
</li>
        <li hidden="hidden" data-menu-item="i4projects-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-99be6164-f953-4248-b6ec-1ac8b937f463" href="/coderonion/awesome-yolo-object-detection/projects" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-table">
    <path d="M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25ZM6.5 6.5v8h7.75a.25.25 0 0 0 .25-.25V6.5Zm8-1.5V1.75a.25.25 0 0 0-.25-.25H6.5V5Zm-13 1.5v7.75c0 .138.112.25.25.25H5v-8ZM5 5V1.5H1.75a.25.25 0 0 0-.25.25V5Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Projects
</span>      
</a>
  
</li>
        <li hidden="hidden" data-menu-item="i5security-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-4b52e30a-08b4-4856-8594-10bcca522c56" href="/coderonion/awesome-yolo-object-detection/security" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-shield">
    <path d="M7.467.133a1.748 1.748 0 0 1 1.066 0l5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667Zm.61 1.429a.25.25 0 0 0-.153 0l-5.25 1.68a.25.25 0 0 0-.174.238V7c0 1.358.275 2.666 1.057 3.86.784 1.194 2.121 2.34 4.366 3.297a.196.196 0 0 0 .154 0c2.245-.956 3.582-2.104 4.366-3.298C13.225 9.666 13.5 8.36 13.5 7V3.48a.251.251 0 0 0-.174-.237l-5.25-1.68ZM8.75 4.75v3a.75.75 0 0 1-1.5 0v-3a.75.75 0 0 1 1.5 0ZM9 10.5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Security
</span>      
</a>
  
</li>
        <li hidden="hidden" data-menu-item="i6insights-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-a1450798-9d73-42e4-9f84-4181571697e8" href="/coderonion/awesome-yolo-object-detection/pulse" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-graph">
    <path d="M1.5 1.75V13.5h13.75a.75.75 0 0 1 0 1.5H.75a.75.75 0 0 1-.75-.75V1.75a.75.75 0 0 1 1.5 0Zm14.28 2.53-5.25 5.25a.75.75 0 0 1-1.06 0L7 7.06 4.28 9.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.25-3.25a.75.75 0 0 1 1.06 0L10 7.94l4.72-4.72a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Insights
</span>      
</a>
  
</li>
</ul>    
</div></action-list>


</div>
      
</div></anchored-position>  </focus-group>
</action-menu></div>
</nav>

  </div>

  



<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance" class="">
    <div id="repo-content-pjax-container" class="repository-content " >
    



    
      
  <h1 class='sr-only'>coderonion/awesome-yolo-object-detection</h1>
  <div class="clearfix container-xl px-md-4 px-lg-5 px-3">
    <div>

  <div style="max-width: 100%" data-view-component="true" class="Layout Layout--flowRow-until-md react-repos-overview-margin Layout--sidebarPosition-end Layout--sidebarPosition-flowRow-end">
  <div data-view-component="true" class="Layout-main">      <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.f595f41454298e934d3c.module.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/app_assets_modules_react-partials_repos-overview_components_OverviewContent_module_css-app_as-2f8a17.0268c3a576b1dbc77d72.module.css" />

<react-partial
  partial-name="repos-overview"
  data-ssr="false"
  data-attempted-ssr="true"
  data-react-profiling="false"
>
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{"initialPayload":{"allShortcutsEnabled":false,"path":"/","repo":{"id":461270746,"defaultBranch":"main","name":"awesome-yolo-object-detection","ownerLogin":"coderonion","currentUserCanPush":false,"isFork":false,"isEmpty":false,"createdAt":"2022-02-19T17:57:06.000Z","ownerAvatar":"https://avatars.githubusercontent.com/u/99076655?v=4","public":true,"private":false,"isOrgOwned":false},"currentUser":null,"refInfo":{"name":"main","listCacheKey":"v0:1645293775.060168","canEdit":false,"refType":"branch","currentOid":"2e64f9d661bae442684585d3158b01e9f70853c6"},"tree":{"items":[{"name":"README.md","path":"README.md","contentType":"file"}],"templateDirectorySuggestionUrl":null,"readme":null,"totalCount":1,"showBranchInfobar":false},"fileTree":null,"fileTreeProcessingTime":null,"foldersToFetch":[],"treeExpanded":false,"symbolsExpanded":false,"copilotSWEAgentEnabled":false,"isOverview":true,"overview":{"banners":{"shouldRecommendReadme":false,"isPersonalRepo":false,"showUseActionBanner":false,"actionSlug":null,"actionId":null,"showProtectBranchBanner":false,"publishBannersInfo":{"dismissActionNoticePath":"/settings/dismiss-notice/publish_action_from_repo","releasePath":"/coderonion/awesome-yolo-object-detection/releases/new?marketplace=true","showPublishActionBanner":false},"interactionLimitBanner":null,"showInvitationBanner":false,"inviterName":null,"actionsMigrationBannerInfo":{"releaseTags":[],"showImmutableActionsMigrationBanner":false,"initialMigrationStatus":null},"showDeployBanner":false,"detectedStack":{"framework":null,"packageManager":null}},"codeButton":{"contactPath":"/contact","isEnterprise":false,"local":{"protocolInfo":{"httpAvailable":true,"sshAvailable":null,"httpUrl":"https://github.com/coderonion/awesome-yolo-object-detection.git","showCloneWarning":null,"sshUrl":null,"sshCertificatesRequired":null,"sshCertificatesAvailable":null,"ghCliUrl":"gh repo clone coderonion/awesome-yolo-object-detection","defaultProtocol":"http","newSshKeyUrl":"/settings/ssh/new","setProtocolPath":"/users/set_protocol"},"platformInfo":{"cloneUrl":"https://desktop.github.com","showVisualStudioCloneButton":false,"visualStudioCloneUrl":"https://windows.github.com","showXcodeCloneButton":false,"xcodeCloneUrl":"xcode://clone?repo=https%3A%2F%2Fgithub.com%2Fcoderonion%2Fawesome-yolo-object-detection","zipballUrl":"/coderonion/awesome-yolo-object-detection/archive/refs/heads/main.zip"}},"newCodespacePath":"/codespaces/new?hide_repo_select=true\u0026repo=461270746"},"popovers":{"rename":null,"renamedParentRepo":null},"commitCount":"410","overviewFiles":[{"displayName":"README.md","repoName":"awesome-yolo-object-detection","refName":"main","path":"README.md","preferredFileType":"readme","tabName":"README","richText":"\u003carticle class=\"markdown-body entry-content container-lg\" itemprop=\"text\"\u003e\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch1 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAwesome-YOLO-Object-Detection\u003c/h1\u003e\u003ca id=\"user-content-awesome-yolo-object-detection\" class=\"anchor\" aria-label=\"Permalink: Awesome-YOLO-Object-Detection\" href=\"#awesome-yolo-object-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sindresorhus/awesome\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8693bde04030b1670d5097703441005eba34240c32d1df1eb82a5f0d6716518e/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667\" alt=\"Awesome\" data-canonical-src=\"https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e🚀🚀🚀 YOLO is a great real-time one-stage object detection framework. This repository lists some awesome public YOLO object detection projects and datasets.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eContents\u003c/h2\u003e\u003ca id=\"user-content-contents\" class=\"anchor\" aria-label=\"Permalink: Contents\" href=\"#contents\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#awesome-yolo-object-detection\"\u003eAwesome-YOLO-Object-Detection\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#summary\"\u003eSummary\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#famous-yolo\"\u003eFamous YOLO\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#extensional-frameworks\"\u003eExtensional Frameworks\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#awesome-list\"\u003eAwesome List\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#paper-and-code-overview\"\u003ePaper and Code Overview\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#paper-review\"\u003ePaper Review\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#code-review\"\u003eCode Review\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#learning-resources\"\u003eLearning Resources\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#other-versions-of-yolo\"\u003eOther Versions of YOLO\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#pytorch-implementation\"\u003ePyTorch Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#c-implementation\"\u003eC Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#cpp-implementation\"\u003eCPP Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#ros-implementation\"\u003eROS Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#mojo-implementation\"\u003eMojo Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#rust-implementation\"\u003eRust Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#go-implementation\"\u003eGo Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#csharp-implementation\"\u003eCSharp Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#tensorflow-and-keras-implementation\"\u003eTensorflow and Keras Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#paddlepaddle-implementation\"\u003ePaddlePaddle Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#caffe-implementation\"\u003eCaffe Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#mxnet-implementation\"\u003eMXNet Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#web-implementation\"\u003eWeb Implementation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#others\"\u003eOthers\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#lighter-and-deployment-frameworks\"\u003eLighter and Deployment Frameworks\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#high-performance-inference-engine\"\u003eHigh-performance Inference Engine\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#onnx\"\u003eONNX\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#tensorrt\"\u003eTensorRT\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#deepstream\"\u003eDeepStream\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#openvino\"\u003eOpenVINO\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#ncnn\"\u003eNCNN\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#mnn\"\u003eMNN\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#other-engine\"\u003eOther Engine\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#npu-and-fpga-hardware-deployment\"\u003eNPU and FPGA Hardware Deployment\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#rk3588\"\u003eRK3588\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#fpga\"\u003eFPGA\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#other-hardware\"\u003eOther Hardware\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#pruning-knoweldge-distillation-quantization\"\u003ePruning Knoweldge-Distillation Quantization\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#pruning\"\u003ePruning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#quantization\"\u003eQuantization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#knoweldge-distillation\"\u003eKnoweldge-Distillation\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#lightweight-backbones-and-fpn\"\u003eLightweight Backbones and FPN\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#object-detection-applications\"\u003eObject Detection Applications\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#open-world-object-detection\"\u003eOpen World Object Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#few-shot-object-detection\"\u003eFew-shot Object Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#small-object-detection\"\u003eSmall Object Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#multimodal-image-detection\"\u003eMultimodal Image Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#video-object-detection\"\u003eVideo Object Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#object-tracking\"\u003eObject Tracking\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#multi-object-tracking\"\u003eMulti-Object Tracking\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#Dynamic-object-tracking\"\u003eDynamic Object Tracking\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#deep-reinforcement-learning\"\u003eDeep Reinforcement Learning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#motion-control-field\"\u003eMotion Control Field\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#super-resolution-field\"\u003eSuper-Resolution Field\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#spiking-neural-network\"\u003eSpiking Neural Network\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#attention-and-transformer\"\u003eAttention and Transformer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#oriented-object-detection\"\u003eOriented Object Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#face-detection-and-recognition\"\u003eFace Detection and Recognition\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#face-detection\"\u003eFace Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#face-recognition\"\u003eFace Recognition\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#face-mask-detection\"\u003eFace Mask Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#social-distance-detection\"\u003eSocial Distance Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#autonomous-driving-field-detection\"\u003eAutonomous Driving Field Detection\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#vehicle-detection\"\u003eVehicle Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#license-plate-detection-and-recognition\"\u003eLicense Plate Detection and Recognition\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#lane-detection\"\u003eLane Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#driving-behavior-detection\"\u003eDriving Behavior Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#parking-slot-detection\"\u003eParking Slot Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#traffic-light-detection\"\u003eTraffic Light Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#traffic-sign-detection\"\u003eTraffic Sign Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#crosswalk-detection\"\u003eCrosswalk Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#traffic-accidents-detection\"\u003eTraffic Accidents Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#road-damage-detection\"\u003eRoad Damage Detection\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#animal-detection\"\u003eAnimal Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#helmet-detection\"\u003eHelmet Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#hand-detection\"\u003eHand Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#gesture-recognition\"\u003eGesture Recognition\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#action-detection\"\u003eAction Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#emotion-recognition\"\u003eEmotion Recognition\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#human-pose-estimation\"\u003eHuman Pose Estimation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#distance-measurement\"\u003eDistance Measurement\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#instance-and-semantic-segmentation\"\u003eInstance and Semantic Segmentation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#3d-object-detection\"\u003e3D Object Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#slam-field-detection\"\u003eSLAM Field Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#industrial-defect-detection\"\u003eIndustrial Defect Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#sar-image-detection\"\u003eSAR Image Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#safety-monitoring-field-detection\"\u003eSafety Monitoring Field Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#anti-uav-field-detection\"\u003eAnti-UAV Field Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#medical-field-detection\"\u003eMedical Field Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#chemistry-field-detection\"\u003eChemistry Field Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#agricultural-field-detection\"\u003eAgricultural Field Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#sports-field-detection\"\u003eSports Field Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#aerial-imagery-detection\"\u003eAerial Imagery Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#adverse-weather-conditions\"\u003eAdverse Weather Conditions\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#adversarial-attack-and-defense\"\u003eAdversarial Attack and Defense\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#camouflaged-detection\"\u003eCamouflaged Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#game-field-detection\"\u003eGame Field Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#automatic-annotation-tools\"\u003eAutomatic Annotation Tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#feature-map-visualization\"\u003eFeature Map Visualization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#object-detection-evaluation-metrics\"\u003eObject Detection Evaluation Metrics\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#gui\"\u003eGUI\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#swift-related\"\u003eSwift-Related\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#flutter-related\"\u003eFlutter-Related\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#streamlit-related\"\u003eStreamlit-Related\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#gradio-related\"\u003eGradio-Related\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#qt-related\"\u003eQT-Related\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#pyside-related\"\u003ePySide-Related\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#other-applications\"\u003eOther Applications\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#object-detection-datasets\"\u003eObject Detection Datasets\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#datasets-share-platform\"\u003eDatasets Share Platform\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#datasets-tools\"\u003eDatasets Tools\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#data-annotation\"\u003eData Annotation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#data-augmentation\"\u003eData Augmentation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#data-management\"\u003eData Management\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#general-detection-and-recognition-datasets\"\u003eGeneral Detection and Recognition Datasets\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#general-object-detection-datasets\"\u003eGeneral Object Detection Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#general-object-recognition-datasets\"\u003eGeneral Object Recognition Datasets\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#autonomous-driving-datasets\"\u003eAutonomous Driving Datasets\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#diverse-autonomous-driving-datasets\"\u003eDiverse Autonomous Driving Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#traffic-sign-detection-datasets\"\u003eTraffic Sign Detection Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#license-plate-detection-and-recognition-datasets\"\u003eLicense Plate Detection and Recognition Datasets\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#adverse-weather-datasets\"\u003eAdverse Weather Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#person-detection-datasets\"\u003ePerson Detection Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#anti-uav-datasets\"\u003eAnti-UAV Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#optical-aerial-imagery-datasets\"\u003eOptical Aerial Imagery Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#low-light-image-datasets\"\u003eLow-light Image Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#infrared-image-datasets\"\u003eInfrared Image Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#sar-image-datasets\"\u003eSAR Image Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#sonar-image-datasets\"\u003eSonar Image Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#multimodal-image-datasets\"\u003eMultimodal Image Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#3d-object-detection-datasets\"\u003e3D Object Detection Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#vehicle-to-everything-field-datasets\"\u003eVehicle-to-Everything Field Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#super-resolution-field-datasets\"\u003eSuper-Resolution Field Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#general-detection-and-recognition-datasets\"\u003eFace Detection and Recognition Datasets\u003c/a\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#face-detection-datasets\"\u003eFace Detection Datasets\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#face-recognition-datasets\"\u003eFace Recognition Datasets\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#blogs\"\u003eBlogs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#videos\"\u003eVideos\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSummary\u003c/h2\u003e\u003ca id=\"user-content-summary\" class=\"anchor\" aria-label=\"Permalink: Summary\" href=\"#summary\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFamous YOLO\u003c/h3\u003e\u003ca id=\"user-content-famous-yolo\" class=\"anchor\" aria-label=\"Permalink: Famous YOLO\" href=\"#famous-yolo\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://pjreddie.com/darknet/yolov1\" rel=\"nofollow\"\u003eYOLOv1\u003c/a\u003e (\u003ca href=\"https://github.com/pjreddie/darknet\"\u003eDarknet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e78db04b6860458ce48b5e37283248eaa001e108dc96b47135a89b088e322104/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a7265646469652f6461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e78db04b6860458ce48b5e37283248eaa001e108dc96b47135a89b088e322104/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a7265646469652f6461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pjreddie/darknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e) : \"You Only Look Once: Unified, Real-Time Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Redmon_You_Only_Look_CVPR_2016_paper.html\" rel=\"nofollow\"\u003eCVPR 2016\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://pjreddie.com/darknet/yolov2\" rel=\"nofollow\"\u003eYOLOv2\u003c/a\u003e (\u003ca href=\"https://github.com/pjreddie/darknet\"\u003eDarknet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e78db04b6860458ce48b5e37283248eaa001e108dc96b47135a89b088e322104/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a7265646469652f6461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e78db04b6860458ce48b5e37283248eaa001e108dc96b47135a89b088e322104/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a7265646469652f6461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pjreddie/darknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e) : \"YOLO9000: Better, Faster, Stronger\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_cvpr_2017/html/Redmon_YOLO9000_Better_Faster_CVPR_2017_paper.html\" rel=\"nofollow\"\u003eCVPR 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://pjreddie.com/darknet/yolo\" rel=\"nofollow\"\u003eYOLOv3\u003c/a\u003e (\u003ca href=\"https://github.com/pjreddie/darknet\"\u003eDarknet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e78db04b6860458ce48b5e37283248eaa001e108dc96b47135a89b088e322104/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a7265646469652f6461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e78db04b6860458ce48b5e37283248eaa001e108dc96b47135a89b088e322104/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a7265646469652f6461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pjreddie/darknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e) : \"YOLOv3: An Incremental Improvement\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1804.02767\" rel=\"nofollow\"\u003earXiv 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlexeyAB/darknet\"\u003eYOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7505022ae605a5ef90517df8e6a4dc3968e5ef0690bf8a25b096b10e7be52e02/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f6461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7505022ae605a5ef90517df8e6a4dc3968e5ef0690bf8a25b096b10e7be52e02/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f6461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlexeyAB/darknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e (\u003ca href=\"https://github.com/WongKinYiu/PyTorch_YOLOv4\"\u003eWongKinYiu/PyTorch_YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8c83f25931194dc8d66ccd01a9be4dd983a79e78a479e4b1c0e24cf51f3a482f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f5079546f7263685f594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8c83f25931194dc8d66ccd01a9be4dd983a79e78a479e4b1c0e24cf51f3a482f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f5079546f7263685f594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WongKinYiu/PyTorch_YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e) : \"YOLOv4: Optimal Speed and Accuracy of Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2004.10934\" rel=\"nofollow\"\u003earXiv 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlexeyAB/darknet\"\u003eScaled-YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7505022ae605a5ef90517df8e6a4dc3968e5ef0690bf8a25b096b10e7be52e02/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f6461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7505022ae605a5ef90517df8e6a4dc3968e5ef0690bf8a25b096b10e7be52e02/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f6461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlexeyAB/darknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e (\u003ca href=\"https://github.com/WongKinYiu/ScaledYOLOv4\"\u003eWongKinYiu/ScaledYOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0abe70c666d8b4efd9e6328cf5c3059b48694bbdec84a3e9425fa262f4d7ff0c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f5363616c6564594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0abe70c666d8b4efd9e6328cf5c3059b48694bbdec84a3e9425fa262f4d7ff0c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f5363616c6564594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WongKinYiu/ScaledYOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e) : \"Scaled-YOLOv4: Scaling Cross Stage Partial Network\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Scaled-YOLOv4_Scaling_Cross_Stage_Partial_Network_CVPR_2021_paper.html\" rel=\"nofollow\"\u003eCVPR 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ultralytics/yolov5\"\u003eYOLOv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c4b9baacd1c41802bd1cab446fd9e0918cdead966293fc2713e04ecd067b431d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c4b9baacd1c41802bd1cab446fd9e0918cdead966293fc2713e04ecd067b431d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ultralytics/yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 🚀 in PyTorch \u0026gt; ONNX \u0026gt; CoreML \u0026gt; TFLite. \u003ca href=\"https://docs.ultralytics.com/\" rel=\"nofollow\"\u003edocs.ultralytics.com\u003c/a\u003e. YOLOv5 🚀 is the world's most loved vision AI, representing \u003ca href=\"https://ultralytics.com/\" rel=\"nofollow\"\u003eUltralytics\u003c/a\u003e open-source research into future vision AI methods, incorporating lessons learned and best practices evolved over thousands of hours of research and development.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/meituan/YOLOv6\"\u003eYOLOv6\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f4fd0ceb4b638a82059e96ccf13d37d0f4d14c402857b8b68df56010c9c8209c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d65697475616e2f594f4c4f76363f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f4fd0ceb4b638a82059e96ccf13d37d0f4d14c402857b8b68df56010c9c8209c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d65697475616e2f594f4c4f76363f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/meituan/YOLOv6?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2209.02976\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WongKinYiu/yolov7\"\u003eYOLOv7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/92e74c40ebf900c86bd5f6f6912709d0ceea64a356c2ade1c048df317c8283bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f796f6c6f76373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/92e74c40ebf900c86bd5f6f6912709d0ceea64a356c2ade1c048df317c8283bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f796f6c6f76373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WongKinYiu/yolov7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2207.02696\" rel=\"nofollow\"\u003eCVPR 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ultralytics/ultralytics\"\u003eYOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6bb27e4c4557560b490abaee8cae2be867468ad0fe3c46ad3d106cbb0ef8766e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f756c7472616c79746963733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6bb27e4c4557560b490abaee8cae2be867468ad0fe3c46ad3d106cbb0ef8766e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f756c7472616c79746963733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ultralytics/ultralytics?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : NEW - YOLOv8 🚀 in PyTorch \u0026gt; ONNX \u0026gt; OpenVINO \u0026gt; CoreML \u0026gt; TFLite. \u003ca href=\"https://docs.ultralytics.com/\" rel=\"nofollow\"\u003edocs.ultralytics.com\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WongKinYiu/yolov9\"\u003eYOLOv9\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/552a3c7c05050b066878c86eb77a49337c9ab68cbbc50a6bd0bf40958c5ae54c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f796f6c6f76393f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/552a3c7c05050b066878c86eb77a49337c9ab68cbbc50a6bd0bf40958c5ae54c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f796f6c6f76393f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WongKinYiu/yolov9?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2402.13616\" rel=\"nofollow\"\u003earXiv 2024\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MultimediaTechLab/YOLO\"\u003eMultimediaTechLab/YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cd2b684efe8400d761a589425755bdb5233b55715b29463d1de538a237f3374c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d756c74696d65646961546563684c61622f594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cd2b684efe8400d761a589425755bdb5233b55715b29463d1de538a237f3374c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d756c74696d65646961546563684c61622f594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MultimediaTechLab/YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO: Official Implementation of YOLOv9, YOLOv7, YOLO-RD. Welcome to the official implementation of YOLOv7 and YOLOv9, YOLO-RD. This repository will contains the complete codebase, pre-trained models, and detailed instructions for training and deploying YOLOv9.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/THU-MIG/yolov10\"\u003eYOLOv10\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/64311ea4b42dfd7858489a772f1384ff46d8a9301ef1ee04b28a38705888e475/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5448552d4d49472f796f6c6f7631303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/64311ea4b42dfd7858489a772f1384ff46d8a9301ef1ee04b28a38705888e475/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5448552d4d49472f796f6c6f7631303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/THU-MIG/yolov10?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOv10: Real-Time End-to-End Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2405.14458v1\" rel=\"nofollow\"\u003earXiv 2024\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ultralytics/ultralytics\"\u003eYOLOv11\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6bb27e4c4557560b490abaee8cae2be867468ad0fe3c46ad3d106cbb0ef8766e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f756c7472616c79746963733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6bb27e4c4557560b490abaee8cae2be867468ad0fe3c46ad3d106cbb0ef8766e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f756c7472616c79746963733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ultralytics/ultralytics?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : NEW - YOLOv8 🚀 in PyTorch \u0026gt; ONNX \u0026gt; OpenVINO \u0026gt; CoreML \u0026gt; TFLite. \u003ca href=\"https://www.ultralytics.com/\" rel=\"nofollow\"\u003eUltralytics\u003c/a\u003e \u003ca href=\"https://github.com/ultralytics/ultralytics\"\u003eYOLOv11\u003c/a\u003e s a cutting-edge, state-of-the-art (SOTA) model that builds upon the success of previous YOLO versions and introduces new features and improvements to further boost performance and flexibility. YOLO11 is designed to be fast, accurate, and easy to use, making it an excellent choice for a wide range of object detection and tracking, instance segmentation, image classification and pose estimation tasks. \u003ca href=\"https://docs.ultralytics.com/\" rel=\"nofollow\"\u003edocs.ultralytics.com\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sunsmarterjie/yolov12\"\u003eYOLOv12\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a1b8c6ac4bef785acb7ab350cf7d86a4033215e711ebe3e87f093ebf1ae06539/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756e736d61727465726a69652f796f6c6f7631323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a1b8c6ac4bef785acb7ab350cf7d86a4033215e711ebe3e87f093ebf1ae06539/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756e736d61727465726a69652f796f6c6f7631323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sunsmarterjie/yolov12?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOv12: Attention-Centric Real-Time Object Detectors\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2502.12524\" rel=\"nofollow\"\u003earXiv 2025\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AILab-CVC/YOLO-World\"\u003eYOLO-World | YOLO-World-v2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4df4362f165830998e6956b59d1a08fcce2aa5a7c5018206bd948a4ecba4e178/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41494c61622d4356432f594f4c4f2d576f726c643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4df4362f165830998e6956b59d1a08fcce2aa5a7c5018206bd948a4ecba4e178/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41494c61622d4356432f594f4c4f2d576f726c643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AILab-CVC/YOLO-World?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLO-World: Real-Time Open-Vocabulary Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2401.17270\" rel=\"nofollow\"\u003eCVPR 2024\u003c/a\u003e\u003c/strong\u003e). \u003ca href=\"https://www.yoloworld.cc/\" rel=\"nofollow\"\u003ewww.yoloworld.cc\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/THU-MIG/yoloe\"\u003eYOLOE\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fcc2b287f618019615847350e34e3ae358e1c4d5c28473bd1fc37089756aec66/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5448552d4d49472f796f6c6f653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fcc2b287f618019615847350e34e3ae358e1c4d5c28473bd1fc37089756aec66/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5448552d4d49472f796f6c6f653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/THU-MIG/yoloe?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOE: Real-Time Seeing Anything\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2503.07465\" rel=\"nofollow\"\u003earXiv 2025\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eExtensional Frameworks\u003c/h3\u003e\u003ca id=\"user-content-extensional-frameworks\" class=\"anchor\" aria-label=\"Permalink: Extensional Frameworks\" href=\"#extensional-frameworks\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/QwenLM/Qwen2.5-VL\"\u003eQwen2.5-VL\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6e720aab8cce54c328ac3bfc79ce069691aa012cee4b48e05bf6eb46cf458839/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5177656e4c4d2f5177656e322d564c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6e720aab8cce54c328ac3bfc79ce069691aa012cee4b48e05bf6eb46cf458839/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5177656e4c4d2f5177656e322d564c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/QwenLM/Qwen2-VL?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Qwen2-VL is the multimodal large language model series developed by Qwen team, Alibaba Cloud. \"Qwen2.5-VL Technical Report\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2502.13923\" rel=\"nofollow\"\u003earXiv 2025\u003c/a\u003e\u003c/strong\u003e). \u003ca href=\"https://qwenlm.github.io/blog/qwen2.5-vl/\" rel=\"nofollow\"\u003e2025-01-26，Qwen2.5 VL! Qwen2.5 VL! Qwen2.5 VL!\u003c/a\u003e. \"Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2409.12191\" rel=\"nofollow\"\u003earXiv 2024\u003c/a\u003e\u003c/strong\u003e). \"Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2308.12966\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MoonshotAI/Kimi-VL\"\u003eKimi-VL\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/011986e97c7e150ec0e2eb40dede4c9cdb464955d869db5de2bca7e86604b65a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f6f6e73686f7441492f4b696d692d564c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/011986e97c7e150ec0e2eb40dede4c9cdb464955d869db5de2bca7e86604b65a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f6f6e73686f7441492f4b696d692d564c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MoonshotAI/Kimi-VL?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Kimi-VL: Mixture-of-Experts Vision-Language Model for Multimodal Reasoning, Long-Context Understanding, and Strong Agent Capabilities. \"Kimi-VL Technical Report\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2504.07491\" rel=\"nofollow\"\u003earXiv 2025\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Liuziyu77/Visual-RFT\"\u003eVisual-RFT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2395d7d5e78f5fcb5b4d1368e3827df4a95489eac47d951f7ca4fd1d045aafbd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c69757a69797537372f56697375616c2d5246543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2395d7d5e78f5fcb5b4d1368e3827df4a95489eac47d951f7ca4fd1d045aafbd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c69757a69797537372f56697375616c2d5246543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Liuziyu77/Visual-RFT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🌈We introduce Visual Reinforcement Fine-tuning (Visual-RFT), the first comprehensive adaptation of Deepseek-R1's RL strategy to the multimodal field. We use the Qwen2-VL-2/7B model as our base model and design a rule-based verifiable reward, which is integrated into a GRPO-based reinforcement fine-tuning framework to enhance the performance of LVLMs across various visual perception tasks. ViRFT extends R1's reasoning capabilities to multiple visual perception tasks, including various detection tasks like Open Vocabulary Detection, Few-shot Detection, Reasoning Grounding, and Fine-grained Image Classification. \"Visual-RFT: Visual Reinforcement Fine-Tuning\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2503.01785\" rel=\"nofollow\"\u003earXiv 2025\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/om-ai-lab/VLM-R1\"\u003eVLM-R1\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8816d165d9d4557df7579f42faae766a69d1fa60febc29cb4ba8f1186a5e0859/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6d2d61692d6c61622f564c4d2d52313f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8816d165d9d4557df7579f42faae766a69d1fa60febc29cb4ba8f1186a5e0859/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6d2d61692d6c61622f564c4d2d52313f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/om-ai-lab/VLM-R1?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : VLM-R1: A stable and generalizable R1-style Large Vision-Language Model. Solve Visual Understanding with Reinforced VLMs. \u003ca href=\"https://om-ai-lab.github.io/2025_03_20.html\" rel=\"nofollow\"\u003e2025-03-20，Improving Object Detection through Reinforcement Learning with VLM-R1\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eFlorence-2 : \"Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2311.06242\" rel=\"nofollow\"\u003eCVPR 2024\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/roboflow/maestro\"\u003emaestro\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3809d33b5bd6d0de50380b668f794c9e27a8d01a46fd303435cf426181fff8f1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626f666c6f772f6d61657374726f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3809d33b5bd6d0de50380b668f794c9e27a8d01a46fd303435cf426181fff8f1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626f666c6f772f6d61657374726f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/roboflow/maestro?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : VLM fine-tuning for everyone. maestro is a streamlined tool to accelerate the fine-tuning of multimodal models. By encapsulating best practices from our core modules, maestro handles configuration, data loading, reproducibility, and training loop setup. It currently offers ready-to-use recipes for popular vision-language models such as \u003ca href=\"https://arxiv.org/abs/2311.06242\" rel=\"nofollow\"\u003eFlorence-2\u003c/a\u003e, PaliGemma 2, and \u003ca href=\"https://github.com/QwenLM/Qwen2.5-VL\"\u003eQwen2.5-VL\u003c/a\u003e. \u003ca href=\"https://maestro.roboflow.com/latest/\" rel=\"nofollow\"\u003emaestro.roboflow.com\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/autodistill/autodistill\"\u003eAutodistill\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c62d847952be21af33a3611f569579505b739360aa218da771156aec4b408990/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6175746f64697374696c6c2f6175746f64697374696c6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c62d847952be21af33a3611f569579505b739360aa218da771156aec4b408990/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6175746f64697374696c6c2f6175746f64697374696c6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/autodistill/autodistill?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Images to inference with no labeling (use foundation models to train supervised models). Autodistill uses big, slower foundation models to train small, faster supervised models. Using autodistill, you can go from unlabeled images to inference on a custom model running at the edge with no human intervention in between. \u003ca href=\"https://docs.autodistill.com/\" rel=\"nofollow\"\u003edocs.autodistill.com\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LSH9832/edgeyolo\"\u003eEdgeYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/71bfe61077c58d0fa253ac07bd7e94e96e3eb3b1b3c7e62400b70a761da7664b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5348393833322f65646765796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/71bfe61077c58d0fa253ac07bd7e94e96e3eb3b1b3c7e62400b70a761da7664b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5348393833322f65646765796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LSH9832/edgeyolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : an edge-real-time anchor-free object detector with decent performance. \"Edge YOLO: Real-time intelligent object detection system based on edge-cloud cooperation in autonomous vehicles\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9740044\" rel=\"nofollow\"\u003eIEEE Transactions on Intelligent Transportation Systems, 2022\u003c/a\u003e\u003c/strong\u003e). \"EdgeYOLO: An Edge-Real-Time Object Detector\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2302.07483\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Megvii-BaseDetection/YOLOX\"\u003eYOLOX\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/216991188cbd256de25dc70a644f6e63b29358e53654f11778585bffd1416da8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d65677669692d42617365446574656374696f6e2f594f4c4f583f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/216991188cbd256de25dc70a644f6e63b29358e53654f11778585bffd1416da8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d65677669692d42617365446574656374696f6e2f594f4c4f583f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Megvii-BaseDetection/YOLOX?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOX: Exceeding YOLO Series in 2021\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2107.08430\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WongKinYiu/yolor\"\u003eYOLOR\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/20cb2135d98c84d6dc559a8fa4a8f4d9e3a383f79393fedf79c391fc755fa8cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f796f6c6f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/20cb2135d98c84d6dc559a8fa4a8f4d9e3a383f79393fedf79c391fc755fa8cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f796f6c6f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WongKinYiu/yolor?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"You Only Learn One Representation: Unified Network for Multiple Tasks\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2105.04206\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/megvii-model/YOLOF\"\u003eYOLOF\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9c9a60bdbf73bf12079a039743429cc3acc217b5f7e914e5e5e867ecd76cc13b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d65677669692d6d6f64656c2f594f4c4f463f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9c9a60bdbf73bf12079a039743429cc3acc217b5f7e914e5e5e867ecd76cc13b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d65677669692d6d6f64656c2f594f4c4f463f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/megvii-model/YOLOF?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"You Only Look One-level Feature\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2021/html/Chen_You_Only_Look_One-Level_Feature_CVPR_2021_paper.html\" rel=\"nofollow\"\u003eCVPR 2021\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hustvl/YOLOS\"\u003eYOLOS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/347d7acb3be34eb896c567936c6a53ba9e26ab0e70a8d4e71157680739694d10/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68757374766c2f594f4c4f533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/347d7acb3be34eb896c567936c6a53ba9e26ab0e70a8d4e71157680739694d10/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68757374766c2f594f4c4f533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hustvl/YOLOS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://proceedings.neurips.cc//paper/2021/hash/dc912a253d1e9ba40e2c597ed2376640-Abstract.html\" rel=\"nofollow\"\u003eNeurIPS 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tinyvision/DAMO-YOLO\"\u003eDAMO-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8dfabfb8ae32aaaf9b6849682e80dba0b7d10fe7b47b2dae00075106167c24c3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74696e79766973696f6e2f44414d4f2d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8dfabfb8ae32aaaf9b6849682e80dba0b7d10fe7b47b2dae00075106167c24c3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74696e79766973696f6e2f44414d4f2d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tinyvision/DAMO-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : DAMO-YOLO: a fast and accurate object detection method with some new techs, including NAS backbones, efficient RepGFPN, ZeroHead, AlignedOTA, and distillation enhancement. \"DAMO-YOLO : A Report on Real-Time Object Detection Design\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2211.15444\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Deci-AI/super-gradients\"\u003eYOLO-NAS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4d0992a13a31e5cf5ec6c1ec57c766f06455bcbf8d951e5a1463cf95dcd3f8e6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f446563692d41492f73757065722d6772616469656e74733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4d0992a13a31e5cf5ec6c1ec57c766f06455bcbf8d951e5a1463cf95dcd3f8e6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f446563692d41492f73757065722d6772616469656e74733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Deci-AI/super-gradients?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Easily train or fine-tune SOTA computer vision models with one open source training library. The home of \u003ca href=\"https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md\"\u003eYolo-NAS\u003c/a\u003e. \u003ca href=\"https://www.supergradients.com/\" rel=\"nofollow\"\u003ewww.supergradients.com\u003c/a\u003e. YOLO-NAS and YOLO-NAS-POSE architectures are out! The new YOLO-NAS delivers state-of-the-art performance with the unparalleled accuracy-speed performance, outperforming other models such as YOLOv5, YOLOv6, YOLOv7 and YOLOv8.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LilianHollard/LeYOLO\"\u003eLeYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6e8a1dc7e95f4d2b716635fe5606df68f9fd5c8b9c84d86a497f47ea6aca4221/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696c69616e486f6c6c6172642f4c65594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6e8a1dc7e95f4d2b716635fe5606df68f9fd5c8b9c84d86a497f47ea6aca4221/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696c69616e486f6c6c6172642f4c65594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LilianHollard/LeYOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"LeYOLO, New Scalable and Efficient CNN Architecture for Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2406.14239\" rel=\"nofollow\"\u003earXiv 2024\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/VDIGPKU/DynamicDet\"\u003eDynamicDet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/faa55adc7dd61e2f19de8e1e13e863a958ea99c650bc4a284f0381af8550b9bb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f56444947504b552f44796e616d69634465743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/faa55adc7dd61e2f19de8e1e13e863a958ea99c650bc4a284f0381af8550b9bb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f56444947504b552f44796e616d69634465743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/VDIGPKU/DynamicDet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"DynamicDet: A Unified Dynamic Architecture for Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2304.05552\" rel=\"nofollow\"\u003eCVPR 2023\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/IDEA-Research/DINO\"\u003eDINO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/17073ac7af4a5232b8652ef3b492f099a110784cc8b717523588714bc6553cb3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f44494e4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/17073ac7af4a5232b8652ef3b492f099a110784cc8b717523588714bc6553cb3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f44494e4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/IDEA-Research/DINO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2203.03605\" rel=\"nofollow\"\u003eICLR 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/IDEA-Research/GroundingDINO\"\u003eGroundingDINO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c6a434d03c84765d1ca6368c83522ccc7b0b5178349b2d0e2de3ef764d9be71e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f47726f756e64696e6744494e4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c6a434d03c84765d1ca6368c83522ccc7b0b5178349b2d0e2de3ef764d9be71e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f47726f756e64696e6744494e4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/IDEA-Research/GroundingDINO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2303.05499\" rel=\"nofollow\"\u003eECCV 2024\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lyuwenyu/RT-DETR\"\u003eRT-DETR | RT-DETRv2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b2943964cc1d38f2ae4eaa2c577a2830fbf2c083628cb5d9d30045ebe9d8ca58/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c797577656e79752f52542d444554523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b2943964cc1d38f2ae4eaa2c577a2830fbf2c083628cb5d9d30045ebe9d8ca58/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c797577656e79752f52542d444554523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lyuwenyu/RT-DETR?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"DETRs Beat YOLOs on Real-time Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2304.08069\" rel=\"nofollow\"\u003eCVPR 2024\u003c/a\u003e\u003c/strong\u003e). \"RT-DETRv2: Improved Baseline with Bag-of-Freebies for Real-Time Detection Transformer\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2407.17140\" rel=\"nofollow\"\u003earXiv 2024\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/alibaba/EasyCV\"\u003eEasyCV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3445dcd3d4af94bc921084370d5ececf1fdc295c61cd9cea76eac458a4937c38/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69626162612f4561737943563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3445dcd3d4af94bc921084370d5ececf1fdc295c61cd9cea76eac458a4937c38/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69626162612f4561737943563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/alibaba/EasyCV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An all-in-one toolkit for computer vision. \"YOLOX-PAI: An Improved YOLOX, Stronger and Faster than YOLOv6\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2208.13040\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dbolya/yolact\"\u003eYOLACT \u0026amp; YOLACT++\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a4f07a5ee346ff8bc58cccce5b08db570e6ef17727e6942901a72acbd0fd8b32/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64626f6c79612f796f6c6163743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a4f07a5ee346ff8bc58cccce5b08db570e6ef17727e6942901a72acbd0fd8b32/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64626f6c79612f796f6c6163743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dbolya/yolact?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : You Only Look At CoefficienTs. (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_ICCV_2019/html/Bolya_YOLACT_Real-Time_Instance_Segmentation_ICCV_2019_paper.html\" rel=\"nofollow\"\u003eICCV 2019\u003c/a\u003e, \u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9159935\" rel=\"nofollow\"\u003eIEEE TPAMI 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Jacobi93/Alpha-IoU\"\u003eAlpha-IoU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0c0ad215c33dafea285b25dbe6c63163bea9a290c31a6b1954ba62346fb93c69/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61636f626939332f416c7068612d496f553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0c0ad215c33dafea285b25dbe6c63163bea9a290c31a6b1954ba62346fb93c69/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61636f626939332f416c7068612d496f553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Jacobi93/Alpha-IoU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Alpha-IoU: A Family of Power Intersection over Union Losses for Bounding Box Regression\". (\u003cstrong\u003e\u003ca href=\"https://proceedings.neurips.cc//paper/2021/hash/a8f15eda80c50adb0e71943adc8015cf-Abstract.html\" rel=\"nofollow\"\u003eNeurIPS 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Zzh-tju/CIoU\"\u003eCIoU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3368cfb8d9c4c09f7dee503476dd80b00371f00c1d5f77c05e63ca11877e52cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a7a682d746a752f43496f553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3368cfb8d9c4c09f7dee503476dd80b00371f00c1d5f77c05e63ca11877e52cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a7a682d746a752f43496f553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Zzh-tju/CIoU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Complete-IoU (CIoU) Loss and Cluster-NMS for Object Detection and Instance Segmentation (YOLACT). (\u003cstrong\u003e\u003ca href=\"https://ojs.aaai.org/index.php/AAAI/article/view/6999\" rel=\"nofollow\"\u003eAAAI 2020\u003c/a\u003e, \u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9523600\" rel=\"nofollow\"\u003eIEEE TCYB 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/albumentations-team/albumentations\"\u003eAlbumentations\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/84c7a1c3a26134634d9163e335f0f5413cc53dd7befcd137da96b91aa7b41ed7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c62756d656e746174696f6e732d7465616d2f616c62756d656e746174696f6e733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/84c7a1c3a26134634d9163e335f0f5413cc53dd7befcd137da96b91aa7b41ed7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c62756d656e746174696f6e732d7465616d2f616c62756d656e746174696f6e733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/albumentations-team/albumentations?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Albumentations is a Python library for image augmentation. Image augmentation is used in deep learning and computer vision tasks to increase the quality of trained models. The purpose of image augmentation is to create new training samples from the existing data. \"Albumentations: Fast and Flexible Image Augmentations\". (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/2078-2489/11/2/125\" rel=\"nofollow\"\u003eInformation 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/doubleZ0108/Data-Augmentation\"\u003edoubleZ0108/Data-Augmentation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/aedc1387893882413eb22185722d1e0516af2d2abf95dde86dfdbe432b0aa677/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f75626c655a303130382f446174612d4175676d656e746174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/aedc1387893882413eb22185722d1e0516af2d2abf95dde86dfdbe432b0aa677/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f75626c655a303130382f446174612d4175676d656e746174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/doubleZ0108/Data-Augmentation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : General Data Augmentation Algorithms for Object Detection(esp. Yolo).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAwesome List\u003c/h3\u003e\u003ca id=\"user-content-awesome-list\" class=\"anchor\" aria-label=\"Permalink: Awesome List\" href=\"#awesome-list\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/coderonion/awesome-yolo-object-detection\"\u003eawesome-yolo-object-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/377d1f49944e12ae91ac2b8d6d391f35f2d5a51d89400d4dd563a5c080336f69/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636f6465726f6e696f6e2f617765736f6d652d796f6c6f2d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/377d1f49944e12ae91ac2b8d6d391f35f2d5a51d89400d4dd563a5c080336f69/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636f6465726f6e696f6e2f617765736f6d652d796f6c6f2d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/coderonion/awesome-yolo-object-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🚀🚀🚀 A collection of some awesome public YOLO object detection series projects and the related object detection datasets.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/srebroa/awesome-yolo\"\u003esrebroa/awesome-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/724ab0f93c843e89419702d529be92bf0f7b53b9d48460675c17751aae4faedb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73726562726f612f617765736f6d652d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/724ab0f93c843e89419702d529be92bf0f7b53b9d48460675c17751aae4faedb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73726562726f612f617765736f6d652d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/srebroa/awesome-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🚀 ⭐ The list of the most popular YOLO algorithms - awesome YOLO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Bubble-water/YOLO-Summary\"\u003eBubble-water/YOLO-Summary\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d081d0e1f4038de91235e244a323df1bdf6b078dcf737287f1c122c305db51a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427562626c652d77617465722f594f4c4f2d53756d6d6172793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d081d0e1f4038de91235e244a323df1bdf6b078dcf737287f1c122c305db51a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427562626c652d77617465722f594f4c4f2d53756d6d6172793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Bubble-water/YOLO-Summary?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO-Summary.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WZMIAOMIAO/deep-learning-for-image-processing\"\u003eWZMIAOMIAO/deep-learning-for-image-processing\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7f11beb96be0cfc8857720624fd199880e4477cb7f9f5811fabe17ff54d7f2af/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f575a4d49414f4d49414f2f646565702d6c6561726e696e672d666f722d696d6167652d70726f63657373696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7f11beb96be0cfc8857720624fd199880e4477cb7f9f5811fabe17ff54d7f2af/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f575a4d49414f4d49414f2f646565702d6c6561726e696e672d666f722d696d6167652d70726f63657373696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WZMIAOMIAO/deep-learning-for-image-processing?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : deep learning for image processing including classification and object-detection etc.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hoya012/deep_learning_object_detection\"\u003ehoya012/deep_learning_object_detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9349f1faf0da185bc9b83f62e68ffabde3a4a0aab0d6b49829882e2dab44e742/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686f79613031322f646565705f6c6561726e696e675f6f626a6563745f646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9349f1faf0da185bc9b83f62e68ffabde3a4a0aab0d6b49829882e2dab44e742/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686f79613031322f646565705f6c6561726e696e675f6f626a6563745f646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hoya012/deep_learning_object_detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A paper list of object detection using deep learning.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/amusi/awesome-object-detection\"\u003eamusi/awesome-object-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6e9636458085dc930d3d5a5140c699078bd6b7a65b54ccdc4814b63e3d3c13a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616d7573692f617765736f6d652d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6e9636458085dc930d3d5a5140c699078bd6b7a65b54ccdc4814b63e3d3c13a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616d7573692f617765736f6d652d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/amusi/awesome-object-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Awesome Object Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wenhwu/awesome-remote-sensing-change-detection\"\u003ewenhwu/awesome-remote-sensing-change-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/eed43edb355781cc4ca200cac9a1a20ecb2083dd4f0ef636a90d7db00832b941/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77656e6877752f617765736f6d652d72656d6f74652d73656e73696e672d6368616e67652d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/eed43edb355781cc4ca200cac9a1a20ecb2083dd4f0ef636a90d7db00832b941/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77656e6877752f617765736f6d652d72656d6f74652d73656e73696e672d6368616e67652d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wenhwu/awesome-remote-sensing-change-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : List of datasets, codes, and contests related to remote sensing change detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZHOUYI1023/awesome-radar-perception\"\u003eZHOUYI1023/awesome-radar-perception\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/88bc43d1844827affdbec130d7bb7be5e8fabc9127e798769ce6e241bbe1c7eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a484f555949313032332f617765736f6d652d72616461722d70657263657074696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/88bc43d1844827affdbec130d7bb7be5e8fabc9127e798769ce6e241bbe1c7eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a484f555949313032332f617765736f6d652d72616461722d70657263657074696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZHOUYI1023/awesome-radar-perception?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A curated list of radar datasets, detection, tracking and fusion.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lartpang/awesome-segmentation-saliency-dataset\"\u003elartpang/awesome-segmentation-saliency-dataset\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c035757b237ca395e7dac9783bee601ac2ca4a5eed89bee8fea8cf4566ba1ef6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c61727470616e672f617765736f6d652d7365676d656e746174696f6e2d73616c69656e63792d646174617365743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c035757b237ca395e7dac9783bee601ac2ca4a5eed89bee8fea8cf4566ba1ef6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c61727470616e672f617765736f6d652d7365676d656e746174696f6e2d73616c69656e63792d646174617365743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lartpang/awesome-segmentation-saliency-dataset?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A collection of some datasets for segmentation / saliency detection. Welcome to PR...😄\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TianhaoFu/Awesome-3D-Object-Detection\"\u003eTianhaoFu/Awesome-3D-Object-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7dc16b6262845f3865de1ef9718e8d3cd1c0414904b5e2cada41b244e5cd8ba1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5469616e68616f46752f417765736f6d652d33442d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7dc16b6262845f3865de1ef9718e8d3cd1c0414904b5e2cada41b244e5cd8ba1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5469616e68616f46752f417765736f6d652d33442d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TianhaoFu/Awesome-3D-Object-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Papers, code and datasets about deep learning for 3D Object Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xahidbuffon/Awesome_Underwater_Datasets\"\u003exahidbuffon/Awesome_Underwater_Datasets\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4591d28cdd67c513aea7f3158368e5fa74e870b7f3cb3a87b097ef33b9da6cad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7861686964627566666f6e2f417765736f6d655f556e64657277617465725f44617461736574733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4591d28cdd67c513aea7f3158368e5fa74e870b7f3cb3a87b097ef33b9da6cad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7861686964627566666f6e2f417765736f6d655f556e64657277617465725f44617461736574733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xahidbuffon/Awesome_Underwater_Datasets?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Pointers to large-scale underwater datasets and relevant resources.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/M-3LAB/awesome-industrial-anomaly-detection\"\u003eM-3LAB/awesome-industrial-anomaly-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4372d545ef3fc9c34e94cfa7c61d0f73bf9d4d46315d0058e52472723cb63944/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d2d334c41422f617765736f6d652d696e647573747269616c2d616e6f6d616c792d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4372d545ef3fc9c34e94cfa7c61d0f73bf9d4d46315d0058e52472723cb63944/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d2d334c41422f617765736f6d652d696e647573747269616c2d616e6f6d616c792d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/M-3LAB/awesome-industrial-anomaly-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Paper list and datasets for industrial image anomaly detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZhangXiwuu/Awesome_visual_place_recognition_datasets\"\u003eZhangXiwuu/Awesome_visual_place_recognition_datasets\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/16016d9428686e8f3df06a31308424acc381bce75c81719748c7c18c4dbb2f94/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68616e6758697775752f417765736f6d655f76697375616c5f706c6163655f7265636f676e6974696f6e5f64617461736574733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/16016d9428686e8f3df06a31308424acc381bce75c81719748c7c18c4dbb2f94/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68616e6758697775752f417765736f6d655f76697375616c5f706c6163655f7265636f676e6974696f6e5f64617461736574733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZhangXiwuu/Awesome_visual_place_recognition_datasets?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A curated list of Visual Place Recognition (VPR)/ loop closure detection (LCD) datasets.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ari-dasci/OD-WeaponDetection\"\u003eari-dasci/OD-WeaponDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/29705b459f69572b02f1764d521d865d3a666dd10b16fd9994e5c8e9ca6f2a5d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6172692d64617363692f4f442d576561706f6e446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/29705b459f69572b02f1764d521d865d3a666dd10b16fd9994e5c8e9ca6f2a5d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6172692d64617363692f4f442d576561706f6e446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ari-dasci/OD-WeaponDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Datasets for weapon detection based on image classification and object detection tasks.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DLLXW/objectDetectionDatasets\"\u003eDLLXW/objectDetectionDatasets\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4b4df4c1c3971195413d2bbac64bafd9b627c3473eb640463d4a7996b722cfc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f444c4c58572f6f626a656374446574656374696f6e44617461736574733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4b4df4c1c3971195413d2bbac64bafd9b627c3473eb640463d4a7996b722cfc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f444c4c58572f6f626a656374446574656374696f6e44617461736574733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DLLXW/objectDetectionDatasets?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 目标检测数据集制作:VOC,COCO,YOLO等常用数据集格式的制作和互相转换脚本。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kuanhungchen/awesome-tiny-object-detection\"\u003ekuanhungchen/awesome-tiny-object-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5fd97e6d91205d05f25576b2ba586ced359183f03d8cea339ce1caaa844ffa7e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b75616e68756e676368656e2f617765736f6d652d74696e792d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5fd97e6d91205d05f25576b2ba586ced359183f03d8cea339ce1caaa844ffa7e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b75616e68756e676368656e2f617765736f6d652d74696e792d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kuanhungchen/awesome-tiny-object-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🕶 A curated list of Tiny Object Detection papers and related resources.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003ePaper and Code Overview\u003c/h3\u003e\u003ca id=\"user-content-paper-and-code-overview\" class=\"anchor\" aria-label=\"Permalink: Paper and Code Overview\" href=\"#paper-and-code-overview\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003ePaper Review\u003c/h4\u003e\u003ca id=\"user-content-paper-review\" class=\"anchor\" aria-label=\"Permalink: Paper Review\" href=\"#paper-review\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/52CV/CV-Surveys\"\u003e52CV/CV-Surveys\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/eb09ce4cf38b11697a8137ec0baef98404acce18f4a18555747281f7a114ee19/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f353243562f43562d537572766579733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/eb09ce4cf38b11697a8137ec0baef98404acce18f4a18555747281f7a114ee19/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f353243562f43562d537572766579733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/52CV/CV-Surveys?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 计算机视觉相关综述。包括目标检测、跟踪........\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/GreenTeaHua/YOLO-Review\"\u003eGreenTeaHua/YOLO-Review\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b59ae77c526e1e56a8890a0e797315e305d2604982440d24d22aa8e420a9b5ee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f477265656e5465614875612f594f4c4f2d5265766965773f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b59ae77c526e1e56a8890a0e797315e305d2604982440d24d22aa8e420a9b5ee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f477265656e5465614875612f594f4c4f2d5265766965773f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/GreenTeaHua/YOLO-Review?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"A Review of YOLO Object Detection Based on Deep Learning\". \"基于深度学习的YOLO目标检测综述\". (\u003cstrong\u003e\u003ca href=\"https://jeit.ac.cn/cn/article/doi/10.11999/JEIT210790\" rel=\"nofollow\"\u003eJournal of Electronics \u0026amp; Information Technology 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Review of Yolo Algorithm Developments\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/pii/S1877050922001363\" rel=\"nofollow\"\u003eProcedia Computer Science 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCode Review\u003c/h4\u003e\u003ca id=\"user-content-code-review\" class=\"anchor\" aria-label=\"Permalink: Code Review\" href=\"#code-review\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/iscyy/ultralyticsPro\"\u003eiscyy/ultralyticsPro\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6d01496969abb44c68a3238a64e904327ef4ec2629829088a7ddbea2f21c4e55/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736379792f756c7472616c797469637350726f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6d01496969abb44c68a3238a64e904327ef4ec2629829088a7ddbea2f21c4e55/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736379792f756c7472616c797469637350726f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/iscyy/ultralyticsPro?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🔥🔥🔥 专注于YOLO11，YOLOv8、YOLOv10、RT-DETR、YOLOv7、YOLOv5改进模型，Support to improve backbone, neck, head, loss, IoU, NMS and other modules🚀\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/open-mmlab/mmdetection\"\u003eMMDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/68b0f0a824d1ce240275fa6f85668a366029403a575fc71d41dfdccc91ae97e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d6d6d6c61622f6d6d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/68b0f0a824d1ce240275fa6f85668a366029403a575fc71d41dfdccc91ae97e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d6d6d6c61622f6d6d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/open-mmlab/mmdetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : OpenMMLab Detection Toolbox and Benchmark. \u003ca href=\"https://mmdetection.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003emmdetection.readthedocs.io\u003c/a\u003e. (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1906.07155\" rel=\"nofollow\"\u003earXiv 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/open-mmlab/mmyolo\"\u003eMMYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/34ba85ba06312ee3826006deb4ada6bbd8581b3110b169040a42119ae1ec6ff8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d6d6d6c61622f6d6d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/34ba85ba06312ee3826006deb4ada6bbd8581b3110b169040a42119ae1ec6ff8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d6d6d6c61622f6d6d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/open-mmlab/mmyolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : OpenMMLab YOLO series toolbox and benchmark. Implemented RTMDet, RTMDet-Rotated,YOLOv5, YOLOv6, YOLOv7, YOLOv8, YOLOX, PPYOLOE, etc. \u003ca href=\"https://mmyolo.readthedocs.io/zh_CN/dev/\" rel=\"nofollow\"\u003emmyolo.readthedocs.io/zh_CN/dev/\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/iscyy/yoloair\"\u003eiscyy/yoloair\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/adc54b3a08544f8ec2661f6cd4aad8c8272ebf67a92d46ba7a7b8d32f53ec32c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736379792f796f6c6f6169723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/adc54b3a08544f8ec2661f6cd4aad8c8272ebf67a92d46ba7a7b8d32f53ec32c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736379792f796f6c6f6169723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/iscyy/yoloair?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e :  🔥🔥🔥 专注于YOLO改进模型，Support to improve backbone, neck, head, loss, IoU, NMS and other modules🚀.  YOLOAir是一个基于PyTorch的YOLO算法库。统一模型代码框架、统一应用、统一改进、易于模块组合、构建更强大的网络模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/iscyy/yoloair2\"\u003eiscyy/yoloair2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4e4c4e9554309946c83078ee2fa6da80171eb7c286d65f25bdad06aeec4c0a1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736379792f796f6c6f616972323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4e4c4e9554309946c83078ee2fa6da80171eb7c286d65f25bdad06aeec4c0a1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736379792f796f6c6f616972323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/iscyy/yoloair2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ☁️💡🎈专注于改进YOLOv7，Support to improve Backbone, Neck, Head, Loss, IoU, NMS and other modules.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jizhishutong/YOLOU\"\u003ejizhishutong/YOLOU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/059c9754a72d6a1247c0e4b9c325c7285f47a7691f971348a3761ad717dfdea4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a697a6869736875746f6e672f594f4c4f553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/059c9754a72d6a1247c0e4b9c325c7285f47a7691f971348a3761ad717dfdea4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a697a6869736875746f6e672f594f4c4f553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jizhishutong/YOLOU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOU：United, Study and easier to Deploy. ​ The purpose of our creation of YOLOU is to better learn the algorithms of the YOLO series and pay tribute to our predecessors. YOLOv3、YOLOv4、YOLOv5、YOLOv5-Lite、YOLOv6-v1、YOLOv6-v2、YOLOv7、YOLOX、YOLOX-Lite、PP-YOLOE、PP-PicoDet-Plus、YOLO-Fastest v2、FastestDet、YOLOv5-SPD、TensorRT、NCNN、Tengine、OpenVINO. \"微信公众号「集智书童」《\u003ca href=\"https://mp.weixin.qq.com/s/clupheQ8iHnhR4FJcTtB8A\" rel=\"nofollow\"\u003eYOLOU开源 | 汇集YOLO系列所有算法，集算法学习、科研改进、落地于一身！\u003c/a\u003e》\"\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WangQvQ/Yolov5_Magic\"\u003eWangQvQ/Yolov5_Magic\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6a53bdbd6908292149e6bc0486cc3316c7f96751285a06da4c7c35c59b905614/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57616e675176512f596f6c6f76355f4d616769633f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6a53bdbd6908292149e6bc0486cc3316c7f96751285a06da4c7c35c59b905614/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57616e675176512f596f6c6f76355f4d616769633f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WangQvQ/Yolov5_Magic?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO Magic🪄 is an extension based on Ultralytics' YOLOv5, designed to provide more powerful functionality and simpler operations for visual tasks.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/positive666/yolo_research\"\u003epositive666/yolo_research\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/622bcf1d418489bfeff1f8aebacaa24c2407b169dd2cf1d1f86332ad846d8eef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706f7369746976653636362f796f6c6f5f72657365617263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/622bcf1d418489bfeff1f8aebacaa24c2407b169dd2cf1d1f86332ad846d8eef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706f7369746976653636362f796f6c6f5f72657365617263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/positive666/yolo_research?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🚀 yolo_reserach PLUS High-level. based on yolo-high-level project (detect\\pose\\classify\\segment):include yolov5\\yolov7\\yolov8\\ core ,improvement research ,SwintransformV2 and Attention Series. training skills, business customization, engineering deployment.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/augmentedstartups/AS-One\"\u003eaugmentedstartups/AS-One\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6c30868bf4a2fceebc83e072fe0a1933d2c90c5258215015151aaa44208e40b9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6175676d656e74656473746172747570732f41532d4f6e653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6c30868bf4a2fceebc83e072fe0a1933d2c90c5258215015151aaa44208e40b9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6175676d656e74656473746172747570732f41532d4f6e653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/augmentedstartups/AS-One?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Easy \u0026amp; Modular Computer Vision Detectors and Trackers - Run YOLO-NAS,v8,v7,v6,v5,R,X in under 20 lines of code. \u003ca href=\"https://www.augmentedstartups.com/\" rel=\"nofollow\"\u003ewww.augmentedstartups.com\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Oneflow-Inc/one-yolov5\"\u003eOneflow-Inc/one-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fa7664fba082b62f6752d4cb5761754274b55f55050dfbf7434ae8c4da05917b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f6e65666c6f772d496e632f6f6e652d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fa7664fba082b62f6752d4cb5761754274b55f55050dfbf7434ae8c4da05917b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f6e65666c6f772d496e632f6f6e652d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Oneflow-Inc/one-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A more efficient yolov5 with oneflow backend 🎉🎉🎉. \"微信公众号「GiantPandaCV」《\u003ca href=\"https://mp.weixin.qq.com/s/tZ7swUd0biz7G3CiRkHHfw\" rel=\"nofollow\"\u003eOne-YOLOv5 发布，一个训得更快的YOLOv5\u003c/a\u003e》\"\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PaddlePaddle/PaddleYOLO\"\u003ePaddlePaddle/PaddleYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7490811b89217d604dd745686ec5add19fd81867c35e39759c4ab3fed6f4af51/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506164646c65506164646c652f506164646c65594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7490811b89217d604dd745686ec5add19fd81867c35e39759c4ab3fed6f4af51/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506164646c65506164646c652f506164646c65594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PaddlePaddle/PaddleYOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e :  🚀🚀🚀 YOLO series of PaddlePaddle implementation, PP-YOLOE+, YOLOv5, YOLOv6, YOLOv7, YOLOv8, YOLOX, YOLOv5u, YOLOv7u, RTMDet and so on. 🚀🚀🚀\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WangRongsheng/BestYOLO\"\u003eWangRongsheng/BestYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/00820d416a522d8a518f3ddb65865b908ee5cff45e0d0cf6a7980f1fe41d61e7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57616e67526f6e677368656e672f42657374594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/00820d416a522d8a518f3ddb65865b908ee5cff45e0d0cf6a7980f1fe41d61e7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57616e67526f6e677368656e672f42657374594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WangRongsheng/BestYOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🌟Change the world, it will become a better place. | 以科研和竞赛为导向的最好的YOLO实践框架!\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/KangChou/Cver4s\"\u003eKangChou/Cver4s\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/891996f8706a2763832f55c1f346db73104125f379f7dc661cf32b60028cc60a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b616e6743686f752f4376657234733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/891996f8706a2763832f55c1f346db73104125f379f7dc661cf32b60028cc60a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b616e6743686f752f4376657234733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/KangChou/Cver4s?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Cver4s：Computer vision algorithm code base.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/chaizwj/yolov8-tricks\"\u003echaizwj/yolov8-tricks\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/57a68f7c830ecae585ef2ce17ac89a66a117da5b84a34d74cee6dcd16e5d9462/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636861697a776a2f796f6c6f76382d747269636b733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/57a68f7c830ecae585ef2ce17ac89a66a117da5b84a34d74cee6dcd16e5d9462/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636861697a776a2f796f6c6f76382d747269636b733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/chaizwj/yolov8-tricks?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 目标检测，采用yolov8作为基准模型，数据集采用VisDrone2019，带有自己的改进策略。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eLearning Resources\u003c/h3\u003e\u003ca id=\"user-content-learning-resources\" class=\"anchor\" aria-label=\"Permalink: Learning Resources\" href=\"#learning-resources\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zjhellofss/KuiperLLama\"\u003ezjhellofss/KuiperLLama\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5212ed716985c6e41ef7d711ed09c3e6855b657e005ea3df8cd3ea4890eda4f9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6a68656c6c6f6673732f4b75697065724c4c616d613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5212ed716985c6e41ef7d711ed09c3e6855b657e005ea3df8cd3ea4890eda4f9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6a68656c6c6f6673732f4b75697065724c4c616d613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zjhellofss/KuiperLLama?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 《动手自制大模型推理框架》。KuiperLLama 动手自制大模型推理框架，支持LLama2/3和Qwen2.5。校招、秋招、春招、实习好项目，带你从零动手实现支持LLama2/3和Qwen2.5的大模型推理框架。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zjhellofss/KuiperInfer\"\u003ezjhellofss/KuiperInfer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e9cd23e1eff9e7eead1a60c5c66096068e0f160ec20ed0c00193632818dc2015/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6a68656c6c6f6673732f4b7569706572496e6665723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e9cd23e1eff9e7eead1a60c5c66096068e0f160ec20ed0c00193632818dc2015/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6a68656c6c6f6673732f4b7569706572496e6665723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zjhellofss/KuiperInfer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e :  校招、秋招、春招、实习好项目！带你从零实现一个高性能的深度学习推理库，支持大模型 llama2 、Unet、Yolov5、Resnet等模型的推理。Implement a high-performance deep learning inference library step by step。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zjhellofss/kuiperdatawhale\"\u003ezjhellofss/kuiperdatawhale\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7341ac9e9134db02f63d20da1182e309b62a51871d3a8c69980b2bc34991bea8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6a68656c6c6f6673732f6b7569706572646174617768616c653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7341ac9e9134db02f63d20da1182e309b62a51871d3a8c69980b2bc34991bea8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6a68656c6c6f6673732f6b7569706572646174617768616c653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zjhellofss/kuiperdatawhale?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e :  从零自制深度学习推理框架。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/roboflow/notebooks\"\u003eroboflow/notebooks\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cb8994cf72ba32b952ddded301356528f716f6dba2ce810c773f2e3bc533859e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626f666c6f772f6e6f7465626f6f6b733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cb8994cf72ba32b952ddded301356528f716f6dba2ce810c773f2e3bc533859e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626f666c6f772f6e6f7465626f6f6b733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/roboflow/notebooks?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Examples and tutorials on using SOTA computer vision models and techniques. Learn everything from old-school ResNet, through YOLO and object-detection transformers like DETR, to the latest models like Grounding DINO and SAM. \u003ca href=\"https://roboflow.com/models\" rel=\"nofollow\"\u003eroboflow.com/models\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yjh0410/PyTorch_YOLO_Tutorial\"\u003eyjh0410/PyTorch_YOLO_Tutorial\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/39ad804ea20036f1b93159bc1f54e8793a6d4abfb5aafb74d9977f11ba4824a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796a68303431302f5079546f7263685f594f4c4f5f5475746f7269616c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/39ad804ea20036f1b93159bc1f54e8793a6d4abfb5aafb74d9977f11ba4824a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796a68303431302f5079546f7263685f594f4c4f5f5475746f7269616c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yjh0410/PyTorch_YOLO_Tutorial?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO Tutorial.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HuKai97/yolov5-5.x-annotations\"\u003eHuKai97/yolov5-5.x-annotations\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9dabbaa442203ffb7526d4105433f855239b300c904eb0b034a570b8ccd231f7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48754b616939372f796f6c6f76352d352e782d616e6e6f746174696f6e733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9dabbaa442203ffb7526d4105433f855239b300c904eb0b034a570b8ccd231f7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48754b616939372f796f6c6f76352d352e782d616e6e6f746174696f6e733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HuKai97/yolov5-5.x-annotations?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 一个基于yolov5-5.0的中文注释版本！\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/crkk-feng/yolov5-annotations\"\u003ecrkk-feng/yolov5-annotations\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3fed56cd3b40eaaa25505f01ade279f8052657dba27feef4481c9bae2b57aaec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63726b6b2d66656e672f796f6c6f76352d616e6e6f746174696f6e733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3fed56cd3b40eaaa25505f01ade279f8052657dba27feef4481c9bae2b57aaec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63726b6b2d66656e672f796f6c6f76352d616e6e6f746174696f6e733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/crkk-feng/yolov5-annotations?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Chinese annotated version of yolov5-5.0.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/XiaoJiNu/yolov5-v6-chinese-comment\"\u003eXiaoJiNu/yolov5-v6-chinese-comment\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c19f4e5b4f5c55dab862a9ae4e58e358ba2ff4af130303190197d53d8aee131a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5869616f4a694e752f796f6c6f76352d76362d6368696e6573652d636f6d6d656e743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c19f4e5b4f5c55dab862a9ae4e58e358ba2ff4af130303190197d53d8aee131a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5869616f4a694e752f796f6c6f76352d76362d6368696e6573652d636f6d6d656e743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/XiaoJiNu/yolov5-v6-chinese-comment?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5-v6版本注释。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/1131624548/About-YOLOv5-7-0\"\u003e1131624548/About-YOLOv5-7-0\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c19f4e5b4f5c55dab862a9ae4e58e358ba2ff4af130303190197d53d8aee131a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5869616f4a694e752f796f6c6f76352d76362d6368696e6573652d636f6d6d656e743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c19f4e5b4f5c55dab862a9ae4e58e358ba2ff4af130303190197d53d8aee131a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5869616f4a694e752f796f6c6f76352d76362d6368696e6573652d636f6d6d656e743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/XiaoJiNu/yolov5-v6-chinese-comment?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5代码注释。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zyds/yolov5-code\"\u003ezyds/yolov5-code\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/361aa9c52b30699bb408461dcdef61f59bacdc38a087a45dbb091f4a0ab6f146/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a7964732f796f6c6f76352d636f64653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/361aa9c52b30699bb408461dcdef61f59bacdc38a087a45dbb091f4a0ab6f146/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a7964732f796f6c6f76352d636f64653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zyds/yolov5-code?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 手把手带你实战 YOLOv5。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOther Versions of YOLO\u003c/h2\u003e\u003ca id=\"user-content-other-versions-of-yolo\" class=\"anchor\" aria-label=\"Permalink: Other Versions of YOLO\" href=\"#other-versions-of-yolo\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003ePyTorch Implementation\u003c/h3\u003e\u003ca id=\"user-content-pytorch-implementation\" class=\"anchor\" aria-label=\"Permalink: PyTorch Implementation\" href=\"#pytorch-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ultralytics/yolov3\"\u003eultralytics/yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/44655dae6444f06099d49af479b703057e872b1788dbf203320973ccfc3bd8c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/44655dae6444f06099d49af479b703057e872b1788dbf203320973ccfc3bd8c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ultralytics/yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv3 in PyTorch \u0026gt; ONNX \u0026gt; CoreML \u0026gt; TFLite.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/eriklindernoren/PyTorch-YOLOv3\"\u003eeriklindernoren/PyTorch-YOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3f74a8c3afca8e564692352d407b24d68569d4474f1cbbc1d56272171b23b4bf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6572696b6c696e6465726e6f72656e2f5079546f7263682d594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3f74a8c3afca8e564692352d407b24d68569d4474f1cbbc1d56272171b23b4bf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6572696b6c696e6465726e6f72656e2f5079546f7263682d594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/eriklindernoren/PyTorch-YOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Minimal PyTorch implementation of YOLOv3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Tianxiaomo/pytorch-YOLOv4\"\u003eTianxiaomo/pytorch-YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f94e89a828ca1f02070ea64baac3d775db42b3e9c89950f0b9cbd7065b1d9756/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5469616e7869616f6d6f2f7079746f7263682d594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f94e89a828ca1f02070ea64baac3d775db42b3e9c89950f0b9cbd7065b1d9756/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5469616e7869616f6d6f2f7079746f7263682d594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Tianxiaomo/pytorch-YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PyTorch ,ONNX and TensorRT implementation of YOLOv4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ayooshkathuria/pytorch-yolo-v3\"\u003eayooshkathuria/pytorch-yolo-v3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/baa9aecc5f7ccd64dbc0bcc9f679d64cd358e350e389f7c77e0d37f7ece106d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61796f6f73686b617468757269612f7079746f7263682d796f6c6f2d76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/baa9aecc5f7ccd64dbc0bcc9f679d64cd358e350e389f7c77e0d37f7ece106d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61796f6f73686b617468757269612f7079746f7263682d796f6c6f2d76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ayooshkathuria/pytorch-yolo-v3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A PyTorch implementation of the YOLO v3 object detection algorithm.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WongKinYiu/PyTorch_YOLOv4\"\u003eWongKinYiu/PyTorch_YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8c83f25931194dc8d66ccd01a9be4dd983a79e78a479e4b1c0e24cf51f3a482f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f5079546f7263685f594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8c83f25931194dc8d66ccd01a9be4dd983a79e78a479e4b1c0e24cf51f3a482f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6e674b696e5969752f5079546f7263685f594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WongKinYiu/PyTorch_YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PyTorch implementation of YOLOv4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/argusswift/YOLOv4-pytorch\"\u003eargusswift/YOLOv4-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4ce17ce776f831b8e765de204974d7ce80aee5689571a742721b15cfa8ecd96d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f617267757373776966742f594f4c4f76342d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4ce17ce776f831b8e765de204974d7ce80aee5689571a742721b15cfa8ecd96d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f617267757373776966742f594f4c4f76342d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/argusswift/YOLOv4-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a pytorch repository of YOLOv4, attentive YOLOv4 and mobilenet YOLOv4 with PASCAL VOC and COCO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/longcw/yolo2-pytorch\"\u003elongcw/yolo2-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5ec74205ee239587cb6fa9a827ab08816e5069a20d02fee3e555ccfa16ea93a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6f6e6763772f796f6c6f322d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5ec74205ee239587cb6fa9a827ab08816e5069a20d02fee3e555ccfa16ea93a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6f6e6763772f796f6c6f322d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/longcw/yolo2-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv2 in PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolov5-v6.1-pytorch\"\u003ebubbliiiing/yolov5-v6.1-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/68541ded34bcce0941bc17e8f791365f238e29c7409eed9eb299d844874a0a51/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76352d76362e312d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/68541ded34bcce0941bc17e8f791365f238e29c7409eed9eb299d844874a0a51/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76352d76362e312d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolov5-v6.1-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 这是一个yolov5-v6.1-pytorch的源码，可以用于训练自己的模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolov5-pytorch\"\u003ebubbliiiing/yolov5-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3053e9842fce22410150493f549498b5de3fdfb3d0855408130b07d68d87a6ef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76352d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3053e9842fce22410150493f549498b5de3fdfb3d0855408130b07d68d87a6ef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76352d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolov5-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 这是一个YoloV5-pytorch的源码，可以用于训练自己的模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolov4-pytorch\"\u003ebubbliiiing/yolov4-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8b1c600e28be1130691c9f2288931e2bff61776360c49cd98ffc38fe2bccf754/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8b1c600e28be1130691c9f2288931e2bff61776360c49cd98ffc38fe2bccf754/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolov4-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 这是一个YoloV4-pytorch的源码，可以用于训练自己的模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolov4-tiny-pytorch\"\u003ebubbliiiing/yolov4-tiny-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/16431511267815a921e695e10edf354293821f5ca489f930f759dcd59059882f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d74696e792d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/16431511267815a921e695e10edf354293821f5ca489f930f759dcd59059882f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d74696e792d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolov4-tiny-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 这是一个YoloV4-tiny-pytorch的源码，可以用于训练自己的模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolo3-pytorch\"\u003ebubbliiiing/yolov3-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6aecda4076791858a1db686ce593409e1206bfb3be2d28850b6a1b62106641cc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f332d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6aecda4076791858a1db686ce593409e1206bfb3be2d28850b6a1b62106641cc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f332d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolo3-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 这是一个yolo3-pytorch的源码，可以用于训练自己的模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolox-pytorch\"\u003ebubbliiiing/yolox-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/45fdcbb6394df9bc3b0ba4b9bfa15e750a80b28a2ebf6df788455c7c3c12c0dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f782d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/45fdcbb6394df9bc3b0ba4b9bfa15e750a80b28a2ebf6df788455c7c3c12c0dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f782d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolox-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 这是一个yolox-pytorch的源码，可以用于训练自己的模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolov7-pytorch\"\u003ebubbliiiing/yolov7-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/31c2ce36ddd31aa1c2ef2858f0b74c15dadfef5f1b8aa6f85419ad4ba80ddaad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76372d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/31c2ce36ddd31aa1c2ef2858f0b74c15dadfef5f1b8aa6f85419ad4ba80ddaad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76372d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolov7-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 这是一个yolov7的库，可以用于训练自己的数据集。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolov8-pytorch\"\u003ebubbliiiing/yolov8-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ff03fdb0b8ec2d15ad8780402bead449ba969b96de4035b2a64a26630fa560c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76382d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ff03fdb0b8ec2d15ad8780402bead449ba969b96de4035b2a64a26630fa560c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76382d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolov8-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 这是一个yolov8-pytorch的仓库，可以用于训练自己的数据集。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BobLiu20/YOLOv3_PyTorch\"\u003eBobLiu20/YOLOv3_PyTorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a45978c36c92a780fa61815230f80c631d591952c4997c60043c16130a77d033/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f624c697532302f594f4c4f76335f5079546f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a45978c36c92a780fa61815230f80c631d591952c4997c60043c16130a77d033/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f624c697532302f594f4c4f76335f5079546f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BobLiu20/YOLOv3_PyTorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Full implementation of YOLOv3 in PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ruiminshen/yolo2-pytorch\"\u003eruiminshen/yolo2-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3a4a4d09616743257c41e4b726aba03d4c177414202ef102f17faf92386a18f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7275696d696e7368656e2f796f6c6f322d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3a4a4d09616743257c41e4b726aba03d4c177414202ef102f17faf92386a18f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7275696d696e7368656e2f796f6c6f322d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ruiminshen/yolo2-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PyTorch implementation of the YOLO (You Only Look Once) v2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DeNA/PyTorch_YOLOv3\"\u003eDeNA/PyTorch_YOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/dadcff9db8d2f628cafbe001d29be7b24b885d0f7c75c96d986cb1df4166b58f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44654e412f5079546f7263685f594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dadcff9db8d2f628cafbe001d29be7b24b885d0f7c75c96d986cb1df4166b58f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44654e412f5079546f7263685f594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DeNA/PyTorch_YOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Implementation of YOLOv3 in PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/abeardear/pytorch-YOLO-v1\"\u003eabeardear/pytorch-YOLO-v1\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/960b32d1196262580ea14d23b5f3eebbe8b595e279bd456a0befe041e79d3831/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6162656172646561722f7079746f7263682d594f4c4f2d76313f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/960b32d1196262580ea14d23b5f3eebbe8b595e279bd456a0befe041e79d3831/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6162656172646561722f7079746f7263682d594f4c4f2d76313f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/abeardear/pytorch-YOLO-v1?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : an experiment for yolo-v1, including training and testing.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wuzhihao7788/yolodet-pytorch\"\u003ewuzhihao7788/yolodet-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/255e3f7334505e87fe9e4ee2f37f477e3ec1a4ca2d57962a614f9f85318117fc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77757a686968616f373738382f796f6c6f6465742d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/255e3f7334505e87fe9e4ee2f37f477e3ec1a4ca2d57962a614f9f85318117fc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77757a686968616f373738382f796f6c6f6465742d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wuzhihao7788/yolodet-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : reproduce the YOLO series of papers in pytorch, including YOLOv4, PP-YOLO, YOLOv5，YOLOv3, etc.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/uvipen/Yolo-v2-pytorch\"\u003euvipen/Yolo-v2-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/37349629e0062d68977b612e3114bbd51950f68c15bb9294676fe0eff6a43b8e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f75766970656e2f596f6c6f2d76322d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/37349629e0062d68977b612e3114bbd51950f68c15bb9294676fe0eff6a43b8e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f75766970656e2f596f6c6f2d76322d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/uvipen/Yolo-v2-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO for object detection tasks.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Peterisfar/YOLOV3\"\u003ePeterisfar/YOLOV3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d9647b7f5895b458ebdecd49fc5aed6c241f8d77ff3ca7ec66ba0eca125b31ad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506574657269736661722f594f4c4f56333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d9647b7f5895b458ebdecd49fc5aed6c241f8d77ff3ca7ec66ba0eca125b31ad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506574657269736661722f594f4c4f56333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Peterisfar/YOLOV3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov3 by pytorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/misads/easy_detection\"\u003emisads/easy_detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7ab9507c18e3f420664084d3bf4829406e405ca627887a13269e28fd6e26d1bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69736164732f656173795f646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7ab9507c18e3f420664084d3bf4829406e405ca627887a13269e28fd6e26d1bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69736164732f656173795f646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/misads/easy_detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 一个简单方便的目标检测框架(PyTorch环境可直接运行，不需要cuda编译)，支持Faster_RCNN、Yolo系列(v2~v5)、EfficientDet、RetinaNet、Cascade-RCNN等经典网络。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/miemie2013/miemiedetection\"\u003emiemiedetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7ff578725d5f02d1a2b3b410c50652e95ddc9e7e209a5f702d82a657d8562400/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69656d6965323031332f6d69656d6965646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7ff578725d5f02d1a2b3b410c50652e95ddc9e7e209a5f702d82a657d8562400/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69656d6965323031332f6d69656d6965646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/miemie2013/miemiedetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Pytorch and ncnn implementation of PPYOLOE、YOLOX、PPYOLO、PPYOLOv2、SOLOv2 an so on.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pjh5672/YOLOv1\"\u003epjh5672/YOLOv1\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0693fee5a26ee5e2fe88eaa0681dba7f03a5b500aa7e5e5609ecc1fa1e6ace1e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a68353637322f594f4c4f76313f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0693fee5a26ee5e2fe88eaa0681dba7f03a5b500aa7e5e5609ecc1fa1e6ace1e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a68353637322f594f4c4f76313f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pjh5672/YOLOv1?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv1 implementation using PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pjh5672/YOLOv2\"\u003epjh5672/YOLOv2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/34e979c992fa3a44974a22bdaeed4ae05d6eef685b88f39d1b4102e33f58e6d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a68353637322f594f4c4f76323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/34e979c992fa3a44974a22bdaeed4ae05d6eef685b88f39d1b4102e33f58e6d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a68353637322f594f4c4f76323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pjh5672/YOLOv2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv2 implementation using PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pjh5672/YOLOv3\"\u003epjh5672/YOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b2ece60885e2598583e4b99e4d46f69d13928b3bde6b4cfc4a4b582a16ab246b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a68353637322f594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b2ece60885e2598583e4b99e4d46f69d13928b3bde6b4cfc4a4b582a16ab246b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706a68353637322f594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pjh5672/YOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv3 implementation using PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Iywie/pl_YOLO\"\u003eIywie/pl_YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b542f0beb3de0f81554e175fd7313b8041fb0634d0ce7a42f7072c8b18c47ab7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f49797769652f706c5f594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b542f0beb3de0f81554e175fd7313b8041fb0634d0ce7a42f7072c8b18c47ab7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f49797769652f706c5f594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Iywie/pl_YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv7, YOLOX and YOLOv5 are working right now.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DavidLandup0/deepvision\"\u003eDavidLandup0/deepvision\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f607e2d8807aad4cca859284fc0ab28f2500539663be840da290059a579ac6d1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44617669644c616e647570302f64656570766973696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f607e2d8807aad4cca859284fc0ab28f2500539663be840da290059a579ac6d1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44617669644c616e647570302f64656570766973696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DavidLandup0/deepvision?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PyTorch and TensorFlow/Keras image models with automatic weight conversions and equal API/implementations - Vision Transformer (ViT), ResNetV2, EfficientNetV2, (planned...) DeepLabV3+, ConvNeXtV2, YOLO, NeRF, etc.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/theos-ai/easy-yolov7\"\u003etheos-ai/easy-yolov7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7bd601ba29a0df98823583062303d5032b65263c9c07784a63bd1969d07926d2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7468656f732d61692f656173792d796f6c6f76373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7bd601ba29a0df98823583062303d5032b65263c9c07784a63bd1969d07926d2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7468656f732d61692f656173792d796f6c6f76373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/theos-ai/easy-yolov7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This a clean and easy-to-use implementation of YOLOv7 in PyTorch, made with ❤️ by Theos AI.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eC Implementation\u003c/h3\u003e\u003ca id=\"user-content-c-implementation\" class=\"anchor\" aria-label=\"Permalink: C Implementation\" href=\"#c-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ggerganov/ggml\"\u003eggml\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a2036c240e1e37b39dca30152fa9812f97e1402c6e05a46372006c7a3d3fae37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6767657267616e6f762f67676d6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a2036c240e1e37b39dca30152fa9812f97e1402c6e05a46372006c7a3d3fae37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6767657267616e6f762f67676d6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ggerganov/ggml?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tensor library for machine learning. Written in C.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/rockcarry/ffcnn\"\u003erockcarry/ffcnn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ac1e34df4315c599368222a15d599a1bb56a43e93fa7c3036112bcf9e09d0201/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f636b63617272792f6666636e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ac1e34df4315c599368222a15d599a1bb56a43e93fa7c3036112bcf9e09d0201/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f636b63617272792f6666636e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/rockcarry/ffcnn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ffcnn is a cnn neural network inference framework, written in 600 lines C language.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ar7775/Object-Detection-System-Yolo\"\u003ear7775/Object-Detection-System-Yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bccdcea8859e0be326897bc326f77a33831ffc647542bd8a1e3d90c141c60e40/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6172373737352f4f626a6563742d446574656374696f6e2d53797374656d2d596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bccdcea8859e0be326897bc326f77a33831ffc647542bd8a1e3d90c141c60e40/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6172373737352f4f626a6563742d446574656374696f6e2d53797374656d2d596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ar7775/Object-Detection-System-Yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object Detection System.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lstuma/YOLO_utils\"\u003elstuma/YOLO_utils\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/40a0ac6d1413338240be8553bdee59c043abe638f498ab2a2c53ba149ce8bed5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c7374756d612f594f4c4f5f7574696c733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/40a0ac6d1413338240be8553bdee59c043abe638f498ab2a2c53ba149ce8bed5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c7374756d612f594f4c4f5f7574696c733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lstuma/YOLO_utils?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A few utilities for the YOLO project implemented in C for extra speed.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RajneeshKumar12/yolo-detection-app\"\u003eRajneeshKumar12/yolo-detection-app\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/153a7f185ea336270371568f918e38817acb259f5de04f3b377f316df7d1ef8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52616a6e656573684b756d617231322f796f6c6f2d646574656374696f6e2d6170703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/153a7f185ea336270371568f918e38817acb259f5de04f3b377f316df7d1ef8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52616a6e656573684b756d617231322f796f6c6f2d646574656374696f6e2d6170703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RajneeshKumar12/yolo-detection-app?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo app for object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Deyht/CIANNA\"\u003eDeyht/CIANNA\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4fa2b914f1235bb61eb1cc8f3b208e4cb44817fa1891dee65094faa15e967aa8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44657968742f4349414e4e413f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4fa2b914f1235bb61eb1cc8f3b208e4cb44817fa1891dee65094faa15e967aa8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44657968742f4349414e4e413f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Deyht/CIANNA?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : CIANNA - Convolutional Interactive Artificial Neural Networks by/for Astrophysicists.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCPP Implementation\u003c/h3\u003e\u003ca id=\"user-content-cpp-implementation\" class=\"anchor\" aria-label=\"Permalink: CPP Implementation\" href=\"#cpp-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/walktree/libtorch-yolov3\"\u003ewalktree/libtorch-yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2896b9e6543dca19a5f010c6415a1ce31b8f882a9ba0e21c529f0999c1a7b717/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616c6b747265652f6c6962746f7263682d796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2896b9e6543dca19a5f010c6415a1ce31b8f882a9ba0e21c529f0999c1a7b717/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616c6b747265652f6c6962746f7263682d796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/walktree/libtorch-yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Libtorch implementation of the YOLO v3 object detection algorithm, written with pure C++.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yasenh/libtorch-yolov5\"\u003eyasenh/libtorch-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/561a6a1d97aa97273c363626fee78bce6a703ddc6b399b87b13e8cd75eb83579/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796173656e682f6c6962746f7263682d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/561a6a1d97aa97273c363626fee78bce6a703ddc6b399b87b13e8cd75eb83579/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796173656e682f6c6962746f7263682d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yasenh/libtorch-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A LibTorch inference implementation of the yolov5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Nebula4869/YOLOv5-LibTorch\"\u003eNebula4869/YOLOv5-LibTorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0069065a24bcbbe3423ab3c882c7698dd69c3046e30f6cf0d2c603a50b5f0ad5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e6562756c61343836392f594f4c4f76352d4c6962546f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0069065a24bcbbe3423ab3c882c7698dd69c3046e30f6cf0d2c603a50b5f0ad5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e6562756c61343836392f594f4c4f76352d4c6962546f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Nebula4869/YOLOv5-LibTorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real time object detection with deployment of YOLOv5 through LibTorch C++ API.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ncdhz/YoloV5-LibTorch\"\u003encdhz/YoloV5-LibTorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/deffd9d223d9157d2113d7a57fc949c46d4913b63f33d64d590d72293ea99af7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e6364687a2f596f6c6f56352d4c6962546f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/deffd9d223d9157d2113d7a57fc949c46d4913b63f33d64d590d72293ea99af7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e6364687a2f596f6c6f56352d4c6962546f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ncdhz/YoloV5-LibTorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 一个 C++ 版本的 YoloV5 封装库.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Rane2021/yolov5_train_cpp_inference\"\u003eRane2021/yolov5_train_cpp_inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/272c98663fd283afa1fcd4edea0b48a072ebb8cd109a4a8fa8c0bef5c4b5e05c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52616e65323032312f796f6c6f76355f747261696e5f6370705f696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/272c98663fd283afa1fcd4edea0b48a072ebb8cd109a4a8fa8c0bef5c4b5e05c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52616e65323032312f796f6c6f76355f747261696e5f6370705f696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Rane2021/yolov5_train_cpp_inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5训练和c++推理代码，效果出色。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/stephanecharette/DarkHelp\"\u003estephanecharette/DarkHelp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a91b674ef1d9314565263243c2e483c7691df3114e1ea423b6ea99e6ed0bb307/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374657068616e6563686172657474652f4461726b48656c703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a91b674ef1d9314565263243c2e483c7691df3114e1ea423b6ea99e6ed0bb307/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374657068616e6563686172657474652f4461726b48656c703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/stephanecharette/DarkHelp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The DarkHelp C++ API is a wrapper to make it easier to use the Darknet neural network framework within a C++ application.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/UNeedCryDear/yolov5-opencv-dnn-cpp\"\u003eUNeedCryDear/yolov5-opencv-dnn-cpp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7b5ab192d6624cc93699194e1a206734cce03fecac95288b0748495a9727d878/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f554e656564437279446561722f796f6c6f76352d6f70656e63762d646e6e2d6370703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7b5ab192d6624cc93699194e1a206734cce03fecac95288b0748495a9727d878/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f554e656564437279446561722f796f6c6f76352d6f70656e63762d646e6e2d6370703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/UNeedCryDear/yolov5-opencv-dnn-cpp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 使用opencv模块部署yolov5-6.0版本。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/UNeedCryDear/yolov5-seg-opencv-onnxruntime-cpp\"\u003eUNeedCryDear/yolov5-seg-opencv-onnxruntime-cpp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/25315f2d99a387c98b0df8815ba35756ad1ac3f84586361c2ce793f64593ab1f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f554e656564437279446561722f796f6c6f76352d7365672d6f70656e63762d6f6e6e7872756e74696d652d6370703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/25315f2d99a387c98b0df8815ba35756ad1ac3f84586361c2ce793f64593ab1f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f554e656564437279446561722f796f6c6f76352d7365672d6f70656e63762d6f6e6e7872756e74696d652d6370703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/UNeedCryDear/yolov5-seg-opencv-onnxruntime-cpp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5 segmentation with onnxruntime and opencv.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hpc203/yolov5-dnn-cpp-python\"\u003ehpc203/yolov5-dnn-cpp-python\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/31d1d903d62a7a0fa1a80296bba617ad258de500ac181b4b66d62a4c41733c0e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f796f6c6f76352d646e6e2d6370702d707974686f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/31d1d903d62a7a0fa1a80296bba617ad258de500ac181b4b66d62a4c41733c0e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f796f6c6f76352d646e6e2d6370702d707974686f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hpc203/yolov5-dnn-cpp-python?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 用opencv的dnn模块做yolov5目标检测，包含C++和Python两个版本的程序。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hpc203/yolox-opencv-dnn\"\u003ehpc203/yolox-opencv-dnn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ecf2c6e7b86be03e7a16f4da699ca469156fa6c400e4351da972ccb3b70bbf8b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f796f6c6f782d6f70656e63762d646e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ecf2c6e7b86be03e7a16f4da699ca469156fa6c400e4351da972ccb3b70bbf8b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f796f6c6f782d6f70656e63762d646e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hpc203/yolox-opencv-dnn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 使用OpenCV部署YOLOX，支持YOLOX-S、YOLOX-M、YOLOX-L、YOLOX-X、YOLOX-Darknet53五种结构，包含C++和Python两种版本的程序。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hpc203/yolov7-opencv-onnxrun-cpp-py\"\u003ehpc203/yolov7-opencv-onnxrun-cpp-py\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5e264b42ef2ff864546ab92756a11fbd2065d1ad81e73e2a39f87d3237a75c10/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f796f6c6f76372d6f70656e63762d6f6e6e7872756e2d6370702d70793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5e264b42ef2ff864546ab92756a11fbd2065d1ad81e73e2a39f87d3237a75c10/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f796f6c6f76372d6f70656e63762d6f6e6e7872756e2d6370702d70793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hpc203/yolov7-opencv-onnxrun-cpp-py?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 分别使用OpenCV、ONNXRuntime部署YOLOV7目标检测，一共包含12个onnx模型，依然是包含C++和Python两个版本的程序。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/doleron/yolov5-opencv-cpp-python\"\u003edoleron/yolov5-opencv-cpp-python\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7cd2d1ccee570c9963f7a7a958c68900a66f1798b035d64997f9cfacd8f939a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f6c65726f6e2f796f6c6f76352d6f70656e63762d6370702d707974686f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7cd2d1ccee570c9963f7a7a958c68900a66f1798b035d64997f9cfacd8f939a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f6c65726f6e2f796f6c6f76352d6f70656e63762d6370702d707974686f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/doleron/yolov5-opencv-cpp-python?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Example of using ultralytics YOLO V5 with OpenCV 4.5.4, C++ and Python.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/UNeedCryDear/yolov8-opencv-onnxruntime-cpp\"\u003eUNeedCryDear/yolov8-opencv-onnxruntime-cpp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8120f71fcb69687addd19c1cb4613a2078619c60479787a91612615077eaf99e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f554e656564437279446561722f796f6c6f76382d6f70656e63762d6f6e6e7872756e74696d652d6370703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8120f71fcb69687addd19c1cb4613a2078619c60479787a91612615077eaf99e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f554e656564437279446561722f796f6c6f76382d6f70656e63762d6f6e6e7872756e74696d652d6370703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/UNeedCryDear/yolov8-opencv-onnxruntime-cpp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : detection and instance segmentation of yolov8,use onnxruntime and opencv.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eROS Implementation\u003c/h3\u003e\u003ca id=\"user-content-ros-implementation\" class=\"anchor\" aria-label=\"Permalink: ROS Implementation\" href=\"#ros-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mgonzs13/yolov8_ros\"\u003emgonzs13/yolov8_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cc552bc31a9f418f376b0e5608572f164ec3e65e4a2521a17ea4e0bb077747ab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d676f6e7a7331332f796f6c6f76385f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cc552bc31a9f418f376b0e5608572f164ec3e65e4a2521a17ea4e0bb077747ab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d676f6e7a7331332f796f6c6f76385f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mgonzs13/yolov8_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Ultralytics YOLOv8, YOLOv9, YOLOv10, YOLOv11 for ROS 2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/leggedrobotics/darknet_ros\"\u003eleggedrobotics/darknet_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cfd81b1613c79ab28ce48949eca22d26a81dcd9dd9dce9816261c35030a0c218/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6567676564726f626f746963732f6461726b6e65745f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cfd81b1613c79ab28ce48949eca22d26a81dcd9dd9dce9816261c35030a0c218/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6567676564726f626f746963732f6461726b6e65745f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/leggedrobotics/darknet_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-Time Object Detection for ROS.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/engcang/ros-yolo-sort\"\u003eengcang/ros-yolo-sort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5a0ffdfcb6e3c0c6539070911a9478e23a8ae4dd92ad2fca6a953d6ca6d187dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656e6763616e672f726f732d796f6c6f2d736f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5a0ffdfcb6e3c0c6539070911a9478e23a8ae4dd92ad2fca6a953d6ca6d187dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656e6763616e672f726f732d796f6c6f2d736f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/engcang/ros-yolo-sort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO and SORT, and ROS versions of them.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/chrisgundling/YoloLight\"\u003echrisgundling/YoloLight\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d93a032c384df996ac1f300d5e23d408e38937c207d93dc927775fee5b4f37a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636872697367756e646c696e672f596f6c6f4c696768743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d93a032c384df996ac1f300d5e23d408e38937c207d93dc927775fee5b4f37a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636872697367756e646c696e672f596f6c6f4c696768743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/chrisgundling/YoloLight?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tiny-YOLO-v2 ROS Node for Traffic Light Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ar-Ray-code/YOLOX-ROS\"\u003eAr-Ray-code/YOLOX-ROS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2483d68d88d2e40c8376d7a155385a8be5deaa644291c6457b48f1a435c23199/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41722d5261792d636f64652f594f4c4f582d524f533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2483d68d88d2e40c8376d7a155385a8be5deaa644291c6457b48f1a435c23199/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41722d5261792d636f64652f594f4c4f582d524f533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ar-Ray-code/YOLOX-ROS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOX + ROS2 object detection package.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ar-Ray-code/YOLOv5-ROS\"\u003eAr-Ray-code/YOLOv5-ROS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/426daddc440e507129937ff139f2bf3fb7142a8b5f446d4d4eb6486dd3ddaf0f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41722d5261792d636f64652f594f4c4f76352d524f533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/426daddc440e507129937ff139f2bf3fb7142a8b5f446d4d4eb6486dd3ddaf0f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41722d5261792d636f64652f594f4c4f76352d524f533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ar-Ray-code/YOLOv5-ROS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 + ROS2 object detection package.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Tossy0423/yolov4-for-darknet_ros\"\u003eTossy0423/yolov4-for-darknet_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bd8239717ba8a5a7647502f9f4353063831b150e1fc7bd092fbbf5ee2767ac9f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f546f737379303432332f796f6c6f76342d666f722d6461726b6e65745f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bd8239717ba8a5a7647502f9f4353063831b150e1fc7bd092fbbf5ee2767ac9f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f546f737379303432332f796f6c6f76342d666f722d6461726b6e65745f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Tossy0423/yolov4-for-darknet_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is the environment in which YOLO V4 is ported to darknet_ros.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/qianmin/yolov5_ROS\"\u003eqianmin/yolov5_ROS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c30887fb2e8aa909cc0851b0323bd032634a446299985777fad1799c43e98628/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7169616e6d696e2f796f6c6f76355f524f533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c30887fb2e8aa909cc0851b0323bd032634a446299985777fad1799c43e98628/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7169616e6d696e2f796f6c6f76355f524f533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/qianmin/yolov5_ROS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : run YOLOv5 in ROS，ROS使用YOLOv5。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ailllist/yolov5_ROS\"\u003eailllist/yolov5_ROS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/14b41e1eba932881c656bec8f8ffd598bc8c13152230087508960932e6618540/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61696c6c6c6973742f796f6c6f76355f524f533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/14b41e1eba932881c656bec8f8ffd598bc8c13152230087508960932e6618540/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61696c6c6c6973742f796f6c6f76355f524f533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ailllist/yolov5_ROS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5 for ros, not webcam.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Shua-Kang/ros_pytorch_yolov5\"\u003eShua-Kang/ros_pytorch_yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4b32d6e3b86a04a22b84a245374a25f0570837c42598dc1a29fc7f06a3adeb07/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536875612d4b616e672f726f735f7079746f7263685f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4b32d6e3b86a04a22b84a245374a25f0570837c42598dc1a29fc7f06a3adeb07/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536875612d4b616e672f726f735f7079746f7263685f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Shua-Kang/ros_pytorch_yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A ROS wrapper for yolov5. (master branch is v5.0 of yolov5; for v6.1, see branch v6.1).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ziyan0302/Yolov5_DeepSort_Pytorch_ros\"\u003eziyan0302/Yolov5_DeepSort_Pytorch_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9164d7b346dbceb0dd3c4272addd0e9d604738561eb4a4c4f92879ff1db52bec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6979616e303330322f596f6c6f76355f44656570536f72745f5079746f7263685f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9164d7b346dbceb0dd3c4272addd0e9d604738561eb4a4c4f92879ff1db52bec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6979616e303330322f596f6c6f76355f44656570536f72745f5079746f7263685f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ziyan0302/Yolov5_DeepSort_Pytorch_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Connect Yolov5 detection module and DeepSort tracking module via ROS.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/U07157135/ROS2-with-YOLOv5\"\u003eU07157135/ROS2-with-YOLOv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1560d3bb8de7b9b00dd233b932a342d6a7ee1955fd6f66a72ddafdb2a5ab2ca6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5530373135373133352f524f53322d776974682d594f4c4f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1560d3bb8de7b9b00dd233b932a342d6a7ee1955fd6f66a72ddafdb2a5ab2ca6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5530373135373133352f524f53322d776974682d594f4c4f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/U07157135/ROS2-with-YOLOv5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 在無人機上以ROS2技術實現YOLOv5物件偵測。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lukazso/yolov6-ros\"\u003elukazso/yolov6-ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7abd003e9a57ca44922cb29ad6a23314f2528a80ad399b01dc35e3fd839f4152/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c756b617a736f2f796f6c6f76362d726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7abd003e9a57ca44922cb29ad6a23314f2528a80ad399b01dc35e3fd839f4152/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c756b617a736f2f796f6c6f76362d726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lukazso/yolov6-ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ROS package for YOLOv6.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/qq44642754a/Yolov5_ros\"\u003eqq44642754a/Yolov5_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/96844cd733ebcc0775d6ab60a60412cf1f381486cf9695ab1dbc8c446c798b63/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f71713434363432373534612f596f6c6f76355f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/96844cd733ebcc0775d6ab60a60412cf1f381486cf9695ab1dbc8c446c798b63/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f71713434363432373534612f596f6c6f76355f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/qq44642754a/Yolov5_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time object detection with ROS, based on YOLOv5 and PyTorch (基于 YOLOv5的ROS实时对象检测).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lukazso/yolov7-ros\"\u003elukazso/yolov7-ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/19eaf8591de5df8352c108bc71e96bb140d62e71b9d10001457d1c982b0854b3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c756b617a736f2f796f6c6f76372d726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/19eaf8591de5df8352c108bc71e96bb140d62e71b9d10001457d1c982b0854b3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c756b617a736f2f796f6c6f76372d726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lukazso/yolov7-ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ROS package for official YOLOv7.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/phuoc101/yolov7_ros\"\u003ephuoc101/yolov7_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/235b05b3241424df39e747b50b4f6aca69994f7f86afbd10dfbf404bb91a3171/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7068756f633130312f796f6c6f76375f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/235b05b3241424df39e747b50b4f6aca69994f7f86afbd10dfbf404bb91a3171/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7068756f633130312f796f6c6f76375f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/phuoc101/yolov7_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ROS package for official YOLOv7.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ConfusionTechnologies/ros-yolov5-node\"\u003eConfusionTechnologies/ros-yolov5-node\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d59611cc9a1aa6faf1db208c1afb4ce5bf4d9fba558652a8dca221e04667e595/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436f6e667573696f6e546563686e6f6c6f676965732f726f732d796f6c6f76352d6e6f64653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d59611cc9a1aa6faf1db208c1afb4ce5bf4d9fba558652a8dca221e04667e595/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436f6e667573696f6e546563686e6f6c6f676965732f726f732d796f6c6f76352d6e6f64653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ConfusionTechnologies/ros-yolov5-node?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : For ROS2, uses ONNX GPU Runtime to inference YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ar-Ray-code/darknet_ros_fp16\"\u003eAr-Ray-code/darknet_ros_fp16\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a565de47dceb9eaa9f4c5862c284211b66cb5dd4acb1aa23de8723d11588fde1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41722d5261792d636f64652f6461726b6e65745f726f735f667031363f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a565de47dceb9eaa9f4c5862c284211b66cb5dd4acb1aa23de8723d11588fde1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41722d5261792d636f64652f6461726b6e65745f726f735f667031363f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ar-Ray-code/darknet_ros_fp16?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : darknet + ROS2 Humble + OpenCV4 + CUDA 11（cuDNN, Jetson Orin）.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wk123467/yolov5s_trt_ros\"\u003ewk123467/yolov5s_trt_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a0fd6d86d665a71b41ce3e2412b85fde9c17a9d75e336717ca6f4a85999707b0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776b3132333436372f796f6c6f7635735f7472745f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a0fd6d86d665a71b41ce3e2412b85fde9c17a9d75e336717ca6f4a85999707b0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776b3132333436372f796f6c6f7635735f7472745f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wk123467/yolov5s_trt_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 利用TensorRT对yolov5s进行加速，并将其应用于ROS，实现交通标志、红绿灯(直接输出路灯状态)、行人和车辆等交通场景的检测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PardisTaghavi/yolov7_strongsort_ros\"\u003ePardisTaghavi/yolov7_strongsort_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/67abe53c0d2f1f0f2dc2597fcc498e57f74968525df4f1bba4e15ba099709f22/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506172646973546167686176692f796f6c6f76375f7374726f6e67736f72745f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/67abe53c0d2f1f0f2dc2597fcc498e57f74968525df4f1bba4e15ba099709f22/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506172646973546167686176692f796f6c6f76375f7374726f6e67736f72745f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PardisTaghavi/yolov7_strongsort_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Integration of \"Yolov7 StrongSort\" with ROS for real time object tracking.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/af-doom/yolov8_ros_tensorrt-\"\u003eaf-doom/yolov8_ros_tensorrt-\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1317a0a91d6985a2b3cfbb00b4b8d2508ac99a7f36d8381634e4653fe6f9c8bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61662d646f6f6d2f796f6c6f76385f726f735f74656e736f7272742d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1317a0a91d6985a2b3cfbb00b4b8d2508ac99a7f36d8381634e4653fe6f9c8bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61662d646f6f6d2f796f6c6f76385f726f735f74656e736f7272742d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/af-doom/yolov8_ros_tensorrt-?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a YOLOv8 project based on ROS implementation, where YOLOv8 uses Tensorrt acceleration.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/KoKoMier/ros_darknet_yolov4\"\u003eKoKoMier/ros_darknet_yolov4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9c5161e9ede29964d5598823f9fa0a35e3770e9e62fbd9491b51a400c888e17d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6f4b6f4d6965722f726f735f6461726b6e65745f796f6c6f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9c5161e9ede29964d5598823f9fa0a35e3770e9e62fbd9491b51a400c888e17d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6f4b6f4d6965722f726f735f6461726b6e65745f796f6c6f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/KoKoMier/ros_darknet_yolov4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 这是机器人小组视觉与雷达的结合程序，首先通过yolo目标检测识别到物体，然后把识别到的数据发送给ros里面程序，用于雷达数据结合。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/YellowAndGreen/Yolov5-OpenCV-Cpp-Python-ROS\"\u003eYellowAndGreen/Yolov5-OpenCV-Cpp-Python-ROS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9bfb2386ad14ad7cf2a4885739c36ab6e15746e5eca8df778928d6c0c3b9b6b4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59656c6c6f77416e64477265656e2f596f6c6f76352d4f70656e43562d4370702d507974686f6e2d524f533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9bfb2386ad14ad7cf2a4885739c36ab6e15746e5eca8df778928d6c0c3b9b6b4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59656c6c6f77416e64477265656e2f596f6c6f76352d4f70656e43562d4370702d507974686f6e2d524f533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/YellowAndGreen/Yolov5-OpenCV-Cpp-Python-ROS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Inference with YOLOv5, OpenCV 4.5.4 DNN, C++, ROS and Python.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mgonzs13/yolov8_ros\"\u003emgonzs13/yolov8_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cc552bc31a9f418f376b0e5608572f164ec3e65e4a2521a17ea4e0bb077747ab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d676f6e7a7331332f796f6c6f76385f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cc552bc31a9f418f376b0e5608572f164ec3e65e4a2521a17ea4e0bb077747ab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d676f6e7a7331332f796f6c6f76385f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mgonzs13/yolov8_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ROS 2 wrap for Ultralytics \u003ca href=\"https://github.com/ultralytics/ultralytics\"\u003eYOLOv8\u003c/a\u003e to perform object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fishros/yolov5_ros2\"\u003efishros/yolov5_ros2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/61ff7319e67d5e512e7bcd05d04e791a172fdb74a0f88634bfdd94905ca9db59/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66697368726f732f796f6c6f76355f726f73323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/61ff7319e67d5e512e7bcd05d04e791a172fdb74a0f88634bfdd94905ca9db59/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66697368726f732f796f6c6f76355f726f73323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/fishros/yolov5_ros2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于YoloV5的ROS2功能包，可以快速完成物体识别与位姿发布。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fateshelled/EdgeYOLO-ROS\"\u003efateshelled/EdgeYOLO-ROS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c7a3cf4654a0ac26b4f4584aadc7f740989e480b0302e7867751610a904669d0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666174657368656c6c65642f45646765594f4c4f2d524f533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c7a3cf4654a0ac26b4f4584aadc7f740989e480b0302e7867751610a904669d0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666174657368656c6c65642f45646765594f4c4f2d524f533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/fateshelled/EdgeYOLO-ROS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : EdgeYOLO + ROS2 object detection package.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/vivaldini/yolov6-uav\"\u003evivaldini/yolov6-uav\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7ed9636463dd97d8afb26dbd162a542fd3f03ee25ad39e1122f77f1f36e0fea8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f766976616c64696e692f796f6c6f76362d7561763f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7ed9636463dd97d8afb26dbd162a542fd3f03ee25ad39e1122f77f1f36e0fea8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f766976616c64696e692f796f6c6f76362d7561763f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/vivaldini/yolov6-uav?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository contains a ROS noetic package for YOLOv6 to recognize objects from UAV and provide their positions.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Alpaca-zip/ultralytics_ros\"\u003eAlpaca-zip/ultralytics_ros\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/77f549b12d077dbcf651414b4a5cc09bd6a0e79961390b1c7e73e0577579b292/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c706163612d7a69702f756c7472616c79746963735f726f733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/77f549b12d077dbcf651414b4a5cc09bd6a0e79961390b1c7e73e0577579b292/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c706163612d7a69702f756c7472616c79746963735f726f733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Alpaca-zip/ultralytics_ros?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ROS/ROS2 package for Ultralytics YOLOv8 real-time object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eMojo Implementation\u003c/h3\u003e\u003ca id=\"user-content-mojo-implementation\" class=\"anchor\" aria-label=\"Permalink: Mojo Implementation\" href=\"#mojo-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/taalhaataahir0102/Mojo-Yolo\"\u003etaalhaataahir0102/Mojo-Yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9c10face27f1e048bf683bd9b60302822751a6180dca0373f5fb591769bbd807/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7461616c686161746161686972303130322f4d6f6a6f2d596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9c10face27f1e048bf683bd9b60302822751a6180dca0373f5fb591769bbd807/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7461616c686161746161686972303130322f4d6f6a6f2d596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/taalhaataahir0102/Mojo-Yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Mojo-Yolo.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eRust Implementation\u003c/h3\u003e\u003ca id=\"user-content-rust-implementation\" class=\"anchor\" aria-label=\"Permalink: Rust Implementation\" href=\"#rust-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/huggingface/candle\"\u003eCandle\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/586e4cdae2010f8d60f1ee301e98154c870c483e2a1ecf48050f63e4587caad6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756767696e67666163652f63616e646c653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/586e4cdae2010f8d60f1ee301e98154c870c483e2a1ecf48050f63e4587caad6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756767696e67666163652f63616e646c653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/huggingface/candle?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Minimalist ML framework for Rust.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/huggingface/tokenizers\"\u003eTokenizers\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2aa91170d1b68534dff5f0b6c4a7366371773cf6f6467ec43b51e4304b4fab6a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756767696e67666163652f746f6b656e697a6572733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2aa91170d1b68534dff5f0b6c4a7366371773cf6f6467ec43b51e4304b4fab6a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756767696e67666163652f746f6b656e697a6572733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/huggingface/tokenizers?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 💥 Fast State-of-the-Art Tokenizers optimized for Research and Production. \u003ca href=\"https://huggingface.co/docs/tokenizers/index\" rel=\"nofollow\"\u003ehuggingface.co/docs/tokenizers\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/huggingface/safetensors\"\u003eSafetensors\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e2d062826de5fa5d53219c83bd9f20f5f1d67c0ab775e1c90e636f3bb14fd10e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756767696e67666163652f7361666574656e736f72733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e2d062826de5fa5d53219c83bd9f20f5f1d67c0ab775e1c90e636f3bb14fd10e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756767696e67666163652f7361666574656e736f72733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/huggingface/safetensors?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Simple, safe way to store and distribute tensors. \u003ca href=\"https://huggingface.co/docs/safetensors/index\" rel=\"nofollow\"\u003ehuggingface.co/docs/safetensors\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/burn-rs/burn\"\u003eBurn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7b77aec3ab9378a213c5f73cbf6bc5ebb66b7a023641681394ef231af9703cd7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6275726e2d72732f6275726e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7b77aec3ab9378a213c5f73cbf6bc5ebb66b7a023641681394ef231af9703cd7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6275726e2d72732f6275726e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/burn-rs/burn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Burn - A Flexible and Comprehensive Deep Learning Framework in Rust. \u003ca href=\"https://burn-rs.github.io/\" rel=\"nofollow\"\u003eburn-rs.github.io/\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tensorflow/rust\"\u003eTensorFlow Rust\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/985bf6de8f06b05b56766ad7d2b700c1a7d8dc5f1780ac8debca98611f24115f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74656e736f72666c6f772f727573743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/985bf6de8f06b05b56766ad7d2b700c1a7d8dc5f1780ac8debca98611f24115f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74656e736f72666c6f772f727573743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tensorflow/rust?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Rust language bindings for TensorFlow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LaurentMazare/tch-rs\"\u003etch-rs\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8a072333378f114bff0a3fb74d5acab89b2c14f5d97029d16e93fc4b16cdbe40/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c617572656e744d617a6172652f7463682d72733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8a072333378f114bff0a3fb74d5acab89b2c14f5d97029d16e93fc4b16cdbe40/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c617572656e744d617a6172652f7463682d72733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LaurentMazare/tch-rs?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Rust bindings for the C++ api of PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/coreylowman/dfdx\"\u003edfdx\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b6d38dfe01c2a0de447731cc93ea27116a4fc78ca0fbef681dcb3a7c2a6379a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636f7265796c6f776d616e2f646664783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b6d38dfe01c2a0de447731cc93ea27116a4fc78ca0fbef681dcb3a7c2a6379a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636f7265796c6f776d616e2f646664783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/coreylowman/dfdx?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Deep learning in Rust, with shape checked tensors and neural networks.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sonos/tract\"\u003etract\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b529827f8fb7574e9d382e6d0c524f2f8ca19fd6e547387280d8a682c7ff6919/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736f6e6f732f74726163743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b529827f8fb7574e9d382e6d0c524f2f8ca19fd6e547387280d8a682c7ff6919/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736f6e6f732f74726163743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sonos/tract?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Sonos' Neural Network inference engine. Tiny, no-nonsense, self-contained, Tensorflow and ONNX inference\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pykeio/ort\"\u003eort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/45aa58d12c13b364706b818b5b1d2ea3e8dc88e081669aab1709ac161da8fc46/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70796b65696f2f6f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/45aa58d12c13b364706b818b5b1d2ea3e8dc88e081669aab1709ac161da8fc46/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70796b65696f2f6f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pykeio/ort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Rust wrapper for ONNX Runtime. \u003ca href=\"https://docs.rs/ort/latest/ort/\" rel=\"nofollow\"\u003edocs.rs/ort\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jamjamjon/usls\"\u003eusls\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8f253cf66976601163b49107a1ac27fa592cb74b0af20bfb552a586449fbb6c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a616d6a616d6a6f6e2f75736c733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8f253cf66976601163b49107a1ac27fa592cb74b0af20bfb552a586449fbb6c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a616d6a616d6a6f6e2f75736c733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jamjamjon/usls?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Rust library integrated with ONNXRuntime, providing a collection of Computer Vison and Vision-Language models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ptaxom/pnn\"\u003eptaxom/pnn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/07a28d05ce24384bbb8f7ca8a9d76e5d03d4ba6254c89bd55a9313e02f24769a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f707461786f6d2f706e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/07a28d05ce24384bbb8f7ca8a9d76e5d03d4ba6254c89bd55a9313e02f24769a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f707461786f6d2f706e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ptaxom/pnn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : pnn is \u003ca href=\"https://github.com/alexeyAB/darknet\"\u003eDarknet\u003c/a\u003e compatible neural nets inference engine implemented in Rust. By optimizing was achieved significant performance increment(especially in FP16 mode). pnn provide CUDNN-based and TensorRT-based inference engines.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bencevans/rust-opencv-yolov5\"\u003ebencevans/rust-opencv-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fe0cfb36050febd9fe2ab84e19627ef4926a8a7cee56a58024655d6ae409dea7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62656e636576616e732f727573742d6f70656e63762d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fe0cfb36050febd9fe2ab84e19627ef4926a8a7cee56a58024655d6ae409dea7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62656e636576616e732f727573742d6f70656e63762d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bencevans/rust-opencv-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 Inference with ONNX \u0026amp; OpenCV in Rust.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/masc-it/yolov5-api-rust\"\u003emasc-it/yolov5-api-rust\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d44191a707c1106a22064b2c677d18d451fbc38ab7d0c47ff0b942afd58deb89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6173632d69742f796f6c6f76352d6170692d727573743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d44191a707c1106a22064b2c677d18d451fbc38ab7d0c47ff0b942afd58deb89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6173632d69742f796f6c6f76352d6170692d727573743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/masc-it/yolov5-api-rust?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Rust API to run predictions with YoloV5 models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AndreyGermanov/yolov8_onnx_rust\"\u003eAndreyGermanov/yolov8_onnx_rust\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7aa8968fa8176dcf0be372926532a7848be8221538863cefb2820e583f6c0a2b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e647265794765726d616e6f762f796f6c6f76385f6f6e6e785f727573743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7aa8968fa8176dcf0be372926532a7848be8221538863cefb2820e583f6c0a2b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e647265794765726d616e6f762f796f6c6f76385f6f6e6e785f727573743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AndreyGermanov/yolov8_onnx_rust?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv8 inference using Rust.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/igor-yusupov/rusty-yolo\"\u003eigor-yusupov/rusty-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5a26edf23b4b96bdb350cc3ceb29339cf42580b18faaa19823f61b6a365a28e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69676f722d79757375706f762f72757374792d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5a26edf23b4b96bdb350cc3ceb29339cf42580b18faaa19823f61b6a365a28e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69676f722d79757375706f762f72757374792d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/igor-yusupov/rusty-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : rusty-yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/gsuyemoto/yolo-rust\"\u003egsuyemoto/yolo-rust\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e2267ffcfb501fcb7eecf9d2d2acc143ba455895211facbc34e4d98861f02c90/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67737579656d6f746f2f796f6c6f2d727573743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e2267ffcfb501fcb7eecf9d2d2acc143ba455895211facbc34e4d98861f02c90/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67737579656d6f746f2f796f6c6f2d727573743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/gsuyemoto/yolo-rust?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Run YOLO computer vision model using Rust and OpenCV and/or Torch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/alianse777/darknet-rust\"\u003ealianse777/darknet-rust\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9d023a70aaca47f6df9e449f30176222eec639375bc80157e3f1637446453435/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69616e73653737372f6461726b6e65742d727573743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9d023a70aaca47f6df9e449f30176222eec639375bc80157e3f1637446453435/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69616e73653737372f6461726b6e65742d727573743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/alianse777/darknet-rust?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Rust wrapper for Darknet, an open source neural network framework written in C and CUDA. \u003ca href=\"https://pjreddie.com/darknet/\" rel=\"nofollow\"\u003epjreddie.com/darknet/\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/12101111/yolo-rs\"\u003e12101111/yolo-rs\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/52356ad53a62c94879922bed103acaf8931acddf5ffb21f18e239b17f631ee4f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f31323130313131312f796f6c6f2d72733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/52356ad53a62c94879922bed103acaf8931acddf5ffb21f18e239b17f631ee4f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f31323130313131312f796f6c6f2d72733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/12101111/yolo-rs?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov3 \u0026amp; Yolov4 with TVM and rust.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TKGgunter/yolov4_tiny_rs\"\u003eTKGgunter/yolov4_tiny_rs\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e7df46344cfe2de11a9a3564a9fdefae4b73421ed30c2520567c3127b95e6911/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f544b4767756e7465722f796f6c6f76345f74696e795f72733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e7df46344cfe2de11a9a3564a9fdefae4b73421ed30c2520567c3127b95e6911/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f544b4767756e7465722f796f6c6f76345f74696e795f72733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TKGgunter/yolov4_tiny_rs?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A rust implementation of yolov4_tiny algorithm.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/flixstn/You-Only-Look-Once\"\u003eflixstn/You-Only-Look-Once\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6fb101ab3931ce05b25ab09a8b1521fcad33aa0150f0ad6ef60f43d380757ac5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666c697873746e2f596f752d4f6e6c792d4c6f6f6b2d4f6e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6fb101ab3931ce05b25ab09a8b1521fcad33aa0150f0ad6ef60f43d380757ac5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666c697873746e2f596f752d4f6e6c792d4c6f6f6b2d4f6e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/flixstn/You-Only-Look-Once?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Rust implementation of Yolo for object detection and tracking.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lenna-project/yolo-plugin\"\u003elenna-project/yolo-plugin\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d9a1a5b2b914fdebb591aca3629eba283242740b250188eed756fa9654e24231/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c656e6e612d70726f6a6563742f796f6c6f2d706c7567696e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d9a1a5b2b914fdebb591aca3629eba283242740b250188eed756fa9654e24231/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c656e6e612d70726f6a6563742f796f6c6f2d706c7567696e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lenna-project/yolo-plugin?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo Object Detection Plugin for Lenna.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/laclouis5/globox-rs\"\u003elaclouis5/globox-rs\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/81948ad3e5a1421633c030521e40b6a08c6834c978a23eb4bd7e548921ce8796/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c61636c6f756973352f676c6f626f782d72733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/81948ad3e5a1421633c030521e40b6a08c6834c978a23eb4bd7e548921ce8796/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c61636c6f756973352f676c6f626f782d72733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/laclouis5/globox-rs?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object detection toolbox for parsing, converting and evaluating bounding box annotations.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/metobom/tchrs-opencv-webcam-inference\"\u003emetobom/tchrs-opencv-webcam-inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0dcf4c07d2aba0561c19a40c482e38b71b691d485aba56a9ed48a1b8ee3fa205/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d65746f626f6d2f74636872732d6f70656e63762d77656263616d2d696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0dcf4c07d2aba0561c19a40c482e38b71b691d485aba56a9ed48a1b8ee3fa205/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d65746f626f6d2f74636872732d6f70656e63762d77656263616d2d696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/metobom/tchrs-opencv-webcam-inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This example shows steps for running a Python trained model on webcam feed with opencv and tch-rs. Model will run on GPU.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eGo Implementation\u003c/h3\u003e\u003ca id=\"user-content-go-implementation\" class=\"anchor\" aria-label=\"Permalink: Go Implementation\" href=\"#go-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LdDl/go-darknet\"\u003eLdDl/go-darknet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6cb814e79fdcebfb835ae8fe05a44e8652f3a41690bd693abb71a0c7f2a5d3f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c64446c2f676f2d6461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6cb814e79fdcebfb835ae8fe05a44e8652f3a41690bd693abb71a0c7f2a5d3f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c64446c2f676f2d6461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LdDl/go-darknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : go-darknet: Go bindings for Darknet (Yolo V4, Yolo V7-tiny, Yolo V3).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/adalkiran/distributed-inference\"\u003eadalkiran/distributed-inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5467b03f9b41915c1dd7a40f07a922abe7a9cfc0bb1ea22bd7148f3dace571fb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6164616c6b6972616e2f64697374726962757465642d696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5467b03f9b41915c1dd7a40f07a922abe7a9cfc0bb1ea22bd7148f3dace571fb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6164616c6b6972616e2f64697374726962757465642d696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/adalkiran/distributed-inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Cross-language and distributed deep learning inference pipeline for WebRTC video streams over Redis Streams. Currently supports YOLOX model, which can run well on CPU.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wimspaargaren/yolov3\"\u003ewimspaargaren/yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/78fce265afdf7e36a3ed79def3db3e49e88c00f3f8dcbd73fac1d1768eacefff/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77696d7370616172676172656e2f796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/78fce265afdf7e36a3ed79def3db3e49e88c00f3f8dcbd73fac1d1768eacefff/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77696d7370616172676172656e2f796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wimspaargaren/yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Go implementation of the yolo v3 object detection system.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wimspaargaren/yolov5\"\u003ewimspaargaren/yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8f1c2ee13be1075c2b76c9a5a1787f5d55878416bed260211a16df1441b97c55/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77696d7370616172676172656e2f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8f1c2ee13be1075c2b76c9a5a1787f5d55878416bed260211a16df1441b97c55/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77696d7370616172676172656e2f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wimspaargaren/yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Go implementation of the yolo v5 object detection system.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/genert/real_time_object_detection_go\"\u003egenert/real_time_object_detection_go\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/eef799a7d40318d9ac3f8e3b0df97bde9af30ef78233d7969d78ee5d0b1405f6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67656e6572742f7265616c5f74696d655f6f626a6563745f646574656374696f6e5f676f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/eef799a7d40318d9ac3f8e3b0df97bde9af30ef78233d7969d78ee5d0b1405f6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67656e6572742f7265616c5f74696d655f6f626a6563745f646574656374696f6e5f676f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/genert/real_time_object_detection_go?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real Time Object Detection with OpenCV, Go, and Yolo v4.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCSharp Implementation\u003c/h3\u003e\u003ca id=\"user-content-csharp-implementation\" class=\"anchor\" aria-label=\"Permalink: CSharp Implementation\" href=\"#csharp-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dotnet/machinelearning\"\u003eML.NET\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/13362bf4a6476fe326e915ad8068db923e34721581079c9473ed7f4029d0e7f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f746e65742f6d616368696e656c6561726e696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/13362bf4a6476fe326e915ad8068db923e34721581079c9473ed7f4029d0e7f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f746e65742f6d616368696e656c6561726e696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dotnet/machinelearning?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ML.NET is an open source and cross-platform machine learning framework for .NET.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dotnet/TorchSharp\"\u003eTorchSharp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/15eb7330c52dfe39425999ab85ebf8b51b691c873ea58d5d6fe24adb32f60251/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f746e65742f546f72636853686172703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/15eb7330c52dfe39425999ab85ebf8b51b691c873ea58d5d6fe24adb32f60251/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f746e65742f546f72636853686172703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dotnet/TorchSharp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A .NET library that provides access to the library that powers PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SciSharp/TensorFlow.NET\"\u003eTensorFlow.NET\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/09c133fa99e92c85bb13efbfceb28acb0eedcaf41769b84adc4350507a4709bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53636953686172702f54656e736f72466c6f772e4e45543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/09c133fa99e92c85bb13efbfceb28acb0eedcaf41769b84adc4350507a4709bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53636953686172702f54656e736f72466c6f772e4e45543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SciSharp/TensorFlow.NET?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : .NET Standard bindings for Google's TensorFlow for developing, training and deploying Machine Learning models in C# and F#.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/takuya-takeuchi/DlibDotNet\"\u003eDlibDotNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/aedac681ec9192b090982f570ae4a0eb1c2af6706096365a65638921fbe568e7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616b7579612d74616b65756368692f446c6962446f744e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/aedac681ec9192b090982f570ae4a0eb1c2af6706096365a65638921fbe568e7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616b7579612d74616b65756368692f446c6962446f744e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/takuya-takeuchi/DlibDotNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Dlib .NET wrapper written in C++ and C# for Windows, MacOS, Linux and iOS.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DiffSharp/DiffSharp\"\u003eDiffSharp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e61b7ef68addc492cfc582f0196a90e75e83f42eb7254291e33d6082d1ac390d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4469666653686172702f4469666653686172703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e61b7ef68addc492cfc582f0196a90e75e83f42eb7254291e33d6082d1ac390d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4469666653686172702f4469666653686172703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DiffSharp/DiffSharp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : DiffSharp: Differentiable Functional Programming.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dme-compunet/YOLOv8\"\u003edme-compunet/YOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/55d79485e7c1ae2fbfc92d6ab01dc585fb5ba584daa7d55f5cae4b903007f329/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646d652d636f6d70756e65742f594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/55d79485e7c1ae2fbfc92d6ab01dc585fb5ba584daa7d55f5cae4b903007f329/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646d652d636f6d70756e65742f594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dme-compunet/YOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Use YOLOv8 in real-time, for object detection, instance segmentation, pose estimation and image classification, via ONNX Runtime. \u003ca href=\"https://www.nuget.org/packages/YoloV8\" rel=\"nofollow\"\u003ewww.nuget.org/packages/YoloV8\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/techwingslab/yolov5-net\"\u003etechwingslab/yolov5-net\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/81058e3e417155701560d28eb5d51c270c1f819cd10cd3d47a7eaf079adad9ce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7465636877696e67736c61622f796f6c6f76352d6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/81058e3e417155701560d28eb5d51c270c1f819cd10cd3d47a7eaf079adad9ce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7465636877696e67736c61622f796f6c6f76352d6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/techwingslab/yolov5-net?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 object detection with C#, ML.NET, ONNX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sstainba/Yolov8.Net\"\u003esstainba/Yolov8.Net\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ea6139b829d2d8635c7d8693d6b0c922e9605df5cd3e0e6e4a034776ef5acdb2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73737461696e62612f596f6c6f76382e4e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ea6139b829d2d8635c7d8693d6b0c922e9605df5cd3e0e6e4a034776ef5acdb2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73737461696e62612f596f6c6f76382e4e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sstainba/Yolov8.Net?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A .net 6 implementation to use Yolov5 and Yolov8 models via the ONNX Runtime.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlturosDestinations/Alturos.Yolo\"\u003eAlturos.Yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a98ad31c4e663f788dca3204fc4cb511be742d3d4f3d8375e61be0a80604a82f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c7475726f7344657374696e6174696f6e732f416c7475726f732e596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a98ad31c4e663f788dca3204fc4cb511be742d3d4f3d8375e61be0a80604a82f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c7475726f7344657374696e6174696f6e732f416c7475726f732e596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlturosDestinations/Alturos.Yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : C# Yolo Darknet Wrapper (real-time object detection).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ivilson/Yolov7net\"\u003eivilson/Yolov7net\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/51beda14843c740a220050a84cd7d4215d723720e2017e1625536a3dadbb777d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6976696c736f6e2f596f6c6f76376e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/51beda14843c740a220050a84cd7d4215d723720e2017e1625536a3dadbb777d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6976696c736f6e2f596f6c6f76376e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ivilson/Yolov7net?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov7 Detector for .Net 6.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sangyuxiaowu/ml_yolov7\"\u003esangyuxiaowu/ml_yolov7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/40edbeba4bac1dedf31ebba1f5d53c86e079905ff9f404f019585d509b8cba88/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73616e6779757869616f77752f6d6c5f796f6c6f76373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/40edbeba4bac1dedf31ebba1f5d53c86e079905ff9f404f019585d509b8cba88/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73616e6779757869616f77752f6d6c5f796f6c6f76373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sangyuxiaowu/ml_yolov7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ML.NET Yolov7. \"微信公众号「桑榆肖物」《\u003ca href=\"https://mp.weixin.qq.com/s/vXz6gavYJR2mh5KuJO_slA\" rel=\"nofollow\"\u003eYOLOv7 在 ML.NET 中使用 ONNX 检测对象\u003c/a\u003e》\"\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/keijiro/TinyYOLOv2Barracuda\"\u003ekeijiro/TinyYOLOv2Barracuda\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a6429c69f71ca287223aba1d570f497ee573d558bdcdae5e06d92cc9ef818a96/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b65696a69726f2f54696e79594f4c4f76324261727261637564613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a6429c69f71ca287223aba1d570f497ee573d558bdcdae5e06d92cc9ef818a96/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b65696a69726f2f54696e79594f4c4f76324261727261637564613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/keijiro/TinyYOLOv2Barracuda?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tiny YOLOv2 on Unity Barracuda.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/derenlei/Unity_Detection2AR\"\u003ederenlei/Unity_Detection2AR\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3e7506c516faf056a532a168194b3710f07fddd4eceb80d291a28fc677e91d65/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646572656e6c65692f556e6974795f446574656374696f6e3241523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3e7506c516faf056a532a168194b3710f07fddd4eceb80d291a28fc677e91d65/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646572656e6c65692f556e6974795f446574656374696f6e3241523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/derenlei/Unity_Detection2AR?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Localize 2D image object detection in 3D Scene with Yolo in Unity Barracuda and ARFoundation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/died/YOLO3-With-OpenCvSharp4\"\u003edied/YOLO3-With-OpenCvSharp4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f18a9c87479a9a7eaf5526a9119c5280ca52b5236254406d7f91fa42a4ce5556/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646965642f594f4c4f332d576974682d4f70656e43765368617270343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f18a9c87479a9a7eaf5526a9119c5280ca52b5236254406d7f91fa42a4ce5556/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646965642f594f4c4f332d576974682d4f70656e43765368617270343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/died/YOLO3-With-OpenCvSharp4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Demo of implement YOLO v3 with OpenCvSharp v4 on C#.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mbaske/yolo-unity\"\u003embaske/yolo-unity\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/72a0cca9725264f5ac86ecedb548bba4e5431024b9f1b0d7b95d971a1f1a94f4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6261736b652f796f6c6f2d756e6974793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/72a0cca9725264f5ac86ecedb548bba4e5431024b9f1b0d7b95d971a1f1a94f4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6261736b652f796f6c6f2d756e6974793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mbaske/yolo-unity?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO In-Game Object Detection for Unity (Windows).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BobLd/YOLOv4MLNet\"\u003eBobLd/YOLOv4MLNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1dc3926c6590340b4eb3ca9ff90354080a5d2d434976e7bd4b07ed71eff75e85/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f624c642f594f4c4f76344d4c4e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1dc3926c6590340b4eb3ca9ff90354080a5d2d434976e7bd4b07ed71eff75e85/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f624c642f594f4c4f76344d4c4e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BobLd/YOLOv4MLNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Use the YOLO v4 and v5 (ONNX) models for object detection in C# using ML.Net.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/keijiro/YoloV4TinyBarracuda\"\u003ekeijiro/YoloV4TinyBarracuda\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3f75f0b55e58353fa70f3746a06f1bf76b89362d4a7be4d521d17750f245efff/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b65696a69726f2f596f6c6f563454696e794261727261637564613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3f75f0b55e58353fa70f3746a06f1bf76b89362d4a7be4d521d17750f245efff/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b65696a69726f2f596f6c6f563454696e794261727261637564613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/keijiro/YoloV4TinyBarracuda?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV4TinyBarracuda is an implementation of the YOLOv4-tiny object detection model on the Unity Barracuda neural network inference library.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zhang8043/YoloWrapper\"\u003ezhang8043/YoloWrapper\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/dc6167a62fb96d212045e5783098cf92041d918e3ac7a5391b12c114b2ff2b3d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68616e67383034332f596f6c6f577261707065723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dc6167a62fb96d212045e5783098cf92041d918e3ac7a5391b12c114b2ff2b3d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68616e67383034332f596f6c6f577261707065723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zhang8043/YoloWrapper?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : C#封装YOLOv4算法进行目标检测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/maalik0786/FastYolo\"\u003emaalik0786/FastYolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8b62ff6cd826f9eb97b7a5e0383ebba9eaf0ddc29e8ea4f59b2978fecd4aae68/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61616c696b303738362f46617374596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8b62ff6cd826f9eb97b7a5e0383ebba9eaf0ddc29e8ea4f59b2978fecd4aae68/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61616c696b303738362f46617374596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/maalik0786/FastYolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Fast Yolo for fast initializing, object detection and tracking.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Uehwan/CSharp-Yolo-Video\"\u003eUehwan/CSharp-Yolo-Video\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8b3433716d176021ffd1047b9351e3cf62a92ecd005178cefbfb08ad9b3f60a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f55656877616e2f4353686172702d596f6c6f2d566964656f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8b3433716d176021ffd1047b9351e3cf62a92ecd005178cefbfb08ad9b3f60a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f55656877616e2f4353686172702d596f6c6f2d566964656f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Uehwan/CSharp-Yolo-Video?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : C# Yolo for Video.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/https://github.com/HTTP123-A/HumanDetection_Yolov5NET\"\u003eHTTP123-A/HumanDetection_Yolov5NET\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/658512dbbf601e442b347bb2cf4f5cc7f3fbc67f199a8e938aabf06d5b024aa7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f485454503132332d412f48756d616e446574656374696f6e5f596f6c6f76354e45543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/658512dbbf601e442b347bb2cf4f5cc7f3fbc67f199a8e938aabf06d5b024aa7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f485454503132332d412f48756d616e446574656374696f6e5f596f6c6f76354e45543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HTTP123-A/HumanDetection_Yolov5NET?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 object detection with ML.NET, ONNX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Celine-Hsieh/Hand_Gesture_Training--yolov4\"\u003eCeline-Hsieh/Hand_Gesture_Training--yolov4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3c95aefa9f8c75a7a8ec40585bb3a95d8bf3d03aab81cc2c9fd506fb9935285f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43656c696e652d48736965682f48616e645f476573747572655f547261696e696e672d2d796f6c6f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3c95aefa9f8c75a7a8ec40585bb3a95d8bf3d03aab81cc2c9fd506fb9935285f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43656c696e652d48736965682f48616e645f476573747572655f547261696e696e672d2d796f6c6f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Celine-Hsieh/Hand_Gesture_Training--yolov4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Recognize the gestures' features using the YOLOv4 algorithm.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lin-tea/YOLOv5DetectionWithCSharp\"\u003elin-tea/YOLOv5DetectionWithCSharp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6de1e4170db4cdaadd9422ddef5a635feb3b60936d66b6a2fdfd421b4a3f6cbe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c696e2d7465612f594f4c4f7635446574656374696f6e576974684353686172703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6de1e4170db4cdaadd9422ddef5a635feb3b60936d66b6a2fdfd421b4a3f6cbe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c696e2d7465612f594f4c4f7635446574656374696f6e576974684353686172703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lin-tea/YOLOv5DetectionWithCSharp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5s inference In C# and Training In Python.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MirCore/Unity-Object-Detection-and-Localization-with-VR\"\u003eMirCore/Unity-Object-Detection-and-Localization-with-VR\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/972f654dfbb6dbc4d6579f9cdbf503577179014e620ae6231333f37d6757c542/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6972436f72652f556e6974792d4f626a6563742d446574656374696f6e2d616e642d4c6f63616c697a6174696f6e2d776974682d56523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/972f654dfbb6dbc4d6579f9cdbf503577179014e620ae6231333f37d6757c542/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6972436f72652f556e6974792d4f626a6563742d446574656374696f6e2d616e642d4c6f63616c697a6174696f6e2d776974682d56523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MirCore/Unity-Object-Detection-and-Localization-with-VR?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detect and localize objects from the front-facing camera image of a VR Headset in a 3D Scene in Unity using Yolo and Barracuda.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CarlAreDHopen-eaton/YoloObjectDetection\"\u003eCarlAreDHopen-eaton/YoloObjectDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a98a50e0b3fd8acd824ea348e42c65f75c266e24113ff95047b6228682f76189/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4361726c41726544486f70656e2d6561746f6e2f596f6c6f4f626a656374446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a98a50e0b3fd8acd824ea348e42c65f75c266e24113ff95047b6228682f76189/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4361726c41726544486f70656e2d6561746f6e2f596f6c6f4f626a656374446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CarlAreDHopen-eaton/YoloObjectDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo Object Detection Application for RTSP streams.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TimothyMeadows/Yolo6.NetCore\"\u003eTimothyMeadows/Yolo6.NetCore\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2454528d18834f68b0c5d221a6005f923084a2013e7a975fd32cab7316fa0bef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54696d6f7468794d6561646f77732f596f6c6f362e4e6574436f72653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2454528d18834f68b0c5d221a6005f923084a2013e7a975fd32cab7316fa0bef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54696d6f7468794d6561646f77732f596f6c6f362e4e6574436f72653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TimothyMeadows/Yolo6.NetCore?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : You Only Look Once (v6) for .NET Core LTS.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mwetzko/EasyYoloDarknet\"\u003emwetzko/EasyYoloDarknet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b5ed78c48f03abf2119c907312b16287aa3afd996c70a66a5b6b0147c8f84c7b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d7765747a6b6f2f45617379596f6c6f4461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b5ed78c48f03abf2119c907312b16287aa3afd996c70a66a5b6b0147c8f84c7b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d7765747a6b6f2f45617379596f6c6f4461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mwetzko/EasyYoloDarknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : EasyYoloDarknet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mwetzko/EasyYoloDarknet\"\u003emwetzko/EasyYoloDarknet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b5ed78c48f03abf2119c907312b16287aa3afd996c70a66a5b6b0147c8f84c7b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d7765747a6b6f2f45617379596f6c6f4461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b5ed78c48f03abf2119c907312b16287aa3afd996c70a66a5b6b0147c8f84c7b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d7765747a6b6f2f45617379596f6c6f4461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mwetzko/EasyYoloDarknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Windows optimized Yolo / Darknet Compile, Train and Detect.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cj-mills/Unity-OpenVINO-YOLOX\"\u003ecj-mills/Unity-OpenVINO-YOLOX\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/66f1f530f699e905c9f30325c095131af3813f139a36d8d42e8d22f8d7436131/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636a2d6d696c6c732f556e6974792d4f70656e56494e4f2d594f4c4f583f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/66f1f530f699e905c9f30325c095131af3813f139a36d8d42e8d22f8d7436131/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636a2d6d696c6c732f556e6974792d4f70656e56494e4f2d594f4c4f583f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cj-mills/Unity-OpenVINO-YOLOX?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This tutorial series covers how to perform object detection in the Unity game engine with the OpenVINO™ Toolkit.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/natml-hub/YOLOX\"\u003enatml-hub/YOLOX\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7720ebc131f5517d75ee77b1d3b30de724ddc4f8361be59f920725de4f138b64/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e61746d6c2d6875622f594f4c4f583f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7720ebc131f5517d75ee77b1d3b30de724ddc4f8361be59f920725de4f138b64/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e61746d6c2d6875622f594f4c4f583f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/natml-hub/YOLOX?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : High performance object detector based on YOLO series.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/thisistherealdiana/YOLO_project\"\u003ethisistherealdiana/YOLO_project\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e75214098978493e91d0bbb4264cd78b0c8a93a2dd13db854c300c86ed76b843/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7468697369737468657265616c6469616e612f594f4c4f5f70726f6a6563743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e75214098978493e91d0bbb4264cd78b0c8a93a2dd13db854c300c86ed76b843/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7468697369737468657265616c6469616e612f594f4c4f5f70726f6a6563743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/thisistherealdiana/YOLO_project?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO project made by Diana Kereselidze.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/oujunke/Yolo5Net\"\u003eoujunke/Yolo5Net\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c7e0d6731c6c8a65923c1f804a854fc8ca857bd1fa0ad191c325a08d18a35331/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f756a756e6b652f596f6c6f354e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c7e0d6731c6c8a65923c1f804a854fc8ca857bd1fa0ad191c325a08d18a35331/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f756a756e6b652f596f6c6f354e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/oujunke/Yolo5Net?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo5实现于TensorFlow.Net.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wojciechp6/YOLO-UnityBarracuda\"\u003ewojciechp6/YOLO-UnityBarracuda\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fe1b5f7774c15e65a062b07dc2f63436530114667982b3b3818e79915d7f34df/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776f6a636965636870362f594f4c4f2d556e6974794261727261637564613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fe1b5f7774c15e65a062b07dc2f63436530114667982b3b3818e79915d7f34df/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776f6a636965636870362f594f4c4f2d556e6974794261727261637564613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wojciechp6/YOLO-UnityBarracuda?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object detection app build on Unity Barracuda and YOLOv2 Tiny.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RaminAbbaszadi/YoloWrapper-WPF\"\u003eRaminAbbaszadi/YoloWrapper-WPF\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1b7a4febd22d9ec6a93c1ca2b0916ccb48f69752d337891ae8877eb775d2c901/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52616d696e41626261737a6164692f596f6c6f577261707065722d5750463f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1b7a4febd22d9ec6a93c1ca2b0916ccb48f69752d337891ae8877eb775d2c901/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52616d696e41626261737a6164692f596f6c6f577261707065722d5750463f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RaminAbbaszadi/YoloWrapper-WPF?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : WPF (C#) Yolo Darknet Wrapper.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fengyhack/YoloWpf\"\u003efengyhack/YoloWpf\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ea856b34343d7b932471ecefd1425e23f171579e553d887a77139da5829997f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66656e67796861636b2f596f6c6f5770663f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ea856b34343d7b932471ecefd1425e23f171579e553d887a77139da5829997f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66656e67796861636b2f596f6c6f5770663f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/fengyhack/YoloWpf?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : GUI demo for Object Detection with YOLO and OpenCVSharp.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hanzhuang111/Yolov5Wpf\"\u003ehanzhuang111/Yolov5Wpf\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/41143381f260201a1280875cdf12ec967b3e49d6da462e96d493de7e470631f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68616e7a6875616e673131312f596f6c6f76355770663f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/41143381f260201a1280875cdf12ec967b3e49d6da462e96d493de7e470631f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68616e7a6875616e673131312f596f6c6f76355770663f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hanzhuang111/Yolov5Wpf?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 使用ML.NET部署YOLOV5 的ONNX模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MaikoKingma/yolo-winforms-test\"\u003eMaikoKingma/yolo-winforms-test\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8de825f9e028deaccadad6a54af57b171085578433f9d41e9da933ae3c6d0772/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d61696b6f4b696e676d612f796f6c6f2d77696e666f726d732d746573743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8de825f9e028deaccadad6a54af57b171085578433f9d41e9da933ae3c6d0772/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d61696b6f4b696e676d612f796f6c6f2d77696e666f726d732d746573743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MaikoKingma/yolo-winforms-test?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Windows forms application that can execute pre-trained object detection models via ML.NET. In this instance the You Only Look Once version 4 (yolov4) is used.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SeanAnd/WebcamObjectDetection\"\u003eSeanAnd/WebcamObjectDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fbb2a879ddc3ce707a25eb6421414cd480f990a3424846d608310cd46880f655/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5365616e416e642f57656263616d4f626a656374446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fbb2a879ddc3ce707a25eb6421414cd480f990a3424846d608310cd46880f655/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5365616e416e642f57656263616d4f626a656374446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SeanAnd/WebcamObjectDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO object detection using webcam in winforms.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Devmawi/BlazorObjectDetection-Sample\"\u003eDevmawi/BlazorObjectDetection-Sample\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0a7a3aaeb487c934dad1fb44b7dc62bc26c0fbec3f566acc9eee3e21f4681ac4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465766d6177692f426c617a6f724f626a656374446574656374696f6e2d53616d706c653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0a7a3aaeb487c934dad1fb44b7dc62bc26c0fbec3f566acc9eee3e21f4681ac4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465766d6177692f426c617a6f724f626a656374446574656374696f6e2d53616d706c653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Devmawi/BlazorObjectDetection-Sample?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Simple project for demonstrating how to embed a continuously object detection with Yolo on a video in a hybrid Blazor app (WebView2).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Soju06/yolov5-annotation-viewer\"\u003eSoju06/yolov5-annotation-viewer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/af8a420482f287cbe6fbcd1b6953f5496aaee1094d3534746aaa2c5af6acad5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536f6a7530362f796f6c6f76352d616e6e6f746174696f6e2d7669657765723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/af8a420482f287cbe6fbcd1b6953f5496aaee1094d3534746aaa2c5af6acad5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536f6a7530362f796f6c6f76352d616e6e6f746174696f6e2d7669657765723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Soju06/yolov5-annotation-viewer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5 annotation viewer.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/developer-ken/YoloPredictorMLDotNet\"\u003edeveloper-ken/YoloPredictorMLDotNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8efb62ed3016a27f9182b14ec8b07146c2990d04818208ae6219de381f6802e5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646576656c6f7065722d6b656e2f596f6c6f507265646963746f724d4c446f744e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8efb62ed3016a27f9182b14ec8b07146c2990d04818208ae6219de381f6802e5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646576656c6f7065722d6b656e2f596f6c6f507265646963746f724d4c446f744e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/developer-ken/YoloPredictorMLDotNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloPredictorMLDotNet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LionelC-Kyo/CSharp_YoloV5_Torch\"\u003eLionelC-Kyo/CSharp_YoloV5_Torch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/74c95823b32eb626e61ce25fa67b4770b93ec65d72b3987355e3f95250bee81d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696f6e656c432d4b796f2f4353686172705f596f6c6f56355f546f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/74c95823b32eb626e61ce25fa67b4770b93ec65d72b3987355e3f95250bee81d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696f6e656c432d4b796f2f4353686172705f596f6c6f56355f546f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LionelC-Kyo/CSharp_YoloV5_Torch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Run Yolo V5 in C# By Torch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wanglvhang/OnnxYoloDemo\"\u003ewanglvhang/OnnxYoloDemo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e4a38e0671b113c40c05be738c7f678032c718bc959c195149a08dd345eb0d14/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e676c7668616e672f4f6e6e78596f6c6f44656d6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e4a38e0671b113c40c05be738c7f678032c718bc959c195149a08dd345eb0d14/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e676c7668616e672f4f6e6e78596f6c6f44656d6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wanglvhang/OnnxYoloDemo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : demo of using c# to run yolo onnx model with onnx runtime, and contains a windows capture tool to get bitmap from windows desktop and window.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BobLd/YOLOv3MLNet\"\u003eBobLd/YOLOv3MLNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4dc10b3385a2b85a8c90773c2e27e1d95955178ff87d81d1b21fbc5ea4d9ac52/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f624c642f594f4c4f76334d4c4e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4dc10b3385a2b85a8c90773c2e27e1d95955178ff87d81d1b21fbc5ea4d9ac52/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f624c642f594f4c4f76334d4c4e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BobLd/YOLOv3MLNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Use the YOLO v3 (ONNX) model for object detection in C# using ML.Net.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zgabi/Yolo.Net\"\u003ezgabi/Yolo.Net\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4b10c524cb2958891e32d68a2338941a330bf3aff9119560f6cb0673f6cce7a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a676162692f596f6c6f2e4e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4b10c524cb2958891e32d68a2338941a330bf3aff9119560f6cb0673f6cce7a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a676162692f596f6c6f2e4e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zgabi/Yolo.Net?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : zgabi/Yolo.Net\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/aliardan/RoadMarkingDetection\"\u003ealiardan/RoadMarkingDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d8a0e9657b36e21ea4b36d2ac3ddde74d43730cad416095efc50b4f5079b80dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69617264616e2f526f61644d61726b696e67446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d8a0e9657b36e21ea4b36d2ac3ddde74d43730cad416095efc50b4f5079b80dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69617264616e2f526f61644d61726b696e67446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/aliardan/RoadMarkingDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Road markings detection using yolov5 model based on ONNX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TimothyMeadows/Yolo5.NetCore\"\u003eTimothyMeadows/Yolo5.NetCore\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1bf8de3a3c69567b73a82121815fcda105f8af5d25d83f977ca50dc6806e437b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54696d6f7468794d6561646f77732f596f6c6f352e4e6574436f72653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1bf8de3a3c69567b73a82121815fcda105f8af5d25d83f977ca50dc6806e437b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54696d6f7468794d6561646f77732f596f6c6f352e4e6574436f72653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TimothyMeadows/Yolo5.NetCore?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : You Only Look Once (v5) for .NET Core LTS.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AD-HO/YOLOv5-ML.NET\"\u003eAD-HO/YOLOv5-ML.NET\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9a51a877c49715d4d7a57f4c441ca4ae0dc163f89e0ae63d71f1bbac55026a24/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41442d484f2f594f4c4f76352d4d4c2e4e45543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9a51a877c49715d4d7a57f4c441ca4ae0dc163f89e0ae63d71f1bbac55026a24/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41442d484f2f594f4c4f76352d4d4c2e4e45543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AD-HO/YOLOv5-ML.NET?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Inferencing Yolov5 ONNX model using ML.NET and ONNX Runtime.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ToxicSkill/YOLOV7-Webcam-inference\"\u003eToxicSkill/YOLOV7-Webcam-inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2052e5e273bf14fdfb73a4f3edddac2066f729d5db0cdf91e6753309a6ab2204/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f546f786963536b696c6c2f594f4c4f56372d57656263616d2d696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2052e5e273bf14fdfb73a4f3edddac2066f729d5db0cdf91e6753309a6ab2204/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f546f786963536b696c6c2f594f4c4f56372d57656263616d2d696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ToxicSkill/YOLOV7-Webcam-inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Simple WPF program for webcam inference with yoloV7 models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/aliardan/RoadMarkingDetection\"\u003ealiardan/RoadMarkingDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d8a0e9657b36e21ea4b36d2ac3ddde74d43730cad416095efc50b4f5079b80dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69617264616e2f526f61644d61726b696e67446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d8a0e9657b36e21ea4b36d2ac3ddde74d43730cad416095efc50b4f5079b80dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69617264616e2f526f61644d61726b696e67446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/aliardan/RoadMarkingDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Road markings detection using yolov5 model based on ONNX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/rabbitsun2/csharp_and_microsoft_ml_and_yolo_v5_sample\"\u003erabbitsun2/csharp_and_microsoft_ml_and_yolo_v5_sample\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8dd7c19660f9d09628f1a415412e2bb4936a9805361486e5c2007da0d5bb37d8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616262697473756e322f6373686172705f616e645f6d6963726f736f66745f6d6c5f616e645f796f6c6f5f76355f73616d706c653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8dd7c19660f9d09628f1a415412e2bb4936a9805361486e5c2007da0d5bb37d8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616262697473756e322f6373686172705f616e645f6d6963726f736f66745f6d6c5f616e645f796f6c6f5f76355f73616d706c653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/rabbitsun2/csharp_and_microsoft_ml_and_yolo_v5_sample?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : C#, Microsoft ML, Yolo v5, Microsoft ML.DNN, OpenCVSharp4 연계 프로젝트.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hsysfan/YOLOv5-Seg-OnnxRuntime\"\u003ehsysfan/YOLOv5-Seg-OnnxRuntime\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ca9dbcaf2cdcd6a17b49d981d92d7591316ef12154597d963ecd7d8ebfeef844/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6873797366616e2f594f4c4f76352d5365672d4f6e6e7852756e74696d653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ca9dbcaf2cdcd6a17b49d981d92d7591316ef12154597d963ecd7d8ebfeef844/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6873797366616e2f594f4c4f76352d5365672d4f6e6e7852756e74696d653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hsysfan/YOLOv5-Seg-OnnxRuntime?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 Segmenation Implementation in C# and OnnxRuntime.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dme-compunet/YOLOv8\"\u003edme-compunet/YOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/55d79485e7c1ae2fbfc92d6ab01dc585fb5ba584daa7d55f5cae4b903007f329/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646d652d636f6d70756e65742f594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/55d79485e7c1ae2fbfc92d6ab01dc585fb5ba584daa7d55f5cae4b903007f329/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646d652d636f6d70756e65742f594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dme-compunet/YOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Use YOLOv8 in real-time, for object detection, instance segmentation, pose estimation and image classification, via ONNX Runtime.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eTensorflow and Keras Implementation\u003c/h3\u003e\u003ca id=\"user-content-tensorflow-and-keras-implementation\" class=\"anchor\" aria-label=\"Permalink: Tensorflow and Keras Implementation\" href=\"#tensorflow-and-keras-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/YunYang1994/tensorflow-yolov3\"\u003eYunYang1994/tensorflow-yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/69cce1841872334df861ed1df2437aa6655dd7e8d06c4de54a9d02a76d560e35/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59756e59616e67313939342f74656e736f72666c6f772d796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/69cce1841872334df861ed1df2437aa6655dd7e8d06c4de54a9d02a76d560e35/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59756e59616e67313939342f74656e736f72666c6f772d796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/YunYang1994/tensorflow-yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🔥 TensorFlow Code for technical report: \"YOLOv3: An Incremental Improvement\".\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zzh8829/yolov3-tf2\"\u003ezzh8829/yolov3-tf2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/92dc9c99ae837db75c9e522ba7df8922670e3adfb4211585b214d339931b6cd8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a7a68383832392f796f6c6f76332d7466323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/92dc9c99ae837db75c9e522ba7df8922670e3adfb4211585b214d339931b6cd8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a7a68383832392f796f6c6f76332d7466323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zzh8829/yolov3-tf2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV3 Implemented in Tensorflow 2.0.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hunglc007/tensorflow-yolov4-tflite\"\u003ehunglc007/tensorflow-yolov4-tflite\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7098e9f8b2c4dd5fb83792783315583ae677a2977772b463cd2e94bc6aa740fd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756e676c633030372f74656e736f72666c6f772d796f6c6f76342d74666c6974653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7098e9f8b2c4dd5fb83792783315583ae677a2977772b463cd2e94bc6aa740fd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756e676c633030372f74656e736f72666c6f772d796f6c6f76342d74666c6974653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hunglc007/tensorflow-yolov4-tflite?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv4, YOLOv4-tiny, YOLOv3, YOLOv3-tiny Implemented in Tensorflow 2.0, Android. Convert YOLO v4 .weights tensorflow, tensorrt and tflite.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/gliese581gg/YOLO_tensorflow\"\u003egliese581gg/YOLO_tensorflow\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/aa82feec1d7833d2e2da94f84d001ef00645377dde1ff329bf7ed5aefa2719d7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f676c6965736535383167672f594f4c4f5f74656e736f72666c6f773f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/aa82feec1d7833d2e2da94f84d001ef00645377dde1ff329bf7ed5aefa2719d7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f676c6965736535383167672f594f4c4f5f74656e736f72666c6f773f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/gliese581gg/YOLO_tensorflow?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : tensorflow implementation of 'YOLO : Real-Time Object Detection'.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/llSourcell/YOLO_Object_Detection\"\u003ellSourcell/YOLO_Object_Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/24e2476af366f53ca70a9d83d776389cf1b9173a207302e7c2e2e11c9d254e23/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6c536f757263656c6c2f594f4c4f5f4f626a6563745f446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/24e2476af366f53ca70a9d83d776389cf1b9173a207302e7c2e2e11c9d254e23/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6c536f757263656c6c2f594f4c4f5f4f626a6563745f446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/llSourcell/YOLO_Object_Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is the code for \"YOLO Object Detection\" by Siraj Raval on Youtube.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wizyoung/YOLOv3_TensorFlow\"\u003ewizyoung/YOLOv3_TensorFlow\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d6657184c0fec52576ce554f96e7180b53b602713aa9f45aa6f4971e5777c054/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77697a796f756e672f594f4c4f76335f54656e736f72466c6f773f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d6657184c0fec52576ce554f96e7180b53b602713aa9f45aa6f4971e5777c054/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77697a796f756e672f594f4c4f76335f54656e736f72466c6f773f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wizyoung/YOLOv3_TensorFlow?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Complete YOLO v3 TensorFlow implementation. Support training on your own dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/theAIGuysCode/yolov4-deepsort\"\u003etheAIGuysCode/yolov4-deepsort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b764532c2fd44fcef54c916633e37624e70b2f98a0ce7f9cac1a6a1c794753df/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746865414947757973436f64652f796f6c6f76342d64656570736f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b764532c2fd44fcef54c916633e37624e70b2f98a0ce7f9cac1a6a1c794753df/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746865414947757973436f64652f796f6c6f76342d64656570736f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/theAIGuysCode/yolov4-deepsort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object tracking implemented with YOLOv4, DeepSort, and TensorFlow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mystic123/tensorflow-yolo-v3\"\u003emystic123/tensorflow-yolo-v3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a6e882b64953df9ea2389f8585453256b164663578d1ff6b278cf8d629dcb8bb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d79737469633132332f74656e736f72666c6f772d796f6c6f2d76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a6e882b64953df9ea2389f8585453256b164663578d1ff6b278cf8d629dcb8bb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d79737469633132332f74656e736f72666c6f772d796f6c6f2d76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mystic123/tensorflow-yolo-v3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Implementation of YOLO v3 object detector in Tensorflow (TF-Slim).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hizhangp/yolo_tensorflow\"\u003ehizhangp/yolo_tensorflow\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/96a0fda47bdbb608a8aec1997045fb8cb8d7e814234c9081e94b603b30836671/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68697a68616e67702f796f6c6f5f74656e736f72666c6f773f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/96a0fda47bdbb608a8aec1997045fb8cb8d7e814234c9081e94b603b30836671/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68697a68616e67702f796f6c6f5f74656e736f72666c6f773f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hizhangp/yolo_tensorflow?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tensorflow implementation of YOLO, including training and test phase.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nilboy/tensorflow-yolo\"\u003enilboy/tensorflow-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/10d5c7153d31076a20b2526d21c3666be3f346f9ac22791ecbed2c51bf4120f9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e696c626f792f74656e736f72666c6f772d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/10d5c7153d31076a20b2526d21c3666be3f346f9ac22791ecbed2c51bf4120f9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e696c626f792f74656e736f72666c6f772d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nilboy/tensorflow-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : tensorflow implementation of 'YOLO : Real-Time Object Detection'(train and test).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/qqwweee/keras-yolo3\"\u003eqqwweee/keras-yolo3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f382abf5c94790e427de31f5c9d203ab654a4e5ee888948987fc2e2081aab7ec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f717177776565652f6b657261732d796f6c6f333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f382abf5c94790e427de31f5c9d203ab654a4e5ee888948987fc2e2081aab7ec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f717177776565652f6b657261732d796f6c6f333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/qqwweee/keras-yolo3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Keras implementation of YOLOv3 (Tensorflow backend).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/allanzelener/YAD2K\"\u003eallanzelener/YAD2K\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/98c54e5148f3043e7b9e13992811df219a07dc25eb944700b13bcf81fe3cd1bf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c6c616e7a656c656e65722f594144324b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/98c54e5148f3043e7b9e13992811df219a07dc25eb944700b13bcf81fe3cd1bf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c6c616e7a656c656e65722f594144324b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/allanzelener/YAD2K?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YAD2K: Yet Another Darknet 2 Keras.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/experiencor/keras-yolo2\"\u003eexperiencor/keras-yolo2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b93473c24b804f154d1adac7d04b22395908168d8ae803c4bc9bc4cea24a077c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657870657269656e636f722f6b657261732d796f6c6f323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b93473c24b804f154d1adac7d04b22395908168d8ae803c4bc9bc4cea24a077c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657870657269656e636f722f6b657261732d796f6c6f323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/experiencor/keras-yolo2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv2 in Keras and Applications.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/experiencor/keras-yolo3\"\u003eexperiencor/keras-yolo3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/58a9e41bf1f9e32dba41ece6c4f0ff980bd5b2a531a94d78df0ef0dac1ac206e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657870657269656e636f722f6b657261732d796f6c6f333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/58a9e41bf1f9e32dba41ece6c4f0ff980bd5b2a531a94d78df0ef0dac1ac206e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657870657269656e636f722f6b657261732d796f6c6f333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/experiencor/keras-yolo3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Training and Detecting Objects with YOLO3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SpikeKing/keras-yolo3-detection\"\u003eSpikeKing/keras-yolo3-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/92c8eedb3c9d56b27bf7df8ac446b153716b4d1d0c3ae4874dfde3182d6bb091/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5370696b654b696e672f6b657261732d796f6c6f332d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/92c8eedb3c9d56b27bf7df8ac446b153716b4d1d0c3ae4874dfde3182d6bb091/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5370696b654b696e672f6b657261732d796f6c6f332d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SpikeKing/keras-yolo3-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO v3 物体检测算法。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xiaochus/YOLOv3\"\u003exiaochus/YOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e5af5d5a93814b718e6ea0964549bc91c0f857a838e2b40eb0a15325d76089c8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616f636875732f594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e5af5d5a93814b718e6ea0964549bc91c0f857a838e2b40eb0a15325d76089c8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616f636875732f594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xiaochus/YOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Keras implementation of yolo v3 object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolo3-keras\"\u003ebubbliiiing/yolo3-keras\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2f8de2d19e71d2f3d340996fd8cef2dcce5286c05d0829cf910f96f327fb465d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f332d6b657261733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2f8de2d19e71d2f3d340996fd8cef2dcce5286c05d0829cf910f96f327fb465d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f332d6b657261733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolo3-keras?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 这是一个yolo3-keras的源码，可以用于训练自己的模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolov4-keras\"\u003ebubbliiiing/yolov4-keras\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/223b8763864c8e5095a185503417c1ff72474b9b37595da441476507a6206655/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d6b657261733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/223b8763864c8e5095a185503417c1ff72474b9b37595da441476507a6206655/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d6b657261733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolov4-keras?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 这是一个YoloV4-keras的源码，可以用于训练自己的模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolov4-tf2\"\u003ebubbliiiing/yolov4-tf2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/78bf74e5714836e301f505a83864f9aa18366e3d2d823588fc7d79ebf021d76e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d7466323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/78bf74e5714836e301f505a83864f9aa18366e3d2d823588fc7d79ebf021d76e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d7466323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolov4-tf2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 这是一个yolo4-tf2（tensorflow2）的源码，可以用于训练自己的模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/yolov4-tiny-tf2\"\u003ebubbliiiing/yolov4-tiny-tf2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/40462360f8f13e583eecda8931c1e498c0f28240addf7442e1b9a2c364f4b544/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d74696e792d7466323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/40462360f8f13e583eecda8931c1e498c0f28240addf7442e1b9a2c364f4b544/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f796f6c6f76342d74696e792d7466323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/yolov4-tiny-tf2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 这是一个YoloV4-tiny-tf2的源码，可以用于训练自己的模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pythonlessons/TensorFlow-2.x-YOLOv3\"\u003epythonlessons/TensorFlow-2.x-YOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ca3fd42659bbd1b6d9879445005011235d01d5f792fa36cce50280581db15163/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f707974686f6e6c6573736f6e732f54656e736f72466c6f772d322e782d594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ca3fd42659bbd1b6d9879445005011235d01d5f792fa36cce50280581db15163/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f707974686f6e6c6573736f6e732f54656e736f72466c6f772d322e782d594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pythonlessons/TensorFlow-2.x-YOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv3 implementation in TensorFlow 2.3.1.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/miemie2013/Keras-YOLOv4\"\u003emiemie2013/Keras-YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/06eb998a993df6aea7e1ba25b5323f9f395daff30300e666ce3339c5b3bdfa26/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69656d6965323031332f4b657261732d594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/06eb998a993df6aea7e1ba25b5323f9f395daff30300e666ce3339c5b3bdfa26/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69656d6965323031332f4b657261732d594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/miemie2013/Keras-YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PPYOLO AND YOLOv4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ma-Dan/keras-yolo4\"\u003eMa-Dan/keras-yolo4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2c189e2736465d4b9cdbaa10742c1899833a061fd09904d3d5aacbaca8b93131/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d612d44616e2f6b657261732d796f6c6f343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2c189e2736465d4b9cdbaa10742c1899833a061fd09904d3d5aacbaca8b93131/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d612d44616e2f6b657261732d796f6c6f343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ma-Dan/keras-yolo4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Keras implementation of YOLOv4 (Tensorflow backend).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/miranthajayatilake/YOLOw-Keras\"\u003emiranthajayatilake/YOLOw-Keras\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cbe50e9b152075fdfbc6059f01c9f476cb1fe6958a1c87a86a8b94807547a14b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6972616e7468616a61796174696c616b652f594f4c4f772d4b657261733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cbe50e9b152075fdfbc6059f01c9f476cb1fe6958a1c87a86a8b94807547a14b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6972616e7468616a61796174696c616b652f594f4c4f772d4b657261733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/miranthajayatilake/YOLOw-Keras?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv2 Object Detection w/ Keras (in just 20 lines of code).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/maiminh1996/YOLOv3-tensorflow\"\u003emaiminh1996/YOLOv3-tensorflow\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/144736fd84de7be7bbb8a31b7fd2048b7eed92cc5e04bfe14ec025a42e0bb930/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61696d696e68313939362f594f4c4f76332d74656e736f72666c6f773f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/144736fd84de7be7bbb8a31b7fd2048b7eed92cc5e04bfe14ec025a42e0bb930/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61696d696e68313939362f594f4c4f76332d74656e736f72666c6f773f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/maiminh1996/YOLOv3-tensorflow?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Re-implement YOLOv3 with TensorFlow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Stick-To/Object-Detection-Tensorflow\"\u003eStick-To/Object-Detection-Tensorflow\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/57ee0a553ad1548130b1d1d9364af3c2c43c1219a846c08f94da6d0d77248dee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f537469636b2d546f2f4f626a6563742d446574656374696f6e2d54656e736f72666c6f773f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/57ee0a553ad1548130b1d1d9364af3c2c43c1219a846c08f94da6d0d77248dee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f537469636b2d546f2f4f626a6563742d446574656374696f6e2d54656e736f72666c6f773f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Stick-To/Object-Detection-Tensorflow?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object Detection API Tensorflow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/avBuffer/Yolov5_tf\"\u003eavBuffer/Yolov5_tf\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d0b88aa2cd00c416cda98e60dd9368423710adcfe125d7b3d5d5002667eddb3b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61764275666665722f596f6c6f76355f74663f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d0b88aa2cd00c416cda98e60dd9368423710adcfe125d7b3d5d5002667eddb3b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61764275666665722f596f6c6f76355f74663f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/avBuffer/Yolov5_tf?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov5/Yolov4/ Yolov3/ Yolo_tiny in tensorflow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ruiminshen/yolo-tf\"\u003eruiminshen/yolo-tf\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/76012a882d3430830f37bdf48f4f85bb26795a7556126ff0970d5ddc10551652/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7275696d696e7368656e2f796f6c6f2d74663f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/76012a882d3430830f37bdf48f4f85bb26795a7556126ff0970d5ddc10551652/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7275696d696e7368656e2f796f6c6f2d74663f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ruiminshen/yolo-tf?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorFlow implementation of the YOLO (You Only Look Once).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xiao9616/yolo4_tensorflow2\"\u003exiao9616/yolo4_tensorflow2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/95c1eb598faa93b4695cbfad5bcdb3c69e6bd4df5137afd4e0174d2bd189705b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616f393631362f796f6c6f345f74656e736f72666c6f77323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/95c1eb598faa93b4695cbfad5bcdb3c69e6bd4df5137afd4e0174d2bd189705b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616f393631362f796f6c6f345f74656e736f72666c6f77323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xiao9616/yolo4_tensorflow2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolo 4th edition implemented by tensorflow2.0.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sicara/tf2-yolov4\"\u003esicara/tf2-yolov4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/da84ad7b5be3c9f1189886c4696380310e41dd7d9a07f2d88515365e05608acd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7369636172612f7466322d796f6c6f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/da84ad7b5be3c9f1189886c4696380310e41dd7d9a07f2d88515365e05608acd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7369636172612f7466322d796f6c6f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sicara/tf2-yolov4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A TensorFlow 2.0 implementation of YOLOv4: Optimal Speed and Accuracy of Object Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LongxingTan/Yolov5\"\u003eLongxingTan/Yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2073f53c6fe4a01fd58bbc741d10503ef516cab9a9b1bc09ed29fb491f48deee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c6f6e6778696e6754616e2f596f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2073f53c6fe4a01fd58bbc741d10503ef516cab9a9b1bc09ed29fb491f48deee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c6f6e6778696e6754616e2f596f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LongxingTan/Yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Efficient implementation of YOLOV5 in TensorFlow2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/geekjr/quickai\"\u003egeekjr/quickai\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ca5bc1905f588a0c5cfe84024d61ac83732034c700147fae12ccb435fc7d7d04/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6765656b6a722f717569636b61693f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ca5bc1905f588a0c5cfe84024d61ac83732034c700147fae12ccb435fc7d7d04/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6765656b6a722f717569636b61693f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/geekjr/quickai?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : QuickAI is a Python library that makes it extremely easy to experiment with state-of-the-art Machine Learning models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://gitee.com/CV_Lab/yolov5_rt_tfjs\" rel=\"nofollow\"\u003eCV_Lab/yolov5_rt_tfjs\u003c/a\u003e : 🚀 基于TensorFlow.js的YOLOv5实时目标检测项目。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Burf/TFDetection\"\u003eBurf/TFDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cf89c158090c1761515fa5c73b89866ce874e135e735c33bb5e9e0eb0f67ee5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427572662f5446446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cf89c158090c1761515fa5c73b89866ce874e135e735c33bb5e9e0eb0f67ee5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427572662f5446446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Burf/TFDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Detection Toolbox for Tensorflow2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/taipingeric/yolo-v4-tf.keras\"\u003etaipingeric/yolo-v4-tf.keras\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b030793d44ff9e197eb3254872d3703341efa24e1bcb05e4cc85037bb827e44f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616970696e67657269632f796f6c6f2d76342d74662e6b657261733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b030793d44ff9e197eb3254872d3703341efa24e1bcb05e4cc85037bb827e44f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616970696e67657269632f796f6c6f2d76342d74662e6b657261733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/taipingeric/yolo-v4-tf.keras?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A simple tf.keras implementation of YOLO v4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/david8862/keras-YOLOv3-model-set\"\u003edavid8862/keras-YOLOv3-model-set\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5b9abe069a1e8a1623bdc317705d0e790b4146488420617ad3d754791cf14866/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6461766964383836322f6b657261732d594f4c4f76332d6d6f64656c2d7365743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5b9abe069a1e8a1623bdc317705d0e790b4146488420617ad3d754791cf14866/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6461766964383836322f6b657261732d594f4c4f76332d6d6f64656c2d7365743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/david8862/keras-YOLOv3-model-set?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : end-to-end YOLOv4/v3/v2 object detection pipeline, implemented on tf.keras with different technologies.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003ePaddlePaddle Implementation\u003c/h3\u003e\u003ca id=\"user-content-paddlepaddle-implementation\" class=\"anchor\" aria-label=\"Permalink: PaddlePaddle Implementation\" href=\"#paddlepaddle-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PaddlePaddle/PaddleDetection\"\u003ePaddlePaddle/PaddleDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f3c9773ff34de7d0d273c5bd7486e9b01fe36c95a0f0fa0b9d86fbfb6fb7d045/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506164646c65506164646c652f506164646c65446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f3c9773ff34de7d0d273c5bd7486e9b01fe36c95a0f0fa0b9d86fbfb6fb7d045/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506164646c65506164646c652f506164646c65446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PaddlePaddle/PaddleDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object Detection toolkit based on PaddlePaddle. \"PP-YOLO: An Effective and Efficient Implementation of Object Detector\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2007.12099\" rel=\"nofollow\"\u003earXiv 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nemonameless/PaddleDetection_YOLOv5\"\u003enemonameless/PaddleDetection_YOLOv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/61c9615add66892a90cd6ca65dde57c1db3ae2dd70f5abea056505866a814dc7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e656d6f6e616d656c6573732f506164646c65446574656374696f6e5f594f4c4f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/61c9615add66892a90cd6ca65dde57c1db3ae2dd70f5abea056505866a814dc7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e656d6f6e616d656c6573732f506164646c65446574656374696f6e5f594f4c4f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nemonameless/PaddleDetection_YOLOv5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 of PaddleDetection, Paddle implementation of YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nemonameless/PaddleDetection_YOLOX\"\u003enemonameless/PaddleDetection_YOLOX\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e883d3715a631e2f9ec053a1411d746c0dd9d5e3a95bea4f2d75ced37f30727a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e656d6f6e616d656c6573732f506164646c65446574656374696f6e5f594f4c4f583f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e883d3715a631e2f9ec053a1411d746c0dd9d5e3a95bea4f2d75ced37f30727a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e656d6f6e616d656c6573732f506164646c65446574656374696f6e5f594f4c4f583f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nemonameless/PaddleDetection_YOLOX?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Paddle YOLOX, 51.8% on COCO val by YOLOX-x, 44.6% on YOLOX-ConvNeXt-s.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nemonameless/PaddleDetection_YOLOset\"\u003enemonameless/PaddleDetection_YOLOset\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f7dfc4961a9b68cc235b262ff54da416091dc4224de9c046b4eb20383f408211/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e656d6f6e616d656c6573732f506164646c65446574656374696f6e5f594f4c4f7365743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f7dfc4961a9b68cc235b262ff54da416091dc4224de9c046b4eb20383f408211/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e656d6f6e616d656c6573732f506164646c65446574656374696f6e5f594f4c4f7365743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nemonameless/PaddleDetection_YOLOset?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Paddle YOLO set: YOLOv3, PPYOLO, PPYOLOE, YOLOX, YOLOv5, YOLOv7 and so on.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/miemie2013/Paddle-YOLOv4\"\u003emiemie2013/Paddle-YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0fce707f3f45f23147f245271c4d5a8be3a26b443e7cb8316acd4786487d0d5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69656d6965323031332f506164646c652d594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0fce707f3f45f23147f245271c4d5a8be3a26b443e7cb8316acd4786487d0d5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69656d6965323031332f506164646c652d594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/miemie2013/Paddle-YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Paddle-YOLOv4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Sharpiless/PaddleDetection-Yolov5\"\u003eSharpiless/PaddleDetection-Yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/857b829521fd3bd2f58a49458c09d03db6a06abd0bbe0652daf584af2196e377/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f506164646c65446574656374696f6e2d596f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/857b829521fd3bd2f58a49458c09d03db6a06abd0bbe0652daf584af2196e377/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f506164646c65446574656374696f6e2d596f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Sharpiless/PaddleDetection-Yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于Paddlepaddle复现yolov5，支持PaddleDetection接口。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Nioolek/PPYOLOE_pytorch\"\u003eNioolek/PPYOLOE_pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6a93992f64621b8298cb9221906bddff90badd65b0ab80545f8c804a0e8df884/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e696f6f6c656b2f5050594f4c4f455f7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6a93992f64621b8298cb9221906bddff90badd65b0ab80545f8c804a0e8df884/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e696f6f6c656b2f5050594f4c4f455f7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Nioolek/PPYOLOE_pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An unofficial implementation of Pytorch version PP-YOLOE,based on Megvii YOLOX training code.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCaffe Implementation\u003c/h3\u003e\u003ca id=\"user-content-caffe-implementation\" class=\"anchor\" aria-label=\"Permalink: Caffe Implementation\" href=\"#caffe-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ChenYingpeng/caffe-yolov3\"\u003eChenYingpeng/caffe-yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/307e96673c3fb834371dee728e35170ddd1d1e9979fdd92051adda0a18cf88dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368656e59696e6770656e672f63616666652d796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/307e96673c3fb834371dee728e35170ddd1d1e9979fdd92051adda0a18cf88dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368656e59696e6770656e672f63616666652d796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ChenYingpeng/caffe-yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A real-time object detection framework of Yolov3/v4 based on caffe.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ChenYingpeng/darknet2caffe\"\u003eChenYingpeng/darknet2caffe\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f9234ff083ca12f5e4b58caab44c2ed4045005429df73149b091a06551ce51aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368656e59696e6770656e672f6461726b6e65743263616666653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f9234ff083ca12f5e4b58caab44c2ed4045005429df73149b091a06551ce51aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368656e59696e6770656e672f6461726b6e65743263616666653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ChenYingpeng/darknet2caffe?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Convert darknet weights to caffemodel.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/eric612/Caffe-YOLOv3-Windows\"\u003eeric612/Caffe-YOLOv3-Windows\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ee72874502fafefeb1cb7e098ffd88a4b10b2da1c12ec38d1ecc56f111abb96a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657269633631322f43616666652d594f4c4f76332d57696e646f77733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ee72874502fafefeb1cb7e098ffd88a4b10b2da1c12ec38d1ecc56f111abb96a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657269633631322f43616666652d594f4c4f76332d57696e646f77733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/eric612/Caffe-YOLOv3-Windows?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A windows caffe implementation of YOLO detection network.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Harick1/caffe-yolo\"\u003eHarick1/caffe-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/38f0f18570d5e42dd3ada3edfd95dc9d844ce6962bc715b384e8c45dd2576ac2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48617269636b312f63616666652d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/38f0f18570d5e42dd3ada3edfd95dc9d844ce6962bc715b384e8c45dd2576ac2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48617269636b312f63616666652d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Harick1/caffe-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Caffe for YOLO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/choasup/caffe-yolo9000\"\u003echoasup/caffe-yolo9000\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/db4ee788ba3fe69da1d9b7a63326211a664778b3dcbbfd98710ce29b95a0b59e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63686f617375702f63616666652d796f6c6f393030303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/db4ee788ba3fe69da1d9b7a63326211a664778b3dcbbfd98710ce29b95a0b59e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63686f617375702f63616666652d796f6c6f393030303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/choasup/caffe-yolo9000?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Caffe for YOLOv2 \u0026amp; YOLO9000.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/gklz1982/caffe-yolov2\"\u003egklz1982/caffe-yolov2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/24f694e54bb220b2c45550e030f83b32744d73d951ff07d9b7b2d7bf59a4d8c8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f676b6c7a313938322f63616666652d796f6c6f76323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/24f694e54bb220b2c45550e030f83b32744d73d951ff07d9b7b2d7bf59a4d8c8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f676b6c7a313938322f63616666652d796f6c6f76323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/gklz1982/caffe-yolov2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : caffe-yolov2.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eMXNet Implementation\u003c/h3\u003e\u003ca id=\"user-content-mxnet-implementation\" class=\"anchor\" aria-label=\"Permalink: MXNet Implementation\" href=\"#mxnet-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dmlc/gluon-cv\"\u003eGluon CV Toolkit\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/67e8a659da8bcf14d75581b0d011131aa56bed5993da5fc6d48b03d0f63ced30/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646d6c632f676c756f6e2d63763f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/67e8a659da8bcf14d75581b0d011131aa56bed5993da5fc6d48b03d0f63ced30/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646d6c632f676c756f6e2d63763f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dmlc/gluon-cv?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : GluonCV provides implementations of the state-of-the-art (SOTA) deep learning models in computer vision.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zhreshold/mxnet-yolo\"\u003ezhreshold/mxnet-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1a9c805e7d7623c2a0a0546063c565981a99cd2f044b0ff1ccae3055f92b4f0c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68726573686f6c642f6d786e65742d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1a9c805e7d7623c2a0a0546063c565981a99cd2f044b0ff1ccae3055f92b4f0c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68726573686f6c642f6d786e65742d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zhreshold/mxnet-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO: You only look once real-time object detector.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eWeb Implementation\u003c/h3\u003e\u003ca id=\"user-content-web-implementation\" class=\"anchor\" aria-label=\"Permalink: Web Implementation\" href=\"#web-implementation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ModelDepot/tfjs-yolo-tiny\"\u003eModelDepot/tfjs-yolo-tiny\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/95e7d5171aca6a2cb42cc5a37fb7fbd153d1d0b82cf01e23c9e836fdf0548bba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f64656c4465706f742f74666a732d796f6c6f2d74696e793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/95e7d5171aca6a2cb42cc5a37fb7fbd153d1d0b82cf01e23c9e836fdf0548bba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f64656c4465706f742f74666a732d796f6c6f2d74696e793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ModelDepot/tfjs-yolo-tiny?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : In-Browser Object Detection using Tiny YOLO on Tensorflow.js.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/justadudewhohacks/tfjs-tiny-yolov2\"\u003ejustadudewhohacks/tfjs-tiny-yolov2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/44d4a6c3fc482435d3a3e91df3e9a9f44a7b7402613f9db16bd657aa831a6f90/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a757374616475646577686f6861636b732f74666a732d74696e792d796f6c6f76323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/44d4a6c3fc482435d3a3e91df3e9a9f44a7b7402613f9db16bd657aa831a6f90/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a757374616475646577686f6861636b732f74666a732d74696e792d796f6c6f76323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/justadudewhohacks/tfjs-tiny-yolov2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tiny YOLO v2 object detection with tensorflow.js.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/reu2018DL/YOLO-LITE\"\u003ereu2018DL/YOLO-LITE\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/80778432726d750c63bdbf7ab68003a4062cf1aad9c4eeb159252b07f2b4ab69/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72657532303138444c2f594f4c4f2d4c4954453f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/80778432726d750c63bdbf7ab68003a4062cf1aad9c4eeb159252b07f2b4ab69/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72657532303138444c2f594f4c4f2d4c4954453f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/reu2018DL/YOLO-LITE?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO-LITE is a web implementation of YOLOv2-tiny.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mobimeo/node-yolo\"\u003emobimeo/node-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e6dd3d99914b1ee67dab473610c27b703148942eaa0de43fdb26e980d2b9ac5f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6f62696d656f2f6e6f64652d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e6dd3d99914b1ee67dab473610c27b703148942eaa0de43fdb26e980d2b9ac5f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6f62696d656f2f6e6f64652d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mobimeo/node-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Node bindings for YOLO/Darknet image recognition library.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Sharpiless/Yolov5-Flask-VUE\"\u003eSharpiless/Yolov5-Flask-VUE\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/90a0db3fb21469de04241c2b56a8a0c5a4bb39b5efadf73d9d198afc08625cbc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76352d466c61736b2d5655453f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/90a0db3fb21469de04241c2b56a8a0c5a4bb39b5efadf73d9d198afc08625cbc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76352d466c61736b2d5655453f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Sharpiless/Yolov5-Flask-VUE?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于Flask开发后端、VUE开发前端框架，在WEB端部署YOLOv5目标检测模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/shaqian/tfjs-yolo\"\u003eshaqian/tfjs-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f5612b3707bbbc44ce50b401037c4b5df2c53b89ba22d03471eced2893c0cd59/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7368617169616e2f74666a732d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f5612b3707bbbc44ce50b401037c4b5df2c53b89ba22d03471eced2893c0cd59/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7368617169616e2f74666a732d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/shaqian/tfjs-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO v3 and Tiny YOLO v1, v2, v3 with Tensorflow.js.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zqingr/tfjs-yolov3\"\u003ezqingr/tfjs-yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d96ce8a883d78f2f4a358a68a605e1134bed92dd2b7e8634deb001bed29e2ecc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a71696e67722f74666a732d796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d96ce8a883d78f2f4a358a68a605e1134bed92dd2b7e8634deb001bed29e2ecc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a71696e67722f74666a732d796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zqingr/tfjs-yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Tensorflow js implementation of YOLOv3 and YOLOv3-tiny.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bennetthardwick/darknet.js\"\u003ebennetthardwick/darknet.js\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bbebcd4253f992efdc0be357b2a73a7cb61eb8cce09afeaae5ace4b1a9a5c598/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62656e6e657474686172647769636b2f6461726b6e65742e6a733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bbebcd4253f992efdc0be357b2a73a7cb61eb8cce09afeaae5ace4b1a9a5c598/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62656e6e657474686172647769636b2f6461726b6e65742e6a733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bennetthardwick/darknet.js?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A NodeJS wrapper of pjreddie's darknet / yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nihui/ncnn-webassembly-yolov5\"\u003enihui/ncnn-webassembly-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/efb42dd0f4f6883bf82afad80432bee64fbea22d428fe46d74c8b1d0cb100102/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e696875692f6e636e6e2d776562617373656d626c792d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/efb42dd0f4f6883bf82afad80432bee64fbea22d428fe46d74c8b1d0cb100102/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e696875692f6e636e6e2d776562617373656d626c792d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nihui/ncnn-webassembly-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Deploy YOLOv5 in your web browser with ncnn and webassembly.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/muhk01/Yolov5-on-Flask\"\u003emuhk01/Yolov5-on-Flask\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a0e26ec4e167038ed01cff1f0360fbeb819aafce40eb28f6b40330451b777e8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d75686b30312f596f6c6f76352d6f6e2d466c61736b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a0e26ec4e167038ed01cff1f0360fbeb819aafce40eb28f6b40330451b777e8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d75686b30312f596f6c6f76352d6f6e2d466c61736b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/muhk01/Yolov5-on-Flask?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Running YOLOv5 through web browser using Flask microframework.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tcyfree/yolov5\"\u003etcyfree/yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fdac64d776d2983ea0e2442abd9b3914da35c13c7b53f4b61cc73cc0a8e1a140/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746379667265652f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fdac64d776d2983ea0e2442abd9b3914da35c13c7b53f4b61cc73cc0a8e1a140/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746379667265652f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tcyfree/yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于Flask开发后端、VUE开发前端框架，在WEB端部署YOLOv5目标检测模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/siffyy/YOLOv5-Web-App-for-Vehicle-Detection\"\u003esiffyy/YOLOv5-Web-App-for-Vehicle-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9c91b5d607038bddf394a4693e466a5a041c61a492953529692563626c505cb3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7369666679792f594f4c4f76352d5765622d4170702d666f722d56656869636c652d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9c91b5d607038bddf394a4693e466a5a041c61a492953529692563626c505cb3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7369666679792f594f4c4f76352d5765622d4170702d666f722d56656869636c652d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/siffyy/YOLOv5-Web-App-for-Vehicle-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Repo for Web Application for Vehicle detection from Satellite Imagery using YOLOv5 model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Devmawi/BlazorObjectDetection-Sample\"\u003eDevmawi/BlazorObjectDetection-Sample\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0a7a3aaeb487c934dad1fb44b7dc62bc26c0fbec3f566acc9eee3e21f4681ac4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465766d6177692f426c617a6f724f626a656374446574656374696f6e2d53616d706c653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0a7a3aaeb487c934dad1fb44b7dc62bc26c0fbec3f566acc9eee3e21f4681ac4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465766d6177692f426c617a6f724f626a656374446574656374696f6e2d53616d706c653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Devmawi/BlazorObjectDetection-Sample?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A sample for demonstrating online execution of an onnx model by a Blazor app.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Hyuto/yolov5-onnxruntime-web\"\u003eHyuto/yolov5-onnxruntime-web\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f73317c3801a14112cc950c80e5ad4845acc8b61d4fa92c11b2b0e38b007ff8d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f487975746f2f796f6c6f76352d6f6e6e7872756e74696d652d7765623f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f73317c3801a14112cc950c80e5ad4845acc8b61d4fa92c11b2b0e38b007ff8d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f487975746f2f796f6c6f76352d6f6e6e7872756e74696d652d7765623f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Hyuto/yolov5-onnxruntime-web?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 right in your browser with onnxruntime-web.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOthers\u003c/h3\u003e\u003ca id=\"user-content-others\" class=\"anchor\" aria-label=\"Permalink: Others\" href=\"#others\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jinfagang/yolov7_d2\"\u003ejinfagang/yolov7_d2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/75ac2ec2ed94f7b5b8bf93a2d80ae03b5f10440c8ade9ba824eab65dcfa62e05/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a696e666167616e672f796f6c6f76375f64323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/75ac2ec2ed94f7b5b8bf93a2d80ae03b5f10440c8ade9ba824eab65dcfa62e05/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a696e666167616e672f796f6c6f76375f64323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jinfagang/yolov7_d2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🔥🔥🔥🔥 (Earlier YOLOv7 not official one) YOLO with Transformers and Instance Segmentation, with TensorRT acceleration! 🔥🔥🔥\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yang-0201/YOLOv6_pro\"\u003eyang-0201/YOLOv6_pro\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2ce9ac5f491826cbfc3c3008d94ceb548400eda43f3cd48bddeec5399d09a90d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f79616e672d303230312f594f4c4f76365f70726f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2ce9ac5f491826cbfc3c3008d94ceb548400eda43f3cd48bddeec5399d09a90d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f79616e672d303230312f594f4c4f76365f70726f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yang-0201/YOLOv6_pro?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Make it easier for yolov6 to change the network structure.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/j-marple-dev/AYolov2\"\u003ej-marple-dev/AYolov2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e87fe72ff0a677240effb3ba6bac8b6245f5948655d4311881fb8600a7b3695d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a2d6d6172706c652d6465762f41596f6c6f76323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e87fe72ff0a677240effb3ba6bac8b6245f5948655d4311881fb8600a7b3695d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a2d6d6172706c652d6465762f41596f6c6f76323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/j-marple-dev/AYolov2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The main goal of this repository is to rewrite the object detection pipeline with a better code structure for better portability and adaptability to apply new experimental methods. The object detection pipeline is based on \u003ca href=\"https://github.com/ultralytics/yolov5\"\u003eUltralytics YOLOv5\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fcakyon/yolov5-pip\"\u003efcakyon/yolov5-pip\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/181dce865af43b3ceeaa66297c4abe04f6eb885d68ec4883b8a8a825da686b75/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6663616b796f6e2f796f6c6f76352d7069703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/181dce865af43b3ceeaa66297c4abe04f6eb885d68ec4883b8a8a825da686b75/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6663616b796f6e2f796f6c6f76352d7069703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/fcakyon/yolov5-pip?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Packaged version of ultralytics/yolov5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kadirnar/yolov6-pip\"\u003ekadirnar/yolov6-pip\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/83a4b786e66c05082bde11bd221ea5bf74b15860fc6e6371cc662e6e21ebf77a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f796f6c6f76362d7069703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/83a4b786e66c05082bde11bd221ea5bf74b15860fc6e6371cc662e6e21ebf77a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f796f6c6f76362d7069703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kadirnar/yolov6-pip?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Packaged version of yolov6 model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kadirnar/yolov7-pip\"\u003ekadirnar/yolov7-pip\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fcc88c8f689bac403c5561a89c13f44b5e3f0ccf5fcffe82eb6e541955588ea9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f796f6c6f76372d7069703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fcc88c8f689bac403c5561a89c13f44b5e3f0ccf5fcffe82eb6e541955588ea9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f796f6c6f76372d7069703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kadirnar/yolov7-pip?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Packaged version of yolov7 model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kadirnar/torchyolo\"\u003ekadirnar/torchyolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/03c8a6e2443aa79b0fcfd8cc46ef788691df34f97509376bb23322430e53d5bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f746f726368796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/03c8a6e2443aa79b0fcfd8cc46ef788691df34f97509376bb23322430e53d5bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f746f726368796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kadirnar/torchyolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PyTorch implementation of YOLOv5, YOLOv6, YOLOv7, YOLOX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/shanglianlm0525/CvPytorch\"\u003eCvPytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ba551cd3c0404b99f027ebe9e1ff68b11284ae895f7363bb54dce7a047e1c2ee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7368616e676c69616e6c6d303532352f43765079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ba551cd3c0404b99f027ebe9e1ff68b11284ae895f7363bb54dce7a047e1c2ee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7368616e676c69616e6c6d303532352f43765079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/shanglianlm0525/CvPytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : CvPytorch is an open source COMPUTER VISION toolbox based on PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/frgfm/Holocron\"\u003eHolocron\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c1c4cf2e7ea11e006d2e56999997f0226f8a9a7e9222ccbecd8f7db644568f90/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f667267666d2f486f6c6f63726f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c1c4cf2e7ea11e006d2e56999997f0226f8a9a7e9222ccbecd8f7db644568f90/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f667267666d2f486f6c6f63726f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/frgfm/Holocron?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PyTorch implementations of recent Computer Vision tricks (ReXNet, RepVGG, Unet3p, YOLOv4, CIoU loss, AdaBelief, PolyLoss).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DL-Practise/YoloAll\"\u003eDL-Practise/YoloAll\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e30775ab2fd883b2328629fe0c7b61868830747e3bdb3666c0992dcc49843637/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f444c2d50726163746973652f596f6c6f416c6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e30775ab2fd883b2328629fe0c7b61868830747e3bdb3666c0992dcc49843637/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f444c2d50726163746973652f596f6c6f416c6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DL-Practise/YoloAll?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloAll is a collection of yolo all versions. you you use YoloAll to test yolov3/yolov5/yolox/yolo_fastest.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/msnh2012/Msnhnet\"\u003emsnh2012/Msnhnet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e2b3164bbcd5e135a9730be6a8f8e319c63d18aaaa29508bd0442e5fb85bca45/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d736e68323031322f4d736e686e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e2b3164bbcd5e135a9730be6a8f8e319c63d18aaaa29508bd0442e5fb85bca45/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d736e68323031322f4d736e686e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/msnh2012/Msnhnet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : (yolov3 yolov4 yolov5 unet ...)A mini pytorch inference framework which inspired from darknet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xinghanliuying/yolov5-trick\"\u003exinghanliuying/yolov5-trick\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/91ebf281beafca1882db28e35cb8f4e184350ba5548a910ba79e9e52d757fa53/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78696e6768616e6c697579696e672f796f6c6f76352d747269636b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/91ebf281beafca1882db28e35cb8f4e184350ba5548a910ba79e9e52d757fa53/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78696e6768616e6c697579696e672f796f6c6f76352d747269636b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xinghanliuying/yolov5-trick?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于yolov5的改进库。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BMW-InnovationLab/BMW-YOLOv4-Training-Automation\"\u003eBMW-InnovationLab/BMW-YOLOv4-Training-Automation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2ecbce3b056df31c432437681ef4a5727734394ae1564a8f1d2dc4dac9521ab8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f424d572d496e6e6f766174696f6e4c61622f424d572d594f4c4f76342d547261696e696e672d4175746f6d6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2ecbce3b056df31c432437681ef4a5727734394ae1564a8f1d2dc4dac9521ab8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f424d572d496e6e6f766174696f6e4c61622f424d572d594f4c4f76342d547261696e696e672d4175746f6d6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BMW-InnovationLab/BMW-YOLOv4-Training-Automation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv4-v3 Training Automation API for Linux.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AntonMu/TrainYourOwnYOLO\"\u003eAntonMu/TrainYourOwnYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/18654c49f1d1514b5e3e67a8287c3783656bc904ac3c8d0dc19d9b46ee094fcf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e746f6e4d752f547261696e596f75724f776e594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/18654c49f1d1514b5e3e67a8287c3783656bc904ac3c8d0dc19d9b46ee094fcf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e746f6e4d752f547261696e596f75724f776e594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AntonMu/TrainYourOwnYOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Train a state-of-the-art yolov3 object detector from scratch!\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/madhawav/YOLO3-4-Py\"\u003emadhawav/YOLO3-4-Py\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ef379b0c142ca5c497c41c505d5265aa0d85e8a5afe186448c246a8fd86fba98/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d616468617761762f594f4c4f332d342d50793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ef379b0c142ca5c497c41c505d5265aa0d85e8a5afe186448c246a8fd86fba98/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d616468617761762f594f4c4f332d342d50793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/madhawav/YOLO3-4-Py?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Python wrapper on Darknet. Compatible with YOLO V3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/theAIGuysCode/yolov4-custom-functions\"\u003etheAIGuysCode/yolov4-custom-functions\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/af252087e8c8581a60b23bb9addec4a153e71b1802cba6327e9e063cd7571470/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746865414947757973436f64652f796f6c6f76342d637573746f6d2d66756e6374696f6e733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/af252087e8c8581a60b23bb9addec4a153e71b1802cba6327e9e063cd7571470/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746865414947757973436f64652f796f6c6f76342d637573746f6d2d66756e6374696f6e733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/theAIGuysCode/yolov4-custom-functions?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Wide Range of Custom Functions for YOLOv4, YOLOv4-tiny, YOLOv3, and YOLOv3-tiny Implemented in TensorFlow, TFLite, and TensorRT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tiquasar/FLAITER\"\u003etiquasar/FLAITER\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/47159639a6a6d90c3acf47e60e6cf7f588cc9a39ee94ab77265a4a963bddd168/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74697175617361722f464c41495445523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/47159639a6a6d90c3acf47e60e6cf7f588cc9a39ee94ab77265a4a963bddd168/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74697175617361722f464c41495445523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tiquasar/FLAITER?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Machine Learning and AI Mobile Application.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kadirnar/Minimal-Yolov6\"\u003ekadirnar/Minimal-Yolov6\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/dcdb67d8dd1902d19c002a6635d9b05067a7599a1333c2e394b3fc4426532018/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f4d696e696d616c2d596f6c6f76363f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dcdb67d8dd1902d19c002a6635d9b05067a7599a1333c2e394b3fc4426532018/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f4d696e696d616c2d596f6c6f76363f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kadirnar/Minimal-Yolov6?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Minimal-Yolov6.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DataXujing/YOLOv6\"\u003eDataXujing/YOLOv6\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1376f59ff435534195ed900b5b04c52e39aae9dc90c19527edbfff62f58728bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f76363f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1376f59ff435534195ed900b5b04c52e39aae9dc90c19527edbfff62f58728bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f76363f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DataXujing/YOLOv6?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🌀 🌀 手摸手 美团 YOLOv6模型训练和TensorRT端到端部署方案教程。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DataXujing/YOLOv7\"\u003eDataXujing/YOLOv7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b9725daecb5df18b934fb9ad1b2a3a894a207a8f8c012d9d57379153e8380891/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f76373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b9725daecb5df18b934fb9ad1b2a3a894a207a8f8c012d9d57379153e8380891/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f76373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DataXujing/YOLOv7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🔥🔥🔥 Official YOLOv7训练自己的数据集并实现端到端的TensorRT模型加速推断。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DataXujing/YOLOv8\"\u003eDataXujing/YOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2601cd11edfbaed709b30521504e1f6c803379dd865a3631add1939700498c61/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2601cd11edfbaed709b30521504e1f6c803379dd865a3631add1939700498c61/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DataXujing/YOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🔥 Official YOLOv8模型训练和部署。Official YOLOv8 训练自己的数据集并基于NVIDIA TensorRT和华为昇腾端到端模型加速以及安卓手机端部署。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DataXujing/YOLOv9\"\u003eDataXujing/YOLOv9\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/508c404273b82639991732f7c4ff22b86aaeeb3397511ca66f04046fa6964b02/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f76393f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/508c404273b82639991732f7c4ff22b86aaeeb3397511ca66f04046fa6964b02/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f76393f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DataXujing/YOLOv9?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🔥 YOLOv9 paper解析，训练自己的数据集，TensorRT端到端部署， NCNN安卓手机部署。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Code-keys/yolov5-darknet\"\u003eCode-keys/yolov5-darknet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cb8788b0ed78e07e6b689eab96915e9432ecc8739b65603262fb9045dd5caef5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436f64652d6b6579732f796f6c6f76352d6461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cb8788b0ed78e07e6b689eab96915e9432ecc8739b65603262fb9045dd5caef5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436f64652d6b6579732f796f6c6f76352d6461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Code-keys/yolov5-darknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5-darknet support yaml \u0026amp;\u0026amp; cfg.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Code-keys/yolo-darknet\"\u003eCode-keys/yolo-darknet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a01fbb77a4a808004994d5e82ac9ff48efa7a863e5e02f7ee648fb32d8107417/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436f64652d6b6579732f796f6c6f2d6461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a01fbb77a4a808004994d5e82ac9ff48efa7a863e5e02f7ee648fb32d8107417/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436f64652d6b6579732f796f6c6f2d6461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Code-keys/yolo-darknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO-family complemented by darknet. yolov5 yolov7 et al ...\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pooya-mohammadi/deep_utils\"\u003epooya-mohammadi/deep_utils\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f9d3cd6b23b4bcb4bb1ddef2cdf1d9c7ebee3e1a4c44f986ce4a58e54bdfcd95/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706f6f79612d6d6f68616d6d6164692f646565705f7574696c733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f9d3cd6b23b4bcb4bb1ddef2cdf1d9c7ebee3e1a4c44f986ce4a58e54bdfcd95/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706f6f79612d6d6f68616d6d6164692f646565705f7574696c733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pooya-mohammadi/deep_utils?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A toolkit full of handy functions including most used models and utilities for deep-learning practitioners!\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yl-jiang/YOLOSeries\"\u003eyl-jiang/YOLOSeries\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ecf098b6a49aa5d70f1d3fc5fb373b0dce86a2b0e98f5395e434b6ec77b2bf77/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796c2d6a69616e672f594f4c4f5365726965733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ecf098b6a49aa5d70f1d3fc5fb373b0dce86a2b0e98f5395e434b6ec77b2bf77/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796c2d6a69616e672f594f4c4f5365726965733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yl-jiang/YOLOSeries?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO Series.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yjh0410/FreeYOLO\"\u003eyjh0410/FreeYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/51be201dd97beab31b18da6204d1dca9accf336303a0e2096df20e9429c783fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796a68303431302f46726565594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/51be201dd97beab31b18da6204d1dca9accf336303a0e2096df20e9429c783fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796a68303431302f46726565594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yjh0410/FreeYOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : FreeYOLO is inspired by many other excellent works, such as YOLOv7 and YOLOX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/open-yolo/yolov7\"\u003eopen-yolo/yolov7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8e35b28b1b315f65551a02a1722bf7c00f09f9914b9793c566012b8ce19b1ef2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d796f6c6f2f796f6c6f76373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8e35b28b1b315f65551a02a1722bf7c00f09f9914b9793c566012b8ce19b1ef2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d796f6c6f2f796f6c6f76373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/open-yolo/yolov7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Improved and packaged version of WongKinYiu/yolov7.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/iloveai8086/YOLOC\"\u003eiloveai8086/YOLOC\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e06425fc63e9f09d510caa0ed472ce839f9cb66c8f38c37a807a8f0c843e81db/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696c6f76656169383038362f594f4c4f433f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e06425fc63e9f09d510caa0ed472ce839f9cb66c8f38c37a807a8f0c843e81db/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696c6f76656169383038362f594f4c4f433f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/iloveai8086/YOLOC?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🚀YOLOC is Combining different modules to build an different Object detection model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/miemie2013/miemiedetection\"\u003emiemie2013/miemiedetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7ff578725d5f02d1a2b3b410c50652e95ddc9e7e209a5f702d82a657d8562400/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69656d6965323031332f6d69656d6965646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7ff578725d5f02d1a2b3b410c50652e95ddc9e7e209a5f702d82a657d8562400/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69656d6965323031332f6d69656d6965646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/miemie2013/miemiedetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Pytorch and ncnn implementation of PPYOLOE、YOLOX、PPYOLO、PPYOLOv2、SOLOv2 an so on.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RyanCCC/YOLOSeries\"\u003eRyanCCC/YOLOSeries\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/310e35f7cda9fe1a2b2a4fcdd490f8731520dfeb712ba924d6c35ec4ea2cbc4b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5279616e4343432f594f4c4f5365726965733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/310e35f7cda9fe1a2b2a4fcdd490f8731520dfeb712ba924d6c35ec4ea2cbc4b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5279616e4343432f594f4c4f5365726965733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RyanCCC/YOLOSeries?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO算法的实现。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HuKai97/YOLOX-Annotations\"\u003eHuKai97/YOLOX-Annotations\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d2cf808b3bd3d5fc6b02e3f20cdc40fca16dfdc91eb65643be34c24983de0332/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48754b616939372f594f4c4f582d416e6e6f746174696f6e733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d2cf808b3bd3d5fc6b02e3f20cdc40fca16dfdc91eb65643be34c24983de0332/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48754b616939372f594f4c4f582d416e6e6f746174696f6e733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HuKai97/YOLOX-Annotations?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 一个YOLOX的中文注释版本，供大家参考学习！\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/isLinXu/YOLOv8_Efficient\"\u003eisLinXu/YOLOv8_Efficient\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9213d69cc8f4aa8f64471b43e3ba0230c07bddf2b00c4d5b73e5046965b73981/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69734c696e58752f594f4c4f76385f456666696369656e743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9213d69cc8f4aa8f64471b43e3ba0230c07bddf2b00c4d5b73e5046965b73981/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69734c696e58752f594f4c4f76385f456666696369656e743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/isLinXu/YOLOv8_Efficient?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🚀Simple and efficient use for Ultralytics yolov8🚀\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/z1069614715/objectdetection_script\"\u003ez1069614715/objectdetection_script\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ddeda98af5ea8d744a454e2b494551e3a2b7b4c8755be3e638fc036add0e4cff/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a313036393631343731352f6f626a656374646574656374696f6e5f7363726970743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ddeda98af5ea8d744a454e2b494551e3a2b7b4c8755be3e638fc036add0e4cff/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a313036393631343731352f6f626a656374646574656374696f6e5f7363726970743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/z1069614715/objectdetection_script?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 一些关于目标检测的脚本的改进思路代码。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eLighter and Deployment Frameworks\u003c/h2\u003e\u003ca id=\"user-content-lighter-and-deployment-frameworks\" class=\"anchor\" aria-label=\"Permalink: Lighter and Deployment Frameworks\" href=\"#lighter-and-deployment-frameworks\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eHigh-performance Inference Engine\u003c/h3\u003e\u003ca id=\"user-content-high-performance-inference-engine\" class=\"anchor\" aria-label=\"Permalink: High-performance Inference Engine\" href=\"#high-performance-inference-engine\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e高性能推理引擎\u003c/h4\u003e\u003ca id=\"user-content-高性能推理引擎\" class=\"anchor\" aria-label=\"Permalink: 高性能推理引擎\" href=\"#高性能推理引擎\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eONNX\u003c/h5\u003e\u003ca id=\"user-content-onnx\" class=\"anchor\" aria-label=\"Permalink: ONNX\" href=\"#onnx\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/microsoft/onnxruntime\"\u003eONNX Runtime\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a2f598ebbcb9fce782597f473cff1718e1677ccd89cf37f150bd088d4937e887/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6963726f736f66742f6f6e6e7872756e74696d653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a2f598ebbcb9fce782597f473cff1718e1677ccd89cf37f150bd088d4937e887/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6963726f736f66742f6f6e6e7872756e74696d653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/microsoft/onnxruntime?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ONNX Runtime: cross-platform, high performance ML inferencing and training accelerator. \u003ca href=\"https://onnxruntime.ai/\" rel=\"nofollow\"\u003eonnxruntime.ai\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/onnx/onnx\"\u003eONNX\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/eadfb34447ae8a8b2bd008ba0c388c4d8cb3e0640c9278cccb2c227b9aaf73ab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6e6e782f6f6e6e783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/eadfb34447ae8a8b2bd008ba0c388c4d8cb3e0640c9278cccb2c227b9aaf73ab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6e6e782f6f6e6e783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/onnx/onnx?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Open Neural Network Exchange. Open standard for machine learning interoperability. \u003ca href=\"https://onnx.ai/\" rel=\"nofollow\"\u003eonnx.ai\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/onnx/onnxmltools\"\u003eONNXMLTools\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d4f6f208dc051ab689b7773f3faf9008607850cff9ad7796428c139075e7ecbd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6e6e782f6f6e6e786d6c746f6f6c733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d4f6f208dc051ab689b7773f3faf9008607850cff9ad7796428c139075e7ecbd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6e6e782f6f6e6e786d6c746f6f6c733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/onnx/onnxmltools?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ONNXMLTools enables you to convert models from different machine learning toolkits into \u003ca href=\"https://github.com/onnx/onnx\"\u003eONNX\u003c/a\u003e. \u003ca href=\"https://onnx.ai/\" rel=\"nofollow\"\u003eonnx.ai\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xboot/libonnx\"\u003exboot/libonnx\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8bfb4abace40e7107043e6d495a5c1ce18662920a353e5e2834a0f382118b9ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78626f6f742f6c69626f6e6e783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8bfb4abace40e7107043e6d495a5c1ce18662920a353e5e2834a0f382118b9ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78626f6f742f6c69626f6e6e783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xboot/libonnx?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A lightweight, portable pure C99 onnx inference engine for embedded devices with hardware acceleration support.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kraiskil/onnx2c\"\u003ekraiskil/onnx2c\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/12be4f92e4ebe218a2b01a488ea2b6d2497b2b66e98cd94504b9be97b6c0d4dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b726169736b696c2f6f6e6e7832633f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/12be4f92e4ebe218a2b01a488ea2b6d2497b2b66e98cd94504b9be97b6c0d4dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b726169736b696c2f6f6e6e7832633f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kraiskil/onnx2c?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Open Neural Network Exchange to C compiler. Onnx2c is a \u003ca href=\"https://onnx.ai/\" rel=\"nofollow\"\u003eONNX\u003c/a\u003e to C compiler. It will read an ONNX file, and generate C code to be included in your project. Onnx2c's target is \"Tiny ML\", meaning running the inference on microcontrollers.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sonos/tract\"\u003etract\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b529827f8fb7574e9d382e6d0c524f2f8ca19fd6e547387280d8a682c7ff6919/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736f6e6f732f74726163743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b529827f8fb7574e9d382e6d0c524f2f8ca19fd6e547387280d8a682c7ff6919/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736f6e6f732f74726163743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sonos/tract?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Sonos' Neural Network inference engine. Tiny, no-nonsense, self-contained, Tensorflow and ONNX inference\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pykeio/ort\"\u003eort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/45aa58d12c13b364706b818b5b1d2ea3e8dc88e081669aab1709ac161da8fc46/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70796b65696f2f6f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/45aa58d12c13b364706b818b5b1d2ea3e8dc88e081669aab1709ac161da8fc46/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70796b65696f2f6f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pykeio/ort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Rust wrapper for ONNX Runtime. \u003ca href=\"https://docs.rs/ort/latest/ort/\" rel=\"nofollow\"\u003edocs.rs/ort\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nbigaouette/onnxruntime-rs\"\u003eonnxruntime-rs\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/37355e862d6aaf161a8880fb22a16a1932f116b66206a2b6c85a889030d6d0eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e626967616f75657474652f6f6e6e7872756e74696d652d72733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/37355e862d6aaf161a8880fb22a16a1932f116b66206a2b6c85a889030d6d0eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e626967616f75657474652f6f6e6e7872756e74696d652d72733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nbigaouette/onnxruntime-rs?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is an attempt at a Rust wrapper for \u003ca href=\"https://github.com/microsoft/onnxruntime\"\u003eMicrosoft's ONNX Runtime\u003c/a\u003e (version 1.8).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/webonnx/wonnx\"\u003eWonnx\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2f6e0f93d6b26e6ed79ab8aa8c1411b5c5822bd2d0bd24ef87543727b18fef34/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7765626f6e6e782f776f6e6e783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2f6e0f93d6b26e6ed79ab8aa8c1411b5c5822bd2d0bd24ef87543727b18fef34/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7765626f6e6e782f776f6e6e783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/webonnx/wonnx?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Wonnx is a GPU-accelerated ONNX inference run-time written 100% in Rust, ready for the web.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/maekawatoshiki/altius\"\u003ealtius\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f263afc1427585c0872223370743d58f3623d72ac3d46af4bead36da02cdf35f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61656b617761746f7368696b692f616c746975733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f263afc1427585c0872223370743d58f3623d72ac3d46af4bead36da02cdf35f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61656b617761746f7368696b692f616c746975733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/maekawatoshiki/altius?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Small ONNX inference runtime written in Rust.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Hyuto/yolo-nas-onnx\"\u003eHyuto/yolo-nas-onnx\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bd13e254814719dac044388f2cb9c905c1dd4140a0841bfc5a7f9f37afc5af95/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f487975746f2f796f6c6f2d6e61732d6f6e6e783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bd13e254814719dac044388f2cb9c905c1dd4140a0841bfc5a7f9f37afc5af95/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f487975746f2f796f6c6f2d6e61732d6f6e6e783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Hyuto/yolo-nas-onnx?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Inference YOLO-NAS ONNX model. \u003ca href=\"https://hyuto.github.io/yolo-nas-onnx/\" rel=\"nofollow\"\u003ehyuto.github.io/yolo-nas-onnx/\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DanielSarmiento04/yolov10cpp\"\u003eDanielSarmiento04/yolov10cpp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8479531a9c7c4aa842eb2b358a71d8d76ad9f610d010c08ef408dfcdd9cec199/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44616e69656c5361726d69656e746f30342f796f6c6f7631306370703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8479531a9c7c4aa842eb2b358a71d8d76ad9f610d010c08ef408dfcdd9cec199/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44616e69656c5361726d69656e746f30342f796f6c6f7631306370703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DanielSarmiento04/yolov10cpp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Implementation of yolo v10 in c++ std 17 over opencv and onnxruntime.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eTensorRT\u003c/h5\u003e\u003ca id=\"user-content-tensorrt\" class=\"anchor\" aria-label=\"Permalink: TensorRT\" href=\"#tensorrt\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NVIDIA/TensorRT\"\u003eTensorRT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0375d1cf222c092085220f7c6c3c9969ea4549482355526cf93ed5d689fcd87b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412f54656e736f7252543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0375d1cf222c092085220f7c6c3c9969ea4549482355526cf93ed5d689fcd87b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412f54656e736f7252543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NVIDIA/TensorRT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : NVIDIA® TensorRT™ is an SDK for high-performance deep learning inference on NVIDIA GPUs. This repository contains the open source components of TensorRT. \u003ca href=\"https://developer.nvidia.com/tensorrt\" rel=\"nofollow\"\u003edeveloper.nvidia.com/tensorrt\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NVIDIA/TensorRT-LLM\"\u003eTensorRT-LLM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ee764b9764a279377a54f33585cd0e13cea0c7ee0a421e1db79bcb756df74c8f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412f54656e736f7252542d4c4c4d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ee764b9764a279377a54f33585cd0e13cea0c7ee0a421e1db79bcb756df74c8f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412f54656e736f7252542d4c4c4d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NVIDIA/TensorRT-LLM?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs. TensorRT-LLM also contains components to create Python and C++ runtimes that execute those TensorRT engines. \u003ca href=\"https://nvidia.github.io/TensorRT-LLM\" rel=\"nofollow\"\u003envidia.github.io/TensorRT-LLM\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NVIDIA/TensorRT-Model-Optimizer\"\u003eNVIDIA/TensorRT-Model-Optimizer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e4de7bc60820e749a190eb0570051780232075a76de93cce711a7aa23b181e01/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412f54656e736f7252542d4d6f64656c2d4f7074696d697a65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e4de7bc60820e749a190eb0570051780232075a76de93cce711a7aa23b181e01/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412f54656e736f7252542d4d6f64656c2d4f7074696d697a65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NVIDIA/TensorRT-Model-Optimizer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRT Model Optimizer is a unified library of state-of-the-art model optimization techniques such as quantization, pruning, distillation, etc. It compresses deep learning models for downstream deployment frameworks like TensorRT-LLM or TensorRT to optimize inference speed on NVIDIA GPUs. \u003ca href=\"https://nvidia.github.io/TensorRT-Model-Optimizer/\" rel=\"nofollow\"\u003envidia.github.io/TensorRT-Model-Optimizer\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kalfazed/tensorrt_starter\"\u003ekalfazed/tensorrt_starter\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c2e0bc22fd3c9803c385c16a5a9402233aa321ab5b0078a033eba7035c8badda/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616c66617a65642f74656e736f7272745f737461727465723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c2e0bc22fd3c9803c385c16a5a9402233aa321ab5b0078a033eba7035c8badda/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616c66617a65642f74656e736f7272745f737461727465723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kalfazed/tensorrt_starter?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository give a guidline to learn CUDA and TensorRT from the beginning.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wang-xinyu/tensorrtx\"\u003ewang-xinyu/tensorrtx\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8c496330b4704f24e8aa74a7a72a4293a4529c96c1c46e0b67876b1059fba55b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e672d78696e79752f74656e736f727274783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8c496330b4704f24e8aa74a7a72a4293a4529c96c1c46e0b67876b1059fba55b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e672d78696e79752f74656e736f727274783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wang-xinyu/tensorrtx?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRTx aims to implement popular deep learning networks with tensorrt network definition APIs.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/laugh12321/TensorRT-YOLO\"\u003elaugh12321/TensorRT-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5b30d047ada124253400bc8a6d24644473d84536d0294cb5af05b35e25e2cac1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6175676831323332312f54656e736f7252542d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5b30d047ada124253400bc8a6d24644473d84536d0294cb5af05b35e25e2cac1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6175676831323332312f54656e736f7252542d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/laugh12321/TensorRT-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🚀 Easier \u0026amp; Faster YOLO Deployment Toolkit for NVIDIA 🛠️. 🚀 TensorRT-YOLO is an easy-to-use, extremely efficient inference deployment tool for the YOLO series designed specifically for NVIDIA devices. The project not only integrates TensorRT plugins to enhance post-processing but also utilizes CUDA kernels and CUDA graphs to accelerate inference. 🚀 TensorRT-YOLO 是一款专为 NVIDIA 设备设计的易用灵活、极致高效的YOLO系列推理部署工具。项目不仅集成了 TensorRT 插件以增强后处理效果，还使用了 CUDA 核函数以及 CUDA 图来加速推理。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/olibartfast/object-detection-inference\"\u003eolibartfast/object-detection-inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4fa000d3b07903db52223b4a193230ff7441c5cf6ae27e86615a8463a553fde3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6c6962617274666173742f6f626a6563742d646574656374696f6e2d696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4fa000d3b07903db52223b4a193230ff7441c5cf6ae27e86615a8463a553fde3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6c6962617274666173742f6f626a6563742d646574656374696f6e2d696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/olibartfast/object-detection-inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : C++ object detection inference from video or image input source. Inference for object detection from a video or image input source, with support for multiple switchable frameworks to manage the inference process, and optional GStreamer integration for video capture.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/shouxieai/tensorRT_Pro\"\u003eshouxieai/tensorRT_Pro\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ca59a545d98996ab947a2c9aeafe9fc1beff6df602a0b929d45749187424e86b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73686f7578696561692f74656e736f7252545f50726f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ca59a545d98996ab947a2c9aeafe9fc1beff6df602a0b929d45749187424e86b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73686f7578696561692f74656e736f7252545f50726f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/shouxieai/tensorRT_Pro?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : C++ library based on tensorrt integration.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/shouxieai/infer\"\u003eshouxieai/infer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/13239cfe07e93039bdb929406298d13159398027283ed7bc325d6a488164238a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73686f7578696561692f696e6665723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/13239cfe07e93039bdb929406298d13159398027283ed7bc325d6a488164238a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73686f7578696561692f696e6665723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/shouxieai/infer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A new tensorrt integrate. Easy to integrate many tasks.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Melody-Zhou/tensorRT_Pro-YOLOv8\"\u003eMelody-Zhou/tensorRT_Pro-YOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e290917e1beecc650ba393365a9af6d843069926f5d206a2bd05b541b6509d5d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d656c6f64792d5a686f752f74656e736f7252545f50726f2d594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e290917e1beecc650ba393365a9af6d843069926f5d206a2bd05b541b6509d5d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d656c6f64792d5a686f752f74656e736f7252545f50726f2d594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Melody-Zhou/tensorRT_Pro-YOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository is based on \u003ca href=\"https://github.com/shouxieai/tensorRT_Pro\"\u003eshouxieai/tensorRT_Pro\u003c/a\u003e, with adjustments to support YOLOv8. 前已支持 YOLOv8、YOLOv8-Cls、YOLOv8-Seg、YOLOv8-OBB、YOLOv8-Pose、RT-DETR、ByteTrack、YOLOv9、YOLOv10、RTMO、PP-OCRv4、LaneATT 高性能推理！！！🚀🚀🚀\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FeiYull/TensorRT-Alpha\"\u003eFeiYull/TensorRT-Alpha\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/906e2316bb7843807dfb69787764cc1bf56a4fed36dd3e228c3576bb5ed203f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f746f726368327472743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/906e2316bb7843807dfb69787764cc1bf56a4fed36dd3e228c3576bb5ed203f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f746f726368327472743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NVIDIA-AI-IOT/torch2trt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🔥🔥🔥TensorRT for YOLOv8、YOLOv8-Pose、YOLOv8-Seg、YOLOv8-Cls、YOLOv7、YOLOv6、YOLOv5、YOLONAS......🚀🚀🚀CUDA IS ALL YOU NEED.🍎🍎🍎\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zhiqwang/yolort\"\u003ezhiqwang/yolort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/77f3143b81f59c13a081e5b6974e990b16d67cce05675983e4a41ebf8a60d8a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68697177616e672f796f6c6f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/77f3143b81f59c13a081e5b6974e990b16d67cce05675983e4a41ebf8a60d8a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68697177616e672f796f6c6f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zhiqwang/yolort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolort is a runtime stack for yolov5 on specialized accelerators such as tensorrt, libtorch, onnxruntime, tvm and ncnn. \u003ca href=\"https://zhiqwang.com/yolort/\" rel=\"nofollow\"\u003ezhiqwang.com/yolort\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/1461521844lijin/trt_yolo_video_pipeline\"\u003e1461521844lijin/trt_yolo_video_pipeline\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b7dc39a0d64dcdee2a495ef963801041779f33282c35a442ca7b5a2deb000a58/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f313436313532313834346c696a696e2f7472745f796f6c6f5f766964656f5f706970656c696e653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b7dc39a0d64dcdee2a495ef963801041779f33282c35a442ca7b5a2deb000a58/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f313436313532313834346c696a696e2f7472745f796f6c6f5f766964656f5f706970656c696e653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/1461521844lijin/trt_yolo_video_pipeline?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRT+YOLO系列的 多路 多卡 多实例 并行视频分析处理案例。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/l-sf/Linfer\"\u003el-sf/Linfer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ab04faa5de0bd75fe6d962274280b9e1cb59a48859c55b328aeac03829d0ebf9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c2d73662f4c696e6665723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ab04faa5de0bd75fe6d962274280b9e1cb59a48859c55b328aeac03829d0ebf9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c2d73662f4c696e6665723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/l-sf/Linfer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于TensorRT的C++高性能推理库，Yolov10, YoloPv2，Yolov5/7/X/8，RT-DETR，单目标跟踪OSTrack、LightTrack。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/taifyang/yolo-inference\"\u003etaifyang/yolo-inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fd63c5266ceeacc79ecc3c904d7206f1cf2ed6ceac60086f4065d9381a3bc967/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7461696679616e672f796f6c6f2d696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fd63c5266ceeacc79ecc3c904d7206f1cf2ed6ceac60086f4065d9381a3bc967/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7461696679616e672f796f6c6f2d696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/taifyang/yolo-inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : C++ and Python implementations of YOLOv5, YOLOv6, YOLOv7, YOLOv8, YOLOv9, YOLOv10, YOLOv11 inference.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/triple-Mu/YOLOv8-TensorRT\"\u003etriple-Mu/YOLOv8-TensorRT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c2aa79ac3d7f461d748dd43ba96d31757f8eb7322d3deac7546d001ed23248d8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f747269706c652d4d752f594f4c4f76382d54656e736f7252543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c2aa79ac3d7f461d748dd43ba96d31757f8eb7322d3deac7546d001ed23248d8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f747269706c652d4d752f594f4c4f76382d54656e736f7252543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/triple-Mu/YOLOv8-TensorRT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv8 using TensorRT accelerate !\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/emptysoal/TensorRT-YOLOv8-ByteTrack\"\u003eemptysoal/TensorRT-YOLOv8-ByteTrack\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3de99ef022efea487cb0a9295a6ea4c5b29438eb8209f9a501d4b1db5429a656/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656d707479736f616c2f54656e736f7252542d594f4c4f76382d42797465547261636b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3de99ef022efea487cb0a9295a6ea4c5b29438eb8209f9a501d4b1db5429a656/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656d707479736f616c2f54656e736f7252542d594f4c4f76382d42797465547261636b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/emptysoal/TensorRT-YOLOv8-ByteTrack?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An object tracking project with YOLOv8 and ByteTrack, speed up by C++ and TensorRT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Linaom1214/TensorRT-For-YOLO-Series\"\u003eLinaom1214/TensorRT-For-YOLO-Series\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/504699f5f0f48bdcce503d21c6cb588227768f95a2abc8cf450c04b49a1b6265/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696e616f6d313231342f54656e736f7252542d466f722d594f4c4f2d5365726965733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/504699f5f0f48bdcce503d21c6cb588227768f95a2abc8cf450c04b49a1b6265/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696e616f6d313231342f54656e736f7252542d466f722d594f4c4f2d5365726965733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Linaom1214/TensorRT-For-YOLO-Series?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : tensorrt for yolo series (YOLOv10,YOLOv9,YOLOv8,YOLOv7,YOLOv6,YOLOX,YOLOv5), nms plugin support.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/spacewalk01/yolov11-tensorrt\"\u003espacewalk01/yolov11-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5007e0fedd6e021dd75fd274c2617c83051abcfcebc17d66ea5dde0335aeda5f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737061636577616c6b30312f796f6c6f7631312d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5007e0fedd6e021dd75fd274c2617c83051abcfcebc17d66ea5dde0335aeda5f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737061636577616c6b30312f796f6c6f7631312d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/spacewalk01/yolov11-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : C++ implementation of YOLOv11 using TensorRT API.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cyrusbehr/YOLOv8-TensorRT-CPP\"\u003ecyrusbehr/YOLOv8-TensorRT-CPP\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/40c832f1bcbe15f0b32e335aed3a2130641f42b1e8950521eacd0d9346dba660/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6379727573626568722f594f4c4f76382d54656e736f7252542d4350503f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/40c832f1bcbe15f0b32e335aed3a2130641f42b1e8950521eacd0d9346dba660/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6379727573626568722f594f4c4f76382d54656e736f7252542d4350503f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cyrusbehr/YOLOv8-TensorRT-CPP?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv8 TensorRT C++ Implementation. A C++ Implementation of YoloV8 using TensorRT Supports object detection, semantic segmentation, and body pose estimation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/emptysoal/TensorRT-YOLOv8\"\u003eemptysoal/TensorRT-YOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3ba343e54dc8fc076f7292598112a38bca94838864dff48fbb5513c970263387/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656d707479736f616c2f54656e736f7252542d594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3ba343e54dc8fc076f7292598112a38bca94838864dff48fbb5513c970263387/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656d707479736f616c2f54656e736f7252542d594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/emptysoal/TensorRT-YOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Based on tensorrt v8.0+, deploy detect, pose, segment, tracking of YOLOv8 with C++ and python api.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hamdiboukamcha/yolov10-tensorrt\"\u003ehamdiboukamcha/yolov10-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/867fc18b51a4b44d2b519dc175c2393d99f3190193d947efa9f3df5d383ab81f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68616d6469626f756b616d6368612f796f6c6f7631302d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/867fc18b51a4b44d2b519dc175c2393d99f3190193d947efa9f3df5d383ab81f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68616d6469626f756b616d6368612f796f6c6f7631302d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hamdiboukamcha/yolov10-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv10 C++ TensorRT : Real-Time End-to-End Object Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NVIDIA-AI-IOT/torch2trt\"\u003eVIDIA-AI-IOT/torch2trt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/906e2316bb7843807dfb69787764cc1bf56a4fed36dd3e228c3576bb5ed203f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f746f726368327472743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/906e2316bb7843807dfb69787764cc1bf56a4fed36dd3e228c3576bb5ed203f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f746f726368327472743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NVIDIA-AI-IOT/torch2trt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An easy to use PyTorch to TensorRT converter.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DefTruth/lite.ai.toolkit\"\u003eDefTruth/lite.ai.toolkit\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4872d3a5f1c9cbb9000aee906bd1f2488666f1bea1bc63be201c5807f369cdf3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44656654727574682f6c6974652e61692e746f6f6c6b69743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4872d3a5f1c9cbb9000aee906bd1f2488666f1bea1bc63be201c5807f369cdf3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44656654727574682f6c6974652e61692e746f6f6c6b69743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DefTruth/lite.ai.toolkit?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🛠 A lite C++ toolkit of awesome AI models with ONNXRuntime, NCNN, MNN and TNN. YOLOX, YOLOP, YOLOv6, YOLOR, MODNet, YOLOX, YOLOv7, YOLOv5. MNN, NCNN, TNN, ONNXRuntime. “🛠Lite.Ai.ToolKit: 一个轻量级的C++ AI模型工具箱，用户友好（还行吧），开箱即用。已经包括 100+ 流行的开源模型。这是一个根据个人兴趣整理的C++工具箱，, 涵盖目标检测、人脸检测、人脸识别、语义分割、抠图等领域。”\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PaddlePaddle/FastDeploy\"\u003ePaddlePaddle/FastDeploy\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/034bb02e20083b6a0f4779a11bca9b666d41aa6e87b3ba24d3cbc1aef1c18cac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506164646c65506164646c652f466173744465706c6f793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/034bb02e20083b6a0f4779a11bca9b666d41aa6e87b3ba24d3cbc1aef1c18cac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506164646c65506164646c652f466173744465706c6f793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PaddlePaddle/FastDeploy?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ⚡️An Easy-to-use and Fast Deep Learning Model Deployment Toolkit for ☁️Cloud 📱Mobile and 📹Edge. Including Image, Video, Text and Audio 20+ main stream scenarios and 150+ SOTA models with end-to-end optimization, multi-platform and multi-framework support.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/enazoe/yolo-tensorrt\"\u003eenazoe/yolo-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9b137a9061b7007e457b3c20b26c68c517854225035cfcbd7932267d060d5fed/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656e617a6f652f796f6c6f2d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9b137a9061b7007e457b3c20b26c68c517854225035cfcbd7932267d060d5fed/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656e617a6f652f796f6c6f2d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/enazoe/yolo-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRT8.Support Yolov5n,s,m,l,x .darknet -\u0026gt; tensorrt. Yolov4 Yolov3 use raw darknet *.weights and *.cfg fils. If the wrapper is useful to you,please Star it.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/guojianyang/cv-detect-robot\"\u003eguojianyang/cv-detect-robot\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/44e9eb4379b88f43464390c78025883ff45ade2416aa369ab10600ae45e61162/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67756f6a69616e79616e672f63762d6465746563742d726f626f743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/44e9eb4379b88f43464390c78025883ff45ade2416aa369ab10600ae45e61162/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67756f6a69616e79616e672f63762d6465746563742d726f626f743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/guojianyang/cv-detect-robot?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🔥🔥🔥🔥🔥🔥Docker NVIDIA Docker2 YOLOV5 YOLOX YOLO Deepsort TensorRT ROS Deepstream Jetson Nano TX2 NX for High-performance deployment(高性能部署)。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BlueMirrors/Yolov5-TensorRT\"\u003eBlueMirrors/Yolov5-TensorRT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8e3eb2c51ead40bdeaceed64150e1c6c7bc061b08217044f58f52027807a3fda/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426c75654d6972726f72732f596f6c6f76352d54656e736f7252543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8e3eb2c51ead40bdeaceed64150e1c6c7bc061b08217044f58f52027807a3fda/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426c75654d6972726f72732f596f6c6f76352d54656e736f7252543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BlueMirrors/Yolov5-TensorRT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov5 TensorRT Implementations.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lewes6369/TensorRT-Yolov3\"\u003elewes6369/TensorRT-Yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/41e16240d345aeacd2f7bdd1d714c3e771ec6b87bc7cac82800fab06bcca0574/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c65776573363336392f54656e736f7252542d596f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/41e16240d345aeacd2f7bdd1d714c3e771ec6b87bc7cac82800fab06bcca0574/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c65776573363336392f54656e736f7252542d596f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lewes6369/TensorRT-Yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRT for Yolov3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CaoWGG/TensorRT-YOLOv4\"\u003eCaoWGG/TensorRT-YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8a744e928dd0b1349807d2b2708b889d7e9490c30242cfacc566f712e427043e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43616f5747472f54656e736f7252542d594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8a744e928dd0b1349807d2b2708b889d7e9490c30242cfacc566f712e427043e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43616f5747472f54656e736f7252542d594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CaoWGG/TensorRT-YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e :tensorrt5, yolov4, yolov3,yolov3-tniy,yolov3-tniy-prn.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/isarsoft/yolov4-triton-tensorrt\"\u003eisarsoft/yolov4-triton-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9cb8a8e8da43900a28c26172087a6470cad4fa8c07619a5ddb5b06d22824f79e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736172736f66742f796f6c6f76342d747269746f6e2d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9cb8a8e8da43900a28c26172087a6470cad4fa8c07619a5ddb5b06d22824f79e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736172736f66742f796f6c6f76342d747269746f6e2d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/isarsoft/yolov4-triton-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv4 on Triton Inference Server with TensorRT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TrojanXu/yolov5-tensorrt\"\u003eTrojanXu/yolov5-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/085879deb0d9dd5659f2aaae5c5000f78e056138125d6f90d391e23dc77b47ef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54726f6a616e58752f796f6c6f76352d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/085879deb0d9dd5659f2aaae5c5000f78e056138125d6f90d391e23dc77b47ef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54726f6a616e58752f796f6c6f76352d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TrojanXu/yolov5-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A tensorrt implementation of yolov5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tjuskyzhang/Scaled-YOLOv4-TensorRT\"\u003etjuskyzhang/Scaled-YOLOv4-TensorRT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f7f8d4bdaa4065f11591039fa72f54e662d7b29908146e58d7de17745977e17e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746a75736b797a68616e672f5363616c65642d594f4c4f76342d54656e736f7252543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f7f8d4bdaa4065f11591039fa72f54e662d7b29908146e58d7de17745977e17e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746a75736b797a68616e672f5363616c65642d594f4c4f76342d54656e736f7252543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tjuskyzhang/Scaled-YOLOv4-TensorRT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Implement yolov4-tiny-tensorrt, yolov4-csp-tensorrt, yolov4-large-tensorrt(p5, p6, p7) layer by layer using TensorRT API.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Syencil/tensorRT\"\u003eSyencil/tensorRT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e9731538c347e03f7b16e1ae7039a1aa8ae3aee8dd0ce708842a65f0ce41d276/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5379656e63696c2f74656e736f7252543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e9731538c347e03f7b16e1ae7039a1aa8ae3aee8dd0ce708842a65f0ce41d276/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5379656e63696c2f74656e736f7252543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Syencil/tensorRT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRT-7 Network Lib 包括常用目标检测、关键点检测、人脸检测、OCR等 可训练自己数据。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SeanAvery/yolov5-tensorrt\"\u003eSeanAvery/yolov5-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3325f6f83e8e5bde02d42260d7e359e39047f1a0132a767c65836718aad698a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5365616e41766572792f796f6c6f76352d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3325f6f83e8e5bde02d42260d7e359e39047f1a0132a767c65836718aad698a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5365616e41766572792f796f6c6f76352d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SeanAvery/yolov5-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 in TensorRT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Monday-Leo/YOLOv7_Tensorrt\"\u003eMonday-Leo/YOLOv7_Tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e2609229a68b3694b738d682f6bc90574e085a783036980caa110ff7439fb557/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f6e6461792d4c656f2f594f4c4f76375f54656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e2609229a68b3694b738d682f6bc90574e085a783036980caa110ff7439fb557/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f6e6461792d4c656f2f594f4c4f76375f54656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Monday-Leo/YOLOv7_Tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A simple implementation of Tensorrt YOLOv7.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ibaiGorordo/ONNX-YOLOv6-Object-Detection\"\u003eibaiGorordo/ONNX-YOLOv6-Object-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a4058e765b7ec6dbaf214664230c38b44b76e640d6a784fbe14e02e17f6ec13b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69626169476f726f72646f2f4f4e4e582d594f4c4f76362d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a4058e765b7ec6dbaf214664230c38b44b76e640d6a784fbe14e02e17f6ec13b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69626169476f726f72646f2f4f4e4e582d594f4c4f76362d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ibaiGorordo/ONNX-YOLOv6-Object-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Python scripts performing object detection using the YOLOv6 model in ONNX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ibaiGorordo/ONNX-YOLOv7-Object-Detection\"\u003eibaiGorordo/ONNX-YOLOv7-Object-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9e0df6d0b164197cd27cabb2ccb7a85e8a0ee144c2bbbe2e566dffd429c9cc90/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69626169476f726f72646f2f4f4e4e582d594f4c4f76372d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9e0df6d0b164197cd27cabb2ccb7a85e8a0ee144c2bbbe2e566dffd429c9cc90/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69626169476f726f72646f2f4f4e4e582d594f4c4f76372d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ibaiGorordo/ONNX-YOLOv7-Object-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Python scripts performing object detection using the YOLOv7 model in ONNX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/triple-Mu/yolov7\"\u003etriple-Mu/yolov7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/41d5206d8d0d21ff41530e72cf55fe7e0b3eacff6362777776a319781cf1de6d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f747269706c652d4d752f796f6c6f76373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/41d5206d8d0d21ff41530e72cf55fe7e0b3eacff6362777776a319781cf1de6d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f747269706c652d4d752f796f6c6f76373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/triple-Mu/yolov7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : End2end TensorRT YOLOv7.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hewen0901/yolov7_trt\"\u003ehewen0901/yolov7_trt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6b5c5e62a81acae515fee0fc0f208912d06fe1a00b5a0042e8ff6c0ccd3e6908/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686577656e303930312f796f6c6f76375f7472743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6b5c5e62a81acae515fee0fc0f208912d06fe1a00b5a0042e8ff6c0ccd3e6908/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686577656e303930312f796f6c6f76375f7472743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hewen0901/yolov7_trt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov7目标检测算法的c++ tensorrt部署代码。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tsutof/tiny_yolov2_onnx_cam\"\u003etsutof/tiny_yolov2_onnx_cam\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0b000dead55d0c856760d0c5411955768bb7ecceda08e8e1d9e8f21a5cce4b3f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f747375746f662f74696e795f796f6c6f76325f6f6e6e785f63616d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0b000dead55d0c856760d0c5411955768bb7ecceda08e8e1d9e8f21a5cce4b3f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f747375746f662f74696e795f796f6c6f76325f6f6e6e785f63616d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tsutof/tiny_yolov2_onnx_cam?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tiny YOLO v2 Inference Application with NVIDIA TensorRT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Monday-Leo/Yolov5_Tensorrt_Win10\"\u003eMonday-Leo/Yolov5_Tensorrt_Win10\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f7e8570cbb8f3a2e06ea1f2faf91e6b4fb7eb3aa1297ae5cf5f0df573da88a38/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f6e6461792d4c656f2f596f6c6f76355f54656e736f7272745f57696e31303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f7e8570cbb8f3a2e06ea1f2faf91e6b4fb7eb3aa1297ae5cf5f0df573da88a38/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f6e6461792d4c656f2f596f6c6f76355f54656e736f7272745f57696e31303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Monday-Leo/Yolov5_Tensorrt_Win10?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A simple implementation of tensorrt yolov5 python/c++🔥\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Wulingtian/yolov5_tensorrt_int8\"\u003eWulingtian/yolov5_tensorrt_int8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1a7daaf88c474cbc2e315446bb2adb9d9dcc34331b8ffe0fc804b6cef715e834/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57756c696e677469616e2f796f6c6f76355f74656e736f7272745f696e74383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1a7daaf88c474cbc2e315446bb2adb9d9dcc34331b8ffe0fc804b6cef715e834/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57756c696e677469616e2f796f6c6f76355f74656e736f7272745f696e74383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Wulingtian/yolov5_tensorrt_int8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRT int8 量化部署 yolov5s 模型，实测3.3ms一帧！\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Wulingtian/yolov5_tensorrt_int8_tools\"\u003eWulingtian/yolov5_tensorrt_int8_tools\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/acbdb43e28a723dadc2de3027e4462d5487128a10b4bc459492e2a2e686bce57/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57756c696e677469616e2f796f6c6f76355f74656e736f7272745f696e74385f746f6f6c733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/acbdb43e28a723dadc2de3027e4462d5487128a10b4bc459492e2a2e686bce57/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57756c696e677469616e2f796f6c6f76355f74656e736f7272745f696e74385f746f6f6c733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Wulingtian/yolov5_tensorrt_int8_tools?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : tensorrt int8 量化yolov5 onnx模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MadaoFY/yolov5_TensorRT_inference\"\u003eMadaoFY/yolov5_TensorRT_inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/60858563edcd7cd842d9d636671744b1a0e14236dc03d68531864145225b95ea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6164616f46592f796f6c6f76355f54656e736f7252545f696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/60858563edcd7cd842d9d636671744b1a0e14236dc03d68531864145225b95ea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6164616f46592f796f6c6f76355f54656e736f7252545f696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MadaoFY/yolov5_TensorRT_inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 记录yolov5的TensorRT量化及推理代码，经实测可运行于Jetson平台。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ibaiGorordo/ONNX-YOLOv8-Object-Detection\"\u003eibaiGorordo/ONNX-YOLOv8-Object-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/655c84f66b1eed29eef8c2689c0157f8a43cad94fc45e9238a94c9ef25694364/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69626169476f726f72646f2f4f4e4e582d594f4c4f76382d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/655c84f66b1eed29eef8c2689c0157f8a43cad94fc45e9238a94c9ef25694364/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69626169476f726f72646f2f4f4e4e582d594f4c4f76382d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ibaiGorordo/ONNX-YOLOv8-Object-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Python scripts performing object detection using the YOLOv8 model in ONNX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/we0091234/yolov8-tensorrt\"\u003ewe0091234/yolov8-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0e11f06202dcfa168e4fc4b1b9779b156cb393336246ce69036420a10a3c9f37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7765303039313233342f796f6c6f76382d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0e11f06202dcfa168e4fc4b1b9779b156cb393336246ce69036420a10a3c9f37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7765303039313233342f796f6c6f76382d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/we0091234/yolov8-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov8 tensorrt 加速.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FeiYull/yolov8-tensorrt\"\u003eFeiYull/yolov8-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cf51132da93738691e2c8412a82f1b4417889c28c5f0cb27bd4a2873a19195c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46656959756c6c2f796f6c6f76382d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cf51132da93738691e2c8412a82f1b4417889c28c5f0cb27bd4a2873a19195c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46656959756c6c2f796f6c6f76382d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FeiYull/yolov8-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv8的TensorRT+CUDA加速部署，代码可在Win、Linux下运行。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cvdong/YOLO_TRT_SIM\"\u003ecvdong/YOLO_TRT_SIM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d206284982b7588a61891358294ca64adabdf4e041a6902267d0a4c9fadbe722/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6376646f6e672f594f4c4f5f5452545f53494d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d206284982b7588a61891358294ca64adabdf4e041a6902267d0a4c9fadbe722/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6376646f6e672f594f4c4f5f5452545f53494d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cvdong/YOLO_TRT_SIM?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🐇 一套代码同时支持YOLO X, V5, V6, V7, V8 TRT推理 ™️ 🔝 ,前后处理均由CUDA核函数实现 CPP/CUDA🚀\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cvdong/YOLO_TRT_PY\"\u003ecvdong/YOLO_TRT_PY\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/28021c8fd009112321e281286a6cbf05389957f0c44fd3dfcc709198b7ffc836/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6376646f6e672f594f4c4f5f5452545f50593f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/28021c8fd009112321e281286a6cbf05389957f0c44fd3dfcc709198b7ffc836/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6376646f6e672f594f4c4f5f5452545f50593f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cvdong/YOLO_TRT_PY?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🐰 一套代码同时支持YOLOV5, V6, V7, V8 TRT推理 ™️ PYTHON \u003cg-emoji class=\"g-emoji\" alias=\"airplane\"\u003e✈️\u003c/g-emoji\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Psynosaur/Jetson-SecVision\"\u003ePsynosaur/Jetson-SecVision\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f44949899f3e3571614b5724473c096afd9e6fc9c28307e250539e53cd22a7cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5073796e6f736175722f4a6574736f6e2d536563566973696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f44949899f3e3571614b5724473c096afd9e6fc9c28307e250539e53cd22a7cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5073796e6f736175722f4a6574736f6e2d536563566973696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Psynosaur/Jetson-SecVision?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Person detection for Hikvision DVR with AlarmIO ports, uses TensorRT and yolov4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tatsuya-fukuoka/yolov7-onnx-infer\"\u003etatsuya-fukuoka/yolov7-onnx-infer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/354c328209a12c0ec19fef3d51516589ebd53368aff8ab31922c4c1b89469f10/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746174737579612d66756b756f6b612f796f6c6f76372d6f6e6e782d696e6665723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/354c328209a12c0ec19fef3d51516589ebd53368aff8ab31922c4c1b89469f10/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746174737579612d66756b756f6b612f796f6c6f76372d6f6e6e782d696e6665723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tatsuya-fukuoka/yolov7-onnx-infer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Inference with yolov7's onnx model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MadaoFY/yolov5_TensorRT_inference\"\u003eMadaoFY/yolov5_TensorRT_inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/60858563edcd7cd842d9d636671744b1a0e14236dc03d68531864145225b95ea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6164616f46592f796f6c6f76355f54656e736f7252545f696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/60858563edcd7cd842d9d636671744b1a0e14236dc03d68531864145225b95ea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6164616f46592f796f6c6f76355f54656e736f7252545f696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MadaoFY/yolov5_TensorRT_inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 记录yolov5的TensorRT量化及推理代码，经实测可运行于Jetson平台。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ervgan/yolov5_tensorrt_inference\"\u003eervgan/yolov5_tensorrt_inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b6dca175c1b92b47fc54fc4900289664866e72a73f46615cb9b512e7c762e524/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f65727667616e2f796f6c6f76355f74656e736f7272745f696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b6dca175c1b92b47fc54fc4900289664866e72a73f46615cb9b512e7c762e524/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f65727667616e2f796f6c6f76355f74656e736f7272745f696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ervgan/yolov5_tensorrt_inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRT cpp inference for Yolov5 model. Supports yolov5 v1.0, v2.0, v3.0, v3.1, v4.0, v5.0, v6.0, v6.2, v7.0.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlbinZhu/easy-trt\"\u003eAlbinZhu/easy-trt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9432205eafcbdf093914cfcb5fcac7c750bac719d2905bf96300e06cd02bee3e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c62696e5a68752f656173792d7472743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9432205eafcbdf093914cfcb5fcac7c750bac719d2905bf96300e06cd02bee3e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c62696e5a68752f656173792d7472743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlbinZhu/easy-trt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TensorRT for YOLOv10 with CUDA.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PrinceP/tensorrt-cpp-for-onnx\"\u003ePrinceP/tensorrt-cpp-for-onnx\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3637b1c708aa8e7c8b2668b96e4eb5b5b20144a648b357100a0dcded87457fcf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5072696e6365502f74656e736f7272742d6370702d666f722d6f6e6e783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3637b1c708aa8e7c8b2668b96e4eb5b5b20144a648b357100a0dcded87457fcf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5072696e6365502f74656e736f7272742d6370702d666f722d6f6e6e783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PrinceP/tensorrt-cpp-for-onnx?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tensorrt codebase to inference in c++ for all major neural arch using onnx.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hamdiboukamcha/Yolo-V10-cpp-TensorRT\"\u003ehamdiboukamcha/Yolo-V10-cpp-TensorRT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/78b79a37fc01fb407b56de375c4b491962f30a2aa46088431249a9df01573f7f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68616d6469626f756b616d6368612f596f6c6f2d5631302d6370702d54656e736f7252543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/78b79a37fc01fb407b56de375c4b491962f30a2aa46088431249a9df01573f7f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68616d6469626f756b616d6368612f596f6c6f2d5631302d6370702d54656e736f7252543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hamdiboukamcha/Yolo-V10-cpp-TensorRT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The YOLOv10 C++ TensorRT Project in C++ and optimized using NVIDIA TensorRT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DataXujing/YOLOv12-TensorRT\"\u003eDataXujing/YOLOv12-TensorRT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/41e23db69776f7617e835b1d3cc546402e379ab320fee03562cde39bbdba03a5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f7631322d54656e736f7252543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/41e23db69776f7617e835b1d3cc546402e379ab320fee03562cde39bbdba03a5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f7631322d54656e736f7252543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DataXujing/YOLOv12-TensorRT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv12 TensorRT 端到端模型加速推理和INT8量化实现。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eDeepStream\u003c/h5\u003e\u003ca id=\"user-content-deepstream\" class=\"anchor\" aria-label=\"Permalink: DeepStream\" href=\"#deepstream\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NVIDIA-AI-IOT/deepstream_reference_apps\"\u003eNVIDIA-AI-IOT/deepstream_reference_apps\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/142e450769825a3832d5060982824bc1a1700ba932170db757d3be6ae2d724a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f6465657073747265616d5f7265666572656e63655f617070733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/142e450769825a3832d5060982824bc1a1700ba932170db757d3be6ae2d724a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f6465657073747265616d5f7265666572656e63655f617070733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NVIDIA-AI-IOT/deepstream_reference_apps?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Reference Apps using DeepStream 6.1.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NVIDIA-AI-IOT/deepstream_python_apps\"\u003eNVIDIA-AI-IOT/deepstream_python_apps\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/35604b7d8133062622b680359795a789af314cf985369807d1f8ef3ec8933c70/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f6465657073747265616d5f707974686f6e5f617070733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/35604b7d8133062622b680359795a789af314cf985369807d1f8ef3ec8933c70/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f6465657073747265616d5f707974686f6e5f617070733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NVIDIA-AI-IOT/deepstream_python_apps?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : DeepStream SDK Python bindings and sample applications.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NVIDIA-AI-IOT/yolov5_gpu_optimization\"\u003eNVIDIA-AI-IOT/deepstream_python_apps\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/adb2f5e1839408a70daa5d8b051e01c8b52a2dde78030e6579e634dba57d4915/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f796f6c6f76355f6770755f6f7074696d697a6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/adb2f5e1839408a70daa5d8b051e01c8b52a2dde78030e6579e634dba57d4915/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f796f6c6f76355f6770755f6f7074696d697a6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NVIDIA-AI-IOT/yolov5_gpu_optimization?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository provides YOLOV5 GPU optimization sample.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/marcoslucianops/DeepStream-Yolo\"\u003emarcoslucianops/DeepStream-Yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/081b4a864d27afb69387494716270e4d632d57f309830d551704d07e465c8271/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6172636f736c756369616e6f70732f4465657053747265616d2d596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/081b4a864d27afb69387494716270e4d632d57f309830d551704d07e465c8271/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6172636f736c756369616e6f70732f4465657053747265616d2d596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/marcoslucianops/DeepStream-Yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : NVIDIA DeepStream SDK 6.1.1 / 6.1 / 6.0.1 / 6.0 implementation for YOLO models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DanaHan/Yolov5-in-Deepstream-5.0\"\u003eDanaHan/Yolov5-in-Deepstream-5.0\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7c32d28e01f71fa39c58426c534f6876e8fb83a34fc553f54d0685b8c32b9a4f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44616e6148616e2f596f6c6f76352d696e2d4465657073747265616d2d352e303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7c32d28e01f71fa39c58426c534f6876e8fb83a34fc553f54d0685b8c32b9a4f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44616e6148616e2f596f6c6f76352d696e2d4465657073747265616d2d352e303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DanaHan/Yolov5-in-Deepstream-5.0?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Describe how to use yolov5 in Deepstream 5.0.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ozinc/Deepstream6_YoloV5_Kafka\"\u003eozinc/Deepstream6_YoloV5_Kafka\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9cbd7c29561ffc932679b7a7505d87c59d57ce5430b3f12e13e2e8171407ef35/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f7a696e632f4465657073747265616d365f596f6c6f56355f4b61666b613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9cbd7c29561ffc932679b7a7505d87c59d57ce5430b3f12e13e2e8171407ef35/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f7a696e632f4465657073747265616d365f596f6c6f56355f4b61666b613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ozinc/Deepstream6_YoloV5_Kafka?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository gives a detailed explanation on making custom trained deepstream-Yolo models predict and send message over kafka.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kn1ghtf1re/yolov8-deepstream-6-1\"\u003ekn1ghtf1re/yolov8-deepstream-6-1\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7193e3c60f1c699add1af0a849f1ca740682c5ab35e492c7f3cf78c8f10a81e7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b6e31676874663172652f796f6c6f76382d6465657073747265616d2d362d313f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7193e3c60f1c699add1af0a849f1ca740682c5ab35e492c7f3cf78c8f10a81e7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b6e31676874663172652f796f6c6f76382d6465657073747265616d2d362d313f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kn1ghtf1re/yolov8-deepstream-6-1?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv8 by Ultralytics in DeepStream 6.1.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bharath5673/Deepstream\"\u003ebharath5673/Deepstream\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/50b87de6dbfd9edd53c5676a8a38e1db358ac39c5862742f3c2ed67daf0570ad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62686172617468353637332f4465657073747265616d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/50b87de6dbfd9edd53c5676a8a38e1db358ac39c5862742f3c2ed67daf0570ad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62686172617468353637332f4465657073747265616d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bharath5673/Deepstream?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov2 ,yolov5 ,yolov6 ,yolov7 ,yolov7,yolovR ,yolovX on deepstream.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/insight-platform/Savant\"\u003eSavant\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/857a2d7be9080390d32196265f8554ad18084b2b2c3c38c2c9e7545563ffd618/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e73696768742d706c6174666f726d2f536176616e743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/857a2d7be9080390d32196265f8554ad18084b2b2c3c38c2c9e7545563ffd618/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e73696768742d706c6174666f726d2f536176616e743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/insight-platform/Savant?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Python Computer Vision \u0026amp; Video Analytics Framework With Batteries Included. \u003ca href=\"https://savant-ai.io/\" rel=\"nofollow\"\u003esavant-ai.io\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/quangdungluong/DeepStream-YOLOv11\"\u003eSavant\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3df4b6911846dfdb989b93829dbe9574fef802d5d61c1f1ddd7bc8a1d317023d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7175616e6764756e676c756f6e672f4465657053747265616d2d594f4c4f7631313f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3df4b6911846dfdb989b93829dbe9574fef802d5d61c1f1ddd7bc8a1d317023d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7175616e6764756e676c756f6e672f4465657053747265616d2d594f4c4f7631313f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/quangdungluong/DeepStream-YOLOv11?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Plug-and-Play Custom Parsers for AI Models in NVIDIA DeepStream SDK. Supported YOLOv11 model.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOpenVINO\u003c/h5\u003e\u003ca id=\"user-content-openvino\" class=\"anchor\" aria-label=\"Permalink: OpenVINO\" href=\"#openvino\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/openvinotoolkit/openvino\"\u003eOpenVINO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/739efdd36838aef02d043f818bec13c5446a9bf61dbaeb47092365a93930072e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e76696e6f746f6f6c6b69742f6f70656e76696e6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/739efdd36838aef02d043f818bec13c5446a9bf61dbaeb47092365a93930072e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e76696e6f746f6f6c6b69742f6f70656e76696e6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/openvinotoolkit/openvino?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This open source version includes several components: namely Model Optimizer, OpenVINO™ Runtime, Post-Training Optimization Tool, as well as CPU, GPU, MYRIAD, multi device and heterogeneous plugins to accelerate deep learning inferencing on Intel® CPUs and Intel® Processor Graphics.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PINTO0309/OpenVINO-YoloV3\"\u003ePINTO0309/OpenVINO-YoloV3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/84a3665ed018a6f17827b03ca21fc9be7086bde65381321bdc40294b7889e2d3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f50494e544f303330392f4f70656e56494e4f2d596f6c6f56333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/84a3665ed018a6f17827b03ca21fc9be7086bde65381321bdc40294b7889e2d3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f50494e544f303330392f4f70656e56494e4f2d596f6c6f56333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PINTO0309/OpenVINO-YoloV3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV3/tiny-YoloV3 + RaspberryPi3/Ubuntu LaptopPC + NCS/NCS2 + USB Camera + Python + OpenVINO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TNTWEN/OpenVINO-YOLOV4\"\u003eTNTWEN/OpenVINO-YOLOV4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3df5c4f9cc0fa614efa57a9266abc841840e5f9469b79c1685a8440c48308fad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f544e5457454e2f4f70656e56494e4f2d594f4c4f56343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3df5c4f9cc0fa614efa57a9266abc841840e5f9469b79c1685a8440c48308fad/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f544e5457454e2f4f70656e56494e4f2d594f4c4f56343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TNTWEN/OpenVINO-YOLOV4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is implementation of YOLOv4,YOLOv4-relu,YOLOv4-tiny,YOLOv4-tiny-3l,Scaled-YOLOv4 and INT8 Quantization in OpenVINO2021.3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fb029ed/yolov5_cpp_openvino\"\u003efb029ed/yolov5_cpp_openvino\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8c50d6464af8e5f96e853baf1001b50f00ad24d33bd093b18e0ee3cb57103ace/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666230323965642f796f6c6f76355f6370705f6f70656e76696e6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8c50d6464af8e5f96e853baf1001b50f00ad24d33bd093b18e0ee3cb57103ace/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666230323965642f796f6c6f76355f6370705f6f70656e76696e6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/fb029ed/yolov5_cpp_openvino?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 用c++实现了yolov5使用openvino的部署。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dlod-openvino/yolov5_infer\"\u003edlod-openvino/yolov5_infer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/90a36f9b4bde35ec2fe1fc355f749c059fd663b9cfdb539e00d4ec3bc19533c1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646c6f642d6f70656e76696e6f2f796f6c6f76355f696e6665723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/90a36f9b4bde35ec2fe1fc355f749c059fd663b9cfdb539e00d4ec3bc19533c1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646c6f642d6f70656e76696e6f2f796f6c6f76355f696e6665723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dlod-openvino/yolov5_infer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Do the YOLOv5 model inference by OpenCV/OpenVINO based on onnx model format.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/snail0614/yolov5.6_openvino_cpp\"\u003esnail0614/yolov5.6_openvino_cpp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1c22fe4c6db8fd684bc3de0346fc745def428833eceb1cd6dc2b1f7d5f6c2b12/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736e61696c303631342f796f6c6f76352e365f6f70656e76696e6f5f6370703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1c22fe4c6db8fd684bc3de0346fc745def428833eceb1cd6dc2b1f7d5f6c2b12/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736e61696c303631342f796f6c6f76352e365f6f70656e76696e6f5f6370703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/snail0614/yolov5.6_openvino_cpp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5.6.1 OpenVINO的C++实现。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/shungfu/openvino_yolov5v7\"\u003eshungfu/openvino_yolov5v7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5fb33f13f6cf3e8ec06ca4a41043ce585052dc053cb77fa121a69f225531b315/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7368756e6766752f6f70656e76696e6f5f796f6c6f763576373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5fb33f13f6cf3e8ec06ca4a41043ce585052dc053cb77fa121a69f225531b315/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7368756e6766752f6f70656e76696e6f5f796f6c6f763576373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/shungfu/openvino_yolov5v7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 YOLOv7 INT8 quantization using OpenVINO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dacquaviva/yolov5-openvino-cpp-python\"\u003edacquaviva/yolov5-openvino-cpp-python\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/472de67c713818b3ebb7a96d8b199ecf503f0bf59fe413ce727df287685f4072/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646163717561766976612f796f6c6f76352d6f70656e76696e6f2d6370702d707974686f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/472de67c713818b3ebb7a96d8b199ecf503f0bf59fe413ce727df287685f4072/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646163717561766976612f796f6c6f76352d6f70656e76696e6f2d6370702d707974686f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dacquaviva/yolov5-openvino-cpp-python?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Example of using ultralytics YOLOv5 with Openvino in C++ and Python.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/rlggyp/YOLOv10-OpenVINO-CPP-Inference\"\u003erlggyp/YOLOv10-OpenVINO-CPP-Inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/252fc6ce15289046fa03dab9c8d16f2c7840273956570557d348b04fe4afc7df/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726c676779702f594f4c4f7631302d4f70656e56494e4f2d4350502d496e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/252fc6ce15289046fa03dab9c8d16f2c7840273956570557d348b04fe4afc7df/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726c676779702f594f4c4f7631302d4f70656e56494e4f2d4350502d496e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/rlggyp/YOLOv10-OpenVINO-CPP-Inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv10 C++ implementation using OpenVINO for efficient and accurate real-time object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eNCNN\u003c/h5\u003e\u003ca id=\"user-content-ncnn\" class=\"anchor\" aria-label=\"Permalink: NCNN\" href=\"#ncnn\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Tencent/ncnn\"\u003eNCNN\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5c72531566f052b2acd667593b42e0dd599bbb415bf7ea22ace7bbe4a9f9bfc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54656e63656e742f6e636e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5c72531566f052b2acd667593b42e0dd599bbb415bf7ea22ace7bbe4a9f9bfc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54656e63656e742f6e636e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Tencent/ncnn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ncnn is a high-performance neural network inference framework optimized for the mobile platform.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Baiyuetribe/ncnn-models\"\u003eBaiyuetribe/ncnn-models\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/24fdd8179935c60095f33ffa3f6766f1bd6a334bdb1a41ef1d141c8966d730b4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42616979756574726962652f6e636e6e2d6d6f64656c733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/24fdd8179935c60095f33ffa3f6766f1bd6a334bdb1a41ef1d141c8966d730b4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42616979756574726962652f6e636e6e2d6d6f64656c733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Baiyuetribe/ncnn-models?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : awesome AI models with NCNN, and how they were converted ✨✨✨\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloV10-ncnn-Raspberry-Pi-4\"\u003eQengineering/YoloV10-ncnn-Raspberry-Pi-4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8f1467be7a431d720889ca97396c9fdc930d73b7477d86e532dadf98a32557bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f5631302d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8f1467be7a431d720889ca97396c9fdc930d73b7477d86e532dadf98a32557bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f5631302d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloV10-ncnn-Raspberry-Pi-4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV10 for a bare Raspberry Pi 4 or 5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cmdbug/YOLOv5_NCNN\"\u003ecmdbug/YOLOv5_NCNN\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7d0a12e2c178bf39b01e0baa2701b17544eae7da261de9e69d342c0d9344fc04/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636d646275672f594f4c4f76355f4e434e4e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7d0a12e2c178bf39b01e0baa2701b17544eae7da261de9e69d342c0d9344fc04/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636d646275672f594f4c4f76355f4e434e4e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cmdbug/YOLOv5_NCNN?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🍅 Deploy ncnn on mobile phones. Support Android and iOS. 移动端ncnn部署，支持Android与iOS。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/natanielruiz/android-yolo\"\u003enatanielruiz/android-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/eb72a9ad9c0ddfced4200ea88c62db25dd5151de475a8f50269e541e96f846cf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e6174616e69656c7275697a2f616e64726f69642d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/eb72a9ad9c0ddfced4200ea88c62db25dd5151de475a8f50269e541e96f846cf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e6174616e69656c7275697a2f616e64726f69642d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/natanielruiz/android-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time object detection on Android using the YOLO network with TensorFlow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nihui/ncnn-android-yolov5\"\u003enihui/ncnn-android-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9908c82ca5f6036a71be93c8d7fc762fcdc98dc2d6ff9e738e1be39f3730da4d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e696875692f6e636e6e2d616e64726f69642d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9908c82ca5f6036a71be93c8d7fc762fcdc98dc2d6ff9e738e1be39f3730da4d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e696875692f6e636e6e2d616e64726f69642d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nihui/ncnn-android-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The YOLOv5 object detection android example.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/szaza/android-yolo-v2\"\u003eszaza/android-yolo-v2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3e8e27d75bbdb29df6335c1434f86523297618e61e80c7ab06963068feb312b2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737a617a612f616e64726f69642d796f6c6f2d76323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3e8e27d75bbdb29df6335c1434f86523297618e61e80c7ab06963068feb312b2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737a617a612f616e64726f69642d796f6c6f2d76323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/szaza/android-yolo-v2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Android YOLO real time object detection sample application with Tensorflow mobile.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FeiGeChuanShu/ncnn-android-yolox\"\u003eFeiGeChuanShu/ncnn-android-yolox\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2b114dd6b421b1c1e7799fb83bcdac016f815cef0127128ea8d3e3edb2ec113c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4665694765436875616e5368752f6e636e6e2d616e64726f69642d796f6c6f783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2b114dd6b421b1c1e7799fb83bcdac016f815cef0127128ea8d3e3edb2ec113c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4665694765436875616e5368752f6e636e6e2d616e64726f69642d796f6c6f783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FeiGeChuanShu/ncnn-android-yolox?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real time yolox Android demo by ncnn.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xiangweizeng/darknet2ncnn\"\u003exiangweizeng/darknet2ncnn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/29a4385eaf0d66811c436727bbdf04933e959834b1e1b43d109d76dd3a2ab874/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616e677765697a656e672f6461726b6e6574326e636e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/29a4385eaf0d66811c436727bbdf04933e959834b1e1b43d109d76dd3a2ab874/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616e677765697a656e672f6461726b6e6574326e636e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xiangweizeng/darknet2ncnn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Darknet2ncnn converts the darknet model to the ncnn model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sunnyden/YOLOV5_NCNN_Android\"\u003esunnyden/YOLOV5_NCNN_Android\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6b041b9363aede2525a4062a91633a4ef4fccd2eefd223a58c11e49404604825/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756e6e7964656e2f594f4c4f56355f4e434e4e5f416e64726f69643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6b041b9363aede2525a4062a91633a4ef4fccd2eefd223a58c11e49404604825/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756e6e7964656e2f594f4c4f56355f4e434e4e5f416e64726f69643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sunnyden/YOLOV5_NCNN_Android?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 C++ Implementation on Android using NCNN framework.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/duangenquan/YoloV2NCS\"\u003eduangenquan/YoloV2NCS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c88b9402f1c4ff6ee2f6a548b5daeddfbd3a2a1878518d702edacf7d524dfa86/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6475616e67656e7175616e2f596f6c6f56324e43533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c88b9402f1c4ff6ee2f6a548b5daeddfbd3a2a1878518d702edacf7d524dfa86/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6475616e67656e7175616e2f596f6c6f56324e43533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/duangenquan/YoloV2NCS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This project shows how to run tiny yolo v2 with movidius stick.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lp6m/yolov5s_android\"\u003elp6m/yolov5s_android\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e744cfaaab54cd282316cd8a67e63802c3f45888ab9e36a46ad82735a030f4b7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c70366d2f796f6c6f7635735f616e64726f69643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e744cfaaab54cd282316cd8a67e63802c3f45888ab9e36a46ad82735a030f4b7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c70366d2f796f6c6f7635735f616e64726f69643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lp6m/yolov5s_android?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Run yolov5s on Android device!\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/KoheiKanagu/ncnn_yolox_flutter\"\u003eKoheiKanagu/ncnn_yolox_flutter\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2ee24377c35806d6f248958efdba14dfc9c0d7c2ad93093f89300d2f9da66826/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6f6865694b616e6167752f6e636e6e5f796f6c6f785f666c75747465723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2ee24377c35806d6f248958efdba14dfc9c0d7c2ad93093f89300d2f9da66826/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6f6865694b616e6167752f6e636e6e5f796f6c6f785f666c75747465723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/KoheiKanagu/ncnn_yolox_flutter?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a plugin to run YOLOX on ncnn.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cyrillkuettel/ncnn-android-yolov5\"\u003ecyrillkuettel/ncnn-android-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9ff61d0d29f4604d83c193f3bd32381cd55d506c92df4b5f1b41ff637d627d89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f637972696c6c6b75657474656c2f6e636e6e2d616e64726f69642d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9ff61d0d29f4604d83c193f3bd32381cd55d506c92df4b5f1b41ff637d627d89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f637972696c6c6b75657474656c2f6e636e6e2d616e64726f69642d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cyrillkuettel/ncnn-android-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a sample ncnn android project, it depends on ncnn library and opencv.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DataXujing/ncnn_android_yolov6\"\u003eDataXujing/ncnn_android_yolov6\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1cca359d0c267435cc4c5d1a06d5cb1145d2318e598c0594ad36e603eaf2890d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f6e636e6e5f616e64726f69645f796f6c6f76363f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1cca359d0c267435cc4c5d1a06d5cb1145d2318e598c0594ad36e603eaf2890d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f6e636e6e5f616e64726f69645f796f6c6f76363f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DataXujing/ncnn_android_yolov6?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 手摸手实现基于QT和NCNN的安卓手机YOLOv6模型的部署！\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloV3-ncnn-Raspberry-Pi-4\"\u003eQengineering/YoloV3-ncnn-Raspberry-Pi-4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/359fd3a7a21ef726aa0c1ed43e5f4ca5604229e8688f31261ff3fcc96d1d899a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56332d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/359fd3a7a21ef726aa0c1ed43e5f4ca5604229e8688f31261ff3fcc96d1d899a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56332d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloV3-ncnn-Raspberry-Pi-4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV3 Raspberry Pi 4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloV4-ncnn-Raspberry-Pi-4\"\u003eQengineering/YoloV4-ncnn-Raspberry-Pi-4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c5593836c6dd9fdd9da4ff0a16cb74f78a6eb97d38b66d9e9f1ff6853e69432a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56342d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c5593836c6dd9fdd9da4ff0a16cb74f78a6eb97d38b66d9e9f1ff6853e69432a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56342d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloV4-ncnn-Raspberry-Pi-4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV4 on a bare Raspberry Pi 4 with ncnn framework.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloV5-ncnn-Raspberry-Pi-4\"\u003eQengineering/YoloV5-ncnn-Raspberry-Pi-4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/09671a5b4c5fc25d7f0ce714cfd23302075d6179b96c65f618db37e2f54a0fb4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56352d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/09671a5b4c5fc25d7f0ce714cfd23302075d6179b96c65f618db37e2f54a0fb4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56352d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloV5-ncnn-Raspberry-Pi-4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV5 for a bare Raspberry Pi 4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloV6-ncnn-Raspberry-Pi-4\"\u003eQengineering/YoloV6-ncnn-Raspberry-Pi-4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/eaed56b04578eb5bddba6eb92f7a26514a2114fa605d0a1c4d735b4d3cf5ed53/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56362d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/eaed56b04578eb5bddba6eb92f7a26514a2114fa605d0a1c4d735b4d3cf5ed53/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56362d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloV6-ncnn-Raspberry-Pi-4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV6 for a bare Raspberry Pi using ncnn.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloV7-ncnn-Raspberry-Pi-4\"\u003eQengineering/YoloV7-ncnn-Raspberry-Pi-4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/adc9f37bba0efa266a00c4c0edf1408a6fa18c5b0643e669bcc76cc7612bf3fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56372d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/adc9f37bba0efa266a00c4c0edf1408a6fa18c5b0643e669bcc76cc7612bf3fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56372d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloV7-ncnn-Raspberry-Pi-4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV7 for a bare Raspberry Pi using ncnn.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloV8-ncnn-Raspberry-Pi-4\"\u003eQengineering/YoloV8-ncnn-Raspberry-Pi-4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b6cd90ae8fa955be67d84e8d026e8b9399f9952fa219f36af28330783c8ed1eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56382d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b6cd90ae8fa955be67d84e8d026e8b9399f9952fa219f36af28330783c8ed1eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56382d6e636e6e2d5261737062657272792d50692d343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloV8-ncnn-Raspberry-Pi-4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV8 for a bare Raspberry Pi 4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FeiGeChuanShu/ncnn-android-yolov8\"\u003eFeiGeChuanShu/ncnn-android-yolov8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ae353aa0ee568f3ae05de50723e822674f1efbc144548466f8926a4992a134c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4665694765436875616e5368752f6e636e6e2d616e64726f69642d796f6c6f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ae353aa0ee568f3ae05de50723e822674f1efbc144548466f8926a4992a134c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4665694765436875616e5368752f6e636e6e2d616e64726f69642d796f6c6f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FeiGeChuanShu/ncnn-android-yolov8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real time yolov8 Android demo by ncnn.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FLamefiREz/yolov10-android-ncnn\"\u003eFLamefiREz/yolov10-android-ncnn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c902ba55930831b85c1a363d186144f42814c1cb0b3f9552ba2edbce9b41fe11/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f464c616d65666952457a2f796f6c6f7631302d616e64726f69642d6e636e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c902ba55930831b85c1a363d186144f42814c1cb0b3f9552ba2edbce9b41fe11/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f464c616d65666952457a2f796f6c6f7631302d616e64726f69642d6e636e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FLamefiREz/yolov10-android-ncnn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov10-android-ncnn.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eMNN\u003c/h5\u003e\u003ca id=\"user-content-mnn\" class=\"anchor\" aria-label=\"Permalink: MNN\" href=\"#mnn\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/alibaba/MNN\"\u003eMNN\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f65ac69d4afe8f811e289774cee39b8a0c45a37b539db52ad5af444a6ab8117d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69626162612f4d4e4e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f65ac69d4afe8f811e289774cee39b8a0c45a37b539db52ad5af444a6ab8117d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69626162612f4d4e4e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/alibaba/MNN?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : MNN is a blazing fast, lightweight deep learning framework, battle-tested by business-critical use cases in Alibaba. (\u003cstrong\u003e\u003ca href=\"https://proceedings.mlsys.org/paper/2020/hash/8f14e45fceea167a5a36dedd4bea2543-Abstract.html\" rel=\"nofollow\"\u003eMLSys 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/apxlwl/MNN-yolov3\"\u003eapxlwl/MNN-yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/00b80e3d6d6516105c460cd829ef6d4bae9bf9f03ec12f1eef4416d7ae146840/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6170786c776c2f4d4e4e2d796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/00b80e3d6d6516105c460cd829ef6d4bae9bf9f03ec12f1eef4416d7ae146840/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6170786c776c2f4d4e4e2d796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/apxlwl/MNN-yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : MNN demo of Strongeryolo, including channel pruning, android support...\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOther Engine\u003c/h5\u003e\u003ca id=\"user-content-other-engine\" class=\"anchor\" aria-label=\"Permalink: Other Engine\" href=\"#other-engine\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/apache/tvm\"\u003eTVM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/98823984dbc785e54ff14e39483f27188d21c990af5250f0a677dbc22ddc1296/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6170616368652f74766d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/98823984dbc785e54ff14e39483f27188d21c990af5250f0a677dbc22ddc1296/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6170616368652f74766d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/apache/tvm?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Open deep learning compiler stack for cpu, gpu and specialized accelerators.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ceccocats/tkDNN\"\u003ececcocats/tkDNN\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/182ae2c1843f4faf86c2ebdfd3d95f42d568f6215dfb609a641f2589a39cf964/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636563636f636174732f746b444e4e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/182ae2c1843f4faf86c2ebdfd3d95f42d568f6215dfb609a641f2589a39cf964/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636563636f636174732f746b444e4e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ceccocats/tkDNN?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Deep neural network library and toolkit to do high performace inference on NVIDIA jetson platforms. \"A Systematic Assessment of Embedded Neural Networks for Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/document/9212130\" rel=\"nofollow\"\u003eIEEE ETFA 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/OAID/Tengine\"\u003eTengine\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8ca3bfd45d2c41f059351cd57fb0b72b87df96861b890bad58aa7b143fcaa61c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f4149442f54656e67696e653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8ca3bfd45d2c41f059351cd57fb0b72b87df96861b890bad58aa7b143fcaa61c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f4149442f54656e67696e653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/OAID/Tengine?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tengine is a lite, high performance, modular inference engine for embedded device.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/paddlepaddle/paddle-lite\"\u003ePaddle Lite\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c327d099615f469136b9ee9d9cae01142a3a7242da191535e5d88d621d22262e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706164646c65706164646c652f706164646c652d6c6974653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c327d099615f469136b9ee9d9cae01142a3a7242da191535e5d88d621d22262e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706164646c65706164646c652f706164646c652d6c6974653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/paddlepaddle/paddle-lite?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Multi-platform high performance deep learning inference engine (飞桨多端多平台高性能深度学习推理引擎）。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DeployAI/nndeploy\"\u003eDeployAI/nndeploy\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5c16c6f36ec6da6b7e64d893ad79122a91e8f496485f46387c1af19013d81034/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465706c6f7941492f6e6e6465706c6f793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5c16c6f36ec6da6b7e64d893ad79122a91e8f496485f46387c1af19013d81034/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465706c6f7941492f6e6e6465706c6f793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DeployAI/nndeploy?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : nndeploy is a cross-platform, high-performing, and straightforward AI model deployment framework. We strive to deliver a consistent and user-friendly experience across various inference framework in complex deployment environments and focus on performance. nndeploy一款跨平台、高性能、简单易用的模型端到端部署框架。我们致力于屏蔽不同推理框架的差异，提供一致且用户友好的编程体验，同时专注于部署全流程的性能。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yhwang-hub/dl_model_infer\"\u003eyhwang-hub/dl_model_infer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/07aada3f299dd15c7a814b88943c15a530898871fb31f83bf06da03440d07ee2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796877616e672d6875622f646c5f6d6f64656c5f696e6665723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/07aada3f299dd15c7a814b88943c15a530898871fb31f83bf06da03440d07ee2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796877616e672d6875622f646c5f6d6f64656c5f696e6665723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yhwang-hub/dl_model_infer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : his is a c++ version of the AI reasoning library. Currently, it only supports the reasoning of the tensorrt model. The follow-up plan supports the c++ reasoning of frameworks such as Openvino, NCNN, and MNN. There are two versions for pre- and post-processing, c++ version and cuda version. It is recommended to use the cuda version., This repository provides accelerated deployment cases of deep learning CV popular models, and cuda c supports dynamic-batch image process, infer, decode, NMS.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hollance/YOLO-CoreML-MPSNNGraph\"\u003ehollance/YOLO-CoreML-MPSNNGraph\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/70e456dcebfd43fefd4430577098f5dde664abf1df10980eaa96626ad64dc914/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686f6c6c616e63652f594f4c4f2d436f72654d4c2d4d50534e4e47726170683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/70e456dcebfd43fefd4430577098f5dde664abf1df10980eaa96626ad64dc914/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686f6c6c616e63652f594f4c4f2d436f72654d4c2d4d50534e4e47726170683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hollance/YOLO-CoreML-MPSNNGraph?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tiny YOLO for iOS implemented using CoreML but also using the new MPS graph API.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/r4ghu/iOS-CoreML-Yolo\"\u003er4ghu/iOS-CoreML-Yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8abc8c19f000c68e4a3d04d7e5aed0312ba6f531f0fa0c55d98b8d2d87a3c7e8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72346768752f694f532d436f72654d4c2d596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8abc8c19f000c68e4a3d04d7e5aed0312ba6f531f0fa0c55d98b8d2d87a3c7e8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72346768752f694f532d436f72654d4c2d596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/r4ghu/iOS-CoreML-Yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is the implementation of Object Detection using Tiny YOLO v1 model on Apple's CoreML Framework.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/airockchip/rknn_model_zoo\"\u003eairockchip/rknn_model_zoo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d3cfbdb3b4622b63af680668b0b266e343326c494a6974b0c691e82590e8b2a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6169726f636b636869702f726b6e6e5f6d6f64656c5f7a6f6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d3cfbdb3b4622b63af680668b0b266e343326c494a6974b0c691e82590e8b2a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6169726f636b636869702f726b6e6e5f6d6f64656c5f7a6f6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/airockchip/rknn_model_zoo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Rockchip Neural Network(RKNN)是瑞芯微为了加速模型推理而基于自身NPU硬件架构定义的一套模型格式.使用该格式定义的模型在Rockchip NPU上可以获得远高于CPU/GPU的性能。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LynxiTechnology/Lynxi-model-zoo\"\u003eLynxiTechnology/Lynxi-model-zoo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ab1ec2d79393427c2e35bf8e431375ccaf4a4aa99dbec015b5a8cf9c403175d7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c796e7869546563686e6f6c6f67792f4c796e78692d6d6f64656c2d7a6f6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ab1ec2d79393427c2e35bf8e431375ccaf4a4aa99dbec015b5a8cf9c403175d7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c796e7869546563686e6f6c6f67792f4c796e78692d6d6f64656c2d7a6f6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LynxiTechnology/Lynxi-model-zoo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Lynxi-model-zoo.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eNPU and FPGA Hardware Deployment\u003c/h3\u003e\u003ca id=\"user-content-npu-and-fpga-hardware-deployment\" class=\"anchor\" aria-label=\"Permalink: NPU and FPGA Hardware Deployment\" href=\"#npu-and-fpga-hardware-deployment\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eNPU 和 FPGA 硬件部署\u003c/h4\u003e\u003ca id=\"user-content-npu-和-fpga-硬件部署\" class=\"anchor\" aria-label=\"Permalink: NPU 和 FPGA 硬件部署\" href=\"#npu-和-fpga-硬件部署\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eRK3588\u003c/h5\u003e\u003ca id=\"user-content-rk3588\" class=\"anchor\" aria-label=\"Permalink: RK3588\" href=\"#rk3588\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloV8-NPU\"\u003eQengineering/YoloV8-NPU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a1c70014fb4985fdb23a08603ce619f42d7e6b87d6a031b174e95449be52efc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56382d4e50553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a1c70014fb4985fdb23a08603ce619f42d7e6b87d6a031b174e95449be52efc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f56382d4e50553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloV8-NPU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV8 for RK3566/68/88 NPU (Rock 5, Orange Pi 5, Radxa Zero 3).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/aemior/yolov8n_rk3588\"\u003eaemior/yolov8n_rk3588\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d9c44d64203c838cce4c250a819a162af8b23058cdcbcccee062634219d91b13/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61656d696f722f796f6c6f76386e5f726b333538383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d9c44d64203c838cce4c250a819a162af8b23058cdcbcccee062634219d91b13/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61656d696f722f796f6c6f76386e5f726b333538383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/aemior/yolov8n_rk3588?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository contains a demonstration of Yolv8n running on an RK3588 device.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cqu20160901/yolov8n_rknn_Cplusplus_dfl\"\u003ecqu20160901/yolov8n_rknn_Cplusplus_dfl\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cb7af19950f93e942e66fa8cb9c61787ffc89eb527eb73d567ca87a69c0b2d5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63717532303136303930312f796f6c6f76386e5f726b6e6e5f43706c7573706c75735f64666c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cb7af19950f93e942e66fa8cb9c61787ffc89eb527eb73d567ca87a69c0b2d5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63717532303136303930312f796f6c6f76386e5f726b6e6e5f43706c7573706c75735f64666c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cqu20160901/yolov8n_rknn_Cplusplus_dfl?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov8 瑞芯微 rknn 板端 C++部署，使用平台 rk3588，全网最简单、运行最快的部署方式。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cqu20160901/yolov8seg_rknn_Cplusplus\"\u003ecqu20160901/yolov8seg_rknn_Cplusplus\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/15c2bf5953561406f967fe18ea34cd3ac6186f7c3a755b8f63de2cbdd27adc34/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63717532303136303930312f796f6c6f76387365675f726b6e6e5f43706c7573706c75733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/15c2bf5953561406f967fe18ea34cd3ac6186f7c3a755b8f63de2cbdd27adc34/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63717532303136303930312f796f6c6f76387365675f726b6e6e5f43706c7573706c75733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cqu20160901/yolov8seg_rknn_Cplusplus?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov8seg 瑞芯微 rknn 板端 C++部署，使用平台 rk3588。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ley-WL/ultralytics-rknn\"\u003eLey-WL/ultralytics-rknn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9bd6bf4ff8707afb5bca389e0d778fed2f4dd456966c7156e3b0b594cbb06a25/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c65792d574c2f756c7472616c79746963732d726b6e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9bd6bf4ff8707afb5bca389e0d778fed2f4dd456966c7156e3b0b594cbb06a25/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c65792d574c2f756c7472616c79746963732d726b6e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ley-WL/ultralytics-rknn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于ultralytics-yolov8, 将其检测/分类/分割/姿态等任务移植到rk3588上。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/455670288/rknn-yolov8s-multi-thread-inference\"\u003e455670288/rknn-yolov8s-multi-thread-inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6c93a2ecfd9dd657253857a8cee46536856add009a8754f149d9dde64217eac1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3435353637303238382f726b6e6e2d796f6c6f7638732d6d756c74692d7468726561642d696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6c93a2ecfd9dd657253857a8cee46536856add009a8754f149d9dde64217eac1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3435353637303238382f726b6e6e2d796f6c6f7638732d6d756c74692d7468726561642d696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/455670288/rknn-yolov8s-multi-thread-inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov8s在rk3588的推理部署，并使用多线程池并行npu推理加速。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/leafqycc/rknn-cpp-Multithreading\"\u003eleafqycc/rknn-cpp-Multithreading\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9febc2df204bd3ab181507d8ce079d023c4009e59c95e8fe3eeec003945542b3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c656166717963632f726b6e6e2d6370702d4d756c7469746872656164696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9febc2df204bd3ab181507d8ce079d023c4009e59c95e8fe3eeec003945542b3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c656166717963632f726b6e6e2d6370702d4d756c7469746872656164696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/leafqycc/rknn-cpp-Multithreading?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A simple demo of yolov5s running on rk3588/3588s using c++ (about 142 frames). / 一个使用c++在rk3588/3588s上运行的yolov5s简单demo(142帧/s)。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/leafqycc/rknn-multi-threaded\"\u003eleafqycc/rknn-multi-threaded\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2262a24a1c58019b2fb5dffcc5b739aeecdcb654e5ba6e0c1315db53fe57b5a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c656166717963632f726b6e6e2d6d756c74692d74687265616465643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2262a24a1c58019b2fb5dffcc5b739aeecdcb654e5ba6e0c1315db53fe57b5a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c656166717963632f726b6e6e2d6d756c74692d74687265616465643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/leafqycc/rknn-multi-threaded?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A simple demo of yolov5s running on rk3588/3588s using Python (about 72 frames). / 一个使用Python在rk3588/3588s上运行的yolov5s简单demo(大约72帧/s)。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wzxzhuxi/rknn-3588-npu-yolo-accelerate\"\u003ewzxzhuxi/rknn-3588-npu-yolo-accelerate\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a9d2310e28ac2c39c7dee1dff8d1d60aa63012c309f14cd848aef0a2e66a1c99/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f777a787a687578692f726b6e6e2d333538382d6e70752d796f6c6f2d616363656c65726174653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a9d2310e28ac2c39c7dee1dff8d1d60aa63012c309f14cd848aef0a2e66a1c99/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f777a787a687578692f726b6e6e2d333538382d6e70752d796f6c6f2d616363656c65726174653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wzxzhuxi/rknn-3588-npu-yolo-accelerate?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : rknn-3588部署yolov5，利用线程池实现npu推理加速；Deploying YOLOv5 on RKNN-3588, utilizing a thread pool to achieve NPU inference acceleration.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kaylorchen/rk3588-yolo-demo\"\u003ekaylorchen/rk3588-yolo-demo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2ea197e2546a8c4ceff56564eff68524259d7afb5196f48aa063031a6fdfeb20/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b61796c6f726368656e2f726b333538382d796f6c6f2d64656d6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2ea197e2546a8c4ceff56564eff68524259d7afb5196f48aa063031a6fdfeb20/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b61796c6f726368656e2f726b333538382d796f6c6f2d64656d6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kaylorchen/rk3588-yolo-demo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The project is a multi-threaded inference demo of Yolo running on the RK3588 platform, which has been adapted for reading video files and camera feeds. The demo uses the Yolov8n model for file inference, with a maximum inference frame rate of up to 100 frames per second.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MontaukLaw/yolov5_3588_multi_thread\"\u003eMontaukLaw/yolov5_3588_multi_thread\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fcf234021ca5720a2973c524e760a551e24be96aec160c6600bc0d725d35edf6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f6e7461756b4c61772f796f6c6f76355f333538385f6d756c74695f7468726561643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fcf234021ca5720a2973c524e760a551e24be96aec160c6600bc0d725d35edf6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f6e7461756b4c61772f796f6c6f76355f333538385f6d756c74695f7468726561643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MontaukLaw/yolov5_3588_multi_thread?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 启动多线程, relu激活, 3588的yolo部署, 帧率150以上.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/crab2rab/RKNN-YOLOV5-BatchInference-MultiThreading\"\u003ecrab2rab/RKNN-YOLOV5-BatchInference-MultiThreading\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7b2cec4fea2d402004f9fde8060c8636599655896ec94f75fdde846910fa0cc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63726162327261622f524b4e4e2d594f4c4f56352d4261746368496e666572656e63652d4d756c7469546872656164696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7b2cec4fea2d402004f9fde8060c8636599655896ec94f75fdde846910fa0cc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63726162327261622f524b4e4e2d594f4c4f56352d4261746368496e666572656e63652d4d756c7469546872656164696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/crab2rab/RKNN-YOLOV5-BatchInference-MultiThreading?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : RKNN-YOLOV5-BatchInference-MultiThreadingYOLOV5多张图片多线程C++推理。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloV10-NPU\"\u003eQengineering/YoloV10-NPU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/303a2c99bb41e2a1094595f30b4bfeaaadc47e867feecc5d796562dea09a0540/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f5631302d4e50553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/303a2c99bb41e2a1094595f30b4bfeaaadc47e867feecc5d796562dea09a0540/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f5631302d4e50553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloV10-NPU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV10 NPU for the RK3566/68/88.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cqu20160901/yolov10_rknn_Cplusplus\"\u003ecqu20160901/yolov10_rknn_Cplusplus\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d1545aef12dcc02fee833975959a10af05512b984389b64f37bc1465d9989a8d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63717532303136303930312f796f6c6f7631305f726b6e6e5f43706c7573706c75733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d1545aef12dcc02fee833975959a10af05512b984389b64f37bc1465d9989a8d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63717532303136303930312f796f6c6f7631305f726b6e6e5f43706c7573706c75733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cqu20160901/yolov10_rknn_Cplusplus?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov10 瑞芯微 rknn 板端 C++部署，使用平台 rk3588。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Zhou-sx/yolov5_Deepsort_rknn\"\u003eZhou-sx/yolov5_Deepsort_rknn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/07808ab2be52e7ea599b1a0f280918ab9ac8c9828ac317d6e3f73157c6b9cdfc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a686f752d73782f796f6c6f76355f44656570736f72745f726b6e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/07808ab2be52e7ea599b1a0f280918ab9ac8c9828ac317d6e3f73157c6b9cdfc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a686f752d73782f796f6c6f76355f44656570736f72745f726b6e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Zhou-sx/yolov5_Deepsort_rknn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Track vehicles and persons on rk3588 / rk3399pro.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Applied-Deep-Learning-Lab/Yolov5_RK3588\"\u003eApplied-Deep-Learning-Lab/Yolov5_RK3588\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/385e57389335c16cddd9709a51cc2c8504e699a178a66a91f2e9a24dd36aef1c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4170706c6965642d446565702d4c6561726e696e672d4c61622f596f6c6f76355f524b333538383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/385e57389335c16cddd9709a51cc2c8504e699a178a66a91f2e9a24dd36aef1c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4170706c6965642d446565702d4c6561726e696e672d4c61622f596f6c6f76355f524b333538383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Applied-Deep-Learning-Lab/Yolov5_RK3588?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov5_RK3588.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cqu20160901/yolov10_onnx_rknn_horizon_tensorRT\"\u003ecqu20160901/yolov10_onnx_rknn_horizon_tensorRT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5ce002e416b43788a94b8b646341cf82c6e55c463ed3553e11a205a580b18fea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63717532303136303930312f796f6c6f7631305f6f6e6e785f726b6e6e5f686f72697a6f6e5f74656e736f7252543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5ce002e416b43788a94b8b646341cf82c6e55c463ed3553e11a205a580b18fea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63717532303136303930312f796f6c6f7631305f6f6e6e785f726b6e6e5f686f72697a6f6e5f74656e736f7252543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cqu20160901/yolov10_onnx_rknn_horizon_tensorRT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov10 目标检测部署版本，便于移植不同平台（onnx、tensorRT、rknn、Horizon），全网部署最简单、运行速度最快的部署方式（全网首发）。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/icetd/RkYoloRtspServer\"\u003eicetd/RkYoloRtspServer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c55ce9603f82e112b04ea983b06c2ed244e0ea063ad311d1e8bd5af5b6061d32/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69636574642f526b596f6c6f527473705365727665723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c55ce9603f82e112b04ea983b06c2ed244e0ea063ad311d1e8bd5af5b6061d32/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69636574642f526b596f6c6f527473705365727665723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/icetd/RkYoloRtspServer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : simple yolov5 rtspserver for rk3588.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFPGA\u003c/h5\u003e\u003ca id=\"user-content-fpga\" class=\"anchor\" aria-label=\"Permalink: FPGA\" href=\"#fpga\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Xilinx/Vitis-AI/tree/master/demo\"\u003eXilinx/Vitis-AI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4c94f32044c8405aa56b21388a5b40815d886653f720ca946eb1ac4354c2f3d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f58696c696e782f56697469732d41493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4c94f32044c8405aa56b21388a5b40815d886653f720ca946eb1ac4354c2f3d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f58696c696e782f56697469732d41493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Xilinx/Vitis-AI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Vitis AI offers a unified set of high-level C++/Python programming APIs to run AI applications across edge-to-cloud platforms, including DPU for Alveo, and DPU for Zynq Ultrascale+ MPSoC and Zynq-7000. It brings the benefits to easily port AI applications from cloud to edge and vice versa. 10 samples in \u003ca href=\"https://github.com/Xilinx/Vitis-AI/tree/master/demo/VART\"\u003eVART Samples\u003c/a\u003e are available to help you get familiar with the unfied programming APIs. \u003ca href=\"https://github.com/Xilinx/Vitis-AI/tree/master/demo/Vitis-AI-Library\"\u003eVitis-AI-Library\u003c/a\u003e provides an easy-to-use and unified interface by encapsulating many efficient and high-quality neural networks.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tensil-ai/tensil\"\u003etensil-ai/tensil\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0706eeeef9d261e1e171873cffb4f9875c009c4f41877179d1ff36636a52fa12/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74656e73696c2d61692f74656e73696c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0706eeeef9d261e1e171873cffb4f9875c009c4f41877179d1ff36636a52fa12/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74656e73696c2d61692f74656e73696c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tensil-ai/tensil?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Open source machine learning accelerators. \u003ca href=\"https://www.tensil.ai/\" rel=\"nofollow\"\u003ewww.tensil.ai\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/19801201/SpinalHDL_CNN_Accelerator\"\u003e19801201/SpinalHDL_CNN_Accelerator\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6e49b43aef15ad5b12d53a1a3aa861293cc3d6332e0d9b3191af1f63d4fd1cca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f31393830313230312f5370696e616c48444c5f434e4e5f416363656c657261746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6e49b43aef15ad5b12d53a1a3aa861293cc3d6332e0d9b3191af1f63d4fd1cca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f31393830313230312f5370696e616c48444c5f434e4e5f416363656c657261746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/19801201/SpinalHDL_CNN_Accelerator?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : CNN accelerator implemented with Spinal HDL.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dhm2013724/yolov2_xilinx_fpga\"\u003edhm2013724/yolov2_xilinx_fpga\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f00aa2c85a8afcba3e0ffedb4974a88d7040786f4dbc9512a312327bd71b0ab6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64686d323031333732342f796f6c6f76325f78696c696e785f667067613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f00aa2c85a8afcba3e0ffedb4974a88d7040786f4dbc9512a312327bd71b0ab6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64686d323031333732342f796f6c6f76325f78696c696e785f667067613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dhm2013724/yolov2_xilinx_fpga?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv2 Accelerator in Xilinx's Zynq-7000 Soc(PYNQ-z2, Zedboard and ZCU102). (\u003cstrong\u003e\u003ca href=\"https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD\u0026amp;dbname=CMFDTEMP\u0026amp;filename=1019228234.nh\u0026amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoOGhUTzA5T0tESzdFZ2pyR1NJR1ZBaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!\u0026amp;v=MjE5NTN5dmdXN3JBVkYyNkY3RzZGdFBQcTVFYlBJUjhlWDFMdXhZUzdEaDFUM3FUcldNMUZyQ1VSTE9lWnVkdUY=\" rel=\"nofollow\"\u003e硕士论文 2019\u003c/a\u003e, \u003ca href=\"https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFQ\u0026amp;dbname=CJFDLAST2019\u0026amp;filename=DZJY201908009\u0026amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoOGhUTzA5T0tESzdFZ2pyR1NJR1ZBaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!\u0026amp;v=MDU0NDJDVVJMT2VadWR1Rnl2Z1c3ck1JVGZCZDdHNEg5ak1wNDlGYllSOGVYMUx1eFlTN0RoMVQzcVRyV00xRnI=\" rel=\"nofollow\"\u003e电子技术应用 2019\u003c/a\u003e, \u003ca href=\"https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFQ\u0026amp;dbname=CJFDTEMP\u0026amp;filename=KXTS201910005\u0026amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoOGhUTzA5T0tESzdFZ2pyR1NJR1ZBaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!\u0026amp;v=MjkwNzdXTTFGckNVUkxPZVp1ZHVGeXZnVzdyT0xqWGZmYkc0SDlqTnI0OUZZWVI4ZVgxTHV4WVM3RGgxVDNxVHI=\" rel=\"nofollow\"\u003e计算机科学与探索 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Yu-Zhewen/Tiny_YOLO_v3_ZYNQ\"\u003eYu-Zhewen/Tiny_YOLO_v3_ZYNQ\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7926885e41b34df6e228c8b714af9f4bedc43bbd524ef93e0462d25dc600dfde/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59752d5a686577656e2f54696e795f594f4c4f5f76335f5a594e513f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7926885e41b34df6e228c8b714af9f4bedc43bbd524ef93e0462d25dc600dfde/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59752d5a686577656e2f54696e795f594f4c4f5f76335f5a594e513f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Yu-Zhewen/Tiny_YOLO_v3_ZYNQ?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Implement Tiny YOLO v3 on ZYNQ. \"A Parameterisable FPGA-Tailored Architecture for YOLOv3-Tiny\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/chapter/10.1007/978-3-030-44534-8_25\" rel=\"nofollow\"\u003eARC 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HSqure/ultralytics-pt-yolov3-vitis-ai-edge\"\u003eHSqure/ultralytics-pt-yolov3-vitis-ai-edge\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f6b5be8ac9d083e68bbd318a5906955d1b9d188a7765890675589413fe659a9b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4853717572652f756c7472616c79746963732d70742d796f6c6f76332d76697469732d61692d656467653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f6b5be8ac9d083e68bbd318a5906955d1b9d188a7765890675589413fe659a9b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4853717572652f756c7472616c79746963732d70742d796f6c6f76332d76697469732d61692d656467653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HSqure/ultralytics-pt-yolov3-vitis-ai-edge?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This demo is only used for inference testing of Vitis AI v1.4 and quantitative compilation of DPU. It is compatible with the training results of \u003ca href=\"https://github.com/ultralytics/yolov3\"\u003eultralytics/yolov3\u003c/a\u003e v9.5.0 (it needs to use the model saving method of Pytorch V1.4).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mcedrdiego/Kria_yolov3_ppe\"\u003emcedrdiego/Kria_yolov3_ppe\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/77dbac1d0ddd4958a7c8399a550be18f66a9a6fca67a2295a863e3992d7fa131/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d63656472646965676f2f4b7269615f796f6c6f76335f7070653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/77dbac1d0ddd4958a7c8399a550be18f66a9a6fca67a2295a863e3992d7fa131/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d63656472646965676f2f4b7269615f796f6c6f76335f7070653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mcedrdiego/Kria_yolov3_ppe?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Kria KV260 Real-Time Personal Protective Equipment Detection. \"Deep Learning for Site Safety: Real-Time Detection of Personal Protective Equipment\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S0926580519308325\" rel=\"nofollow\"\u003eAutomation in Construction 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xlsjdjdk/Ship-Detection-based-on-YOLOv3-and-KV260\"\u003exlsjdjdk/Ship-Detection-based-on-YOLOv3-and-KV260\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/46e444d3963a9330fe2175dafcfe6935f096e59fd8f20a3f3cd75dd9ceca0079/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f786c736a646a646b2f536869702d446574656374696f6e2d62617365642d6f6e2d594f4c4f76332d616e642d4b563236303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/46e444d3963a9330fe2175dafcfe6935f096e59fd8f20a3f3cd75dd9ceca0079/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f786c736a646a646b2f536869702d446574656374696f6e2d62617365642d6f6e2d594f4c4f76332d616e642d4b563236303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xlsjdjdk/Ship-Detection-based-on-YOLOv3-and-KV260?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is the entry project of the Xilinx Adaptive Computing Challenge 2021. It uses YOLOv3 for ship target detection in optical remote sensing images, and deploys DPU on the KV260 platform to achieve hardware acceleration.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Pomiculture/YOLOv4-Vitis-AI\"\u003ePomiculture/YOLOv4-Vitis-AI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5d5400d006d023d1691aab4f7d537a5bba1c752a118c8a9e1917cf8438cc42fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506f6d6963756c747572652f594f4c4f76342d56697469732d41493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5d5400d006d023d1691aab4f7d537a5bba1c752a118c8a9e1917cf8438cc42fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506f6d6963756c747572652f594f4c4f76342d56697469732d41493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Pomiculture/YOLOv4-Vitis-AI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Custom YOLOv4 for apple recognition (clean/damaged) on Alveo U280 accelerator card using Vitis AI framework.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mkshuvo2/ZCU104_YOLOv3_Post_Processing\"\u003emkshuvo2/ZCU104_YOLOv3_Post_Processing\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/30bc6ed72362fa2e1f529284985697b26861824ee17a22778ed18c800e206c55/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6b736875766f322f5a43553130345f594f4c4f76335f506f73745f50726f63657373696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/30bc6ed72362fa2e1f529284985697b26861824ee17a22778ed18c800e206c55/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6b736875766f322f5a43553130345f594f4c4f76335f506f73745f50726f63657373696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mkshuvo2/ZCU104_YOLOv3_Post_Processing?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tensor outputs form Vitis AI Runner Class for YOLOv3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/puffdrum/v4tiny_pt_quant\"\u003epuffdrum/v4tiny_pt_quant\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e6c8a4491ff2be5386fcf8c2af7ace3f07de29ba5b221bc37142928737967a89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f707566666472756d2f763474696e795f70745f7175616e743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e6c8a4491ff2be5386fcf8c2af7ace3f07de29ba5b221bc37142928737967a89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f707566666472756d2f763474696e795f70745f7175616e743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/puffdrum/v4tiny_pt_quant?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : quantization for yolo with xilinx/vitis-ai-pytorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/chanshann/LITE_YOLOV3_TINY_VITISAI\"\u003echanshann/LITE_YOLOV3_TINY_VITISAI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/75ee010fc582b69eca3af1a177a82a4dcb88de846fa5300ec685301b94bc640a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368616e7368616e6e2f4c4954455f594f4c4f56335f54494e595f564954495341493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/75ee010fc582b69eca3af1a177a82a4dcb88de846fa5300ec685301b94bc640a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368616e7368616e6e2f4c4954455f594f4c4f56335f54494e595f564954495341493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/chanshann/LITE_YOLOV3_TINY_VITISAI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : LITE_YOLOV3_TINY_VITISAI.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LukiBa/zybo_yolo\"\u003eLukiBa/zybo_yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f9580c0619165e771e0c894e0a0f7c5ee6818b7edb5a99c3cf87defd9a7ab181/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c756b6942612f7a79626f5f796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f9580c0619165e771e0c894e0a0f7c5ee6818b7edb5a99c3cf87defd9a7ab181/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c756b6942612f7a79626f5f796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LukiBa/zybo_yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO example implementation using Intuitus CNN accelerator on ZYBO ZYNQ-7000 FPGA board.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/matsuda-slab/YOLO_ZYNQ_MASTER\"\u003ematsuda-slab/YOLO_ZYNQ_MASTER\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/195a81ce55ce91382f31dfdf1257708c68156345c2f88415b4b34d3ad7088c83/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6174737564612d736c61622f594f4c4f5f5a594e515f4d41535445523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/195a81ce55ce91382f31dfdf1257708c68156345c2f88415b4b34d3ad7088c83/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6174737564612d736c61622f594f4c4f5f5a594e515f4d41535445523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/matsuda-slab/YOLO_ZYNQ_MASTER?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Implementation of YOLOv3-tiny on FPGA.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FerberZhang/Yolov2-FPGA-CNN-\"\u003eFerberZhang/Yolov2-FPGA-CNN-\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2d9f0a57b49470c68ee90c060c8158ef044314e2ad319c49d9599265226f9336/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4665726265725a68616e672f596f6c6f76322d465047412d434e4e2d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2d9f0a57b49470c68ee90c060c8158ef044314e2ad319c49d9599265226f9336/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4665726265725a68616e672f596f6c6f76322d465047412d434e4e2d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FerberZhang/Yolov2-FPGA-CNN-?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A demo for accelerating YOLOv2 in xilinx's fpga PYNQ.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ChainZeeLi/FPGA_DPU\"\u003eChainZeeLi/FPGA_DPU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1c5dd5934a82e5c7c919e8d93b74595c605a12389e10f3f6be70904cda8a8392/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436861696e5a65654c692f465047415f4450553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1c5dd5934a82e5c7c919e8d93b74595c605a12389e10f3f6be70904cda8a8392/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436861696e5a65654c692f465047415f4450553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ChainZeeLi/FPGA_DPU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This project is to implement YOLO v3 on Xilinx FPGA with DPU.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xbdxwyh/yolov3_fpga_project\"\u003exbdxwyh/yolov3_fpga_project\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/51f01ebe58c9e0bca9c692f55212c9da111550f319d7cce7baa30954a55f1927/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f786264787779682f796f6c6f76335f667067615f70726f6a6563743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/51f01ebe58c9e0bca9c692f55212c9da111550f319d7cce7baa30954a55f1927/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f786264787779682f796f6c6f76335f667067615f70726f6a6563743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xbdxwyh/yolov3_fpga_project?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov3_fpga_project.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZLkanyo009/Yolo-compression-and-deployment-in-FPGA\"\u003eZLkanyo009/Yolo-compression-and-deployment-in-FPGA\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c07e32bdfb35d6bc2a35adea1cd4cae2345c06d92318fd4957e9449149ba9327/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a4c6b616e796f3030392f596f6c6f2d636f6d7072657373696f6e2d616e642d6465706c6f796d656e742d696e2d465047413f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c07e32bdfb35d6bc2a35adea1cd4cae2345c06d92318fd4957e9449149ba9327/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a4c6b616e796f3030392f596f6c6f2d636f6d7072657373696f6e2d616e642d6465706c6f796d656e742d696e2d465047413f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZLkanyo009/Yolo-compression-and-deployment-in-FPGA?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于FPGA量化的人脸口罩检测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xiying-boy/yolov3-AX7350\"\u003exiying-boy/yolov3-AX7350\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d62bde51ec453c352b91557cac25f78d23c4f2c36a4a20a0a34293226a204f0e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f786979696e672d626f792f796f6c6f76332d4158373335303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d62bde51ec453c352b91557cac25f78d23c4f2c36a4a20a0a34293226a204f0e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f786979696e672d626f792f796f6c6f76332d4158373335303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xiying-boy/yolov3-AX7350?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于HLS_YOLOV3的驱动文件。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/himewel/yolowell\"\u003ehimewel/yolowell\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cd932cde45b0e6256e3bfd428d5bd335bd21b4d05c1777287a301ee8c256d32d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68696d6577656c2f796f6c6f77656c6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cd932cde45b0e6256e3bfd428d5bd335bd21b4d05c1777287a301ee8c256d32d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68696d6577656c2f796f6c6f77656c6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/himewel/yolowell?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A set of hardware architectures to build a co-design of convolutional neural networks inference at FPGA devices.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/embedeep/Free-TPU\"\u003eembedeep/Free-TPU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b178973a2fb2042677967163b0eda0c3f48765fe25239060d48a4cdd9cd65d36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656d6265646565702f467265652d5450553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b178973a2fb2042677967163b0eda0c3f48765fe25239060d48a4cdd9cd65d36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f656d6265646565702f467265652d5450553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/embedeep/Free-TPU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Free TPU for FPGA with Lenet, MobileNet, Squeezenet, Resnet, Inception V3, YOLO V3, and ICNet. Deep learning acceleration using Xilinx zynq (Zedboard or ZC702 ) or kintex-7 to solve image classification, detection, and segmentation problem.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yarakigit/design_contest_yolo_change_ps_to_pl\"\u003eyarakigit/design_contest_yolo_change_ps_to_pl\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a378b98be334909e2d3f15d207f63c95c39a8803f8879d8ac3522b1f4bf54a5f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796172616b696769742f64657369676e5f636f6e746573745f796f6c6f5f6368616e67655f70735f746f5f706c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a378b98be334909e2d3f15d207f63c95c39a8803f8879d8ac3522b1f4bf54a5f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796172616b696769742f64657369676e5f636f6e746573745f796f6c6f5f6368616e67655f70735f746f5f706c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yarakigit/design_contest_yolo_change_ps_to_pl?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Converts pytorch yolo format weights to C header files for bare-metal (FPGA implementation).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MasLiang/CNN-On-FPGA\"\u003eMasLiang/CNN-On-FPGA\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/83121c4c89131dc9cf45df88eda0ab51c6e9b4e3efde9558f5be7d8f399749c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d61734c69616e672f434e4e2d4f6e2d465047413f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/83121c4c89131dc9cf45df88eda0ab51c6e9b4e3efde9558f5be7d8f399749c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d61734c69616e672f434e4e2d4f6e2d465047413f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MasLiang/CNN-On-FPGA?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is the code of the CNN on FPGA.But this can only be used for reference at present for some files are write coarsly using ISE.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/adamgallas/fpga_accelerator_yolov3tiny\"\u003eadamgallas/fpga_accelerator_yolov3tiny\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4fd0eee231a29d2ea75669b687d4445d51418e96f68a22c205a668c6666126ab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6164616d67616c6c61732f667067615f616363656c657261746f725f796f6c6f763374696e793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4fd0eee231a29d2ea75669b687d4445d51418e96f68a22c205a668c6666126ab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6164616d67616c6c61732f667067615f616363656c657261746f725f796f6c6f763374696e793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/adamgallas/fpga_accelerator_yolov3tiny?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : fpga_accelerator_yolov3tiny.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ylk678910/tiny-yolov3-fpga\"\u003eylk678910/tiny-yolov3-fpga\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6de0e5079fbf09681dc7688fc2bba5466c40eae0e56d4a7fe0be6eca8c47c70f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796c6b3637383931302f74696e792d796f6c6f76332d667067613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6de0e5079fbf09681dc7688fc2bba5466c40eae0e56d4a7fe0be6eca8c47c70f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796c6b3637383931302f74696e792d796f6c6f76332d667067613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ylk678910/tiny-yolov3-fpga?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Use an all-programmable SoC board to implement locating and tracking tasks. The hardware algorithm, a row-stationary-like strategy, can parallel calculate and reduce the storage buffer area on FPGA.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zhen8838/K210_Yolo_framework\"\u003ezhen8838/K210_Yolo_framework\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a7623e42bdb0f457861d1012fa301df4393f330144c30a98e5ab0ee023b89d67/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68656e383833382f4b3231305f596f6c6f5f6672616d65776f726b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a7623e42bdb0f457861d1012fa301df4393f330144c30a98e5ab0ee023b89d67/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68656e383833382f4b3231305f596f6c6f5f6672616d65776f726b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zhen8838/K210_Yolo_framework?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo v3 framework base on tensorflow, support multiple models, multiple datasets, any number of output layers, any number of anchors, model prune, and portable model to K210 !\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SEASKY-Master/SEASKY_K210\"\u003eSEASKY-Master/SEASKY_K210\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b83d2d73b18d4ef531f9b96ecaa6f4d829529cd3df85aab626a1df9bb6ca190c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f534541534b592d4d61737465722f534541534b595f4b3231303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b83d2d73b18d4ef531f9b96ecaa6f4d829529cd3df85aab626a1df9bb6ca190c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f534541534b592d4d61737465722f534541534b595f4b3231303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SEASKY-Master/SEASKY_K210?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : K210 PCB YOLO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SEASKY-Master/Yolo-for-k210\"\u003eSEASKY-Master/Yolo-for-k210\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/db5d9f38068f602381e58f4fccded95816044d18053bdf27381f3b6131f90085/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f534541534b592d4d61737465722f596f6c6f2d666f722d6b3231303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/db5d9f38068f602381e58f4fccded95816044d18053bdf27381f3b6131f90085/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f534541534b592d4d61737465722f596f6c6f2d666f722d6b3231303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SEASKY-Master/Yolo-for-k210?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo-for-k210.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TonyZ1Min/yolo-for-k210\"\u003eTonyZ1Min/yolo-for-k210\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cf41aaa6840e2781bd8a6b6d016c3fd6efe8785bafcfec128a4f844c7cf77d07/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f546f6e795a314d696e2f796f6c6f2d666f722d6b3231303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cf41aaa6840e2781bd8a6b6d016c3fd6efe8785bafcfec128a4f844c7cf77d07/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f546f6e795a314d696e2f796f6c6f2d666f722d6b3231303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TonyZ1Min/yolo-for-k210?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : keras-yolo-for-k210.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/vseasky/yolo-for-k210\"\u003evseasky/yolo-for-k210\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b2a81ca657f7d083760d9244b582bdf98f4b4ee9bba8d6e79775e6a4306cf497/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76736561736b792f796f6c6f2d666f722d6b3231303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b2a81ca657f7d083760d9244b582bdf98f4b4ee9bba8d6e79775e6a4306cf497/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76736561736b792f796f6c6f2d666f722d6b3231303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/vseasky/yolo-for-k210?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo-for-k210.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/InnoIPA/dpu-sc\"\u003eInnoIPA/dpu-sc\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2bd4df0e34d14bede104c4529198ff113a38d27f288f205e57fb4bc6ad338036/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e6e6f6970612f6470752d73633f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2bd4df0e34d14bede104c4529198ff113a38d27f288f205e57fb4bc6ad338036/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e6e6f6970612f6470752d73633f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/innoipa/dpu-sc?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : dpu-sc presented how to create quick demos to run AI inference(YOLOv4-Tiny, LPRNet) on DPU with MPSoC.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/InnoIPA/vaiGo\"\u003eInnoIPA/vaiGO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7c2dbaa1f1eafc570d8a4c0ab48354e16372d52347672706da4ba7d0c95584e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e6e6f6970612f766169474f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7c2dbaa1f1eafc570d8a4c0ab48354e16372d52347672706da4ba7d0c95584e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e6e6f6970612f766169474f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/innoipa/vaiGO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : vaiGO means Vitis-ai GO. We provide utility and tutorial that make it easy to convert a trained AI model into a bitstream that can be deployed on an FPGA Edge AI Box.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/InnoIPA/EXMU-X261-usermanual\"\u003eInnoIPA/EXMU-X261-usermanual\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b43e4cba45f22afa6075d1c8a4264c339985290eb938501cdfb6b728fb60b4db/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e6e6f6970612f65786d752d783236312d757365726d616e75616c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b43e4cba45f22afa6075d1c8a4264c339985290eb938501cdfb6b728fb60b4db/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e6e6f6970612f65786d752d783236312d757365726d616e75616c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/innoipa/exmu-x261-usermanual?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : We have built more defect detection solutions with YOLOv4-tiny on EXMU-X261.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOther Hardware\u003c/h5\u003e\u003ca id=\"user-content-other-hardware\" class=\"anchor\" aria-label=\"Permalink: Other Hardware\" href=\"#other-hardware\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/guichristmann/edge-tpu-tiny-yolo\"\u003eguichristmann/edge-tpu-tiny-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/efa3777710bb38efb87ce2be8b9c2f436fabaa9ee07abe1c6dae9d833c543e54/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6775696368726973746d616e6e2f656467652d7470752d74696e792d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/efa3777710bb38efb87ce2be8b9c2f436fabaa9ee07abe1c6dae9d833c543e54/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6775696368726973746d616e6e2f656467652d7470752d74696e792d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/guichristmann/edge-tpu-tiny-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Run Tiny YOLO-v3 on Google's Edge TPU USB Accelerator.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Charlie839242/-Trash-Classification-Car\"\u003eCharlie839242/-Trash-Classification-Car\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9d5a493de72f4220195559763acc69b80f191632b9ecf5fc29aa06037854faef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436861726c69653833393234322f2d54726173682d436c617373696669636174696f6e2d4361723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9d5a493de72f4220195559763acc69b80f191632b9ecf5fc29aa06037854faef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436861726c69653833393234322f2d54726173682d436c617373696669636174696f6e2d4361723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Charlie839242/-Trash-Classification-Car?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 这是一个基于yolo-fastest模型的小车，主控是art-pi开发板，使用了rt thread操作系统。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Charlie839242/Deploy-yolo-fastest-tflite-on-raspberry\"\u003eCharlie839242/Deploy-yolo-fastest-tflite-on-raspberry\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/52f26d4b3aa359569c10a4a0ad8f774664dd4dd9a2e5771173e1c457c0293667/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436861726c69653833393234322f4465706c6f792d796f6c6f2d666173746573742d74666c6974652d6f6e2d7261737062657272793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/52f26d4b3aa359569c10a4a0ad8f774664dd4dd9a2e5771173e1c457c0293667/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436861726c69653833393234322f4465706c6f792d796f6c6f2d666173746573742d74666c6974652d6f6e2d7261737062657272793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Charlie839242/Deploy-yolo-fastest-tflite-on-raspberry?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This project deploys a yolo fastest model in the form of tflite on raspberry 3b+.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mahxn0/Hisi3559A_Yolov5\"\u003emahxn0/Hisi3559A_Yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5dfab46b375c7aea8e7802af9b960d537191b5115479948849ce0b59e9b930f7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6168786e302f4869736933353539415f596f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5dfab46b375c7aea8e7802af9b960d537191b5115479948849ce0b59e9b930f7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6168786e302f4869736933353539415f596f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mahxn0/Hisi3559A_Yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于hisi3559a的yolov5训练部署全流程。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZhenxinYUAN/YOLO_hi3516Deploy\"\u003eZhenxinYUAN/YOLO_hi3516Deploy\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/181831c669692586726b833cbb803eb65842e4f4e1af56d8dc01eee7d67ff95e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68656e78696e5955414e2f594f4c4f5f6869333531364465706c6f793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/181831c669692586726b833cbb803eb65842e4f4e1af56d8dc01eee7d67ff95e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68656e78696e5955414e2f594f4c4f5f6869333531364465706c6f793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZhenxinYUAN/YOLO_hi3516Deploy?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Deploy Yolo series algorithms on Hisilicon platform hi3516, including yolov3, yolov5, yolox, etc.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jveitchmichaelis/edgetpu-yolo\"\u003ejveitchmichaelis/edgetpu-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d50e3882a1a786d9728ec69f86057d6f2b40451a8f3b96403f8b7c22ea8ae622/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a7665697463686d69636861656c69732f656467657470752d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d50e3882a1a786d9728ec69f86057d6f2b40451a8f3b96403f8b7c22ea8ae622/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a7665697463686d69636861656c69732f656467657470752d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jveitchmichaelis/edgetpu-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Minimal-dependency Yolov5 export and inference demonstration for the Google Coral EdgeTPU.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xiaqing10/Hisi_YoLoV5\"\u003exiaqing10/Hisi_YoLoV5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/96e6349577d188b8d65229f84ab7e8cb9cd41ea0a1c7b80a21fe13a0a2083115/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78696171696e6731302f486973695f596f4c6f56353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/96e6349577d188b8d65229f84ab7e8cb9cd41ea0a1c7b80a21fe13a0a2083115/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78696171696e6731302f486973695f596f4c6f56353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xiaqing10/Hisi_YoLoV5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 海思nnie跑yolov5。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BaronLeeLZP/hi3516dv300_nnie-yolov3-demo\"\u003eBaronLeeLZP/hi3516dv300_nnie-yolov3-demo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/387c424f009adc0397388d36250080046b4643640da7c9f00c05ef4df1d1636c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4261726f6e4c65654c5a502f68693335313664763330305f6e6e69652d796f6c6f76332d64656d6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/387c424f009adc0397388d36250080046b4643640da7c9f00c05ef4df1d1636c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4261726f6e4c65654c5a502f68693335313664763330305f6e6e69652d796f6c6f76332d64656d6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BaronLeeLZP/hi3516dv300_nnie-yolov3-demo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 在海思Hisilicon的Hi3516dv300芯片上，利用nnie和opencv库，简洁了官方yolov3用例中各种复杂的嵌套调用/复杂编译，提供了交叉编译后可成功上板部署运行的demo。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/OpenVINO-dev-contest/YOLOv7_OpenVINO\"\u003eOpenVINO-dev-contest/YOLOv7_OpenVINO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/39563e830c4e0564f74a379e4333afc9a894e3ad978371587893ae5ba11d614c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f70656e56494e4f2d6465762d636f6e746573742f594f4c4f76375f4f70656e56494e4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/39563e830c4e0564f74a379e4333afc9a894e3ad978371587893ae5ba11d614c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f70656e56494e4f2d6465762d636f6e746573742f594f4c4f76375f4f70656e56494e4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/OpenVINO-dev-contest/YOLOv7_OpenVINO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository will demostrate how to deploy a offical YOLOv7 pre-trained model with OpenVINO runtime api.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/littledeep/YOLOv5-RK3399Pro\"\u003elittledeep/YOLOv5-RK3399Pro\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6041cbcf1f1cc328a38e497b1f181f64a2a9ecaa3cbe959bd713f06301a6bad8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6974746c65646565702f594f4c4f76352d524b3333393950726f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6041cbcf1f1cc328a38e497b1f181f64a2a9ecaa3cbe959bd713f06301a6bad8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6974746c65646565702f594f4c4f76352d524b3333393950726f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/littledeep/YOLOv5-RK3399Pro?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PyTorch--\u0026gt;ONNX--\u0026gt;RKNN.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jnulzl/YOLOV5_RK1126\"\u003ejnulzl/YOLOV5_RK1126\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cdbd0d4adb78e2f80b5cc9c3cecd6cb0055b4b207bf0419ad38adbba4b373f9e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a6e756c7a6c2f594f4c4f56355f524b313132363f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cdbd0d4adb78e2f80b5cc9c3cecd6cb0055b4b207bf0419ad38adbba4b373f9e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a6e756c7a6c2f594f4c4f56355f524b313132363f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jnulzl/YOLOV5_RK1126?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5 rk1126 cpp code.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qengineering/YoloCam\"\u003eQengineering/YoloCam\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b04463f0a9e4991031f990a1e4274c64c4754ee1872cc27480f28ce8fdf40f85/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f43616d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b04463f0a9e4991031f990a1e4274c64c4754ee1872cc27480f28ce8fdf40f85/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51656e67696e656572696e672f596f6c6f43616d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qengineering/YoloCam?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : AI camera with live feed, email notification, Gdrive storage and event-triggered GPIO. Raspberry Pi stand-alone AI-powered camera with live feed, email notification and event-triggered cloud storage.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LSH9832/edgeyolo\"\u003eLSH9832/edgeyolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/71bfe61077c58d0fa253ac07bd7e94e96e3eb3b1b3c7e62400b70a761da7664b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5348393833322f65646765796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/71bfe61077c58d0fa253ac07bd7e94e96e3eb3b1b3c7e62400b70a761da7664b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5348393833322f65646765796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LSH9832/edgeyolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : an edge-real-time anchor-free object detector with decent performance.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/liuyuan000/Rv1126_YOLOv5-Lite\"\u003eliuyuan000/Rv1126_YOLOv5-Lite\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/94588fb5930eed5deb0294ec3807faa87969028fdbd24fd94d38e76bf34fd1eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c69757975616e3030302f5276313132365f594f4c4f76352d4c6974653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/94588fb5930eed5deb0294ec3807faa87969028fdbd24fd94d38e76bf34fd1eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c69757975616e3030302f5276313132365f594f4c4f76352d4c6974653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/liuyuan000/Rv1126_YOLOv5-Lite?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5-Lite在Rv1126部署。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003ePruning Knoweldge-Distillation Quantization\u003c/h3\u003e\u003ca id=\"user-content-pruning-knoweldge-distillation-quantization\" class=\"anchor\" aria-label=\"Permalink: Pruning Knoweldge-Distillation Quantization\" href=\"#pruning-knoweldge-distillation-quantization\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003ePruning\u003c/h5\u003e\u003ca id=\"user-content-pruning\" class=\"anchor\" aria-label=\"Permalink: Pruning\" href=\"#pruning\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch6 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e剪枝\u003c/h6\u003e\u003ca id=\"user-content-剪枝\" class=\"anchor\" aria-label=\"Permalink: 剪枝\" href=\"#剪枝\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/VainF/Torch-Pruning\"\u003eTorch-Pruning\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/26313a3ae281feb15c55af3831ca95e4e815b16300f8f52dcf9cc7b6bfe34ccd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5661696e462f546f7263682d5072756e696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/26313a3ae281feb15c55af3831ca95e4e815b16300f8f52dcf9cc7b6bfe34ccd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5661696e462f546f7263682d5072756e696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/VainF/Torch-Pruning?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Towards Any Structural Pruning; LLMs / SAM / Diffusion / Transformers / YOLOv8 / CNNs. \"Towards Any Structural Pruning\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2023/html/Fang_DepGraph_Towards_Any_Structural_Pruning_CVPR_2023_paper.html\" rel=\"nofollow\"\u003eCVPR 2023\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/neuralmagic/sparseml\"\u003eSparseML\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5d22918f22530481a41d0f7a9554e6a0e3d23dbbfdd76c8a1ca6fa9ea1f8aa1c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e657572616c6d616769632f7370617273656d6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5d22918f22530481a41d0f7a9554e6a0e3d23dbbfdd76c8a1ca6fa9ea1f8aa1c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e657572616c6d616769632f7370617273656d6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/neuralmagic/sparseml?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Libraries for applying sparsification recipes to neural networks with a few lines of code, enabling faster and smaller models. \"Inducing and Exploiting Activation Sparsity for Fast Inference on Deep Neural Networks\". (\u003cstrong\u003e\u003ca href=\"http://proceedings.mlr.press/v119/kurtz20a.html\" rel=\"nofollow\"\u003ePMLR 2020\u003c/a\u003e\u003c/strong\u003e). \"Woodfisher: Efficient second-order approximation for neural network compression\". (\u003cstrong\u003e\u003ca href=\"https://proceedings.neurips.cc/paper/2020/hash/d1ff1ec86b62cd5f3903ff19c3a326b2-Abstract.html\" rel=\"nofollow\"\u003eNeurIPS 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/neuralmagic/sparsezoo\"\u003eSparseZoo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0569a447a00a2ae81db6e5cf5268e6b961cf9d651a8b031020b9b131c16ccfc8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e657572616c6d616769632f7370617273657a6f6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0569a447a00a2ae81db6e5cf5268e6b961cf9d651a8b031020b9b131c16ccfc8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e657572616c6d616769632f7370617273657a6f6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/neuralmagic/sparsezoo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Neural network model repository for highly sparse and sparse-quantized models with matching sparsification recipes.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Gumpest/YOLOv5-Multibackbone-Compression\"\u003eGumpest/YOLOv5-Multibackbone-Compression\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/04710cf8e6cdbf63c0ae368af6561c7b847ebc43c77af004d38ec3a0906fcb8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f47756d706573742f594f4c4f76352d4d756c74696261636b626f6e652d436f6d7072657373696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/04710cf8e6cdbf63c0ae368af6561c7b847ebc43c77af004d38ec3a0906fcb8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f47756d706573742f594f4c4f76352d4d756c74696261636b626f6e652d436f6d7072657373696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Gumpest/YOLOv5-Multibackbone-Compression?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 Series Multi-backbone(TPH-YOLOv5, Ghostnet, ShuffleNetv2, Mobilenetv3Small, EfficientNetLite, PP-LCNet, SwinTransformer YOLO), Module(CBAM, DCN), Pruning (EagleEye, Network Slimming) and Quantization (MQBench) Compression Tool Box.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PengyiZhang/SlimYOLOv3\"\u003eSlimYOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/60f1be5d6eb3b7c85ee162255aa9e2da0d54b40f09dc485788f84ce211150617/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f50656e6779695a68616e672f536c696d594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/60f1be5d6eb3b7c85ee162255aa9e2da0d54b40f09dc485788f84ce211150617/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f50656e6779695a68616e672f536c696d594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PengyiZhang/SlimYOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"SlimYOLOv3: Narrower, Faster and Better for UAV Real-Time Applications\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1907.11093\" rel=\"nofollow\"\u003earXiv 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/uyzhang/yolov5_prune\"\u003euyzhang/yolov5_prune\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2bc43c70e9e490bb7714929e1fa7b867f7d772c799805776dda92c87a1888f4b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f75797a68616e672f796f6c6f76355f7072756e653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2bc43c70e9e490bb7714929e1fa7b867f7d772c799805776dda92c87a1888f4b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f75797a68616e672f796f6c6f76355f7072756e653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/uyzhang/yolov5_prune?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov5 pruning on COCO Dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/midasklr/yolov5prune\"\u003emidasklr/yolov5prune\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/106028c0821ae08c806ee81ae19c3a44127d7865a8647cb8bc6dad4fb78d8e37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696461736b6c722f796f6c6f76357072756e653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/106028c0821ae08c806ee81ae19c3a44127d7865a8647cb8bc6dad4fb78d8e37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696461736b6c722f796f6c6f76357072756e653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/midasklr/yolov5prune?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5模型剪枝。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZJU-lishuang/yolov5_prune\"\u003eZJU-lishuang/yolov5_prune\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3e77b29a43a54e55e855d0f7f599554fd74ec71ba1de723fe6ad537cbdb2037c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a4a552d6c69736875616e672f796f6c6f76355f7072756e653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3e77b29a43a54e55e855d0f7f599554fd74ec71ba1de723fe6ad537cbdb2037c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a4a552d6c69736875616e672f796f6c6f76355f7072756e653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZJU-lishuang/yolov5_prune?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5 prune，Support V2, V3, V4 and V6 versions of yolov5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sbbug/yolov5-prune-multi\"\u003esbbug/yolov5-prune-multi\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fdc36aef5293e32de32beb1c725c90385b92bb8aa551a9d7f9f6a993a2fb2776/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73626275672f796f6c6f76352d7072756e652d6d756c74693f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fdc36aef5293e32de32beb1c725c90385b92bb8aa551a9d7f9f6a993a2fb2776/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73626275672f796f6c6f76352d7072756e652d6d756c74693f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sbbug/yolov5-prune-multi?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5-prune-multi 无人机视角、多模态、模型剪枝、国产AI芯片部署。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Syencil/mobile-yolov5-pruning-distillation\"\u003eSyencil/mobile-yolov5-pruning-distillation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b9c889b2d1a7be771d63520941900575d216b46e622b5e5f09ce30d99f276059/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5379656e63696c2f6d6f62696c652d796f6c6f76352d7072756e696e672d64697374696c6c6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b9c889b2d1a7be771d63520941900575d216b46e622b5e5f09ce30d99f276059/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5379656e63696c2f6d6f62696c652d796f6c6f76352d7072756e696e672d64697374696c6c6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Syencil/mobile-yolov5-pruning-distillation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : mobilev2-yolov5s剪枝、蒸馏，支持ncnn，tensorRT部署。ultra-light but better performence！\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Lam1360/YOLOv3-model-pruning\"\u003eLam1360/YOLOv3-model-pruning\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/adab704eefaf5d12126e6be51a92cf853cc859b452670ce1c3fde422cc9ebd0b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c616d313336302f594f4c4f76332d6d6f64656c2d7072756e696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/adab704eefaf5d12126e6be51a92cf853cc859b452670ce1c3fde422cc9ebd0b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c616d313336302f594f4c4f76332d6d6f64656c2d7072756e696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Lam1360/YOLOv3-model-pruning?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 在 oxford hand 数据集上对 YOLOv3 做模型剪枝（network slimming）。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tanluren/yolov3-channel-and-layer-pruning\"\u003etanluren/yolov3-channel-and-layer-pruning\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e524d748e4584e86cfa9021117c669415dfd55a815f5da09d52d31b4a977c664/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616e6c7572656e2f796f6c6f76332d6368616e6e656c2d616e642d6c617965722d7072756e696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e524d748e4584e86cfa9021117c669415dfd55a815f5da09d52d31b4a977c664/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616e6c7572656e2f796f6c6f76332d6368616e6e656c2d616e642d6c617965722d7072756e696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tanluren/yolov3-channel-and-layer-pruning?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov3 yolov4 channel and layer pruning, Knowledge Distillation 层剪枝，通道剪枝，知识蒸馏。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/coldlarry/YOLOv3-complete-pruning\"\u003ecoldlarry/YOLOv3-complete-pruning\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c88376ed6e4b7d58bccd269446a48fbcfe6614b80d624e48624565565583aea6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636f6c646c617272792f594f4c4f76332d636f6d706c6574652d7072756e696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c88376ed6e4b7d58bccd269446a48fbcfe6614b80d624e48624565565583aea6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636f6c646c617272792f594f4c4f76332d636f6d706c6574652d7072756e696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/coldlarry/YOLOv3-complete-pruning?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 提供对YOLOv3及Tiny的多种剪枝版本，以适应不同的需求。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SpursLipu/YOLOv3v4-ModelCompression-MultidatasetTraining-Multibackbone\"\u003eSpursLipu/YOLOv3v4-ModelCompression-MultidatasetTraining-Multibackbone\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fc3ea6513f9e95a4e9df262ed07ef43157f00af1b7d06336e81aa89a12572a52/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53707572734c6970752f594f4c4f763376342d4d6f64656c436f6d7072657373696f6e2d4d756c746964617461736574547261696e696e672d4d756c74696261636b626f6e653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fc3ea6513f9e95a4e9df262ed07ef43157f00af1b7d06336e81aa89a12572a52/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53707572734c6970752f594f4c4f763376342d4d6f64656c436f6d7072657373696f6e2d4d756c746964617461736574547261696e696e672d4d756c74696261636b626f6e653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SpursLipu/YOLOv3v4-ModelCompression-MultidatasetTraining-Multibackbone?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO ModelCompression MultidatasetTraining.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/talebolano/yolov3-network-slimming\"\u003etalebolano/yolov3-network-slimming\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c040e023bec22cadbfb6fe2e3f24500e8a27ebd231e2e16860d65559532613ce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616c65626f6c616e6f2f796f6c6f76332d6e6574776f726b2d736c696d6d696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c040e023bec22cadbfb6fe2e3f24500e8a27ebd231e2e16860d65559532613ce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616c65626f6c616e6f2f796f6c6f76332d6e6574776f726b2d736c696d6d696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/talebolano/yolov3-network-slimming?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov3 network slimming剪枝的一种实现。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Bigtuo/YOLOX-Lite\"\u003eBigtuo/YOLOX-Lite\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7d74cb970e82c96e7157ba474b389b1c859e0f69b910ad8305fc25d5a88ce6e1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42696774756f2f594f4c4f582d4c6974653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7d74cb970e82c96e7157ba474b389b1c859e0f69b910ad8305fc25d5a88ce6e1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42696774756f2f594f4c4f582d4c6974653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Bigtuo/YOLOX-Lite?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 将YOLOv5-Lite代码中的head更换为YOLOX head。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/YINYIPENG-EN/Pruning_for_YOLOV5_pytorch\"\u003eYINYIPENG-EN/Pruning_for_YOLOV5_pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/00fab67dce2cbcacea577e5852f02db8eb0d86c74f494614f02aecac075df191/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59494e594950454e472d454e2f5072756e696e675f666f725f594f4c4f56355f7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/00fab67dce2cbcacea577e5852f02db8eb0d86c74f494614f02aecac075df191/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59494e594950454e472d454e2f5072756e696e675f666f725f594f4c4f56355f7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/YINYIPENG-EN/Pruning_for_YOLOV5_pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Pruning_for_YOLOV5_pytorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/chumingqian/Model_Compression_For_YOLOV3-V4\"\u003echumingqian/Model_Compression_For_YOLOV3-V4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a92f7de1f7ffce5256b74530ab268db7dcddd760f06d8f52907d7f143a646a7b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368756d696e677169616e2f4d6f64656c5f436f6d7072657373696f6e5f466f725f594f4c4f56332d56343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a92f7de1f7ffce5256b74530ab268db7dcddd760f06d8f52907d7f143a646a7b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368756d696e677169616e2f4d6f64656c5f436f6d7072657373696f6e5f466f725f594f4c4f56332d56343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/chumingqian/Model_Compression_For_YOLOV3-V4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : In this repository using the dynamic sparse training( variable sparse rate s which can speed up the sparse training process), channel pruning and knowledge distilling for YOLOV3 and YOLOV4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xhwNobody/yolov5_prune_sfp\"\u003exhwNobody/yolov5_prune_sfp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/408edb28d9c15a203f951733ceb9eb372e1d48676613e1b76176e92c4a57d949/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7868774e6f626f64792f796f6c6f76355f7072756e655f7366703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/408edb28d9c15a203f951733ceb9eb372e1d48676613e1b76176e92c4a57d949/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7868774e6f626f64792f796f6c6f76355f7072756e655f7366703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xhwNobody/yolov5_prune_sfp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于SFP和FPGM的yolov5的软剪枝实现。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eQuantization\u003c/h5\u003e\u003ca id=\"user-content-quantization\" class=\"anchor\" aria-label=\"Permalink: Quantization\" href=\"#quantization\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch6 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e量化\u003c/h6\u003e\u003ca id=\"user-content-量化\" class=\"anchor\" aria-label=\"Permalink: 量化\" href=\"#量化\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dog-qiuqiu/FastestDet\"\u003edog-qiuqiu/FastestDet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/53f603509725d740b5bddfcecc71a9b3195d0747d56418f449d98457c60df25d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f672d7169757169752f466173746573744465743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/53f603509725d740b5bddfcecc71a9b3195d0747d56418f449d98457c60df25d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f672d7169757169752f466173746573744465743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dog-qiuqiu/FastestDet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ⚡ A newly designed ultra lightweight anchor free target detection algorithm， weight only 250K parameters， reduces the time consumption by 10% compared with yolo-fastest, and the post-processing is simpler. \"知乎「马雪浩」《\u003ca href=\"https://zhuanlan.zhihu.com/p/536500269\" rel=\"nofollow\"\u003eFastestDet: 比yolo-fastest更快！更强！更简单！全新设计的超实时Anchor-free目标检测算法\u003c/a\u003e》\"。 \"微信公众号「计算机视觉研究院」《\u003ca href=\"https://mp.weixin.qq.com/s/Bskc5WQd8ujy16Jl4qekjQ\" rel=\"nofollow\"\u003eFastestDet：比yolov5更快！更强！全新设计的超实时Anchor-free目标检测算法（附源代码下载）\u003c/a\u003e》\"。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dog-qiuqiu/Yolo-Fastest\"\u003edog-qiuqiu/Yolo-Fastest\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7e83a9551c56e26ead9bca9a8358587750c98f2398466b9b09a02a09c8afb800/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f672d7169757169752f596f6c6f2d466173746573743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7e83a9551c56e26ead9bca9a8358587750c98f2398466b9b09a02a09c8afb800/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f672d7169757169752f596f6c6f2d466173746573743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dog-qiuqiu/Yolo-Fastest?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo-Fastest：超超超快的开源ARM实时目标检测算法。 \u003ca href=\"http://doi.org/10.5281/zenodo.5131532\" rel=\"nofollow\"\u003eZenodo 2021\u003c/a\u003e. \"知乎「马雪浩」《\u003ca href=\"https://zhuanlan.zhihu.com/p/234506503\" rel=\"nofollow\"\u003eYolo-Fastest：超超超快的开源ARM实时目标检测算法\u003c/a\u003e》\"。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dog-qiuqiu/Yolo-FastestV2\"\u003edog-qiuqiu/Yolo-FastestV2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4b0ff101ff8457436ab8bc45e422f7fd467e968a956376c5f0364c0042f9fe38/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f672d7169757169752f596f6c6f2d4661737465737456323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4b0ff101ff8457436ab8bc45e422f7fd467e968a956376c5f0364c0042f9fe38/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f672d7169757169752f596f6c6f2d4661737465737456323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dog-qiuqiu/Yolo-FastestV2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo-FastestV2:更快，更轻，移动端可达300FPS，参数量仅250k。 \"知乎「马雪浩」《\u003ca href=\"https://zhuanlan.zhihu.com/p/400474142\" rel=\"nofollow\"\u003eYolo-FastestV2:更快，更轻，移动端可达300FPS，参数量仅250k\u003c/a\u003e》\"。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nightsnack/YOLObile\"\u003eYOLObile\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/867866669c1fa1a72547c272bd96b4d1083bf0a84fe75e855118ead5d60b2bd5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e69676874736e61636b2f594f4c4f62696c653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/867866669c1fa1a72547c272bd96b4d1083bf0a84fe75e855118ead5d60b2bd5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e69676874736e61636b2f594f4c4f62696c653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nightsnack/YOLObile?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLObile: Real-Time Object Detection on Mobile Devices via Compression-Compilation Co-Design\". (\u003cstrong\u003e\u003ca href=\"https://www.aaai.org/AAAI21Papers/AAAI-7561.CaiY.pdf\" rel=\"nofollow\"\u003eAAAI 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PaddlePaddle/PaddleSlim\"\u003ePaddleSlim\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/50e1dc85cbb577e409532041fb7724eb255d21186318b9ccf63e37b82ee9d9d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506164646c65506164646c652f506164646c65536c696d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/50e1dc85cbb577e409532041fb7724eb255d21186318b9ccf63e37b82ee9d9d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506164646c65506164646c652f506164646c65536c696d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PaddlePaddle/PaddleSlim?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PaddleSlim is an open-source library for deep model compression and architecture search. PaddleSlim是一个专注于深度学习模型压缩的工具库，提供低比特量化、知识蒸馏、稀疏化和模型结构搜索等模型压缩策略，帮助用户快速实现模型的小型化。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/openppl-public/ppq\"\u003ePPL量化工具\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/595ea2f61dc569ac82b26d2f88e4fbdd4bfb4cb76977bf2d2903f75c8e16744d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e70706c2d7075626c69632f7070713f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/595ea2f61dc569ac82b26d2f88e4fbdd4bfb4cb76977bf2d2903f75c8e16744d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e70706c2d7075626c69632f7070713f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/openppl-public/ppq?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PPL Quantization Tool (PPQ) is a powerful offline neural network quantization tool. PPL QuantTool 是一个高效的工业级神经网络量化工具。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PINTO0309/PINTO_model_zoo\"\u003ePINTO_model_zoo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a07bbba10382a37793334c5ef7e0bd772fa44a34bf98307a494c8713e820770f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f50494e544f303330392f50494e544f5f6d6f64656c5f7a6f6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a07bbba10382a37793334c5ef7e0bd772fa44a34bf98307a494c8713e820770f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f50494e544f303330392f50494e544f5f6d6f64656c5f7a6f6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PINTO0309/PINTO_model_zoo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A repository for storing models that have been inter-converted between various frameworks. Supported frameworks are TensorFlow, PyTorch, ONNX, OpenVINO, TFJS, TFTRT, TensorFlowLite (Float32/16/INT8), EdgeTPU, CoreML.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ppogg/YOLOv5-Lite\"\u003eppogg/YOLOv5-Lite\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/810011f170f0e6bfd755f8cd0912178ae5422cf71aa5dcf3364ccddf3033b541/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70706f67672f594f4c4f76352d4c6974653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/810011f170f0e6bfd755f8cd0912178ae5422cf71aa5dcf3364ccddf3033b541/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70706f67672f594f4c4f76352d4c6974653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ppogg/YOLOv5-Lite?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🍅🍅🍅YOLOv5-Lite: lighter, faster and easier to deploy. Evolved from yolov5 and the size of model is only 930+kb (int8) and 1.7M (fp16). It can reach 10+ FPS on the Raspberry Pi 4B when the input size is 320×320~\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlexeyAB/yolo2_light\"\u003eAlexeyAB/yolo2_light\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f390aefef82d381043eed0ef21785c38158335acf13cb84f9809daf987d705a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f796f6c6f325f6c696768743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f390aefef82d381043eed0ef21785c38158335acf13cb84f9809daf987d705a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f796f6c6f325f6c696768743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlexeyAB/yolo2_light?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Light version of convolutional neural network Yolo v3 \u0026amp; v2 for objects detection with a minimum of dependencies (INT8-inference, BIT1-XNOR-inference).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eKnoweldge-Distillation\u003c/h5\u003e\u003ca id=\"user-content-knoweldge-distillation\" class=\"anchor\" aria-label=\"Permalink: Knoweldge-Distillation\" href=\"#knoweldge-distillation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch6 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e知识蒸馏\u003c/h6\u003e\u003ca id=\"user-content-知识蒸馏\" class=\"anchor\" aria-label=\"Permalink: 知识蒸馏\" href=\"#知识蒸馏\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yoshitomo-matsubara/torchdistill\"\u003etorchdistill\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5b5846f149878674f9c644a2257422625e0ec1de4c9ff0d40387323a3cb3cb07/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796f736869746f6d6f2d6d61747375626172612f746f72636864697374696c6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5b5846f149878674f9c644a2257422625e0ec1de4c9ff0d40387323a3cb3cb07/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796f736869746f6d6f2d6d61747375626172612f746f72636864697374696c6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yoshitomo-matsubara/torchdistill?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : torchdistill: A Modular, Configuration-Driven Framework for Knowledge Distillation. A coding-free framework built on PyTorch for reproducible deep learning studies. 🏆20 knowledge distillation methods presented at CVPR, ICLR, ECCV, NeurIPS, ICCV, etc are implemented so far. 🎁 Trained models, training logs and configurations are available for ensuring the reproducibiliy and benchmark.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wonbeomjang/yolov5-knowledge-distillation\"\u003ewonbeomjang/yolov5-knowledge-distillation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/beeb3670caaa59c35563e76d082f96fa4b2fa47e952052f475f732a9b66fe269/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776f6e62656f6d6a616e672f796f6c6f76352d6b6e6f776c656467652d64697374696c6c6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/beeb3670caaa59c35563e76d082f96fa4b2fa47e952052f475f732a9b66fe269/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776f6e62656f6d6a616e672f796f6c6f76352d6b6e6f776c656467652d64697374696c6c6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wonbeomjang/yolov5-knowledge-distillation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : implementation of \u003ca href=\"https://github.com/twangnh/Distilling-Object-Detectors\"\u003eDistilling Object Detectors with Fine-grained Feature Imitation\u003c/a\u003e on yolov5. \"Distilling Object Detectors with Fine-grained Feature Imitation\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Distilling_Object_Detectors_With_Fine-Grained_Feature_Imitation_CVPR_2019_paper.html\" rel=\"nofollow\"\u003eCVPR 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Sharpiless/Yolov5-distillation-train-inference\"\u003eSharpiless/Yolov5-distillation-train-inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/de1d76e255ad6ecde1ccb5f8cdeb3d18144e73662b288e2976550d7eae0500d5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76352d64697374696c6c6174696f6e2d747261696e2d696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/de1d76e255ad6ecde1ccb5f8cdeb3d18144e73662b288e2976550d7eae0500d5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76352d64697374696c6c6174696f6e2d747261696e2d696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Sharpiless/Yolov5-distillation-train-inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov5 distillation training | Yolov5知识蒸馏训练，支持训练自己的数据。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Sharpiless/yolov5-distillation-5.0\"\u003eSharpiless/yolov5-distillation-5.0\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4aa5226cf817d0a2dff9f0e8b3a27a11cf6509fd828504735506e0350baff1f6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f796f6c6f76352d64697374696c6c6174696f6e2d352e303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4aa5226cf817d0a2dff9f0e8b3a27a11cf6509fd828504735506e0350baff1f6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f796f6c6f76352d64697374696c6c6174696f6e2d352e303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Sharpiless/yolov5-distillation-5.0?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5 5.0 version distillation || yolov5 5.0版本知识蒸馏，yolov5l \u0026gt;\u0026gt; yolov5s。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Sharpiless/yolov5-knowledge-distillation\"\u003eSharpiless/yolov5-knowledge-distillation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/717fc578c3953101bdb27a1381134602bbeb77574906b54d0aafe9193086e21d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f796f6c6f76352d6b6e6f776c656467652d64697374696c6c6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/717fc578c3953101bdb27a1381134602bbeb77574906b54d0aafe9193086e21d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f796f6c6f76352d6b6e6f776c656467652d64697374696c6c6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Sharpiless/yolov5-knowledge-distillation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5目标检测模型的知识蒸馏（基于响应的蒸馏）。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/chengpanghu/Knowledge-Distillation-yolov5\"\u003echengpanghu/Knowledge-Distillation-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1d65cdf969ee884c5fa568b477bbff223af2de7878f96d9b8834bf49ed6afd22/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368656e6770616e6768752f4b6e6f776c656467652d44697374696c6c6174696f6e2d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1d65cdf969ee884c5fa568b477bbff223af2de7878f96d9b8834bf49ed6afd22/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368656e6770616e6768752f4b6e6f776c656467652d44697374696c6c6174696f6e2d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/chengpanghu/Knowledge-Distillation-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Knowledge-Distillation-yolov5 基于yolov5的知识蒸馏。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/magicshuang/yolov5_distillation\"\u003emagicshuang/yolov5_distillation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/781285810e9cd348d53c3c5168c8ca0997a30a093a9099a5b291ef6c2fcbed07/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61676963736875616e672f796f6c6f76355f64697374696c6c6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/781285810e9cd348d53c3c5168c8ca0997a30a093a9099a5b291ef6c2fcbed07/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61676963736875616e672f796f6c6f76355f64697374696c6c6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/magicshuang/yolov5_distillation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5 知识蒸馏，yolov5-l模型压缩至yolov5-s 压缩算法是 \u003ca href=\"https://github.com/twangnh/Distilling-Object-Detectors\"\u003eDistilling Object Detectors with Fine-grained Feature Imitation\u003c/a\u003e。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Sharpiless/Yolov3-MobileNet-Distillation\"\u003eSharpiless/Yolov3-MobileNet-Distillation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/599629a4733ff83bb060c15d165bbf6d5aebb8549bb60498c76a3841a77ad086/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76332d4d6f62696c654e65742d44697374696c6c6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/599629a4733ff83bb060c15d165bbf6d5aebb8549bb60498c76a3841a77ad086/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76332d4d6f62696c654e65742d44697374696c6c6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Sharpiless/Yolov3-MobileNet-Distillation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 在Yolov3-MobileNet上进行模型蒸馏训练。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SsisyphusTao/Object-Detection-Knowledge-Distillation\"\u003eSsisyphusTao/Object-Detection-Knowledge-Distillation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a2e33e15723a8af896a4a072998b69fc1e7be3b9c244b82f95980574d57d2bd7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53736973797068757354616f2f4f626a6563742d446574656374696f6e2d4b6e6f776c656467652d44697374696c6c6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a2e33e15723a8af896a4a072998b69fc1e7be3b9c244b82f95980574d57d2bd7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53736973797068757354616f2f4f626a6563742d446574656374696f6e2d4b6e6f776c656467652d44697374696c6c6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SsisyphusTao/Object-Detection-Knowledge-Distillation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An Object Detection Knowledge Distillation framework powered by pytorch, now having SSD and yolov5.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eLightweight Backbones and FPN\u003c/h3\u003e\u003ca id=\"user-content-lightweight-backbones-and-fpn\" class=\"anchor\" aria-label=\"Permalink: Lightweight Backbones and FPN\" href=\"#lightweight-backbones-and-fpn\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e轻量级骨干网络和特征金字塔网络\u003c/h4\u003e\u003ca id=\"user-content-轻量级骨干网络和特征金字塔网络\" class=\"anchor\" aria-label=\"Permalink: 轻量级骨干网络和特征金字塔网络\" href=\"#轻量级骨干网络和特征金字塔网络\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/murufeng/awesome_lightweight_networks\"\u003emurufeng/awesome_lightweight_networks\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/42b4a396a81640b052d774b0786f60802012712a742d0870a2b670d41f26d0bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d75727566656e672f617765736f6d655f6c696768747765696768745f6e6574776f726b733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/42b4a396a81640b052d774b0786f60802012712a742d0870a2b670d41f26d0bd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d75727566656e672f617765736f6d655f6c696768747765696768745f6e6574776f726b733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/murufeng/awesome_lightweight_networks?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The implementation of various lightweight networks by using PyTorch. such as：MobileNetV2，MobileNeXt，GhostNet，ParNet，MobileViT、AdderNet，ShuffleNetV1-V2，LCNet，ConvNeXt，etc. ⭐⭐⭐⭐⭐\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Bobo-y/flexible-yolov5\"\u003eBobo-y/flexible-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fde02dadf059148334f69cec7d7b9b6676fa9e2b3960adfc66fbcb7f7a58f1ec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f626f2d792f666c657869626c652d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fde02dadf059148334f69cec7d7b9b6676fa9e2b3960adfc66fbcb7f7a58f1ec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f626f2d792f666c657869626c652d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Bobo-y/flexible-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : More readable and flexible yolov5 with more backbone(resnet, shufflenet, moblienet, efficientnet, hrnet, swin-transformer) and (cbam，dcn and so on), and tensorrt.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/XingZeng307/YOLOv5_with_BiFPN\"\u003eXingZeng307/YOLOv5_with_BiFPN\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/70ad03a07b43ac9f545087306ff63dadc9e076282313f4af07944f1e302dac8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f58696e675a656e673330372f594f4c4f76355f776974685f426946504e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/70ad03a07b43ac9f545087306ff63dadc9e076282313f4af07944f1e302dac8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f58696e675a656e673330372f594f4c4f76355f776974685f426946504e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/XingZeng307/YOLOv5_with_BiFPN?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repo is mainly for replacing PANet with BiFPN in YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dog-qiuqiu/MobileNet-Yolo\"\u003edog-qiuqiu/MobileNet-Yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6ab014d426fbf9d3c657e76bd24f2ca51bf73248649cd4251ff02e2010e32ad8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f672d7169757169752f4d6f62696c654e65742d596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6ab014d426fbf9d3c657e76bd24f2ca51bf73248649cd4251ff02e2010e32ad8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f672d7169757169752f4d6f62696c654e65742d596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dog-qiuqiu/MobileNet-Yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : MobileNetV2-YoloV3-Nano: 0.5BFlops 3MB HUAWEI P40: 6ms/img, YoloFace-500k:0.1Bflops 420KB🔥🔥🔥.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/eric612/MobileNet-YOLO\"\u003eeric612/MobileNet-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5e8bd9cb86f0aaf1f477ea7791832f5759110c16103b59847e85641daca5138c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657269633631322f4d6f62696c654e65742d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5e8bd9cb86f0aaf1f477ea7791832f5759110c16103b59847e85641daca5138c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657269633631322f4d6f62696c654e65742d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/eric612/MobileNet-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A caffe implementation of MobileNet-YOLO detection network.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/eric612/Mobilenet-YOLO-Pytorch\"\u003eeric612/Mobilenet-YOLO-Pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/962a8376b4dc7598d16a6c50b234e07c2bdfcecb72b953909ca135987fa33bc4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657269633631322f4d6f62696c656e65742d594f4c4f2d5079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/962a8376b4dc7598d16a6c50b234e07c2bdfcecb72b953909ca135987fa33bc4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657269633631322f4d6f62696c656e65742d594f4c4f2d5079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/eric612/Mobilenet-YOLO-Pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Include mobilenet series (v1,v2,v3...) and yolo series (yolov3,yolov4,...) .\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Adamdad/keras-YOLOv3-mobilenet\"\u003eAdamdad/keras-YOLOv3-mobilenet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f730e4f48532d4bb905c0e95825ac40a2ae934f69183d6c69a6ca0d296998413/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4164616d6461642f6b657261732d594f4c4f76332d6d6f62696c656e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f730e4f48532d4bb905c0e95825ac40a2ae934f69183d6c69a6ca0d296998413/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4164616d6461642f6b657261732d594f4c4f76332d6d6f62696c656e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Adamdad/keras-YOLOv3-mobilenet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Keras implementation of YOLOv3 (Tensorflow backend) inspired by \u003ca href=\"https://github.com/allanzelener/YAD2K\"\u003eallanzelener/YAD2K\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fsx950223/mobilenetv2-yolov3\"\u003efsx950223/mobilenetv2-yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a35ecc0d599d11b6c6ca08ce00feebae15ff70a4adf1c6f71b12ed4099d0fc37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6673783935303232332f6d6f62696c656e657476322d796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a35ecc0d599d11b6c6ca08ce00feebae15ff70a4adf1c6f71b12ed4099d0fc37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6673783935303232332f6d6f62696c656e657476322d796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/fsx950223/mobilenetv2-yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov3 with mobilenetv2 and efficientnet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/liux0614/yolo_nano\"\u003eliux0614/yolo_nano\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0cd3985c3a3d57a2d0f7703dc467dca412a23ed845da9ccec9c74bc78a46ed5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c697578303631342f796f6c6f5f6e616e6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0cd3985c3a3d57a2d0f7703dc467dca412a23ed845da9ccec9c74bc78a46ed5b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c697578303631342f796f6c6f5f6e616e6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/liux0614/yolo_nano?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Unofficial implementation of yolo nano.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lingtengqiu/Yolo_Nano\"\u003elingtengqiu/Yolo_Nano\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/486d6441b54fca785fb038bfd080ffe27b79de3ee18603247ed1b2ef0c82287e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c696e6774656e677169752f596f6c6f5f4e616e6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/486d6441b54fca785fb038bfd080ffe27b79de3ee18603247ed1b2ef0c82287e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c696e6774656e677169752f596f6c6f5f4e616e6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lingtengqiu/Yolo_Nano?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Pytorch implementation of yolo_Nano for pedestrian detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/mobilenet-yolov4-pytorch\"\u003ebubbliiiing/mobilenet-yolov4-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fce79962418fd5707a61f62bfb8ca03b2f7af1f827fb1cb3027b29b27152081e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f6d6f62696c656e65742d796f6c6f76342d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fce79962418fd5707a61f62bfb8ca03b2f7af1f827fb1cb3027b29b27152081e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f6d6f62696c656e65742d796f6c6f76342d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/mobilenet-yolov4-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 这是一个mobilenet-yolov4的库，把yolov4主干网络修改成了mobilenet，修改了Panet的卷积组成，使参数量大幅度缩小。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bubbliiiing/efficientnet-yolo3-pytorch\"\u003ebubbliiiing/efficientnet-yolo3-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/524f02a8e7f73a374007c6b8286968e910a5df8a6644c0f829ceb047447b4fd8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f656666696369656e746e65742d796f6c6f332d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/524f02a8e7f73a374007c6b8286968e910a5df8a6644c0f829ceb047447b4fd8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627562626c696969696e672f656666696369656e746e65742d796f6c6f332d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bubbliiiing/efficientnet-yolo3-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 这是一个efficientnet-yolo3-pytorch的源码，将yolov3的主干特征提取网络修改成了efficientnet。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HuKai97/YOLOv5-ShuffleNetv2\"\u003eHuKai97/YOLOv5-ShuffleNetv2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/041bd348b33d0ee5a7d44260464edbf80ef349d906128d1fb06929ab64ee3eeb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48754b616939372f594f4c4f76352d53687566666c654e657476323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/041bd348b33d0ee5a7d44260464edbf80ef349d906128d1fb06929ab64ee3eeb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48754b616939372f594f4c4f76352d53687566666c654e657476323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HuKai97/YOLOv5-ShuffleNetv2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5的轻量化改进(蜂巢检测项目)。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/guotao0628/yoloret\"\u003eYOLO-ReT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5c860b5c6ff5c9dede35d04f5f4951e7b23a71479aa5455d329347f280569c1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67756f74616f303632382f796f6c6f7265743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5c860b5c6ff5c9dede35d04f5f4951e7b23a71479aa5455d329347f280569c1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67756f74616f303632382f796f6c6f7265743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/guotao0628/yoloret?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLO-ReT: Towards High Accuracy Real-time Object Detection on Edge GPUs\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/WACV2022/html/Ganesh_YOLO-ReT_Towards_High_Accuracy_Real-Time_Object_Detection_on_Edge_GPUs_WACV_2022_paper.html\" rel=\"nofollow\"\u003eWACV 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eObject Detection Applications\u003c/h2\u003e\u003ca id=\"user-content-object-detection-applications\" class=\"anchor\" aria-label=\"Permalink: Object Detection Applications\" href=\"#object-detection-applications\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOpen World Object Detection\u003c/h3\u003e\u003ca id=\"user-content-open-world-object-detection\" class=\"anchor\" aria-label=\"Permalink: Open World Object Detection\" href=\"#open-world-object-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e开放世界目标检测\u003c/h4\u003e\u003ca id=\"user-content-开放世界目标检测\" class=\"anchor\" aria-label=\"Permalink: 开放世界目标检测\" href=\"#开放世界目标检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AILab-CVC/YOLO-World\"\u003eYOLO-World\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4df4362f165830998e6956b59d1a08fcce2aa5a7c5018206bd948a4ecba4e178/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41494c61622d4356432f594f4c4f2d576f726c643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4df4362f165830998e6956b59d1a08fcce2aa5a7c5018206bd948a4ecba4e178/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41494c61622d4356432f594f4c4f2d576f726c643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AILab-CVC/YOLO-World?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLO-World: Real-Time Open-Vocabulary Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2401.17270\" rel=\"nofollow\"\u003eCVPR 2024\u003c/a\u003e\u003c/strong\u003e). \u003ca href=\"https://www.yoloworld.cc/\" rel=\"nofollow\"\u003ewww.yoloworld.cc\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eFlorence-2 : \"Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2311.06242\" rel=\"nofollow\"\u003eCVPR 2024\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/roboflow/maestro\"\u003emaestro\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3809d33b5bd6d0de50380b668f794c9e27a8d01a46fd303435cf426181fff8f1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626f666c6f772f6d61657374726f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3809d33b5bd6d0de50380b668f794c9e27a8d01a46fd303435cf426181fff8f1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626f666c6f772f6d61657374726f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/roboflow/maestro?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : VLM fine-tuning for everyone. maestro is a streamlined tool to accelerate the fine-tuning of multimodal models. By encapsulating best practices from our core modules, maestro handles configuration, data loading, reproducibility, and training loop setup. It currently offers ready-to-use recipes for popular vision-language models such as \u003ca href=\"https://arxiv.org/abs/2311.06242\" rel=\"nofollow\"\u003eFlorence-2\u003c/a\u003e, PaliGemma 2, and \u003ca href=\"https://github.com/QwenLM/Qwen2.5-VL\"\u003eQwen2.5-VL\u003c/a\u003e. \u003ca href=\"https://maestro.roboflow.com/latest/\" rel=\"nofollow\"\u003emaestro.roboflow.com\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/autodistill/autodistill\"\u003eAutodistill\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c62d847952be21af33a3611f569579505b739360aa218da771156aec4b408990/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6175746f64697374696c6c2f6175746f64697374696c6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c62d847952be21af33a3611f569579505b739360aa218da771156aec4b408990/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6175746f64697374696c6c2f6175746f64697374696c6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/autodistill/autodistill?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Images to inference with no labeling (use foundation models to train supervised models). Autodistill uses big, slower foundation models to train small, faster supervised models. Using autodistill, you can go from unlabeled images to inference on a custom model running at the edge with no human intervention in between. \u003ca href=\"https://docs.autodistill.com/\" rel=\"nofollow\"\u003edocs.autodistill.com\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/D-Robotics-AI-Lab/DOSOD\"\u003eDOSOD\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/15b23797d9c6e7c6effe5e64d3bd6b2111c0e9b6e4a293f9619033da7bc3c9e9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f442d526f626f746963732d41492d4c61622f444f534f443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/15b23797d9c6e7c6effe5e64d3bd6b2111c0e9b6e4a293f9619033da7bc3c9e9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f442d526f626f746963732d41492d4c61622f444f534f443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/D-Robotics-AI-Lab/DOSOD?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"A Light-Weight Framework for Open-Set Object Detection with Decoupled Feature Alignment in Joint Space\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2412.14680\" rel=\"nofollow\"\u003earXiv 2024\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/IDEA-Research/DINO\"\u003eDINO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/17073ac7af4a5232b8652ef3b492f099a110784cc8b717523588714bc6553cb3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f44494e4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/17073ac7af4a5232b8652ef3b492f099a110784cc8b717523588714bc6553cb3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f44494e4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/IDEA-Research/DINO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2203.03605\" rel=\"nofollow\"\u003eICLR 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/IDEA-Research/GroundingDINO\"\u003eGroundingDINO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c6a434d03c84765d1ca6368c83522ccc7b0b5178349b2d0e2de3ef764d9be71e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f47726f756e64696e6744494e4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c6a434d03c84765d1ca6368c83522ccc7b0b5178349b2d0e2de3ef764d9be71e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f47726f756e64696e6744494e4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/IDEA-Research/GroundingDINO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2303.05499\" rel=\"nofollow\"\u003eECCV 2024\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zhenyuw16/UniDetector\"\u003eUniDetector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/58ae5622601625368069e0d1b06a68ccaa4a18fdc272f5b36fb849d1c0dfd42c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68656e79757731362f556e694465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/58ae5622601625368069e0d1b06a68ccaa4a18fdc272f5b36fb849d1c0dfd42c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68656e79757731362f556e694465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zhenyuw16/UniDetector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Detecting Everything in the Open World: Towards Universal Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2303.11749\" rel=\"nofollow\"\u003eCVPR 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/buxihuo/OW-YOLO\"\u003ebuxihuo/OW-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8bdcb3cfecabef094af4c81e104dd73d7f8040fd5e61639941c6f04615f73047/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6275786968756f2f4f572d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8bdcb3cfecabef094af4c81e104dd73d7f8040fd5e61639941c6f04615f73047/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6275786968756f2f4f572d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/buxihuo/OW-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detect known and unknown objects in the open world（具有区分已知与未知能力的全新检测器））.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFew-shot Object Detection\u003c/h3\u003e\u003ca id=\"user-content-few-shot-object-detection\" class=\"anchor\" aria-label=\"Permalink: Few-shot Object Detection\" href=\"#few-shot-object-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e少样本目标检测\u003c/h4\u003e\u003ca id=\"user-content-少样本目标检测\" class=\"anchor\" aria-label=\"Permalink: 少样本目标检测\" href=\"#少样本目标检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/autodistill/autodistill\"\u003eAutodistill\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c62d847952be21af33a3611f569579505b739360aa218da771156aec4b408990/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6175746f64697374696c6c2f6175746f64697374696c6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c62d847952be21af33a3611f569579505b739360aa218da771156aec4b408990/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6175746f64697374696c6c2f6175746f64697374696c6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/autodistill/autodistill?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Images to inference with no labeling (use foundation models to train supervised models). Autodistill uses big, slower foundation models to train small, faster supervised models. Using autodistill, you can go from unlabeled images to inference on a custom model running at the edge with no human intervention in between. \u003ca href=\"https://docs.autodistill.com/\" rel=\"nofollow\"\u003edocs.autodistill.com\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bingykang/Fewshot_Detection\"\u003ebingykang/Fewshot_Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ff3bd1752b702fd71ab5433db12e2ce136024c3cd6aeac02e402bac82fcbb106/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62696e67796b616e672f46657773686f745f446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ff3bd1752b702fd71ab5433db12e2ce136024c3cd6aeac02e402bac82fcbb106/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62696e67796b616e672f46657773686f745f446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bingykang/Fewshot_Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Few-shot Object Detection via Feature Reweighting\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_ICCV_2019/html/Kang_Few-Shot_Object_Detection_via_Feature_Reweighting_ICCV_2019_paper.html\" rel=\"nofollow\"\u003eICCV 2019\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hnuzhy/SSDA-YOLO\"\u003eSSDA-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a592456d1dcfc5c9b4056b758191146a428eb323181c6cf5d1c5f3ddcbc6ddc0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686e757a68792f535344412d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a592456d1dcfc5c9b4056b758191146a428eb323181c6cf5d1c5f3ddcbc6ddc0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686e757a68792f535344412d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hnuzhy/SSDA-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Codes for my paper \"SSDA-YOLO: Semi-supervised Domain Adaptive YOLO for Cross-Domain Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S1077314223000292\" rel=\"nofollow\"\u003eComputer Vision and Image Understanding, 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/luogen1996/OneTeacher\"\u003eOneTeacher\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/caf44931e6c0e962b40cdabe4a0a6ad74bfdf31e5dabcc28d0f700c911cbe9a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c756f67656e313939362f4f6e65546561636865723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/caf44931e6c0e962b40cdabe4a0a6ad74bfdf31e5dabcc28d0f700c911cbe9a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c756f67656e313939362f4f6e65546561636865723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/luogen1996/OneTeacher?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Towards End-to-end Semi-supervised Learning for One-stage Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2302.11299\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlibabaResearch/efficientteacher\"\u003eEfficient Teacher\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/34f23fd4f117eaa9d99740069ba8a198b3e7b930748069a5f87a6a1ec54f8feb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c696261626152657365617263682f656666696369656e74746561636865723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/34f23fd4f117eaa9d99740069ba8a198b3e7b930748069a5f87a6a1ec54f8feb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c696261626152657365617263682f656666696369656e74746561636865723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlibabaResearch/efficientteacher?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Efficient Teacher: Semi-Supervised Object Detection for YOLOv5\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2302.07577\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSmall Object Detection\u003c/h3\u003e\u003ca id=\"user-content-small-object-detection\" class=\"anchor\" aria-label=\"Permalink: Small Object Detection\" href=\"#small-object-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e小目标检测\u003c/h4\u003e\u003ca id=\"user-content-小目标检测\" class=\"anchor\" aria-label=\"Permalink: 小目标检测\" href=\"#小目标检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Koldim2001/YOLO-Patch-Based-Inference\"\u003eYOLO-Patch-Based-Inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c113ee896699b5158b20748e67a7e6bf0cd0f321761dbe9aaee6ce95d8f3274a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6f6c64696d323030312f594f4c4f2d50617463682d42617365642d496e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c113ee896699b5158b20748e67a7e6bf0cd0f321761dbe9aaee6ce95d8f3274a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6f6c64696d323030312f594f4c4f2d50617463682d42617365642d496e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Koldim2001/YOLO-Patch-Based-Inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Python library for YOLO small object detection and instance segmentation. This Python library simplifies SAHI-like inference for instance segmentation tasks, enabling the detection of small objects in images. It caters to both object detection and instance segmentation tasks, supporting a wide range of Ultralytics models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/obss/sahi\"\u003eSAHI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0347894aaa55676cf2eafc5e350d024001d939b4875da57fe15c527b93fa2111/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6273732f736168693f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0347894aaa55676cf2eafc5e350d024001d939b4875da57fe15c527b93fa2111/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6273732f736168693f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/obss/sahi?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Slicing Aided Hyper Inference and Fine-tuning for Small Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2202.06934v2\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e, \u003ca href=\"https://doi.org/10.5281/zenodo.5718950\" rel=\"nofollow\"\u003eZenodo 2021\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlanLi1997/slim-neck-by-gsconv\"\u003eSlim-neck by GSConv\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a0ad2237c66afe91f4eab95f5eed4c06d4e27bdc8bf1c26c27ccd2f564da26d1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c616e4c69313939372f736c696d2d6e65636b2d62792d6773636f6e763f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a0ad2237c66afe91f4eab95f5eed4c06d4e27bdc8bf1c26c27ccd2f564da26d1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c616e4c69313939372f736c696d2d6e65636b2d62792d6773636f6e763f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlanLi1997/slim-neck-by-gsconv?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Slim-neck by GSConv: A better design paradigm of detector architectures for autonomous vehicles\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2206.02424\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hustvl/TinyDet\"\u003ehustvl/TinyDet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bde524dc482931323c1ff205f953f527a03249a55210764a92e8c16cd921dbd8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68757374766c2f54696e794465743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bde524dc482931323c1ff205f953f527a03249a55210764a92e8c16cd921dbd8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68757374766c2f54696e794465743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hustvl/TinyDet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"TinyDet: accurately detecting small objects within 1 GFLOPs\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/article/10.1007/s11432-021-3504-4\" rel=\"nofollow\"\u003eScience China Information Sciences, 2023\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ChenhongyiYang/QueryDet-PyTorch\"\u003eQueryDet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/365213e1e4ed5e0ea6f18927aeedcd457f67a9c219b9a92a702ce51a92fae275/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368656e686f6e67796959616e672f51756572794465742d5079546f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/365213e1e4ed5e0ea6f18927aeedcd457f67a9c219b9a92a702ce51a92fae275/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368656e686f6e67796959616e672f51756572794465742d5079546f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ChenhongyiYang/QueryDet-PyTorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"QueryDet: Cascaded Sparse Query for Accelerating High-Resolution Small Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2022/html/Yang_QueryDet_Cascaded_Sparse_Query_for_Accelerating_High-Resolution_Small_Object_Detection_CVPR_2022_paper.html\" rel=\"nofollow\"\u003eCVPR 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Chasel-Tsui/mmdet-rfla\"\u003eRFLA\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7225d15c9a1134cf367788ba6b729250f40a1adf817fe7b62c98ddab71dccbe5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43686173656c2d547375692f6d6d6465742d72666c613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7225d15c9a1134cf367788ba6b729250f40a1adf817fe7b62c98ddab71dccbe5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43686173656c2d547375692f6d6d6465742d72666c613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Chasel-Tsui/mmdet-rfla?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"RFLA: Gaussian Receptive Field based Label Assignment for Tiny Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2208.08738\" rel=\"nofollow\"\u003eECCV 2022\u003c/a\u003e\u003c/strong\u003e). \"微信公众号「CV技术指南」《\u003ca href=\"https://mp.weixin.qq.com/s/h0J775I3D6zoTIeaJRnFgQ\" rel=\"nofollow\"\u003eECCV 2022 | RFLA：基于高斯感受野的微小目标检测标签分配\u003c/a\u003e》\"\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/avanetten/yolt\"\u003eYOLT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/91674c1daee2804a6afeaba83e4592e7096952eebe32875ee4178203bf6d235c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6176616e657474656e2f796f6c743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/91674c1daee2804a6afeaba83e4592e7096952eebe32875ee4178203bf6d235c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6176616e657474656e2f796f6c743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/avanetten/yolt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"You Only Look Twice: Rapid Multi-Scale Object Detection In Satellite Imagery\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1805.09512\" rel=\"nofollow\"\u003earXiv 2018\u003c/a\u003e\u003c/strong\u003e). \"微信公众号「江大白」《\u003ca href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NzgyNTU2Mg==\u0026amp;mid=2247498265\u0026amp;idx=1\u0026amp;sn=1eee95f8f4d09d761dc7b94f4ac55c34\u0026amp;source=41#wechat_redirect\" rel=\"nofollow\"\u003e基于大尺寸图像的小目标检测竞赛经验总结\u003c/a\u003e》\"\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/avanetten/simrdwn\"\u003eSIMRDWN\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5e1465428d22615cd49772d2b5698d72e5796e2058ee97eb6512b0024fe01606/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6176616e657474656e2f73696d7264776e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5e1465428d22615cd49772d2b5698d72e5796e2058ee97eb6512b0024fe01606/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6176616e657474656e2f73696d7264776e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/avanetten/simrdwn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Satellite Imagery Multiscale Rapid Detection with Windowed Networks\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1809.09978\" rel=\"nofollow\"\u003earXiv 2018\u003c/a\u003e, \u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8659155\" rel=\"nofollow\"\u003eWACV 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/avanetten/yoltv5\"\u003eYOLTv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ba9684ab5c71202355e65cb0fbc38811aba475102bb9862a1ac1319126c3f9e3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6176616e657474656e2f796f6c7476353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ba9684ab5c71202355e65cb0fbc38811aba475102bb9862a1ac1319126c3f9e3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6176616e657474656e2f796f6c7476353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/avanetten/yoltv5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLTv5 builds upon \u003ca href=\"https://github.com/avanetten/yolt\"\u003eYOLT\u003c/a\u003e and \u003ca href=\"https://github.com/avanetten/simrdwn\"\u003eSIMRDWN\u003c/a\u003e, and updates these frameworks to use the \u003ca href=\"https://github.com/ultralytics/yolov5\"\u003eultralytics/yolov5\u003c/a\u003e version of the YOLO object detection family.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cv516Buaa/tph-yolov5\"\u003eTPH-YOLOv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8626cd4a31f48c11b165d9ac4281c6d6bca0ff85cdc1036101d9bb869775dedd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6376353136427561612f7470682d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8626cd4a31f48c11b165d9ac4281c6d6bca0ff85cdc1036101d9bb869775dedd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6376353136427561612f7470682d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cv516Buaa/tph-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"TPH-YOLOv5: Improved YOLOv5 Based on Transformer Prediction Head for Object Detection on Drone-Captured Scenarios\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/ICCV2021W/VisDrone/html/Zhu_TPH-YOLOv5_Improved_YOLOv5_Based_on_Transformer_Prediction_Head_for_Object_ICCVW_2021_paper.html\" rel=\"nofollow\"\u003eICCV 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mwaseema/Drone-Detection\"\u003emwaseema/Drone-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0af7d58fc7c4b7ef6b14646ff7493257c1be7694d270baec5f911edae4338565/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d77617365656d612f44726f6e652d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0af7d58fc7c4b7ef6b14646ff7493257c1be7694d270baec5f911edae4338565/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d77617365656d612f44726f6e652d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mwaseema/Drone-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Dogfight: Detecting Drones from Drones Videos\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2021/html/Ashraf_Dogfight_Detecting_Drones_From_Drones_Videos_CVPR_2021_paper.html\" rel=\"nofollow\"\u003eCVPR 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cuogeihong/ceasc\"\u003eCEASA\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/11187a27838b6354a6dc208c0c5a2ab7224b394ca104f61563262e1be332a6af/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63756f676569686f6e672f63656173633f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/11187a27838b6354a6dc208c0c5a2ab7224b394ca104f61563262e1be332a6af/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63756f676569686f6e672f63656173633f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cuogeihong/ceasc?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Adaptive Sparse Convolutional Networks with Global Context Enhancement for Faster Object Detection on Drone Images\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2303.14488\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e). \"微信公众号「集智书童」《\u003ca href=\"https://mp.weixin.qq.com/s/-a4Wz04jLHFiAU88pUyDNQ\" rel=\"nofollow\"\u003e即插即用 | CEASA模块给你所有，小目标精度提升的同时速度也变快了\u003c/a\u003e》\"\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/KevinMuyaoGuo/yolov5s_for_satellite_imagery\"\u003eKevinMuyaoGuo/yolov5s_for_satellite_imagery\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d8681860d1b13aae5cefa0837349304ae8dabfa48463e2e95115f98d22900acf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6576696e4d7579616f47756f2f796f6c6f7635735f666f725f736174656c6c6974655f696d61676572793f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d8681860d1b13aae5cefa0837349304ae8dabfa48463e2e95115f98d22900acf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6576696e4d7579616f47756f2f796f6c6f7635735f666f725f736174656c6c6974655f696d61676572793f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/KevinMuyaoGuo/yolov5s_for_satellite_imagery?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于YOLOv5的卫星图像目标检测demo | A demo for satellite imagery object detection based on YOLOv5。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Hongyu-Yue/yoloV5_modify_smalltarget\"\u003eHongyu-Yue/yoloV5_modify_smalltarget\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5e8076db6759ed618c69b1242dacdd35b6c58dc52a41609a9bec67f2b297869c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f486f6e6779752d5975652f796f6c6f56355f6d6f646966795f736d616c6c7461726765743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5e8076db6759ed618c69b1242dacdd35b6c58dc52a41609a9bec67f2b297869c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f486f6e6779752d5975652f796f6c6f56355f6d6f646966795f736d616c6c7461726765743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Hongyu-Yue/yoloV5_modify_smalltarget?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOV5 小目标检测修改版。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/muyuuuu/Self-Supervise-Object-Detection\"\u003emuyuuuu/Self-Supervise-Object-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/736ee4551e02c94c5a567097163adc1445505e2944121fdab7a864f615c9d57f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d7579757575752f53656c662d5375706572766973652d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/736ee4551e02c94c5a567097163adc1445505e2944121fdab7a864f615c9d57f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d7579757575752f53656c662d5375706572766973652d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/muyuuuu/Self-Supervise-Object-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Self-Supervised Object Detection. 水面漂浮垃圾目标检测，分析源码改善 yolox 检测小目标的缺陷，提出自监督算法预训练无标签数据，提升检测性能。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/swricci/small-boat-detector\"\u003eswricci/small-boat-detector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/287aed9d6868fddb89f72c21be57cb9eff113b4e987dde7134ecf92984fa0c2c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737772696363692f736d616c6c2d626f61742d6465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/287aed9d6868fddb89f72c21be57cb9eff113b4e987dde7134ecf92984fa0c2c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737772696363692f736d616c6c2d626f61742d6465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/swricci/small-boat-detector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Trained yolo v3 model weights and configuration file to detect small boats in satellite imagery.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Resham-Sundar/sahi-yolox\"\u003eResham-Sundar/sahi-yolox\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/07d6e35167b89f4d031ee0ae977ab3cd745e8dbed85f6fb29706ee2ee094eb2a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52657368616d2d53756e6461722f736168692d796f6c6f783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/07d6e35167b89f4d031ee0ae977ab3cd745e8dbed85f6fb29706ee2ee094eb2a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52657368616d2d53756e6461722f736168692d796f6c6f783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Resham-Sundar/sahi-yolox?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloX with SAHI Implementation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eYOLO-Z : \"YOLO-Z: Improving small object detection in YOLOv5 for autonomous vehicles\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2112.11798\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e). \"微信公众号「计算机视觉研究院」《\u003ca href=\"https://mp.weixin.qq.com/s/ehkUapLOMdDghF2kAoAV4w\" rel=\"nofollow\"\u003eYolo-Z：改进的YOLOv5用于小目标检测（附原论文下载）\u003c/a\u003e》\".\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eM2S : \"A novel Multi to Single Module for small object detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2303.14977\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e). \"微信公众号「集智书童」《\u003ca href=\"https://mp.weixin.qq.com/s/FlKgYYGUHtJAxCF2wrh4NA\" rel=\"nofollow\"\u003e基于YOLOv5改进再设计 | M2S全面提升小目标精度\u003c/a\u003e》\".\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ultralytics/xview-yolov3\"\u003eultralytics/xview-yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9f2418011fc394590fcc348571beaeaae3eb4f7a5bb4c227618357888b04ecf7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f78766965772d796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9f2418011fc394590fcc348571beaeaae3eb4f7a5bb4c227618357888b04ecf7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f78766965772d796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ultralytics/xview-yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : xView 2018 Object Detection Challenge: YOLOv3 Training and Inference.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/inderpreet1390/yolov5-small-target\"\u003einderpreet1390/yolov5-small-target\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bb318824c02d38bbe9978d44916a6e592454825c6d3f26fcf7688f19e3924223/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e6465727072656574313339302f796f6c6f76352d736d616c6c2d7461726765743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bb318824c02d38bbe9978d44916a6e592454825c6d3f26fcf7688f19e3924223/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e6465727072656574313339302f796f6c6f76352d736d616c6c2d7461726765743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/inderpreet1390/yolov5-small-target?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Repository for improved yolov5 for small target detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AllenSquirrel/YOLOv3_ReSAM\"\u003eAllenSquirrel/YOLOv3_ReSAM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/baa6c30681dc79baeb1b21feecc693edc1ba655e5fcd26ee843aff0fb323b737/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6c656e537175697272656c2f594f4c4f76335f526553414d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/baa6c30681dc79baeb1b21feecc693edc1ba655e5fcd26ee843aff0fb323b737/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6c656e537175697272656c2f594f4c4f76335f526553414d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AllenSquirrel/YOLOv3_ReSAM?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv3_ReSAM:A Small Target Detection Method With Spatial Attention Module.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kadirnar/yolov5-sahi\"\u003ekadirnar/yolov5-sahi\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f5d105c527c1f5bcc6cf0f7fc3abcdd00e68952df6c6a85372b0adc1ca395120/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f796f6c6f76352d736168693f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f5d105c527c1f5bcc6cf0f7fc3abcdd00e68952df6c6a85372b0adc1ca395120/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f796f6c6f76352d736168693f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kadirnar/yolov5-sahi?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov5 Modelini Kullanarak Özel Nesne Eğitimi ve SAHI Kullanımı.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kadirnar/Yolov6-SAHI\"\u003ekadirnar/Yolov6-SAHI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5d37638321fc4ff76dcc37d68565ecc02474c6c643f0539efdb25d8fc33dda4c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f596f6c6f76362d534148493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5d37638321fc4ff76dcc37d68565ecc02474c6c643f0539efdb25d8fc33dda4c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f596f6c6f76362d534148493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kadirnar/Yolov6-SAHI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov6-SAHI.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zRzRzRzRzRzRzR/Mult-YOLO-alogorithm-of-RoboMaster-Radar-Detection-2023\"\u003ezRzRzRzRzRzRzR/Mult-YOLO-alogorithm-of-RoboMaster-Radar-Detection-2023\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/66898487c38cb2969eaed16838702747518e5b0e9316331c7202b43609fb70a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a527a527a527a527a527a527a522f4d756c742d594f4c4f2d616c6f676f726974686d2d6f662d526f626f4d61737465722d52616461722d446574656374696f6e2d323032333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/66898487c38cb2969eaed16838702747518e5b0e9316331c7202b43609fb70a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a527a527a527a527a527a527a522f4d756c742d594f4c4f2d616c6f676f726974686d2d6f662d526f626f4d61737465722d52616461722d446574656374696f6e2d323032333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zRzRzRzRzRzRzR/Mult-YOLO-alogorithm-of-RoboMaster-Radar-Detection-2023?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 2023年西交利物浦大学动云科技GMaster战队雷达yolo小目标检测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/quantumxiaol/yolov8-small-target-detection\"\u003equantumxiaol/yolov8-small-target-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/54daf01eed476a8bfef85cd4a71151fdbd794bcee8c09bdd4e1399c92f6e777e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7175616e74756d7869616f6c2f796f6c6f76382d736d616c6c2d7461726765742d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/54daf01eed476a8bfef85cd4a71151fdbd794bcee8c09bdd4e1399c92f6e777e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7175616e74756d7869616f6c2f796f6c6f76382d736d616c6c2d7461726765742d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/quantumxiaol/yolov8-small-target-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于yolov8实现小目标检测，在NWPU VHR-10和DOTA上测试。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/shaunyuan22/SODA\"\u003eshaunyuan22/SODA\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2522ec1b30d33adacbf6b9403af2e9e9805b17668301baaa217ffc9de439f311/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736861756e7975616e32322f534f44413f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2522ec1b30d33adacbf6b9403af2e9e9805b17668301baaa217ffc9de439f311/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736861756e7975616e32322f534f44413f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/shaunyuan22/SODA?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Official code library for SODA: A Large-scale Benchmark for Small Object Detection. \"Towards Large-Scale Small Object Detection: Survey and Benchmarks\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2207.14096\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/qunshansj/Small-Object-Detection-Head-Improved-YOLOv5-Infrared-Sensing-System\"\u003equnshansj/Small-Object-Detection-Head-Improved-YOLOv5-Infrared-Sensing-System\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/69f84785318f43a940036f9c9da384de955d99d14a703770deaba718c9626a99/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f71756e7368616e736a2f536d616c6c2d4f626a6563742d446574656374696f6e2d486561642d496d70726f7665642d594f4c4f76352d496e6672617265642d53656e73696e672d53797374656d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/69f84785318f43a940036f9c9da384de955d99d14a703770deaba718c9626a99/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f71756e7368616e736a2f536d616c6c2d4f626a6563742d446574656374696f6e2d486561642d496d70726f7665642d594f4c4f76352d496e6672617265642d53656e73696e672d53797374656d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/qunshansj/Small-Object-Detection-Head-Improved-YOLOv5-Infrared-Sensing-System?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于小目标检测头的改进YOLOv5红外遥感图像小目标检测系统。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eMultimodal Image Detection\u003c/h4\u003e\u003ca id=\"user-content-multimodal-image-detection\" class=\"anchor\" aria-label=\"Permalink: Multimodal Image Detection\" href=\"#multimodal-image-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e多模态图像检测\u003c/h4\u003e\u003ca id=\"user-content-多模态图像检测\" class=\"anchor\" aria-label=\"Permalink: 多模态图像检测\" href=\"#多模态图像检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NVIDIA-AI-IOT/Lidar_AI_Solution\"\u003eNVIDIA-AI-IOT/Lidar_AI_Solution\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4e3fe9c882102e5b25a1aa742a409a63a5b01f404efc2e9761b23e369209c8cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f4c696461725f41495f536f6c7574696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4e3fe9c882102e5b25a1aa742a409a63a5b01f404efc2e9761b23e369209c8cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e56494449412d41492d494f542f4c696461725f41495f536f6c7574696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NVIDIA-AI-IOT/Lidar_AI_Solution?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a highly optimized solution for self-driving 3D-lidar repository. It does a great job of speeding up sparse convolution/CenterPoint/BEVFusion/OSD/Conversion. A project demonstrating Lidar related AI solutions, including three GPU accelerated Lidar/camera DL networks (PointPillars, CenterPoint, BEVFusion) and the related libs (cuPCL, 3D SparseConvolution, YUV2RGB, cuOSD,).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/remaro-network/KD-YOLOX-ViT\"\u003eremaro-network/KD-YOLOX-ViT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ede49c18cb9c8cb1eef28b362ebb68919e18dc8fc9e6217c9b218cdb18412eb8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72656d61726f2d6e6574776f726b2f4b442d594f4c4f582d5669543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ede49c18cb9c8cb1eef28b362ebb68919e18dc8fc9e6217c9b218cdb18412eb8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72656d61726f2d6e6574776f726b2f4b442d594f4c4f582d5669543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/remaro-network/KD-YOLOX-ViT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository holds the code for the Python implementation of YOLOX-ViT. Furthermore, it has the implementation of the Knowledge Distillation (KD) method, evaluation metrics of the object detector and the side-scan sonar image dataset for underwater wall detection. \"Knowledge Distillation in YOLOX-ViT for Side-Scan Sonar Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2403.09313\" rel=\"nofollow\"\u003earXiv 2024\u003c/a\u003e\u003c/strong\u003e). The Sonar Wall Detection Dataset (SWDD) is publicly accessible at \u003ca href=\"https://zenodo.org/records/10528135\" rel=\"nofollow\"\u003ehttps://zenodo.org/records/10528135\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wandahangFY/YOLO-MIF\"\u003ewandahangFY/YOLO-MIF\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/725e5885eb87c0012ced0b09fe4665c67256641aec2f3090541a399708c2980f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e646168616e6746592f594f4c4f2d4d49463f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/725e5885eb87c0012ced0b09fe4665c67256641aec2f3090541a399708c2980f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e646168616e6746592f594f4c4f2d4d49463f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wandahangFY/YOLO-MIF?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO-MIF(YOLOv8-RGBT) is an improved version of YOLOv8 for object detection in gray-scale images, incorporating multi-information fusion to enhance detection accuracy. The detection of RGBT mode is also added. YOLO-MIF是在灰度图像中进行目标检测的改进型YOLOv8模型，引入了多信息融合策略，提高了检测准确性。 并添加了RGBT模式的检测,分割以及关节点任务。 \"YOLO-MIF: Improved YOLOv8 with Multi-Information fusion for object detection in Gray-Scale images\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S1474034624003574\" rel=\"nofollow\"\u003eAdvanced Engineering Informatics, 2024\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wandahangFY/YOLOv11-RGBT\"\u003ewandahangFY/YOLOv11-RGBT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/76ccef5c047bcd9ae18c06b5629ee6d18341c7b435186500270070d990f80da8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e646168616e6746592f594f4c4f7631312d524742543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/76ccef5c047bcd9ae18c06b5629ee6d18341c7b435186500270070d990f80da8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e646168616e6746592f594f4c4f7631312d524742543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wandahangFY/YOLOv11-RGBT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv11-RGBT: Towards a Comprehensive Multispectral Object Detection Framework（Supports RGBT detection for all YOLO series from YOLOv3 to YOLOv12, as well as RTDETR.））\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mcw1217/Triple_YOLOv8\"\u003emcw1217/Triple_YOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fd41786685a592351551fa5af9d9304afb7a6228ea066aa2b87f6d7ece2f5737/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6377313231372f547269706c655f594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fd41786685a592351551fa5af9d9304afb7a6228ea066aa2b87f6d7ece2f5737/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6377313231372f547269706c655f594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mcw1217/Triple_YOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This project uses three types of images as inputs RGB, Depth, and thermal images to perform object detection with YOLOv8.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ljcuestc/YoloMultispectralFusion-Coarse-to-fine-Registration\"\u003eljcuestc/YoloMultispectralFusion-Coarse-to-fine-Registration\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2b8817f3036cc4bd73ecd239afd5c65812ae73bd53b01fc7662085023a91d3e9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6a6375657374632f596f6c6f4d756c7469737065637472616c467573696f6e2d436f617273652d746f2d66696e652d526567697374726174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2b8817f3036cc4bd73ecd239afd5c65812ae73bd53b01fc7662085023a91d3e9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c6a6375657374632f596f6c6f4d756c7469737065637472616c467573696f6e2d436f617273652d746f2d66696e652d526567697374726174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ljcuestc/YoloMultispectralFusion-Coarse-to-fine-Registration?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"A Novel Multispectral Fusion Defect Detection Framework With Coarse-to-Fine Multispectral Registration\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/document/10365549\" rel=\"nofollow\"\u003eIEEE Transactions on Instrumentation and Measurement, 2023\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/icey-zhang/SuperYOLO\"\u003eSuperYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/304eaf2a7e371e4963897079f02bc3dddf2c6b13c44d963d28496fd082a67ce0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696365792d7a68616e672f5375706572594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/304eaf2a7e371e4963897079f02bc3dddf2c6b13c44d963d28496fd082a67ce0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696365792d7a68616e672f5375706572594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/icey-zhang/SuperYOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"SuperYOLO: Super Resolution Assisted Object Detection in Multimodal Remote Sensing Imagery\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2209.13351\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/QuincyQAQ/YOLOv8-Multi-Modal-Fusion-Network-RGB-IR\"\u003eQuincyQAQ/YOLOv8-Multi-Modal-Fusion-Network-RGB-IR\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/414b76fdd5ac317ef0bd589c30524ae1d2021a0624f206c5117e51f06366dc89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5175696e63795141512f594f4c4f76382d4d756c74692d4d6f64616c2d467573696f6e2d4e6574776f726b2d5247422d49523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/414b76fdd5ac317ef0bd589c30524ae1d2021a0624f206c5117e51f06366dc89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5175696e63795141512f594f4c4f76382d4d756c74692d4d6f64616c2d467573696f6e2d4e6574776f726b2d5247422d49523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/QuincyQAQ/YOLOv8-Multi-Modal-Fusion-Network-RGB-IR?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv8-Multi-Modal-Fusion-Network-RGB-IR.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mangoggul/YOLO-MultiModal\"\u003emangoggul/YOLO-MultiModal\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a43db68601a2fe6f8e80285c16efa8fd49e7e43b70e74842486a7a3e1905abf6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d616e676f6767756c2f594f4c4f2d4d756c74694d6f64616c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a43db68601a2fe6f8e80285c16efa8fd49e7e43b70e74842486a7a3e1905abf6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d616e676f6767756c2f594f4c4f2d4d756c74694d6f64616c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mangoggul/YOLO-MultiModal?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Multi-Modal-YOLO detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DocF/multispectral-object-detection\"\u003eDocF/multispectral-object-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/936e95a4953f076cc5dd404514dcb073ba7fc1b0ed6ee480c1599ac76fbd5077/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f446f63462f6d756c7469737065637472616c2d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/936e95a4953f076cc5dd404514dcb073ba7fc1b0ed6ee480c1599ac76fbd5077/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f446f63462f6d756c7469737065637472616c2d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DocF/multispectral-object-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Multispectral Object Detection with Yolov5 and Transformer.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ye-zixiao/Double-YOLO-Kaist\"\u003eYe-zixiao/Double-YOLO-Kaist\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d1fdd398abc7f304a58874ed3d5edb9c595ce6b667bbcd1c430447664db9c14f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59652d7a697869616f2f446f75626c652d594f4c4f2d4b616973743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d1fdd398abc7f304a58874ed3d5edb9c595ce6b667bbcd1c430447664db9c14f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59652d7a697869616f2f446f75626c652d594f4c4f2d4b616973743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ye-zixiao/Double-YOLO-Kaist?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 一种基于YOLOv3/4的双流混合模态道路行人检测方法🌊💧💦。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lzhihan/yolov5_Visible_Infrared_Vehicle_Detection\"\u003elzhihan/yolov5_Visible_Infrared_Vehicle_Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/417e97b4768b267e25606ac287cc5b0704c67f4f1ca2fe33a14f8fdd5b4d2841/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c7a686968616e2f796f6c6f76355f56697369626c655f496e6672617265645f56656869636c655f446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/417e97b4768b267e25606ac287cc5b0704c67f4f1ca2fe33a14f8fdd5b4d2841/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c7a686968616e2f796f6c6f76355f56697369626c655f496e6672617265645f56656869636c655f446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lzhihan/yolov5_Visible_Infrared_Vehicle_Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于可见光和红外图像的深度学习车辆目标检测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jere357/yolov5-RGBD\"\u003ejere357/yolov5-RGBD\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/236b96f7913b4e7e691afbfd0d54ca49847d9bd83beff23343c460fbe99e1dba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a6572653335372f796f6c6f76352d524742443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/236b96f7913b4e7e691afbfd0d54ca49847d9bd83beff23343c460fbe99e1dba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a6572653335372f796f6c6f76352d524742443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jere357/yolov5-RGBD?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"fork\" from yolov5 with the possibility of running inferences on RGBD(C) images, work in progress. This repo is not a fork of the original repo bcs i already have 1 fork with a PR pending, this is still messy code and a work in progress.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/huashu996/dual_result_fusion_yolov5\"\u003ehuashu996/dual_result_fusion_yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7f9e40f6e802f219ec419f29f61e06d26826bf676d9c5ee41bc3da1204f6aa64/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6875617368753939362f6475616c5f726573756c745f667573696f6e5f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7f9e40f6e802f219ec419f29f61e06d26826bf676d9c5ee41bc3da1204f6aa64/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6875617368753939362f6475616c5f726573756c745f667573696f6e5f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/huashu996/dual_result_fusion_yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : result set fusion for visible-light and infrared images. 此双模态检测是通过对可见光和红外图像分别训练，得到两个weight，在运行时会对两种图像分别检测，最后对检测结果求极大似然，并且能够对目标进行测距。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MAli-Farooq/Thermal-YOLO\"\u003eMAli-Farooq/Thermal-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4c4db31ab25351234bed488e6aa327763248240df649cf8900ad6223eca1e8fc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736965727072696e736b792f596f6c6f56355f626c6f6f645f63656c6c733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4c4db31ab25351234bed488e6aa327763248240df649cf8900ad6223eca1e8fc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736965727072696e736b792f596f6c6f56355f626c6f6f645f63656c6c733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sierprinsky/YoloV5_blood_cells?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This study is related to object detection in thermal infrared spectrum using YOLO-V5 framework for ADAS application.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/OrangeSodahub/CRLFnet\"\u003eOrangeSodahub/CRLFnet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/208a096b4363a94b078ab0040d548001315b316a0f8bf054b948d0e16fb0cf02/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f72616e6765536f64616875622f43524c466e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/208a096b4363a94b078ab0040d548001315b316a0f8bf054b948d0e16fb0cf02/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f72616e6765536f64616875622f43524c466e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/OrangeSodahub/CRLFnet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Camera-Radar-Lidar Fusion detection net based on ROS, YOLOv3, OpenPCDet integration.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mjoshi07/Visual-Sensor-Fusion\"\u003emjoshi07/Visual-Sensor-Fusion\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e6961d9a14e474aa8b68eaffaf1fda90e4e4c7fd9b6ac0647c6314b39a36ea5c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6a6f73686930372f56697375616c2d53656e736f722d467573696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e6961d9a14e474aa8b68eaffaf1fda90e4e4c7fd9b6ac0647c6314b39a36ea5c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6a6f73686930372f56697375616c2d53656e736f722d467573696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mjoshi07/Visual-Sensor-Fusion?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : LiDAR Fusion with Vision.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Arrowes/CEAM-YOLOv7\"\u003eArrowes/CEAM-YOLOv7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/34b80f920cb805ab8b35fec2f29e19abfc8cde8acc22a6a0b21f56f476fae139/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4172726f7765732f4345414d2d594f4c4f76373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/34b80f920cb805ab8b35fec2f29e19abfc8cde8acc22a6a0b21f56f476fae139/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4172726f7765732f4345414d2d594f4c4f76373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Arrowes/CEAM-YOLOv7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : CEAM-YOLOv7: Improved YOLOv7 Based on Channel Expansion and Attention Mechanism for Driver Distraction Behavior Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eVideo Object Detection\u003c/h3\u003e\u003ca id=\"user-content-video-object-detection\" class=\"anchor\" aria-label=\"Permalink: Video Object Detection\" href=\"#video-object-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e视频目标检测\u003c/h4\u003e\u003ca id=\"user-content-视频目标检测\" class=\"anchor\" aria-label=\"Permalink: 视频目标检测\" href=\"#视频目标检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/YuHengsss/YOLOV\"\u003eYOLOV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/29749d69e78c07f86e15ba82ec1117db69fa40de8de42dee85bf704c7c017c01/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f597548656e677373732f594f4c4f563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/29749d69e78c07f86e15ba82ec1117db69fa40de8de42dee85bf704c7c017c01/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f597548656e677373732f594f4c4f563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/YuHengsss/YOLOV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOV: Making Still Image Object Detectors Great at Video Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2208.09686\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yancie-yjr/StreamYOLO\"\u003eStreamYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fa4b133d00493b4cb23f96578c9a1666bb89bfc36162dbe771877cdbc4420b9e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f79616e6369652d796a722f53747265616d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fa4b133d00493b4cb23f96578c9a1666bb89bfc36162dbe771877cdbc4420b9e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f79616e6369652d796a722f53747265616d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yancie-yjr/StreamYOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Real-time Object Detection for Streaming Perception\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2203.12338v1\" rel=\"nofollow\"\u003eCVPR 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlbertoSabater/Robust-and-efficient-post-processing-for-video-object-detection\"\u003eREPP\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ba12fc9fcd83bc7e798363c9f713e28aa5e42f3d13819045b5dee33b30529139/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c626572746f536162617465722f526f627573742d616e642d656666696369656e742d706f73742d70726f63657373696e672d666f722d766964656f2d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ba12fc9fcd83bc7e798363c9f713e28aa5e42f3d13819045b5dee33b30529139/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c626572746f536162617465722f526f627573742d616e642d656666696369656e742d706f73742d70726f63657373696e672d666f722d766964656f2d6f626a6563742d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlbertoSabater/Robust-and-efficient-post-processing-for-video-object-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Robust and efficient post-processing for video object detection\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9341600\" rel=\"nofollow\"\u003eIROS 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/stanford-futuredata/noscope\"\u003eNoScope\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a25729920b662998ba4375a4956a43ef151046005e7394e838cf31cb5ad9f6da/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374616e666f72642d667574757265646174612f6e6f73636f70653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a25729920b662998ba4375a4956a43ef151046005e7394e838cf31cb5ad9f6da/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374616e666f72642d667574757265646174612f6e6f73636f70653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/stanford-futuredata/noscope?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Noscope: optimizing neural network queries over video at scale\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1703.02529\" rel=\"nofollow\"\u003earXiv 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eObject Tracking\u003c/h3\u003e\u003ca id=\"user-content-object-tracking\" class=\"anchor\" aria-label=\"Permalink: Object Tracking\" href=\"#object-tracking\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e目标跟踪\u003c/h4\u003e\u003ca id=\"user-content-目标跟踪\" class=\"anchor\" aria-label=\"Permalink: 目标跟踪\" href=\"#目标跟踪\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eMulti-Object Tracking\u003c/h4\u003e\u003ca id=\"user-content-multi-object-tracking\" class=\"anchor\" aria-label=\"Permalink: Multi-Object Tracking\" href=\"#multi-object-tracking\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e多目标跟踪\u003c/h5\u003e\u003ca id=\"user-content-多目标跟踪\" class=\"anchor\" aria-label=\"Permalink: 多目标跟踪\" href=\"#多目标跟踪\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nmhaddad/fast-track\"\u003enmhaddad/fast-track\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/206139bfa856faf333cc5952a4ee99d72427e5dfaa2ed518f0128182e490b6f4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e6d6861646461642f666173742d747261636b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/206139bfa856faf333cc5952a4ee99d72427e5dfaa2ed518f0128182e490b6f4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e6d6861646461642f666173742d747261636b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nmhaddad/fast-track?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object tracking pipelines complete with RF-DETR, YOLOv9, YOLO-NAS, YOLOv8, and YOLOv7 detection and BYTETracker tracking.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sujanshresstha/YOLOv10_DeepSORT\"\u003esujanshresstha/YOLOv10_DeepSORT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/71f98f3c54a70cf1b011de9d566a61bd388d649c09d6087a2a7844214050b203/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756a616e7368726573737468612f594f4c4f7631305f44656570534f52543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/71f98f3c54a70cf1b011de9d566a61bd388d649c09d6087a2a7844214050b203/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756a616e7368726573737468612f594f4c4f7631305f44656570534f52543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sujanshresstha/YOLOv10_DeepSORT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository contains code for object detection and tracking in videos using the YOLOv10 object detection model and the DeepSORT algorithm.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eBoxMOT \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4e1908be92e0371c6e69e6359845324f20c53fe568e9a9dd8dc281c296156f6d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696b656c2d62726f7374726f6d2f626f786d6f743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4e1908be92e0371c6e69e6359845324f20c53fe568e9a9dd8dc281c296156f6d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696b656c2d62726f7374726f6d2f626f786d6f743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mikel-brostrom/boxmot?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : BoxMOT: pluggable SOTA tracking modules for segmentation, object detection and pose estimation models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mikel-brostrom/Yolov7_StrongSORT_OSNet\"\u003emikel-brostrom/Yolov7_StrongSORT_OSNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/04ca3ecdf3b56d65c545d1dcf6e281fd9e2d301d03c1beedd1f9693459c14c1a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696b656c2d62726f7374726f6d2f596f6c6f76375f5374726f6e67534f52545f4f534e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/04ca3ecdf3b56d65c545d1dcf6e281fd9e2d301d03c1beedd1f9693459c14c1a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696b656c2d62726f7374726f6d2f596f6c6f76375f5374726f6e67534f52545f4f534e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mikel-brostrom/Yolov7_StrongSORT_OSNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time multi-camera multi-object tracker using \u003ca href=\"https://github.com/WongKinYiu/yolov7\"\u003eYOLOv7\u003c/a\u003e and \u003ca href=\"https://github.com/dyhBUPT/StrongSORT\"\u003eStrongSORT\u003c/a\u003e with \u003ca href=\"https://github.com/KaiyangZhou/deep-person-reid\"\u003eOSNet\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RizwanMunawar/yolov8-object-tracking\"\u003eRizwanMunawar/yolov8-object-tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1b7145a0b64b60ceae3e4777ea142b1eefd9785d06cec3f3b033d696e8fe7736/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76382d6f626a6563742d747261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1b7145a0b64b60ceae3e4777ea142b1eefd9785d06cec3f3b033d696e8fe7736/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76382d6f626a6563742d747261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RizwanMunawar/yolov8-object-tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv8 Object Tracking Using PyTorch, OpenCV and Ultralytics.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xuarehere/yolo_series_deepsort_pytorch\"\u003exuarehere/yolo_series_deepsort_pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/48c4dd02b79e58f597757fac19d31056ec2a49ceb90859425ba85c6abaf58392/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7875617265686572652f796f6c6f5f7365726965735f64656570736f72745f7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/48c4dd02b79e58f597757fac19d31056ec2a49ceb90859425ba85c6abaf58392/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7875617265686572652f796f6c6f5f7365726965735f64656570736f72745f7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xuarehere/yolo_series_deepsort_pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Deepsort with yolo series. This project support the existing yolo detection model algorithm (YOLOv3, YOLOV4, YOLOV4Scaled, YOLOV5, YOLOV6, YOLOV7, YOLOV8, YOLOX, YOLOR, PPYOLOE ).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/JackWoo0831/Yolov7-tracker\"\u003eJackWoo0831/Yolov7-tracker\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/10af1ee3fbb719533a4e8827a28635e2cdf9ccf4c2ca54e159de21fefc308728/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61636b576f6f303833312f596f6c6f76372d747261636b65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/10af1ee3fbb719533a4e8827a28635e2cdf9ccf4c2ca54e159de21fefc308728/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61636b576f6f303833312f596f6c6f76372d747261636b65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/JackWoo0831/Yolov7-tracker?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo v7 and several Multi-Object Tracker(SORT, DeepSORT, ByteTrack, BoT-SORT, etc.) in VisDrone2019 Dataset. It uses a unified style and integrated tracker for easy embedding in your own projects. YOLOv7 + 各种tracker实现多目标跟踪。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NirAharon/BoT-SORT\"\u003eBoT-SORT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/22e644dce08636e4c7b0777ecf5cc208a3cefd481d129dc3453ee408d9469522/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e6972416861726f6e2f426f542d534f52543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/22e644dce08636e4c7b0777ecf5cc208a3cefd481d129dc3453ee408d9469522/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e6972416861726f6e2f426f542d534f52543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NirAharon/BoT-SORT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"BoT-SORT: Robust Associations Multi-Pedestrian Tracking\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2206.14651\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dyhBUPT/StrongSORT\"\u003eStrongSORT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/80c3c741d4a52e68aac9aaafe2c0dc1f9bef2c9f7b24f4643dfe3098cc6b2efe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f647968425550542f5374726f6e67534f52543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/80c3c741d4a52e68aac9aaafe2c0dc1f9bef2c9f7b24f4643dfe3098cc6b2efe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f647968425550542f5374726f6e67534f52543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dyhBUPT/StrongSORT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"StrongSORT: Make DeepSORT Great Again\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2202.13514\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LiuShuaiyr/UAVMOT\"\u003eUAVMOT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c506c1e7ebf954a4ae43e6a7171e6af9e9a1020d517c120f7642a995e8600b1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c6975536875616979722f5541564d4f543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c506c1e7ebf954a4ae43e6a7171e6af9e9a1020d517c120f7642a995e8600b1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c6975536875616979722f5541564d4f543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LiuShuaiyr/UAVMOT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Multi-Object Tracking Meets Moving UAV\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Multi-Object_Tracking_Meets_Moving_UAV_CVPR_2022_paper.html\" rel=\"nofollow\"\u003eCVPR 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HKPolyU-UAV/AUTO\"\u003eHKPolyU-UAV/AUTO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/df039f9b564a95ca0cdc6315bfc809ea13c1780909bedf40a0888abe7424f875/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f484b506f6c79552d5541562f4155544f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/df039f9b564a95ca0cdc6315bfc809ea13c1780909bedf40a0888abe7424f875/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f484b506f6c79552d5541562f4155544f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HKPolyU-UAV/AUTO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Dynamic Object Tracking on Autonomous UAV System for Surveillance Applications\". (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/1424-8220/21/23/7888\" rel=\"nofollow\"\u003eSensors 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bharath5673/StrongSORT-YOLO\"\u003ebharath5673/StrongSORT-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c0094918a516c63ab169944d2f5475e563b327711c707996277bc5e810374901/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62686172617468353637332f5374726f6e67534f52542d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c0094918a516c63ab169944d2f5475e563b327711c707996277bc5e810374901/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62686172617468353637332f5374726f6e67534f52542d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bharath5673/StrongSORT-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time multi-camera multi-object tracker using (YOLOv5, YOLOv7) and \u003ca href=\"https://github.com/dyhBUPT/StrongSORT\"\u003eStrongSORT\u003c/a\u003e with OSNet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mikel-brostrom/Yolov7_StrongSORT_OSNet\"\u003emikel-brostrom/Yolov7_StrongSORT_OSNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/04ca3ecdf3b56d65c545d1dcf6e281fd9e2d301d03c1beedd1f9693459c14c1a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696b656c2d62726f7374726f6d2f596f6c6f76375f5374726f6e67534f52545f4f534e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/04ca3ecdf3b56d65c545d1dcf6e281fd9e2d301d03c1beedd1f9693459c14c1a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696b656c2d62726f7374726f6d2f596f6c6f76375f5374726f6e67534f52545f4f534e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mikel-brostrom/Yolov7_StrongSORT_OSNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time multi-camera multi-object tracker using YOLOv7 and StrongSORT with OSNet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kadirnar/yolov5-strongsort\"\u003ekadirnar/yolov5-strongsort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/60b2705e9e6c79bec2aa96070d62e9292c77906485be098d0121d2bfd97f3116/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f796f6c6f76352d7374726f6e67736f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/60b2705e9e6c79bec2aa96070d62e9292c77906485be098d0121d2bfd97f3116/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b616469726e61722f796f6c6f76352d7374726f6e67736f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kadirnar/yolov5-strongsort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Minimal PyTorch implementation of YOLOv5 and \u003ca href=\"https://github.com/dyhBUPT/StrongSORT\"\u003eStrongSORT\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZQPei/deep_sort_pytorch\"\u003eZQPei/deep_sort_pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e49a7dddf46fb80d2ecf977929eb53eeba5c008d64ef2ef40659403a420e0d7a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a515065692f646565705f736f72745f7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e49a7dddf46fb80d2ecf977929eb53eeba5c008d64ef2ef40659403a420e0d7a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a515065692f646565705f736f72745f7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZQPei/deep_sort_pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : MOT using deepsort and yolov3 with pytorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Qidian213/deep_sort_yolov3\"\u003eQidian213/deep_sort_yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/26f8b901a4328b0c940ed55bfeff7d0a5d25968fca6f6ff6513ff4ef3f445289/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51696469616e3231332f646565705f736f72745f796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/26f8b901a4328b0c940ed55bfeff7d0a5d25968fca6f6ff6513ff4ef3f445289/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51696469616e3231332f646565705f736f72745f796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Qidian213/deep_sort_yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time Multi-person tracker using YOLO v3 and deep_sort with tensorflow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/JudasDie/SOTS\"\u003eCSTrack\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0417c1714faac932571dea60a379cc09db465c35950eaaa15d40830b07632f16/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a756461734469652f534f54533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0417c1714faac932571dea60a379cc09db465c35950eaaa15d40830b07632f16/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a756461734469652f534f54533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/JudasDie/SOTS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Rethinking the competition between detection and ReID in Multi-Object Tracking\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2010.12138\" rel=\"nofollow\"\u003earXiv 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Guanghan/ROLO\"\u003eROLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0d8540e70b225bc7601aba0d72612ebfba89516cbaa938103f3e72622efb09ec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4775616e6768616e2f524f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0d8540e70b225bc7601aba0d72612ebfba89516cbaa938103f3e72622efb09ec/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4775616e6768616e2f524f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Guanghan/ROLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ROLO is short for Recurrent YOLO, aimed at simultaneous object detection and tracking.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/GeekAlexis/FastMOT\"\u003eFastMOT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e5b45e39d63fb400e7b0d007cc35310eccdef6975f4adcab8c3f6124250cfa26/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4765656b416c657869732f466173744d4f543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e5b45e39d63fb400e7b0d007cc35310eccdef6975f4adcab8c3f6124250cfa26/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4765656b416c657869732f466173744d4f543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/GeekAlexis/FastMOT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"FastMOT: High-Performance Multiple Object Tracking Based on Deep SORT and KLT\". (\u003cstrong\u003e\u003ca href=\"https://doi.org/10.5281/zenodo.4294717\" rel=\"nofollow\"\u003eZenodo 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Sharpiless/Yolov5-deepsort-inference\"\u003eSharpiless/Yolov5-deepsort-inference\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9329eb8975820f5bc7edf10dc3b3560d6aa018750ce60723726c6296cfd1ec48/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76352d64656570736f72742d696e666572656e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9329eb8975820f5bc7edf10dc3b3560d6aa018750ce60723726c6296cfd1ec48/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76352d64656570736f72742d696e666572656e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Sharpiless/Yolov5-deepsort-inference?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 使用YOLOv5+Deepsort实现车辆行人追踪和计数，代码封装成一个Detector类，更容易嵌入到自己的项目中。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Sharpiless/Yolov5-Deepsort\"\u003eSharpiless/Yolov5-Deepsort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4e0987e19a04a04855db73d5f86122ea86423fe36a8798be2ab10e3590a61d6c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76352d44656570736f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4e0987e19a04a04855db73d5f86122ea86423fe36a8798be2ab10e3590a61d6c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5368617270696c6573732f596f6c6f76352d44656570736f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Sharpiless/Yolov5-Deepsort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 最新版本yolov5+deepsort目标检测和追踪，能够显示目标类别，支持5.0版本可训练自己数据集。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LeonLok/Multi-Camera-Live-Object-Tracking\"\u003eLeonLok/Multi-Camera-Live-Object-Tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f12c7f3f0a8f1e6eebd2a985d116f1cfaedd8433f24866adeac40375f6940227/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c656f6e4c6f6b2f4d756c74692d43616d6572612d4c6976652d4f626a6563742d547261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f12c7f3f0a8f1e6eebd2a985d116f1cfaedd8433f24866adeac40375f6940227/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c656f6e4c6f6b2f4d756c74692d43616d6572612d4c6976652d4f626a6563742d547261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LeonLok/Multi-Camera-Live-Object-Tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Multi-camera live traffic and object counting with YOLO v4, Deep SORT, and Flask.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LeonLok/Deep-SORT-YOLOv4\"\u003eLeonLok/Deep-SORT-YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e2ccc7a646fd5ae0bf0e458fdeefb06e9dea5630fb7c848feccac5826773fa82/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c656f6e4c6f6b2f446565702d534f52542d594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e2ccc7a646fd5ae0bf0e458fdeefb06e9dea5630fb7c848feccac5826773fa82/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c656f6e4c6f6b2f446565702d534f52542d594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LeonLok/Deep-SORT-YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : People detection and optional tracking with Tensorflow backend.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/obendidi/Tracking-with-darkflow\"\u003eobendidi/Tracking-with-darkflow\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2c0aa7376d70e4883db9a106d067075cfec9de623e2d76b1ad8c8489ef031264/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f62656e646964692f547261636b696e672d776974682d6461726b666c6f773f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2c0aa7376d70e4883db9a106d067075cfec9de623e2d76b1ad8c8489ef031264/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f62656e646964692f547261636b696e672d776974682d6461726b666c6f773f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/obendidi/Tracking-with-darkflow?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time people Multitracker using YOLO v2 and deep_sort with tensorflow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DrewNF/Tensorflow_Object_Tracking_Video\"\u003eDrewNF/Tensorflow_Object_Tracking_Video\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b07d17b586a58352238796f028c345f363a060d7af794d174d4f249e96de461a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f447265774e462f54656e736f72666c6f775f4f626a6563745f547261636b696e675f566964656f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b07d17b586a58352238796f028c345f363a060d7af794d174d4f249e96de461a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f447265774e462f54656e736f72666c6f775f4f626a6563745f547261636b696e675f566964656f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DrewNF/Tensorflow_Object_Tracking_Video?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object Tracking in Tensorflow ( Localization Detection Classification ) developed to partecipate to ImageNET VID competition.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dyh/unbox_yolov5_deepsort_counting\"\u003edyh/unbox_yolov5_deepsort_counting\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/811fc3285b0629b539c49da1cb3c99036a8e60dda7674e2a7664420e1b8155e1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6479682f756e626f785f796f6c6f76355f64656570736f72745f636f756e74696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/811fc3285b0629b539c49da1cb3c99036a8e60dda7674e2a7664420e1b8155e1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6479682f756e626f785f796f6c6f76355f64656570736f72745f636f756e74696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dyh/unbox_yolov5_deepsort_counting?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5 deepsort 行人 车辆 跟踪 检测 计数。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/theAIGuysCode/yolov3_deepsort\"\u003etheAIGuysCode/yolov3_deepsort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/30d37a7b57424be6b33cfca88989b7342b545f6455a7446146a69285a70f0d5f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746865414947757973436f64652f796f6c6f76335f64656570736f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/30d37a7b57424be6b33cfca88989b7342b545f6455a7446146a69285a70f0d5f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746865414947757973436f64652f796f6c6f76335f64656570736f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/theAIGuysCode/yolov3_deepsort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object tracking implemented with YOLOv3, Deep Sort and Tensorflow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/weixu000/libtorch-yolov3-deepsort\"\u003eweixu000/libtorch-yolov3-deepsort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/849460b5d0c6f920aa3840d83f19d59015f8e6cfb3c3897ba5e985b1a354d913/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77656978753030302f6c6962746f7263682d796f6c6f76332d64656570736f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/849460b5d0c6f920aa3840d83f19d59015f8e6cfb3c3897ba5e985b1a354d913/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77656978753030302f6c6962746f7263682d796f6c6f76332d64656570736f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/weixu000/libtorch-yolov3-deepsort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : libtorch-yolov3-deepsort.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pmj110119/YOLOX_deepsort_tracker\"\u003epmj110119/YOLOX_deepsort_tracker\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c51199a74fd0dc140bd2971c4e2fe2557a6e1c4d7c22c06e1400883bc5078efd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706d6a3131303131392f594f4c4f585f64656570736f72745f747261636b65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c51199a74fd0dc140bd2971c4e2fe2557a6e1c4d7c22c06e1400883bc5078efd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706d6a3131303131392f594f4c4f585f64656570736f72745f747261636b65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pmj110119/YOLOX_deepsort_tracker?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : using yolox+deepsort for object-tracking.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/abhyantrika/nanonets_object_tracking\"\u003eabhyantrika/nanonets_object_tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9eb415453040721d3563b2284f87645fc2ec08f93d86797f47ebc5b28bf7f012/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61626879616e7472696b612f6e616e6f6e6574735f6f626a6563745f747261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9eb415453040721d3563b2284f87645fc2ec08f93d86797f47ebc5b28bf7f012/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61626879616e7472696b612f6e616e6f6e6574735f6f626a6563745f747261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/abhyantrika/nanonets_object_tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : nanonets_object_tracking.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mattzheng/keras-yolov3-KF-objectTracking\"\u003emattzheng/keras-yolov3-KF-objectTracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/71cdf67fe4fe9d5f6ba36e2ec506c0ca6f12a2fc5d1aee7f6d2ffe7da7443ecd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6174747a68656e672f6b657261732d796f6c6f76332d4b462d6f626a656374547261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/71cdf67fe4fe9d5f6ba36e2ec506c0ca6f12a2fc5d1aee7f6d2ffe7da7443ecd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6174747a68656e672f6b657261732d796f6c6f76332d4b462d6f626a656374547261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mattzheng/keras-yolov3-KF-objectTracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 以kears-yolov3做detector，以Kalman-Filter算法做tracker，进行多人物目标追踪。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/rohanchandra30/TrackNPred\"\u003erohanchandra30/TrackNPred\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4670ffc4d659cc580390012512bbf7304316e323a32c7b0e14928566cfdc9ece/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f68616e6368616e64726133302f547261636b4e507265643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4670ffc4d659cc580390012512bbf7304316e323a32c7b0e14928566cfdc9ece/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f68616e6368616e64726133302f547261636b4e507265643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/rohanchandra30/TrackNPred?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Software Framework for End-to-End Trajectory Prediction.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RichardoMrMu/yolov5-deepsort-tensorrt\"\u003eRichardoMrMu/yolov5-deepsort-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a8f933159d9398c0a5357add7b3465ede4bd09ef0369c6672f6817febb12b4f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f526963686172646f4d724d752f796f6c6f76352d64656570736f72742d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a8f933159d9398c0a5357add7b3465ede4bd09ef0369c6672f6817febb12b4f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f526963686172646f4d724d752f796f6c6f76352d64656570736f72742d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RichardoMrMu/yolov5-deepsort-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A c++ implementation of yolov5 and deepsort.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bamwani/car-counting-and-speed-estimation-yolo-sort-python\"\u003ebamwani/car-counting-and-speed-estimation-yolo-sort-python\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7038cf4fe7d5ad687f7e6c96dc649239e3a84b6ac098fd069a0d49e1e4108308/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62616d77616e692f6361722d636f756e74696e672d616e642d73706565642d657374696d6174696f6e2d796f6c6f2d736f72742d707974686f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7038cf4fe7d5ad687f7e6c96dc649239e3a84b6ac098fd069a0d49e1e4108308/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62616d77616e692f6361722d636f756e74696e672d616e642d73706565642d657374696d6174696f6e2d796f6c6f2d736f72742d707974686f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bamwani/car-counting-and-speed-estimation-yolo-sort-python?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This project imlements the following tasks in the project: 1. Vehicle counting, 2. Lane detection. 3.Lane change detection and 4.speed estimation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ArtLabss/tennis-tracking\"\u003eArtLabss/tennis-tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4f87c977d889e021c49a4bbf105a148468b965911ab385d2f25093f0322d725c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4172744c616273732f74656e6e69732d747261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4f87c977d889e021c49a4bbf105a148468b965911ab385d2f25093f0322d725c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4172744c616273732f74656e6e69732d747261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ArtLabss/tennis-tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Open-source Monocular Python HawkEye for Tennis.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CaptainEven/YOLOV4_MCMOT\"\u003eCaptainEven/YOLOV4_MCMOT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a2034011cc4e3f8b30282201c639ce1d8442f2eaaf6622401113cfdade1d014c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4361707461696e4576656e2f594f4c4f56345f4d434d4f543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a2034011cc4e3f8b30282201c639ce1d8442f2eaaf6622401113cfdade1d014c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4361707461696e4576656e2f594f4c4f56345f4d434d4f543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CaptainEven/YOLOV4_MCMOT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Using YOLOV4 as detector for MCMOT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/opendatacam/node-moving-things-tracker\"\u003eopendatacam/node-moving-things-tracker\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/46fa9cb9a0f90a0ed982c7694bcd021fce4fc51d74eecc8419012f5b2667474f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e6461746163616d2f6e6f64652d6d6f76696e672d7468696e67732d747261636b65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/46fa9cb9a0f90a0ed982c7694bcd021fce4fc51d74eecc8419012f5b2667474f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e6461746163616d2f6e6f64652d6d6f76696e672d7468696e67732d747261636b65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/opendatacam/node-moving-things-tracker?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : javascript implementation of \"tracker by detections\" for realtime multiple object tracking (MOT).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lanmengyiyu/yolov5-deepmar\"\u003elanmengyiyu/yolov5-deepmar\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e2698e1e58c1f96c287d4398621a3409cb6cd80b87d5f5a3d490cd30c72bd284/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c616e6d656e67796979752f796f6c6f76352d646565706d61723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e2698e1e58c1f96c287d4398621a3409cb6cd80b87d5f5a3d490cd30c72bd284/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c616e6d656e67796979752f796f6c6f76352d646565706d61723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lanmengyiyu/yolov5-deepmar?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 行人轨迹和属性分析。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zengwb-lx/Yolov5-Deepsort-Fastreid\"\u003ezengwb-lx/Yolov5-Deepsort-Fastreid\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/13f3a37dc4717ab14b686ea63419ea9b14a3875db5ea633c2bee28919b7e4cac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a656e6777622d6c782f596f6c6f76352d44656570736f72742d46617374726569643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/13f3a37dc4717ab14b686ea63419ea9b14a3875db5ea633c2bee28919b7e4cac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a656e6777622d6c782f596f6c6f76352d44656570736f72742d46617374726569643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zengwb-lx/Yolov5-Deepsort-Fastreid?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV5 + deepsort + Fast-ReID 完整行人重识别系统。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tensorturtle/classy-sort-yolov5\"\u003etensorturtle/classy-sort-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a3e0ebefd361ea0bb2e883d7ac105fbd0bc67e6192534631f628b1ca70787233/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74656e736f72747572746c652f636c617373792d736f72742d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a3e0ebefd361ea0bb2e883d7ac105fbd0bc67e6192534631f628b1ca70787233/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74656e736f72747572746c652f636c617373792d736f72742d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tensorturtle/classy-sort-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Ready-to-use realtime multi-object tracker that works for any object category. YOLOv5 + SORT implementation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/supperted825/FairMOT-X\"\u003esupperted825/FairMOT-X\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b4def26ffefb7c772395f004f30fd2a693ea4b9b2f4afda1bb8570edeecc2442/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7375707065727465643832352f466169724d4f542d583f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b4def26ffefb7c772395f004f30fd2a693ea4b9b2f4afda1bb8570edeecc2442/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7375707065727465643832352f466169724d4f542d583f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/supperted825/FairMOT-X?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : FairMOT for Multi-Class MOT using YOLOX as Detector.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/deyiwang89/pytorch-yolov7-deepsort\"\u003edeyiwang89/pytorch-yolov7-deepsort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c1ac3640086c592912c2586ed612dc94369d02eed2176c3d9a421ada4194fa2a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6465796977616e6738392f7079746f7263682d796f6c6f76372d64656570736f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c1ac3640086c592912c2586ed612dc94369d02eed2176c3d9a421ada4194fa2a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6465796977616e6738392f7079746f7263682d796f6c6f76372d64656570736f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/deyiwang89/pytorch-yolov7-deepsort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : an implentation of yolov7-deepsort based on pytorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xuarehere/yolovx_deepsort_pytorch\"\u003exuarehere/yolovx_deepsort_pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/dc5d2d943abd157cdc0df39eaf7dfcc6641e75063320653aca6e40e287e7895d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7875617265686572652f796f6c6f76785f64656570736f72745f7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dc5d2d943abd157cdc0df39eaf7dfcc6641e75063320653aca6e40e287e7895d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7875617265686572652f796f6c6f76785f64656570736f72745f7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xuarehere/yolovx_deepsort_pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : this project support the existing yolo detection model algorithm (YOLOv3, YOLOV4, YOLOV4Scaled, YOLOV5, YOLOV6, YOLOV7 ).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/deshwalmahesh/yolov7-deepsort-tracking\"\u003edeshwalmahesh/yolov7-deepsort-tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1782a46c0153a9bb32e17e8d712a0697f78705b018fe20183ad23f649fe98631/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6465736877616c6d61686573682f796f6c6f76372d64656570736f72742d747261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1782a46c0153a9bb32e17e8d712a0697f78705b018fe20183ad23f649fe98631/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6465736877616c6d61686573682f796f6c6f76372d64656570736f72742d747261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/deshwalmahesh/yolov7-deepsort-tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Modular and ready to deploy code to detect and track videos using YOLO-v7 and DeepSORT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RizwanMunawar/yolov7-object-tracking\"\u003eRizwanMunawar/yolov7-object-tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/21f5047a24dcec36ae6bc0b1d80895e127659dbd2ef1b5960057dac6e9689326/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d6f626a6563742d747261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/21f5047a24dcec36ae6bc0b1d80895e127659dbd2ef1b5960057dac6e9689326/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d6f626a6563742d747261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RizwanMunawar/yolov7-object-tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv7 Object Tracking Using PyTorch, OpenCV and Sort Tracking.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RizwanMunawar/yolov5-object-tracking\"\u003eRizwanMunawar/yolov5-object-tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7327b5cf88409de11a1d898aa5a0e57479ef580171fcae5813ec2bcca48c8d39/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76352d6f626a6563742d747261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7327b5cf88409de11a1d898aa5a0e57479ef580171fcae5813ec2bcca48c8d39/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76352d6f626a6563742d747261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RizwanMunawar/yolov5-object-tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 Object Tracking + Detection + Object Blurring + Streamlit Dashboard Using OpenCV, PyTorch and Streamlit.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Smorodov/Multitarget-tracker\"\u003eSmorodov/Multitarget-tracker\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9872c2cce9a4ad31051d24617d7d7afa9f56003d5c3864061875c2083ddf65d4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536d6f726f646f762f4d756c74697461726765742d747261636b65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9872c2cce9a4ad31051d24617d7d7afa9f56003d5c3864061875c2083ddf65d4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536d6f726f646f762f4d756c74697461726765742d747261636b65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Smorodov/Multitarget-tracker?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Multiple Object Tracker, Based on Hungarian algorithm + Kalman filter.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Naughty-Galileo/YoloV5_MCMOT\"\u003eNaughty-Galileo/YoloV5_MCMOT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/446b0f7dcb0ad8091a9cfc77ea5b129a82174c627f02a18b1bb7b80efe4530ac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e6175676874792d47616c696c656f2f596f6c6f56355f4d434d4f543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/446b0f7dcb0ad8091a9cfc77ea5b129a82174c627f02a18b1bb7b80efe4530ac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e6175676874792d47616c696c656f2f596f6c6f56355f4d434d4f543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Naughty-Galileo/YoloV5_MCMOT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 多类别多目标跟踪YoloV5+sort/deepsort/bytetrack/BotSort/motdt.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MuhammadMoinFaisal/YOLOv8-DeepSORT-Object-Tracking\"\u003eMuhammadMoinFaisal/YOLOv8-DeepSORT-Object-Tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/018dc7fafc1d62d25317d39fcc12c0a2472d0bef26a92814de088555080fec03/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d7568616d6d61644d6f696e46616973616c2f594f4c4f76382d44656570534f52542d4f626a6563742d547261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/018dc7fafc1d62d25317d39fcc12c0a2472d0bef26a92814de088555080fec03/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d7568616d6d61644d6f696e46616973616c2f594f4c4f76382d44656570534f52542d4f626a6563742d547261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MuhammadMoinFaisal/YOLOv8-DeepSORT-Object-Tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv8 Object Tracking using PyTorch, OpenCV and DeepSORT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sujanshresstha/YOLO-NAS_DeepSORT\"\u003esujanshresstha/YOLO-NAS_DeepSORT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8e769fcf0c31a4d641d5edb643ea1b3526fb6100ee9e5ef9e6fd4f9a986918c3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756a616e7368726573737468612f594f4c4f2d4e41535f44656570534f52543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8e769fcf0c31a4d641d5edb643ea1b3526fb6100ee9e5ef9e6fd4f9a986918c3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756a616e7368726573737468612f594f4c4f2d4e41535f44656570534f52543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sujanshresstha/YOLO-NAS_DeepSORT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository contains code for object tracking in videos using the YOLO-NAS object detection model and the DeepSORT algorithm.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eDynamic Object Tracking\u003c/h4\u003e\u003ca id=\"user-content-dynamic-object-tracking\" class=\"anchor\" aria-label=\"Permalink: Dynamic Object Tracking\" href=\"#dynamic-object-tracking\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e动态目标跟踪\u003c/h5\u003e\u003ca id=\"user-content-动态目标跟踪\" class=\"anchor\" aria-label=\"Permalink: 动态目标跟踪\" href=\"#动态目标跟踪\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/PolyU-AIRO-Lab/AUTO\"\u003ePolyU-AIRO-Lab/AUTO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6deaf090abd7080177b1581953d345170dd8610b06239131dd93d2b2d91eb4c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506f6c79552d4149524f2d4c61622f4155544f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6deaf090abd7080177b1581953d345170dd8610b06239131dd93d2b2d91eb4c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506f6c79552d4149524f2d4c61622f4155544f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PolyU-AIRO-Lab/AUTO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Dynamic Object Tracking on Autonomous UAV System for Surveillance Applications\". (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/1424-8220/21/23/7888\" rel=\"nofollow\"\u003eSensors 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eDeep Reinforcement Learning\u003c/h4\u003e\u003ca id=\"user-content-deep-reinforcement-learning\" class=\"anchor\" aria-label=\"Permalink: Deep Reinforcement Learning\" href=\"#deep-reinforcement-learning\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e深度强化学习\u003c/h4\u003e\u003ca id=\"user-content-深度强化学习\" class=\"anchor\" aria-label=\"Permalink: 深度强化学习\" href=\"#深度强化学习\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/uzkent/EfficientObjectDetection\"\u003euzkent/EfficientObjectDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0e44dc6bdfe533c1e9480a596644652a5aef1cbbf59b7872670372ef1c34abbb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f757a6b656e742f456666696369656e744f626a656374446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0e44dc6bdfe533c1e9480a596644652a5aef1cbbf59b7872670372ef1c34abbb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f757a6b656e742f456666696369656e744f626a656374446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/uzkent/EfficientObjectDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Efficient Object Detection in Large Images with Deep Reinforcement Learning\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_WACV_2020/html/Uzkent_Efficient_Object_Detection_in_Large_Images_Using_Deep_Reinforcement_Learning_WACV_2020_paper.html\" rel=\"nofollow\"\u003eWACV 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eMotion Control Field\u003c/h4\u003e\u003ca id=\"user-content-motion-control-field\" class=\"anchor\" aria-label=\"Permalink: Motion Control Field\" href=\"#motion-control-field\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e运动控制领域\u003c/h4\u003e\u003ca id=\"user-content-运动控制领域\" class=\"anchor\" aria-label=\"Permalink: 运动控制领域\" href=\"#运动控制领域\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/icns-distributed-cloud/adaptive-cruise-control\"\u003eicns-distributed-cloud/adaptive-cruise-control\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/31e21e3d3f47ed0227e040f6bf2334b4430563ba34f41b10f272b937fbb2c1db/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69636e732d64697374726962757465642d636c6f75642f61646170746976652d6372756973652d636f6e74726f6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/31e21e3d3f47ed0227e040f6bf2334b4430563ba34f41b10f272b937fbb2c1db/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69636e732d64697374726962757465642d636c6f75642f61646170746976652d6372756973652d636f6e74726f6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/icns-distributed-cloud/adaptive-cruise-control?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO-v5 기반 \"단안 카메라\"의 영상을 활용해 차간 거리를 일정하게 유지하며 주행하는 Adaptive Cruise Control 기능 구현.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LeBronLiHD/ZJU2021_MotionControl_PID_YOLOv5\"\u003eLeBronLiHD/ZJU2021_MotionControl_PID_YOLOv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d50da264fbc427b07f5e5b3083d990ad22327ecfd941c43ecb2206dc62211860/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c6542726f6e4c6948442f5a4a55323032315f4d6f74696f6e436f6e74726f6c5f5049445f594f4c4f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d50da264fbc427b07f5e5b3083d990ad22327ecfd941c43ecb2206dc62211860/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c6542726f6e4c6948442f5a4a55323032315f4d6f74696f6e436f6e74726f6c5f5049445f594f4c4f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LeBronLiHD/ZJU2021_MotionControl_PID_YOLOv5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ZJU2021_MotionControl_PID_YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SananSuleymanov/PID_YOLOv5s_ROS_Diver_Tracking\"\u003eSananSuleymanov/PID_YOLOv5s_ROS_Diver_Tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fa71ca94fdb7ee0e0486e55860d60311fdd1ab595d3d6cdb78969e68fee64916/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53616e616e53756c65796d616e6f762f5049445f594f4c4f7635735f524f535f44697665725f547261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fa71ca94fdb7ee0e0486e55860d60311fdd1ab595d3d6cdb78969e68fee64916/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53616e616e53756c65796d616e6f762f5049445f594f4c4f7635735f524f535f44697665725f547261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SananSuleymanov/PID_YOLOv5s_ROS_Diver_Tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PID_YOLOv5s_ROS_Diver_Tracking.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sumght-z/apex_yolov5\"\u003esumght-z/apex_yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ba77efd812f1d40955bd08010cdc4afc044438aaa74b8b52a501bd954944a9a6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756d6768742d7a2f617065785f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ba77efd812f1d40955bd08010cdc4afc044438aaa74b8b52a501bd954944a9a6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756d6768742d7a2f617065785f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sumght-z/apex_yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : something by yolov5 and PID.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSuper-Resolution Field\u003c/h4\u003e\u003ca id=\"user-content-super-resolution-field\" class=\"anchor\" aria-label=\"Permalink: Super-Resolution Field\" href=\"#super-resolution-field\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e超分辨率领域\u003c/h4\u003e\u003ca id=\"user-content-超分辨率领域\" class=\"anchor\" aria-label=\"Permalink: 超分辨率领域\" href=\"#超分辨率领域\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/Fireboltz/Psychic-CCTV\"\u003eFireboltz/Psychic-CCTV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b4a0523234bbf50f90d87f13709ae100437484457815c6523f4d79b488092a75/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46697265626f6c747a2f507379636869632d434354563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b4a0523234bbf50f90d87f13709ae100437484457815c6523f4d79b488092a75/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46697265626f6c747a2f507379636869632d434354563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Fireboltz/Psychic-CCTV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A video analysis tool built completely in python.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSpiking Neural Network\u003c/h4\u003e\u003ca id=\"user-content-spiking-neural-network\" class=\"anchor\" aria-label=\"Permalink: Spiking Neural Network\" href=\"#spiking-neural-network\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSNN, 脉冲神经网络\u003c/h4\u003e\u003ca id=\"user-content-snn-脉冲神经网络\" class=\"anchor\" aria-label=\"Permalink: SNN, 脉冲神经网络\" href=\"#snn-脉冲神经网络\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BICLab/SpikeYOLO\"\u003eSpikeYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/41a0050325c28ee3f18f80d7c7b5ebe9cf4505b2ddf3838c99fe9eb5648a51c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f5370696b65594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/41a0050325c28ee3f18f80d7c7b5ebe9cf4505b2ddf3838c99fe9eb5648a51c4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f5370696b65594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BICLab/SpikeYOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Offical implementation of \"Integer-Valued Training and Spike-Driven Inference Spiking Neural Network for High-performance and Energy-efficient Object Detection\" (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2407.20708\" rel=\"nofollow\"\u003eECCV 2024 Oral\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BICLab/EMS-YOLO\"\u003eEMS-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8897198d23a8f79c45c3d4156f7537b42f0540dc212dfc741a71f37cf2fa8d95/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f454d532d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8897198d23a8f79c45c3d4156f7537b42f0540dc212dfc741a71f37cf2fa8d95/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f454d532d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BICLab/EMS-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Offical implementation of \"Deep Directly-Trained Spiking Neural Networks for Object Detection\" (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/ICCV2023/html/Su_Deep_Directly-Trained_Spiking_Neural_Networks_for_Object_Detection_ICCV_2023_paper.html\" rel=\"nofollow\"\u003eICCV 2023\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BICLab/Attention-SNN\"\u003eAttention-SNN\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/be6c15e9a289cc50c46a51964acba8a0d7607c3b2cdb7635dc98cc6b75152abf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f417474656e74696f6e2d534e4e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/be6c15e9a289cc50c46a51964acba8a0d7607c3b2cdb7635dc98cc6b75152abf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f417474656e74696f6e2d534e4e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BICLab/Attention-SNN?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Offical implementation of \"Attention Spiking Neural Networks\" (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/10032591\" rel=\"nofollow\"\u003eIEEE TPAMI 2023\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BICLab/Spike-Driven-Transformer\"\u003eSpike-Driven-Transformer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/334f77eed46cdea5ba7e395ae56bb5033f93d21645a71b90639bd1bff7b54887/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f5370696b652d44726976656e2d5472616e73666f726d65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/334f77eed46cdea5ba7e395ae56bb5033f93d21645a71b90639bd1bff7b54887/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f5370696b652d44726976656e2d5472616e73666f726d65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BICLab/Spike-Driven-Transformer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Offical implementation of \"Spike-driven Transformer\" (\u003cstrong\u003e\u003ca href=\"https://openreview.net/forum?id=9FmolyOHi5\" rel=\"nofollow\"\u003eNeurIPS 2023\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BICLab/Spike-Driven-Transformer-V2\"\u003eSpike-Driven-Transformer-V2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/10d2ea5bc789cf7b780cc3fca3a4dcdc28f302d20cf45b2e18def7b96f78b40f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f5370696b652d44726976656e2d5472616e73666f726d65722d56323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/10d2ea5bc789cf7b780cc3fca3a4dcdc28f302d20cf45b2e18def7b96f78b40f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4249434c61622f5370696b652d44726976656e2d5472616e73666f726d65722d56323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BICLab/Spike-Driven-Transformer-V2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Offical implementation of \"Spike-driven Transformer V2: Meta Spiking Neural Network Architecture Inspiring the Design of Next-generation Neuromorphic Chips\" (\u003cstrong\u003e\u003ca href=\"https://openreview.net/forum?id=1SIBN5Xyw7\" rel=\"nofollow\"\u003eICLR 2024\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cwq159/PyTorch-Spiking-YOLOv3\"\u003eSpiking-YOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/71c7028763ccd0ce46c8757d0a13422483ac5a7019de0437c1bd91f8f0413bc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6377713135392f5079546f7263682d5370696b696e672d594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/71c7028763ccd0ce46c8757d0a13422483ac5a7019de0437c1bd91f8f0413bc6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6377713135392f5079546f7263682d5370696b696e672d594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cwq159/PyTorch-Spiking-YOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A PyTorch implementation of Spiking-YOLOv3. Two branches are provided, based on two common PyTorch implementation of YOLOv3(\u003ca href=\"https://github.com/ultralytics/yolov3\"\u003eultralytics/yolov3\u003c/a\u003e \u0026amp; \u003ca href=\"https://github.com/eriklindernoren/PyTorch-YOLOv3\"\u003eeriklindernoren/PyTorch-YOLOv3\u003c/a\u003e), with support for Spiking-YOLOv3-Tiny at present. (\u003cstrong\u003e\u003ca href=\"https://ojs.aaai.org/index.php/AAAI/article/view/6787\" rel=\"nofollow\"\u003eAAAI 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fjcu-ee-islab/Spiking_Converted_YOLOv4\"\u003efjcu-ee-islab/Spiking_Converted_YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e6d346e5d914106b0ce88895ef1b7ed9b1f7fd4d7b9aca19b5e904bc5e0f5a76/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666a63752d65652d69736c61622f5370696b696e675f436f6e7665727465645f594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e6d346e5d914106b0ce88895ef1b7ed9b1f7fd4d7b9aca19b5e904bc5e0f5a76/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666a63752d65652d69736c61622f5370696b696e675f436f6e7665727465645f594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/fjcu-ee-islab/Spiking_Converted_YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object Detection Based on Dynamic Vision Sensor with Spiking Neural Network.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Zaabon/spiking_yolo\"\u003eZaabon/spiking_yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/804493d306470af6971dea8b70a9ff32414748ac56a60cc21aef6b3afa4b7a6a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a6161626f6e2f7370696b696e675f796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/804493d306470af6971dea8b70a9ff32414748ac56a60cc21aef6b3afa4b7a6a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a6161626f6e2f7370696b696e675f796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Zaabon/spiking_yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This project is a combined neural network utilizing an spiking CNN with backpropagation and YOLOv3 for object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Dignity-ghost/PyTorch-Spiking-YOLOv3\"\u003eDignity-ghost/PyTorch-Spiking-YOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5b1d3c06a4d9c751c551c6365468a64af4cb0f1ed1fed85c70092a4f447b5735/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4469676e6974792d67686f73742f5079546f7263682d5370696b696e672d594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5b1d3c06a4d9c751c551c6365468a64af4cb0f1ed1fed85c70092a4f447b5735/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4469676e6974792d67686f73742f5079546f7263682d5370696b696e672d594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Dignity-ghost/PyTorch-Spiking-YOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A modified repository based on \u003ca href=\"https://github.com/cwq159/PyTorch-Spiking-YOLOv3\"\u003eSpiking-YOLOv3\u003c/a\u003e and \u003ca href=\"https://pjreddie.com/darknet/yolo\" rel=\"nofollow\"\u003eYOLOv3\u003c/a\u003e, which makes it suitable for VOC-dataset and YOLOv2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/beauty-girl-cxy/spiking-yolov5\"\u003ebeauty-girl-cxy/spiking-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1186151c1028620e7494a9646e9d34e66e07f7111028755240f55945fe96a235/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6265617574792d6769726c2d6378792f7370696b696e672d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1186151c1028620e7494a9646e9d34e66e07f7111028755240f55945fe96a235/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6265617574792d6769726c2d6378792f7370696b696e672d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/beauty-girl-cxy/spiking-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : spiking-yolov5.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAttention and Transformer\u003c/h4\u003e\u003ca id=\"user-content-attention-and-transformer\" class=\"anchor\" aria-label=\"Permalink: Attention and Transformer\" href=\"#attention-and-transformer\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e注意力机制\u003c/h4\u003e\u003ca id=\"user-content-注意力机制\" class=\"anchor\" aria-label=\"Permalink: 注意力机制\" href=\"#注意力机制\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xmu-xiaoma666/External-Attention-pytorch\"\u003exmu-xiaoma666/External-Attention-pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0887e57d805705f73c1fecb4d4ed81ad30e39ecb36486deed4a2606efcbd7fd0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f786d752d7869616f6d613636362f45787465726e616c2d417474656e74696f6e2d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0887e57d805705f73c1fecb4d4ed81ad30e39ecb36486deed4a2606efcbd7fd0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f786d752d7869616f6d613636362f45787465726e616c2d417474656e74696f6e2d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xmu-xiaoma666/External-Attention-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🍀 Pytorch implementation of various Attention Mechanisms, MLP, Re-parameter, Convolution, which is helpful to further understand papers.⭐⭐⭐.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MenghaoGuo/Awesome-Vision-Attentions\"\u003eMenghaoGuo/Awesome-Vision-Attentions\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d65d130c14de8312a4e4d17311bdd340eafbdb3a02a2520f872e648fcfd6085c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d656e6768616f47756f2f417765736f6d652d566973696f6e2d417474656e74696f6e733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d65d130c14de8312a4e4d17311bdd340eafbdb3a02a2520f872e648fcfd6085c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d656e6768616f47756f2f417765736f6d652d566973696f6e2d417474656e74696f6e733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MenghaoGuo/Awesome-Vision-Attentions?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Summary of related papers on visual attention. Related code will be released based on Jittor gradually. \"Attention Mechanisms in Computer Vision: A Survey\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2111.07624\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pprp/awesome-attention-mechanism-in-cv\"\u003epprp/awesome-attention-mechanism-in-cv\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/49500e7c2920ff7778564c00d590a0d3c820bb53a559ba7eeb6380805ca44d6c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f707072702f617765736f6d652d617474656e74696f6e2d6d656368616e69736d2d696e2d63763f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/49500e7c2920ff7778564c00d590a0d3c820bb53a559ba7eeb6380805ca44d6c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f707072702f617765736f6d652d617474656e74696f6e2d6d656368616e69736d2d696e2d63763f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pprp/awesome-attention-mechanism-in-cv?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 👊 CV中常用注意力模块;即插即用模块;ViT模型. PyTorch Implementation Collection of Attention Module and Plug\u0026amp;Play Module.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bfshi/AbSViT\"\u003eAbSViT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a84aa393bbc6b480e4f0182eb775e352849c360c1f05b8c2ea5a57d6fab97261/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62667368692f4162535669543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a84aa393bbc6b480e4f0182eb775e352849c360c1f05b8c2ea5a57d6fab97261/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62667368692f4162535669543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bfshi/AbSViT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Top-Down Visual Attention from Analysis by Synthesis\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2303.13043\" rel=\"nofollow\"\u003eCVPR 2023\u003c/a\u003e\u003c/strong\u003e). \"微信公众号「人工智能前沿讲习」《\u003ca href=\"https://mp.weixin.qq.com/s/FtVd37tOXMfu92eDSvdvbg\" rel=\"nofollow\"\u003e【源头活水】CVPR 2023 | AbSViT：拥有自上而下注意力机制的视觉Transformer\u003c/a\u003e》\"。 \"微信公众号「极市平台」《\u003ca href=\"https://mp.weixin.qq.com/s/UMA3Vk9L71zUEtNkCshYBg\" rel=\"nofollow\"\u003eCVPR23 Highlight｜拥有top-down attention能力的vision transformer\u003c/a\u003e》\"。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HaloTrouvaille/YOLO-Multi-Backbones-Attention\"\u003eHaloTrouvaille/YOLO-Multi-Backbones-Attention\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/08faf0c8b6c0aa04dc2c771b4d3ac11a36bfed368b582663b04a481ca378dcb7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48616c6f54726f757661696c6c652f594f4c4f2d4d756c74692d4261636b626f6e65732d417474656e74696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/08faf0c8b6c0aa04dc2c771b4d3ac11a36bfed368b582663b04a481ca378dcb7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48616c6f54726f757661696c6c652f594f4c4f2d4d756c74692d4261636b626f6e65732d417474656e74696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HaloTrouvaille/YOLO-Multi-Backbones-Attention?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This Repository includes YOLOv3 with some lightweight backbones (ShuffleNetV2, GhostNet, VoVNet), some computer vision attention mechanism (SE Block, CBAM Block, ECA Block), pruning,quantization and distillation for GhostNet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kay-cottage/CoordAttention_YOLOX_Pytorch\"\u003ekay-cottage/CoordAttention_YOLOX_Pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7fa5da34a8ffd9988914ff42e50b7724c4986ca8ffb046dd2ae90717703befde/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b61792d636f74746167652f436f6f7264417474656e74696f6e5f594f4c4f585f5079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7fa5da34a8ffd9988914ff42e50b7724c4986ca8ffb046dd2ae90717703befde/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b61792d636f74746167652f436f6f7264417474656e74696f6e5f594f4c4f585f5079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kay-cottage/CoordAttention_YOLOX_Pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : CoordAttention_YOLOX(基于CoordAttention坐标注意力机制的改进版YOLOX目标检测平台）。 \"Coordinate Attention for Efficient Mobile Network Design\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Coordinate_Attention_for_Efficient_Mobile_Network_Design_CVPR_2021_paper.html\" rel=\"nofollow\"\u003eCVPR 2021\u003c/a\u003e, \u003ca href=\"https://github.com/Andrew-Qibin/CoordAttention\"\u003e Andrew-Qibin/CoordAttention\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/liangzhendong123/Attention-yolov5\"\u003eliangzhendong123/Attention-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/90e9149d693c82a2b030c7fc2b7d8757b91d2000efbee7b20f42c757f048698e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c69616e677a68656e646f6e673132332f417474656e74696f6e2d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/90e9149d693c82a2b030c7fc2b7d8757b91d2000efbee7b20f42c757f048698e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c69616e677a68656e646f6e673132332f417474656e74696f6e2d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/liangzhendong123/Attention-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于注意力机制改进的yolov5模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/e96031413/AA-YOLO\"\u003ee96031413/AA-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7984c9687ad284d360bd4ccc7f3d0fe127c4db863b4c99a2e428ddb57ef84428/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6539363033313431332f41412d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7984c9687ad284d360bd4ccc7f3d0fe127c4db863b4c99a2e428ddb57ef84428/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6539363033313431332f41412d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/e96031413/AA-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Attention ALL-CNN Twin Head YOLO (AA -YOLO). \"Improving Tiny YOLO with Fewer Model Parameters\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9643269/\" rel=\"nofollow\"\u003eIEEE BigMM 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/anonymoussss/YOLOX-SwinTransformer\"\u003eanonymoussss/YOLOX-SwinTransformer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9bebcc34b289a647b87f898c74e10f6e8fd30375c412d1866eda8a4658643a56/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616e6f6e796d6f75737373732f594f4c4f582d5377696e5472616e73666f726d65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9bebcc34b289a647b87f898c74e10f6e8fd30375c412d1866eda8a4658643a56/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616e6f6e796d6f75737373732f594f4c4f582d5377696e5472616e73666f726d65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/anonymoussss/YOLOX-SwinTransformer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOX with Swin-Transformer backbone.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/GuanRunwei/MAN-and-CAT\"\u003eGuanRunwei/MAN-and-CAT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6a04407121cce96b2506fd2074723d3e51e97e378493a4930505c32639762fa6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4775616e52756e7765692f4d414e2d616e642d4341543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6a04407121cce96b2506fd2074723d3e51e97e378493a4930505c32639762fa6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4775616e52756e7765692f4d414e2d616e642d4341543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/GuanRunwei/MAN-and-CAT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"MAN and CAT: mix attention to nn and concatenate attention to YOLO\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/article/10.1007/s11227-022-04726-7\" rel=\"nofollow\"\u003e The Journal of Supercomputing, 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOriented Object Detection\u003c/h3\u003e\u003ca id=\"user-content-oriented-object-detection\" class=\"anchor\" aria-label=\"Permalink: Oriented Object Detection\" href=\"#oriented-object-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e旋转目标检测\u003c/h4\u003e\u003ca id=\"user-content-旋转目标检测\" class=\"anchor\" aria-label=\"Permalink: 旋转目标检测\" href=\"#旋转目标检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yangxue0827/RotationDetection\"\u003eAlphaRotate\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/41112f1983c41f2de4c34cfeb65a93a8590220fd6f28ed1d385c35d560644573/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f79616e67787565303832372f526f746174696f6e446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/41112f1983c41f2de4c34cfeb65a93a8590220fd6f28ed1d385c35d560644573/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f79616e67787565303832372f526f746174696f6e446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"AlphaRotate: A Rotation Detection Benchmark using TensorFlow\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2111.06677\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hukaixuan19970627/yolov5_obb\"\u003ehukaixuan19970627/yolov5_obb\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e9fe5fdf7c9a8b61d9451d5ff326e88b0861bac8fcb7af3f326b7b5298ad134a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756b61697875616e31393937303632372f796f6c6f76355f6f62623f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e9fe5fdf7c9a8b61d9451d5ff326e88b0861bac8fcb7af3f326b7b5298ad134a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756b61697875616e31393937303632372f796f6c6f76355f6f62623f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hukaixuan19970627/yolov5_obb?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5 + csl_label.(Oriented Object Detection)（Rotation Detection）（Rotated BBox）基于yolov5的旋转目标检测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BossZard/rotation-yolov5\"\u003eBossZard/rotation-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a35ec3fedaa6879f5cb1fecb7723572b0597ba69b0935885ac2eb43a7ede5e0b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f73735a6172642f726f746174696f6e2d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a35ec3fedaa6879f5cb1fecb7723572b0597ba69b0935885ac2eb43a7ede5e0b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f73735a6172642f726f746174696f6e2d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BossZard/rotation-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : rotation detection based on yolov5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/acai66/yolov5_rotation\"\u003eacai66/yolov5_rotation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0bd159beded6b8fb1185351a399156ffee972a215ec9fbf48965bb179f0cb64a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6163616936362f796f6c6f76355f726f746174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0bd159beded6b8fb1185351a399156ffee972a215ec9fbf48965bb179f0cb64a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6163616936362f796f6c6f76355f726f746174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/acai66/yolov5_rotation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : rotated bbox detection. inspired by \u003ca href=\"https://github.com/hukaixuan19970627/yolov5_obb\"\u003ehukaixuan19970627/yolov5_obb\u003c/a\u003e, thanks hukaixuan19970627.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ming71/rotate-yolov3\"\u003eming71/rotate-yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e2c510accffc368312c44787609c2f986e379350fd7747801e39b19e50a1567e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696e6737312f726f746174652d796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e2c510accffc368312c44787609c2f986e379350fd7747801e39b19e50a1567e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696e6737312f726f746174652d796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ming71/rotate-yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Arbitrary oriented object detection implemented with yolov3 (attached with some tricks).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ming71/yolov3-polygon\"\u003eming71/yolov3-polygon\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/47e6b51244f178af5139b817ace3ac434b26863b1f3b3c12b90cdd6d39bba6fd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696e6737312f796f6c6f76332d706f6c79676f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/47e6b51244f178af5139b817ace3ac434b26863b1f3b3c12b90cdd6d39bba6fd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696e6737312f796f6c6f76332d706f6c79676f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ming71/yolov3-polygon?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Arbitrary-oriented object detection based on yolov3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kunnnnethan/R-YOLOv4\"\u003ekunnnnethan/R-YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cc3d29dfdfaec77ee17ec13575e9757f7caf600b61d93edb2d39a0a01a9aada8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b756e6e6e6e657468616e2f522d594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cc3d29dfdfaec77ee17ec13575e9757f7caf600b61d93edb2d39a0a01a9aada8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b756e6e6e6e657468616e2f522d594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kunnnnethan/R-YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a PyTorch-based R-YOLOv4 implementation which combines YOLOv4 model and loss function from R3Det for arbitrary oriented object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/XinzeLee/PolygonObjectDetection\"\u003eXinzeLee/PolygonObjectDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/96240edc0d6c0ec2ad319a476dbf633907407b649ee8ea4fe843e311746da2a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f58696e7a654c65652f506f6c79676f6e4f626a656374446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/96240edc0d6c0ec2ad319a476dbf633907407b649ee8ea4fe843e311746da2a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f58696e7a654c65652f506f6c79676f6e4f626a656374446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/XinzeLee/PolygonObjectDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository is based on Ultralytics/yolov5, with adjustments to enable polygon prediction boxes.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hukaixuan19970627/DOTA_devkit_YOLO\"\u003ehukaixuan19970627/DOTA_devkit_YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8d887a1059dd354b9f195e0eab2090df12da6d6b20d9a58ca69dba2c1991b2bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756b61697875616e31393937303632372f444f54415f6465766b69745f594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8d887a1059dd354b9f195e0eab2090df12da6d6b20d9a58ca69dba2c1991b2bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756b61697875616e31393937303632372f444f54415f6465766b69745f594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hukaixuan19970627/DOTA_devkit_YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Trans DOTA OBB format(poly format) to YOLO format.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hpc203/rotate-yolov5-opencv-onnxrun\"\u003ehpc203/rotate-yolov5-opencv-onnxrun\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8e33cb3bec04e1fc67f631757f2819a117660378a217997f37b0afd0acbdd0f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f726f746174652d796f6c6f76352d6f70656e63762d6f6e6e7872756e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8e33cb3bec04e1fc67f631757f2819a117660378a217997f37b0afd0acbdd0f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f726f746174652d796f6c6f76352d6f70656e63762d6f6e6e7872756e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hpc203/rotate-yolov5-opencv-onnxrun?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 分别使用OpenCV、ONNXRuntime部署yolov5旋转目标检测，包含C++和Python两个版本的程序。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hpc203/rotateyolov5-opencv-onnxrun\"\u003ehpc203/rotateyolov5-opencv-onnxrun\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d66bd312942fcfcd8ed8255b80d3b4e062c2c9552f5c15badbcb734f802a0139/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f726f74617465796f6c6f76352d6f70656e63762d6f6e6e7872756e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d66bd312942fcfcd8ed8255b80d3b4e062c2c9552f5c15badbcb734f802a0139/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f726f74617465796f6c6f76352d6f70656e63762d6f6e6e7872756e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hpc203/rotateyolov5-opencv-onnxrun?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 分别使用OpenCV，ONNXRuntime部署yolov5旋转目标检测，包含C++和Python两个版本的程序。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kunnnnethan/R-YOLOv4\"\u003ekunnnnethan/R-YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cc3d29dfdfaec77ee17ec13575e9757f7caf600b61d93edb2d39a0a01a9aada8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b756e6e6e6e657468616e2f522d594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cc3d29dfdfaec77ee17ec13575e9757f7caf600b61d93edb2d39a0a01a9aada8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b756e6e6e6e657468616e2f522d594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kunnnnethan/R-YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a PyTorch-based R-YOLOv4 implementation which combines YOLOv4 model and loss function from R3Det for arbitrary oriented object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DDGRCF/YOLOX_OBB\"\u003eDDGRCF/YOLOX_OBB\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a03ee927d8a7c3326152b2dc45ddb6e5bb44a6145f38b930d0602ef9eafee64c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4444475243462f594f4c4f585f4f42423f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a03ee927d8a7c3326152b2dc45ddb6e5bb44a6145f38b930d0602ef9eafee64c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4444475243462f594f4c4f585f4f42423f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DDGRCF/YOLOX_OBB?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOX OBB -- YOLOX 旋转框 | 实例分割。 \"知乎「刀刀狗」《\u003ca href=\"https://zhuanlan.zhihu.com/p/430850089\" rel=\"nofollow\"\u003eYOLOX OBB -- YOLOX 旋转框检测 超详细！！！\u003c/a\u003e》\"。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFace Detection and Recognition\u003c/h3\u003e\u003ca id=\"user-content-face-detection-and-recognition\" class=\"anchor\" aria-label=\"Permalink: Face Detection and Recognition\" href=\"#face-detection-and-recognition\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e人脸检测与识别\u003c/h4\u003e\u003ca id=\"user-content-人脸检测与识别\" class=\"anchor\" aria-label=\"Permalink: 人脸检测与识别\" href=\"#人脸检测与识别\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFace Detection\u003c/h4\u003e\u003ca id=\"user-content-face-detection\" class=\"anchor\" aria-label=\"Permalink: Face Detection\" href=\"#face-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e人脸检测\u003c/h5\u003e\u003ca id=\"user-content-人脸检测\" class=\"anchor\" aria-label=\"Permalink: 人脸检测\" href=\"#人脸检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/deepcam-cn/yolov5-face\"\u003eYOLO5Face\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4c32e6a91c4985713558371cdd4ffe7ac8118ef1ff65091c6ee141d208f2a3ea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6465657063616d2d636e2f796f6c6f76352d666163653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4c32e6a91c4985713558371cdd4ffe7ac8118ef1ff65091c6ee141d208f2a3ea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6465657063616d2d636e2f796f6c6f76352d666163653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/deepcam-cn/yolov5-face?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLO5Face: Why Reinventing a Face Detector\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2105.12931\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/derronqi/yolov7-face\"\u003ederronqi/yolov7-face\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/17ae4027ac3419236d1513be25e5f6941d2af70754d6b74f2dc30fcfbac60a1c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646572726f6e71692f796f6c6f76372d666163653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/17ae4027ac3419236d1513be25e5f6941d2af70754d6b74f2dc30fcfbac60a1c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646572726f6e71692f796f6c6f76372d666163653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/derronqi/yolov7-face?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov7 face detection with landmark.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/derronqi/yolov8-face\"\u003ederronqi/yolov8-face\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cceecedda4966f36ee97fd68f8038795e869181c79c492aaddee25e607096eea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646572726f6e71692f796f6c6f76382d666163653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cceecedda4966f36ee97fd68f8038795e869181c79c492aaddee25e607096eea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646572726f6e71692f796f6c6f76382d666163653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/derronqi/yolov8-face?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov8 face detection with landmark.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/we0091234/yolov7-face-tensorrt\"\u003ewe0091234/yolov7-face-tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2418af45fe283c1c274583e2fa41dba27dd91c0ad2a467856dfd527d7b18dab7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7765303039313233342f796f6c6f76372d666163652d74656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2418af45fe283c1c274583e2fa41dba27dd91c0ad2a467856dfd527d7b18dab7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7765303039313233342f796f6c6f76372d666163652d74656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/we0091234/yolov7-face-tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov7-face TensorRT.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Krasjet-Yu/YOLO-FaceV2\"\u003eYOLO-FaceV2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5782c769c2cc4c0b8544e79871a22d7e82121ec9fd9a724394b543fceea7cf4e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b7261736a65742d59752f594f4c4f2d4661636556323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5782c769c2cc4c0b8544e79871a22d7e82121ec9fd9a724394b543fceea7cf4e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b7261736a65742d59752f594f4c4f2d4661636556323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Krasjet-Yu/YOLO-FaceV2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLO-FaceV2: A Scale and Occlusion Aware Face Detector \". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2208.02019\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e). \"微信公众号「江大白」《\u003ca href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NzgyNTU2Mg==\u0026amp;mid=2247498561\u0026amp;idx=1\u0026amp;sn=b7ff0592644ab6bc5b716e07294e1c0a\u0026amp;source=41#wechat_redirect\" rel=\"nofollow\"\u003e超越Yolo5-Face，Yolo-Facev2开源，各类Trick优化，值得学习！\u003c/a\u003e》\"\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/OAID/TengineKit\"\u003eOAID/TengineKit\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/220a8a434643f00b6c4f196539df6d1018417bfa13b1beb38f461a82d299021b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f4149442f54656e67696e654b69743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/220a8a434643f00b6c4f196539df6d1018417bfa13b1beb38f461a82d299021b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f4149442f54656e67696e654b69743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/OAID/TengineKit?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : TengineKit - Free, Fast, Easy, Real-Time Face Detection \u0026amp; Face Landmarks \u0026amp; Face Attributes \u0026amp; Hand Detection \u0026amp; Hand Landmarks \u0026amp; Body Detection \u0026amp; Body Landmarks \u0026amp; Iris Landmarks \u0026amp; Yolov5 SDK On Mobile.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xialuxi/yolov5_face_landmark\"\u003exialuxi/yolov5_face_landmark\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c06761e25c69b83809153b5b05572d8e461133c13abbcc0e7d72a33cb5ececf8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616c7578692f796f6c6f76355f666163655f6c616e646d61726b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c06761e25c69b83809153b5b05572d8e461133c13abbcc0e7d72a33cb5ececf8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616c7578692f796f6c6f76355f666163655f6c616e646d61726b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xialuxi/yolov5_face_landmark?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于yolov5的人脸检测，带关键点检测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sthanhng/yoloface\"\u003esthanhng/yoloface\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a8eab5898fb592aaa838b4e1e4b3bc7be446d16deb1217d7153133b1647e7270/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737468616e686e672f796f6c6f666163653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a8eab5898fb592aaa838b4e1e4b3bc7be446d16deb1217d7153133b1647e7270/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737468616e686e672f796f6c6f666163653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sthanhng/yoloface?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Deep learning-based Face detection using the YOLOv3 algorithm.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DayBreak-u/yolo-face-with-landmark\"\u003eDayBreak-u/yolo-face-with-landmark\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5c5ef4e269674c01280fee750aa0988252ea82714bcb75db841e91d46be00c14/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f446179427265616b2d752f796f6c6f2d666163652d776974682d6c616e646d61726b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5c5ef4e269674c01280fee750aa0988252ea82714bcb75db841e91d46be00c14/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f446179427265616b2d752f796f6c6f2d666163652d776974682d6c616e646d61726b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DayBreak-u/yolo-face-with-landmark?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yoloface大礼包 使用pytroch实现的基于yolov3的轻量级人脸检测（包含关键点）。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/abars/YoloKerasFaceDetection\"\u003eabars/YoloKerasFaceDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bdf9e9f5bc17cc911d8ad32812723301bf8b22c0e52d94c00d89820d0eda65c0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61626172732f596f6c6f4b6572617346616365446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bdf9e9f5bc17cc911d8ad32812723301bf8b22c0e52d94c00d89820d0eda65c0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61626172732f596f6c6f4b6572617346616365446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/abars/YoloKerasFaceDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Face Detection and Gender and Age Classification using Keras.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dannyblueliu/YOLO-Face-detection\"\u003edannyblueliu/YOLO-Face-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c42e99f69e11984caf6d0992f28293a81147f7fd2041d1ea8e70de1b95af7474/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64616e6e79626c75656c69752f594f4c4f2d466163652d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c42e99f69e11984caf6d0992f28293a81147f7fd2041d1ea8e70de1b95af7474/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64616e6e79626c75656c69752f594f4c4f2d466163652d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dannyblueliu/YOLO-Face-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Face detection based on YOLO darknet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wmylxmj/YOLO-V3-IOU\"\u003ewmylxmj/YOLO-V3-IOU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/42d860822d2f0cdd665a860131b57f44de8d6ea48641a0b8b6a6d1303cc971c0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776d796c786d6a2f594f4c4f2d56332d494f553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/42d860822d2f0cdd665a860131b57f44de8d6ea48641a0b8b6a6d1303cc971c0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776d796c786d6a2f594f4c4f2d56332d494f553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wmylxmj/YOLO-V3-IOU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO3 动漫人脸检测 (Based on keras and tensorflow) 2019-1-19.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pranoyr/head-detection-using-yolo\"\u003epranoyr/head-detection-using-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3d1b4d4e076a5d6c1017b73291c99f3185e871d8e3702f83a39b2188ffe3c261/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7072616e6f79722f686561642d646574656374696f6e2d7573696e672d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3d1b4d4e076a5d6c1017b73291c99f3185e871d8e3702f83a39b2188ffe3c261/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7072616e6f79722f686561642d646574656374696f6e2d7573696e672d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pranoyr/head-detection-using-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detection of head using YOLO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/grapeot/AnimeHeadDetector\"\u003egrapeot/AnimeHeadDetector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/56c2a76bd05bb26be118cc7efb3efa51d2d57e67d02d9e2a3164524b81552b60/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67726170656f742f416e696d65486561644465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/56c2a76bd05bb26be118cc7efb3efa51d2d57e67d02d9e2a3164524b81552b60/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67726170656f742f416e696d65486561644465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/grapeot/AnimeHeadDetector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An object detector for character heads in animes, based on Yolo V3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Chenyang-ZHU/YOLOv3-Based-Face-Detection-Tracking\"\u003eChenyang-ZHU/YOLOv3-Based-Face-Detection-Tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9ffc474bfda63a106b02e87dcdfe9350eae787ea1d0484a624c145b4e0c85aa3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368656e79616e672d5a48552f594f4c4f76332d42617365642d466163652d446574656374696f6e2d547261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9ffc474bfda63a106b02e87dcdfe9350eae787ea1d0484a624c145b4e0c85aa3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368656e79616e672d5a48552f594f4c4f76332d42617365642d466163652d446574656374696f6e2d547261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Chenyang-ZHU/YOLOv3-Based-Face-Detection-Tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a robot project for television live. System will tracking the host's face, making the face in the middle of the screen.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zdfb/Yolov5_face\"\u003ezdfb/Yolov5_face\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ae37f09960c89b77332c355d3d87a86a577dc6d9cedbed389ae97062c0b127fb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6466622f596f6c6f76355f666163653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ae37f09960c89b77332c355d3d87a86a577dc6d9cedbed389ae97062c0b127fb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6466622f596f6c6f76355f666163653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zdfb/Yolov5_face?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于pytorch的Yolov5人脸检测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jinfagang/yolov7-face\"\u003ejinfagang/yolov7-face\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f563dde904a8331e83fa742852680bd981059969ba9cec82658abdeeb880b4dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a696e666167616e672f796f6c6f76372d666163653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f563dde904a8331e83fa742852680bd981059969ba9cec82658abdeeb880b4dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a696e666167616e672f796f6c6f76372d666163653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jinfagang/yolov7-face?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Next Gen Face detection based on YOLOv7.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Yusepp/YOLOv8-Face\"\u003eYusepp/YOLOv8-Face\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ca7c8a73f6678ceed1f1f639b8f4a18667a9950fe04245310cacad83c04c45b4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5975736570702f594f4c4f76382d466163653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ca7c8a73f6678ceed1f1f639b8f4a18667a9950fe04245310cacad83c04c45b4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5975736570702f594f4c4f76382d466163653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Yusepp/YOLOv8-Face?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv8 for Face Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFace Recognition\u003c/h4\u003e\u003ca id=\"user-content-face-recognition\" class=\"anchor\" aria-label=\"Permalink: Face Recognition\" href=\"#face-recognition\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e人脸识别\u003c/h5\u003e\u003ca id=\"user-content-人脸识别\" class=\"anchor\" aria-label=\"Permalink: 人脸识别\" href=\"#人脸识别\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ChanChiChoi/awesome-Face_Recognition\"\u003eChanChiChoi/awesome-Face_Recognition\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/06d3239db8341b54aff6f1edcd772c2b4601f091bbfd40591ecd3e03e35db0b9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368616e43686943686f692f617765736f6d652d466163655f5265636f676e6974696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/06d3239db8341b54aff6f1edcd772c2b4601f091bbfd40591ecd3e03e35db0b9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368616e43686943686f692f617765736f6d652d466163655f5265636f676e6974696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ChanChiChoi/awesome-Face_Recognition?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : papers about Face Detection; Face Alignment; Face Recognition \u0026amp;\u0026amp; Face Identification \u0026amp;\u0026amp; Face Verification \u0026amp;\u0026amp; Face Representation; Face Reconstruction; Face Tracking; Face Super-Resolution \u0026amp;\u0026amp; Face Deblurring; Face Generation \u0026amp;\u0026amp; Face Synthesis; Face Transfer; Face Anti-Spoofing; Face Retrieval.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hpc203/10kinds-light-face-detector-align-recognition\"\u003ehpc203/10kinds-light-face-detector-align-recognition\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/69def8b705327a0a7348d08a647456a614ff7959f173b9ba6e7d436ca3517439/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f31306b696e64732d6c696768742d666163652d6465746563746f722d616c69676e2d7265636f676e6974696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/69def8b705327a0a7348d08a647456a614ff7959f173b9ba6e7d436ca3517439/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f31306b696e64732d6c696768742d666163652d6465746563746f722d616c69676e2d7265636f676e6974696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hpc203/10kinds-light-face-detector-align-recognition?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 10种轻量级人脸检测算法的比拼，其中还包含人脸关键点检测与对齐，人脸特征向量提取和计算距离相似度。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ooooxianyu/yoloV5-arcface_forlearn\"\u003eooooxianyu/yoloV5-arcface_forlearn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/92ccdd7bbc57216f0f9c763fa8ededef6e99627cbca3e0d74ae6b480308512ae/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6f6f6f7869616e79752f796f6c6f56352d617263666163655f666f726c6561726e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/92ccdd7bbc57216f0f9c763fa8ededef6e99627cbca3e0d74ae6b480308512ae/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f6f6f6f7869616e79752f796f6c6f56352d617263666163655f666f726c6561726e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ooooxianyu/yoloV5-arcface_forlearn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 简单拼接一些源码，实现的人脸识别项目。可供学习参考。具体使用到：yolov5人脸检测、arcface人脸识别。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zhouyuchong/face-recognition-deepstream\"\u003ezhouyuchong/face-recognition-deepstream\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ef44b73c47518019c700215367d77db0160708255c7e4dcf2bbe84538a01cc15/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a686f75797563686f6e672f666163652d7265636f676e6974696f6e2d6465657073747265616d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ef44b73c47518019c700215367d77db0160708255c7e4dcf2bbe84538a01cc15/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a686f75797563686f6e672f666163652d7265636f676e6974696f6e2d6465657073747265616d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zhouyuchong/face-recognition-deepstream?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Deepstream app use YOLO, retinaface and arcface for face recognition.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/duckzhao/face_detection_and_recognition_yolov5\"\u003educkzhao/face_detection_and_recognition_yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7b54ed9646e4a3295ef7f39b34270405b709cd5cdca3d19eb2385a85a26f5350/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6475636b7a68616f2f666163655f646574656374696f6e5f616e645f7265636f676e6974696f6e5f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7b54ed9646e4a3295ef7f39b34270405b709cd5cdca3d19eb2385a85a26f5350/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6475636b7a68616f2f666163655f646574656374696f6e5f616e645f7265636f676e6974696f6e5f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/duckzhao/face_detection_and_recognition_yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 使用yolov5构建人脸检测模型，使用预训练的Arcface完成人脸特征提取和识别。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PhucNDA/FaceID--YOLOV5.ArcFace\"\u003ePhucNDA/FaceID--YOLOV5.ArcFace\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3e00f31aafad33384ce2f22e209066d96ffb5fb5b83784a3cece88e6c894a2aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506875634e44412f4661636549442d2d594f4c4f56352e417263466163653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3e00f31aafad33384ce2f22e209066d96ffb5fb5b83784a3cece88e6c894a2aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506875634e44412f4661636549442d2d594f4c4f56352e417263466163653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PhucNDA/FaceID--YOLOV5.ArcFace?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : ONNX implementation of YOLOv5 and Siamese Network (ResNet100) with ArcFace loss for Face Detection and Recognition.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFace Mask Detection\u003c/h3\u003e\u003ca id=\"user-content-face-mask-detection\" class=\"anchor\" aria-label=\"Permalink: Face Mask Detection\" href=\"#face-mask-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e口罩检测\u003c/h4\u003e\u003ca id=\"user-content-口罩检测\" class=\"anchor\" aria-label=\"Permalink: 口罩检测\" href=\"#口罩检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Bil369/MaskDetect-YOLOv4-PyTorch\"\u003eBil369/MaskDetect-YOLOv4-PyTorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5251edbe64b25d393b860f0665c2e1fa1970a221f5da8f2b50eed62111140bc2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42696c3336392f4d61736b4465746563742d594f4c4f76342d5079546f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5251edbe64b25d393b860f0665c2e1fa1970a221f5da8f2b50eed62111140bc2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42696c3336392f4d61736b4465746563742d594f4c4f76342d5079546f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Bil369/MaskDetect-YOLOv4-PyTorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于PyTorch\u0026amp;YOLOv4实现的口罩佩戴检测 ⭐ 自建口罩数据集分享。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/adityap27/face-mask-detector\"\u003eadityap27/face-mask-detector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/251c17876b211701da249c1923c09306be7ce2ae2f71beb6b2ca53803775cf82/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6164697479617032372f666163652d6d61736b2d6465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/251c17876b211701da249c1923c09306be7ce2ae2f71beb6b2ca53803775cf82/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6164697479617032372f666163652d6d61736b2d6465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/adityap27/face-mask-detector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 𝐑𝐞𝐚𝐥-𝐓𝐢𝐦𝐞 𝐅𝐚𝐜𝐞 𝐦𝐚𝐬𝐤 𝐝𝐞𝐭𝐞𝐜𝐭𝐢𝐨𝐧 𝐮𝐬𝐢𝐧𝐠 𝐝𝐞𝐞𝐩𝐥𝐞𝐚𝐫𝐧𝐢𝐧𝐠 𝐰𝐢𝐭𝐡 𝐀𝐥𝐞𝐫𝐭 𝐬𝐲𝐬𝐭𝐞𝐦 💻🔔.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/VictorLin000/YOLOv3_mask_detect\"\u003eVictorLin000/YOLOv3_mask_detect\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/195b6b63fdfa74ff1634fe414656a4f9aa061f70ab7bf08241016749e1ac1bda/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f566963746f724c696e3030302f594f4c4f76335f6d61736b5f6465746563743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/195b6b63fdfa74ff1634fe414656a4f9aa061f70ab7bf08241016749e1ac1bda/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f566963746f724c696e3030302f594f4c4f76335f6d61736b5f6465746563743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/VictorLin000/YOLOv3_mask_detect?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Face mask detection using YOLOv3 on GoogleColab.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/amh28/IBM-Data-Science-Capstone-Alejandra-Marquez\"\u003eamh28/IBM-Data-Science-Capstone-Alejandra-Marquez\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ebbf6df43b658c3ee69a0d249074829586f5058bf7307301534991c20e93e209/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616d6832382f49424d2d446174612d536369656e63652d43617073746f6e652d416c656a616e6472612d4d61727175657a3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ebbf6df43b658c3ee69a0d249074829586f5058bf7307301534991c20e93e209/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616d6832382f49424d2d446174612d536369656e63652d43617073746f6e652d416c656a616e6472612d4d61727175657a3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/amh28/IBM-Data-Science-Capstone-Alejandra-Marquez?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Homemade face mask detector fine-tuning a Yolo-v3 network.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LorenRd/JetsonYolov4\"\u003eLorenRd/JetsonYolov4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8fe419fddf7bf1d74c2e1f7b28430a591d464371d05c03531ba792923c57ff7e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c6f72656e52642f4a6574736f6e596f6c6f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8fe419fddf7bf1d74c2e1f7b28430a591d464371d05c03531ba792923c57ff7e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c6f72656e52642f4a6574736f6e596f6c6f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LorenRd/JetsonYolov4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Face Mask Yolov4 detector - Nvidia Jetson Nano.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Backl1ght/yolov4_face_mask_detection\"\u003eBackl1ght/yolov4_face_mask_detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/35db2468de8514dc5e8b11448cbe736bf6ebcb8451381e507b571a2f7260eb56/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4261636b6c316768742f796f6c6f76345f666163655f6d61736b5f646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/35db2468de8514dc5e8b11448cbe736bf6ebcb8451381e507b571a2f7260eb56/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4261636b6c316768742f796f6c6f76345f666163655f6d61736b5f646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Backl1ght/yolov4_face_mask_detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于yolov4实现口罩佩戴检测，在验证集上做到了0.954的mAP。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pritul2/yolov5_FaceMask\"\u003epritul2/yolov5_FaceMask\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b06c3c3e612112c465566e4c9d0ad8932345fff59602a24e9be747ac918b5a32/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70726974756c322f796f6c6f76355f466163654d61736b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b06c3c3e612112c465566e4c9d0ad8932345fff59602a24e9be747ac918b5a32/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70726974756c322f796f6c6f76355f466163654d61736b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pritul2/yolov5_FaceMask?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detecting person with or without face mask. Trained using YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/NisargPethani/FACE-MASK-DETECTION-USING-YOLO-V3\"\u003eNisargPethani/FACE-MASK-DETECTION-USING-YOLO-V3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bec259109be63699bf6869631d14c4d8e365b4cf0ce7e95dada103066f21e1f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e697361726750657468616e692f464143452d4d41534b2d444554454354494f4e2d5553494e472d594f4c4f2d56333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bec259109be63699bf6869631d14c4d8e365b4cf0ce7e95dada103066f21e1f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e697361726750657468616e692f464143452d4d41534b2d444554454354494f4e2d5553494e472d594f4c4f2d56333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/NisargPethani/FACE-MASK-DETECTION-USING-YOLO-V3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : FACE-MASK DETECTION.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/waittim/mask-detector\"\u003ewaittim/mask-detector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/89e430cdea37c3522241e177d4e04e9e339814872ce4301b219123c0defbf25a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7761697474696d2f6d61736b2d6465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/89e430cdea37c3522241e177d4e04e9e339814872ce4301b219123c0defbf25a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7761697474696d2f6d61736b2d6465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/waittim/mask-detector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time video streaming mask detection based on Python. Designed to defeat COVID-19.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BogdanMarghescu/Face-Mask-Detection-Using-YOLOv4\"\u003eBogdanMarghescu/Face-Mask-Detection-Using-YOLOv4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5f96c57cf463ac8f099d6a7b5d7a3aa8e96e4deeddb404bce4e653fcea744cdc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f6764616e4d61726768657363752f466163652d4d61736b2d446574656374696f6e2d5573696e672d594f4c4f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5f96c57cf463ac8f099d6a7b5d7a3aa8e96e4deeddb404bce4e653fcea744cdc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f6764616e4d61726768657363752f466163652d4d61736b2d446574656374696f6e2d5573696e672d594f4c4f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BogdanMarghescu/Face-Mask-Detection-Using-YOLOv4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Face Mask Detector using YOLOv4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xinghanliuying/yolov5_bus\"\u003exinghanliuying/yolov5_bus\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5a8350cef98d3682398b5c4d45bd6b766e6865f68aa5b136ec0131bbffcd1419/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78696e6768616e6c697579696e672f796f6c6f76355f6275733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5a8350cef98d3682398b5c4d45bd6b766e6865f68aa5b136ec0131bbffcd1419/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78696e6768616e6c697579696e672f796f6c6f76355f6275733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xinghanliuying/yolov5_bus?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 手把手教你使用YOLOV5训练自己的目标检测模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://gitee.com/song-laogou/yolov5-mask-42\" rel=\"nofollow\"\u003esong-laogou/yolov5-mask-42\u003c/a\u003e : 基于YOLOV5的口罩检测系统-提供教学视频。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSocial Distance Detection\u003c/h3\u003e\u003ca id=\"user-content-social-distance-detection\" class=\"anchor\" aria-label=\"Permalink: Social Distance Detection\" href=\"#social-distance-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e社交距离检测\u003c/h4\u003e\u003ca id=\"user-content-社交距离检测\" class=\"anchor\" aria-label=\"Permalink: 社交距离检测\" href=\"#社交距离检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ank-Cha/Social-Distancing-Analyser-COVID-19\"\u003eAnk-Cha/Social-Distancing-Analyser-COVID-19\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/16a8e03f33ee6b87e4db7f40dd43304fcd679cabd6907d929b4415f1ae3bf4e3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e6b2d4368612f536f6369616c2d44697374616e63696e672d416e616c797365722d434f5649442d31393f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/16a8e03f33ee6b87e4db7f40dd43304fcd679cabd6907d929b4415f1ae3bf4e3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e6b2d4368612f536f6369616c2d44697374616e63696e672d416e616c797365722d434f5649442d31393f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ank-Cha/Social-Distancing-Analyser-COVID-19?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Social Distancing Analyser to prevent COVID19.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/abd-shoumik/Social-distance-detection\"\u003eabd-shoumik/Social-distance-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a69753f50e65ed2ad495f71c135c0078ed36dd88c17a9d2188c04b769ff90844/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6162642d73686f756d696b2f536f6369616c2d64697374616e63652d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a69753f50e65ed2ad495f71c135c0078ed36dd88c17a9d2188c04b769ff90844/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6162642d73686f756d696b2f536f6369616c2d64697374616e63652d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/abd-shoumik/Social-distance-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Social distance detection, a deep learning computer vision project with yolo object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ChargedMonk/Social-Distancing-using-YOLOv5\"\u003eChargedMonk/Social-Distancing-using-YOLOv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/792853596cf77ba7e60c244df32b79116019f3879b5f90df9e898c9440f1cb54/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436861726765644d6f6e6b2f536f6369616c2d44697374616e63696e672d7573696e672d594f4c4f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/792853596cf77ba7e60c244df32b79116019f3879b5f90df9e898c9440f1cb54/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436861726765644d6f6e6b2f536f6369616c2d44697374616e63696e672d7573696e672d594f4c4f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ChargedMonk/Social-Distancing-using-YOLOv5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Classifying people as high risk and low risk based on their distance to other people.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/JohnBetaCode/Social-Distancing-Analyser\"\u003eJohnBetaCode/Social-Distancing-Analyser\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/99ba378ccfdd6abc5c3070eb036981cf37adefd233897c91fd001d15896cd17c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a6f686e42657461436f64652f536f6369616c2d44697374616e63696e672d416e616c797365723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/99ba378ccfdd6abc5c3070eb036981cf37adefd233897c91fd001d15896cd17c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a6f686e42657461436f64652f536f6369616c2d44697374616e63696e672d416e616c797365723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/JohnBetaCode/Social-Distancing-Analyser?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Social Distancing Analyzer.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ashamaria/Safe-distance-tracker-using-YOLOv3-v3\"\u003eAshamaria/Safe-distance-tracker-using-YOLOv3-v3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/40b6d4cb8aaa832cf45b66328068e1ae21e740053b95b5df117aab7a49284591/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f417368616d617269612f536166652d64697374616e63652d747261636b65722d7573696e672d594f4c4f76332d76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/40b6d4cb8aaa832cf45b66328068e1ae21e740053b95b5df117aab7a49284591/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f417368616d617269612f536166652d64697374616e63652d747261636b65722d7573696e672d594f4c4f76332d76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ashamaria/Safe-distance-tracker-using-YOLOv3-v3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Safe Distance Tracker.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAutonomous Driving Field Detection\u003c/h3\u003e\u003ca id=\"user-content-autonomous-driving-field-detection\" class=\"anchor\" aria-label=\"Permalink: Autonomous Driving Field Detection\" href=\"#autonomous-driving-field-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e自动驾驶领域检测\u003c/h4\u003e\u003ca id=\"user-content-自动驾驶领域检测\" class=\"anchor\" aria-label=\"Permalink: 自动驾驶领域检测\" href=\"#自动驾驶领域检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eVehicle Detection\u003c/h4\u003e\u003ca id=\"user-content-vehicle-detection\" class=\"anchor\" aria-label=\"Permalink: Vehicle Detection\" href=\"#vehicle-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e车辆检测\u003c/h5\u003e\u003ca id=\"user-content-车辆检测\" class=\"anchor\" aria-label=\"Permalink: 车辆检测\" href=\"#车辆检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jason-li-831202/Vehicle-CV-ADAS\"\u003ejason-li-831202/Vehicle-CV-ADAS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ad08e46a654f7db16cad8ddc03240ed4b12aeedb3bfaed517712b53e7460e18e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a61736f6e2d6c692d3833313230322f56656869636c652d43562d414441533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ad08e46a654f7db16cad8ddc03240ed4b12aeedb3bfaed517712b53e7460e18e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a61736f6e2d6c692d3833313230322f56656869636c652d43562d414441533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jason-li-831202/Vehicle-CV-ADAS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The project can achieve FCWS, LDWS, and LKAS functions solely using only visual sensors. using YOLOv5 / YOLOv5-lite / YOLOv6 / YOLOv7 / YOLOv8 / YOLOv9 / EfficientDet and Ultra-Fast-Lane-Detection-v2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/williamhyin/yolov5s_bdd100k\"\u003ewilliamhyin/yolov5s_bdd100k\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/682d58b5754c2d789a56a7489946f15db8db1637ee1071f84b88186e7c92ed61/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77696c6c69616d6879696e2f796f6c6f7635735f6264643130306b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/682d58b5754c2d789a56a7489946f15db8db1637ee1071f84b88186e7c92ed61/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77696c6c69616d6879696e2f796f6c6f7635735f6264643130306b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/williamhyin/yolov5s_bdd100k?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Train a yolo v5 object detection model on Bdd100k dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jwchoi384/Gaussian_YOLOv3\"\u003eGaussian_YOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a16e0f4f2d1eb8a554227a7f348794caf4552c07a8b438c607b3cb9ff92431ef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a7763686f693338342f476175737369616e5f594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a16e0f4f2d1eb8a554227a7f348794caf4552c07a8b438c607b3cb9ff92431ef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a7763686f693338342f476175737369616e5f594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jwchoi384/Gaussian_YOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Gaussian YOLOv3: An Accurate and Fast Object Detector Using Localization Uncertainty for Autonomous Driving\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_ICCV_2019/html/Choi_Gaussian_YOLOv3_An_Accurate_and_Fast_Object_Detector_Using_Localization_ICCV_2019_paper.html\" rel=\"nofollow\"\u003eICCV 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/streamlit/demo-self-driving\"\u003estreamlit/demo-self-driving\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e2b9f558f65a83043627968313a89b1bcbf741461c012d074e84037b68a4ff08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73747265616d6c69742f64656d6f2d73656c662d64726976696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e2b9f558f65a83043627968313a89b1bcbf741461c012d074e84037b68a4ff08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73747265616d6c69742f64656d6f2d73656c662d64726976696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/streamlit/demo-self-driving?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Streamlit app demonstrating an image browser for the Udacity self-driving-car dataset with realtime object detection using YOLO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/JunshengFu/vehicle-detection\"\u003eJunshengFu/vehicle-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f72ea8464e996ea73439936b07ee505f2af9b38ebb26d76e6a8ffd050d5fc9a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a756e7368656e6746752f76656869636c652d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f72ea8464e996ea73439936b07ee505f2af9b38ebb26d76e6a8ffd050d5fc9a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a756e7368656e6746752f76656869636c652d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/JunshengFu/vehicle-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Created vehicle detection pipeline with two approaches: (1) deep neural networks (YOLO framework) and (2) support vector machines ( OpenCV + HOG).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xslittlegrass/CarND-Vehicle-Detection\"\u003exslittlegrass/CarND-Vehicle-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e9bf8708866e8051e45a2772a67b522d18b54bfc475b32a1dc40b6e0c8709795/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78736c6974746c6567726173732f4361724e442d56656869636c652d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e9bf8708866e8051e45a2772a67b522d18b54bfc475b32a1dc40b6e0c8709795/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78736c6974746c6567726173732f4361724e442d56656869636c652d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xslittlegrass/CarND-Vehicle-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Vehicle detection using YOLO in Keras runs at 21FPS.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Kevinnan-teen/Intelligent-Traffic-Based-On-CV\"\u003eKevinnan-teen/Intelligent-Traffic-Based-On-CV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6e3d2150cd25e7c5e9099144b3266cab1be80ee327eb9ca222241567e7023ab0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6576696e6e616e2d7465656e2f496e74656c6c6967656e742d547261666669632d42617365642d4f6e2d43563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6e3d2150cd25e7c5e9099144b3266cab1be80ee327eb9ca222241567e7023ab0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b6576696e6e616e2d7465656e2f496e74656c6c6967656e742d547261666669632d42617365642d4f6e2d43563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Kevinnan-teen/Intelligent-Traffic-Based-On-CV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于计算机视觉的交通路口智能监控系统。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/subodh-malgonde/vehicle-detection\"\u003esubodh-malgonde/vehicle-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d98375ad194a34e7aa356cea13803fbf149801a8c1b27691eb9d0f59efc4b347/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7375626f64682d6d616c676f6e64652f76656869636c652d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d98375ad194a34e7aa356cea13803fbf149801a8c1b27691eb9d0f59efc4b347/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7375626f64682d6d616c676f6e64652f76656869636c652d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/subodh-malgonde/vehicle-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detect vehicles in a video.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CaptainEven/Vehicle-Car-detection-and-multilabel-classification\"\u003eCaptainEven/Vehicle-Car-detection-and-multilabel-classification\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4b8b64e714f8562e217601dbe2e81995af97e2d8efa4d703251e9d54b9aaa9d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4361707461696e4576656e2f56656869636c652d4361722d646574656374696f6e2d616e642d6d756c74696c6162656c2d636c617373696669636174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4b8b64e714f8562e217601dbe2e81995af97e2d8efa4d703251e9d54b9aaa9d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4361707461696e4576656e2f56656869636c652d4361722d646574656374696f6e2d616e642d6d756c74696c6162656c2d636c617373696669636174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CaptainEven/Vehicle-Car-detection-and-multilabel-classification?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 使用YOLO_v3_tiny和B-CNN实现街头车辆的检测和车辆属性的多标签识别 Using yolo_v3_tiny to do vehicle or car detection and attribute's multilabel classification or recognize。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kaylode/vehicle-counting\"\u003ekaylode/vehicle-counting\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8bd2068118be8e6bf1f0f77cd9223d4a07e3551d4dcdbca6b84d276f35c2b140/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b61796c6f64652f76656869636c652d636f756e74696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8bd2068118be8e6bf1f0f77cd9223d4a07e3551d4dcdbca6b84d276f35c2b140/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b61796c6f64652f76656869636c652d636f756e74696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kaylode/vehicle-counting?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Vehicle counting using Pytorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MaryamBoneh/Vehicle-Detection\"\u003eMaryamBoneh/Vehicle-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/637bdfa8fab5fc1ae6f7b30b659f7b946f92260e9050b89db3039c96d6252ac1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d617279616d426f6e65682f56656869636c652d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/637bdfa8fab5fc1ae6f7b30b659f7b946f92260e9050b89db3039c96d6252ac1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d617279616d426f6e65682f56656869636c652d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MaryamBoneh/Vehicle-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Vehicle Detection Using Deep Learning and YOLO Algorithm.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/JeffWang0325/Image-Identification-for-Self-Driving-Cars\"\u003eJeffWang0325/Image-Identification-for-Self-Driving-Cars\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/54070c3f234c071d1238401f753c4536ebe48b0e8f802a21bb82660d3c9876e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a65666657616e67303332352f496d6167652d4964656e74696669636174696f6e2d666f722d53656c662d44726976696e672d436172733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/54070c3f234c071d1238401f753c4536ebe48b0e8f802a21bb82660d3c9876e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a65666657616e67303332352f496d6167652d4964656e74696669636174696f6e2d666f722d53656c662d44726976696e672d436172733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/JeffWang0325/Image-Identification-for-Self-Driving-Cars?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e :  This project achieves some functions of image identification for Self-Driving Cars.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AnarbekovAlt/Traffic-analysis\"\u003eAnarbekovAlt/Traffic-analysis\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/88e3539c68ed35225228429682f528a0d01a7b61499c127bb79f12e6e11be604/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e617262656b6f76416c742f547261666669632d616e616c797369733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/88e3539c68ed35225228429682f528a0d01a7b61499c127bb79f12e6e11be604/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e617262656b6f76416c742f547261666669632d616e616c797369733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AnarbekovAlt/Traffic-analysis?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A traffic analysis system is built on the basis of the YOLO network.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ruhyadi/yolov5-nodeflux\"\u003eruhyadi/yolov5-nodeflux\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1177ed116afbe4843ae75eea02faca9d6ff8aa7adfc3cec62a85e3847d6019f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f727568796164692f796f6c6f76352d6e6f6465666c75783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1177ed116afbe4843ae75eea02faca9d6ff8aa7adfc3cec62a85e3847d6019f8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f727568796164692f796f6c6f76352d6e6f6465666c75783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ruhyadi/yolov5-nodeflux?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 Nodeflux Vehicle Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Daheer/Driving-Environment-Detector\"\u003eDaheer/Driving-Environment-Detector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e38d0a870a1f20ade0c22aeb6baaaa8db38359e6ec8168084b94dc9fd40790b3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461686565722f44726976696e672d456e7669726f6e6d656e742d4465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e38d0a870a1f20ade0c22aeb6baaaa8db38359e6ec8168084b94dc9fd40790b3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461686565722f44726976696e672d456e7669726f6e6d656e742d4465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Daheer/Driving-Environment-Detector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detecting road objects using YOLO CNN Architecture.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/georgia-tech-db/eva\"\u003egeorgia-tech-db/eva\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cc26bb797654ec37a208409242a8f202d4776f008a1a72e1e438afeec0ebe42e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67656f726769612d746563682d64622f6576613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cc26bb797654ec37a208409242a8f202d4776f008a1a72e1e438afeec0ebe42e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67656f726769612d746563682d64622f6576613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/georgia-tech-db/eva?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Exploratory Video Analytics System.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/heathhenley/RhodyCarCounter\"\u003eheathhenley/RhodyCarCounter\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/792754789b750fa417aa43a0b7287c6bcc5f3ceb775d2f5b3cc0858085560834/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686561746868656e6c65792f52686f6479436172436f756e7465723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/792754789b750fa417aa43a0b7287c6bcc5f3ceb775d2f5b3cc0858085560834/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686561746868656e6c65792f52686f6479436172436f756e7465723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/heathhenley/RhodyCarCounter?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An app that uses Yolo to count the cars passing by traffic cams mostly in the Providence, RI area.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zehengl/yyc-traffic-cam\"\u003ezehengl/yyc-traffic-cam\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c3d6abadc0cb52e5826686e625df51c47f49bd299be1d65151fc52ab0eacfcef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6568656e676c2f7979632d747261666669632d63616d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c3d6abadc0cb52e5826686e625df51c47f49bd299be1d65151fc52ab0eacfcef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6568656e676c2f7979632d747261666669632d63616d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zehengl/yyc-traffic-cam?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A demo to detect vehicles in traffic cam. \u003ca href=\"https://zehengl.github.io/yyc-traffic-cam/\" rel=\"nofollow\"\u003ezehengl.github.io/yyc-traffic-cam/\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ruhyadi/vehicle-detection-yolov8\"\u003eruhyadi/vehicle-detection-yolov8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4d55326180b77c58c79e58d3163b8282d45a38615ebe9c0f76e6678ae19f6e2a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f727568796164692f76656869636c652d646574656374696f6e2d796f6c6f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4d55326180b77c58c79e58d3163b8282d45a38615ebe9c0f76e6678ae19f6e2a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f727568796164692f76656869636c652d646574656374696f6e2d796f6c6f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ruhyadi/vehicle-detection-yolov8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Vehicle Detection with YOLOv8.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eLicense Plate Detection and Recognition\u003c/h4\u003e\u003ca id=\"user-content-license-plate-detection-and-recognition\" class=\"anchor\" aria-label=\"Permalink: License Plate Detection and Recognition\" href=\"#license-plate-detection-and-recognition\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e车牌检测与识别\u003c/h5\u003e\u003ca id=\"user-content-车牌检测与识别\" class=\"anchor\" aria-label=\"Permalink: 车牌检测与识别\" href=\"#车牌检测与识别\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zeusees/License-Plate-Detector\"\u003ezeusees/License-Plate-Detector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/77fb7de6ad8270e1cf5c07b4a7af8b1b8d6b3835fd3d18d454e14ab45dc5914e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6575736565732f4c6963656e73652d506c6174652d4465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/77fb7de6ad8270e1cf5c07b4a7af8b1b8d6b3835fd3d18d454e14ab45dc5914e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6575736565732f4c6963656e73652d506c6174652d4465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zeusees/License-Plate-Detector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : License Plate Detection with Yolov5，基于Yolov5车牌检测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TheophileBuy/LicensePlateRecognition\"\u003eTheophileBuy/LicensePlateRecognition\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/028e9321c771b1a7e43f3699ef71d9c858308344ed172a2a1e6b5d579421e8f3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5468656f7068696c654275792f4c6963656e7365506c6174655265636f676e6974696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/028e9321c771b1a7e43f3699ef71d9c858308344ed172a2a1e6b5d579421e8f3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5468656f7068696c654275792f4c6963656e7365506c6174655265636f676e6974696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TheophileBuy/LicensePlateRecognition?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : License Plate Recognition.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/alitourani/yolo-license-plate-detection\"\u003ealitourani/yolo-license-plate-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/42e8ecd73f05a175ef20bab34c572e1ee9d4de008127cf6595a071488c7356f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69746f7572616e692f796f6c6f2d6c6963656e73652d706c6174652d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/42e8ecd73f05a175ef20bab34c572e1ee9d4de008127cf6595a071488c7356f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c69746f7572616e692f796f6c6f2d6c6963656e73652d706c6174652d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/alitourani/yolo-license-plate-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A License-Plate detecttion application based on YOLO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HuKai97/YOLOv5-LPRNet-Licence-Recognition\"\u003eHuKai97/YOLOv5-LPRNet-Licence-Recognition\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/62368b1329067a8e5ca6e2ee68b1b8d444c4bef32659753d7708ae9ba86be713/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48754b616939372f594f4c4f76352d4c50524e65742d4c6963656e63652d5265636f676e6974696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/62368b1329067a8e5ca6e2ee68b1b8d444c4bef32659753d7708ae9ba86be713/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48754b616939372f594f4c4f76352d4c50524e65742d4c6963656e63652d5265636f676e6974696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HuKai97/YOLOv5-LPRNet-Licence-Recognition?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 使用YOLOv5和LPRNet进行车牌检测+识别（CCPD数据集）。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xialuxi/yolov5-car-plate\"\u003exialuxi/yolov5-car-plate\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5b1476715ba3bdc4b50cd75fc80caa3cc3e634c243faa09186c1552e8b69a03e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616c7578692f796f6c6f76352d6361722d706c6174653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5b1476715ba3bdc4b50cd75fc80caa3cc3e634c243faa09186c1552e8b69a03e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869616c7578692f796f6c6f76352d6361722d706c6174653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xialuxi/yolov5-car-plate?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于yolov5的车牌检测，包含车牌角点检测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kyrielw24/License_Plate_Recognition\"\u003ekyrielw24/License_Plate_Recognition\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/01e2559555318ae1fe294f0f44ea72ce364d3fafdfe0ebb98a6cf46364089f8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b797269656c7732342f4c6963656e73655f506c6174655f5265636f676e6974696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/01e2559555318ae1fe294f0f44ea72ce364d3fafdfe0ebb98a6cf46364089f8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b797269656c7732342f4c6963656e73655f506c6174655f5265636f676e6974696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kyrielw24/License_Plate_Recognition?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于Yolo\u0026amp;CNN的车牌识别可视化项目。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/we0091234/yolov7_plate\"\u003ewe0091234/yolov7_plate\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3efeb36b7ad350ca2f0d90021f895de911b4571a4e1047ca0edbf2da54b4d768/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7765303039313233342f796f6c6f76375f706c6174653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3efeb36b7ad350ca2f0d90021f895de911b4571a4e1047ca0edbf2da54b4d768/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7765303039313233342f796f6c6f76375f706c6174653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/we0091234/yolov7_plate?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov7 车牌检测 车牌识别 中文车牌识别 检测 支持双层车牌 支持13种中文车牌。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MuhammadMoinFaisal/Automatic_Number_Plate_Detection_Recognition_YOLOv8\"\u003eMuhammadMoinFaisal/Automatic_Number_Plate_Detection_Recognition_YOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a5eea0eb8abfbe1ccd54f3f5a95bf6dbc7f1aa272c3653922833af8d66f565bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d7568616d6d61644d6f696e46616973616c2f4175746f6d617469635f4e756d6265725f506c6174655f446574656374696f6e5f5265636f676e6974696f6e5f594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a5eea0eb8abfbe1ccd54f3f5a95bf6dbc7f1aa272c3653922833af8d66f565bc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d7568616d6d61644d6f696e46616973616c2f4175746f6d617469635f4e756d6265725f506c6174655f446574656374696f6e5f5265636f676e6974696f6e5f594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MuhammadMoinFaisal/Automatic_Number_Plate_Detection_Recognition_YOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Automatic Number Plate Detection YOLOv8.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eLane Detection\u003c/h4\u003e\u003ca id=\"user-content-lane-detection\" class=\"anchor\" aria-label=\"Permalink: Lane Detection\" href=\"#lane-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e车道线检测\u003c/h5\u003e\u003ca id=\"user-content-车道线检测\" class=\"anchor\" aria-label=\"Permalink: 车道线检测\" href=\"#车道线检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hustvl/YOLOP\"\u003eYOLOP\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/268baea33e613c8c60abf4ca4c71ec1a019404f571c6e058abb36ed456b42beb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68757374766c2f594f4c4f503f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/268baea33e613c8c60abf4ca4c71ec1a019404f571c6e058abb36ed456b42beb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68757374766c2f594f4c4f503f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hustvl/YOLOP?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOP: You Only Look Once for Panoptic Driving Perception\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2108.11250\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CAIC-AD/YOLOPv2\"\u003eYOLOPv2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/40001fdf143ca900f598d41962f44567c94fa5d71fed814b50d95986f8c87e36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f434149432d41442f594f4c4f5076323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/40001fdf143ca900f598d41962f44567c94fa5d71fed814b50d95986f8c87e36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f434149432d41442f594f4c4f5076323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CAIC-AD/YOLOPv2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLOPv2: Better, Faster, Stronger for Panoptic Driving Perception\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2208.11434\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e). \"微信公众号「集智书童」《\u003ca href=\"https://mp.weixin.qq.com/s/XTD32JCu_YbZjV2Br3KXCA\" rel=\"nofollow\"\u003eYOLOP v2来啦 | YOLOv7结合YOLOP的多任务版本，超越YOLOP以及HybridNets\u003c/a\u003e》\"\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FeiGeChuanShu/YOLOPv2-ncnn\"\u003eFeiGeChuanShu/YOLOPv2-ncnn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8ffeb1682287a1ecebc0c1cf6415b80db9d25a41a375da3bdb21324c09cf2ae4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4665694765436875616e5368752f594f4c4f5076322d6e636e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8ffeb1682287a1ecebc0c1cf6415b80db9d25a41a375da3bdb21324c09cf2ae4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4665694765436875616e5368752f594f4c4f5076322d6e636e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FeiGeChuanShu/YOLOPv2-ncnn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOPv2-ncnn.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/visualbuffer/copilot\"\u003evisualbuffer/copilot\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6b794c7c1f832d360a1746bdb6010600f335d2d32fb20d3ecb1685eaf2706b59/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76697375616c6275666665722f636f70696c6f743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6b794c7c1f832d360a1746bdb6010600f335d2d32fb20d3ecb1685eaf2706b59/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76697375616c6275666665722f636f70696c6f743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/visualbuffer/copilot?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Lane and obstacle detection for active assistance during driving.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hpc203/YOLOP-opencv-dnn\"\u003ehpc203/YOLOP-opencv-dnn\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/007f0ed071c2f6ec2819b7851878b93165efc9ddad8b789d333aa112472483f6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f594f4c4f502d6f70656e63762d646e6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/007f0ed071c2f6ec2819b7851878b93165efc9ddad8b789d333aa112472483f6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f594f4c4f502d6f70656e63762d646e6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hpc203/YOLOP-opencv-dnn?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 使用OpenCV部署全景驾驶感知网络YOLOP，可同时处理交通目标检测、可驾驶区域分割、车道线检测，三项视觉感知任务。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/EdVince/YOLOP-NCNN\"\u003eEdVince/YOLOP-NCNN\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/27628443aebc13440931d96431fbb7e4c7d4b85c0989c35cb89e9c5f810601e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f456456696e63652f594f4c4f502d4e434e4e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/27628443aebc13440931d96431fbb7e4c7d4b85c0989c35cb89e9c5f810601e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f456456696e63652f594f4c4f502d4e434e4e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/EdVince/YOLOP-NCNN?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOP running in Android by ncnn.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eDriving Behavior Detection\u003c/h4\u003e\u003ca id=\"user-content-driving-behavior-detection\" class=\"anchor\" aria-label=\"Permalink: Driving Behavior Detection\" href=\"#driving-behavior-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e驾驶行为检测\u003c/h5\u003e\u003ca id=\"user-content-驾驶行为检测\" class=\"anchor\" aria-label=\"Permalink: 驾驶行为检测\" href=\"#驾驶行为检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/JingyibySUTsoftware/Yolov5-deepsort-driverDistracted-driving-behavior-detection\"\u003eJingyibySUTsoftware/Yolov5-deepsort-driverDistracted-driving-behavior-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a58f3f2596965457bd6a5f32a5925662ef0f6286ee4359fd2b2112c3c1686dbc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a696e6779696279535554736f6674776172652f596f6c6f76352d64656570736f72742d647269766572446973747261637465642d64726976696e672d6265686176696f722d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a58f3f2596965457bd6a5f32a5925662ef0f6286ee4359fd2b2112c3c1686dbc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a696e6779696279535554736f6674776172652f596f6c6f76352d64656570736f72742d647269766572446973747261637465642d64726976696e672d6265686176696f722d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/JingyibySUTsoftware/Yolov5-deepsort-driverDistracted-driving-behavior-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于深度学习的驾驶员分心驾驶行为（疲劳+危险行为）预警系统使用YOLOv5+Deepsort实现驾驶员的危险驾驶行为的预警监测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Arrowes/CEAM-YOLOv7\"\u003eArrowes/CEAM-YOLOv7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/34b80f920cb805ab8b35fec2f29e19abfc8cde8acc22a6a0b21f56f476fae139/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4172726f7765732f4345414d2d594f4c4f76373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/34b80f920cb805ab8b35fec2f29e19abfc8cde8acc22a6a0b21f56f476fae139/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4172726f7765732f4345414d2d594f4c4f76373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Arrowes/CEAM-YOLOv7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"CEAM-YOLOv7:Improved YOLOv7 Based on Channel Expansion and Attention Mechanism for Driver Distraction Behavior Detection\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9980374/\" rel=\"nofollow\"\u003eIEEE Access, 2022\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eParking Slot Detection\u003c/h4\u003e\u003ca id=\"user-content-parking-slot-detection\" class=\"anchor\" aria-label=\"Permalink: Parking Slot Detection\" href=\"#parking-slot-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e停车位检测\u003c/h5\u003e\u003ca id=\"user-content-停车位检测\" class=\"anchor\" aria-label=\"Permalink: 停车位检测\" href=\"#停车位检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/visualbuffer/parkingslot\"\u003evisualbuffer/parkingslot\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7480e5bcb53c9f3f459e620ef400bf8a59977e852a31cd3fd7802481d45ab961/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76697375616c6275666665722f7061726b696e67736c6f743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7480e5bcb53c9f3f459e620ef400bf8a59977e852a31cd3fd7802481d45ab961/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76697375616c6275666665722f7061726b696e67736c6f743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/visualbuffer/parkingslot?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Automated parking occupancy detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/anil2k/smart-car-parking-yolov5\"\u003eanil2k/smart-car-parking-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7f14973dd8ef0945d19a38347472793ca9ab136e699fa2e67cd9e69eca7c4ce5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616e696c326b2f736d6172742d6361722d7061726b696e672d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7f14973dd8ef0945d19a38347472793ca9ab136e699fa2e67cd9e69eca7c4ce5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616e696c326b2f736d6172742d6361722d7061726b696e672d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/anil2k/smart-car-parking-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detect free parking lot available for cars.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eTraffic Light Detection\u003c/h4\u003e\u003ca id=\"user-content-traffic-light-detection\" class=\"anchor\" aria-label=\"Permalink: Traffic Light Detection\" href=\"#traffic-light-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e交通灯检测\u003c/h5\u003e\u003ca id=\"user-content-交通灯检测\" class=\"anchor\" aria-label=\"Permalink: 交通灯检测\" href=\"#交通灯检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/berktepebag/Traffic-light-detection-with-YOLOv3-BOSCH-traffic-light-dataset\"\u003eberktepebag/Traffic-light-detection-with-YOLOv3-BOSCH-traffic-light-dataset\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/66b591afcc784b21063bacf8740003aa1644c7dbff7523fc6102a210099e3c30/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6265726b746570656261672f547261666669632d6c696768742d646574656374696f6e2d776974682d594f4c4f76332d424f5343482d747261666669632d6c696768742d646174617365743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/66b591afcc784b21063bacf8740003aa1644c7dbff7523fc6102a210099e3c30/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6265726b746570656261672f547261666669632d6c696768742d646574656374696f6e2d776974682d594f4c4f76332d424f5343482d747261666669632d6c696768742d646174617365743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/berktepebag/Traffic-light-detection-with-YOLOv3-BOSCH-traffic-light-dataset?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detecting Traffic Lights in Real-time with YOLOv3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mihir-m-gandhi/Adaptive-Traffic-Signal-Timer\"\u003emihir-m-gandhi/Adaptive-Traffic-Signal-Timer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8e3f9c7009484cbc53eb059ca999955b2d57dc8e8e34dafb2bad78a594a2b764/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696869722d6d2d67616e6468692f41646170746976652d547261666669632d5369676e616c2d54696d65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8e3f9c7009484cbc53eb059ca999955b2d57dc8e8e34dafb2bad78a594a2b764/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696869722d6d2d67616e6468692f41646170746976652d547261666669632d5369676e616c2d54696d65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mihir-m-gandhi/Adaptive-Traffic-Signal-Timer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This Adaptive Traffic Signal Timer uses live images from the cameras at traffic junctions for real-time traffic density calculation using YOLO object detection and sets the signal timers accordingly.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wade0125/Traffic_Light_Detection_Yolo\"\u003ewade0125/Traffic_Light_Detection_Yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e9574a96800f53b64856ffcf140c7c71fda7509da28389202ca80429d17dfd97/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616465303132352f547261666669635f4c696768745f446574656374696f6e5f596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e9574a96800f53b64856ffcf140c7c71fda7509da28389202ca80429d17dfd97/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616465303132352f547261666669635f4c696768745f446574656374696f6e5f596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wade0125/Traffic_Light_Detection_Yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Traffic Light Detection Yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LIU42/PassingRules\"\u003eLIU42/PassingRules\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/aabdd3a66444d723af05bde9791f8f97e802501420750f0907928592389391d4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c495534322f50617373696e6752756c65733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/aabdd3a66444d723af05bde9791f8f97e802501420750f0907928592389391d4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c495534322f50617373696e6752756c65733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LIU42/PassingRules?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 一种基于 YOLOv8 的路口交通信号灯通行规则识别模型及算法.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eTraffic Sign Detection\u003c/h4\u003e\u003ca id=\"user-content-traffic-sign-detection\" class=\"anchor\" aria-label=\"Permalink: Traffic Sign Detection\" href=\"#traffic-sign-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e交通标志检测\u003c/h5\u003e\u003ca id=\"user-content-交通标志检测\" class=\"anchor\" aria-label=\"Permalink: 交通标志检测\" href=\"#交通标志检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ai-trainee/Traffic-Sign-Recognition-PyQt5-YOLOv5-GUI\"\u003eAi-trainee/Traffic-Sign-Recognition-PyQt5-YOLOv5-GUI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/90c72d4f35e2e36b19db9ea449b487cede52d7ca82c29f3f6dddb31914d294c1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41692d747261696e65652f547261666669632d5369676e2d5265636f676e6974696f6e2d50795174352d594f4c4f76352d4755493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/90c72d4f35e2e36b19db9ea449b487cede52d7ca82c29f3f6dddb31914d294c1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41692d747261696e65652f547261666669632d5369676e2d5265636f676e6974696f6e2d50795174352d594f4c4f76352d4755493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ai-trainee/Traffic-Sign-Recognition-PyQt5-YOLOv5-GUI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Road Sign Recognition Project Based on YOLOv5. This is a road sign recognition project based on YOLOv5, developed with a PyQt5 interface, YOLOv5 trained model, and MySQL database. 这是一个基于YOLOv5🚀的道路标志识别系统😊，使用了MySQL数据库💽，PyQt5进行界面设计🎨，PyTorch深度学习框架和TensorRT进行加速⚡，同时包含了CSS样式🌈。系统由五个主要模块组成：系统登录模块🔑负责用户登陆；初始化参数模块📋提供YOLOv5模型的初始化参数设置；标志识别模块🔍是系统的核心，负责对道路标志进行识别并将结果导入数据库；数据库模块💾包含基本数据库操作和数据分析两个子模块；图像处理模块🖼️负责单个图像的处理和数据增强。整个系统支持多种数据输入和模型切换，提供了包括mossic和mixup在内的图像增强方法📈。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/halftop/TT100K_YOLO_Label\"\u003ehalftop/TT100K_YOLO_Label\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4717196de267dd63c40b11e726ee486da531aa67ab558baeb107d4f18f51ec2e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68616c66746f702f54543130304b5f594f4c4f5f4c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4717196de267dd63c40b11e726ee486da531aa67ab558baeb107d4f18f51ec2e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68616c66746f702f54543130304b5f594f4c4f5f4c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/halftop/TT100K_YOLO_Label?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Tsinghua-Tencent 100K dataset XML and TXT Label.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/amazingcodeLYL/Traffic_signs_detection_darket\"\u003eamazingcodeLYL/Traffic_signs_detection_darket\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2033727f268d06cf6bbf3e60617ec047e0c9cc3acc90a80118e9286ea8f01c99/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616d617a696e67636f64654c594c2f547261666669635f7369676e735f646574656374696f6e5f6461726b65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2033727f268d06cf6bbf3e60617ec047e0c9cc3acc90a80118e9286ea8f01c99/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616d617a696e67636f64654c594c2f547261666669635f7369676e735f646574656374696f6e5f6461726b65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/amazingcodeLYL/Traffic_signs_detection_darket?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : darknet交通标志检测\u0026amp;TT100K数据集。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TalkUHulk/yolov3-TT100k\"\u003eTalkUHulk/yolov3-TT100k\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5e164fd63189c1e9e400c32d6a166bdaf81f2f35e9302c7defc7d9a864aa15b6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54616c6b5548756c6b2f796f6c6f76332d54543130306b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5e164fd63189c1e9e400c32d6a166bdaf81f2f35e9302c7defc7d9a864aa15b6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54616c6b5548756c6b2f796f6c6f76332d54543130306b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TalkUHulk/yolov3-TT100k?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 使用yolov3训练的TT100k(交通标志)模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TalkUHulk/yolov4-TT100k\"\u003eTalkUHulk/yolov4-TT100k\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c3d8db4c4c6cdad96f24f627023fe2742ffa45fba547b1f38578c99fb6cb990f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54616c6b5548756c6b2f796f6c6f76342d54543130306b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c3d8db4c4c6cdad96f24f627023fe2742ffa45fba547b1f38578c99fb6cb990f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54616c6b5548756c6b2f796f6c6f76342d54543130306b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TalkUHulk/yolov4-TT100k?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 使用yolov4训练的TT100k(交通标志)模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sarah-antillia/YOLO_Realistic_USA_RoadSigns_160classes\"\u003esarah-antillia/YOLO_Realistic_USA_RoadSigns_160classes\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cf7fca7ae480ce780fb231f43bc15783f0289abacd4e20c8d5aa25a1c9903f60/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73617261682d616e74696c6c69612f594f4c4f5f5265616c69737469635f5553415f526f61645369676e735f313630636c61737365733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cf7fca7ae480ce780fb231f43bc15783f0289abacd4e20c8d5aa25a1c9903f60/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73617261682d616e74696c6c69612f594f4c4f5f5265616c69737469635f5553415f526f61645369676e735f313630636c61737365733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sarah-antillia/YOLO_Realistic_USA_RoadSigns_160classes?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : USA RoadSigns Dataset 160classes annotated by YOLO format.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DickensKP/yolov3-vehicle-pedestrian-trafficsign-detection-system\"\u003eDickensKP/yolov3-vehicle-pedestrian-trafficsign-detection-system\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b011a4b70f48f96314a21465b8f75bce73c69452469fe4288a559d8760de6b86/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4469636b656e734b502f796f6c6f76332d76656869636c652d7065646573747269616e2d747261666669637369676e2d646574656374696f6e2d73797374656d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b011a4b70f48f96314a21465b8f75bce73c69452469fe4288a559d8760de6b86/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4469636b656e734b502f796f6c6f76332d76656869636c652d7065646573747269616e2d747261666669637369676e2d646574656374696f6e2d73797374656d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DickensKP/yolov3-vehicle-pedestrian-trafficsign-detection-system?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于bubbliiiing的yolov3-pytorch框架，自主训练的车辆、行人、交通标志识别系统.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mkrupczak3/Coneslayer\"\u003emkrupczak3/Coneslayer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d7f3a609b1320de19a872cb0ce00798babc42406495246d144dba4ca2f17697d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6b727570637a616b332f436f6e65736c617965723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d7f3a609b1320de19a872cb0ce00798babc42406495246d144dba4ca2f17697d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6b727570637a616b332f436f6e65736c617965723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mkrupczak3/Coneslayer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A lightweight neural-network for rapid detection of traffic cones.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCrosswalk Detection\u003c/h4\u003e\u003ca id=\"user-content-crosswalk-detection\" class=\"anchor\" aria-label=\"Permalink: Crosswalk Detection\" href=\"#crosswalk-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e人行横道/斑马线检测\u003c/h5\u003e\u003ca id=\"user-content-人行横道斑马线检测\" class=\"anchor\" aria-label=\"Permalink: 人行横道/斑马线检测\" href=\"#人行横道斑马线检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zhangzhengde0225/CDNet\"\u003eCDNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/73b9ca8f4904da16f05b56fecd7d561409a3b95839b44789d2c9a2cd8347c4aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68616e677a68656e676465303232352f43444e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/73b9ca8f4904da16f05b56fecd7d561409a3b95839b44789d2c9a2cd8347c4aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68616e677a68656e676465303232352f43444e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zhangzhengde0225/CDNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"CDNet: a real-time and robust crosswalk detection network on Jetson nano based on YOLOv5\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/article/10.1007/s00521-022-07007-9\" rel=\"nofollow\"\u003eNeural Computing and Applications 2022\u003c/a\u003e\u003c/strong\u003e). \"微信公众号「CVer」《\u003ca href=\"https://mp.weixin.qq.com/s/2F3WBtfN_7DkhERMOH8-QA\" rel=\"nofollow\"\u003e上海交大提出CDNet：基于改进YOLOv5的斑马线和汽车过线行为检测\u003c/a\u003e》\"。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xN1ckuz/Crosswalks-Detection-using-YoloV5\"\u003exN1ckuz/Crosswalks-Detection-using-YoloV5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/413e971284333cfb2256ac7b1570b47dcd99b68370082aa20b245e107e34abd4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f784e31636b757a2f43726f737377616c6b732d446574656374696f6e2d7573696e672d596f6c6f56353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/413e971284333cfb2256ac7b1570b47dcd99b68370082aa20b245e107e34abd4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f784e31636b757a2f43726f737377616c6b732d446574656374696f6e2d7573696e672d596f6c6f56353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xN1ckuz/Crosswalks-Detection-using-YoloV5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Crosswalks Detection using YOLO, project for Computer Vision and Machine Perception course at University of Basilicata, Computer Science and Engineering.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eTraffic Accidents Detection\u003c/h4\u003e\u003ca id=\"user-content-traffic-accidents-detection\" class=\"anchor\" aria-label=\"Permalink: Traffic Accidents Detection\" href=\"#traffic-accidents-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e交通事故检测\u003c/h5\u003e\u003ca id=\"user-content-交通事故检测\" class=\"anchor\" aria-label=\"Permalink: 交通事故检测\" href=\"#交通事故检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/khaledsabry97/Argus\"\u003ekhaledsabry97/Argus\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8881ba679e60d084423cc05f79ef02b5c49be34207ed4c944b6b360c69b9f6da/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b68616c6564736162727939372f41726775733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8881ba679e60d084423cc05f79ef02b5c49be34207ed4c944b6b360c69b9f6da/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b68616c6564736162727939372f41726775733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/khaledsabry97/Argus?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Road Traffic Accidents Detection Based On Crash Estimation\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/document/9698968\" rel=\"nofollow\"\u003eIEEE ICENCO 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eRoad Damage Detection\u003c/h4\u003e\u003ca id=\"user-content-road-damage-detection\" class=\"anchor\" aria-label=\"Permalink: Road Damage Detection\" href=\"#road-damage-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch5 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e道路损伤检测\u003c/h5\u003e\u003ca id=\"user-content-道路损伤检测\" class=\"anchor\" aria-label=\"Permalink: 道路损伤检测\" href=\"#道路损伤检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/adnanmushtaq1996/Yolov4_Road_Damage_Detection\"\u003eadnanmushtaq1996/Yolov4_Road_Damage_Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8917757e1cfca085709f5845ec0324b5a442b7087727a88ae141a3484e5104eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61646e616e6d757368746171313939362f596f6c6f76345f526f61645f44616d6167655f446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8917757e1cfca085709f5845ec0324b5a442b7087727a88ae141a3484e5104eb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f61646e616e6d757368746171313939362f596f6c6f76345f526f61645f44616d6167655f446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/adnanmushtaq1996/Yolov4_Road_Damage_Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Repository to Train a Custom Yolov4 based object detector for road damage detection using the RDD2020 dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/E-Kozyreva/detection_potholes_yolov8n\"\u003eE-Kozyreva/detection_potholes_yolov8n\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c42f6b4edf5a82621f645c9429299c0d6c05abc0c0860d49e9a8ab9079431ae8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f452d4b6f7a79726576612f646574656374696f6e5f706f74686f6c65735f796f6c6f76386e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c42f6b4edf5a82621f645c9429299c0d6c05abc0c0860d49e9a8ab9079431ae8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f452d4b6f7a79726576612f646574656374696f6e5f706f74686f6c65735f796f6c6f76386e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/E-Kozyreva/detection_potholes_yolov8n?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Поиск выбоин на дорогах с использованием YOLOv8 Nano.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mounishvatti/pothole_detection_yolov8\"\u003emounishvatti/pothole_detection_yolov8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6ba8a39451f4ca80e57a046aec75ac4101b3249bff2d8d0063f2593f39528366/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6f756e69736876617474692f706f74686f6c655f646574656374696f6e5f796f6c6f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6ba8a39451f4ca80e57a046aec75ac4101b3249bff2d8d0063f2593f39528366/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6f756e69736876617474692f706f74686f6c655f646574656374696f6e5f796f6c6f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mounishvatti/pothole_detection_yolov8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Pothole Detection using Ultralytics YOLOv8\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAnimal Detection\u003c/h3\u003e\u003ca id=\"user-content-animal-detection\" class=\"anchor\" aria-label=\"Permalink: Animal Detection\" href=\"#animal-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e动物检测\u003c/h4\u003e\u003ca id=\"user-content-动物检测\" class=\"anchor\" aria-label=\"Permalink: 动物检测\" href=\"#动物检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SaiSwarup27/Animal-Intrusion-Detection\"\u003eSaiSwarup27/Animal-Intrusion-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1e2c1ab0d3544c1990548e3cca3001ab870078a842bb867247c0ace9f15ba0a7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53616953776172757032372f416e696d616c2d496e74727573696f6e2d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1e2c1ab0d3544c1990548e3cca3001ab870078a842bb867247c0ace9f15ba0a7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53616953776172757032372f416e696d616c2d496e74727573696f6e2d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SaiSwarup27/Animal-Intrusion-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Animal Detection using YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xcapt0/animal_recognition\"\u003excapt0/animal_recognition\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6fc614ba453018a29831e562e3959d305f792090bc0bee150a0409f2f26a54dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7863617074302f616e696d616c5f7265636f676e6974696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6fc614ba453018a29831e562e3959d305f792090bc0bee150a0409f2f26a54dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7863617074302f616e696d616c5f7265636f676e6974696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xcapt0/animal_recognition?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🦁 Let the robot recognize the animal instead of you | YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PhamDangNguyen/YOLOv5_Animals\"\u003ePhamDangNguyen/YOLOv5_Animals\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/46bc3ff562b5f8ba27f117a75a8f7c35814ddc9d0f25c3de4a7c710bef2d2090/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5068616d44616e674e677579656e2f594f4c4f76355f416e696d616c733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/46bc3ff562b5f8ba27f117a75a8f7c35814ddc9d0f25c3de4a7c710bef2d2090/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5068616d44616e674e677579656e2f594f4c4f76355f416e696d616c733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PhamDangNguyen/YOLOv5_Animals?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 for detection Animals.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Sabuj-CSE11/AnimalDetection\"\u003eSabuj-CSE11/AnimalDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4c3aeba6da79f1d198437140a8092282f7430c3a4df2fa60f7a7ca8d6d791566/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536162756a2d43534531312f416e696d616c446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4c3aeba6da79f1d198437140a8092282f7430c3a4df2fa60f7a7ca8d6d791566/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536162756a2d43534531312f416e696d616c446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Sabuj-CSE11/AnimalDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Cat and Dogs detection using YoloV5.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eHelmet Detection\u003c/h3\u003e\u003ca id=\"user-content-helmet-detection\" class=\"anchor\" aria-label=\"Permalink: Helmet Detection\" href=\"#helmet-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e头盔/安全帽检测\u003c/h4\u003e\u003ca id=\"user-content-头盔安全帽检测\" class=\"anchor\" aria-label=\"Permalink: 头盔/安全帽检测\" href=\"#头盔安全帽检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PeterH0323/Smart_Construction\"\u003ePeterH0323/Smart_Construction\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c01d4f71125def99db5fb613f9716bdc085984bcd0caa56e25f74b338bba1c66/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506574657248303332332f536d6172745f436f6e737472756374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c01d4f71125def99db5fb613f9716bdc085984bcd0caa56e25f74b338bba1c66/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506574657248303332332f536d6172745f436f6e737472756374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PeterH0323/Smart_Construction?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Head Person Helmet Detection on Construction Sites，基于目标检测工地安全帽和禁入危险区域识别系统。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Byronnar/tensorflow-serving-yolov3\"\u003eByronnar/tensorflow-serving-yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bf42033c7a95e46bf918f33729ec1897d1f9a2fa2a961513347103676c3e12a7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4279726f6e6e61722f74656e736f72666c6f772d73657276696e672d796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bf42033c7a95e46bf918f33729ec1897d1f9a2fa2a961513347103676c3e12a7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4279726f6e6e61722f74656e736f72666c6f772d73657276696e672d796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Byronnar/tensorflow-serving-yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 对原tensorflow-yolov3版本做了许多细节上的改进，增加了TensorFlow-Serving工程部署，训练了多个数据集，包括Visdrone2019, 安全帽等。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/gengyanlei/reflective-clothes-detect-yolov5\"\u003egengyanlei/reflective-clothes-detect-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6b39427a1bac6fe9dd0ec0e992822d1dc5552807c642eb32aa4f9670a94215d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67656e6779616e6c65692f7265666c6563746976652d636c6f746865732d6465746563742d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6b39427a1bac6fe9dd0ec0e992822d1dc5552807c642eb32aa4f9670a94215d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67656e6779616e6c65692f7265666c6563746976652d636c6f746865732d6465746563742d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/gengyanlei/reflective-clothes-detect-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : reflective-clothes-detect-dataset、helemet detection yolov5、工作服(反光衣)检测数据集、安全帽检测、施工人员穿戴检测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DataXujing/YOLO-V3-Tensorflow\"\u003eDataXujing/YOLO-V3-Tensorflow\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/237c316a53bc527c4b634612637bb77b320ac2d1bd2efafd8c068854e415bc8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f2d56332d54656e736f72666c6f773f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/237c316a53bc527c4b634612637bb77b320ac2d1bd2efafd8c068854e415bc8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f2d56332d54656e736f72666c6f773f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DataXujing/YOLO-V3-Tensorflow?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 👷 👷👷 YOLO V3(Tensorflow 1.x) 安全帽 识别 | 提供数据集下载和与预训练模型。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/rafiuddinkhan/Yolo-Training-GoogleColab\"\u003erafiuddinkhan/Yolo-Training-GoogleColab\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/18823f9533fbc515bfb18d6e4c1e23c59c216007c06ef6d86a46e8387ed1e498/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616669756464696e6b68616e2f596f6c6f2d547261696e696e672d476f6f676c65436f6c61623f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/18823f9533fbc515bfb18d6e4c1e23c59c216007c06ef6d86a46e8387ed1e498/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616669756464696e6b68616e2f596f6c6f2d547261696e696e672d476f6f676c65436f6c61623f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/rafiuddinkhan/Yolo-Training-GoogleColab?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Helmet Detection using tiny-yolo-v3 by training using your own dataset and testing the results in the google colaboratory.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BlcaKHat/yolov3-Helmet-Detection\"\u003eBlcaKHat/yolov3-Helmet-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b24cfe1cd35a36a8f943bc85dda487385f0e7c3299987791442b27b0728c6236/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426c63614b4861742f796f6c6f76332d48656c6d65742d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b24cfe1cd35a36a8f943bc85dda487385f0e7c3299987791442b27b0728c6236/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426c63614b4861742f796f6c6f76332d48656c6d65742d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BlcaKHat/yolov3-Helmet-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Training a YOLOv3 model to detect the presence of helmet for intrusion or traffic monitoring.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yumulinfeng1/YOLOv4-Hat-detection\"\u003eyumulinfeng1/YOLOv4-Hat-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/24d6018c8f1565e555dc30662dc07018e573a43a3e74bf8a7b3e5ba95a14c095/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f79756d756c696e66656e67312f594f4c4f76342d4861742d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/24d6018c8f1565e555dc30662dc07018e573a43a3e74bf8a7b3e5ba95a14c095/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f79756d756c696e66656e67312f594f4c4f76342d4861742d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yumulinfeng1/YOLOv4-Hat-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于YOLOv4的安全帽佩戴检测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FanDady/Helmet-Detection-YoloV5\"\u003eFanDady/Helmet-Detection-YoloV5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/73e01d7ba3874a54f80a6dda46c0f424a001612124b23c8a0a2fd9dac7299185/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46616e446164792f48656c6d65742d446574656374696f6e2d596f6c6f56353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/73e01d7ba3874a54f80a6dda46c0f424a001612124b23c8a0a2fd9dac7299185/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46616e446164792f48656c6d65742d446574656374696f6e2d596f6c6f56353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FanDady/Helmet-Detection-YoloV5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Safety helmet wearing detection on construction site based on YoloV5s-V5.0 including helmet dataset（基于YoloV5-V5.0的工地安全帽检测并且包含开源的安全帽数据集）。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RUI-LIU7/Helmet_Detection\"\u003eRUI-LIU7/Helmet_Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/dd2ab3d00b90389dc30a8e5a626bf73f40e787e2b6399e75ac71817d39aabaac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5255492d4c4955372f48656c6d65745f446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dd2ab3d00b90389dc30a8e5a626bf73f40e787e2b6399e75ac71817d39aabaac/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5255492d4c4955372f48656c6d65745f446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RUI-LIU7/Helmet_Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 使用yolov5算法实现安全帽以及危险区域的监测，同时接入海康摄像头实现实时监测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZijianWang1995/PPE_detection\"\u003eZijianWang1995/PPE_detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e1a25011715873e62509aea06a36f468be4cb31d839b81e1a46e4af59ab3eba3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a696a69616e57616e67313939352f5050455f646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e1a25011715873e62509aea06a36f468be4cb31d839b81e1a46e4af59ab3eba3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a696a69616e57616e67313939352f5050455f646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZijianWang1995/PPE_detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time PPE detection based on YOLO. Open high-quality dataset. \"Fast Personal Protective Equipment Detection for Real Construction Sites Using Deep Learning Approaches\". (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/1424-8220/21/10/3478\" rel=\"nofollow\"\u003eSensors 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eHand Detection\u003c/h3\u003e\u003ca id=\"user-content-hand-detection\" class=\"anchor\" aria-label=\"Permalink: Hand Detection\" href=\"#hand-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e手部检测\u003c/h4\u003e\u003ca id=\"user-content-手部检测\" class=\"anchor\" aria-label=\"Permalink: 手部检测\" href=\"#手部检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/cansik/yolo-hand-detection\"\u003ecansik/yolo-hand-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b979a323cee0755fd5a178051b98bd2ef5c075615082820aa62f2d703974df24/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63616e73696b2f796f6c6f2d68616e642d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b979a323cee0755fd5a178051b98bd2ef5c075615082820aa62f2d703974df24/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63616e73696b2f796f6c6f2d68616e642d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cansik/yolo-hand-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A pre-trained YOLO based hand detection network.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eGesture Recognition\u003c/h3\u003e\u003ca id=\"user-content-gesture-recognition\" class=\"anchor\" aria-label=\"Permalink: Gesture Recognition\" href=\"#gesture-recognition\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e手势/手语识别\u003c/h4\u003e\u003ca id=\"user-content-手势手语识别\" class=\"anchor\" aria-label=\"Permalink: 手势/手语识别\" href=\"#手势手语识别\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MahmudulAlam/Unified-Gesture-and-Fingertip-Detection\"\u003eMahmudulAlam/Unified-Gesture-and-Fingertip-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b801be0b59f8246c5c19475fa572c5f527d52927da44758e415fd8d04d1c6c08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d61686d7564756c416c616d2f556e69666965642d476573747572652d616e642d46696e6765727469702d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b801be0b59f8246c5c19475fa572c5f527d52927da44758e415fd8d04d1c6c08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d61686d7564756c416c616d2f556e69666965642d476573747572652d616e642d46696e6765727469702d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MahmudulAlam/Unified-Gesture-and-Fingertip-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Unified learning approach for egocentric hand gesture recognition and fingertip detection\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S0031320321003824\" rel=\"nofollow\"\u003eElsevier 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/insigh1/Interactive_ABCs_with_American_Sign_Language_using_Yolov5\"\u003einsigh1/Interactive_ABCs_with_American_Sign_Language_using_Yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c219186fb0ab1c5da121915be8c4f0f635af8ed41966a62d27497f60673930ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e73696768312f496e7465726163746976655f414243735f776974685f416d65726963616e5f5369676e5f4c616e67756167655f7573696e675f596f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c219186fb0ab1c5da121915be8c4f0f635af8ed41966a62d27497f60673930ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f696e73696768312f496e7465726163746976655f414243735f776974685f416d65726963616e5f5369676e5f4c616e67756167655f7573696e675f596f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/insigh1/Interactive_ABCs_with_American_Sign_Language_using_Yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Interactive ABC's with American Sign Language.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Dreaming-future/YOLO-Object-Detection\"\u003eDreaming-future/YOLO-Object-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6dcb15889d5d8a5cd1f2fc4da9dce94a66f6b0cb904fd32b698f489f15797431/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f447265616d696e672d6675747572652f594f4c4f2d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6dcb15889d5d8a5cd1f2fc4da9dce94a66f6b0cb904fd32b698f489f15797431/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f447265616d696e672d6675747572652f594f4c4f2d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Dreaming-future/YOLO-Object-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e :  YOLO-Object-Detection 集成多种yolo模型，作为一个模板进行目标检测。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAction Detection\u003c/h3\u003e\u003ca id=\"user-content-action-detection\" class=\"anchor\" aria-label=\"Permalink: Action Detection\" href=\"#action-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e行为检测\u003c/h4\u003e\u003ca id=\"user-content-行为检测\" class=\"anchor\" aria-label=\"Permalink: 行为检测\" href=\"#行为检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/wufan-tb/yolo_slowfast\"\u003ewufan-tb/yolo_slowfast\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a692976db9bbe3f0541fcbbdef1c2a29e953eaba62142b61fd8b31ed8d68a340/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f777566616e2d74622f796f6c6f5f736c6f77666173743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a692976db9bbe3f0541fcbbdef1c2a29e953eaba62142b61fd8b31ed8d68a340/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f777566616e2d74622f796f6c6f5f736c6f77666173743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wufan-tb/yolo_slowfast?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A realtime action detection frame work based on PytorchVideo.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eEmotion Recognition\u003c/h3\u003e\u003ca id=\"user-content-emotion-recognition\" class=\"anchor\" aria-label=\"Permalink: Emotion Recognition\" href=\"#emotion-recognition\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e情感识别\u003c/h4\u003e\u003ca id=\"user-content-情感识别\" class=\"anchor\" aria-label=\"Permalink: 情感识别\" href=\"#情感识别\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/Tandon-A/emotic\"\u003eTandon-A/emotic\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b8cc2d06695b1944643cf76b6f89e11e53e7e8d1f6c1fdc54f71e3f36c412650/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54616e646f6e2d412f656d6f7469633f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b8cc2d06695b1944643cf76b6f89e11e53e7e8d1f6c1fdc54f71e3f36c412650/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54616e646f6e2d412f656d6f7469633f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Tandon-A/emotic?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Context based emotion recognition using emotic dataset\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2003.13401\" rel=\"nofollow\"\u003earXiv 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eHuman Pose Estimation\u003c/h3\u003e\u003ca id=\"user-content-human-pose-estimation\" class=\"anchor\" aria-label=\"Permalink: Human Pose Estimation\" href=\"#human-pose-estimation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e人体姿态估计\u003c/h4\u003e\u003ca id=\"user-content-人体姿态估计\" class=\"anchor\" aria-label=\"Permalink: 人体姿态估计\" href=\"#人体姿态估计\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wmcnally/kapao\"\u003ewmcnally/kapao\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e7a853285fe26109f5beb31c4a3381d8425796fee9c99e3b3cf8b13ac924806f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776d636e616c6c792f6b6170616f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e7a853285fe26109f5beb31c4a3381d8425796fee9c99e3b3cf8b13ac924806f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776d636e616c6c792f6b6170616f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wmcnally/kapao?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : KAPAO is a state-of-the-art single-stage human pose estimation model that detects keypoints and poses as objects and fuses the detections to predict human poses. \"Rethinking Keypoint Representations: Modeling Keypoints and Poses as Objects for Multi-Person Human Pose Estimation\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2111.08557\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TexasInstruments/edgeai-yolov5\"\u003eTexasInstruments/edgeai-yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e62031557ee76a2ca62cac054c28b747295d20a1eef167c2d092f0e4d23d6102/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5465786173496e737472756d656e74732f6564676561692d796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e62031557ee76a2ca62cac054c28b747295d20a1eef167c2d092f0e4d23d6102/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5465786173496e737472756d656e74732f6564676561692d796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TexasInstruments/edgeai-yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLO-Pose: Enhancing YOLO for Multi Person Pose Estimation Using Object Keypoint Similarity Loss\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2204.06806\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TexasInstruments/edgeai-yolox\"\u003eTexasInstruments/edgeai-yolox\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/213b6398624215a716010c173b6a75ab209108dca03e0b6b4bba1448b87af8d0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5465786173496e737472756d656e74732f6564676561692d796f6c6f783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/213b6398624215a716010c173b6a75ab209108dca03e0b6b4bba1448b87af8d0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5465786173496e737472756d656e74732f6564676561692d796f6c6f783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TexasInstruments/edgeai-yolox?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"YOLO-Pose: Enhancing YOLO for Multi Person Pose Estimation Using Object Keypoint Similarity Loss\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2204.06806\" rel=\"nofollow\"\u003earXiv 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jinfagang/VIBE_yolov5\"\u003ejinfagang/VIBE_yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/06360061dd2ee2531f39027468d49d24292179108f70ac1b4735b7a1ed5605d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a696e666167616e672f564942455f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/06360061dd2ee2531f39027468d49d24292179108f70ac1b4735b7a1ed5605d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a696e666167616e672f564942455f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jinfagang/VIBE_yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Using YOLOv5 as detection on VIBE. \"VIBE: Video Inference for Human Body Pose and Shape Estimation\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_CVPR_2020/html/Kocabas_VIBE_Video_Inference_for_Human_Body_Pose_and_Shape_Estimation_CVPR_2020_paper.html\" rel=\"nofollow\"\u003eCVPR 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zhuoxiangpang/ism_person_openpose\"\u003ezhuoxiangpang/ism_person_openpose\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/02e2c5f313360414a8a318ce36064618ca086c35a4f1126043e045c8801aba77/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68756f7869616e6770616e672f69736d5f706572736f6e5f6f70656e706f73653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/02e2c5f313360414a8a318ce36064618ca086c35a4f1126043e045c8801aba77/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a68756f7869616e6770616e672f69736d5f706572736f6e5f6f70656e706f73653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zhuoxiangpang/ism_person_openpose?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5人体检测+openpose姿态检测 实现摔倒检测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pengyang1225/yolov5_person_pose\"\u003epengyang1225/yolov5_person_pose\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b75a6f672e61c1edca09514ada8bf2d7d7a3a9c4c1f8fc0508f2d3fd83a3776a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70656e6779616e67313232352f796f6c6f76355f706572736f6e5f706f73653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b75a6f672e61c1edca09514ada8bf2d7d7a3a9c4c1f8fc0508f2d3fd83a3776a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70656e6779616e67313232352f796f6c6f76355f706572736f6e5f706f73653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pengyang1225/yolov5_person_pose?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于yolov5的person—pose。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hpc203/yolov5_pose_opencv\"\u003ehpc203/yolov5_pose_opencv\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b2edc2f4299262e8f271926d8f7b8fed8eb46e7828851e2acd637e559b251626/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f796f6c6f76355f706f73655f6f70656e63763f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b2edc2f4299262e8f271926d8f7b8fed8eb46e7828851e2acd637e559b251626/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870633230332f796f6c6f76355f706f73655f6f70656e63763f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hpc203/yolov5_pose_opencv?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 使用OpenCV部署yolov5-pose目标检测+人体姿态估计，包含C++和Python两个版本的程序。支持yolov5s，yolov5m，yolov5l。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RizwanMunawar/yolov7-pose-estimation\"\u003eRizwanMunawar/yolov7-pose-estimation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8e4176534f85d94c924d8ba21b62a474b12af86b118d37d9a9bec9a065564434/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d706f73652d657374696d6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8e4176534f85d94c924d8ba21b62a474b12af86b118d37d9a9bec9a065564434/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d706f73652d657374696d6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RizwanMunawar/yolov7-pose-estimation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv7 Pose estimation using OpenCV, PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/nanmi/yolov7-pose\"\u003enanmi/yolov7-pose\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e8415b0bcd3e46d104f4cd1fd98cf4f1cc7e86035bb29a64751ec0ecb0c9e0f9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e616e6d692f796f6c6f76372d706f73653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e8415b0bcd3e46d104f4cd1fd98cf4f1cc7e86035bb29a64751ec0ecb0c9e0f9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e616e6d692f796f6c6f76372d706f73653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/nanmi/yolov7-pose?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : pose detection base on yolov7.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eDistance Measurement\u003c/h3\u003e\u003ca id=\"user-content-distance-measurement\" class=\"anchor\" aria-label=\"Permalink: Distance Measurement\" href=\"#distance-measurement\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e距离测量\u003c/h4\u003e\u003ca id=\"user-content-距离测量\" class=\"anchor\" aria-label=\"Permalink: 距离测量\" href=\"#距离测量\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/davidfrz/yolov5_distance_count\"\u003edavidfrz/yolov5_distance_count\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6f3c7e22bb883258ad3fe5ea0533096fbf1b3007b446c905182b62bfabf3eade/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646176696466727a2f796f6c6f76355f64697374616e63655f636f756e743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6f3c7e22bb883258ad3fe5ea0533096fbf1b3007b446c905182b62bfabf3eade/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646176696466727a2f796f6c6f76355f64697374616e63655f636f756e743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/davidfrz/yolov5_distance_count?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 通过yolov5实现目标检测+双目摄像头实现距离测量。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wenyishengkingkong/realsense-D455-YOLOV5\"\u003ewenyishengkingkong/realsense-D455-YOLOV5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f411b21110b2810bf35aaaa912d369756d86f1c4110ebaf2b9e9f8a6cf047733/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77656e79697368656e676b696e676b6f6e672f7265616c73656e73652d443435352d594f4c4f56353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f411b21110b2810bf35aaaa912d369756d86f1c4110ebaf2b9e9f8a6cf047733/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77656e79697368656e676b696e676b6f6e672f7265616c73656e73652d443435352d594f4c4f56353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wenyishengkingkong/realsense-D455-YOLOV5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 利用realsense深度相机实现yolov5目标检测的同时测出距离。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Thinkin99/yolov5_d435i_detection\"\u003eThinkin99/yolov5_d435i_detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/957c91192103378751f7d562a3434e9a84d0ac6e58033d8fca708b282d57298e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5468696e6b696e39392f796f6c6f76355f64343335695f646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/957c91192103378751f7d562a3434e9a84d0ac6e58033d8fca708b282d57298e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5468696e6b696e39392f796f6c6f76355f64343335695f646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Thinkin99/yolov5_d435i_detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 使用realsense d435i相机，基于pytorch实现yolov5目标检测，返回检测目标相机坐标系下的位置信息。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MUCHWAY/detect_distance_gazebo\"\u003eMUCHWAY/detect_distance_gazebo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9670e1862ee077150962c6dca7dec4a2f6b16a47d0fb3ea42ba3e6daa699eb34/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d5543485741592f6465746563745f64697374616e63655f67617a65626f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9670e1862ee077150962c6dca7dec4a2f6b16a47d0fb3ea42ba3e6daa699eb34/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d5543485741592f6465746563745f64697374616e63655f67617a65626f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MUCHWAY/detect_distance_gazebo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5+camera_distance+gazebo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/magisystem0408/yolov5-DeepSort-RealSenseD435i\"\u003emagisystem0408/yolov5-DeepSort-RealSenseD435i\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4cf406cb1a1ae78ef70a1c8eb7e7ad8448bbca98c9b0481b4bd4c1e3e157c490/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61676973797374656d303430382f796f6c6f76352d44656570536f72742d5265616c53656e736544343335693f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4cf406cb1a1ae78ef70a1c8eb7e7ad8448bbca98c9b0481b4bd4c1e3e157c490/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d61676973797374656d303430382f796f6c6f76352d44656570536f72742d5265616c53656e736544343335693f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/magisystem0408/yolov5-DeepSort-RealSenseD435i?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5+Realsence+DeepSense D435i.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eInstance and Semantic Segmentation\u003c/h3\u003e\u003ca id=\"user-content-instance-and-semantic-segmentation\" class=\"anchor\" aria-label=\"Permalink: Instance and Semantic Segmentation\" href=\"#instance-and-semantic-segmentation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e实例和语义分割\u003c/h4\u003e\u003ca id=\"user-content-实例和语义分割\" class=\"anchor\" aria-label=\"Permalink: 实例和语义分割\" href=\"#实例和语义分割\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/facebookresearch/segment-anything\"\u003eSAM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fda9f7bfbe5462db4c5ea420348ca3592c669a0d5b92eca51d8bb1044b5c11b5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66616365626f6f6b72657365617263682f7365676d656e742d616e797468696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fda9f7bfbe5462db4c5ea420348ca3592c669a0d5b92eca51d8bb1044b5c11b5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66616365626f6f6b72657365617263682f7365676d656e742d616e797468696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/facebookresearch/segment-anything?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The repository provides code for running inference with the SegmentAnything Model (SAM), links for downloading the trained model checkpoints, and example notebooks that show how to use the model. \"Segment Anything\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2304.02643\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/IDEA-Research/Grounded-Segment-Anything\"\u003eGrounded-SAM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a6feb0326dc5825bc17354675a5c5cf4e0b32f66fe541a0634748c4923204f75/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f47726f756e6465642d5365676d656e742d416e797468696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a6feb0326dc5825bc17354675a5c5cf4e0b32f66fe541a0634748c4923204f75/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f494445412d52657365617263682f47726f756e6465642d5365676d656e742d416e797468696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/IDEA-Research/Grounded-Segment-Anything?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Marrying Grounding DINO with Segment Anything \u0026amp; Stable Diffusion \u0026amp; Tag2Text \u0026amp; BLIP \u0026amp; Whisper \u0026amp; ChatBot - Automatically Detect , Segment and Generate Anything with Image, Text, and Audio Inputs. We plan to create a very interesting demo by combining \u003ca href=\"https://github.com/IDEA-Research/GroundingDINO\"\u003eGrounding DINO\u003c/a\u003e and \u003ca href=\"https://github.com/facebookresearch/segment-anything\"\u003eSegment Anything\u003c/a\u003e which aims to detect and segment Anything with text inputs!\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Laughing-q/yolov5-q\"\u003eLaughing-q/yolov5-q\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7152dcf3d7f3dc6ec308d1cc6441248634db62a1695ce2bd2af0e043033b0899/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c61756768696e672d712f796f6c6f76352d713f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7152dcf3d7f3dc6ec308d1cc6441248634db62a1695ce2bd2af0e043033b0899/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c61756768696e672d712f796f6c6f76352d713f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Laughing-q/yolov5-q?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repo is plan for instance segmentation based on yolov5-6.0 and yolact.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TomMao23/multiyolov5\"\u003eTomMao23/multiyolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/830e87a96d9638b31369440988efaed266e83ef08ae0f9595d89e2d292d5967d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f546f6d4d616f32332f6d756c7469796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/830e87a96d9638b31369440988efaed266e83ef08ae0f9595d89e2d292d5967d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f546f6d4d616f32332f6d756c7469796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TomMao23/multiyolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Multi YOLO V5——Detection and Semantic Segmentation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ArtyZe/yolo_segmentation\"\u003eArtyZe/yolo_segmentation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/be357a9a771a1ef145ef780243f076b7e0c20d52c5f826d850b3bbb3fcc72648/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f417274795a652f796f6c6f5f7365676d656e746174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/be357a9a771a1ef145ef780243f076b7e0c20d52c5f826d850b3bbb3fcc72648/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f417274795a652f796f6c6f5f7365676d656e746174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ArtyZe/yolo_segmentation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : image (semantic segmentation) instance segmentation by darknet or yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/midasklr/yolov5ds\"\u003emidasklr/yolov5ds\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2b968f05e1ed8c5793fb87c3cde8af8d72fa60617703e6e1e2008dfc82119c14/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696461736b6c722f796f6c6f763564733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2b968f05e1ed8c5793fb87c3cde8af8d72fa60617703e6e1e2008dfc82119c14/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d696461736b6c722f796f6c6f763564733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/midasklr/yolov5ds?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : multi-task yolov5 with detection and segmentation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RizwanMunawar/yolov7-segmentation\"\u003eRizwanMunawar/yolov7-segmentation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/71369aff60351deee25a900ac1ae7973a432ac0031faafe731f0e5b7db3f28b4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d7365676d656e746174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/71369aff60351deee25a900ac1ae7973a432ac0031faafe731f0e5b7db3f28b4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d7365676d656e746174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RizwanMunawar/yolov7-segmentation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv7 Instance Segmentation using OpenCV and PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/leandro-svg/Yolov7_Segmentation_Tensorrt\"\u003eleandro-svg/Yolov7_Segmentation_Tensorrt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/edb17dbd904dda379f84e43da090ffdac40eb9d2c6d93868026791b982653480/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c65616e64726f2d7376672f596f6c6f76375f5365676d656e746174696f6e5f54656e736f7272743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/edb17dbd904dda379f84e43da090ffdac40eb9d2c6d93868026791b982653480/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c65616e64726f2d7376672f596f6c6f76375f5365676d656e746174696f6e5f54656e736f7272743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/leandro-svg/Yolov7_Segmentation_Tensorrt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The real-time Instance Segmentation Algorithm Yolov7 running on TensoRT and ONNX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/akashAD98/YOLOV8_SAM\"\u003eakashAD98/YOLOV8_SAM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3e431c9fcef5989feedf5872782e2c0155d6c5ce08162fb01c2cd9686b69338e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616b617368414439382f594f4c4f56385f53414d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3e431c9fcef5989feedf5872782e2c0155d6c5ce08162fb01c2cd9686b69338e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616b617368414439382f594f4c4f56385f53414d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/akashAD98/YOLOV8_SAM?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Use yolov8 \u0026amp; SAM model to get segmention for custom model.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e3D Object Detection\u003c/h3\u003e\u003ca id=\"user-content-3d-object-detection\" class=\"anchor\" aria-label=\"Permalink: 3D Object Detection\" href=\"#3d-object-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e三维目标检测\u003c/h4\u003e\u003ca id=\"user-content-三维目标检测\" class=\"anchor\" aria-label=\"Permalink: 三维目标检测\" href=\"#三维目标检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ADLab-AutoDrive/BEVFusion\"\u003eADLab-AutoDrive/BEVFusion\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4f0facc8e862e6934dd4b26eccc46c632fe40779d334bf4c9a7c9633b89baa05/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41444c61622d4175746f44726976652f424556467573696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4f0facc8e862e6934dd4b26eccc46c632fe40779d334bf4c9a7c9633b89baa05/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41444c61622d4175746f44726976652f424556467573696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ADLab-AutoDrive/BEVFusion?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"BEVFusion: A Simple and Robust LiDAR-Camera Fusion Framework\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2205.13790\" rel=\"nofollow\"\u003eNeurIPS 2022\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mit-han-lab/bevfusion\"\u003emit-han-lab/bevfusion\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4ecb9355993b34f1c7c4d5c4ef89a339c77f00158f1e82c48eb65a207a00ebe0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69742d68616e2d6c61622f626576667573696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4ecb9355993b34f1c7c4d5c4ef89a339c77f00158f1e82c48eb65a207a00ebe0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d69742d68616e2d6c61622f626576667573696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mit-han-lab/bevfusion?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird's-Eye View Representation\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2205.13542\" rel=\"nofollow\"\u003eICRA 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DYZhang09/SAM3D\"\u003eSAM3D\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d134f81b80fe55343cee290353aa2a7fdc669531e096c9070ddbf40711cd0323/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44595a68616e6730392f53414d33443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d134f81b80fe55343cee290353aa2a7fdc669531e096c9070ddbf40711cd0323/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f44595a68616e6730392f53414d33443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DYZhang09/SAM3D?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"SAM3D: Zero-Shot 3D Object Detection via \u003ca href=\"https://github.com/facebookresearch/segment-anything\"\u003eSegment Anything\u003c/a\u003e Model\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2306.02245\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/maudzung/YOLO3D-YOLOv4-PyTorch\"\u003emaudzung/YOLO3D-YOLOv4-PyTorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b55d59b598e1346a1e42417d4ec33526784aa0277164afbb7c4fe0be3dae223c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6175647a756e672f594f4c4f33442d594f4c4f76342d5079546f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b55d59b598e1346a1e42417d4ec33526784aa0277164afbb7c4fe0be3dae223c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6175647a756e672f594f4c4f33442d594f4c4f76342d5079546f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/maudzung/YOLO3D-YOLOv4-PyTorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The PyTorch Implementation based on YOLOv4 of the paper: \"YOLO3D: End-to-end real-time 3D Oriented Object Bounding Box Detection from LiDAR Point Cloud\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_eccv_2018_workshops/w18/html/Ali_YOLO3D_End-to-end_real-time_3D_Oriented_Object_Bounding_Box_Detection_from_ECCVW_2018_paper.html\" rel=\"nofollow\"\u003eECCV 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/maudzung/Complex-YOLOv4-Pytorch\"\u003emaudzung/Complex-YOLOv4-Pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0367af3f9db012be0ff10c588e535bdb35e2dae11ce4244023bc7603cef32c6f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6175647a756e672f436f6d706c65782d594f4c4f76342d5079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0367af3f9db012be0ff10c588e535bdb35e2dae11ce4244023bc7603cef32c6f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6175647a756e672f436f6d706c65782d594f4c4f76342d5079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/maudzung/Complex-YOLOv4-Pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The PyTorch Implementation based on YOLOv4 of the paper: \"Complex-YOLO: Real-time 3D Object Detection on Point Clouds\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1803.06199\" rel=\"nofollow\"\u003earXiv 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AI-liu/Complex-YOLO\"\u003eAI-liu/Complex-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bf5f504a4eb84723010be1cc872585dbce791942f67e308b28333dc8f3dca662/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41492d6c69752f436f6d706c65782d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bf5f504a4eb84723010be1cc872585dbce791942f67e308b28333dc8f3dca662/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41492d6c69752f436f6d706c65782d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AI-liu/Complex-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is an unofficial implementation of \"Complex-YOLO: Real-time 3D Object Detection on Point Clouds in pytorch\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1803.06199\" rel=\"nofollow\"\u003earXiv 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ghimiredhikura/Complex-YOLOv3\"\u003eghimiredhikura/Complex-YOLOv3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fd7ef8509c09b1b14c9ad5f709dc970afea821ae593088d7b0f9b11b550242cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6768696d6972656468696b7572612f436f6d706c65782d594f4c4f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fd7ef8509c09b1b14c9ad5f709dc970afea821ae593088d7b0f9b11b550242cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6768696d6972656468696b7572612f436f6d706c65782d594f4c4f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ghimiredhikura/Complex-YOLOv3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Complete but Unofficial PyTorch Implementation of \"Complex-YOLO: Real-time 3D Object Detection on Point Clouds with YoloV3\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1803.06199\" rel=\"nofollow\"\u003earXiv 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ruhyadi/YOLO3D\"\u003eruhyadi/YOLO3D\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6c8234eb7af33de41de806cffa55f847978cb8f8fd1eac9dd3c47ecfd4198739/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f727568796164692f594f4c4f33443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6c8234eb7af33de41de806cffa55f847978cb8f8fd1eac9dd3c47ecfd4198739/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f727568796164692f594f4c4f33443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ruhyadi/YOLO3D?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO 3D Object Detection for Autonomous Driving Vehicle. Reference by \u003ca href=\"https://github.com/skhadem/3D-BoundingBox\"\u003eskhadem/3D-BoundingBox\u003c/a\u003e, \"3D Bounding Box Estimation Using Deep Learning and Geometry\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_cvpr_2017/html/Mousavian_3D_Bounding_Box_CVPR_2017_paper.html\" rel=\"nofollow\"\u003eCVPR 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ruhyadi/yolo3d-lightning\"\u003eruhyadi/yolo3d-lightning\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6c8234eb7af33de41de806cffa55f847978cb8f8fd1eac9dd3c47ecfd4198739/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f727568796164692f594f4c4f33443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6c8234eb7af33de41de806cffa55f847978cb8f8fd1eac9dd3c47ecfd4198739/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f727568796164692f594f4c4f33443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ruhyadi/YOLO3D?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO for 3D Object Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Yuanchu/YOLO3D\"\u003eYuanchu/YOLO3D\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a025024ff0a9d1dc69c8adbdaf1ef5a430bc1a88ad7c9daffb77c25a09eb47f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5975616e6368752f594f4c4f33443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a025024ff0a9d1dc69c8adbdaf1ef5a430bc1a88ad7c9daffb77c25a09eb47f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5975616e6368752f594f4c4f33443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Yuanchu/YOLO3D?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Implementation of a basic YOLO model for object detection in 3D.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/EmiyaNing/3D-YOLO\"\u003eEmiyaNing/3D-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/83960daa29d8ae0ec81f2f111e4c3ed6ab3d70f6812d2ddffce291225a864867/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f456d6979614e696e672f33442d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/83960daa29d8ae0ec81f2f111e4c3ed6ab3d70f6812d2ddffce291225a864867/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f456d6979614e696e672f33442d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/EmiyaNing/3D-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO v5 for Lidar-based 3D BEV Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSLAM Field Detection\u003c/h3\u003e\u003ca id=\"user-content-slam-field-detection\" class=\"anchor\" aria-label=\"Permalink: SLAM Field Detection\" href=\"#slam-field-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSLAM领域检测\u003c/h4\u003e\u003ca id=\"user-content-slam领域检测\" class=\"anchor\" aria-label=\"Permalink: SLAM领域检测\" href=\"#slam领域检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bijustin/YOLO-DynaSLAM\"\u003ebijustin/YOLO-DynaSLAM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fef880c17702d2e5c090183099c2bcb6e10472f6ce8a445b83c00276b99bea58/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62696a757374696e2f594f4c4f2d44796e61534c414d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fef880c17702d2e5c090183099c2bcb6e10472f6ce8a445b83c00276b99bea58/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62696a757374696e2f594f4c4f2d44796e61534c414d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bijustin/YOLO-DynaSLAM?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO Dynamic ORB_SLAM is a visual SLAM system that is robust in dynamic scenarios for RGB-D configuration.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BzdTaisa/YoloPlanarSLAM\"\u003eBzdTaisa/YoloPlanarSLAM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/35574c7fc2d732c8ed1919e3e65241a48e971ac52bb920573079d0497ba47ed6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427a6454616973612f596f6c6f506c616e6172534c414d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/35574c7fc2d732c8ed1919e3e65241a48e971ac52bb920573079d0497ba47ed6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427a6454616973612f596f6c6f506c616e6172534c414d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BzdTaisa/YoloPlanarSLAM?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO-Planar-SLAM.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/saransapmaz/cv-slam-object-determination\"\u003esaransapmaz/cv-slam-object-determination\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c9b683e6262df15b55150fb6f84dcb712bf8ed67ace610be643bf9b7dff6f14d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736172616e7361706d617a2f63762d736c616d2d6f626a6563742d64657465726d696e6174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c9b683e6262df15b55150fb6f84dcb712bf8ed67ace610be643bf9b7dff6f14d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736172616e7361706d617a2f63762d736c616d2d6f626a6563742d64657465726d696e6174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/saransapmaz/cv-slam-object-determination?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object detection with hector slam and YOLO v3 computer vision algorithm.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eIndustrial Defect Detection\u003c/h3\u003e\u003ca id=\"user-content-industrial-defect-detection\" class=\"anchor\" aria-label=\"Permalink: Industrial Defect Detection\" href=\"#industrial-defect-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e工业缺陷检测\u003c/h4\u003e\u003ca id=\"user-content-工业缺陷检测\" class=\"anchor\" aria-label=\"Permalink: 工业缺陷检测\" href=\"#工业缺陷检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/annsonic/Steel_defect\"\u003eannsonic/Steel_defect\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5db29d69c135d3872bcb125f4f92a51ab767e75df0296f17861101630d4e02a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616e6e736f6e69632f537465656c5f6465666563743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5db29d69c135d3872bcb125f4f92a51ab767e75df0296f17861101630d4e02a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616e6e736f6e69632f537465656c5f6465666563743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/annsonic/Steel_defect?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Exercise: Use YOLO to detect hot-rolled steel strip surface defects (NEU-DET dataset).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/VanillaHours/pcbDefectDetectionYOLO\"\u003eVanillaHours/pcbDefectDetectionYOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0aa3c7f87fcac4b519c6ffd5c773bab0b5ebbbb2b81efbe537368dee3e625cdf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f56616e696c6c61486f7572732f706362446566656374446574656374696f6e594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0aa3c7f87fcac4b519c6ffd5c773bab0b5ebbbb2b81efbe537368dee3e625cdf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f56616e696c6c61486f7572732f706362446566656374446574656374696f6e594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/VanillaHours/pcbDefectDetectionYOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PCB defect detection using YOLOv3, on DeepPCB dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/talisma-cassoma/pcb-components-detection-recognition\"\u003etalisma-cassoma/pcb-components-detection-recognition\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/50184ae7044e67026044e4cf40acd96afca74e0e40c13851112a2c2d797fe71f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616c69736d612d636173736f6d612f7063622d636f6d706f6e656e74732d646574656374696f6e2d7265636f676e6974696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/50184ae7044e67026044e4cf40acd96afca74e0e40c13851112a2c2d797fe71f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616c69736d612d636173736f6d612f7063622d636f6d706f6e656e74732d646574656374696f6e2d7265636f676e6974696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/talisma-cassoma/pcb-components-detection-recognition?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : this code shows the train and test of a YOLOV5 convolutional neural network for detection of electronics components.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Luckycat518/Yolo-MSAPF\"\u003eLuckycat518/Yolo-MSAPF\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4debe7dc2469da7fc091f76c3fa0e6d17585c297799591e8cdb8fc24e18492f1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c75636b796361743531382f596f6c6f2d4d534150463f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4debe7dc2469da7fc091f76c3fa0e6d17585c297799591e8cdb8fc24e18492f1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c75636b796361743531382f596f6c6f2d4d534150463f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Luckycat518/Yolo-MSAPF?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo-MSAPF: Multi-Scale Alignment fusion with Parallel feature Filtering model for high accuracy weld defect detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/JiaLim98/YOLO-PCB\"\u003eJiaLim98/YOLO-PCB\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a987163daa51a9e05787d1a1daea5c1d3c9d3cf40aa5ce43ffe94e0ab5dd4b09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a69614c696d39382f594f4c4f2d5043423f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a987163daa51a9e05787d1a1daea5c1d3c9d3cf40aa5ce43ffe94e0ab5dd4b09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a69614c696d39382f594f4c4f2d5043423f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/JiaLim98/YOLO-PCB?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Deep Context Learning based PCB Defect Detection Model with Anomalous Trend Alarming System.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSAR Image Detection\u003c/h3\u003e\u003ca id=\"user-content-sar-image-detection\" class=\"anchor\" aria-label=\"Permalink: SAR Image Detection\" href=\"#sar-image-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e合成孔径雷达图像检测\u003c/h4\u003e\u003ca id=\"user-content-合成孔径雷达图像检测\" class=\"anchor\" aria-label=\"Permalink: 合成孔径雷达图像检测\" href=\"#合成孔径雷达图像检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/humblecoder612/SAR_yolov3\"\u003ehumblecoder612/SAR_yolov3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/39a47bc1cb3f0ec40cc1d2606ac82d9739863cbcdb13989fa8092c1d0f19900e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756d626c65636f6465723631322f5341525f796f6c6f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/39a47bc1cb3f0ec40cc1d2606ac82d9739863cbcdb13989fa8092c1d0f19900e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f68756d626c65636f6465723631322f5341525f796f6c6f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/humblecoder612/SAR_yolov3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Best Accruacy:speed ratio SAR Ship detection in the world.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSafety Monitoring Field Detection\u003c/h3\u003e\u003ca id=\"user-content-safety-monitoring-field-detection\" class=\"anchor\" aria-label=\"Permalink: Safety Monitoring Field Detection\" href=\"#safety-monitoring-field-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e安防监控领域检测\u003c/h4\u003e\u003ca id=\"user-content-安防监控领域检测\" class=\"anchor\" aria-label=\"Permalink: 安防监控领域检测\" href=\"#安防监控领域检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/gengyanlei/fire-smoke-detect-yolov4\"\u003egengyanlei/fire-smoke-detect-yolov4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/899d5c2fe809fca1d281c5934cd3deb555cf5d183cf95836c0058a06d6854d72/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67656e6779616e6c65692f666972652d736d6f6b652d6465746563742d796f6c6f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/899d5c2fe809fca1d281c5934cd3deb555cf5d183cf95836c0058a06d6854d72/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f67656e6779616e6c65692f666972652d736d6f6b652d6465746563742d796f6c6f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/gengyanlei/fire-smoke-detect-yolov4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : fire-smoke-detect-yolov4-yolov5 and fire-smoke-detection-dataset 火灾检测，烟雾检测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CVUsers/Smoke-Detect-by-YoloV5\"\u003eCVUsers/Smoke-Detect-by-YoloV5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7ac573df71b6e351ec158d7d1650b292f0fc1a1c6200cddc4dc1f3c22f5f5715/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f435655736572732f536d6f6b652d4465746563742d62792d596f6c6f56353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7ac573df71b6e351ec158d7d1650b292f0fc1a1c6200cddc4dc1f3c22f5f5715/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f435655736572732f536d6f6b652d4465746563742d62792d596f6c6f56353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CVUsers/Smoke-Detect-by-YoloV5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov5 real time smoke detection system.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CVUsers/Fire-Detect-by-YoloV5\"\u003eCVUsers/Fire-Detect-by-YoloV5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7094c49a8b61997426da07128ce42e25b100bb6b2594e11ed81a654a66e556a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f435655736572732f466972652d4465746563742d62792d596f6c6f56353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7094c49a8b61997426da07128ce42e25b100bb6b2594e11ed81a654a66e556a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f435655736572732f466972652d4465746563742d62792d596f6c6f56353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CVUsers/Fire-Detect-by-YoloV5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 火灾检测，浓烟检测，吸烟检测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/spacewalk01/Yolov5-Fire-Detection\"\u003espacewalk01/Yolov5-Fire-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/52a3adbb86a0e44b6a9af9dd5c79f43e64869bd42dc937560032c6e07f3e56a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737061636577616c6b30312f596f6c6f76352d466972652d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/52a3adbb86a0e44b6a9af9dd5c79f43e64869bd42dc937560032c6e07f3e56a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f737061636577616c6b30312f596f6c6f76352d466972652d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/spacewalk01/Yolov5-Fire-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Train yolov5 to detect fire in an image or video.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/roflcoopter/viseron\"\u003eroflcoopter/viseron\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d81b59d13d5bb2f0f3f020b60dc4faadaa8f0ecad7eda04e793dea4cb61664d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f666c636f6f707465722f76697365726f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d81b59d13d5bb2f0f3f020b60dc4faadaa8f0ecad7eda04e793dea4cb61664d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f666c636f6f707465722f76697365726f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/roflcoopter/viseron?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Viseron - Self-hosted NVR with object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/dcmartin/motion-ai\"\u003edcmartin/motion-ai\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8dac5c471352afe3938d28a18d65afdfacf2f850b40a690f0d0b2e65f6c3f1a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64636d617274696e2f6d6f74696f6e2d61693f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8dac5c471352afe3938d28a18d65afdfacf2f850b40a690f0d0b2e65f6c3f1a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64636d617274696e2f6d6f74696f6e2d61693f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/dcmartin/motion-ai?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : AI assisted motion detection for Home Assistant.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Nico31415/Drowning-Detector\"\u003eNico31415/Drowning-Detector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6a462073a1f2d6f8d0d2162e8438f3f66aeb1e59cc84c4764ab645b802df6ffb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e69636f33313431352f44726f776e696e672d4465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6a462073a1f2d6f8d0d2162e8438f3f66aeb1e59cc84c4764ab645b802df6ffb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4e69636f33313431352f44726f776e696e672d4465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Nico31415/Drowning-Detector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Using YOLO object detection, this program will detect if a person is drowning.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mc-cat-tty/DoorbellCamDaemon\"\u003emc-cat-tty/DoorbellCamDaemon\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4a8fbb6b2fad0019328402a32a1fcae7b9e554f5a550df9610a7e33dac18e394/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d632d6361742d7474792f446f6f7262656c6c43616d4461656d6f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4a8fbb6b2fad0019328402a32a1fcae7b9e554f5a550df9610a7e33dac18e394/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d632d6361742d7474792f446f6f7262656c6c43616d4461656d6f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mc-cat-tty/DoorbellCamDaemon?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Part of DoorbellCam project: daemon for people recognition with YOLO from a RTSP video stream.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Choe-Ji-Hwan/Fire_Detect_Custom_Yolov5\"\u003eChoe-Ji-Hwan/Fire_Detect_Custom_Yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/76aa04024071ae275d3cce45a51489bbce23e7071b22c63ab97116d34461b81c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43686f652d4a692d4877616e2f466972655f4465746563745f437573746f6d5f596f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/76aa04024071ae275d3cce45a51489bbce23e7071b22c63ab97116d34461b81c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43686f652d4a692d4877616e2f466972655f4465746563745f437573746f6d5f596f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Choe-Ji-Hwan/Fire_Detect_Custom_Yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 2022-1 Individual Research Assignment: Using YOLOv5 to simply recognize each type of fire.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bishal116/FireDetection\"\u003ebishal116/FireDetection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a984cd0f8ab1b9d763280e37017003368b367fd1a9580fba8bfa2054a4b0cb8a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62697368616c3131362f46697265446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a984cd0f8ab1b9d763280e37017003368b367fd1a9580fba8bfa2054a4b0cb8a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62697368616c3131362f46697265446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bishal116/FireDetection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This project builds fire detecton using YOLO v3 model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Psynosaur/Jetson-SecVision\"\u003ePsynosaur/Jetson-SecVision\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f44949899f3e3571614b5724473c096afd9e6fc9c28307e250539e53cd22a7cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5073796e6f736175722f4a6574736f6e2d536563566973696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f44949899f3e3571614b5724473c096afd9e6fc9c28307e250539e53cd22a7cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5073796e6f736175722f4a6574736f6e2d536563566973696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Psynosaur/Jetson-SecVision?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Person detection for Hikvision DVR with AlarmIO ports, uses TensorRT and yolov4.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/robmarkcole/fire-detection-from-images\"\u003erobmarkcole/fire-detection-from-images\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3e4f510173eef696c61cc6fa1b75b2baf65613ba3bc127831579acb7ee91d8d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626d61726b636f6c652f666972652d646574656374696f6e2d66726f6d2d696d616765733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3e4f510173eef696c61cc6fa1b75b2baf65613ba3bc127831579acb7ee91d8d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626d61726b636f6c652f666972652d646574656374696f6e2d66726f6d2d696d616765733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/robmarkcole/fire-detection-from-images?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detect fire in images using neural nets.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/gaiasd/DFireDataset\"\u003egaiasd/DFireDataset\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9079f6548233b8e2e3823ed86ac3e39e2c25ef0323ab0ad25854f41bfcd6cbc3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6761696173642f4446697265446174617365743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9079f6548233b8e2e3823ed86ac3e39e2c25ef0323ab0ad25854f41bfcd6cbc3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6761696173642f4446697265446174617365743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/gaiasd/DFireDataset?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : D-Fire: an image data set for fire and smoke detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MuhammadMoinFaisal/FireDetectionYOLOv8\"\u003eMuhammadMoinFaisal/FireDetectionYOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/50c2ef96c8d2020de79868a7c40881474267901e0a7c1e7af4d7d722a6f0f24d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d7568616d6d61644d6f696e46616973616c2f46697265446574656374696f6e594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/50c2ef96c8d2020de79868a7c40881474267901e0a7c1e7af4d7d722a6f0f24d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d7568616d6d61644d6f696e46616973616c2f46697265446574656374696f6e594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MuhammadMoinFaisal/FireDetectionYOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Fire Detection using YOLOv8.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AI-Expert-04/School_Zone_Eye_Level\"\u003eAI-Expert-04/School_Zone_Eye_Level\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0cde8bf1a1db29c6a82fc82a37b0245d06784ecea2c57be804b5485b4449bade/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41492d4578706572742d30342f5363686f6f6c5f5a6f6e655f4579655f4c6576656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0cde8bf1a1db29c6a82fc82a37b0245d06784ecea2c57be804b5485b4449bade/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41492d4578706572742d30342f5363686f6f6c5f5a6f6e655f4579655f4c6576656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AI-Expert-04/School_Zone_Eye_Level?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Prevention of accidents in school zones using deep learning.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/roboflow/supervision\"\u003eroboflow/supervision\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1b39f8841d1d11b310e911a38b018c9079106a311e56bd8419e0df2defde48f0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626f666c6f772f7375706572766973696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1b39f8841d1d11b310e911a38b018c9079106a311e56bd8419e0df2defde48f0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f726f626f666c6f772f7375706572766973696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/roboflow/supervision?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : We write your reusable computer vision tools. 💜 \u003ca href=\"https://roboflow.github.io/supervision/\" rel=\"nofollow\"\u003eroboflow.github.io/supervision\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AntroSafin/Fire_Detection_YoloV5\"\u003eAntroSafin/Fire_Detection_YoloV5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/905bfc55ffe4805cd9b0611be38749c26bbb0c3bab626cbfa323381cc1620d4b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e74726f536166696e2f466972655f446574656374696f6e5f596f6c6f56353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/905bfc55ffe4805cd9b0611be38749c26bbb0c3bab626cbfa323381cc1620d4b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416e74726f536166696e2f466972655f446574656374696f6e5f596f6c6f56353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AntroSafin/Fire_Detection_YoloV5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is the YoloV5 fire detection application.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/harivams-sai/FireDetectionYOLOv8\"\u003eharivams-sai/FireDetectionYOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b66143e699330776d8178cd239e99e438e30537bdeaaea02f9534d567d7985a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6861726976616d732d7361692f46697265446574656374696f6e594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b66143e699330776d8178cd239e99e438e30537bdeaaea02f9534d567d7985a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6861726976616d732d7361692f46697265446574656374696f6e594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/harivams-sai/FireDetectionYOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A fire detection model based on YOLOv8 Ultralytics model for object detection. Tech: Python, Computer Vision, Colab Notebook, Fire-detection, YOLOv8.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/e-candeloro/SAURUSS-Autonomous-Drone-Surveillance\"\u003ee-candeloro/SAURUSS-Autonomous-Drone-Surveillance\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/32d60b861b65c4cda6b530623189daa88ecb9e31ce41812782a624debe31bb9c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f652d63616e64656c6f726f2f534155525553532d4175746f6e6f6d6f75732d44726f6e652d5375727665696c6c616e63653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/32d60b861b65c4cda6b530623189daa88ecb9e31ce41812782a624debe31bb9c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f652d63616e64656c6f726f2f534155525553532d4175746f6e6f6d6f75732d44726f6e652d5375727665696c6c616e63653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/e-candeloro/SAURUSS-Autonomous-Drone-Surveillance?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An autonomous drone and sensor based surveillance system that use a Tello Drone, an Arduino, a Raspberry Pi and an Android smartphone.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pedbrgs/Fire-Detection\"\u003epedbrgs/Fire-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/193bafac51f7e553ab414db2948d1e8bbea6f5ca7f9ecc4e2850f550386411ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706564627267732f466972652d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/193bafac51f7e553ab414db2948d1e8bbea6f5ca7f9ecc4e2850f550386411ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706564627267732f466972652d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pedbrgs/Fire-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Fire and smoke detection using spatial and temporal patterns.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAnti-UAV Field Detection\u003c/h3\u003e\u003ca id=\"user-content-anti-uav-field-detection\" class=\"anchor\" aria-label=\"Permalink: Anti-UAV Field Detection\" href=\"#anti-uav-field-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e反无人机领域检测\u003c/h4\u003e\u003ca id=\"user-content-反无人机领域检测\" class=\"anchor\" aria-label=\"Permalink: 反无人机领域检测\" href=\"#反无人机领域检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZhaoJ9014/Anti-UAV\"\u003eAnti-UAV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f4011264d69ecf9a1839ac7bce6be873eeab7abb74913794ffcf866e7f9c5a36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68616f4a393031342f416e74692d5541563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f4011264d69ecf9a1839ac7bce6be873eeab7abb74913794ffcf866e7f9c5a36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68616f4a393031342f416e74692d5541563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZhaoJ9014/Anti-UAV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🔥🔥Official Repository for Anti-UAV🔥🔥. Anti-UAV300, Anti-UAV410, Anti-UAV600. Please refer to our \u003ca href=\"https://ieeexplore.ieee.org/document/9615243\" rel=\"nofollow\"\u003eAnti-UAV v1\u003c/a\u003e paper and \u003ca href=\"https://arxiv.org/pdf/2306.15767.pdf\" rel=\"nofollow\"\u003eAnti-UAV v3\u003c/a\u003e paper for more details (\u003ca href=\"https://zhaoj9014.github.io/pub/Anti-UAV.pdf\" rel=\"nofollow\"\u003eWeChat News\u003c/a\u003e). \"Anti-UAV: A Large-Scale Benchmark for Vision-Based UAV Tracking\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/document/9615243\" rel=\"nofollow\"\u003eIEEE Transactions on Multimedia, 2022\u003c/a\u003e\u003c/strong\u003e). \"Evidential Detection and Tracking Collaboration: New Problem, Benchmark and Algorithm for Robust Anti-UAV System\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2306.15767\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wangdongdut/DUT-Anti-UAV\"\u003eDUT-Anti-UAV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6d1b7e1210c59ca143ac28ef22b2f92f54acc49ff085b6fab12c5d5385d3dbdc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e67646f6e676475742f4455542d416e74692d5541563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6d1b7e1210c59ca143ac28ef22b2f92f54acc49ff085b6fab12c5d5385d3dbdc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e67646f6e676475742f4455542d416e74692d5541563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wangdongdut/DUT-Anti-UAV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : DUT Anti-UAV Detection and Tracking. \"Vision-based Anti-UAV Detection and Tracking\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2205.10851\" rel=\"nofollow\"\u003eIEEE Transactions on Intelligent Transportation Systems, 2022\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eMedical Field Detection\u003c/h3\u003e\u003ca id=\"user-content-medical-field-detection\" class=\"anchor\" aria-label=\"Permalink: Medical Field Detection\" href=\"#medical-field-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e医学领域检测\u003c/h4\u003e\u003ca id=\"user-content-医学领域检测\" class=\"anchor\" aria-label=\"Permalink: 医学领域检测\" href=\"#医学领域检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DataXujing/YOLO-v5\"\u003eDataXujing/YOLO-v5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1af840add24fd1789925f735e6ae328ef1686c368b928e167f15d302b9434a81/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f2d76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1af840add24fd1789925f735e6ae328ef1686c368b928e167f15d302b9434a81/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4461746158756a696e672f594f4c4f2d76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DataXujing/YOLO-v5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO v5在医疗领域中消化内镜目标检测的应用。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Jafar-Abdollahi/Automated-detection-of-COVID-19-cases-using-deep-neural-networks-with-CTS-images\"\u003eJafar-Abdollahi/Automated-detection-of-COVID-19-cases-using-deep-neural-networks-with-CTS-images\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/78ead0d275ad05b47814a1dbd4e56c9e601d198fcf89b5b726074c23a01ec69f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a616661722d4162646f6c6c6168692f4175746f6d617465642d646574656374696f6e2d6f662d434f5649442d31392d63617365732d7573696e672d646565702d6e657572616c2d6e6574776f726b732d776974682d4354532d696d616765733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/78ead0d275ad05b47814a1dbd4e56c9e601d198fcf89b5b726074c23a01ec69f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a616661722d4162646f6c6c6168692f4175746f6d617465642d646574656374696f6e2d6f662d434f5649442d31392d63617365732d7573696e672d646565702d6e657572616c2d6e6574776f726b732d776974682d4354532d696d616765733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Jafar-Abdollahi/Automated-detection-of-COVID-19-cases-using-deep-neural-networks-with-CTS-images?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : In this project, a new model for automatic detection of covid-19 using raw chest X-ray images is presented.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fahriwps/breast-cancer-detection\"\u003efahriwps/breast-cancer-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7b746d706f6d92dc15d621b5545d68402c4a098252171a08520fdefa3681c18e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66616872697770732f6272656173742d63616e6365722d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7b746d706f6d92dc15d621b5545d68402c4a098252171a08520fdefa3681c18e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66616872697770732f6272656173742d63616e6365722d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/fahriwps/breast-cancer-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Breast cancer mass detection using YOLO object detection algorithm and GUI.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/niehusst/YOLO-Cancer-Detection\"\u003eniehusst/YOLO-Cancer-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0f30940184b5c0f933bf47bf6191c946102e24dc200f73012ee6df9dd6701f41/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e696568757373742f594f4c4f2d43616e6365722d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0f30940184b5c0f933bf47bf6191c946102e24dc200f73012ee6df9dd6701f41/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6e696568757373742f594f4c4f2d43616e6365722d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/niehusst/YOLO-Cancer-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An implementation of the YOLO algorithm trained to spot tumors in DICOM images.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/safakgunes/Blood-Cancer-Detection-YOLOV5\"\u003esafakgunes/Blood-Cancer-Detection-YOLOV5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fc8d4f88eff3e21ef495e2b7f1a1c9656e4a9931bb49ec91638d5591e99ae39d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736166616b67756e65732f426c6f6f642d43616e6365722d446574656374696f6e2d594f4c4f56353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fc8d4f88eff3e21ef495e2b7f1a1c9656e4a9931bb49ec91638d5591e99ae39d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736166616b67756e65732f426c6f6f642d43616e6365722d446574656374696f6e2d594f4c4f56353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/safakgunes/Blood-Cancer-Detection-YOLOV5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Blood Cancer Detection with YOLOV5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/shchiang0708/YOLOv2_skinCancer\"\u003eshchiang0708/YOLOv2_skinCancer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9bb8845c5f87f30f14a1a547be561e1fc3fd9bfeb30f3b7ef05c7aad54d6e608/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7368636869616e67303730382f594f4c4f76325f736b696e43616e6365723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9bb8845c5f87f30f14a1a547be561e1fc3fd9bfeb30f3b7ef05c7aad54d6e608/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7368636869616e67303730382f594f4c4f76325f736b696e43616e6365723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/shchiang0708/YOLOv2_skinCancer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv2_skinCancer.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/avral1810/parkinsongait\"\u003eavral1810/parkinsongait\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e68f1b36d288985d59e25cf5c8898c639da32a396469433ab2b9f15a27c66e81/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f617672616c313831302f7061726b696e736f6e676169743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e68f1b36d288985d59e25cf5c8898c639da32a396469433ab2b9f15a27c66e81/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f617672616c313831302f7061726b696e736f6e676169743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/avral1810/parkinsongait?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Parkinson’s Disease.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sierprinsky/YoloV5_blood_cells\"\u003esierprinsky/YoloV5_blood_cells\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4c4db31ab25351234bed488e6aa327763248240df649cf8900ad6223eca1e8fc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736965727072696e736b792f596f6c6f56355f626c6f6f645f63656c6c733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4c4db31ab25351234bed488e6aa327763248240df649cf8900ad6223eca1e8fc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736965727072696e736b792f596f6c6f56355f626c6f6f645f63656c6c733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sierprinsky/YoloV5_blood_cells?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The main idea of this project is to detect blood cells using YOLOV5 over a public roboflow dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LuozyCS/skin_disease_detection_yolov5\"\u003eLuozyCS/skin_disease_detection_yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3ffaf730e6f491bd3efb9c6f0618e0f16ab4337cdb36cf3673db70dbd9485b29/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c756f7a7943532f736b696e5f646973656173655f646574656374696f6e5f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3ffaf730e6f491bd3efb9c6f0618e0f16ab4337cdb36cf3673db70dbd9485b29/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c756f7a7943532f736b696e5f646973656173655f646574656374696f6e5f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LuozyCS/skin_disease_detection_yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : skin_disease_detection_yolov5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Moqixis/object_detection_yolov5_deepsort\"\u003eMoqixis/object_detection_yolov5_deepsort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/25a7e252883372e437a721e96e5a1d9d3a0e6d18355d88da96b66a05cd988ce6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f71697869732f6f626a6563745f646574656374696f6e5f796f6c6f76355f64656570736f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/25a7e252883372e437a721e96e5a1d9d3a0e6d18355d88da96b66a05cd988ce6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6f71697869732f6f626a6563745f646574656374696f6e5f796f6c6f76355f64656570736f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Moqixis/object_detection_yolov5_deepsort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于yolov5+deepsort的息肉目标检测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mdciri/YOLOv7-Bone-Fracture-Detection\"\u003emdciri/YOLOv7-Bone-Fracture-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f8afc3efb5e16125a6efb129776d9b045bfc3f1b4b46b6e1955701c84541bf42/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d64636972692f594f4c4f76372d426f6e652d46726163747572652d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f8afc3efb5e16125a6efb129776d9b045bfc3f1b4b46b6e1955701c84541bf42/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d64636972692f594f4c4f76372d426f6e652d46726163747572652d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mdciri/YOLOv7-Bone-Fracture-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv7 to detect bone fractures on X-ray images.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MIRACLE-Center/YOLO_Universal_Anatomical_Landmark_Detection\"\u003eMIRACLE-Center/YOLO_Universal_Anatomical_Landmark_Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fd3fcb3fa1b49cfe960d67ced46e04e262ecc2608d347a23c92c797af5f2d471/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d495241434c452d43656e7465722f594f4c4f5f556e6976657273616c5f416e61746f6d6963616c5f4c616e646d61726b5f446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fd3fcb3fa1b49cfe960d67ced46e04e262ecc2608d347a23c92c797af5f2d471/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d495241434c452d43656e7465722f594f4c4f5f556e6976657273616c5f416e61746f6d6963616c5f4c616e646d61726b5f446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MIRACLE-Center/YOLO_Universal_Anatomical_Landmark_Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : [MICCAI 2021] \u003ca href=\"https://arxiv.org/abs/2103.04657\" rel=\"nofollow\"\u003eYou Only Learn Once: Universal Anatomical Landmark Detection\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/fahriwps/breast-cancer-detection\"\u003efahriwps/breast-cancer-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7b746d706f6d92dc15d621b5545d68402c4a098252171a08520fdefa3681c18e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66616872697770732f6272656173742d63616e6365722d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7b746d706f6d92dc15d621b5545d68402c4a098252171a08520fdefa3681c18e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66616872697770732f6272656173742d63616e6365722d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/fahriwps/breast-cancer-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Breast cancer mass detection using YOLO object detection algorithm and GUI.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mkang315/CST-YOLO\"\u003emkang315/CST-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f42f204462a050842f2d1186b1abc7d24e3a0f6551068e8efd7899b97cba0b32/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6b616e673331352f4353542d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f42f204462a050842f2d1186b1abc7d24e3a0f6551068e8efd7899b97cba0b32/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6b616e673331352f4353542d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mkang315/CST-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Official implementation of \"CST-YOLO: A Novel Method for Blood Cell Detection Based on Improved YOLOv7 and CNN-Swin Transformer\".\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mkang315/BGF-YOLO\"\u003emkang315/BGF-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/91cfe276745d8f74aa2a5b28176809054af866a6baa9878d8c8b5ce1b70fd367/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6b616e673331352f4247462d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/91cfe276745d8f74aa2a5b28176809054af866a6baa9878d8c8b5ce1b70fd367/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6b616e673331352f4247462d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mkang315/BGF-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : [MICCAI'24] Official implementation of \"BGF-YOLO: Enhanced YOLOv8 with Multiscale Attentional Feature Fusion for Brain Tumor Detection\".\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eChemistry Field Detection\u003c/h3\u003e\u003ca id=\"user-content-chemistry-field-detection\" class=\"anchor\" aria-label=\"Permalink: Chemistry Field Detection\" href=\"#chemistry-field-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e化学领域检测\u003c/h4\u003e\u003ca id=\"user-content-化学领域检测\" class=\"anchor\" aria-label=\"Permalink: 化学领域检测\" href=\"#化学领域检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/xuguodong1999/COCR\"\u003exuguodong1999/COCR\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/491dd0efc3f1ff4ad88b9becc472f3b05945e2854f18c33480ad9c54af22449e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f787567756f646f6e67313939392f434f43523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/491dd0efc3f1ff4ad88b9becc472f3b05945e2854f18c33480ad9c54af22449e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f787567756f646f6e67313939392f434f43523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xuguodong1999/COCR?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : COCR is designed to convert an image of hand-writing chemical structure to graph of that molecule.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAgricultural Field Detection\u003c/h3\u003e\u003ca id=\"user-content-agricultural-field-detection\" class=\"anchor\" aria-label=\"Permalink: Agricultural Field Detection\" href=\"#agricultural-field-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e农业领域检测\u003c/h4\u003e\u003ca id=\"user-content-农业领域检测\" class=\"anchor\" aria-label=\"Permalink: 农业领域检测\" href=\"#农业领域检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/liao1fan/MGA-YOLO-for-apple-leaf-disease-detection\"\u003eliao1fan/MGA-YOLO-for-apple-leaf-disease-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1e6d1cedbe4679ffa1d32c5ae522f3807830b99f587dd68e7b847ab745e60c80/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c69616f3166616e2f4d47412d594f4c4f2d666f722d6170706c652d6c6561662d646973656173652d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1e6d1cedbe4679ffa1d32c5ae522f3807830b99f587dd68e7b847ab745e60c80/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c69616f3166616e2f4d47412d594f4c4f2d666f722d6170706c652d6c6561662d646973656173652d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/liao1fan/MGA-YOLO-for-apple-leaf-disease-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : MGA-YOLO: A Lightweight One-Stage Network for Apple Leaf Disease Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/tanmaypandey7/wheat-detection\"\u003etanmaypandey7/wheat-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fc06bc91700bb79848533f2968dbdd4028eb5651da0678a1ee6250fba9c5feae/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616e6d617970616e646579372f77686561742d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fc06bc91700bb79848533f2968dbdd4028eb5651da0678a1ee6250fba9c5feae/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f74616e6d617970616e646579372f77686561742d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tanmaypandey7/wheat-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detecting wheat heads using YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WoodratTradeCo/crop-rows-detection\"\u003eWoodratTradeCo/crop-rows-detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a43d16067576155fdf651ac28deda4ca37c795a555b8ee71e3078a81a72fca95/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6f647261745472616465436f2f63726f702d726f77732d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a43d16067576155fdf651ac28deda4ca37c795a555b8ee71e3078a81a72fca95/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f576f6f647261745472616465436f2f63726f702d726f77732d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WoodratTradeCo/crop-rows-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : It is an real-time crop rows detection method using YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/denghv/Vegetables_Fruit_Detection\"\u003edenghv/Vegetables_Fruit_Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7409a2eaa2d85c3f7b1dbd73e45868c70e80b9b01c1b437ed4f26c9a1da00188/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64656e6768762f566567657461626c65735f46727569745f446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7409a2eaa2d85c3f7b1dbd73e45868c70e80b9b01c1b437ed4f26c9a1da00188/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f64656e6768762f566567657461626c65735f46727569745f446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/denghv/Vegetables_Fruit_Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Using YOLOv10 to detect vegetables \u0026amp; fruit.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSports Field Detection\u003c/h3\u003e\u003ca id=\"user-content-sports-field-detection\" class=\"anchor\" aria-label=\"Permalink: Sports Field Detection\" href=\"#sports-field-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e体育领域检测\u003c/h4\u003e\u003ca id=\"user-content-体育领域检测\" class=\"anchor\" aria-label=\"Permalink: 体育领域检测\" href=\"#体育领域检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/tomer-erez/pingpong-referee\"\u003etomer-erez/pingpong-referee\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e977dcbc92e4307137c17c2a71745492e176eaad82f8ce448d63f0a4a2e102ee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746f6d65722d6572657a2f70696e67706f6e672d726566657265653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e977dcbc92e4307137c17c2a71745492e176eaad82f8ce448d63f0a4a2e102ee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f746f6d65722d6572657a2f70696e67706f6e672d726566657265653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/tomer-erez/pingpong-referee?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : using the YOlO algorithm for an automated pingpong referee.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAerial Imagery Detection\u003c/h3\u003e\u003ca id=\"user-content-aerial-imagery-detection\" class=\"anchor\" aria-label=\"Permalink: Aerial Imagery Detection\" href=\"#aerial-imagery-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e遥感图像检测\u003c/h4\u003e\u003ca id=\"user-content-遥感图像检测\" class=\"anchor\" aria-label=\"Permalink: 遥感图像检测\" href=\"#遥感图像检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/stephansturges/WALDO\"\u003eWALDO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/40e7754098dab06cff72eea934a63b0ed20a613fefa1f2ff7f974d07af57156f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374657068616e737475726765732f57414c444f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/40e7754098dab06cff72eea934a63b0ed20a613fefa1f2ff7f974d07af57156f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374657068616e737475726765732f57414c444f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/stephansturges/WALDO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Whereabouts Ascertainment for Low-lying Detectable Objects. The SOTA in FOSS AI for drones!\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAdverse Weather Conditions\u003c/h3\u003e\u003ca id=\"user-content-adverse-weather-conditions\" class=\"anchor\" aria-label=\"Permalink: Adverse Weather Conditions\" href=\"#adverse-weather-conditions\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e恶劣天气情况\u003c/h4\u003e\u003ca id=\"user-content-恶劣天气情况\" class=\"anchor\" aria-label=\"Permalink: 恶劣天气情况\" href=\"#恶劣天气情况\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/wenyyu/Image-Adaptive-YOLO\"\u003eImage-Adaptive YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f07e611e956d4129c185b7b9c603aaec2b1764905dcd86cf8e78fd18733a9c39/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77656e7979752f496d6167652d41646170746976652d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f07e611e956d4129c185b7b9c603aaec2b1764905dcd86cf8e78fd18733a9c39/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77656e7979752f496d6167652d41646170746976652d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wenyyu/Image-Adaptive-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Image-Adaptive YOLO for Object Detection in Adverse Weather Conditions\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2112.08088\" rel=\"nofollow\"\u003eAAAI 2022\u003c/a\u003e\u003c/strong\u003e). \"计算机视觉研究院：《\u003ca href=\"https://mp.weixin.qq.com/s/QdM6Dx990VhN97MRIP74XA\" rel=\"nofollow\"\u003e图像自适应YOLO：模糊环境下的目标检测（附源代码）\u003c/a\u003e》\"\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAdversarial Attack and Defense\u003c/h3\u003e\u003ca id=\"user-content-adversarial-attack-and-defense\" class=\"anchor\" aria-label=\"Permalink: Adversarial Attack and Defense\" href=\"#adversarial-attack-and-defense\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e对抗攻击与防御\u003c/h4\u003e\u003ca id=\"user-content-对抗攻击与防御\" class=\"anchor\" aria-label=\"Permalink: 对抗攻击与防御\" href=\"#对抗攻击与防御\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://gitlab.com/EAVISE/adversarial-yolo\" rel=\"nofollow\"\u003eEAVISE/adversarial-yolo\u003c/a\u003e : \"Fooling automated surveillance cameras: adversarial patches to attack person detection\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_CVPRW_2019/html/CV-COPS/Thys_Fooling_Automated_Surveillance_Cameras_Adversarial_Patches_to_Attack_Person_Detection_CVPRW_2019_paper.html\" rel=\"nofollow\"\u003eCVPR 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/git-disl/TOG\"\u003egit-disl/TOG\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6c8f2df8da38991eab313db758e3dbe95a8082cb2b8536567203694f2f4a1c7d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6769742d6469736c2f544f473f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6c8f2df8da38991eab313db758e3dbe95a8082cb2b8536567203694f2f4a1c7d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6769742d6469736c2f544f473f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/git-disl/TOG?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Adversarial Objectness Gradient Attacks on Real-time Object Detection Systems\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9325397\" rel=\"nofollow\"\u003eIEEE TPS-ISA 2020\u003c/a\u003e\u003c/strong\u003e) | \"Understanding Object Detection Through an Adversarial Lens\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/chapter/10.1007/978-3-030-59013-0_23\" rel=\"nofollow\"\u003eESORICS 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/VITA-Group/3D_Adversarial_Logo\"\u003eVITA-Group/3D_Adversarial_Logo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/60da7b1af009c42fbc7394f8692a4ea97678ac3cd196c7009b5e81e989087d48/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f564954412d47726f75702f33445f416476657273617269616c5f4c6f676f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/60da7b1af009c42fbc7394f8692a4ea97678ac3cd196c7009b5e81e989087d48/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f564954412d47726f75702f33445f416476657273617269616c5f4c6f676f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/VITA-Group/3D_Adversarial_Logo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 3D adversarial logo attack on different3D object meshes to fool a YOLOV2 detector. \"Can 3D Adversarial Logos Clock Humans?\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2006.14655\" rel=\"nofollow\"\u003earXiv 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ASGuard-UCI/MSF-ADV\"\u003eASGuard-UCI/MSF-ADV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2d77dda0ec84c933ebbe1058f1b175826813f5401529291dca8d5be6be1993ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f415347756172642d5543492f4d53462d4144563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2d77dda0ec84c933ebbe1058f1b175826813f5401529291dca8d5be6be1993ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f415347756172642d5543492f4d53462d4144563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ASGuard-UCI/MSF-ADV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : MSF-ADV is a novel physical-world adversarial attack method, which can fool the Multi Sensor Fusion (MSF) based autonomous driving (AD) perception in the victim autonomous vehicle (AV) to fail in detecting a front obstacle and thus crash into it. \"Invisible for both Camera and LiDAR: Security of Multi-Sensor Fusion based Perception in Autonomous Driving Under Physical-World Attacks\". (\u003cstrong\u003e\u003ca href=\"https://www.computer.org/csdl/proceedings-article/sp/2021/893400b302/1t0x9btzenu\" rel=\"nofollow\"\u003eIEEE S\u0026amp;P 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/veralauee/DPatch\"\u003everalauee/DPatch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5133bfd4b7f1aa18e4d15d85ba1db96f34db7440211a2d5359df9a8fe1a268fe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f766572616c617565652f4450617463683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5133bfd4b7f1aa18e4d15d85ba1db96f34db7440211a2d5359df9a8fe1a268fe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f766572616c617565652f4450617463683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/veralauee/DPatch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"DPatch: An Adversarial Patch Attack on Object Detectors\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1806.02299\" rel=\"nofollow\"\u003earXiv 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Shudeng/GPAttack\"\u003eShudeng/GPAttack\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b79ddd3249ce967fcad3ec000d411528bfb466712575d5f012fabcb4bd3fbc9b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53687564656e672f475041747461636b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b79ddd3249ce967fcad3ec000d411528bfb466712575d5f012fabcb4bd3fbc9b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53687564656e672f475041747461636b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Shudeng/GPAttack?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Grid Patch Attack for Object Detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Wu-Shudeng/DPAttack\"\u003eWu-Shudeng/DPAttack\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/eff5d8d5f57f70829708e7043bc971ca7218f24aaa57ce83735dab039452d3d5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57752d53687564656e672f445041747461636b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/eff5d8d5f57f70829708e7043bc971ca7218f24aaa57ce83735dab039452d3d5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57752d53687564656e672f445041747461636b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Wu-Shudeng/DPAttack?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"DPAttack: Diffused Patch Attacks against Universal Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2010.11679\" rel=\"nofollow\"\u003earXiv 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FenHua/DetDak\"\u003eFenHua/DetDak\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0109a9629428be1e077cb0980fa8f181acd8d3305b09b25cae0f5fae2dc540f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46656e4875612f44657444616b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0109a9629428be1e077cb0980fa8f181acd8d3305b09b25cae0f5fae2dc540f2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46656e4875612f44657444616b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FenHua/DetDak?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Patch adversarial attack; object detection; CIKM2020 安全AI挑战者计划第四期：通用目标检测的对抗攻击。 \"Object Hider: Adversarial Patch Attack Against Object Detectors\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2010.14974\" rel=\"nofollow\"\u003earXiv 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/THUrssq/Tianchi04\"\u003eTHUrssq/Tianchi04\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bf7175d1182d6733378c29cbcc45ee71626752a310008ad65ae3d3958211fff2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f544855727373712f5469616e63686930343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bf7175d1182d6733378c29cbcc45ee71626752a310008ad65ae3d3958211fff2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f544855727373712f5469616e63686930343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/THUrssq/Tianchi04?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is NO.4 solution for \"CIKM-2020 Alibaba-Tsinghua Adversarial Challenge on Object Detection\". \"Sparse Adversarial Attack to Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2012.13692\" rel=\"nofollow\"\u003earXiv 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mesunhlf/UPC-tf\"\u003emesunhlf/UPC-tf\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f261ece22845c344d7919e064092583b2dc2b1ea8432968dad05ea6ae3ff606c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6573756e686c662f5550432d74663f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f261ece22845c344d7919e064092583b2dc2b1ea8432968dad05ea6ae3ff606c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6573756e686c662f5550432d74663f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mesunhlf/UPC-tf?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Universal Physical Camouflage Attacks on Object Detectors\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_CVPR_2020/html/Huang_Universal_Physical_Camouflage_Attacks_on_Object_Detectors_CVPR_2020_paper.html\" rel=\"nofollow\"\u003eCVPR 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/alex96295/YOLOv3_adversarial_defense\"\u003ealex96295/YOLOv3_adversarial_defense\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6f76d4a11fec21a8b0e3bf309e727940ec2a8f0acd9b6a4c04a12c81994e5474/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c657839363239352f594f4c4f76335f616476657273617269616c5f646566656e73653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6f76d4a11fec21a8b0e3bf309e727940ec2a8f0acd9b6a4c04a12c81994e5474/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c657839363239352f594f4c4f76335f616476657273617269616c5f646566656e73653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/alex96295/YOLOv3_adversarial_defense?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv3_adversarial_defense.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/alex96295/YOLO_adversarial_attacks\"\u003ealex96295/YOLO_adversarial_attacks\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3a6b6eb7b762e07d7ef2f527b6e940893a8d05418df1ae1872d8a3de1cf6ae28/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c657839363239352f594f4c4f5f616476657273617269616c5f61747461636b733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3a6b6eb7b762e07d7ef2f527b6e940893a8d05418df1ae1872d8a3de1cf6ae28/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c657839363239352f594f4c4f5f616476657273617269616c5f61747461636b733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/alex96295/YOLO_adversarial_attacks?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO_adversarial_attacks.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/alex96295/Adversarial-Patch-Attacks-TRAINING-YOLO-SSD-Pytorch\"\u003ealex96295/Adversarial-Patch-Attacks-TRAINING-YOLO-SSD-Pytorch\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/51d22d689296a61b4a40fd01756de5d910770929a7c33cf0003a1eb8da4b95dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c657839363239352f416476657273617269616c2d50617463682d41747461636b732d545241494e494e472d594f4c4f2d5353442d5079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/51d22d689296a61b4a40fd01756de5d910770929a7c33cf0003a1eb8da4b95dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c657839363239352f416476657273617269616c2d50617463682d41747461636b732d545241494e494e472d594f4c4f2d5353442d5079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/alex96295/Adversarial-Patch-Attacks-TRAINING-YOLO-SSD-Pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repository has the code needed to train 'Adversarial Patch Attacks' on YOLO and SSD models for object detection in Pytorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FranBesq/attack-yolo\"\u003eFranBesq/attack-yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c464c2654cb1fd03e94c2f4d67755d13316421628c88028cb8312f4f14e7f669/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4672616e426573712f61747461636b2d796f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c464c2654cb1fd03e94c2f4d67755d13316421628c88028cb8312f4f14e7f669/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4672616e426573712f61747461636b2d796f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FranBesq/attack-yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Developing adversarial attacks on YOLO algorithm for computer vision.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Rushi314/GPR-Object-Detection\"\u003eRushi314/GPR-Object-Detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3cdc9d17fd0cc862b3a86c11d124aba537d7b36e4c298a1b7188d2aee6a47512/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52757368693331342f4750522d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3cdc9d17fd0cc862b3a86c11d124aba537d7b36e4c298a1b7188d2aee6a47512/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52757368693331342f4750522d4f626a6563742d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Rushi314/GPR-Object-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detecting Objects in Ground Penetrating Radars Scans.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/realtxy/pso-adversarial-yolo_v3\"\u003erealtxy/pso-adversarial-yolo_v3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e86ccc2bb83ebb652e720749795cea83dd6a04c4453c2732b1e68d5541c1ec75/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7265616c7478792f70736f2d616476657273617269616c2d796f6c6f5f76333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e86ccc2bb83ebb652e720749795cea83dd6a04c4453c2732b1e68d5541c1ec75/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7265616c7478792f70736f2d616476657273617269616c2d796f6c6f5f76333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/realtxy/pso-adversarial-yolo_v3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : pso-adversarial-yolo_v3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sowgali/ObjCAM\"\u003esowgali/ObjCAM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1010f8f9001c631df74815d6fc8489452b5692376300544de011443ab8d556e0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736f7767616c692f4f626a43414d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1010f8f9001c631df74815d6fc8489452b5692376300544de011443ab8d556e0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736f7767616c692f4f626a43414d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sowgali/ObjCAM?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Visualizations for adversarial attacks in object detectors like YOLO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/andrewpatrickdu/adversarial-yolov3-cowc\"\u003eandrewpatrickdu/adversarial-yolov3-cowc\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/18a5ed5d6703c4b5929c24b244dc361e191af44145ca3ef1a729fb1c3cdd7cdc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616e647265777061747269636b64752f616476657273617269616c2d796f6c6f76332d636f77633f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/18a5ed5d6703c4b5929c24b244dc361e191af44145ca3ef1a729fb1c3cdd7cdc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616e647265777061747269636b64752f616476657273617269616c2d796f6c6f76332d636f77633f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/andrewpatrickdu/adversarial-yolov3-cowc?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Physical Adversarial Attacks on an Aerial Imagery Object Detector\".  (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/WACV2022/html/Du_Physical_Adversarial_Attacks_on_an_Aerial_Imagery_Object_Detector_WACV_2022_paper.html\" rel=\"nofollow\"\u003eWACV 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/IQTLabs/camolo\"\u003eIQTLabs/camolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bac2def1f59fbf1752378ae11aaea22ba30e77feea16ba425fa89b077a82110d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4951544c6162732f63616d6f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bac2def1f59fbf1752378ae11aaea22ba30e77feea16ba425fa89b077a82110d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4951544c6162732f63616d6f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/IQTLabs/camolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Camouflage YOLO - (CAMOLO) trains adversarial patches to confuse the YOLO family of object detectors.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WhoTHU/Adversarial_Texture\"\u003eAdvTexture\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/09724874f0faa6343ced1dcf350d93c3e631c7a247572b4032397d47bcb4621b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57686f5448552f416476657273617269616c5f546578747572653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/09724874f0faa6343ced1dcf350d93c3e631c7a247572b4032397d47bcb4621b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57686f5448552f416476657273617269616c5f546578747572653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WhoTHU/Adversarial_Texture?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Adversarial Texture for Fooling Person Detectors in the Physical World\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Adversarial_Texture_for_Fooling_Person_Detectors_in_the_Physical_World_CVPR_2022_paper.html\" rel=\"nofollow\"\u003eCVPR 2022\u003c/a\u003e\u003c/strong\u003e).  \"知乎「WhoTH」《\u003ca href=\"https://zhuanlan.zhihu.com/p/499854846\" rel=\"nofollow\"\u003eCVPR2022 Oral 物理对抗样本 如何做一件“隐形衣”\u003c/a\u003e》\"。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SamSamhuns/yolov5_adversarial\"\u003eSamSamhuns/yolov5_adversarial\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5c410d703e6bcd25db5df6d353cd8c6f24db20ca138bb8d02e1ca1ada91900cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53616d53616d68756e732f796f6c6f76355f616476657273617269616c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5c410d703e6bcd25db5df6d353cd8c6f24db20ca138bb8d02e1ca1ada91900cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53616d53616d68756e732f796f6c6f76355f616476657273617269616c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SamSamhuns/yolov5_adversarial?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Generate adversarial patches against YOLOv5 🚀\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCamouflaged Detection\u003c/h3\u003e\u003ca id=\"user-content-camouflaged-detection\" class=\"anchor\" aria-label=\"Permalink: Camouflaged Detection\" href=\"#camouflaged-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e伪装目标检测\u003c/h4\u003e\u003ca id=\"user-content-伪装目标检测\" class=\"anchor\" aria-label=\"Permalink: 伪装目标检测\" href=\"#伪装目标检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/Ap1rate/yolov8-SIM\"\u003eAp1rate/yolov8-SIM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1fee74960c2ff235a900c8fa236e36f47df77c3a7d17a024cd8a6833f32c191d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f417031726174652f796f6c6f76382d53494d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1fee74960c2ff235a900c8fa236e36f47df77c3a7d17a024cd8a6833f32c191d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f417031726174652f796f6c6f76382d53494d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ap1rate/yolov8-SIM?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Link to Journal of Ecological Informatics paper ' Camouflaged Detection: Optimization-Based Computer Vision for Alligator sinensis with Low Detectability in Complex Wild Environments '.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eGame Field Detection\u003c/h3\u003e\u003ca id=\"user-content-game-field-detection\" class=\"anchor\" aria-label=\"Permalink: Game Field Detection\" href=\"#game-field-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e游戏领域检测\u003c/h4\u003e\u003ca id=\"user-content-游戏领域检测\" class=\"anchor\" aria-label=\"Permalink: 游戏领域检测\" href=\"#游戏领域检测\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SunOner/sunone_aimbot\"\u003eSunOner/sunone_aimbot\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/47a54b8bd5e0336193b2c245d5a78c9aa8c169b422747d7bde7f781eb27976c9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53756e4f6e65722f73756e6f6e655f61696d626f743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/47a54b8bd5e0336193b2c245d5a78c9aa8c169b422747d7bde7f781eb27976c9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53756e4f6e65722f73756e6f6e655f61696d626f743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SunOner/sunone_aimbot?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🌲Aim-bot based on AI for all FPS games. \u003ca href=\"https://boosty.to/sunone\" rel=\"nofollow\"\u003eboosty.to/sunone\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Passer1072/RookieAI_yolov8\"\u003ePasser1072/RookieAI_yolov8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1aea46cf4ef865ed76b69f134d089133ee87d56b138e22389e3f6213380eed55/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506173736572313037322f526f6f6b696541495f796f6c6f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1aea46cf4ef865ed76b69f134d089133ee87d56b138e22389e3f6213380eed55/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506173736572313037322f526f6f6b696541495f796f6c6f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Passer1072/RookieAI_yolov8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于yolov8实现的AI自瞄项目 AI self-aiming project based on yolov8.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/petercunha/Pine\"\u003epetercunha/Pine\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d949cb2f037ae47f662336972fb8e1dccb4d3fef6f3fb3229a61430ab8f959e1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706574657263756e68612f50696e653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d949cb2f037ae47f662336972fb8e1dccb4d3fef6f3fb3229a61430ab8f959e1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706574657263756e68612f50696e653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/petercunha/Pine?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🌲 Aimbot powered by real-time object detection with neural networks, GPU accelerated with Nvidia. Optimized for use with CS:GO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/chaoyu1999/FPSAutomaticAiming\"\u003echaoyu1999/FPSAutomaticAiming\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8176d852683f88b7379886d2ef6bfb0e34742634fe4bc6b5e23c9c5b8dc9eaa9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368616f7975313939392f4650534175746f6d6174696341696d696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8176d852683f88b7379886d2ef6bfb0e34742634fe4bc6b5e23c9c5b8dc9eaa9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368616f7975313939392f4650534175746f6d6174696341696d696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/chaoyu1999/FPSAutomaticAiming?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于yolov5的FPS类游戏AI自瞄AI。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Lu-tju/CSGO_AI\"\u003eLu-tju/CSGO_AI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7a16da44bb2dbe7a0565789164a25f121e5d43f8dbd832fd26b8a9dda2fd976f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c752d746a752f4353474f5f41493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7a16da44bb2dbe7a0565789164a25f121e5d43f8dbd832fd26b8a9dda2fd976f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c752d746a752f4353474f5f41493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Lu-tju/CSGO_AI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于YOLOv3的csgo自瞄。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/kir486680/csgo_aim\"\u003ekir486680/csgo_aim\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b4258fc43c0311f975dfbdec55c84850f30894372301b0c3e6af83f7485815a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b69723438363638302f6373676f5f61696d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b4258fc43c0311f975dfbdec55c84850f30894372301b0c3e6af83f7485815a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b69723438363638302f6373676f5f61696d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/kir486680/csgo_aim?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Aim assist for CSGO with python and yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/c925777075/yolov5-dnf\"\u003ec925777075/yolov5-dnf\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8d955e17c1cbb5e67e5ff07a186374d9957e32aa4e047ac04bc5ff596352cd1c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f633932353737373037352f796f6c6f76352d646e663f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8d955e17c1cbb5e67e5ff07a186374d9957e32aa4e047ac04bc5ff596352cd1c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f633932353737373037352f796f6c6f76352d646e663f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/c925777075/yolov5-dnf?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolov5-DNF.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/davidhoung2/APEX-yolov5-aim-assist\"\u003edavidhoung2/APEX-yolov5-aim-assist\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6ddd58af92b2dee98fad32bedba7fded5c828782d8762d10e20aae5ecd23ef08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6461766964686f756e67322f415045582d796f6c6f76352d61696d2d6173736973743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6ddd58af92b2dee98fad32bedba7fded5c828782d8762d10e20aae5ecd23ef08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6461766964686f756e67322f415045582d796f6c6f76352d61696d2d6173736973743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/davidhoung2/APEX-yolov5-aim-assist?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : using yolov5 to help you aim enemies.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Brednan/CSGO-Aimbot\"\u003eBrednan/CSGO-Aimbot\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f967e80701ff5d3e83a5e812e5baa910b3bb62f63969630c008f39486651515c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427265646e616e2f4353474f2d41696d626f743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f967e80701ff5d3e83a5e812e5baa910b3bb62f63969630c008f39486651515c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427265646e616e2f4353474f2d41696d626f743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Brednan/CSGO-Aimbot?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Aimbot for the FPS game CSGO. It uses YOLOv5 to detect enemy players on my screen, then moves my cursor to the location.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/2319590263/yolov5-csgo\"\u003e2319590263/yolov5-csgo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8b0a90bf7ca375dbf47c43bd5e4940c248534bd8f7f861650b89367374cada33/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f323331393539303236332f796f6c6f76352d6373676f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8b0a90bf7ca375dbf47c43bd5e4940c248534bd8f7f861650b89367374cada33/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f323331393539303236332f796f6c6f76352d6373676f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/2319590263/yolov5-csgo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于yolov5实现的csgo自瞄。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SCRN-VRC/YOLOv4-Tiny-in-UnityCG-HLSL\"\u003eSCRN-VRC/YOLOv4-Tiny-in-UnityCG-HLSL\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8fe4aae69befded56696f7c28268dc37d1494a8d8916c27d1e5db5ae9267be96/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5343524e2d5652432f594f4c4f76342d54696e792d696e2d556e69747943472d484c534c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8fe4aae69befded56696f7c28268dc37d1494a8d8916c27d1e5db5ae9267be96/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5343524e2d5652432f594f4c4f76342d54696e792d696e2d556e69747943472d484c534c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SCRN-VRC/YOLOv4-Tiny-in-UnityCG-HLSL?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A modern object detector inside fragment shaders.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/qcjxs-hn/yolov5-csgo\"\u003eqcjxs-hn/yolov5-csgo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/352ced640f2603465f0ff28860857df170d407664b87334e35af911d6d123df5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f71636a78732d686e2f796f6c6f76352d6373676f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/352ced640f2603465f0ff28860857df170d407664b87334e35af911d6d123df5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f71636a78732d686e2f796f6c6f76352d6373676f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/qcjxs-hn/yolov5-csgo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 这是一个根据教程写的csgo-ai和我自己训练的模型，还有数据集。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/IgaoGuru/Sequoia\"\u003eSequoia\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/965e6326ecd7db86bfe93e3fb47e6ca0a23e4db6c18e80a5daf9e63b873c449d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4967616f477572752f536571756f69613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/965e6326ecd7db86bfe93e3fb47e6ca0a23e4db6c18e80a5daf9e63b873c449d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4967616f477572752f536571756f69613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/IgaoGuru/Sequoia?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A neural network for CounterStrike:GlobalOffensive character detection and classification. Built on a custom-made dataset (csgo-data-collector).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ItGarbager/aimcf_yolov5\"\u003eItGarbager/aimcf_yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3db1d638695a17d1d4c1542007d3511a46651d9f8d50ada958e0b81ed1f83628/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f497447617262616765722f61696d63665f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3db1d638695a17d1d4c1542007d3511a46651d9f8d50ada958e0b81ed1f83628/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f497447617262616765722f61696d63665f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ItGarbager/aimcf_yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 使用yolov5算法实现cf角色头部预测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jiaran-takeme/Target-Detection-for-CSGO-by-YOLOv5\"\u003ejiaran-takeme/Target-Detection-for-CSGO-by-YOLOv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/92483f60a653254bb62b59e15e1028274738514a5bfae15c2524eae8a3ac808c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a696172616e2d74616b656d652f5461726765742d446574656374696f6e2d666f722d4353474f2d62792d594f4c4f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/92483f60a653254bb62b59e15e1028274738514a5bfae15c2524eae8a3ac808c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a696172616e2d74616b656d652f5461726765742d446574656374696f6e2d666f722d4353474f2d62792d594f4c4f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jiaran-takeme/Target-Detection-for-CSGO-by-YOLOv5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Target Detection for CSGO by YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Lucid1ty/Yolov5ForCSGO\"\u003eLucid1ty/Yolov5ForCSGO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f31cc959f6992f8acee8f88e9539d12105ca11f7a5b92545297083eefef1717c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c756369643174792f596f6c6f7635466f724353474f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f31cc959f6992f8acee8f88e9539d12105ca11f7a5b92545297083eefef1717c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c756369643174792f596f6c6f7635466f724353474f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Lucid1ty/Yolov5ForCSGO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : CSGO character detection and auto aim.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/leo4048111/Yolov5-LabelMaker-For-CSGO\"\u003eleo4048111/Yolov5-LabelMaker-For-CSGO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/16d0363f9ae4319ce5d1742a132363989fe97afb2a5f2b61005afeac7ff0f107/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c656f343034383131312f596f6c6f76352d4c6162656c4d616b65722d466f722d4353474f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/16d0363f9ae4319ce5d1742a132363989fe97afb2a5f2b61005afeac7ff0f107/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c656f343034383131312f596f6c6f76352d4c6162656c4d616b65722d466f722d4353474f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/leo4048111/Yolov5-LabelMaker-For-CSGO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A simple tool for making CSGO dataset in YOLO format.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/soloist-v/AutoStrike\"\u003esoloist-v/AutoStrike\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/57c6cb258dcb31171e11b6398d5d3ba8c4145108f1c73d4430d45410ea87ebbe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736f6c6f6973742d762f4175746f537472696b653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/57c6cb258dcb31171e11b6398d5d3ba8c4145108f1c73d4430d45410ea87ebbe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736f6c6f6973742d762f4175746f537472696b653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/soloist-v/AutoStrike?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 使用yolov5自动瞄准，支持fps游戏 鼠标移动控制需要自行调整。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/slyautomation/osrs_yolov5\"\u003eslyautomation/osrs_yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e7458da7d0c13d1eb126c9d468a78ac34ff524fa5842862562eab09b57032e9b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736c796175746f6d6174696f6e2f6f7372735f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e7458da7d0c13d1eb126c9d468a78ac34ff524fa5842862562eab09b57032e9b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736c796175746f6d6174696f6e2f6f7372735f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/slyautomation/osrs_yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov5 Object Detection In OSRS using Python code, Detecting Cows - Botting.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HarunoWindy/yolo-games-weights\"\u003eHarunoWindy/yolo-games-weights\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/125e86184b562f411f4936bd3007ae79536e2a08f302d9a5f07c56b6055dba91/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f486172756e6f57696e64792f796f6c6f2d67616d65732d776569676874733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/125e86184b562f411f4936bd3007ae79536e2a08f302d9a5f07c56b6055dba91/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f486172756e6f57696e64792f796f6c6f2d67616d65732d776569676874733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HarunoWindy/yolo-games-weights?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5 vision deep-learning on detect games UI (current support: onmyoji) YOLOv5深度学习识别游戏UI(目前支持：阴阳师).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mrathena/python.yolo.csgo.autoaim.helper\"\u003emrathena/python.yolo.csgo.autoaim.helper\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/45fc1be8bf12e08c7748f668d3e4da5614ffdbd88508dce1715ed26cbeec01b1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d72617468656e612f707974686f6e2e796f6c6f2e6373676f2e6175746f61696d2e68656c7065723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/45fc1be8bf12e08c7748f668d3e4da5614ffdbd88508dce1715ed26cbeec01b1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d72617468656e612f707974686f6e2e796f6c6f2e6373676f2e6175746f61696d2e68656c7065723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mrathena/python.yolo.csgo.autoaim.helper?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Python Yolo v5 6.2 Csgo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Aa-bN/AimYolo\"\u003eAa-bN/AimYolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/35c5053838e99822efe7f81b32338c07bd69f014e182bcc7bd43db49ee6d813e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41612d624e2f41696d596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/35c5053838e99822efe7f81b32338c07bd69f014e182bcc7bd43db49ee6d813e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41612d624e2f41696d596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Aa-bN/AimYolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : AI外挂——基于YOLOv5的射击类游戏瞄准辅助。An AI plug-in - targeting aid for shooting games based on YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/suixin1424/cf-yolo-trt\"\u003esuixin1424/cf-yolo-trt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a9cbff54489a8043c5d0835bdfadefac5b798fb745b4c87e4a9296c4767fb648/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756978696e313432342f63662d796f6c6f2d7472743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a9cbff54489a8043c5d0835bdfadefac5b798fb745b4c87e4a9296c4767fb648/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756978696e313432342f63662d796f6c6f2d7472743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/suixin1424/cf-yolo-trt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于yolov5-trt的穿越火线ai自瞄。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DuGuYifei/Yolov5_FPS_AICheatPrinciple\"\u003eDuGuYifei/Yolov5_FPS_AICheatPrinciple\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/eeb75c07bdc51a934c236703f2406bd5d56ac4feef48cd72c34774dee64d1154/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4475477559696665692f596f6c6f76355f4650535f414943686561745072696e6369706c653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/eeb75c07bdc51a934c236703f2406bd5d56ac4feef48cd72c34774dee64d1154/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4475477559696665692f596f6c6f76355f4650535f414943686561745072696e6369706c653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DuGuYifei/Yolov5_FPS_AICheatPrinciple?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The AI cheating principle of fps game. (This is only used for learning).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MistyAI/MistyFN\"\u003eMistyAI/MistyFN\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a519603ebb62540c87e788cb68cf3ca2fee806f2b37e5aaf7443708db52a662c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6973747941492f4d69737479464e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a519603ebb62540c87e788cb68cf3ca2fee806f2b37e5aaf7443708db52a662c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6973747941492f4d69737479464e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MistyAI/MistyFN?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Aimbot and Triggerbot for Fortnite based on artificial intelligence.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/suixin1424/crossfire-yolo-TensorRT\"\u003esuixin1424/crossfire-yolo-TensorRT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/40ef63ab9ed0f89ba8a85d3d5ea52caf8410f4ef9db5d2440e00f08860333eee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756978696e313432342f63726f7373666972652d796f6c6f2d54656e736f7252543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/40ef63ab9ed0f89ba8a85d3d5ea52caf8410f4ef9db5d2440e00f08860333eee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73756978696e313432342f63726f7373666972652d796f6c6f2d54656e736f7252543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/suixin1424/crossfire-yolo-TensorRT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : crossfire-yolo-TensorRT. 基于yolo-trt的穿越火线ai自瞄。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/EthanH3514/AL_Yolo\"\u003eEthanH3514/AL_Yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/227efe01e36e3b9d6ed6db141820dd5bed597b8d0e4fa465e7d3a8828d796058/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f457468616e48333531342f414c5f596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/227efe01e36e3b9d6ed6db141820dd5bed597b8d0e4fa465e7d3a8828d796058/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f457468616e48333531342f414c5f596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/EthanH3514/AL_Yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于Yolov5的Apex Legend游戏 AI 辅瞄外挂。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SunOner/yolov8_aimbot\"\u003eSunOner/yolov8_aimbot\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/02df7ac6e3a8e35e0fca97ac0cdb14e06dc0d2589ffc0592d9da3053a97ec7a6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53756e4f6e65722f796f6c6f76385f61696d626f743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/02df7ac6e3a8e35e0fca97ac0cdb14e06dc0d2589ffc0592d9da3053a97ec7a6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f53756e4f6e65722f796f6c6f76385f61696d626f743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SunOner/yolov8_aimbot?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Aim-bot based on AI for all FPS games.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bigQY/calabiyau-cheat\"\u003ebigQY/calabiyau-cheat\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/98ae4ad31fe2aa8bb697416ccd53c74e0716b6aefe0c002643e5d5ac471b2816/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62696751592f63616c6162697961752d63686561743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/98ae4ad31fe2aa8bb697416ccd53c74e0716b6aefe0c002643e5d5ac471b2816/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f62696751592f63616c6162697961752d63686561743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bigQY/calabiyau-cheat?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于yolov10的卡拉彼丘自瞄。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAutomatic Annotation Tools\u003c/h3\u003e\u003ca id=\"user-content-automatic-annotation-tools\" class=\"anchor\" aria-label=\"Permalink: Automatic Annotation Tools\" href=\"#automatic-annotation-tools\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e自动标注工具\u003c/h4\u003e\u003ca id=\"user-content-自动标注工具\" class=\"anchor\" aria-label=\"Permalink: 自动标注工具\" href=\"#自动标注工具\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HumanSignal/label-studio\"\u003eLabel Studio\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/67036dea2546fceffdfc29d776ff2b3735d525e4527ad8ddd6a59b4822cb3ad5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48756d616e5369676e616c2f6c6162656c2d73747564696f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/67036dea2546fceffdfc29d776ff2b3735d525e4527ad8ddd6a59b4822cb3ad5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48756d616e5369676e616c2f6c6162656c2d73747564696f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HumanSignal/label-studio?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Label Studio is a multi-type data labeling and annotation tool with standardized output format. \u003ca href=\"https://labelstud.io/\" rel=\"nofollow\"\u003elabelstud.io\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/vietanhdev/anylabeling\"\u003eAnyLabeling\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fabfde4bb4cc495066df3245b2d5ff1d8e1b95d8f377ab207fcb45588a33f6cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76696574616e686465762f616e796c6162656c696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fabfde4bb4cc495066df3245b2d5ff1d8e1b95d8f377ab207fcb45588a33f6cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76696574616e686465762f616e796c6162656c696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/vietanhdev/anylabeling?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🌟 AnyLabeling 🌟. Effortless AI-assisted data labeling with AI support from YOLO, Segment Anything, MobileSAM!! \u003ca href=\"https://anylabeling.nrl.ai/\" rel=\"nofollow\"\u003eanylabeling.nrl.ai\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CVHub520/X-AnyLabeling\"\u003eX-AnyLabeling\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/822ce53353585f82ef9fb52ff2b5e2439c18912227c1fe5550a73acaf89ea2e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43564875623532302f582d416e794c6162656c696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/822ce53353585f82ef9fb52ff2b5e2439c18912227c1fe5550a73acaf89ea2e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43564875623532302f582d416e794c6162656c696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CVHub520/X-AnyLabeling?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 💫 X-AnyLabeling 💫. X-AnyLabeling：一款多 SOTA 模型集成的高级自动标注工具！ Effortless data labeling with AI support from Segment Anything and other awesome models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/open-mmlab/playground/tree/main/label_anything\"\u003eLabel Anything\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2803dd19ecd3c798e5a6155e46e2aba807950cc13d53136974565447c7b19a47/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d6d6d6c61622f706c617967726f756e643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2803dd19ecd3c798e5a6155e46e2aba807950cc13d53136974565447c7b19a47/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d6d6d6c61622f706c617967726f756e643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/open-mmlab/playground?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : OpenMMLab PlayGround: Semi-Automated Annotation with Label-Studio and SAM.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/heartexlabs/labelImg\"\u003eLabelImg\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/dadc4a6251bef7ddf268b9606b0cccc7a958971ebd9b5f518e5abed8839f42a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686561727465786c6162732f6c6162656c496d673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dadc4a6251bef7ddf268b9606b0cccc7a958971ebd9b5f518e5abed8839f42a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686561727465786c6162732f6c6162656c496d673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/heartexlabs/labelImg?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🖍️ LabelImg is a graphical image annotation tool and label object bounding boxes in images.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wkentaro/labelme\"\u003elabelme\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5a182962d92bb16f13a72a6a57003ce19d8d3ec41bcb3e1fea71b9639c9e356f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776b656e7461726f2f6c6162656c6d653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5a182962d92bb16f13a72a6a57003ce19d8d3ec41bcb3e1fea71b9639c9e356f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776b656e7461726f2f6c6162656c6d653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wkentaro/labelme?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Image Polygonal Annotation with Python (polygon, rectangle, circle, line, point and image-level flag annotation).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/darkpgmr/DarkLabel\"\u003eDarkLabel\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/dc1ee184b84c0eddc37bd121b96efe7778dd45f40eb033cc3985d5e8155ea94e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6461726b70676d722f4461726b4c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dc1ee184b84c0eddc37bd121b96efe7778dd45f40eb033cc3985d5e8155ea94e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6461726b70676d722f4461726b4c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/darkpgmr/DarkLabel?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Video/Image Labeling and Annotation Tool.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlexeyAB/Yolo_mark\"\u003eAlexeyAB/Yolo_mark\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5f0d86929b24cadd73bfb672723a507e94cbf9d176b515bfce3b1e918bbbc2e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f596f6c6f5f6d61726b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5f0d86929b24cadd73bfb672723a507e94cbf9d176b515bfce3b1e918bbbc2e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f596f6c6f5f6d61726b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlexeyAB/Yolo_mark?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : GUI for marking bounded boxes of objects in images for training neural network Yolo v3 and v2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Cartucho/OpenLabeling\"\u003eCartucho/OpenLabeling\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/85366566b5f23bcd02b387b80aecfac3e4baa0e1b2735a04b3e551d0486723fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436172747563686f2f4f70656e4c6162656c696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/85366566b5f23bcd02b387b80aecfac3e4baa0e1b2735a04b3e551d0486723fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436172747563686f2f4f70656e4c6162656c696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Cartucho/OpenLabeling?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Label images and video for Computer Vision applications.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cvat-ai/cvat\"\u003eCVAT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fe9a07e7636fde23bdec44e090a5f2f0bbacd2036375694b3be07da38108da77/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f637661742d61692f637661743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fe9a07e7636fde23bdec44e090a5f2f0bbacd2036375694b3be07da38108da77/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f637661742d61692f637661743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cvat-ai/cvat?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Computer Vision Annotation Tool (CVAT). Annotate better with CVAT, the industry-leading data engine for machine learning. Used and trusted by teams at any scale, for data of any scale.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Microsoft/VoTT\"\u003eVoTT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/695897a0062f5aae617295086997957761e99e9042ca2dacaa1259fd6f50b25c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6963726f736f66742f566f54543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/695897a0062f5aae617295086997957761e99e9042ca2dacaa1259fd6f50b25c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6963726f736f66742f566f54543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Microsoft/VoTT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Visual Object Tagging Tool: An electron app for building end to end Object Detection Models from Images and Videos.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WangRongsheng/KDAT\"\u003eWangRongsheng/KDAT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2d66a5d1fa71d78e1b2336df8582396d6bbd610e6ddc39b4d64248c15801274c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57616e67526f6e677368656e672f4b4441543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2d66a5d1fa71d78e1b2336df8582396d6bbd610e6ddc39b4d64248c15801274c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57616e67526f6e677368656e672f4b4441543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WangRongsheng/KDAT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 一个专为视觉方向目标检测全流程的标注工具集，全称：Kill Object Detection Annotation Tools。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ryouchinsa/Rectlabel-support\"\u003eRectlabel-support\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/81e95ba68beb08b64d183eae8ae23f01dc8ffadb41279118e21cb3e778c5946e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72796f756368696e73612f526563746c6162656c2d737570706f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/81e95ba68beb08b64d183eae8ae23f01dc8ffadb41279118e21cb3e778c5946e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72796f756368696e73612f526563746c6162656c2d737570706f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ryouchinsa/Rectlabel-support?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : RectLabel - An image annotation tool to label images for bounding box object detection and segmentation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cnyvfang/labelGo-Yolov5AutoLabelImg\"\u003ecnyvfang/labelGo-Yolov5AutoLabelImg\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/68e9f1abd14edfe12bc90dabcc941509334ee989db4aa9dc1c338bd3c2744931/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636e797666616e672f6c6162656c476f2d596f6c6f76354175746f4c6162656c496d673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/68e9f1abd14edfe12bc90dabcc941509334ee989db4aa9dc1c338bd3c2744931/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636e797666616e672f6c6162656c476f2d596f6c6f76354175746f4c6162656c496d673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cnyvfang/labelGo-Yolov5AutoLabelImg?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 💕YOLOV5 semi-automatic annotation tool (Based on labelImg)💕一个基于labelImg及YOLOV5的图形化半自动标注工具。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CVUsers/Auto_maker\"\u003eCVUsers/Auto_maker\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/31c56c1966068b2cc0840abbd696cb7a7a89afb2ce0c6f4f58e2815531641022/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f435655736572732f4175746f5f6d616b65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/31c56c1966068b2cc0840abbd696cb7a7a89afb2ce0c6f4f58e2815531641022/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f435655736572732f4175746f5f6d616b65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CVUsers/Auto_maker?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 深度学习数据自动标注器开源 目标检测和图像分类（高精度高效率）。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/OvidijusParsiunas/myvision\"\u003eMyVision\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/76e9fb38381abef02bffcb05cfd095d4ebed24804cb339470cdb83c69c6cc889/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f766964696a75735061727369756e61732f6d79766973696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/76e9fb38381abef02bffcb05cfd095d4ebed24804cb339470cdb83c69c6cc889/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f766964696a75735061727369756e61732f6d79766973696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/OvidijusParsiunas/myvision?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Computer vision based ML training data generation tool 🚀\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wufan-tb/AutoLabelImg\"\u003ewufan-tb/AutoLabelImg\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/64e224ef08aabd2c4751c8501d17ff7a88a4d5f4bffe825f2911e71708fc4202/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f777566616e2d74622f4175746f4c6162656c496d673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/64e224ef08aabd2c4751c8501d17ff7a88a4d5f4bffe825f2911e71708fc4202/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f777566616e2d74622f4175746f4c6162656c496d673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wufan-tb/AutoLabelImg?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : auto-labelimg based on yolov5, with many other useful tools. AutoLabelImg 多功能自动标注工具。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MrZander/YoloMarkNet\"\u003eMrZander/YoloMarkNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/07165a8ff9ed22800e62d4daee320cd0cdc47eb042819a83874dbcd99a0ee65f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d725a616e6465722f596f6c6f4d61726b4e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/07165a8ff9ed22800e62d4daee320cd0cdc47eb042819a83874dbcd99a0ee65f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d725a616e6465722f596f6c6f4d61726b4e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MrZander/YoloMarkNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Darknet YOLOv2/3 annotation tool written in C#/WPF.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mahxn0/Yolov3_ForTextLabel\"\u003emahxn0/Yolov3_ForTextLabel\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/50610f6ad79c28ba605e629e99e947f38b8bd2d7a7e3916b66f71e19a4eb0f1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6168786e302f596f6c6f76335f466f72546578744c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/50610f6ad79c28ba605e629e99e947f38b8bd2d7a7e3916b66f71e19a4eb0f1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6168786e302f596f6c6f76335f466f72546578744c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mahxn0/Yolov3_ForTextLabel?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于yolov3的目标/自然场景文字自动标注工具。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MNConnor/YoloV5-AI-Label\"\u003eMNConnor/YoloV5-AI-Label\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bae30cda23e2451058ec7422d8233aab8a4ef55d7e8c108bd329e7511fbdb7aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d4e436f6e6e6f722f596f6c6f56352d41492d4c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bae30cda23e2451058ec7422d8233aab8a4ef55d7e8c108bd329e7511fbdb7aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d4e436f6e6e6f722f596f6c6f56352d41492d4c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MNConnor/YoloV5-AI-Label?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV5 AI Assisted Labeling.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LILINOpenGitHub/Labeling-Tool\"\u003eLILINOpenGitHub/Labeling-Tool\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0dda3d9021bae83c1599227cba107851e7fca8ed66964b0409228ebf9925507a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c494c494e4f70656e4769744875622f4c6162656c696e672d546f6f6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0dda3d9021bae83c1599227cba107851e7fca8ed66964b0409228ebf9925507a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c494c494e4f70656e4769744875622f4c6162656c696e672d546f6f6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LILINOpenGitHub/Labeling-Tool?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Free YOLO AI labeling tool. YOLO AI labeling tool is a Windows app for labeling YOLO dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/whs0523003/YOLOv5_6.1_autolabel\"\u003ewhs0523003/YOLOv5_6.1_autolabel\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5945d2dd0cf857c10634ff50faf0a6fa29fab0229b0e836b63142bb5c2b084e8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776873303532333030332f594f4c4f76355f362e315f6175746f6c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5945d2dd0cf857c10634ff50faf0a6fa29fab0229b0e836b63142bb5c2b084e8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776873303532333030332f594f4c4f76355f362e315f6175746f6c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/whs0523003/YOLOv5_6.1_autolabel?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5_6.1 自动标记目标框。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/2vin/PyYAT\"\u003e2vin/PyYAT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c7e1064e7dd50959690eef4f38f1d4749dbc5aa325696511fb5a1c72a133073c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3276696e2f50795941543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c7e1064e7dd50959690eef4f38f1d4749dbc5aa325696511fb5a1c72a133073c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3276696e2f50795941543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/2vin/PyYAT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Semi-Automatic Yolo Annotation Tool In Python.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlturosDestinations/Alturos.ImageAnnotation\"\u003eAlturosDestinations/Alturos.ImageAnnotation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b6ba89fc7367ee013a360cdc8eaa6c1c379243f52450f81df24188e7ed826e92/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c7475726f7344657374696e6174696f6e732f416c7475726f732e496d616765416e6e6f746174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b6ba89fc7367ee013a360cdc8eaa6c1c379243f52450f81df24188e7ed826e92/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c7475726f7344657374696e6174696f6e732f416c7475726f732e496d616765416e6e6f746174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlturosDestinations/Alturos.ImageAnnotation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A collaborative tool for labeling image data for yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/stephanecharette/DarkMark\"\u003estephanecharette/DarkMark\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fd2bd5cfcdb3e964e498f8dc1989a07abccac0d267e0f362358a8ae32516fa0f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374657068616e6563686172657474652f4461726b4d61726b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fd2bd5cfcdb3e964e498f8dc1989a07abccac0d267e0f362358a8ae32516fa0f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374657068616e6563686172657474652f4461726b4d61726b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/stephanecharette/DarkMark?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Marking up images for use with Darknet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/2vin/yolo_annotation_tool\"\u003e2vin/yolo_annotation_tool\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8fac3b71b05b60c41d0fc33d10f11fa87124cd2f34af81cd74c00726646a14c6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3276696e2f796f6c6f5f616e6e6f746174696f6e5f746f6f6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8fac3b71b05b60c41d0fc33d10f11fa87124cd2f34af81cd74c00726646a14c6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3276696e2f796f6c6f5f616e6e6f746174696f6e5f746f6f6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/2vin/yolo_annotation_tool?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Annotation tool for YOLO in opencv.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sanfooh/quick_yolo2_label_tool\"\u003esanfooh/quick_yolo2_label_tool\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/601f50b57a84009341cc6308ee832f54eb3e6b6f2feda6bfc4cf9bb8b10525b2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73616e666f6f682f717569636b5f796f6c6f325f6c6162656c5f746f6f6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/601f50b57a84009341cc6308ee832f54eb3e6b6f2feda6bfc4cf9bb8b10525b2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73616e666f6f682f717569636b5f796f6c6f325f6c6162656c5f746f6f6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sanfooh/quick_yolo2_label_tool?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolo快速标注工具 quick yolo2 label tool.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/folkien/yaya\"\u003efolkien/yaya\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a1a5789fd999eac0555317afe1e759db4bf040f715e39e1fbc84f27b931ad01a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666f6c6b69656e2f796179613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a1a5789fd999eac0555317afe1e759db4bf040f715e39e1fbc84f27b931ad01a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666f6c6b69656e2f796179613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/folkien/yaya?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YAYA - Yet annother YOLO annoter for images (in QT5). Support yolo format, image modifications, labeling and detecting with previously trained detector.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pylabel-project/pylabel\"\u003epylabel-project/pylabel\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2391c03e201ec8104ea2aa1b0ef63f6dc5c4818c99c2f9527698a7556db39c09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70796c6162656c2d70726f6a6563742f70796c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2391c03e201ec8104ea2aa1b0ef63f6dc5c4818c99c2f9527698a7556db39c09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70796c6162656c2d70726f6a6563742f70796c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pylabel-project/pylabel?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Python library for computer vision labeling tasks. The core functionality is to translate bounding box annotations between different formats-for example, from coco to yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/opendatalab/labelU\"\u003eopendatalab/labelU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ef37844fb33e54c59b70a193bdb2d3c2afff71b26eb40d3fc8db53abba609e7a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e646174616c61622f6c6162656c553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ef37844fb33e54c59b70a193bdb2d3c2afff71b26eb40d3fc8db53abba609e7a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e646174616c61622f6c6162656c553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/opendatalab/labelU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Uniform, Unlimited, Universal and Unbelievable Annotation Toolbox.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFeature Map Visualization\u003c/h3\u003e\u003ca id=\"user-content-feature-map-visualization\" class=\"anchor\" aria-label=\"Permalink: Feature Map Visualization\" href=\"#feature-map-visualization\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e特征图可视化\u003c/h4\u003e\u003ca id=\"user-content-特征图可视化\" class=\"anchor\" aria-label=\"Permalink: 特征图可视化\" href=\"#特征图可视化\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pooya-mohammadi/yolov5-gradcam\"\u003epooya-mohammadi/yolov5-gradcam\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4280d20ac758753bf41b1122f5ba2946864bb8faca55530b607cdd0fc298bca8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706f6f79612d6d6f68616d6d6164692f796f6c6f76352d6772616463616d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4280d20ac758753bf41b1122f5ba2946864bb8faca55530b607cdd0fc298bca8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f706f6f79612d6d6f68616d6d6164692f796f6c6f76352d6772616463616d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pooya-mohammadi/yolov5-gradcam?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Visualizing Yolov5's layers using GradCam.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/frgfm/torch-cam\"\u003eTorchCAM\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/343e418944612501d28790632747a51a2b043a79f11c7816915a117ca2923fce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f667267666d2f746f7263682d63616d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/343e418944612501d28790632747a51a2b043a79f11c7816915a117ca2923fce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f667267666d2f746f7263682d63616d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/frgfm/torch-cam?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Class activation maps for your PyTorch models (CAM, Grad-CAM, Grad-CAM++, Smooth Grad-CAM++, Score-CAM, SS-CAM, IS-CAM, XGrad-CAM, Layer-CAM).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Him-wen/OD_Heatmap\"\u003eHim-wen/OD_Heatmap\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fa5b6a628d2b611fc7202190c85c783536f0d6d1cd8cf91c8e53047e819c82e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48696d2d77656e2f4f445f486561746d61703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fa5b6a628d2b611fc7202190c85c783536f0d6d1cd8cf91c8e53047e819c82e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48696d2d77656e2f4f445f486561746d61703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Him-wen/OD_Heatmap?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Heatmap visualization of the YOLO model using the Grad-CAM heatmap visualization method can Intuitively show which regions in the image contribute the most to the category classification.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eObject Detection Evaluation Metrics\u003c/h3\u003e\u003ca id=\"user-content-object-detection-evaluation-metrics\" class=\"anchor\" aria-label=\"Permalink: Object Detection Evaluation Metrics\" href=\"#object-detection-evaluation-metrics\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e目标检测性能评价指标\u003c/h4\u003e\u003ca id=\"user-content-目标检测性能评价指标\" class=\"anchor\" aria-label=\"Permalink: 目标检测性能评价指标\" href=\"#目标检测性能评价指标\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/rafaelpadilla/review_object_detection_metrics\"\u003erafaelpadilla/review_object_detection_metrics\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/72c5af5a8d6ea2585a8cc5339b472d8be149b51f0ba8d1d02ae07150c1f5295f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616661656c706164696c6c612f7265766965775f6f626a6563745f646574656374696f6e5f6d6574726963733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/72c5af5a8d6ea2585a8cc5339b472d8be149b51f0ba8d1d02ae07150c1f5295f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616661656c706164696c6c612f7265766965775f6f626a6563745f646574656374696f6e5f6d6574726963733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/rafaelpadilla/review_object_detection_metrics?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object Detection Metrics. 14 object detection metrics: mean Average Precision (mAP), Average Recall (AR), Spatio-Temporal Tube Average Precision (STT-AP). This project supports different bounding box formats as in COCO, PASCAL, Imagenet, etc. \"A Comparative Analysis of Object Detection Metrics with a Companion Open-Source Toolkit\".  (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/2079-9292/10/3/279\" rel=\"nofollow\"\u003eElectronics 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/rafaelpadilla/Object-Detection-Metrics\"\u003erafaelpadilla/Object-Detection-Metrics\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/288b240195b3187c5e918dff44ced4c4198bbbe3a7dd25cb1655626499fcc709/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616661656c706164696c6c612f4f626a6563742d446574656374696f6e2d4d6574726963733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/288b240195b3187c5e918dff44ced4c4198bbbe3a7dd25cb1655626499fcc709/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616661656c706164696c6c612f4f626a6563742d446574656374696f6e2d4d6574726963733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/rafaelpadilla/Object-Detection-Metrics?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Most popular metrics used to evaluate object detection algorithms. \"A Survey on Performance Metrics for Object-Detection Algorithms\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9145130\" rel=\"nofollow\"\u003eIWSSIP 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Cartucho/mAP\"\u003eCartucho/mAP\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e5c472db7996cbd6f7491434e869dc238447a7f6e57d77e13f3720422874a7de/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436172747563686f2f6d41503f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e5c472db7996cbd6f7491434e869dc238447a7f6e57d77e13f3720422874a7de/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436172747563686f2f6d41503f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Cartucho/mAP?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : mean Average Precision - This code evaluates the performance of your neural net for object recognition.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Lightning-AI/metrics\"\u003eLightning-AI/metrics\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3ccd58b7fa845dbc809c0278dd4fb6831fe22660295b1970a3c38276f6b8e8e0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696768746e696e672d41492f6d6574726963733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3ccd58b7fa845dbc809c0278dd4fb6831fe22660295b1970a3c38276f6b8e8e0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696768746e696e672d41492f6d6574726963733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Lightning-AI/metrics?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Machine learning metrics for distributed, scalable PyTorch applications.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/open-mmlab/mmeval\"\u003eopen-mmlab/mmeval\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0ec53f35460e784a3e09c893e449962c7fd4d25e06d6e28b6dfced6d95fdb2f6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d6d6d6c61622f6d6d6576616c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0ec53f35460e784a3e09c893e449962c7fd4d25e06d6e28b6dfced6d95fdb2f6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e2d6d6d6c61622f6d6d6576616c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/open-mmlab/mmeval?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : MMEval is a machine learning evaluation library that supports efficient and accurate distributed evaluation on a variety of machine learning frameworks.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/laclouis5/globox\"\u003elaclouis5/globox\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/16ab043da9897ec27d25062862d1ad170320751ef6f0767cabab61de07fc0096/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c61636c6f756973352f676c6f626f783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/16ab043da9897ec27d25062862d1ad170320751ef6f0767cabab61de07fc0096/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c61636c6f756973352f676c6f626f783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/laclouis5/globox?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A package to read and convert object detection databases (COCO, YOLO, PascalVOC, LabelMe, CVAT, OpenImage, ...) and evaluate them with COCO and PascalVOC metrics.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eGUI\u003c/h3\u003e\u003ca id=\"user-content-gui\" class=\"anchor\" aria-label=\"Permalink: GUI\" href=\"#gui\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e图形用户界面\u003c/h4\u003e\u003ca id=\"user-content-图形用户界面\" class=\"anchor\" aria-label=\"Permalink: 图形用户界面\" href=\"#图形用户界面\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSwift-Related\u003c/h4\u003e\u003ca id=\"user-content-swift-related\" class=\"anchor\" aria-label=\"Permalink: Swift-Related\" href=\"#swift-related\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/ultralytics/yolo-ios-app\"\u003eultralytics/yolo-ios-app\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5333c8ce4ac7b23fa150a485831fd6290a792294be97ae8a430797460fbd0797/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f796f6c6f2d696f732d6170703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5333c8ce4ac7b23fa150a485831fd6290a792294be97ae8a430797460fbd0797/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f796f6c6f2d696f732d6170703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ultralytics/yolo-ios-app?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Ultralytics YOLO iOS App source code for running YOLOv8 in your own iOS apps 🌟. \u003ca href=\"https://ultralytics.com/yolo\" rel=\"nofollow\"\u003eultralytics.com/yolo\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFlutter-Related\u003c/h4\u003e\u003ca id=\"user-content-flutter-related\" class=\"anchor\" aria-label=\"Permalink: Flutter-Related\" href=\"#flutter-related\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ultralytics/yolo-flutter-app\"\u003eultralytics/yolo-flutter-app\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/09b40faa2198c739a1365a4e510f03b642325a22f1454d0c494f84ae217c34ed/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f796f6c6f2d666c75747465722d6170703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/09b40faa2198c739a1365a4e510f03b642325a22f1454d0c494f84ae217c34ed/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756c7472616c79746963732f796f6c6f2d666c75747465722d6170703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ultralytics/yolo-flutter-app?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A Flutter plugin for Ultralytics YOLO computer vision models. \u003ca href=\"https://ultralytics.com/\" rel=\"nofollow\"\u003eultralytics.com\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/hiennguyen92/flutter_realtime_object_detection\"\u003ehiennguyen92/flutter_realtime_object_detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/933f531f6eab2ccd02343cd44baf9d8503c609ffad56b882c6e7002b9bc4bdfa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6869656e6e677579656e39322f666c75747465725f7265616c74696d655f6f626a6563745f646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/933f531f6eab2ccd02343cd44baf9d8503c609ffad56b882c6e7002b9bc4bdfa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6869656e6e677579656e39322f666c75747465725f7265616c74696d655f6f626a6563745f646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/hiennguyen92/flutter_realtime_object_detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Flutter App real-time object detection with Tensorflow Lite.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eStreamlit-Related\u003c/h4\u003e\u003ca id=\"user-content-streamlit-related\" class=\"anchor\" aria-label=\"Permalink: Streamlit-Related\" href=\"#streamlit-related\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wjnwjn59/YOLOv10_Streamlit_Demo\"\u003ewjnwjn59/YOLOv10_Streamlit_Demo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/eb1d0c21da997b29fa4bcce71cecf4d64ee73beb24c53f139966ce7c22a517ce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776a6e776a6e35392f594f4c4f7631305f53747265616d6c69745f44656d6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/eb1d0c21da997b29fa4bcce71cecf4d64ee73beb24c53f139966ce7c22a517ce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776a6e776a6e35392f594f4c4f7631305f53747265616d6c69745f44656d6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wjnwjn59/YOLOv10_Streamlit_Demo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A simple object detection web demo using YOLOv10 and Streamlit.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/rampal-punia/yolov8-streamlit-detection-tracking\"\u003erampal-punia/yolov8-streamlit-detection-tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1320069969991236dd98b023a381124201978cd54e70e0077bdf9d90e6549179/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616d70616c2d70756e69612f796f6c6f76382d73747265616d6c69742d646574656374696f6e2d747261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1320069969991236dd98b023a381124201978cd54e70e0077bdf9d90e6549179/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72616d70616c2d70756e69612f796f6c6f76382d73747265616d6c69742d646574656374696f6e2d747261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/rampal-punia/yolov8-streamlit-detection-tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object detection and tracking algorithm implemented for Real-Time video streams and static images.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/JackDance/YOLOv8-streamlit-app\"\u003eJackDance/YOLOv8-streamlit-app\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a757a9c757192604ea34a6ab43d77b043c9826699ea6857bca525e5624088fa4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61636b44616e63652f594f4c4f76382d73747265616d6c69742d6170703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a757a9c757192604ea34a6ab43d77b043c9826699ea6857bca525e5624088fa4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61636b44616e63652f594f4c4f76382d73747265616d6c69742d6170703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/JackDance/YOLOv8-streamlit-app?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🔥🔥🔥 Use streamlit framework to increase yolov8 front-end page interaction function. \"知乎「Mr.Luyao」《\u003ca href=\"https://zhuanlan.zhihu.com/p/630029493\" rel=\"nofollow\"\u003e深度学习/机器学习项目的前端展示利器--Streamlit\u003c/a\u003e》\"。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/streamlit/demo-self-driving\"\u003estreamlit/demo-self-driving\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e2b9f558f65a83043627968313a89b1bcbf741461c012d074e84037b68a4ff08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73747265616d6c69742f64656d6f2d73656c662d64726976696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e2b9f558f65a83043627968313a89b1bcbf741461c012d074e84037b68a4ff08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73747265616d6c69742f64656d6f2d73656c662d64726976696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/streamlit/demo-self-driving?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Streamlit app demonstrating an image browser for the Udacity self-driving-car dataset with realtime object detection using YOLO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xugaoxiang/yolov5-streamlit\"\u003exugaoxiang/yolov5-streamlit\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/daf01d051fc6e3abb53860ca735e21fe02ebac5aa9421cb53750dadb756770b9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f787567616f7869616e672f796f6c6f76352d73747265616d6c69743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/daf01d051fc6e3abb53860ca735e21fe02ebac5aa9421cb53750dadb756770b9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f787567616f7869616e672f796f6c6f76352d73747265616d6c69743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xugaoxiang/yolov5-streamlit?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Deploy YOLOv5 detection with Streamlit.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Kedreamix/YoloGesture\"\u003eKedreamix/YoloGesture\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/af65a0a770b62802f1c1c56d6da5934a35bbbebe1a7c6407d5c018c5b31f6d6c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b65647265616d69782f596f6c6f476573747572653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/af65a0a770b62802f1c1c56d6da5934a35bbbebe1a7c6407d5c018c5b31f6d6c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b65647265616d69782f596f6c6f476573747572653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Kedreamix/YoloGesture?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于计算机视觉手势识别控制系统YoLoGesture (利用YOLO实现)，利用yolo进行手势识别的控制系统，最后利用streamlit进行了部署。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eGradio-Related\u003c/h4\u003e\u003ca id=\"user-content-gradio-related\" class=\"anchor\" aria-label=\"Permalink: Gradio-Related\" href=\"#gradio-related\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zyds/yolov5-code\"\u003ezyds/yolov5-code\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/361aa9c52b30699bb408461dcdef61f59bacdc38a087a45dbb091f4a0ab6f146/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a7964732f796f6c6f76352d636f64653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/361aa9c52b30699bb408461dcdef61f59bacdc38a087a45dbb091f4a0ab6f146/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a7964732f796f6c6f76352d636f64653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zyds/yolov5-code?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 手把手带你实战 YOLOv5。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/KdaiP/yolov8-deepsort-tracking\"\u003eKdaiP/yolov8-deepsort-tracking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c005849d8f4fd9218aa95643bdd10a8b6784de030f5586a413b1fdc68fa90ef5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b646169502f796f6c6f76382d64656570736f72742d747261636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c005849d8f4fd9218aa95643bdd10a8b6784de030f5586a413b1fdc68fa90ef5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4b646169502f796f6c6f76382d64656570736f72742d747261636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/KdaiP/yolov8-deepsort-tracking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : opencv+yolov8+deepsort行人检测与跟踪,以及可选的WebUI界面（基于gradio）。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pengxiang1998/YOLOv8\"\u003epengxiang1998/YOLOv8\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ff4a7300727ffe15b8d4a5348339056d35a1cfbf722dd9320c5ed5bc1770d457/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70656e677869616e67313939382f594f4c4f76383f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ff4a7300727ffe15b8d4a5348339056d35a1cfbf722dd9320c5ed5bc1770d457/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70656e677869616e67313939382f594f4c4f76383f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pengxiang1998/YOLOv8?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于Gradio搭建的YOLOv8目标检测推理部署。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eQT-Related\u003c/h4\u003e\u003ca id=\"user-content-qt-related\" class=\"anchor\" aria-label=\"Permalink: QT-Related\" href=\"#qt-related\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ai-trainee/Traffic-Sign-Recognition-PyQt5-YOLOv5-GUI\"\u003eAi-trainee/Traffic-Sign-Recognition-PyQt5-YOLOv5-GUI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/90c72d4f35e2e36b19db9ea449b487cede52d7ca82c29f3f6dddb31914d294c1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41692d747261696e65652f547261666669632d5369676e2d5265636f676e6974696f6e2d50795174352d594f4c4f76352d4755493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/90c72d4f35e2e36b19db9ea449b487cede52d7ca82c29f3f6dddb31914d294c1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41692d747261696e65652f547261666669632d5369676e2d5265636f676e6974696f6e2d50795174352d594f4c4f76352d4755493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ai-trainee/Traffic-Sign-Recognition-PyQt5-YOLOv5-GUI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Road Sign Recognition Project Based on YOLOv5. This is a road sign recognition project based on YOLOv5, developed with a PyQt5 interface, YOLOv5 trained model, and MySQL database. 这是一个基于YOLOv5🚀的道路标志识别系统😊，使用了MySQL数据库💽，PyQt5进行界面设计🎨，PyTorch深度学习框架和TensorRT进行加速⚡，同时包含了CSS样式🌈。系统由五个主要模块组成：系统登录模块🔑负责用户登陆；初始化参数模块📋提供YOLOv5模型的初始化参数设置；标志识别模块🔍是系统的核心，负责对道路标志进行识别并将结果导入数据库；数据库模块💾包含基本数据库操作和数据分析两个子模块；图像处理模块🖼️负责单个图像的处理和数据增强。整个系统支持多种数据输入和模型切换，提供了包括mossic和mixup在内的图像增强方法📈。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/parker-int64/yolov5-RGBD\"\u003eparker-int64/yolov5-RGBD\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b4f59a7411181b368b586f0510047935d6c8d460dad2835209348d7027bf4470/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7061726b65722d696e7436342f796f6c6f76352d524742443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b4f59a7411181b368b586f0510047935d6c8d460dad2835209348d7027bf4470/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7061726b65722d696e7436342f796f6c6f76352d524742443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/parker-int64/yolov5-RGBD?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Qt QML based yolov5 + RGBD camera program.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Aimol-l/qml_with_yolov7\"\u003eAimol-l/qml_with_yolov7\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3c720a4d79f454ea5ff8e03cc92d99f6a5a4884e912355997860a8dc44ec5de1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41696d6f6c2d6c2f716d6c5f776974685f796f6c6f76373f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3c720a4d79f454ea5ff8e03cc92d99f6a5a4884e912355997860a8dc44ec5de1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f41696d6f6c2d6c2f716d6c5f776974685f796f6c6f76373f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Aimol-l/qml_with_yolov7?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 用YOLOV7+ByteTrack的方法识别视频/视频流，用QML绘制GUI，并带有统计信息。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xietx1995/YOLO-QT-Camera-Tool\"\u003exietx1995/YOLO-QT-Camera-Tool\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3c4eb895165d910d35c10e01de4bf3ed0d291fda8502841a719d321ba77776f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869657478313939352f594f4c4f2d51542d43616d6572612d546f6f6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3c4eb895165d910d35c10e01de4bf3ed0d291fda8502841a719d321ba77776f5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7869657478313939352f594f4c4f2d51542d43616d6572612d546f6f6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xietx1995/YOLO-QT-Camera-Tool?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detecting objects from camera or local video files vi qt and yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Javacr/PyQt5-YOLOv5\"\u003eJavacr/PyQt5-YOLOv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cf8f9263f26e2bdd44644415877a72da13220c6149c405c6384b4af1db3cf1c0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61766163722f50795174352d594f4c4f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cf8f9263f26e2bdd44644415877a72da13220c6149c405c6384b4af1db3cf1c0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61766163722f50795174352d594f4c4f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Javacr/PyQt5-YOLOv5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5检测界面-PyQt5实现。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zstar1003/yolov5_pyqt5\"\u003ezstar1003/yolov5_pyqt5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e56d87a5a3f958410049541a97308c52a74b4311f7dc4cfdb4096d268ad0f91c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a73746172313030332f796f6c6f76355f70797174353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e56d87a5a3f958410049541a97308c52a74b4311f7dc4cfdb4096d268ad0f91c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a73746172313030332f796f6c6f76355f70797174353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zstar1003/yolov5_pyqt5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 这是一个使用pyqt5搭建YOLOv5目标检测可视化程序。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/scutlrr/Yolov4-QtGUI\"\u003escutlrr/Yolov4-QtGUI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/77df3e2fabbd152f621bd8cc41de15fda6d69bea884f1e5e015d13642698f898/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736375746c72722f596f6c6f76342d51744755493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/77df3e2fabbd152f621bd8cc41de15fda6d69bea884f1e5e015d13642698f898/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736375746c72722f596f6c6f76342d51744755493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/scutlrr/Yolov4-QtGUI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolov4-QtGUI是基于\u003ca href=\"https://github.com/jmu201521121021/QtGuiDemo\"\u003eQtGuiDemo\u003c/a\u003e项目开发的可视化目标检测界面，可以简便选择本地图片、摄像头来展示图像处理算法的结果。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xugaoxiang/yolov5-pyqt5\"\u003exugaoxiang/yolov5-pyqt5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bc14ea5e9acf7c2b5e1993f203c78c1cfcfdad0f46b8839e4c67eb095e585dd7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f787567616f7869616e672f796f6c6f76352d70797174353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bc14ea5e9acf7c2b5e1993f203c78c1cfcfdad0f46b8839e4c67eb095e585dd7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f787567616f7869616e672f796f6c6f76352d70797174353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xugaoxiang/yolov5-pyqt5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 给yolov5加个gui界面，使用pyqt5，yolov5是5.0版本。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mxy493/YOLOv5-Qt\"\u003emxy493/YOLOv5-Qt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/911ef67eff87b76133a2a14c8051043e2e10f6de55e734e4a6d30383e4c4bd64/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d78793439332f594f4c4f76352d51743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/911ef67eff87b76133a2a14c8051043e2e10f6de55e734e4a6d30383e4c4bd64/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d78793439332f594f4c4f76352d51743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mxy493/YOLOv5-Qt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于YOLOv5的GUI程序，支持选择要使用的权重文件，设置是否使用GPU，设置置信度阈值等参数。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BonesCat/YoloV5_PyQt5\"\u003eBonesCat/YoloV5_PyQt5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b4388a60150c7a21d21fd79be0c311b75ffdc8181b5d8f5f4a2f36ba305aa1cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f6e65734361742f596f6c6f56355f50795174353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b4388a60150c7a21d21fd79be0c311b75ffdc8181b5d8f5f4a2f36ba305aa1cb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f426f6e65734361742f596f6c6f56355f50795174353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BonesCat/YoloV5_PyQt5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Add gui for YoloV5 using PyQt5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LuckyBoy1798/yolov5-pyqt\"\u003eLuckyBoy1798/yolov5-pyqt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/36e04c4ae3eda324b1661b652064f7a484d2ae79a95f9bf646242ca1d7d331c3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c75636b79426f79313739382f796f6c6f76352d707971743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/36e04c4ae3eda324b1661b652064f7a484d2ae79a95f9bf646242ca1d7d331c3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c75636b79426f79313739382f796f6c6f76352d707971743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LuckyBoy1798/yolov5-pyqt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于yolov5+pyqt的甲骨文图形化检测工具。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PySimpleGUI/PySimpleGUI-YOLO\"\u003ePySimpleGUI/PySimpleGUI-YOLO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f02608b7a1765a48a746f61d9dca151220c3360f5fdf819f9b55b17902eda4e0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f507953696d706c654755492f507953696d706c654755492d594f4c4f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f02608b7a1765a48a746f61d9dca151220c3360f5fdf819f9b55b17902eda4e0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f507953696d706c654755492f507953696d706c654755492d594f4c4f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PySimpleGUI/PySimpleGUI-YOLO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A YOLO Artificial Intelligence algorithm demonstration using PySimpleGUI.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/prabindh/qt5-opencv3-darknet\"\u003eprabindh/qt5-opencv3-darknet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cdc12557acfa1b796811a6dafbb426f5c822ff80726db63d3e060c302f3e6634/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70726162696e64682f7174352d6f70656e6376332d6461726b6e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cdc12557acfa1b796811a6dafbb426f5c822ff80726db63d3e060c302f3e6634/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70726162696e64682f7174352d6f70656e6376332d6461726b6e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/prabindh/qt5-opencv3-darknet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Qt5 + Darknet/Yolo + OpenCV3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/GinkgoX/YOLOv3GUI_Pytorch_PyQt5\"\u003eGinkgoX/YOLOv3GUI_Pytorch_PyQt5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1f7e32b433168e1ca1dc64e9e2b6a21f06d96b69ea6bc8699db0be5ad9e25829/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f47696e6b676f582f594f4c4f76334755495f5079746f7263685f50795174353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1f7e32b433168e1ca1dc64e9e2b6a21f06d96b69ea6bc8699db0be5ad9e25829/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f47696e6b676f582f594f4c4f76334755495f5079746f7263685f50795174353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/GinkgoX/YOLOv3GUI_Pytorch_PyQt5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a GUI project for Deep Learning Object Detection based on YOLOv3 model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FatemeZamanian/Yolov5-Fruit-Detector\"\u003eFatemeZamanian/Yolov5-Fruit-Detector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/13fe97c3ef673f2f8e7e10e4a3bb8553a2c582993a6c7471d663a95b522b3ba5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f466174656d655a616d616e69616e2f596f6c6f76352d46727569742d4465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/13fe97c3ef673f2f8e7e10e4a3bb8553a2c582993a6c7471d663a95b522b3ba5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f466174656d655a616d616e69616e2f596f6c6f76352d46727569742d4465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FatemeZamanian/Yolov5-Fruit-Detector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A program to recognize fruits on pictures or videos using yolov5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BioMeasure/PyQt5_YoLoV5_DeepSort\"\u003eBioMeasure/PyQt5_YoLoV5_DeepSort\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/575061dcb9b5ddcee79840d67aa997851d173a49cd0e80948c3e44a29114df7f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42696f4d6561737572652f50795174355f596f4c6f56355f44656570536f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/575061dcb9b5ddcee79840d67aa997851d173a49cd0e80948c3e44a29114df7f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42696f4d6561737572652f50795174355f596f4c6f56355f44656570536f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BioMeasure/PyQt5_YoLoV5_DeepSort?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a PyQt5 GUI program, which is based on YoloV5 and DeepSort to track person.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DongLizhong/YOLO_SORT_QT\"\u003eDongLizhong/YOLO_SORT_QT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/981c2bbf5998a6e0d49a92ef86600b2cdad87190a264e44023282cff7fc9d670/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f446f6e674c697a686f6e672f594f4c4f5f534f52545f51543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/981c2bbf5998a6e0d49a92ef86600b2cdad87190a264e44023282cff7fc9d670/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f446f6e674c697a686f6e672f594f4c4f5f534f52545f51543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DongLizhong/YOLO_SORT_QT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This code uses the opencv dnn module to load the darknet model for detection and add SORT for multi-object tracking(MOT).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Whu-wxy/yolov5_deepsort_ncnn_qt\"\u003eWhu-wxy/yolov5_deepsort_ncnn_qt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b05eaf831a1579281d1f71a43e3c0fe7a2565ee9e9b6d9fd522a4529f16bfe0c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5768752d7778792f796f6c6f76355f64656570736f72745f6e636e6e5f71743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b05eaf831a1579281d1f71a43e3c0fe7a2565ee9e9b6d9fd522a4529f16bfe0c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5768752d7778792f796f6c6f76355f64656570736f72745f6e636e6e5f71743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Whu-wxy/yolov5_deepsort_ncnn_qt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 用ncnn调用yolov5和deep sort模型，opencv读取视频。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jeswanthgalla/PyQt4_GUI_darknet_yolov4\"\u003ejeswanthgalla/PyQt4_GUI_darknet_yolov4\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bc3abd85b4e7b0a11798cf0bd77564672233de1f3c14a2ea21496b9477873377/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a657377616e746867616c6c612f50795174345f4755495f6461726b6e65745f796f6c6f76343f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bc3abd85b4e7b0a11798cf0bd77564672233de1f3c14a2ea21496b9477873377/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a657377616e746867616c6c612f50795174345f4755495f6461726b6e65745f796f6c6f76343f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jeswanthgalla/PyQt4_GUI_darknet_yolov4?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : GUI App using PyQt4. Multithreading to process multiple camera streams and using darknet yolov4 model for object detection.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/barleo01/yoloobjectdetector\"\u003ebarleo01/yoloobjectdetector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/544415cc147fff06d50c8910b8e53cc0a472b32e0997e9d366ee00e38c73cb6b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6261726c656f30312f796f6c6f6f626a6563746465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/544415cc147fff06d50c8910b8e53cc0a472b32e0997e9d366ee00e38c73cb6b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6261726c656f30312f796f6c6f6f626a6563746465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/barleo01/yoloobjectdetector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : The pupose of this application is to capture video from a camera, apply a YOLO Object detector and display it on a simple Qt Gui.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Eagle104fred/PyQt5-Yolov5\"\u003eEagle104fred/PyQt5-Yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/165ba40d3b12cdeb26c0b7a7824a601e078a275dc6d9e16b1c137370840919e6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4561676c65313034667265642f50795174352d596f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/165ba40d3b12cdeb26c0b7a7824a601e078a275dc6d9e16b1c137370840919e6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4561676c65313034667265642f50795174352d596f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Eagle104fred/PyQt5-Yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 把YOLOv5的视频显示到pyqt5ui上。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cnyvfang/YOLOv5-GUI\"\u003ecnyvfang/YOLOv5-GUI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/165ba40d3b12cdeb26c0b7a7824a601e078a275dc6d9e16b1c137370840919e6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4561676c65313034667265642f50795174352d596f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/165ba40d3b12cdeb26c0b7a7824a601e078a275dc6d9e16b1c137370840919e6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4561676c65313034667265642f50795174352d596f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Eagle104fred/PyQt5-Yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Qt-GUI implementation of the YOLOv5 algorithm (ver.6 and ver.5). YOLOv5算法(ver.6及ver.5)的Qt-GUI实现。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WeNN-Artificial-Intelligence/PyQT-Object-Detection-App\"\u003eWeNN-Artificial-Intelligence/PyQT-Object-Detection-App\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c4014cb862714b96e82097e8cd853ffe01beb6763b578ae3727ff88b5e017577/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57654e4e2d4172746966696369616c2d496e74656c6c6967656e63652f507951542d4f626a6563742d446574656374696f6e2d4170703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c4014cb862714b96e82097e8cd853ffe01beb6763b578ae3727ff88b5e017577/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57654e4e2d4172746966696369616c2d496e74656c6c6967656e63652f507951542d4f626a6563742d446574656374696f6e2d4170703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WeNN-Artificial-Intelligence/PyQT-Object-Detection-App?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Real-time object detection app with Python and PyQt framework.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Powercube7/YOLOv5-GUI\"\u003ePowercube7/YOLOv5-GUI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f699018c15f74f1636617b24e22b60bec319c4c1147189d3e114ba78d30d0406/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506f77657263756265372f594f4c4f76352d4755493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f699018c15f74f1636617b24e22b60bec319c4c1147189d3e114ba78d30d0406/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506f77657263756265372f594f4c4f76352d4755493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Powercube7/YOLOv5-GUI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A simple GUI made for creating jobs in YOLOv5.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cdmstrong/yolov5-pyqt-moke\"\u003ecdmstrong/yolov5-pyqt-moke\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4c4f72881a04e478a5a8ccd0bcbe578a3a2217d0d2ef5237966190b59f54a398/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63646d7374726f6e672f796f6c6f76352d707971742d6d6f6b653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4c4f72881a04e478a5a8ccd0bcbe578a3a2217d0d2ef5237966190b59f54a398/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63646d7374726f6e672f796f6c6f76352d707971742d6d6f6b653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cdmstrong/yolov5-pyqt-moke?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 利用yolov5和pyqt做可视化检测。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/GHigher12/Pyqt5_yolov5_unet_centernet\"\u003eGHigher12/Pyqt5_yolov5_unet_centernet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/34554f50d8cd5943e433e2986c3e74012638bd30e06e9262f874072bb7d1acab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4748696768657231322f50797174355f796f6c6f76355f756e65745f63656e7465726e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/34554f50d8cd5943e433e2986c3e74012638bd30e06e9262f874072bb7d1acab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4748696768657231322f50797174355f796f6c6f76355f756e65745f63656e7465726e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/GHigher12/Pyqt5_yolov5_unet_centernet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 集yolov5、centernet、unet算法的pyqt5界面，可实现图片目标检测和语义分割。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/chenanga/qt5_yolov5_2.0\"\u003echenanga/qt5_yolov5_2.0\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/81b4d785a1cb00ec600f366ce3ef7eb1b95dc2fa42a123de2fc90cfb2879a4a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368656e616e67612f7174355f796f6c6f76355f322e303f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/81b4d785a1cb00ec600f366ce3ef7eb1b95dc2fa42a123de2fc90cfb2879a4a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368656e616e67612f7174355f796f6c6f76355f322e303f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/chenanga/qt5_yolov5_2.0?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Pyqt搭建YOLOV5目标检测界面-第一次优化后的版本。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/xun-xh/yolov5-onnx-pyqt-exe\"\u003exun-xh/yolov5-onnx-pyqt-exe\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/552bc5c60fd9c33b9ecf36ab73c350c5f1392f4bdd41bac047019adfb5b5ac91/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78756e2d78682f796f6c6f76352d6f6e6e782d707971742d6578653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/552bc5c60fd9c33b9ecf36ab73c350c5f1392f4bdd41bac047019adfb5b5ac91/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f78756e2d78682f796f6c6f76352d6f6e6e782d707971742d6578653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/xun-xh/yolov5-onnx-pyqt-exe?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于Yolov5 + PyQt5 + onnxruntime的目标检测部署。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LPC1616/pyqt-yolox-modbus\"\u003eLPC1616/pyqt-yolox-modbus\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d4f39f337c8d15f98fbf31a3ad075985896e3f3e42c1e34a13ffaf7cd245f85e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5043313631362f707971742d796f6c6f782d6d6f646275733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d4f39f337c8d15f98fbf31a3ad075985896e3f3e42c1e34a13ffaf7cd245f85e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5043313631362f707971742d796f6c6f782d6d6f646275733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LPC1616/pyqt-yolox-modbus?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : qt界面+yolox识别算法+modbus通信。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zawawiAI/yolo_gpt\"\u003ezawawiAI/yolo_gpt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/785e5615ec6b71780e684c109c5a9966cc4ff4b67a3d9b826c663837bb14b89e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a617761776941492f796f6c6f5f6770743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/785e5615ec6b71780e684c109c5a9966cc4ff4b67a3d9b826c663837bb14b89e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a617761776941492f796f6c6f5f6770743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zawawiAI/yolo_gpt?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is a GUI application that integrates YOLOv8 object recognition with OpenAI's GPT-3 language generation model.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LSH9832/yolov5_training_tool\"\u003eLSH9832/yolov5_training_tool\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/123a004edf8e8900de9b462da4caa92b9e6c4b7dbfe6d36d183f610fc5e13d09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5348393833322f796f6c6f76355f747261696e696e675f746f6f6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/123a004edf8e8900de9b462da4caa92b9e6c4b7dbfe6d36d183f610fc5e13d09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5348393833322f796f6c6f76355f747261696e696e675f746f6f6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LSH9832/yolov5_training_tool?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 本工具使用PYQT5编写界面。通过使用该工具可以快速部署相应数据集并训练，目前仍在不断更新中，较大的缺点是目前只支持PascalVOC格式的xml标签文件，所以其它格式的标签文件需要先转换为PascalVOC的格式，且目前仅适用于Linux系统且仅在Ubuntu16.04-20.04试运行。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Egrt/YOLO_PyQt5\"\u003eEgrt/YOLO_PyQt5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/08ef6e58b284c7a3616bf928c96cb13bf3d17e26e4b53122b827e655b9a0728b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f456772742f594f4c4f5f50795174353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/08ef6e58b284c7a3616bf928c96cb13bf3d17e26e4b53122b827e655b9a0728b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f456772742f594f4c4f5f50795174353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Egrt/YOLO_PyQt5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 使用Pyqt5搭建YOLO系列多线程目标检测系统。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/smartwj/yolov5_pyqt5\"\u003esmartwj/yolov5_pyqt5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9111128202282a000fac12ffa73b55640f278bacf957ccc1c8ca6a08c09fad8f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736d617274776a2f796f6c6f76355f70797174353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9111128202282a000fac12ffa73b55640f278bacf957ccc1c8ca6a08c09fad8f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f736d617274776a2f796f6c6f76355f70797174353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/smartwj/yolov5_pyqt5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于yolov5的pyqt5目标检测图形上位机工具。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LitChi-bit/YOLOv5-6.0-GUI\"\u003eLitChi-bit/YOLOv5-6.0-GUI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/72c7cd57866dc63ca1f2172c29096ab5752e03554d06ddea75882f8bd147cabf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c69744368692d6269742f594f4c4f76352d362e302d4755493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/72c7cd57866dc63ca1f2172c29096ab5752e03554d06ddea75882f8bd147cabf/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c69744368692d6269742f594f4c4f76352d362e302d4755493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LitChi-bit/YOLOv5-6.0-GUI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Qt-GUI implementation of the YOLOv5 algorithm (ver.6).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/BraunGe/YOLOv5-GUI\"\u003eBraunGe/YOLOv5-GUI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2fbf973c6367b0291388fed409b60c2ec0a9637fd7330e62211430e60df26aab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427261756e47652f594f4c4f76352d4755493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2fbf973c6367b0291388fed409b60c2ec0a9637fd7330e62211430e60df26aab/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f427261756e47652f594f4c4f76352d4755493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/BraunGe/YOLOv5-GUI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A GUI for YOLOv5, support all the 11 inference formats that YOLOv5 supports.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PetervanLunteren/EcoAssist\"\u003ePetervanLunteren/EcoAssist\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f6e2f88deea7c02dde4dbac83fd123be491d1842567d7a6df50a07be9b9c01dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506574657276616e4c756e746572656e2f45636f4173736973743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f6e2f88deea7c02dde4dbac83fd123be491d1842567d7a6df50a07be9b9c01dc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f506574657276616e4c756e746572656e2f45636f4173736973743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PetervanLunteren/EcoAssist?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A no-code platform to train and deploy YOLOv5 object detection models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SwimmingLiu/yolov7-Pyside6\"\u003eSwimmingLiu/yolov7-Pyside6\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1dcfae108facc90f77d442aa7a8667aa617ae8634167dcaf7ca78a9e492cd21f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5377696d6d696e674c69752f796f6c6f76372d507973696465363f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1dcfae108facc90f77d442aa7a8667aa617ae8634167dcaf7ca78a9e492cd21f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5377696d6d696e674c69752f796f6c6f76372d507973696465363f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SwimmingLiu/yolov7-Pyside6?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : PySide6 implementation of YOLOv7 GUI.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003ePySide-Related\u003c/h4\u003e\u003ca id=\"user-content-pyside-related\" class=\"anchor\" aria-label=\"Permalink: PySide-Related\" href=\"#pyside-related\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SwimmingLiu/YOLOSHOW\"\u003eJSwimmingLiu/YOLOSHOW\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7ad503e07c06579484af1c7bcdf461059d2c47b44f8815f81f489a95867c5e37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5377696d6d696e674c69752f594f4c4f53484f573f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7ad503e07c06579484af1c7bcdf461059d2c47b44f8815f81f489a95867c5e37/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5377696d6d696e674c69752f594f4c4f53484f573f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SwimmingLiu/YOLOSHOW?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLO SHOW - YOLOv10 / YOLOv9 / YOLOv8 / YOLOv7 / YOLOv5 / RTDETR GUI based on Pyside6.\u003ca href=\"https://swimmingliu.cn/posts/diary/yoloshow\" rel=\"nofollow\"\u003eswimmingliu.cn/posts/diary/yoloshow\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Jai-wei/YOLOv8-PySide6-GUI\"\u003eJai-wei/YOLOv8-PySide6-GUI\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a8acc19dc6e5898555fc945e84f002fae86a5022cec9360ca59b253579d8ed43/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61692d7765692f594f4c4f76382d507953696465362d4755493f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a8acc19dc6e5898555fc945e84f002fae86a5022cec9360ca59b253579d8ed43/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a61692d7765692f594f4c4f76382d507953696465362d4755493f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Jai-wei/YOLOv8-PySide6-GUI?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloSide - YOLOv8 GUI By PySide6.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOther Applications\u003c/h3\u003e\u003ca id=\"user-content-other-applications\" class=\"anchor\" aria-label=\"Permalink: Other Applications\" href=\"#other-applications\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e其它应用\u003c/h4\u003e\u003ca id=\"user-content-其它应用\" class=\"anchor\" aria-label=\"Permalink: 其它应用\" href=\"#其它应用\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ikomia-dev/IkomiaApi\"\u003eIkomia-dev/IkomiaApi\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3977064d5ec1c7cdcec9c1ca1fd2557e614e209ee8cfe06eb817189fce43f3d2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f496b6f6d69612d6465762f496b6f6d69614170693f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3977064d5ec1c7cdcec9c1ca1fd2557e614e209ee8cfe06eb817189fce43f3d2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f496b6f6d69612d6465762f496b6f6d69614170693f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ikomia-dev/IkomiaApi?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : State-of-the-art algorithms in Computer Vision with a few lines of code.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/penny4860/Yolo-digit-detector\"\u003epenny4860/Yolo-digit-detector\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/21dcacbdc0238fa1e64ffd10e75e170ccbbf43e72e2cb0ac609952c3ad8d86a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70656e6e79343836302f596f6c6f2d64696769742d6465746563746f723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/21dcacbdc0238fa1e64ffd10e75e170ccbbf43e72e2cb0ac609952c3ad8d86a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70656e6e79343836302f596f6c6f2d64696769742d6465746563746f723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/penny4860/Yolo-digit-detector?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Implemented digit detector in natural scene using resnet50 and Yolo-v2. I used SVHN as the training set, and implemented it using tensorflow and keras.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/chineseocr/table-detect\"\u003echineseocr/table-detect\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/492e6efe4313020e7c6f7de8ec2020ee49e29d3fb561d69084e503cc70a4b236/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368696e6573656f63722f7461626c652d6465746563743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/492e6efe4313020e7c6f7de8ec2020ee49e29d3fb561d69084e503cc70a4b236/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368696e6573656f63722f7461626c652d6465746563743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/chineseocr/table-detect?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : table detect(yolo) , table line(unet) （表格检测/表格单元格定位）。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/thisiszhou/SexyYolo\"\u003ethisiszhou/SexyYolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/32fc9ab6d1f6ed5c777d7515de9e1290e442d3bdeae4a79ce9d3d2c759df4d4c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7468697369737a686f752f53657879596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/32fc9ab6d1f6ed5c777d7515de9e1290e442d3bdeae4a79ce9d3d2c759df4d4c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7468697369737a686f752f53657879596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/thisiszhou/SexyYolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : An implementation of Yolov3 with Tensorflow1.x, which could detect COCO and sexy or porn person simultaneously.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/javirk/Person_remover\"\u003ejavirk/Person_remover\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3a850b9f0aeaa290bde5e589683c4eb6b6120826b60ca2531158c318da920919/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a617669726b2f506572736f6e5f72656d6f7665723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3a850b9f0aeaa290bde5e589683c4eb6b6120826b60ca2531158c318da920919/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a617669726b2f506572736f6e5f72656d6f7665723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/javirk/Person_remover?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : People removal in images using Pix2Pix and YOLO.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/foschmitz/yolo-python-rtsp\"\u003efoschmitz/yolo-python-rtsp\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0663190a12e67d47782aecb085cb6dc95d7044eb0eac43076128dd8af4244272/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666f7363686d69747a2f796f6c6f2d707974686f6e2d727473703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0663190a12e67d47782aecb085cb6dc95d7044eb0eac43076128dd8af4244272/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666f7363686d69747a2f796f6c6f2d707974686f6e2d727473703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/foschmitz/yolo-python-rtsp?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Object detection using deep learning with Yolo, OpenCV and Python via Real Time Streaming Protocol (RTSP).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ismail-mebsout/Parsing-PDFs-using-YOLOV3\"\u003eismail-mebsout/Parsing-PDFs-using-YOLOV3\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/88872e2f9e6d3c37707e958c27a9a8437745a1167e6ea4e5d7c1ddae834fe460/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736d61696c2d6d6562736f75742f50617273696e672d504446732d7573696e672d594f4c4f56333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/88872e2f9e6d3c37707e958c27a9a8437745a1167e6ea4e5d7c1ddae834fe460/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69736d61696c2d6d6562736f75742f50617273696e672d504446732d7573696e672d594f4c4f56333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ismail-mebsout/Parsing-PDFs-using-YOLOV3?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Parsing pdf tables using YOLOV3.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/008karan/PAN_OCR\"\u003e008karan/PAN_OCR\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b69709590848f6464cd2d4a994c778b17a9c95c9d3e0e6e23c16fea2553285d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3030386b6172616e2f50414e5f4f43523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b69709590848f6464cd2d4a994c778b17a9c95c9d3e0e6e23c16fea2553285d9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3030386b6172616e2f50414e5f4f43523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/008karan/PAN_OCR?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Building OCR using YOLO and Tesseract.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zeyad-mansour/lunar\"\u003ezeyad-mansour/lunar\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f655eee1b16fc4a5eb3e12e263e4b8d42bec03833a6fc25620526a37f8918045/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a657961642d6d616e736f75722f6c756e61723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f655eee1b16fc4a5eb3e12e263e4b8d42bec03833a6fc25620526a37f8918045/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a657961642d6d616e736f75722f6c756e61723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zeyad-mansour/lunar?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Lunar is a neural network aimbot that uses real-time object detection accelerated with CUDA on Nvidia GPUs.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/lannguyen0910/food-recognition\"\u003elannguyen0910/food-recognition\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/beafe827f9701bfc29b0d17f492f07b4bd46b94504eb3dcb95e8cf89d126f098/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c616e6e677579656e303931302f666f6f642d7265636f676e6974696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/beafe827f9701bfc29b0d17f492f07b4bd46b94504eb3dcb95e8cf89d126f098/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c616e6e677579656e303931302f666f6f642d7265636f676e6974696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lannguyen0910/food-recognition?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e :  🍔🍟🍗 Food analysis baseline with Theseus. Integrate object detection, image classification and multi-class semantic segmentation. 🍞🍖🍕\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/killnice/yolov5-D435i\"\u003ekillnice/yolov5-D435i\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/22b822b9607750f0cd77fdea3499d6e765f30b6604f4cb64c875dceb8bf6929c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b696c6c6e6963652f796f6c6f76352d44343335693f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/22b822b9607750f0cd77fdea3499d6e765f30b6604f4cb64c875dceb8bf6929c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6b696c6c6e6963652f796f6c6f76352d44343335693f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/killnice/yolov5-D435i?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : using yolov5 and realsense D435i.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SahilChachra/Video-Analytics-Dashboard\"\u003eSahilChachra/Video-Analytics-Dashboard\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8b883299cdd06c3bd5eb1ad5861977886aea8f34b92b495439d617f08643107c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536168696c436861636872612f566964656f2d416e616c79746963732d44617368626f6172643f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8b883299cdd06c3bd5eb1ad5861977886aea8f34b92b495439d617f08643107c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536168696c436861636872612f566964656f2d416e616c79746963732d44617368626f6172643f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SahilChachra/Video-Analytics-Dashboard?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Video Analytics dashboard built using YoloV5 and Streamlit.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/isLinXu/YOLOv5_Efficient\"\u003eisLinXu/YOLOv5_Efficient\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4cc0199a0a74adfffe83a6153cf1370b1ebbbfa9efc4585e0581fa7e3977d209/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69734c696e58752f594f4c4f76355f456666696369656e743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4cc0199a0a74adfffe83a6153cf1370b1ebbbfa9efc4585e0581fa7e3977d209/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f69734c696e58752f594f4c4f76355f456666696369656e743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/isLinXu/YOLOv5_Efficient?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Use yolov5 efficiently(高效地使用Yolo v5).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HRan2004/Yolo-ArbV2\"\u003eHRan2004/Yolo-ArbV2\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8fc233af084ad50f74a219846a538770a36860e7a4258020a4583d7da144d90f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4852616e323030342f596f6c6f2d41726256323f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8fc233af084ad50f74a219846a538770a36860e7a4258020a4583d7da144d90f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4852616e323030342f596f6c6f2d41726256323f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HRan2004/Yolo-ArbV2?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Yolo-ArbV2 在完全保持YOLOv5功能情况下，实现可选多边形信息输出。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Badw0lf613/wmreading_system\"\u003eBadw0lf613/wmreading_system\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a7b0f94f57ae4e0f9f6779173e3acaaf308815d918269aee99d12a24c18c3392/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42616477306c663631332f776d72656164696e675f73797374656d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a7b0f94f57ae4e0f9f6779173e3acaaf308815d918269aee99d12a24c18c3392/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42616477306c663631332f776d72656164696e675f73797374656d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Badw0lf613/wmreading_system?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于YOLOv5的水表读数系统。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/zgcr/SimpleAICV-pytorch-ImageNet-COCO-training\"\u003ezgcr/SimpleAICV-pytorch-ImageNet-COCO-training\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/369e51ba8ced65d1e9023ec6c58c84575615b12d83ac9f1b3501fad0dbd76141/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6763722f53696d706c65414943562d7079746f7263682d496d6167654e65742d434f434f2d747261696e696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/369e51ba8ced65d1e9023ec6c58c84575615b12d83ac9f1b3501fad0dbd76141/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7a6763722f53696d706c65414943562d7079746f7263682d496d6167654e65742d434f434f2d747261696e696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/zgcr/SimpleAICV-pytorch-ImageNet-COCO-training?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : SimpleAICV:pytorch training example on ImageNet(ILSVRC2012)/COCO2017/VOC2007+2012 datasets.Include ResNet/DarkNet/RetinaNet/FCOS/CenterNet/TTFNet/YOLOv3/YOLOv4/YOLOv5/YOLOX.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ErenKaymakci/Real-Time-QR-Detection-and-Decoding\"\u003eErenKaymakci/Real-Time-QR-Detection-and-Decoding\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/96463682c4ff205ceedd63e748164a30ff4673dfda502d9e946f8539d072a5a7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4572656e4b61796d616b63692f5265616c2d54696d652d51522d446574656374696f6e2d616e642d4465636f64696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/96463682c4ff205ceedd63e748164a30ff4673dfda502d9e946f8539d072a5a7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4572656e4b61796d616b63692f5265616c2d54696d652d51522d446574656374696f6e2d616e642d4465636f64696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ErenKaymakci/Real-Time-QR-Detection-and-Decoding?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This repo explain how qr codes works, qr detection and decoding.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LUMAIS/AntDet_YOLOv5\"\u003eLUMAIS/AntDet_YOLOv5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/54be26680f5ce50506844af6fd2cde77a8110245c8b3ec0b8de818437afcad18/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c554d4149532f416e744465745f594f4c4f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/54be26680f5ce50506844af6fd2cde77a8110245c8b3ec0b8de818437afcad18/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c554d4149532f416e744465745f594f4c4f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LUMAIS/AntDet_YOLOv5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Ants and their Activiteis (Trophallaxis) Detection using YOLOv5 based on PyTorch.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Jiseong-Ok/OCR-Yolov5-SwinIR-SVTR\"\u003eJiseong-Ok/OCR-Yolov5-SwinIR-SVTR\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0140f06f5f6872a5cc7e472180f511244e74ed079f328c0713609815905bef9a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a6973656f6e672d4f6b2f4f43522d596f6c6f76352d5377696e49522d535654523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0140f06f5f6872a5cc7e472180f511244e74ed079f328c0713609815905bef9a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a6973656f6e672d4f6b2f4f43522d596f6c6f76352d5377696e49522d535654523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Jiseong-Ok/OCR-Yolov5-SwinIR-SVTR?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : OCR(Korean).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/QIN2DIM/hcaptcha-challenger\"\u003eQIN2DIM/hcaptcha-challenger\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a0905caa7b20a49c88a3d038d5e0138731e1178405b5ec3e9a590f5617576030/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51494e3244494d2f68636170746368612d6368616c6c656e6765723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a0905caa7b20a49c88a3d038d5e0138731e1178405b5ec3e9a590f5617576030/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f51494e3244494d2f68636170746368612d6368616c6c656e6765723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/QIN2DIM/hcaptcha-challenger?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🥂 Gracefully face hCaptcha challenge with YOLOv6(ONNX) embedded solution.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bobjiangps/vision\"\u003ebobjiangps/vision\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/88206df5589801808faab699feb9d38664133f9480e7319d588c4833b3d12944/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f626f626a69616e6770732f766973696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/88206df5589801808faab699feb9d38664133f9480e7319d588c4833b3d12944/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f626f626a69616e6770732f766973696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bobjiangps/vision?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : UI auto test framework based on YOLO to recognize elements, less code, less maintenance, cross platform, cross project / 基于YOLO的UI层自动化测试框架, 可识别控件类型，减少代码和维护，一定程度上跨平台跨项目。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RizwanMunawar/yolov7-object-cropping\"\u003eRizwanMunawar/yolov7-object-cropping\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bc5f3cb09285882da2f317d66366a4bd116ff7f1e5be422d9ae1fef03bcc234b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d6f626a6563742d63726f7070696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bc5f3cb09285882da2f317d66366a4bd116ff7f1e5be422d9ae1fef03bcc234b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d6f626a6563742d63726f7070696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RizwanMunawar/yolov7-object-cropping?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv7 Object Cropping Using OpenCV.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RizwanMunawar/yolov7-object-blurring\"\u003eRizwanMunawar/yolov7-object-blurring\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ebeaa80277a1679db9722995253a750c1cc5c6010ed64c8c8bfeb62564ce9086/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d6f626a6563742d626c757272696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ebeaa80277a1679db9722995253a750c1cc5c6010ed64c8c8bfeb62564ce9086/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f52697a77616e4d756e617761722f796f6c6f76372d6f626a6563742d626c757272696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RizwanMunawar/yolov7-object-blurring?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv7 Object Blurring Using PyTorch and OpenCV.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pacocp/YOLOF\"\u003epacocp/YOLOF\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/295db73f942f9d64c5075e2fdca48d5c981e034890134d7440ccd8e58fc23f23/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7061636f63702f594f4c4f463f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/295db73f942f9d64c5075e2fdca48d5c981e034890134d7440ccd8e58fc23f23/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7061636f63702f594f4c4f463f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pacocp/YOLOF?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 📹 YOLO meets Optical Flow.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/FabianPlum/OmniTrax\"\u003eFabianPlum/OmniTrax\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/4aaef20b0bb1e1bf2bdcb4feebdb8b5d5e984593dea4b787e403828cacb3e923/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46616269616e506c756d2f4f6d6e69547261783f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4aaef20b0bb1e1bf2bdcb4feebdb8b5d5e984593dea4b787e403828cacb3e923/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f46616269616e506c756d2f4f6d6e69547261783f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/FabianPlum/OmniTrax?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Deep learning-based multi animal tracking and pose estimation Blender Add-on.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/aweihao/ExDark2Yolo\"\u003eaweihao/ExDark2Yolo\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/aa0b5898087c7ba2b23c25fa7e38fef08cc331d57b482f6026c843d042601021/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6177656968616f2f45784461726b32596f6c6f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/aa0b5898087c7ba2b23c25fa7e38fef08cc331d57b482f6026c843d042601021/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6177656968616f2f45784461726b32596f6c6f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/aweihao/ExDark2Yolo?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Convert ExDark annotated format data to YOLO format data. / 将ExDark标注格式的数据转换成YOLO格式的数据。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ozankaraali/yolov3-recaptcha\"\u003eozankaraali/yolov3-recaptcha\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fbd417fde95efafaa891d2f35c4027fc67591f75e966c648cc79a0e5af1b148e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f7a616e6b617261616c692f796f6c6f76332d7265636170746368613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fbd417fde95efafaa891d2f35c4027fc67591f75e966c648cc79a0e5af1b148e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f7a616e6b617261616c692f796f6c6f76332d7265636170746368613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ozankaraali/yolov3-recaptcha?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Solve Recaptcha with YoloV3. A proof of concept Recaptcha solver using YOLOv3 on Tensorflow 2.0 and Selenium. This tutorial shows that with a better trained object detection weight file, ReCaptcha can be easily solved.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jyp-studio/Invoice_detection\"\u003ejyp-studio/Invoice_detection\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/3266c2476a037318c90be851dca309cbf63d504013c2d23e7eede35f0cf36c91/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a79702d73747564696f2f496e766f6963655f646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3266c2476a037318c90be851dca309cbf63d504013c2d23e7eede35f0cf36c91/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a79702d73747564696f2f496e766f6963655f646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jyp-studio/Invoice_detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : This is an AI model for detecting and recognizing invoice information by yolov5 and OCR.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/vmc-7645/YOLOv8-retail\"\u003evmc-7645/YOLOv8-retail\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fab82755f5aebf480f1eea55202fb3415b7f1a15cb4a3830c02decd11ae19789/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f766d632d373634352f594f4c4f76382d72657461696c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fab82755f5aebf480f1eea55202fb3415b7f1a15cb4a3830c02decd11ae19789/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f766d632d373634352f594f4c4f76382d72657461696c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/vmc-7645/YOLOv8-retail?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Detect retail products via the YOLOv8 object recognition engine.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TAber-W/RM_4-points_yolov5\"\u003eTAber-W/RM_4-points_yolov5\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b3dcaf7c4e17a3dcd897fea7bb6d5a783d698c2a5553f751e7fbc11c7ca0152d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54416265722d572f524d5f342d706f696e74735f796f6c6f76353f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b3dcaf7c4e17a3dcd897fea7bb6d5a783d698c2a5553f751e7fbc11c7ca0152d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f54416265722d572f524d5f342d706f696e74735f796f6c6f76353f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TAber-W/RM_4-points_yolov5?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Robomaster 基于yoloface和MobileNet修改的四点模型.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/eternal-echo/picking\"\u003eeternal-echo/picking\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f3e7201027a78724510a3aeaf1f0d3eb9379f09cd21fd69ab3f1b41376049960/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657465726e616c2d6563686f2f7069636b696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f3e7201027a78724510a3aeaf1f0d3eb9379f09cd21fd69ab3f1b41376049960/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657465726e616c2d6563686f2f7069636b696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/eternal-echo/picking?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于YOLO v5视觉分拣零件系统设计。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/swordswind/yolo_ocr_api_server\"\u003eswordswind/yolo_ocr_api_server\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e0a1e2b96ad5a363dd84c0875d2360e599df34bc4580d5033b8943ecf53931d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73776f72647377696e642f796f6c6f5f6f63725f6170695f7365727665723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e0a1e2b96ad5a363dd84c0875d2360e599df34bc4580d5033b8943ecf53931d6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73776f72647377696e642f796f6c6f5f6f63725f6170695f7365727665723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/swordswind/yolo_ocr_api_server?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv10\u0026amp;EasyOCR融合图像识别API服务器。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eObject Detection Datasets\u003c/h2\u003e\u003ca id=\"user-content-object-detection-datasets\" class=\"anchor\" aria-label=\"Permalink: Object Detection Datasets\" href=\"#object-detection-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eDatasets Share Platform\u003c/h3\u003e\u003ca id=\"user-content-datasets-share-platform\" class=\"anchor\" aria-label=\"Permalink: Datasets Share Platform\" href=\"#datasets-share-platform\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://opendatalab.org.cn/\" rel=\"nofollow\"\u003eOpenDataLab\u003c/a\u003e : OpenDataLab 是上海人工智能实验室的大模型数据基座团队打造的数据开放平台，现已成为中国大模型语料数据联盟开源数据服务指定平台，为开发者提供全链条的 AI 数据支持，应对和解决数据处理中的风险与挑战，推动 AI 研究及应用。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.scidb.cn/en\" rel=\"nofollow\"\u003eScience Data Bank(ScienceDB)\u003c/a\u003e : Make your research data citable, discoverable and persistently accessible Satisfy flexible data sharing requirements Dedicate to facilitating data dissemination and reusing. Science Data Bank (ScienceDB) is a public, general-purpose data repository aiming to provide data services (e.g. data acquisition, long-term preservation, publishing, sharing and access) for researchers, research projects/teams, journals, institutions, universities, etc. It supports a variety of data acquisition and data licenses. ScienceDB is dedicated to promoting data findable, citable and reusable on the prerequisite of protecting the rights and interests of data owners and it is built and operated by Computer Network Information Center, Chinese Academy of Sciences.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://www.csdata.org/\" rel=\"nofollow\"\u003e中国科学数据\u003c/a\u003e : 《中国科学数据（中英文网络版）》（China Scientific Data）（CN11-6035/N，ISSN 2096-2223）是目前中国唯一的专门面向多学科领域科学数据出版的学术期刊，作为国家网络连续型出版物的首批试点之一，由中国科学院主管，中国科学院计算机网络信息中心和ISC CODATA中国全国委员会合办，国家科技基础条件平台中心、中国科学院网络安全和信息化领导小组办公室指导，国内外公开发行，中英文，季刊。 中国科学引文数据库（CSCD）来源期刊，中国科技核心期刊 ，收录于中国科协高质量科技期刊分级目录。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://aistudio.baidu.com/aistudio/datasetoverview\" rel=\"nofollow\"\u003e飞桨AI Studio\u003c/a\u003e : 飞桨AI Studio开放数据集。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.cvmart.net/dataSets\" rel=\"nofollow\"\u003e极市开发者平台\u003c/a\u003e : 极市开发者平台开放数据集。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/openvinotoolkit/datumaro\"\u003eopenvinotoolkit/datumaro\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/926b639d50ef6eb0eb8a038750a38508ced921aecbf66cb880fd137494fed1f3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e76696e6f746f6f6c6b69742f646174756d61726f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/926b639d50ef6eb0eb8a038750a38508ced921aecbf66cb880fd137494fed1f3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e76696e6f746f6f6c6b69742f646174756d61726f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/openvinotoolkit/datumaro?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Dataset Management Framework, a Python library and a CLI tool to build, analyze and manage Computer Vision datasets.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eDatasets Tools\u003c/h3\u003e\u003ca id=\"user-content-datasets-tools\" class=\"anchor\" aria-label=\"Permalink: Datasets Tools\" href=\"#datasets-tools\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eData Annotation\u003c/h4\u003e\u003ca id=\"user-content-data-annotation\" class=\"anchor\" aria-label=\"Permalink: Data Annotation\" href=\"#data-annotation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HumanSignal/label-studio\"\u003eLabel Studio\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/67036dea2546fceffdfc29d776ff2b3735d525e4527ad8ddd6a59b4822cb3ad5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48756d616e5369676e616c2f6c6162656c2d73747564696f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/67036dea2546fceffdfc29d776ff2b3735d525e4527ad8ddd6a59b4822cb3ad5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f48756d616e5369676e616c2f6c6162656c2d73747564696f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HumanSignal/label-studio?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Label Studio is a multi-type data labeling and annotation tool with standardized output format. \u003ca href=\"https://labelstud.io/\" rel=\"nofollow\"\u003elabelstud.io\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CVHub520/X-AnyLabeling\"\u003eX-AnyLabeling\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/822ce53353585f82ef9fb52ff2b5e2439c18912227c1fe5550a73acaf89ea2e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43564875623532302f582d416e794c6162656c696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/822ce53353585f82ef9fb52ff2b5e2439c18912227c1fe5550a73acaf89ea2e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f43564875623532302f582d416e794c6162656c696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CVHub520/X-AnyLabeling?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Effortless data labeling with AI support from Segment Anything and other awesome models.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/vietanhdev/anylabeling\"\u003eAnyLabeling\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fabfde4bb4cc495066df3245b2d5ff1d8e1b95d8f377ab207fcb45588a33f6cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76696574616e686465762f616e796c6162656c696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fabfde4bb4cc495066df3245b2d5ff1d8e1b95d8f377ab207fcb45588a33f6cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f76696574616e686465762f616e796c6162656c696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/vietanhdev/anylabeling?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Effortless AI-assisted data labeling with AI support from YOLO, Segment Anything (SAM+SAM2), MobileSAM!! AnyLabeling = LabelImg + Labelme + Improved UI + Auto-labeling. \u003ca href=\"https://anylabeling.nrl.ai/\" rel=\"nofollow\"\u003eanylabeling.nrl.ai\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LSH9832/SAMLabelerPro\"\u003eSAMLabelerPro\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/701c21a16fe00fe13490f7ce369459877a819278e5e89089159f977e8f2d009f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5348393833322f53414d4c6162656c657250726f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/701c21a16fe00fe13490f7ce369459877a819278e5e89089159f977e8f2d009f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c5348393833322f53414d4c6162656c657250726f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LSH9832/SAMLabelerPro?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : label your image with Segment Anything Model or MobileSAM, support remote labeling for multiple persons。使用Segment Anything Model或MobileSAM辅助标注的工具，支持多人远程标注。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/heartexlabs/labelImg\"\u003eLabelImg\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/dadc4a6251bef7ddf268b9606b0cccc7a958971ebd9b5f518e5abed8839f42a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686561727465786c6162732f6c6162656c496d673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dadc4a6251bef7ddf268b9606b0cccc7a958971ebd9b5f518e5abed8839f42a9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686561727465786c6162732f6c6162656c496d673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/heartexlabs/labelImg?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🖍️ LabelImg is a graphical image annotation tool and label object bounding boxes in images.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wkentaro/labelme\"\u003elabelme\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5a182962d92bb16f13a72a6a57003ce19d8d3ec41bcb3e1fea71b9639c9e356f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776b656e7461726f2f6c6162656c6d653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5a182962d92bb16f13a72a6a57003ce19d8d3ec41bcb3e1fea71b9639c9e356f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776b656e7461726f2f6c6162656c6d653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wkentaro/labelme?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Image Polygonal Annotation with Python (polygon, rectangle, circle, line, point and image-level flag annotation).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/darkpgmr/DarkLabel\"\u003eDarkLabel\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/dc1ee184b84c0eddc37bd121b96efe7778dd45f40eb033cc3985d5e8155ea94e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6461726b70676d722f4461726b4c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dc1ee184b84c0eddc37bd121b96efe7778dd45f40eb033cc3985d5e8155ea94e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6461726b70676d722f4461726b4c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/darkpgmr/DarkLabel?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Video/Image Labeling and Annotation Tool.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlexeyAB/Yolo_mark\"\u003eAlexeyAB/Yolo_mark\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5f0d86929b24cadd73bfb672723a507e94cbf9d176b515bfce3b1e918bbbc2e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f596f6c6f5f6d61726b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5f0d86929b24cadd73bfb672723a507e94cbf9d176b515bfce3b1e918bbbc2e2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c6578657941422f596f6c6f5f6d61726b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlexeyAB/Yolo_mark?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : GUI for marking bounded boxes of objects in images for training neural network Yolo v3 and v2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Cartucho/OpenLabeling\"\u003eCartucho/OpenLabeling\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/85366566b5f23bcd02b387b80aecfac3e4baa0e1b2735a04b3e551d0486723fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436172747563686f2f4f70656e4c6162656c696e673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/85366566b5f23bcd02b387b80aecfac3e4baa0e1b2735a04b3e551d0486723fa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f436172747563686f2f4f70656e4c6162656c696e673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Cartucho/OpenLabeling?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Label images and video for Computer Vision applications.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cvat-ai/cvat\"\u003eCVAT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fe9a07e7636fde23bdec44e090a5f2f0bbacd2036375694b3be07da38108da77/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f637661742d61692f637661743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fe9a07e7636fde23bdec44e090a5f2f0bbacd2036375694b3be07da38108da77/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f637661742d61692f637661743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cvat-ai/cvat?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Computer Vision Annotation Tool (CVAT). Annotate better with CVAT, the industry-leading data engine for machine learning. Used and trusted by teams at any scale, for data of any scale.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Microsoft/VoTT\"\u003eVoTT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/695897a0062f5aae617295086997957761e99e9042ca2dacaa1259fd6f50b25c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6963726f736f66742f566f54543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/695897a0062f5aae617295086997957761e99e9042ca2dacaa1259fd6f50b25c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d6963726f736f66742f566f54543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Microsoft/VoTT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Visual Object Tagging Tool: An electron app for building end to end Object Detection Models from Images and Videos.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WangRongsheng/KDAT\"\u003eWangRongsheng/KDAT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2d66a5d1fa71d78e1b2336df8582396d6bbd610e6ddc39b4d64248c15801274c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57616e67526f6e677368656e672f4b4441543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2d66a5d1fa71d78e1b2336df8582396d6bbd610e6ddc39b4d64248c15801274c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57616e67526f6e677368656e672f4b4441543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WangRongsheng/KDAT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 一个专为视觉方向目标检测全流程的标注工具集，全称：Kill Object Detection Annotation Tools。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ryouchinsa/Rectlabel-support\"\u003eRectlabel-support\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/81e95ba68beb08b64d183eae8ae23f01dc8ffadb41279118e21cb3e778c5946e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72796f756368696e73612f526563746c6162656c2d737570706f72743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/81e95ba68beb08b64d183eae8ae23f01dc8ffadb41279118e21cb3e778c5946e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72796f756368696e73612f526563746c6162656c2d737570706f72743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ryouchinsa/Rectlabel-support?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : RectLabel - An image annotation tool to label images for bounding box object detection and segmentation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cnyvfang/labelGo-Yolov5AutoLabelImg\"\u003ecnyvfang/labelGo-Yolov5AutoLabelImg\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/68e9f1abd14edfe12bc90dabcc941509334ee989db4aa9dc1c338bd3c2744931/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636e797666616e672f6c6162656c476f2d596f6c6f76354175746f4c6162656c496d673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/68e9f1abd14edfe12bc90dabcc941509334ee989db4aa9dc1c338bd3c2744931/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636e797666616e672f6c6162656c476f2d596f6c6f76354175746f4c6162656c496d673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cnyvfang/labelGo-Yolov5AutoLabelImg?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 💕YOLOV5 semi-automatic annotation tool (Based on labelImg)💕一个基于labelImg及YOLOV5的图形化半自动标注工具。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CVUsers/Auto_maker\"\u003eCVUsers/Auto_maker\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/31c56c1966068b2cc0840abbd696cb7a7a89afb2ce0c6f4f58e2815531641022/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f435655736572732f4175746f5f6d616b65723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/31c56c1966068b2cc0840abbd696cb7a7a89afb2ce0c6f4f58e2815531641022/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f435655736572732f4175746f5f6d616b65723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CVUsers/Auto_maker?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 深度学习数据自动标注器开源 目标检测和图像分类（高精度高效率）。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/OvidijusParsiunas/myvision\"\u003eMyVision\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/76e9fb38381abef02bffcb05cfd095d4ebed24804cb339470cdb83c69c6cc889/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f766964696a75735061727369756e61732f6d79766973696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/76e9fb38381abef02bffcb05cfd095d4ebed24804cb339470cdb83c69c6cc889/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4f766964696a75735061727369756e61732f6d79766973696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/OvidijusParsiunas/myvision?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Computer vision based ML training data generation tool 🚀\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wufan-tb/AutoLabelImg\"\u003ewufan-tb/AutoLabelImg\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/64e224ef08aabd2c4751c8501d17ff7a88a4d5f4bffe825f2911e71708fc4202/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f777566616e2d74622f4175746f4c6162656c496d673f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/64e224ef08aabd2c4751c8501d17ff7a88a4d5f4bffe825f2911e71708fc4202/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f777566616e2d74622f4175746f4c6162656c496d673f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wufan-tb/AutoLabelImg?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : auto-labelimg based on yolov5, with many other useful tools. AutoLabelImg 多功能自动标注工具。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MrZander/YoloMarkNet\"\u003eMrZander/YoloMarkNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/07165a8ff9ed22800e62d4daee320cd0cdc47eb042819a83874dbcd99a0ee65f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d725a616e6465722f596f6c6f4d61726b4e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/07165a8ff9ed22800e62d4daee320cd0cdc47eb042819a83874dbcd99a0ee65f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d725a616e6465722f596f6c6f4d61726b4e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MrZander/YoloMarkNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Darknet YOLOv2/3 annotation tool written in C#/WPF.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mahxn0/Yolov3_ForTextLabel\"\u003emahxn0/Yolov3_ForTextLabel\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/50610f6ad79c28ba605e629e99e947f38b8bd2d7a7e3916b66f71e19a4eb0f1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6168786e302f596f6c6f76335f466f72546578744c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/50610f6ad79c28ba605e629e99e947f38b8bd2d7a7e3916b66f71e19a4eb0f1d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6168786e302f596f6c6f76335f466f72546578744c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mahxn0/Yolov3_ForTextLabel?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 基于yolov3的目标/自然场景文字自动标注工具。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MNConnor/YoloV5-AI-Label\"\u003eMNConnor/YoloV5-AI-Label\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/bae30cda23e2451058ec7422d8233aab8a4ef55d7e8c108bd329e7511fbdb7aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d4e436f6e6e6f722f596f6c6f56352d41492d4c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/bae30cda23e2451058ec7422d8233aab8a4ef55d7e8c108bd329e7511fbdb7aa/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d4e436f6e6e6f722f596f6c6f56352d41492d4c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MNConnor/YoloV5-AI-Label?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YoloV5 AI Assisted Labeling.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LILINOpenGitHub/Labeling-Tool\"\u003eLILINOpenGitHub/Labeling-Tool\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0dda3d9021bae83c1599227cba107851e7fca8ed66964b0409228ebf9925507a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c494c494e4f70656e4769744875622f4c6162656c696e672d546f6f6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0dda3d9021bae83c1599227cba107851e7fca8ed66964b0409228ebf9925507a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c494c494e4f70656e4769744875622f4c6162656c696e672d546f6f6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LILINOpenGitHub/Labeling-Tool?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Free YOLO AI labeling tool. YOLO AI labeling tool is a Windows app for labeling YOLO dataset.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/whs0523003/YOLOv5_6.1_autolabel\"\u003ewhs0523003/YOLOv5_6.1_autolabel\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5945d2dd0cf857c10634ff50faf0a6fa29fab0229b0e836b63142bb5c2b084e8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776873303532333030332f594f4c4f76355f362e315f6175746f6c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5945d2dd0cf857c10634ff50faf0a6fa29fab0229b0e836b63142bb5c2b084e8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f776873303532333030332f594f4c4f76355f362e315f6175746f6c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/whs0523003/YOLOv5_6.1_autolabel?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOv5_6.1 自动标记目标框。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/2vin/PyYAT\"\u003e2vin/PyYAT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c7e1064e7dd50959690eef4f38f1d4749dbc5aa325696511fb5a1c72a133073c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3276696e2f50795941543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c7e1064e7dd50959690eef4f38f1d4749dbc5aa325696511fb5a1c72a133073c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3276696e2f50795941543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/2vin/PyYAT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Semi-Automatic Yolo Annotation Tool In Python.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AlturosDestinations/Alturos.ImageAnnotation\"\u003eAlturosDestinations/Alturos.ImageAnnotation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b6ba89fc7367ee013a360cdc8eaa6c1c379243f52450f81df24188e7ed826e92/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c7475726f7344657374696e6174696f6e732f416c7475726f732e496d616765416e6e6f746174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b6ba89fc7367ee013a360cdc8eaa6c1c379243f52450f81df24188e7ed826e92/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f416c7475726f7344657374696e6174696f6e732f416c7475726f732e496d616765416e6e6f746174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AlturosDestinations/Alturos.ImageAnnotation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : A collaborative tool for labeling image data for yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/stephanecharette/DarkMark\"\u003estephanecharette/DarkMark\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/fd2bd5cfcdb3e964e498f8dc1989a07abccac0d267e0f362358a8ae32516fa0f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374657068616e6563686172657474652f4461726b4d61726b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fd2bd5cfcdb3e964e498f8dc1989a07abccac0d267e0f362358a8ae32516fa0f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7374657068616e6563686172657474652f4461726b4d61726b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/stephanecharette/DarkMark?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Marking up images for use with Darknet.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/2vin/yolo_annotation_tool\"\u003e2vin/yolo_annotation_tool\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8fac3b71b05b60c41d0fc33d10f11fa87124cd2f34af81cd74c00726646a14c6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3276696e2f796f6c6f5f616e6e6f746174696f6e5f746f6f6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8fac3b71b05b60c41d0fc33d10f11fa87124cd2f34af81cd74c00726646a14c6/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f3276696e2f796f6c6f5f616e6e6f746174696f6e5f746f6f6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/2vin/yolo_annotation_tool?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Annotation tool for YOLO in opencv.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/sanfooh/quick_yolo2_label_tool\"\u003esanfooh/quick_yolo2_label_tool\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/601f50b57a84009341cc6308ee832f54eb3e6b6f2feda6bfc4cf9bb8b10525b2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73616e666f6f682f717569636b5f796f6c6f325f6c6162656c5f746f6f6c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/601f50b57a84009341cc6308ee832f54eb3e6b6f2feda6bfc4cf9bb8b10525b2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f73616e666f6f682f717569636b5f796f6c6f325f6c6162656c5f746f6f6c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/sanfooh/quick_yolo2_label_tool?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : yolo快速标注工具 quick yolo2 label tool.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/folkien/yaya\"\u003efolkien/yaya\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a1a5789fd999eac0555317afe1e759db4bf040f715e39e1fbc84f27b931ad01a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666f6c6b69656e2f796179613f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a1a5789fd999eac0555317afe1e759db4bf040f715e39e1fbc84f27b931ad01a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f666f6c6b69656e2f796179613f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/folkien/yaya?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YAYA - Yet annother YOLO annoter for images (in QT5). Support yolo format, image modifications, labeling and detecting with previously trained detector.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/pylabel-project/pylabel\"\u003epylabel-project/pylabel\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2391c03e201ec8104ea2aa1b0ef63f6dc5c4818c99c2f9527698a7556db39c09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70796c6162656c2d70726f6a6563742f70796c6162656c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2391c03e201ec8104ea2aa1b0ef63f6dc5c4818c99c2f9527698a7556db39c09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f70796c6162656c2d70726f6a6563742f70796c6162656c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/pylabel-project/pylabel?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Python library for computer vision labeling tasks. The core functionality is to translate bounding box annotations between different formats-for example, from coco to yolo.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/opendatalab/labelU\"\u003eopendatalab/labelU\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ef37844fb33e54c59b70a193bdb2d3c2afff71b26eb40d3fc8db53abba609e7a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e646174616c61622f6c6162656c553f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ef37844fb33e54c59b70a193bdb2d3c2afff71b26eb40d3fc8db53abba609e7a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6f70656e646174616c61622f6c6162656c553f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/opendatalab/labelU?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Uniform, Unlimited, Universal and Unbelievable Annotation Toolbox.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eData Augmentation\u003c/h4\u003e\u003ca id=\"user-content-data-augmentation\" class=\"anchor\" aria-label=\"Permalink: Data Augmentation\" href=\"#data-augmentation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/albumentations-team/albumentations\"\u003eAlbumentations\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/84c7a1c3a26134634d9163e335f0f5413cc53dd7befcd137da96b91aa7b41ed7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c62756d656e746174696f6e732d7465616d2f616c62756d656e746174696f6e733f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/84c7a1c3a26134634d9163e335f0f5413cc53dd7befcd137da96b91aa7b41ed7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c62756d656e746174696f6e732d7465616d2f616c62756d656e746174696f6e733f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/albumentations-team/albumentations?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : Albumentations is a Python library for image augmentation. Image augmentation is used in deep learning and computer vision tasks to increase the quality of trained models. The purpose of image augmentation is to create new training samples from the existing data. \"Albumentations: Fast and Flexible Image Augmentations\". (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/2078-2489/11/2/125\" rel=\"nofollow\"\u003eInformation 2020\u003c/a\u003e\u003c/strong\u003e). \u003ca href=\"https://albumentations.ai/\" rel=\"nofollow\"\u003ealbumentations.ai\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/doubleZ0108/Data-Augmentation\"\u003edoubleZ0108/Data-Augmentation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/aedc1387893882413eb22185722d1e0516af2d2abf95dde86dfdbe432b0aa677/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f75626c655a303130382f446174612d4175676d656e746174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/aedc1387893882413eb22185722d1e0516af2d2abf95dde86dfdbe432b0aa677/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f646f75626c655a303130382f446174612d4175676d656e746174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/doubleZ0108/Data-Augmentation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : General Data Augmentation Algorithms for Object Detection(esp. Yolo).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eData Management\u003c/h4\u003e\u003ca id=\"user-content-data-management\" class=\"anchor\" aria-label=\"Permalink: Data Management\" href=\"#data-management\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/lancedb/yoloexplorer\"\u003eYOLOExplorer\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/507c960895daec4c89d562819404975d61a1557d00935e06873f2270d3a9204e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c616e636564622f796f6c6f6578706c6f7265723f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/507c960895daec4c89d562819404975d61a1557d00935e06873f2270d3a9204e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6c616e636564622f796f6c6f6578706c6f7265723f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/lancedb/yoloexplorer?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : YOLOExplorer : Iterate on your YOLO / CV datasets using SQL, Vector semantic search, and more within seconds. Explore, manipulate and iterate on Computer Vision datasets with precision using simple APIs. Supports SQL filters, vector similarity search, native interface with Pandas and more.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eGeneral Detection and Recognition Datasets\u003c/h3\u003e\u003ca id=\"user-content-general-detection-and-recognition-datasets\" class=\"anchor\" aria-label=\"Permalink: General Detection and Recognition Datasets\" href=\"#general-detection-and-recognition-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eGeneral Object Detection Datasets\u003c/h4\u003e\u003ca id=\"user-content-general-object-detection-datasets\" class=\"anchor\" aria-label=\"Permalink: General Object Detection Datasets\" href=\"#general-object-detection-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://cocodataset.org/\" rel=\"nofollow\"\u003eCOCO\u003c/a\u003e : \"Microsoft COCO: Common Objects in Context\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/chapter/10.1007/978-3-319-10602-1_48\" rel=\"nofollow\"\u003eECCV 2014\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://host.robots.ox.ac.uk/pascal/VOC/\" rel=\"nofollow\"\u003ePASCAL VOC\u003c/a\u003e : \"The Pascal Visual Object Classes Challenge: A Retrospective\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/article/10.1007/s11263-014-0733-5\" rel=\"nofollow\"\u003eIJCV 2015\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://www.objects365.org/overview.html\" rel=\"nofollow\"\u003eObjects365\u003c/a\u003e : \"Objects365: A Large-scale, High-quality Dataset for Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_ICCV_2019/html/Shao_Objects365_A_Large-Scale_High-Quality_Dataset_for_Object_Detection_ICCV_2019_paper.html\" rel=\"nofollow\"\u003eICCV 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://v3det.openxlab.org.cn/\" rel=\"nofollow\"\u003eV3Det\u003c/a\u003e : \"V3Det: Vast Vocabulary Visual Detection Dataset\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2304.03752\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SkyCol/ODverse33\"\u003eODverse33\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ef5f96c2ac827b99fbe9cf71af48c0c784def6d4e1231a0614c5d925e52d2c69/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536b79436f6c2f4f44766572736533333f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ef5f96c2ac827b99fbe9cf71af48c0c784def6d4e1231a0614c5d925e52d2c69/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536b79436f6c2f4f44766572736533333f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SkyCol/ODverse33?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"ODverse33: Is the New YOLO Version Always Better? A Multi Domain benchmark from YOLO v5 to v11\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2502.14314\" rel=\"nofollow\"\u003earXiv 2025\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eGeneral Object Recognition Datasets\u003c/h4\u003e\u003ca id=\"user-content-general-object-recognition-datasets\" class=\"anchor\" aria-label=\"Permalink: General Object Recognition Datasets\" href=\"#general-object-recognition-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://image-net.org/challenges/LSVRC/\" rel=\"nofollow\"\u003eImageNet\u003c/a\u003e : \"ImageNet Large Scale Visual Recognition Challenge\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/article/10.1007/s11263-015-0816-y\" rel=\"nofollow\"\u003eIJCV 2015\u003c/a\u003e\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAutonomous Driving Datasets\u003c/h3\u003e\u003ca id=\"user-content-autonomous-driving-datasets\" class=\"anchor\" aria-label=\"Permalink: Autonomous Driving Datasets\" href=\"#autonomous-driving-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eDiverse Autonomous Driving Datasets\u003c/h4\u003e\u003ca id=\"user-content-diverse-autonomous-driving-datasets\" class=\"anchor\" aria-label=\"Permalink: Diverse Autonomous Driving Datasets\" href=\"#diverse-autonomous-driving-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://bdd-data.berkeley.edu/\" rel=\"nofollow\"\u003eBDD100K\u003c/a\u003e : \"BDD100K: A Diverse Driving Dataset for Heterogeneous Multitask Learning\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_CVPR_2020/html/Yu_BDD100K_A_Diverse_Driving_Dataset_for_Heterogeneous_Multitask_Learning_CVPR_2020_paper.html\" rel=\"nofollow\"\u003eCVPR 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://coda-dataset.github.io/\" rel=\"nofollow\"\u003eCODA\u003c/a\u003e : \"CODA: A Real-World Road Corner Case Dataset for Object Detection in Autonomous Driving\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/chapter/10.1007/978-3-031-19839-7_24\" rel=\"nofollow\"\u003eECCV 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eTraffic Sign Detection Datasets\u003c/h4\u003e\u003ca id=\"user-content-traffic-sign-detection-datasets\" class=\"anchor\" aria-label=\"Permalink: Traffic Sign Detection Datasets\" href=\"#traffic-sign-detection-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://cg.cs.tsinghua.edu.cn/traffic-sign/\" rel=\"nofollow\"\u003eTT100K\u003c/a\u003e : \"Traffic-Sign Detection and Classification in the Wild\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_cvpr_2016/html/Zhu_Traffic-Sign_Detection_and_CVPR_2016_paper.html\" rel=\"nofollow\"\u003eCVPR 2016\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/csust7zhangjm/CCTSDB\"\u003eCCTSDB\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/84dd116765dd78e1c615b51d2b7e9df9bc592bceaa7e9e2fcb249c0c718b26ef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6373757374377a68616e676a6d2f4343545344423f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/84dd116765dd78e1c615b51d2b7e9df9bc592bceaa7e9e2fcb249c0c718b26ef/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6373757374377a68616e676a6d2f4343545344423f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/csust7zhangjm/CCTSDB?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : CSUST Chinese Traffic Sign Detection Benchmark 中国交通数据集由长沙理工大学综合交通运输大数据智能处理湖南省重点实验室张建明老师团队制作完成。 \"A Real-Time Chinese Traffic Sign Detection Algorithm Based on Modified YOLOv2\". (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/1999-4893/10/4/127\" rel=\"nofollow\"\u003eAlgorithms, 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/csust7zhangjm/CCTSDB2021\"\u003eCCTSDB2021\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/38dbaaa691f422bb9fdf34cc8be8c9e90fc39e505d312994cd7cc80f8c082da3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6373757374377a68616e676a6d2f434354534442323032313f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/38dbaaa691f422bb9fdf34cc8be8c9e90fc39e505d312994cd7cc80f8c082da3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6373757374377a68616e676a6d2f434354534442323032313f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/csust7zhangjm/CCTSDB2021?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"CCTSDB 2021: a more comprehensive traffic sign detection benchmark\". (\u003cstrong\u003e\u003ca href=\"https://centaur.reading.ac.uk/106129/\" rel=\"nofollow\"\u003eHuman-centric Computing and Information Sciences, 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eLicense Plate Detection and Recognition Datasets\u003c/h4\u003e\u003ca id=\"user-content-license-plate-detection-and-recognition-datasets\" class=\"anchor\" aria-label=\"Permalink: License Plate Detection and Recognition Datasets\" href=\"#license-plate-detection-and-recognition-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/detectRecog/CCPD\"\u003eCCPD\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/38dbaaa691f422bb9fdf34cc8be8c9e90fc39e505d312994cd7cc80f8c082da3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6373757374377a68616e676a6d2f434354534442323032313f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/38dbaaa691f422bb9fdf34cc8be8c9e90fc39e505d312994cd7cc80f8c082da3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6373757374377a68616e676a6d2f434354534442323032313f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/csust7zhangjm/CCTSDB2021?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Towards End-to-End License Plate Detection and Recognition: A Large Dataset and Baseline\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_ECCV_2018/html/Zhenbo_Xu_Towards_End-to-End_License_ECCV_2018_paper.html\" rel=\"nofollow\"\u003eECCV 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAdverse Weather Datasets\u003c/h3\u003e\u003ca id=\"user-content-adverse-weather-datasets\" class=\"anchor\" aria-label=\"Permalink: Adverse Weather Datasets\" href=\"#adverse-weather-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://sites.google.com/site/boyilics/website-builder/reside\" rel=\"nofollow\"\u003eRESID\u003c/a\u003e : \"Benchmarking Single-Image Dehazing and Beyond\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8451944\" rel=\"nofollow\"\u003eIEEE Transactions on Image Processing 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003ePerson Detection Datasets\u003c/h3\u003e\u003ca id=\"user-content-person-detection-datasets\" class=\"anchor\" aria-label=\"Permalink: Person Detection Datasets\" href=\"#person-detection-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://lear.inrialpes.fr/data\" rel=\"nofollow\"\u003eINRIA Person\u003c/a\u003e : \"Histograms of oriented gradients for human detection\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/1467360\" rel=\"nofollow\"\u003eCVPR 2005\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://www.crowdhuman.org/\" rel=\"nofollow\"\u003eCrowdHuman\u003c/a\u003e : \"CrowdHuman: A Benchmark for Detecting Human in a Crowd\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1805.00123\" rel=\"nofollow\"\u003earXiv 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://www.panda-dataset.com\" rel=\"nofollow\"\u003ePANDA\u003c/a\u003e : \"PANDA: A Gigapixel-Level Human-Centric Video Dataset\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_CVPR_2020/html/Wang_PANDA_A_Gigapixel-Level_Human-Centric_Video_Dataset_CVPR_2020_paper.html\" rel=\"nofollow\"\u003eCVPR 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ucas-vg/PointTinyBenchmark\"\u003eTinyPerson\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e4f3118d42bda5763909ec1f95bcf7182dfccb70c3070e887e0d72d75b6f66c2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756361732d76672f506f696e7454696e7942656e63686d61726b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e4f3118d42bda5763909ec1f95bcf7182dfccb70c3070e887e0d72d75b6f66c2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756361732d76672f506f696e7454696e7942656e63686d61726b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ucas-vg/PointTinyBenchmark?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Scale Match for Tiny Person Detection\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_WACV_2020/html/Yu_Scale_Match_for_Tiny_Person_Detection_WACV_2020_paper.html\" rel=\"nofollow\"\u003eWACV 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ucas-vg/PointTinyBenchmark\"\u003eTinyPerson v2 | SeaPerson\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e4f3118d42bda5763909ec1f95bcf7182dfccb70c3070e887e0d72d75b6f66c2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756361732d76672f506f696e7454696e7942656e63686d61726b3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e4f3118d42bda5763909ec1f95bcf7182dfccb70c3070e887e0d72d75b6f66c2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f756361732d76672f506f696e7454696e7942656e63686d61726b3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ucas-vg/PointTinyBenchmark?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Object Localization Under Single Coarse Point Supervision\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Object_Localization_Under_Single_Coarse_Point_Supervision_CVPR_2022_paper.html\" rel=\"nofollow\"\u003eCVPR 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAnti-UAV Datasets\u003c/h2\u003e\u003ca id=\"user-content-anti-uav-datasets\" class=\"anchor\" aria-label=\"Permalink: Anti-UAV Datasets\" href=\"#anti-uav-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZhaoJ9014/Anti-UAV\"\u003eAnti-UAV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f4011264d69ecf9a1839ac7bce6be873eeab7abb74913794ffcf866e7f9c5a36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68616f4a393031342f416e74692d5541563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f4011264d69ecf9a1839ac7bce6be873eeab7abb74913794ffcf866e7f9c5a36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68616f4a393031342f416e74692d5541563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZhaoJ9014/Anti-UAV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🔥🔥Official Repository for Anti-UAV🔥🔥. Anti-UAV300, Anti-UAV410, Anti-UAV600. Please refer to our \u003ca href=\"https://ieeexplore.ieee.org/document/9615243\" rel=\"nofollow\"\u003eAnti-UAV v1\u003c/a\u003e paper and \u003ca href=\"https://arxiv.org/pdf/2306.15767.pdf\" rel=\"nofollow\"\u003eAnti-UAV v3\u003c/a\u003e paper for more details (\u003ca href=\"https://zhaoj9014.github.io/pub/Anti-UAV.pdf\" rel=\"nofollow\"\u003eWeChat News\u003c/a\u003e). \"Anti-UAV: A Large-Scale Benchmark for Vision-Based UAV Tracking\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/document/9615243\" rel=\"nofollow\"\u003eIEEE Transactions on Multimedia, 2022\u003c/a\u003e\u003c/strong\u003e). \"Evidential Detection and Tracking Collaboration: New Problem, Benchmark and Algorithm for Robust Anti-UAV System\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2306.15767\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/wangdongdut/DUT-Anti-UAV\"\u003eDUT-Anti-UAV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/6d1b7e1210c59ca143ac28ef22b2f92f54acc49ff085b6fab12c5d5385d3dbdc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e67646f6e676475742f4455542d416e74692d5541563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6d1b7e1210c59ca143ac28ef22b2f92f54acc49ff085b6fab12c5d5385d3dbdc/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f77616e67646f6e676475742f4455542d416e74692d5541563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/wangdongdut/DUT-Anti-UAV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : DUT Anti-UAV Detection and Tracking. \"Vision-based Anti-UAV Detection and Tracking\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2205.10851\" rel=\"nofollow\"\u003eIEEE Transactions on Intelligent Transportation Systems, 2022\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOptical Aerial Imagery Datasets\u003c/h3\u003e\u003ca id=\"user-content-optical-aerial-imagery-datasets\" class=\"anchor\" aria-label=\"Permalink: Optical Aerial Imagery Datasets\" href=\"#optical-aerial-imagery-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/LLNL/cowc\"\u003eCOWC\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e3f1f82b8a44a0c69b2709c2c33e4818fd02fcf0dffabf8222899331a70b7439/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c4c4e4c2f636f77633f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e3f1f82b8a44a0c69b2709c2c33e4818fd02fcf0dffabf8222899331a70b7439/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c4c4e4c2f636f77633f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/LLNL/cowc?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"A large contextual dataset for classification, detection and counting of cars with deep learning\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/chapter/10.1007/978-3-319-46487-9_48\" rel=\"nofollow\"\u003eECCV 2016\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/RSIA-LIESMARS-WHU/RSOD-Dataset-\"\u003eRSOD\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/60abf6309f4ccbdd708f1fcdc9604b7a6e00b291737094806c2c1909496b228c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f525349412d4c4945534d4152532d5748552f52534f442d446174617365742d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/60abf6309f4ccbdd708f1fcdc9604b7a6e00b291737094806c2c1909496b228c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f525349412d4c4945534d4152532d5748552f52534f442d446174617365742d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/RSIA-LIESMARS-WHU/RSOD-Dataset-?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Accurate object localization in remote sensing images based on convolutional neural networks\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/7827088/\" rel=\"nofollow\"\u003eIEEE TGRS 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://levir.buaa.edu.cn/Code.htm\" rel=\"nofollow\"\u003eLEVIR\u003c/a\u003e : \"Random access memories: A new paradigm for target detection in high resolution aerial remote sensing images\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8106808\" rel=\"nofollow\"\u003eIEEE Transactions on Image Processing 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/WindVChen/LEVIR-Ship\"\u003eLEVIR-Ship\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/814e0a4515b55437de7dab809dda43bc04f38d8dd7f1d316d2e0878f31076efe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57696e64564368656e2f4c455649522d536869703f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/814e0a4515b55437de7dab809dda43bc04f38d8dd7f1d316d2e0878f31076efe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57696e64564368656e2f4c455649522d536869703f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/WindVChen/LEVIR-Ship?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"A Degraded Reconstruction Enhancement-based Method for Tiny Ship Detection in Remote Sensing Images with A New Large-scale Dataset\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9791363\" rel=\"nofollow\"\u003eIEEE TGRS 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.iuii.ua.es/datasets/masati/\" rel=\"nofollow\"\u003eMASATI\u003c/a\u003e : \"Automatic ship classification from optical aerial images with convolutional neural networks\". (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/2072-4292/10/4/511\" rel=\"nofollow\"\u003eRemote Sensing 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://xviewdataset.org/\" rel=\"nofollow\"\u003exView\u003c/a\u003e : \"xView: Objects in Context in Overhead Imagery\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1802.07856\" rel=\"nofollow\"\u003earXiv 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://captain-whu.github.io/DOTA/\" rel=\"nofollow\"\u003eDOTA\u003c/a\u003e : \"DOTA: A Large-Scale Dataset for Object Detection in Aerial Images\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_cvpr_2018/html/Xia_DOTA_A_Large-Scale_CVPR_2018_paper.html\" rel=\"nofollow\"\u003eCVPR 2018\u003c/a\u003e\u003c/strong\u003e). \"Object Detection in Aerial Images: A Large-Scale Benchmark and Challenges\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9560031\" rel=\"nofollow\"\u003eIEEE TPAMI 2021\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://research.utwente.nl/en/datasets/itcvd-dataset\" rel=\"nofollow\"\u003eITCVD\u003c/a\u003e : \"Deep Learning for Vehicle Detection in Aerial Images\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8451454\" rel=\"nofollow\"\u003eIEEE ICIP 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://www.patreo.dcc.ufmg.br/2019/07/10/bridge-dataset/\" rel=\"nofollow\"\u003eBridge Dataset\u003c/a\u003e : \"A Tool for Bridge Detection in Major Infrastructure Works Using Satellite Images\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8876942\" rel=\"nofollow\"\u003eIEEE ICIP 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://www.escience.cn/people/JunweiHan/DIOR.html\" rel=\"nofollow\"\u003eDIOR\u003c/a\u003e : \"Object detection in optical remote sensing images: A survey and a new benchmark\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S0924271619302825\" rel=\"nofollow\"\u003eISPRS 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/mribrahim/PESMOD\"\u003ePESMOD\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/52db5594f0ef78f99079aedf7d472123f38b5b937029df907d72a8627872e1ce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d726962726168696d2f5045534d4f443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/52db5594f0ef78f99079aedf7d472123f38b5b937029df907d72a8627872e1ce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d726962726168696d2f5045534d4f443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/mribrahim/PESMOD?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"UAV Images Dataset for Moving Object Detection from Moving Cameras\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2103.11460\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/jwwangchn/AI-TOD\"\u003eAI-TOD\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1a8221700f10bb7bfbe2654718272d8cf0a138b705535dbd548193be481548b1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a7777616e6763686e2f41492d544f443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1a8221700f10bb7bfbe2654718272d8cf0a138b705535dbd548193be481548b1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a7777616e6763686e2f41492d544f443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/jwwangchn/AI-TOD?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Tiny Object Detection in Aerial Images\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9413340\" rel=\"nofollow\"\u003eIEEE ICPR 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ChaoXiao12/Moving-object-detection-DSFNet\"\u003eRsCarData\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/35e444edbeff61845a84e93a9b7436dc0b723714190ae87c01947d1b92ba1cbe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368616f5869616f31322f4d6f76696e672d6f626a6563742d646574656374696f6e2d4453464e65743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/35e444edbeff61845a84e93a9b7436dc0b723714190ae87c01947d1b92ba1cbe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4368616f5869616f31322f4d6f76696e672d6f626a6563742d646574656374696f6e2d4453464e65743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ChaoXiao12/Moving-object-detection-DSFNet?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"DSFNet: Dynamic and Static Fusion Network for Moving Object Detection in Satellite Videos\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9594855\" rel=\"nofollow\"\u003eIEEE GRSL 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/The-Learning-And-Vision-Atelier-LAVA/VISO\"\u003eVISO\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/8c1d77b068a0e04f227787a44168bf5941c1467433c9e1f53bf2722d0ba192c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5468652d4c6561726e696e672d416e642d566973696f6e2d4174656c6965722d4c4156412f5649534f3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8c1d77b068a0e04f227787a44168bf5941c1467433c9e1f53bf2722d0ba192c5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5468652d4c6561726e696e672d416e642d566973696f6e2d4174656c6965722d4c4156412f5649534f3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/The-Learning-And-Vision-Atelier-LAVA/VISO?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Detecting and Tracking Small and Dense Moving Objects in Satellite Videos: A Benchmark\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9625976\" rel=\"nofollow\"\u003eIEEE TGRS 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/VisDrone/VisDrone-Dataset\"\u003eVisDrone\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/28aa20e7816fa7416c5719a987cd92a06c6c6b0c0dc0033067332a3a29be4038/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f56697344726f6e652f56697344726f6e652d446174617365743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/28aa20e7816fa7416c5719a987cd92a06c6c6b0c0dc0033067332a3a29be4038/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f56697344726f6e652f56697344726f6e652d446174617365743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/VisDrone/VisDrone-Dataset?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Detection and Tracking Meet Drones Challenge\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9573394\" rel=\"nofollow\"\u003eIEEE TPAMI 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://gaofen-challenge.com/benchmark\" rel=\"nofollow\"\u003eFAIR1M\u003c/a\u003e : \"FAIR1M: A benchmark dataset for fine-grained object recognition in high-resolution remote sensing imagery\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S0924271621003269\" rel=\"nofollow\"\u003eISPRS 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Ben93kie/SeaDronesSee\"\u003eSeaDronesSee\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9ca53b8e673bdc8ba257a00a747be8867fe7b6be14002f1c7ba14f8157483c0d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42656e39336b69652f53656144726f6e65735365653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9ca53b8e673bdc8ba257a00a747be8867fe7b6be14002f1c7ba14f8157483c0d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f42656e39336b69652f53656144726f6e65735365653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Ben93kie/SeaDronesSee?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"SeaDronesSee: A Maritime Benchmark for Detecting Humans in Open Water\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/WACV2022/html/Varga_SeaDronesSee_A_Maritime_Benchmark_for_Detecting_Humans_in_Open_Water_WACV_2022_paper.html\" rel=\"nofollow\"\u003eWACV 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eLow-light Image Datasets\u003c/h3\u003e\u003ca id=\"user-content-low-light-image-datasets\" class=\"anchor\" aria-label=\"Permalink: Low-light Image Datasets\" href=\"#low-light-image-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.nightowls-dataset.org/\" rel=\"nofollow\"\u003eNightOwls\u003c/a\u003e : \"NightOwls: A Pedestrians at Night Dataset\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/chapter/10.1007/978-3-030-20887-5_43\" rel=\"nofollow\"\u003eACCV 2018\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/cs-chan/Exclusively-Dark-Image-Dataset\"\u003eExDark\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/306546bd00feb281e842dbc41e97c23882e42f560bd682431ef337d6b2bf8146/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63732d6368616e2f4578636c75736976656c792d4461726b2d496d6167652d446174617365743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/306546bd00feb281e842dbc41e97c23882e42f560bd682431ef337d6b2bf8146/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f63732d6368616e2f4578636c75736976656c792d4461726b2d496d6167652d446174617365743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/cs-chan/Exclusively-Dark-Image-Dataset?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Getting to know low-light images with the exclusively dark dataset\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S1077314218304296\" rel=\"nofollow\"\u003eCVIU 2019\u003c/a\u003e\u003c/strong\u003e). \"Low-light image enhancement using Gaussian Process for features retrieval\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S0923596518310452\" rel=\"nofollow\"\u003eSignal Processing: Image Communication, 2019\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://flyywh.github.io/CVPRW2019LowLight/\" rel=\"nofollow\"\u003eDARK FACE\u003c/a\u003e : DARK FACE: Face Detection in Low Light Condition. \"Advancing Image Understanding in Poor Visibility Environments: A Collective Benchmark Study\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9049390/\" rel=\"nofollow\"\u003eIEEE Transactions on Image Processing 2020\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eInfrared Image Datasets\u003c/h3\u003e\u003ca id=\"user-content-infrared-image-datasets\" class=\"anchor\" aria-label=\"Permalink: Infrared Image Datasets\" href=\"#infrared-image-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.scidb.cn/en/detail?dataSetId=720626420933459968\" rel=\"nofollow\"\u003e地/空背景下红外图像弱小飞机目标检测跟踪数据集\u003c/a\u003e (\u003cstrong\u003e\u003ca href=\"http://www.csdata.org/p/387/\" rel=\"nofollow\"\u003e中国科学数据, 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.scidb.cn/en/detail?dataSetId=808025946870251520\" rel=\"nofollow\"\u003e复杂背景下红外弱小运动目标检测数据集\u003c/a\u003e (\u003cstrong\u003e\u003ca href=\"http://www.csdata.org/p/553/\" rel=\"nofollow\"\u003e中国科学数据, 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.scidb.cn/en/detail?dataSetId=de971a1898774dc5921b68793817916e\" rel=\"nofollow\"\u003e面向空地应用的红外时敏目标检测跟踪数据集\u003c/a\u003e (\u003cstrong\u003e\u003ca href=\"http://www.csdata.org/p/673/\" rel=\"nofollow\"\u003e中国科学数据, 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SCUT-CV/SCUT_FIR_Pedestrian_Dataset\"\u003eSCUT_FIR_Pedestrian_Dataset\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a46f473a19b758f55ad977e000e8a898f381b46673132f035dae17a8fb905e08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f534355542d43562f534355545f4649525f5065646573747269616e5f446174617365743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a46f473a19b758f55ad977e000e8a898f381b46673132f035dae17a8fb905e08/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f534355542d43562f534355545f4649525f5065646573747269616e5f446174617365743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SCUT-CV/SCUT_FIR_Pedestrian_Dataset?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Benchmarking a large-scale FIR dataset for on-road pedestrian detection\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S1350449518305589\" rel=\"nofollow\"\u003eInfrared Physics \u0026amp; Technology, 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/YeRen123455/Infrared-Small-Target-Detection\"\u003eNUDT-SIRST\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9d325c0a32d06813d57035d981abe5c173373c158f43bb0ff886f064595aba68/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f596552656e3132333435352f496e6672617265642d536d616c6c2d5461726765742d446574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9d325c0a32d06813d57035d981abe5c173373c158f43bb0ff886f064595aba68/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f596552656e3132333435352f496e6672617265642d536d616c6c2d5461726765742d446574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/YeRen123455/Infrared-Small-Target-Detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Dense Nested Attention Network for Infrared Small Target Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2106.00487\" rel=\"nofollow\"\u003earXiv 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/YimianDai/sirst\"\u003eSIRST\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/2eb9ee16d25febbfca778ba174d28be46d965b0eee49c0ebb83bf6e1bd60847e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59696d69616e4461692f73697273743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2eb9ee16d25febbfca778ba174d28be46d965b0eee49c0ebb83bf6e1bd60847e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f59696d69616e4461692f73697273743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/YimianDai/sirst?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Asymmetric Contextual Modulation for Infrared Small Target Detection\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/WACV2021/html/Dai_Asymmetric_Contextual_Modulation_for_Infrared_Small_Target_Detection_WACV_2021_paper.html\" rel=\"nofollow\"\u003eWACV 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSAR Image Datasets\u003c/h3\u003e\u003ca id=\"user-content-sar-image-datasets\" class=\"anchor\" aria-label=\"Permalink: SAR Image Datasets\" href=\"#sar-image-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.sandia.gov/radar/pathfinder-radar-isr-and-synthetic-aperture-radar-sar-systems/video/\" rel=\"nofollow\"\u003eSNL VideoSAR\u003c/a\u003e : \"Developments in sar and ifsar systems and technologies at sandia national laboratories\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/1235522\" rel=\"nofollow\"\u003eIEEE Aerospace Conference Proceedings, 2003\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.sdms.afrl.af.mil/index.php?collection=mstar\" rel=\"nofollow\"\u003eMSTAR\u003c/a\u003e : MSTAR public dataset. \"Object recognition results using MSTAR synthetic aperture radar data\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/855250/\" rel=\"nofollow\"\u003eIEEE CVBVS 2000\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://opensar.sjtu.edu.cn/\" rel=\"nofollow\"\u003eOpenSARShip\u003c/a\u003e : \"OpenSARShip: A Dataset Dedicated to Sentinel-1 Ship Interpretation\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8067489\" rel=\"nofollow\"\u003eIEEE JSTAEORS 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://opensar.sjtu.edu.cn/\" rel=\"nofollow\"\u003eOpenSARShip 2.0\u003c/a\u003e : \"OpenSARShip 2.0: A large-volume dataset for deeper interpretation of ship targets in Sentinel-1 imagery\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8124929\" rel=\"nofollow\"\u003eIEEE BIGSARDATA 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://aistudio.baidu.com/aistudio/datasetdetail/54806\" rel=\"nofollow\"\u003eSSDD\u003c/a\u003e : \"Ship detection in SAR images based on an improved faster R-CNN\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8124934/\" rel=\"nofollow\"\u003eIEEE BIGSARDATA 2017\u003c/a\u003e\u003c/strong\u003e). \"基于深度学习的SAR图像舰船检测数据集及性能分析\". (\u003cstrong\u003e\u003ca href=\"https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CPFD\u0026amp;dbname=CPFDLAST2019\u0026amp;filename=ZKZD201810001014\u0026amp;uniplatform=NZKPT\u0026amp;v=yO0QaBvz14EhL7pk2vCZgRGQl9EUK4g_ZLMv--RusqdnPK4jBUFATMtsDuwGc8fzPb9iLY3lVOI%3d\" rel=\"nofollow\"\u003e第五届高分辨率对地观测学术年会, 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://radars.ac.cn/web/data/getData?newsColumnId=1e6ecbcc-266d-432c-9c8a-0b9a922b5e85\" rel=\"nofollow\"\u003eAIR-SARShip\u003c/a\u003e : \"高分辨率SAR舰船检测数据集-2.0\". \"AIR-SARShip-1.0: 高分辨率 SAR 舰船检测数据集\". (\u003cstrong\u003e\u003ca href=\"https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD\u0026amp;dbname=CJFDLAST2020\u0026amp;filename=LDAX201906014\u0026amp;uniplatform=NZKPT\u0026amp;v=pL57X-1uWs_T7QAY3gMTKZ1ZrPt1hdyAPDo3jpXRqPLbyAYbrH6-IAZMrqpRwS3J\" rel=\"nofollow\"\u003e雷达学报 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/CAESAR-Radi/SAR-Ship-Dataset\"\u003eSAR-Ship-Dataset\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5bda6fc1e48687052d0bc31cca80763346e28bc9697af867a90ba6f7442c2a84/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4341455341522d526164692f5341522d536869702d446174617365743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5bda6fc1e48687052d0bc31cca80763346e28bc9697af867a90ba6f7442c2a84/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4341455341522d526164692f5341522d536869702d446174617365743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/CAESAR-Radi/SAR-Ship-Dataset?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"A SAR Dataset of Ship Detection for Deep Learning under Complex Backgrounds\". (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/2072-4292/11/7/765\" rel=\"nofollow\"\u003eRemote Sensing, 2019\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://opensar.sjtu.edu.cn/\" rel=\"nofollow\"\u003eOpenSARUrban\u003c/a\u003e : \"OpenSARUrban: A Sentinel-1 SAR Image Dataset for Urban Interpretation\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8952866/\" rel=\"nofollow\"\u003eIEEE JSTAEORS 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/chaozhong2010/HRSID\"\u003eHRSID\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b161040f3c98f657d52c1fee07f6b3f6e4cc23df6e0b082d3ccaad3ffd9fab60/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368616f7a686f6e67323031302f48525349443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b161040f3c98f657d52c1fee07f6b3f6e4cc23df6e0b082d3ccaad3ffd9fab60/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6368616f7a686f6e67323031302f48525349443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/chaozhong2010/HRSID?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"HRSID: A High-Resolution SAR Images Dataset for Ship Detection and Instance Segmentation\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9127939\" rel=\"nofollow\"\u003eIEEE Access 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://emwlab.fudan.edu.cn/resources/\" rel=\"nofollow\"\u003eFUSAR-Ship\u003c/a\u003e : 高分辨率船只数据集FUSAR-Ship1.0. (\u003cstrong\u003e\u003ca href=\"https://radars.ac.cn/web/data/getData?dataType=FUSAR\" rel=\"nofollow\"\u003e雷达学报\u003c/a\u003e\u003c/strong\u003e). \"FUSAR-Ship: building a high-resolution SAR-AIS matchup dataset of Gaofen-3 for ship detection and recognition\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/article/10.1007/s11432-019-2772-5\" rel=\"nofollow\"\u003eScience China Information Sciences, 2020\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/TianwenZhang0825/Official-SSDD\"\u003eOfficial-SSDD\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cfce8cb07ecf20cbbf40ea6bb30ef1ed33872eaa82f341373db4139479c5002e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5469616e77656e5a68616e67303832352f4f6666696369616c2d535344443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cfce8cb07ecf20cbbf40ea6bb30ef1ed33872eaa82f341373db4139479c5002e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5469616e77656e5a68616e67303832352f4f6666696369616c2d535344443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/TianwenZhang0825/Official-SSDD?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"SAR Ship Detection Dataset (SSDD): Official Release and Comprehensive Data Analysis \". (\u003cstrong\u003e\u003ca href=\"https://www.mdpi.com/2072-4292/13/18/3690\" rel=\"nofollow\"\u003eRemote Sensing, 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://radars.ac.cn/web/data/getData?dataType=MSAR\" rel=\"nofollow\"\u003eMSAR\u003c/a\u003e : \"大规模多类SAR目标检测数据集-1.0\"。(\u003cstrong\u003e\u003ca href=\"https://radars.ac.cn/web/data/getData?dataType=MSAR\" rel=\"nofollow\"\u003e雷达学报 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://radars.ac.cn/web/data/getData?dataType=SDD-SAR\" rel=\"nofollow\"\u003eRSDD-SAR\u003c/a\u003e : \"RSDD-SAR:SAR舰船斜框检测数据集\"。(\u003cstrong\u003e\u003ca href=\"https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD\u0026amp;dbname=CJFDLAST2022\u0026amp;filename=LDAX202204006\u0026amp;uniplatform=NZKPT\u0026amp;v=J3WR8KUVzuYM6uPXqbI64hl8oRAk3mvWRv3hrBCH9ZBek54uYq_UkJGY0PGaaxDg\" rel=\"nofollow\"\u003e雷达学报 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSonar Image Datasets\u003c/h3\u003e\u003ca id=\"user-content-sonar-image-datasets\" class=\"anchor\" aria-label=\"Permalink: Sonar Image Datasets\" href=\"#sonar-image-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://zenodo.org/records/10528135\" rel=\"nofollow\"\u003eSWDD\u003c/a\u003e : SWDD: Sonar Wall Detection Dataset. \"Knowledge Distillation in YOLOX-ViT for Side-Scan Sonar Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2403.09313\" rel=\"nofollow\"\u003earXiv 2024\u003c/a\u003e\u003c/strong\u003e). The Sonar Wall Detection Dataset (SWDD) is publicly accessible at \u003ca href=\"https://zenodo.org/records/10528135\" rel=\"nofollow\"\u003ehttps://zenodo.org/records/10528135\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eMultimodal Image Datasets\u003c/h3\u003e\u003ca id=\"user-content-multimodal-image-datasets\" class=\"anchor\" aria-label=\"Permalink: Multimodal Image Datasets\" href=\"#multimodal-image-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://adas-dataset-v2.flirconservator.com/\" rel=\"nofollow\"\u003eFLIR_ADAS\u003c/a\u003e : Teledyne FLIR Free ADAS Thermal Dataset v2.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ZhaoJ9014/Anti-UAV\"\u003eAnti-UAV\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/f4011264d69ecf9a1839ac7bce6be873eeab7abb74913794ffcf866e7f9c5a36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68616f4a393031342f416e74692d5541563f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f4011264d69ecf9a1839ac7bce6be873eeab7abb74913794ffcf866e7f9c5a36/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f5a68616f4a393031342f416e74692d5541563f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ZhaoJ9014/Anti-UAV?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : 🔥🔥Official Repository for Anti-UAV🔥🔥. Anti-UAV300, Anti-UAV410, Anti-UAV600. Please refer to our \u003ca href=\"https://ieeexplore.ieee.org/document/9615243\" rel=\"nofollow\"\u003eAnti-UAV v1\u003c/a\u003e paper and \u003ca href=\"https://arxiv.org/pdf/2306.15767.pdf\" rel=\"nofollow\"\u003eAnti-UAV v3\u003c/a\u003e paper for more details (\u003ca href=\"https://zhaoj9014.github.io/pub/Anti-UAV.pdf\" rel=\"nofollow\"\u003eWeChat News\u003c/a\u003e). \"Anti-UAV: A Large-Scale Benchmark for Vision-Based UAV Tracking\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/document/9615243\" rel=\"nofollow\"\u003eIEEE Transactions on Multimedia, 2022\u003c/a\u003e\u003c/strong\u003e). \"Evidential Detection and Tracking Collaboration: New Problem, Benchmark and Algorithm for Robust Anti-UAV System\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2306.15767\" rel=\"nofollow\"\u003earXiv 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://downloads.greyc.fr/vedai/\" rel=\"nofollow\"\u003eVEDAI\u003c/a\u003e : \"Vehicle Detection in Aerial Imagery: A small target detection benchmark\". (\u003cstrong\u003e\u003ca href=\"https://hal.archives-ouvertes.fr/hal-01122605v2/document\" rel=\"nofollow\"\u003eJournal of Visual Communication and Image Representation 2015\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/SoonminHwang/rgbt-ped-detection\"\u003eKAIST_rgbt\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ba8ca8ddc6e139b98771a9a144e6d0199a58061fb8dd659b8ac064f880fa5847/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536f6f6e6d696e4877616e672f726762742d7065642d646574656374696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ba8ca8ddc6e139b98771a9a144e6d0199a58061fb8dd659b8ac064f880fa5847/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f536f6f6e6d696e4877616e672f726762742d7065642d646574656374696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/SoonminHwang/rgbt-ped-detection?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Multispectral Pedestrian Detection: Benchmark Dataset and Baseline\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_cvpr_2015/html/Hwang_Multispectral_Pedestrian_Detection_2015_CVPR_paper.html\" rel=\"nofollow\"\u003eCVPR 2015\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/bupt-ai-cz/LLVIP\"\u003eLLVIP\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/edb01f770fad6d847b683c3ee5bd2bc4a3e46e4f9fbe0f318b2568c8f70b07a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627570742d61692d637a2f4c4c5649503f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/edb01f770fad6d847b683c3ee5bd2bc4a3e46e4f9fbe0f318b2568c8f70b07a8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627570742d61692d637a2f4c4c5649503f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/bupt-ai-cz/LLVIP?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"LLVIP: A Visible-Infrared Paired Dataset for Low-Light Vision\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/ICCV2021W/RLQ/html/Jia_LLVIP_A_Visible-Infrared_Paired_Dataset_for_Low-Light_Vision_ICCVW_2021_paper.html\" rel=\"nofollow\"\u003eICCV 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://figshare.com/articles/dataset/TNO_Image_Fusion_Dataset/1008029\" rel=\"nofollow\"\u003eTNO\u003c/a\u003e : \"The TNO multiband image data collection\". (\u003cstrong\u003e\u003ca href=\"https://www.data-in-brief.com/article/S2352-3409(17)30469-9/abstract\" rel=\"nofollow\"\u003eData in brief, 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/haqishen/MFNet-pytorch\"\u003eMFNet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/22493584dc2707c3407f06381751243e96fa906d51c6924b399b455959824f47/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686171697368656e2f4d464e65742d7079746f7263683f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/22493584dc2707c3407f06381751243e96fa906d51c6924b399b455959824f47/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f686171697368656e2f4d464e65742d7079746f7263683f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/haqishen/MFNet-pytorch?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : MFNet-pytorch, image semantic segmentation using RGB-Thermal images. \"MFNet: Towards real-time semantic segmentation for autonomous vehicles with multi-spectral scenes\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8206396/\" rel=\"nofollow\"\u003eIROS 2017\u003c/a\u003e\u003c/strong\u003e). (\u003ca href=\"https://www.mi.t.u-tokyo.ac.jp/static/projects/mil_multispectral/\" rel=\"nofollow\"\u003eMFNet Dataset\u003c/a\u003e : Multi-spectral Object Detection and Semantic Segmentation Datasets)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/Linfeng-Tang/MSRS\"\u003eMSRS\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/40ea7a9f195a9053f2db9564e5820e89435cb9ec7e959de58e0e91bb39f2cf71/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696e66656e672d54616e672f4d5352533f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/40ea7a9f195a9053f2db9564e5820e89435cb9ec7e959de58e0e91bb39f2cf71/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696e66656e672d54616e672f4d5352533f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Linfeng-Tang/MSRS?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : MSRS: Multi-Spectral Road Scenarios for Practical Infrared and Visible Image Fusion. \"\u003ca href=\"https://github.com/Linfeng-Tang/PIAFusion\"\u003ePIAFusion\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/031252273c764b9a4d09d7ca9cc6667ca1a90e223141013f9a1aeabce05278d4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696e66656e672d54616e672f504941467573696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/031252273c764b9a4d09d7ca9cc6667ca1a90e223141013f9a1aeabce05278d4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4c696e66656e672d54616e672f504941467573696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/Linfeng-Tang/PIAFusion?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e: A progressive infrared and visible image fusion network based on illumination aware\". (\u003cstrong\u003e\u003ca href=\"https://www.sciencedirect.com/science/article/abs/pii/S156625352200032X\" rel=\"nofollow\"\u003eInformation Fusion, 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/JinyuanLiu-CV/TarDAL\"\u003eTarDAL\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c7ce2deea252ddae517148e9b649b660ef312762782f7d171a3a9cc0c25a6441/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a696e7975616e4c69752d43562f54617244414c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c7ce2deea252ddae517148e9b649b660ef312762782f7d171a3a9cc0c25a6441/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4a696e7975616e4c69752d43562f54617244414c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/JinyuanLiu-CV/TarDAL?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Target-Aware Dual Adversarial Learning and a Multi-Scenario Multi-Modality Benchmark To Fuse Infrared and Visible for Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Target-Aware_Dual_Adversarial_Learning_and_a_Multi-Scenario_Multi-Modality_Benchmark_To_CVPR_2022_paper.html\" rel=\"nofollow\"\u003eCVPR 2022\u003c/a\u003e\u003c/strong\u003e). (\u003ca href=\"https://drive.google.com/drive/folders/1H-oO7bgRuVFYDcMGvxstT1nmy0WF_Y_6?usp=sharing\" rel=\"nofollow\"\u003eM3FD Dataset\u003c/a\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/VisDrone/DroneVehicle\"\u003eDroneVehicle\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9161421ac43049de32620b71a608434ea519c4d29f6849316fe4dec17acf878d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f56697344726f6e652f44726f6e6556656869636c653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9161421ac43049de32620b71a608434ea519c4d29f6849316fe4dec17acf878d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f56697344726f6e652f44726f6e6556656869636c653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/VisDrone/DroneVehicle?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Drone-based RGB-Infrared Cross-Modality Vehicle Detection via Uncertainty-Aware Learning\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9759286/\" rel=\"nofollow\"\u003eIEEE TCSVT 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e3D Object Detection Datasets\u003c/h3\u003e\u003ca id=\"user-content-3d-object-detection-datasets\" class=\"anchor\" aria-label=\"Permalink: 3D Object Detection Datasets\" href=\"#3d-object-detection-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/google-research-datasets/Objectron\"\u003eObjectron\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/ddfba5e9f93c1728525eb632bc9b9305d3227d2fab08062a5bef6832179de626/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f676f6f676c652d72657365617263682d64617461736574732f4f626a656374726f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ddfba5e9f93c1728525eb632bc9b9305d3227d2fab08062a5bef6832179de626/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f676f6f676c652d72657365617263682d64617461736574732f4f626a656374726f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/google-research-datasets/Objectron?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Objectron: A Large Scale Dataset of Object-Centric Videos in the Wild with Pose Annotations\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2021/html/Ahmadyan_Objectron_A_Large_Scale_Dataset_of_Object-Centric_Videos_in_the_CVPR_2021_paper.html?ref=https://githubhelp.com\" rel=\"nofollow\"\u003eCVPR, 2021\u003c/a\u003e\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eVehicle-to-Everything Field Datasets\u003c/h3\u003e\u003ca id=\"user-content-vehicle-to-everything-field-datasets\" class=\"anchor\" aria-label=\"Permalink: Vehicle-to-Everything Field Datasets\" href=\"#vehicle-to-everything-field-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DerrickXuNu/OpenCOOD\"\u003eOpenCOOD|OPV2V\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b1f93ee81a31dffd275a77cbaf785c5de34ef59a207f325b16d2b565a0bcbb50/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465727269636b58754e752f4f70656e434f4f443f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b1f93ee81a31dffd275a77cbaf785c5de34ef59a207f325b16d2b565a0bcbb50/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465727269636b58754e752f4f70656e434f4f443f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DerrickXuNu/OpenCOOD?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : OpenCOOD is an Open COOperative Detection framework for autonomous driving. It is also the official implementation of the ICRA 2022 paper \u003ca href=\"https://mobility-lab.seas.ucla.edu/opv2v/\" rel=\"nofollow\"\u003eOPV2V\u003c/a\u003e. \"OPV2V: An Open Benchmark Dataset and Fusion Pipeline for Perception with Vehicle-to-Vehicle Communication\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/9812038/\" rel=\"nofollow\"\u003eICRA, 2022\u003c/a\u003e\u003c/strong\u003e). \u003ca href=\"https://mobility-lab.seas.ucla.edu/opv2v/\" rel=\"nofollow\"\u003emobility-lab.seas.ucla.edu/opv2v/\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DerrickXuNu/CoBEVT\"\u003eCoBEVT\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/981eb5d07c0fceddea3439d9ba6318cf9e5dd802a6d2681c8c2e799bade9bcea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465727269636b58754e752f436f424556543f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/981eb5d07c0fceddea3439d9ba6318cf9e5dd802a6d2681c8c2e799bade9bcea/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465727269636b58754e752f436f424556543f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DerrickXuNu/CoBEVT?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2207.02202\" rel=\"nofollow\"\u003eCoRL, 2022\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/MediaBrain-SJTU/where2comm\"\u003eWhere2comm\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/790569a66ce9fe78100cc3fe65140302ecdfeeb95930b0cb9549c6da0f9ce800/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d65646961427261696e2d534a54552f776865726532636f6d6d3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/790569a66ce9fe78100cc3fe65140302ecdfeeb95930b0cb9549c6da0f9ce800/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4d65646961427261696e2d534a54552f776865726532636f6d6d3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/MediaBrain-SJTU/where2comm?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Where2comm: Communication-Efficient Collaborative Perception via Spatial Confidence Maps\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2209.12836\" rel=\"nofollow\"\u003eNeurips, 2022\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/PJLab-ADG/LiDARSimLib-and-Placement-Evaluation\"\u003ePJLab-ADG/LiDARSimLib-and-Placement-Evaluation\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/d31b9608ba153953cc2288a9ce5724e510386db2ccff024a080dee39b1a9d06c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f504a4c61622d4144472f4c6944415253696d4c69622d616e642d506c6163656d656e742d4576616c756174696f6e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d31b9608ba153953cc2288a9ce5724e510386db2ccff024a080dee39b1a9d06c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f504a4c61622d4144472f4c6944415253696d4c69622d616e642d506c6163656d656e742d4576616c756174696f6e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/PJLab-ADG/LiDARSimLib-and-Placement-Evaluation?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Analyzing Infrastructure LiDAR Placement with Realistic LiDAR Simulation Library\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2211.15975\" rel=\"nofollow\"\u003eICRA, 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/yifanlu0227/CoAlign\"\u003eCoAlign\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7afeff9fff21beb199ccf6c830e09ed2c5fd55fb385d6ebb2c8fa758dfe7cea7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796966616e6c75303232372f436f416c69676e3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7afeff9fff21beb199ccf6c830e09ed2c5fd55fb385d6ebb2c8fa758dfe7cea7/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f796966616e6c75303232372f436f416c69676e3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/yifanlu0227/CoAlign?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Robust Collaborative 3D Object Detection in Presence of Pose Errors\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/2211.07214\" rel=\"nofollow\"\u003eICRA, 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/ucla-mobility/V2V4Real\"\u003eV2V4Real\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/0b9de56e3c3a33bb2dcfcd4308cbb82fede97c35b723dc596f6fc11f34c24e01/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f75636c612d6d6f62696c6974792f563256345265616c3f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0b9de56e3c3a33bb2dcfcd4308cbb82fede97c35b723dc596f6fc11f34c24e01/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f75636c612d6d6f62696c6974792f563256345265616c3f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ucla-mobility/V2V4Real?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"V2V4Real: A Real-World Large-Scale Dataset for Vehicle-to-Vehicle Cooperative Perception\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2023/html/Xu_V2V4Real_A_Real-World_Large-Scale_Dataset_for_Vehicle-to-Vehicle_Cooperative_Perception_CVPR_2023_paper.html\" rel=\"nofollow\"\u003eCVPR, 2023\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/DerrickXuNu/v2x-vit\"\u003eV2X-ViT|V2XSet\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/85c04a98f5eaa98b4ec6c8035168ce0dddef1bc75d138d1dcddf01f4df9d3b48/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465727269636b58754e752f7632782d7669743f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/85c04a98f5eaa98b4ec6c8035168ce0dddef1bc75d138d1dcddf01f4df9d3b48/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4465727269636b58754e752f7632782d7669743f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/DerrickXuNu/v2x-vit?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"V2X-ViT: Vehicle-to-Everything Cooperative Perception with Vision Transformer\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/chapter/10.1007/978-3-031-19842-7_7\" rel=\"nofollow\"\u003eECCV, 2022\u003c/a\u003e\u003c/strong\u003e).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AIR-THU/DAIR-V2X\"\u003eDAIR-V2X\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/cac158228171b79bb69210ff145290bfc06cc4895b981fb335051cf8cc5f8c5d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4149522d5448552f444149522d5632583f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cac158228171b79bb69210ff145290bfc06cc4895b981fb335051cf8cc5f8c5d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4149522d5448552f444149522d5632583f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AIR-THU/DAIR-V2X?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"DAIR-V2X: A Large-Scale Dataset for Vehicle-Infrastructure Cooperative 3D Object Detection\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2022/html/Yu_DAIR-V2X_A_Large-Scale_Dataset_for_Vehicle-Infrastructure_Cooperative_3D_Object_Detection_CVPR_2022_paper.html\" rel=\"nofollow\"\u003eCVPR, 2022\u003c/a\u003e\u003c/strong\u003e). \u003ca href=\"https://thudair.baai.ac.cn\" rel=\"nofollow\"\u003e全球首个车路协同自动驾驶数据集发布\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/AIR-THU/DAIR-V2X-Seq\"\u003eV2X-Seq\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/9667030a51278c578149979ef904b1413bf40291d2748518873098698c9bfa4a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4149522d5448552f444149522d5632582d5365713f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9667030a51278c578149979ef904b1413bf40291d2748518873098698c9bfa4a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f4149522d5448552f444149522d5632582d5365713f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/AIR-THU/DAIR-V2X-Seq?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"V2X-Seq: A Large-Scale Sequential Dataset for Vehicle-Infrastructure Cooperative Perception and Forecasting\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2023/html/Yu_V2X-Seq_A_Large-Scale_Sequential_Dataset_for_Vehicle-Infrastructure_Cooperative_Perception_and_CVPR_2023_paper.html\" rel=\"nofollow\"\u003eCVPR, 2023\u003c/a\u003e\u003c/strong\u003e). \u003ca href=\"https://thudair.baai.ac.cn\" rel=\"nofollow\"\u003e全球首个大规模时序车路协同自动驾驶数据集发布\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSuper-Resolution Field Datasets\u003c/h3\u003e\u003ca id=\"user-content-super-resolution-field-datasets\" class=\"anchor\" aria-label=\"Permalink: Super-Resolution Field Datasets\" href=\"#super-resolution-field-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/ckkelvinchan/RealBasicVSR\"\u003eVideoLQ\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c1dac845df8e87ded36638c141bea69fea50f6c27b71c5af00a944a7a46e1d0b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636b6b656c76696e6368616e2f5265616c42617369635653523f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c1dac845df8e87ded36638c141bea69fea50f6c27b71c5af00a944a7a46e1d0b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f636b6b656c76696e6368616e2f5265616c42617369635653523f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/ckkelvinchan/RealBasicVSR?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : \"Investigating Tradeoffs in Real-World Video Super-Resolution\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content/CVPR2022/html/Chan_Investigating_Tradeoffs_in_Real-World_Video_Super-Resolution_CVPR_2022_paper.html\" rel=\"nofollow\"\u003eCVPR, 2022\u003c/a\u003e\u003c/strong\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFace Detection and Recognition Datasets\u003c/h3\u003e\u003ca id=\"user-content-face-detection-and-recognition-datasets\" class=\"anchor\" aria-label=\"Permalink: Face Detection and Recognition Datasets\" href=\"#face-detection-and-recognition-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFace Detection Datasets\u003c/h4\u003e\u003ca id=\"user-content-face-detection-datasets\" class=\"anchor\" aria-label=\"Permalink: Face Detection Datasets\" href=\"#face-detection-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://shuoyang1213.me/WIDERFACE/\" rel=\"nofollow\"\u003eWIDER FACE\u003c/a\u003e : \"WIDER FACE: A Face Detection Benchmark\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_cvpr_2016/html/Yang_WIDER_FACE_A_CVPR_2016_paper.html\" rel=\"nofollow\"\u003eCVPR 2016\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://ufdd.info/\" rel=\"nofollow\"\u003eUFDD\u003c/a\u003e : Unconstrained Face Detection Dataset(UFDD). \"Pushing the Limits of Unconstrained Face Detection: a Challenge Dataset and Baseline Results\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8698561l\" rel=\"nofollow\"\u003eIEEE BTAS 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://github.com/HCIILAB/SCUT-HEAD-Dataset-Release\"\u003eHCIILAB/SCUT-HEAD-Dataset-Release\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/a0bea223e25580aa0ae042a659ec0a6ed3c41e71fdc400c9a87a76ea52e2d79d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f484349494c41422f534355542d484541442d446174617365742d52656c656173653f7374796c653d736f6369616c\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a0bea223e25580aa0ae042a659ec0a6ed3c41e71fdc400c9a87a76ea52e2d79d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f484349494c41422f534355542d484541442d446174617365742d52656c656173653f7374796c653d736f6369616c\" data-canonical-src=\"https://img.shields.io/github/stars/HCIILAB/SCUT-HEAD-Dataset-Release?style=social\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e : SCUT HEAD is a large-scale head detection dataset, including 4405 images labeld with 111251 heads. \"Detecting Heads using Feature Refine Net and Cascaded Multi-scale Architecture\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1803.09256\" rel=\"nofollow\"\u003earXiv, 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFace Recognition Datasets\u003c/h4\u003e\u003ca id=\"user-content-face-recognition-datasets\" class=\"anchor\" aria-label=\"Permalink: Face Recognition Datasets\" href=\"#face-recognition-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://vis-www.cs.umass.edu/lfw/\" rel=\"nofollow\"\u003eLFW\u003c/a\u003e : Labeled Faces in the Wild(LFW). \"Labeled Faces in the Wild: A Database forStudying Face Recognition in Unconstrained Environments\". (\u003cstrong\u003e\u003ca href=\"https://hal.inria.fr/inria-00321923/\" rel=\"nofollow\"\u003eWorkshop on faces in'Real-Life'Images: detection, alignment, and recognition. 2008\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://www.cs.tau.ac.il/~wolf/ytfaces/\" rel=\"nofollow\"\u003eYouTube Faces (YTF)\u003c/a\u003e : \"Face recognition in unconstrained videos with matched background similarity\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/5995566\" rel=\"nofollow\"\u003eCVPR 2011\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://pan.baidu.com/s/1k3Cel2wSHQxHO9NkNi3rkg\" rel=\"nofollow\"\u003eCASIA-WebFace\u003c/a\u003e : \"Learning Face Representation from Scratch\". (\u003cstrong\u003e\u003ca href=\"https://arxiv.org/abs/1411.7923\" rel=\"nofollow\"\u003earXiv 2014\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.nist.gov/programs-projects/face-challenges\" rel=\"nofollow\"\u003eIJB-A\u003c/a\u003e : \"Pushing the Frontiers of Unconstrained Face Detection and Recognition: IARPA Janus Benchmark A\". (\u003cstrong\u003e\u003ca href=\"https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Klare_Pushing_the_Frontiers_2015_CVPR_paper.html\" rel=\"nofollow\"\u003eCVPR 2015\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://academictorrents.com/details/9e67eb7cc23c9417f39778a8e06cca5e26196a97/tech\u0026amp;hit=1\u0026amp;filelist=1\" rel=\"nofollow\"\u003eMS-Celeb-1M\u003c/a\u003e : \"MS-Celeb-1M: A Dataset and Benchmark for Large-Scale Face Recognition\". (\u003cstrong\u003e\u003ca href=\"https://link.springer.com/chapter/10.1007/978-3-319-46487-9_6\" rel=\"nofollow\"\u003eECCV 2016\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"http://megaface.cs.washington.edu/\" rel=\"nofollow\"\u003eMegaFace\u003c/a\u003e : \"The MegaFace Benchmark: 1 Million Faces for Recognition at Scale\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_cvpr_2016/html/Kemelmacher-Shlizerman_The_MegaFace_Benchmark_CVPR_2016_paper.html\" rel=\"nofollow\"\u003eCVPR 2016\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.umdfaces.io/\" rel=\"nofollow\"\u003eUMDFaces\u003c/a\u003e : \"UMDFaces: An annotated face dataset for training deep networks\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8272731\" rel=\"nofollow\"\u003eIJCB 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.nist.gov/programs-projects/face-challenges\" rel=\"nofollow\"\u003eIJB-B\u003c/a\u003e : \"IARPA Janus Benchmark-B Face Dataset\". (\u003cstrong\u003e\u003ca href=\"https://openaccess.thecvf.com/content_cvpr_2017_workshops/w6/html/Whitelam_IARPA_Janus_Benchmark-B_CVPR_2017_paper.html\" rel=\"nofollow\"\u003eCVPR 2017\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.nist.gov/programs-projects/face-challenges\" rel=\"nofollow\"\u003eIJB-C\u003c/a\u003e : \"IARPA Janus Benchmark - C: Face Dataset and Protocol\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8411217\" rel=\"nofollow\"\u003eICB 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"/coderonion/awesome-yolo-object-detection/blob/main\"\u003eVGGFace2\u003c/a\u003e : \"VGGFace2: A Dataset for Recognising Faces across Pose and Age\". (\u003cstrong\u003e\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8373813\" rel=\"nofollow\"\u003eFG 2018\u003c/a\u003e\u003c/strong\u003e)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eBlogs\u003c/h2\u003e\u003ca id=\"user-content-blogs\" class=\"anchor\" aria-label=\"Permalink: Blogs\" href=\"#blogs\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「IDEA数字经济研究院」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/bT_SbHlkyGaas-J6MkugPw\" rel=\"nofollow\"\u003e2024-11-22，IDEA研究院发布DINO-X目标检测视觉大模型：万物识别，开放世界\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.zhihu.com/people/nan-yang-8-13\" rel=\"nofollow\"\u003e知乎「江大白」| 微信公众号「江大白」\u003c/a\u003e\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/143747206\" rel=\"nofollow\"\u003e2020-05-27，深入浅出Yolo系列之Yolov3\u0026amp;Yolov4\u0026amp;Yolov5\u0026amp;Yolox核心基础知识完整讲解\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/172121380\" rel=\"nofollow\"\u003e2020-08-10，深入浅出Yolo系列之Yolov5核心基础知识完整讲解\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/397499216\" rel=\"nofollow\"\u003e2021-08-09，深入浅出Yolox之自有数据集训练超详细教程\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/397993315\" rel=\"nofollow\"\u003e2021-08-11，深入浅出Yolo系列之Yolox核心基础完整讲解\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/463221190\" rel=\"nofollow\"\u003e2022-01-30，深入浅出0基础入门AI及目标检测详细学习路径\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/463176500\" rel=\"nofollow\"\u003e2022-01-30，深入浅出Yolov5之自有数据集训练超详细教程\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/HqXJov5fWIlgKhMp2_Ca7g\" rel=\"nofollow\"\u003e2022-11-03，实践教程 | 在yolov5上验证的一些想法尝试\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/lm77Fe4e6e_cx_gJYhp8QA\" rel=\"nofollow\"\u003e2022-12-17，YOLOv6精度深度优化，感知量化的重参再设计\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/QZnpo24537fhGeFj7-MR_Q\" rel=\"nofollow\"\u003e2022-12-28，Repvgg重参数化，YOLO检测算法涨点实践！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/zhoFAKvFOHh0T1R2fvwZxQ\" rel=\"nofollow\"\u003e2023-01-16，YOLOv8自有数据集训练，及多任务使用详细教程\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/rDpbzIG95TmgpJQH71QY8g\" rel=\"nofollow\"\u003e2023-01-28，YOLOv8+DeepSORT原理讲解及实现（附源码）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/C3O3QeSUnu4LUBxHZtur7A\" rel=\"nofollow\"\u003e2023-02-23，深入浅出TensorRT中ONNX模型解析过程\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/AdnfJ48mnwFejTtHN4v70w\" rel=\"nofollow\"\u003e2023-02-24，模型部署 | TensorRT加速PyTorch实战部署教程，值得收藏学习！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/DZcVdwFZP3TKaTk0n98oeg\" rel=\"nofollow\"\u003e2023-02-25，YOLOv8+ByteTrack，作者开源多目标跟踪算法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/9qpuLCvgaQjc_JOdZchxjQ\" rel=\"nofollow\"\u003e2023-02-27，基于YOLOv5的半监督目标检测，算法进阶之路，阿里团队新作！（附论文及源码）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/3YnNAx_2PFqpxLUZZWoYAg\" rel=\"nofollow\"\u003e2023-03-18，Efficient Teacher，针对YOLOv5的半监督目标检测算法（附论文及源码）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qkktjhALMKgRwSSiq6n5bA\" rel=\"nofollow\"\u003e2023-03-20，onnx模型转换，op不支持时的心得经验分享\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/xyCNXUBE2rTjTUnK6bBm7g\" rel=\"nofollow\"\u003e2023-03-24，深度学习模型训练中，GPU和显存分析\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/54FaTRh8dUXwI4JqO9LAsQ\" rel=\"nofollow\"\u003e2023-03-25，PyTorch模型训练，并行加速方法梳理汇总\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/sTL6aATIDOh8RpicU2B9tA\" rel=\"nofollow\"\u003e2023-03-27，基于YOLO的铝型材表面缺陷识别 \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/fXV3rdB_YtSVap0FtK_AeQ\" rel=\"nofollow\"\u003e2023-03-31，小目标检测精度优化方式，CEASA模块，即插即用（附论文及源码）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/LCJZqnNB6C15EEMPB1X-hQ\" rel=\"nofollow\"\u003e2023-04-01，GPU 利用率低常见原因分析及优化\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/KEdsJO1z19sq7rTtwyC4Rg\" rel=\"nofollow\"\u003e2023-04-03，小目标检测算法，Yolov5优化升级 ，即插即用，值得尝试！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/3rQQ31LWxvDli_1uwGsHIw\" rel=\"nofollow\"\u003e2023-04-22，CUDA卷积算子，手写详细实现流程\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/pij3APMt_wtyS6St89lbdQ\" rel=\"nofollow\"\u003e2023-04-28，深入浅出PyTorch模型，int8量化及原理流程\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/SvgTQfKqGlI5DsrsmfKUhA\" rel=\"nofollow\"\u003e2023-04-29，AI视觉项目，图像标注工具梳理汇总\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/f-sD8ukV3Nm28_-yHi44BA\" rel=\"nofollow\"\u003e2023-05-08，Label-Studio X SAM，半自动化标注神器（附源码）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/aYam5aQXJTZ1ysubEfewYA\" rel=\"nofollow\"\u003e2023-05-09，深入浅出多目标跟踪技术的研究与探索\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/NfUWJ5cBTXvuB45l1hnSfw\" rel=\"nofollow\"\u003e2023-05-10，超强目标检测器RT-DETR，保姆级部署教程，从入门到精通（附论文及源码）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/exo2JkLluChvLDSif2JvMQ\" rel=\"nofollow\"\u003e2023-05-13，YOLOCS目标检测算法，YOLOv5的Backbone/Neck/Head全面改进\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/PkzzElN1uk2Yzu1DsYnOdQ\" rel=\"nofollow\"\u003e2023-05-17，一文看尽深度学习各种注意力机制，学习推荐！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/a9LK35lLE4yfQkqvBp6ujQ\" rel=\"nofollow\"\u003e2023-05-26，一文读懂PyTorch显存管理机制，推荐学习！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/EBc1JrR5n4BlWGBx8kuiXw\" rel=\"nofollow\"\u003e2023-06-05，两万字长文，目标检测入门看这篇就够了，推荐收藏！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/-8A_XaOwHyg653UyRbArQQ\" rel=\"nofollow\"\u003e2023-06-07，手把手带你，自己设计实现一个深度学习框架（附代码实现）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/U3irSW9UTKt0gY0HCV9slQ\" rel=\"nofollow\"\u003e2023-06-12，MMDetection目标检测框架详解，及训练自有数据集教程\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/vXIx7dBRxgxnvh5BoIRQZw\" rel=\"nofollow\"\u003e2023-06-19，万字长文，彻底搞懂YOLOv8网络结构及代码实战！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/E-Iebdd4Es5UK-TrBUJcjA\" rel=\"nofollow\"\u003e2023-06-27，TensorRT模型部署，添加自己插件的落地方式\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/znxT8nsfkq0s5NHRnAxYaw\" rel=\"nofollow\"\u003e2023-06-29，YOLOv7+Transformer部署，TensorRT应用实战（附代码）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/TQ88Oex6YTKAkUZL3kLu3A\" rel=\"nofollow\"\u003e2023-07-06，万字长文，基于PyTorch的多种卷积神经网络BackBone代码实现\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/1yvJIObEs9H4C9Qd3tb9kA\" rel=\"nofollow\"\u003e2023-07-21，万字长文，YOLOv5手势识别训练转换及模型部署！（附代码）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Phu7UmPKuSrUOhCQDV2xEQ\" rel=\"nofollow\"\u003e2023-08-03，TensorRT模型INT8量化，Python代码部署实现\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/_JDPP7Yq8E4bXxZtWlOy6Q\" rel=\"nofollow\"\u003e2023-08-12，目标检测算法，检测框位置优化总结\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/plWUuEVkbK-nDycqVDFU8A\" rel=\"nofollow\"\u003e2023-09-01，基于Yolo算法的AI数钢筋，整体解决方案汇总\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/9naZZ7wXugppelcmPHGVlQ\" rel=\"nofollow\"\u003e2024-01-26，深入浅出，YOLOv8算法使用指南\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/RVG-9h8zKsWACMr6dDRpUQ\" rel=\"nofollow\"\u003e2024-02-23，目标检测YOLOv9算法，重磅开源！（附论文及源码）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/FC9KtCPpwEraYuj4qnw_oQ\" rel=\"nofollow\"\u003e2024-04-04，CPU推理1ms的Backbone开源，精度速度碾压MobileNet/ShuffleNet等轻量模型！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/j2QS3LdudrrlyZYQkVrl5Q\" rel=\"nofollow\"\u003e2024-04-12，深入浅出，PyTorch模型int8量化原理拆解\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/UREcCHvyl7yIEv_si9KOjQ\" rel=\"nofollow\"\u003e2024-06-18，Mamba-YOLO开源，超越 YOLO ，创新SSM 技术，提升目标检测性能！（附论文及源码）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/wTwjDESVipFg2Tnh9Mgp6A\" rel=\"nofollow\"\u003e2024-07-13，YOLOv5、YOLOv8与YOLOv10，性能分析与边缘部署梳理，YOLO算法进化史！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/aYWq8CDXATrk4KAwWQqvIg\" rel=\"nofollow\"\u003e2024-09-07，YOLOv8算法模型深度解析：架构创新、性能提升与用户友好性改进！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/UQeB-Opy46bMQ1eTg1ZzRg\" rel=\"nofollow\"\u003e2025-04-14，TPAMI 2025，国防科大提出RGBT-Tiny数据集，助力小目标检测发展！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/wETR_rxbe5hYiyVLT1Qo8w\" rel=\"nofollow\"\u003e2025-04-16，TPAMI 2025，YOLOv12-BoT-SORT-ReID，无人机检测及追踪算法，问鼎无人机挑战赛（附论文与源码）\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.zhihu.com/people/nemofeng95\" rel=\"nofollow\"\u003e知乎「迪迦奥特曼」\u003c/a\u003e\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/550057480\" rel=\"nofollow\"\u003e2022-08-12，从百度飞桨YOLOSeries库看各个YOLO模型\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/566469003\" rel=\"nofollow\"\u003e2022-09-21，YOLO内卷时期该如何选模型？\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.zhihu.com/people/LEYM2\" rel=\"nofollow\"\u003e知乎「PoemAI」\u003c/a\u003e\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/539932517\" rel=\"nofollow\"\u003e2022-07-10，YOLO家族进化史（v1-v7）\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.zhihu.com/people/wang-jia-hao-53-3\" rel=\"nofollow\"\u003e知乎「科技猛兽」\u003c/a\u003e\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/183261974\" rel=\"nofollow\"\u003e2020-08-14，你一定从未看过如此通俗易懂的YOLO系列(从v1到v5)模型解读 (上)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/183781646\" rel=\"nofollow\"\u003e2020-08-21，你一定从未看过如此通俗易懂的YOLO系列(从v1到v5)模型解读 (中)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/186014243\" rel=\"nofollow\"\u003e2020-08-17，你一定从未看过如此通俗易懂的YOLO系列(从v1到v5)模型解读 (下)\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.zhihu.com/people/cvji-zhu-zhi-nan\" rel=\"nofollow\"\u003e知乎「CV技术指南」| 微信公众号「CV技术指南」\u003c/a\u003e\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/gpr7JZMRgp8B5RxhVzt_mQ\" rel=\"nofollow\"\u003e2021-08-26，目标检测mAP的计算 \u0026amp; COCO的评价指标\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/494572914\" rel=\"nofollow\"\u003e2022-04-07，YOLO系列梳理（一）YOLOv1-YOLOv3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/2lndImcah5QJJJiEujGOsA\" rel=\"nofollow\"\u003e2022-04-15，YOLO系列梳理与复习（二）YOLOv4 \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/503971609\" rel=\"nofollow\"\u003e2022-04-24，YOLO系列梳理（三）YOLOv5\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/534090250\" rel=\"nofollow\"\u003e2022-06-26，YOLO系列梳理（九）初尝新鲜出炉的YOLOv6\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/543574708\" rel=\"nofollow\"\u003e2022-07-19，YOLO系列梳理（十）YOLO官方重回江湖 并带来了YOLOv7\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/DKHOlLtjO2OBtIWlA3cpzg\" rel=\"nofollow\"\u003e2023-03-11，目标跟踪专栏（一）基本任务、常用方法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/N50tOvJwNRZhyoVq6Fc-ig\" rel=\"nofollow\"\u003e2023-04-17，目标跟踪（二）单、多目标跟踪的基本概念与常用数据集\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/wnxOd-DukIpea5j2Dqcpbw\" rel=\"nofollow\"\u003e2023-05-11，全新YOLO模型YOLOCS来啦 | 面面俱到地改进YOLOv5的Backbone/Neck/Head\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cCegxKb1VWxmhpZZwCk1WA\" rel=\"nofollow\"\u003e2024-04-16，YOLC 来袭 | 遥遥领先 ！YOLO与CenterNet思想火花碰撞，让小目标的检测性能原地起飞，落地价值极大 !\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://www.zhihu.com/org/ji-shi-jiao-14\" rel=\"nofollow\"\u003e知乎「极市平台」| 微信公众号「极市平台」\u003c/a\u003e\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://zhuanlan.zhihu.com/p/297965943\" rel=\"nofollow\"\u003e2020-11-17，YOLO算法最全综述：从YOLOv1到YOLOv5\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/31Fb3WSBtRUNu8oUkMrBrg\" rel=\"nofollow\"\u003e2022-08-04，华为轻量级神经网络架构GhostNet再升级，GPU上大显身手的G-GhostNet（IJCV22）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/SQ-ojaRlinLY5PsLTZhz2w\" rel=\"nofollow\"\u003e2022-10-17，Backbone篇｜YOLOv1-v7全系列大解析\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/RBpC-0HqzgtHy5xsoBce8Q\" rel=\"nofollow\"\u003e2022-11-15，NeurIPS'22 Spotlight｜华为诺亚GhostNetV2出炉：长距离注意力机制增强廉价操作\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/mV2Bl4tBZwZ7n-YleMUE4g\" rel=\"nofollow\"\u003e2022-11-21，轻量级的CNN模块！RepGhost：重参数化技术构建硬件高效的 Ghost 模块\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/HAfCpECOxccPfj5b7Pprfw\" rel=\"nofollow\"\u003e2023-02-26，厦大纪荣嵘团队新作｜OneTeacher: 解锁 YOLOv5 的正确打开方式\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/2Md30QdqgWnWwVR7d4sx1Q\" rel=\"nofollow\"\u003e2023-04-18，Repvgg-style ConvNets，硬件友好！详解YOLOv6的高效backbone：EfficientRep\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/UMA3Vk9L71zUEtNkCshYBg\" rel=\"nofollow\"\u003e2023-04-19，CVPR23 Highlight｜拥有top-down attention能力的vision transformer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/JYsJRo8l5-nTFrGwBV-BFA\" rel=\"nofollow\"\u003e2023-04-26，万字长文，深度全面解读PyTorch内部机制\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/VG9itVaOwCpmb48ZAa8Mjw\" rel=\"nofollow\"\u003e2023-05-28，YOLOv10开源｜清华用端到端YOLOv10在速度精度上都生吃YOLOv8和YOLOv9\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/raTAXapLK0mquvC1c6S2Iw\" rel=\"nofollow\"\u003e2023-10-27，「项目经验掏心窝」第二期：真实上手算法开发后的经验总结\u0026amp;心得体会\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/UawQkuRqo-phGvtbC5stQg\" rel=\"nofollow\"\u003e2024-12-03，注意力机制比矩阵分解更好吗？\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「WeThinkln」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/JLYFP8IA7RcIMSeBKekQlw\" rel=\"nofollow\"\u003e2022-09-18，【Make YOLO Great Again】YOLOv1-v7全系列大解析（输入侧篇）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/nEWL9ZAYuVngoejf-muFRw\" rel=\"nofollow\"\u003e2022-07-31，【Make YOLO Great Again】YOLOv1-v7全系列大解析（Neck篇）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/JDaSWyNdLoHc6j6cOmNIWw\" rel=\"nofollow\"\u003e2022-08-14，【Make YOLO Great Again】YOLOv1-v7全系列大解析（Head篇）（尝鲜版）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/85Xh4l_t65HrGx25ByD_iw\" rel=\"nofollow\"\u003e2022-08-28，【Make YOLO Great Again】YOLOv1-v7全系列大解析（Head篇）（完整版）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/T76JkDf82ZPF5WWVDvJ6GA\" rel=\"nofollow\"\u003e2022-10-16，【Make YOLO Great Again】YOLOv1-v7全系列大解析（Backbone篇）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/xJDMKcS9SRQIWKCAbUpMaQ\" rel=\"nofollow\"\u003e2022-11-13，【Make YOLO Great Again】YOLOv1-v7全系列大解析（Tricks篇）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/etaaojeNv8lbBy586FjtQw\" rel=\"nofollow\"\u003e2022-12-11，【Make YOLO Great Again】YOLOv1-v7全系列大解析（汇总篇）\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「GiantPandaCV」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/tZ7swUd0biz7G3CiRkHHfw\" rel=\"nofollow\"\u003e2022-10-26，One-YOLOv5 发布，一个训得更快的YOLOv5\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/N2Xp4IKJAATCmmmQqQ6new\" rel=\"nofollow\"\u003e2022-12-04，One-YOLOv5 v1.1.0发布，大幅优化Eager FP32单卡性能\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qR2ODIMidsNR_Eznxry5pg\" rel=\"nofollow\"\u003e2022-10-28，《YOLOv5全面解析教程》一，网络结构逐行代码解析\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qDNjLKhkjDT54l06SQ_yEA\" rel=\"nofollow\"\u003e2022-11-06，《YOLOv5全面解析教程》二，YOLOv5数据集结构解析\u0026amp;如何制作一个可以获得更好训练效果的数据集\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/1DYz8sp1xR91rr7Q5_X4Qw\" rel=\"nofollow\"\u003e2022-11-10，《YOLOv5全面解析教程》三，IoU深入解析\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/n6ziYYc3BBsobcRkMS9tsQ\" rel=\"nofollow\"\u003e2022-11-12，《YOLOv5全面解析教程》四，目标检测模型精确度评估\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/i8Ygm9BCWNQfyBya7f1Z8Q\" rel=\"nofollow\"\u003e2022-11-18，《YOLOv5全面解析教程》五，计算mAP用到的numpy函数详解\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/B1q_XsvXpf-fI3vDedoWjA\" rel=\"nofollow\"\u003e2022-11-20，《YOLOv5全面解析教程》六，YOLOv5使用教程详解（单卡，多卡，多机训练）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/6UvHK0bRxHGk__B8YMQhiw\" rel=\"nofollow\"\u003e2022-11-22，《YOLOv5全面解析教程》七，使用模型融合提升mAP和mAR\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/UoPY_0E0D5g0R5o5eVmbdA\" rel=\"nofollow\"\u003e2022-11-27，《YOLOv5全面解析教程》八，将训练好的YOLOv5权重导出为其它框架格式\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/4jOg6De01Yxl1uW-v9Zydg\" rel=\"nofollow\"\u003e2022-11-29，《YOLOv5全面解析教程》九，train.py 逐代码解析\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/CZ1btWU9cpbJWC2eVLBVQQ\" rel=\"nofollow\"\u003e2022-12-07，《YOLOv5全面解析教程》十，YOLOv5 的 W \u0026amp; B 科学实验工具教程\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/uouLlV1G35L8_DQaUm8ogg\" rel=\"nofollow\"\u003e2022-12-08，《YOLOv5全面解析教程》十一，YOLOv5 数据增强模块 utils/augmentations.py 逐行解析\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/WfXSQFHgF6Ouwq5re4n1Vw\" rel=\"nofollow\"\u003e2022-12-14，《YOLOv5全面解析教程》​十二，Loss 计算详细解析\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Efa44D7PiwaZkN0jlf4R_w\" rel=\"nofollow\"\u003e2022-12-29，《YOLOv5全面解析教程》​十三，downloads.py 详细解析\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qC-E2UbjNZT-c04IpXfoYA\" rel=\"nofollow\"\u003e2023-01-10，《YOLOv5全面解析教程》​十四，YOLOv5 autoanchor 机制详解\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/osGwscIawS9q07g21rTQcA\" rel=\"nofollow\"\u003e2023-02-07，《YOLOv5全面解析教程》​十五，YOLOv5 Callback机制解读\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/sa2MQIaPIkHHxoVRGYMTAw\" rel=\"nofollow\"\u003e2023-02-18，《YOLOv5全面解析教程》​十六，val.py 源码解读\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/gF_qfXPMvPKWGNoEFdnpHw\" rel=\"nofollow\"\u003e2023-04-24，简单聊聊目标检测新范式RT-DETR的骨干：HGNetv2\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「PandaCVer」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/1iP4H3Ri6uBkq24eOO-viw\" rel=\"nofollow\"\u003e2022-10-18，改进YOLOv5——魔改YOLOv5提升检测精度\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/X6MIRbE4ZD9xA-c-UtAa_A\" rel=\"nofollow\"\u003e2022-10-23，目标检测算法——YOLOv5\u0026amp;无参SimAM！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/NVkHPBv8Ps2fCB2QvNz59Q\" rel=\"nofollow\"\u003e2022-10-25，目标检测算法——YOLOv5改进结合BotNet（Transformer）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/4KmjOSGAHHFdp6jYZI_QFw\" rel=\"nofollow\"\u003e2022-10-27，目标检测算法——YOLOv5/YOLOv7更换FReLU激活函数\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/CdNvKCL6fsQD012zrzZNFA\" rel=\"nofollow\"\u003e2022-10-29，目标检测算法——YOLOv5/YOLOv7改进之GSConv+Slim Neck\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/vnqnNW5y47XThOmodEWHYA\" rel=\"nofollow\"\u003e2022-11-02，目标检测算法——YOLOv5/YOLOv7改进之结合CBAM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/9gGOO66I1kFpyZcRayjF_Q\" rel=\"nofollow\"\u003e2022-11-07，目标检测算法——YOLOv5/YOLOv7改进之结合GAMAttention\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ETkGaGNLx5VqJVSCSsTJNw\" rel=\"nofollow\"\u003e2022-11-08，人工智能前沿——深度学习热门领域（确定选题及研究方向）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ithO0S7R-D8kXH1ZQlpRRQ\" rel=\"nofollow\"\u003e2022-11-10，目标检测算法——YOLOv5/YOLOv7改进之结合​SOCA（单幅图像超分辨率）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/QgL2UxbVvXwrfmGxK7uolQ\" rel=\"nofollow\"\u003e2022-11-12，目标检测算法——YOLOv5/YOLOv7改进之结合​ASPP（空洞空间卷积池化金字塔）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/4TnHyiG88h5oDhD6NZoq2Q\" rel=\"nofollow\"\u003e2022-11-16，目标检测算法——YOLOv5/YOLOv7改进之结合​RepVGG（速度飙升）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/9qTFFu7HImaF8t6ozG_NWw\" rel=\"nofollow\"\u003e2022-11-20，知识经验分享——YOLOv5-6.0训练出错及解决方法（RuntimeError）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qB8G_pf3oCYBstYyFPrcrw\" rel=\"nofollow\"\u003e2022-11-23，目标检测算法——YOLOv5/YOLOv7改进之结合NAMAttention（提升涨点）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/v3pOvqz6ZewPR3fjnA5SIg\" rel=\"nofollow\"\u003e2022-11-25，目标检测算法——YOLOv5/YOLOv7改进之结合Criss-Cross Attention\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cFzcJLOG_1_TzS-Ckg6hGA\" rel=\"nofollow\"\u003e2022-11-29，目标检测算法——YOLOv7改进|增加小目标检测层\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/RwthaHf5d7-dT31Cqco6MA\" rel=\"nofollow\"\u003e2022-11-14，目标检测算法——收藏|小目标检测的定义（一）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/E2ZRBPZjobhlLspJK_DTfA\" rel=\"nofollow\"\u003e2022-11-17，目标检测算法——收藏|小目标检测难点分析（二）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/nuIfgFX_krLtN9EQGNrn2w\" rel=\"nofollow\"\u003e2022-11-18，目标检测算法——收藏|小目标检测解决方案（三）\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「人工智能AI算法工程师」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/mi4BIyITyifl7QRhAKqPjg\" rel=\"nofollow\"\u003e2023-03-25，投稿指南：目标检测论文写作模板（初稿）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/QwY5C2y7HZ6LPRHC5gScFg\" rel=\"nofollow\"\u003e2022-06-26，YOLOv5改进之一：添加SE注意力机制\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/pFQEH4zpYogDOMdMQqugcg\" rel=\"nofollow\"\u003e2022-07-11，YOLOv5改进之二：添加CBAM注意力机制\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/NzN88Vtkb3rVjsyPi60edQ\" rel=\"nofollow\"\u003e2022-07-13，YOLOv5改进之三：添加Coordinate注意力机制\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/4tnD0OZrOn0RdRSY-1XAxw\" rel=\"nofollow\"\u003e2022-07-14，YOLOv5改进之四：添加ECA通道注意力机制\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/CgvdOqRC9JLrWa4mIDT_zA\" rel=\"nofollow\"\u003e2022-07-15，YOLOv5改进之五：改进特征融合网络PANET为BIFPN\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/0IsvGgxhE5USP0c37HzeAQ\" rel=\"nofollow\"\u003e2022-07-16，YOLOv5改进之六：增加小目标检测层\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/0U4Y_ZEI2YvW1sMHxRfwMQ\" rel=\"nofollow\"\u003e2022-07-17，YOLOv5改进之七：损失函数改进\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Q35jjU6qCKhwsVpF_JkFGw\" rel=\"nofollow\"\u003e2022-07-18，YOLOv5改进之八：非极大值抑制NMS算法改进Soft-nms\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/8tfw3l_qy8IyKKh3njsN_w\" rel=\"nofollow\"\u003e2022-07-19，YOLOv5改进之九：锚框K-Means算法改进K-Means++\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/JMbiPaQKHwIULKLE2jeQNA\" rel=\"nofollow\"\u003e2022-07-20，YOLOv5改进之十：损失函数改进为SIOU\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/b3v2zNU4Ek6eO5AajuPI5A\" rel=\"nofollow\"\u003e2022-07-21，YOLOv5改进之十一：主干网络C3替换为轻量化网络MobileNetV3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/9E9U64Wl8C02etSE19Q1iw\" rel=\"nofollow\"\u003e2022-07-27，YOLOv5改进之十二：主干网络C3替换为轻量化网络ShuffleNetV2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/SIqZyXfpx67uRxL7OSHqDg\" rel=\"nofollow\"\u003e2022-07-28，YOLOv5改进之十三：主干网络C3替换为轻量化网络EfficientNetv2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/IVR6kJodBWStFcVoVHArEw\" rel=\"nofollow\"\u003e2022-07-31，YOLOv5改进之十四：主干网络C3替换为轻量化网络Ghostnet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/l3F9vGE2DHxz2otrlM1kfw\" rel=\"nofollow\"\u003e2022-08-01，YOLOv5改进之十五：网络轻量化方法深度可分离卷积\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/sHCpHtgcMurvgaXjnQX5HQ\" rel=\"nofollow\"\u003e2022-08-03，YOLOv5改进之十六：主干网络C3替换为轻量化网络PP-LCNet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/-hEjujFJuK5V-i9jX00iFw\" rel=\"nofollow\"\u003e2022-08-04，YOLOv5改进之十七：CNN+Transformer——融合Bottleneck Transformers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/5mwBdny3xI4vZajfZ_KxjQ\" rel=\"nofollow\"\u003e2022-08-05，YOLOv5改进之十八：损失函数改进为Alpha-IoU损失函数\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/rW9FuDdpNVnO8yQbRon58g\" rel=\"nofollow\"\u003e2022-08-06，YOLOv5改进之十九：非极大值抑制NMS算法改进DIoU NMS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cn7uQtcPN3S_CHJc_INZaQ\" rel=\"nofollow\"\u003e2022-08-07，YOLOv5改进之二十：Involution新神经网络算子引入网络\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/D21iFLFTMFfM--vsfh0T5w\" rel=\"nofollow\"\u003e2022-08-08，YOLOv5改进之二十一：CNN+Transformer——主干网络替换为又快又强的轻量化主干EfficientFormer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qq0M1yaCUysp5L3xap6t9g\" rel=\"nofollow\"\u003e2022-08-09，YOLOv7改进之二十二：涨点神器——引入递归门控卷积（gnConv）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/AfrIRsNDAbwfVzdz8XwgFw\" rel=\"nofollow\"\u003e2022-08-24，YOLOv7改进之二十三：引入SimAM无参数注意力\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/O78PFirnfdfuGlmQRpf9rw\" rel=\"nofollow\"\u003e2022-08-27，YOLOv7改进之二十四：引入量子启发的新型视觉主干模型WaveMLP\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/s4RfXjW17mxUSIuK9QvTxg\" rel=\"nofollow\"\u003e2022-09-03，YOLOv7改进之二十五：引入Swin Transformer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Ty8Eo_qbJZMxjTULVVi-xA\" rel=\"nofollow\"\u003e2022-09-19，YOLOv5、v7改进之二十六：改进特征融合网络PANet为ASFF自适应特征融合网络\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/o23-u-B2I23bttzp14FJTg\" rel=\"nofollow\"\u003e2022-09-21，YOLOv5、v7改进之二十七：解决小目标问题——校正卷积取代特征提取网络中的常规卷积\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/-wH_N4-pXY08XdbJ-Iu8zA\" rel=\"nofollow\"\u003e2022-09-24，YOLOv5、v7改进之二十八：ICLR 2022涨点神器——即插即用的动态卷积ODConv\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/9g-JMK44YQDd3feTBwCYjA\" rel=\"nofollow\"\u003e2022-10-08，YOLOv5、YOLOv7改进之二十九：v2.0版本的Swin Transformer 融入\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Y2kOLVbU5ZnNzPIoiv4voA\" rel=\"nofollow\"\u003e2022-10-13，YOLOv5、YOLOv7改进之三十：引入10月4号发表最新的Transformer视觉模型MOAT结构\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/sSZfmjJHS3USGkqFd5N-Nw\" rel=\"nofollow\"\u003e2022-10-14，YOLOv5、v7改进之三十一：CrissCrossAttention注意力机制\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/fgTTylKkDe36Z45MxMV_ig\" rel=\"nofollow\"\u003e2022-10-16，YOLOv5、v7改进之三十二：SKAttention注意力机制\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Tl5q7TEEPphXvzWQM_f61Q\" rel=\"nofollow\"\u003e2022-10-17，YOLOv5、v7改进之三十三：引入GAMAttention注意力机制\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/k1FIIcaEZxSjuR6aRzotHg\" rel=\"nofollow\"\u003e2022-10-18，YOLOv5、v7改进之三十四：更换激活函数为FReLU\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/rFe2pex6-YsUpRj8K-pw3g\" rel=\"nofollow\"\u003e2022-10-19，YOLOv5、v7改进之三十五：引入NAMAttention注意力机制\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/5MuJiodqJ4ixOSdogr5ebw\" rel=\"nofollow\"\u003e2022-10-20，YOLOv5、v7改进之三十六：引入S2-MLPv2注意力机制\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/f9rjpRkeqBCWeTFkadLZpQ\" rel=\"nofollow\"\u003e2022-10-21，YOLOv5、v7改进之三十七：结合CVPR2022新作ConvNeXt网络\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/7UhjzSwjR2U2h-FC7ZFbCw\" rel=\"nofollow\"\u003e2022-10-22，YOLOv5、v7改进之三十八：引入最新RepVGG\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/X0f0MLhDYMrMZzx72vyGPg\" rel=\"nofollow\"\u003e2022-10-23，YOLOv5、v7改进之三十九：引入改进遮挡检测的Tri-Layer插件 | BMVC 2022\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/rHTYQW5aRucVe8MoWUlA4Q\" rel=\"nofollow\"\u003e2022-10-27，YOLOv5、v7改进之四十：轻量化mobileone主干网络引入\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/TrB7-B-ppU2JkuQ5G46a8Q\" rel=\"nofollow\"\u003e2022-11-01，YOLOv5、v7改进之四十一：引入SPD-Conv处理低分辨率图像和小对象问题\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cg4KinN-vEhcnoiQlN_tfw\" rel=\"nofollow\"\u003e2022-11-02，YOLOv5改进之四十二：引入V7中的ELAN网络，降低网络参数\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/P9TCtm6d_x6sRXtENTwY_A\" rel=\"nofollow\"\u003e2022-11-03，YOLOv7、v5改进之四十三：结合最新Non-local Networks and Attention结构\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/vS7Lm73tgVbQZ6WdKT9J4Q\" rel=\"nofollow\"\u003e2022-11-19，YOLO系列改进之四十四——融入适配GPU的轻量级 G-GhostNet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/akrldqppGT6oyf89BnJe2Q\" rel=\"nofollow\"\u003e2022-11-10，目标检测论文解读复现之一：基于改进YOLOv5的整车原木数量检测方法——TWD-YOLOv5\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/fOAzM-1_b29B79E8gxTP1Q\" rel=\"nofollow\"\u003e2022-11-12，目标检测论文解读复现之二：基于改进YOLOv5的轻量化航空目标检测方法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/6R9g3D2Xd-TZJ_DAiRcBzQ\" rel=\"nofollow\"\u003e2022-11-14，目标检测论文解读复现之三：基于改进YOLOv7的X光图像旋转目标检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/LcImelrj1hbRHlP_QvLd6g\" rel=\"nofollow\"\u003e2022-11-15，目标检测论文解读复现之四：改进YOLOv5算法在停车场火灾检测中的应用\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/UwmamMFM0jnzt1sG-CX6iQ\" rel=\"nofollow\"\u003e2022-11-16，目标检测论文解读复现之五：改进YOLOv5的SAR图像舰船目标检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Qnw_krVnZGxlWUgG8z6q_g\" rel=\"nofollow\"\u003e2022-11-17，目标检测论文解读复现之六：基于YOLOv5的遥感图像舰船的检测方法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/jZI93jPaLtsCFK-kljjppw\" rel=\"nofollow\"\u003e2022-11-20，目标检测论文解读复现之七：基于SE-YOLOv5s的绝缘子检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/47YVYj4svWnkbPrvrfOqmw\" rel=\"nofollow\"\u003e2022-11-21，目标检测论文解读复现之八：基于YOLOv5s的滑雪人员检测研究\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/8VUZ5RX84krFgBdCO7qMhQ\" rel=\"nofollow\"\u003e2022-11-22，目标检测论文解读复现之九：基于改进YOLOv5的复杂场景下SAR图像船舶检测方法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/xEzrjEe8CGfgdttJevFbFw\" rel=\"nofollow\"\u003e2022-11-23，目标检测论文解读复现之十：基于YOLOv5的遥感图像目标检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/uPwcji5mGSstxI9gWnAXCQ\" rel=\"nofollow\"\u003e2022-11-25，目标检测论文解读复现之十一：基于特征融合与注意力的遥感图像小目标检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Ii98povs_xjfUdSxe2WYsQ\" rel=\"nofollow\"\u003e2022-11-26，目标检测论文解读复现之十二：基于注意力机制和上下文信息的目标检测算法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/MByqnwl2YiujOCyWrgMMKg\" rel=\"nofollow\"\u003e2022-11-27，目标检测论文解读复现之十三：改进YOLOv5s的遥感图像目标检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/M2ilkFpP5VwBHa2bY8BLyw\" rel=\"nofollow\"\u003e2022-12-12，目标检测论文解读复现之十四：一种基于残差网络优化的航拍小目标检测算法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qy0hMDcPyKsl5p28E7q30w\" rel=\"nofollow\"\u003e2022-12-13，目标检测论文解读复现之十五：基于YOLOv5的光学遥感图像舰船目标检测算法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Z-FIlLzVE9obCM-YdtGpxg\" rel=\"nofollow\"\u003e2022-12-14，目标检测论文解读复现之十六：基于改进YOLOv5的小目标检测算法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cQHDZkvyw7bYMRCaXUcPKQ\" rel=\"nofollow\"\u003e2022-12-15，目标检测论文解读复现之十七：融合注意力机制的YOLOv5口罩检测算法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Kxe6CGs8hR6vrYgagMVdPQ\" rel=\"nofollow\"\u003e2022-12-16，目标检测论文解读复现之十八：基于注意力机制的光线昏暗条件下口罩佩戴检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/67KIqrl1xSFzUmI6vjjAkw\" rel=\"nofollow\"\u003e2022-12-17，目标检测论文解读复现之十九：基于YOLOv5网络模型的人员口罩佩戴实时检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/2TXXKXsWFDJG2t48rPWGqQ\" rel=\"nofollow\"\u003e2022-12-18，目标检测论文解读复现之二十：基于改进Yolov5的地铁隧道附属设施与衬砌表观病害检测方法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qlVnBh2FFw5yBOvCsP2G-g\" rel=\"nofollow\"\u003e2022-12-19，目标检测论文解读复现之二十一:基于改进YOLOv7的小目标检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/LH7IqfyXLGbmRXCq_SxDJQ\" rel=\"nofollow\"\u003e2022-12-20，目标检测论文解读复现之二十二：多尺度下遥感小目标多头注意力检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qe_LV_8W4hzUxxgax2O4_g\" rel=\"nofollow\"\u003e2023-01-16，YOLOv7/YOLOv5系列改进之四十四：融入YOLOv8中的C2f模块\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/HwPwI-nwl8elbiZfDsqHKg\" rel=\"nofollow\"\u003e2023-01-17，YOLOv7/YOLOv5系列改进之四十五：融入CFPNet网络中的ECVBlock模块，提升小目标检测能力\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/B0WVnNYrRDXcX0pw_2cLjg\" rel=\"nofollow\"\u003e2023-01-18，学习经验分享之十三：首发全网讲解YOLOv8\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Zrth5ANIYOrjVaU0p2eRZQ\" rel=\"nofollow\"\u003e2023-01-24，【目标检测论文解读复现NO.25】基于改进Yolov5的地铁隧道附属设施与衬砌表观病害检测方法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/URWmI6OVVtDkvxSEfroVVg\" rel=\"nofollow\"\u003e2023-01-25，【目标检测论文解读复现NO.26】基于改进YOLOv5s网络的实时输液监测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/nToaAvSgSViP4pQrD_Gfgg\" rel=\"nofollow\"\u003e2023-01-28，基于改进YOLOv5的螺纹钢表面缺陷检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/mtMA87mMQGLA2f4jXlXiUw\" rel=\"nofollow\"\u003e2023-01-30，【目标检测论文解读复现NO.28】基于改进YOLO v5的电厂管道油液泄漏检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/_tDSg2J3JopTBjQtawnycg\" rel=\"nofollow\"\u003e2023-01-31，【目标检测论文解读复现NO.29】基于YOLO-ST的安全帽佩戴精确检测算法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/UYdTR8axfUSCFEOiTN5wMw\" rel=\"nofollow\"\u003e2023-02-03，【目标检测论文解读复现NO.30】基于改进YOLOv5的宁夏草原蝗虫识别模型研究\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/fMfsXIJ6v2cC18eWjrIbKw\" rel=\"nofollow\"\u003e2023-02-05，【目标检测论文解读复现NO.31】基于改进YOLO v5复杂场景下肉鹅姿态的检测算法研究\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/jycEm-pwYhMkihvfS66YIg\" rel=\"nofollow\"\u003e2023-02-04，【目标检测论文解读复现NO.32】基于改进YOLO的飞机起降阶段跟踪方法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/WvHoB5zSPPH1SHRahMLL8g\" rel=\"nofollow\"\u003e2023-03-04，【YOLOv8/YOLOv7/YOLOv5系列算法改进NO.55】融入美团最新QARepVGG\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/T_v7QM_9P20vT5mjFg07xw\" rel=\"nofollow\"\u003e2023-03-07，【YOLOv8/YOLOv7/YOLOv5系列算法改进NO.56】引入Contextual Transformer模块\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/XVl6o2-xK8BfT4BWbmqxxA\" rel=\"nofollow\"\u003e2023-03-10，【YOLOv8/YOLOv7/YOLOv5/YOLOv4/Faster-rcnn系列算法改进NO.57】引入可形变卷积\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/GgN_Y9Kxkz0YP7dxtoMUsA\" rel=\"nofollow\"\u003e2023-03-14，【YOLOv8/YOLOv7/YOLOv5/YOLOv4/Faster-rcnn系列算法改进】引入DRconv动态区域感知卷积\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/_YjOXjxggHGPLg9T5bE2YQ\" rel=\"nofollow\"\u003e2023-03-15，【YOLOv8/YOLOv7/YOLOv5/YOLOv4/Faster-rcnn系列算法改进NO.59】引入ASPP模块\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/YgR-hc1aimba3ij9tfaBAw\" rel=\"nofollow\"\u003e2023-03-30，【YOLOv8/YOLOv7/YOLOv5/YOLOv4系列算法改进】结合NeurIPS 2022年GhostnetV2网络模块\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/JqDIRqM5XAMzqz-Un2yw8Q\" rel=\"nofollow\"\u003e2023-04-08，YOLOv8/YOLOv7/YOLOv5/YOLOv4算法-结合CVPR 2023 即插即用动态稀疏注意力BiFormer模块\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/4Xu9UIwcpgGvqOkXVDhoYA\" rel=\"nofollow\"\u003e2023-05-05，英文论文（sci）解读复现：基于注意机制的改进YOLOv5s目标检测算法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/D2yC4Qiztg1FH64f89iJ_A\" rel=\"nofollow\"\u003e2023-05-10，英文论文（sci）解读复现：基于注意机制和感受野的YOLOv5在唐卡图像缺陷识别中的应用\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/T6VWbQJOWoE3kVTQp0cf7w\" rel=\"nofollow\"\u003e2023-06-10，算法改进：针对遥感图像目标检测中的小目标进行改进CATnet（ContextAggregation模块）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/itgOWmlFID6KwDfiOcQ9Ag\" rel=\"nofollow\"\u003e2023-06-27，YOLOv8/YOLOv7/YOLOv5/YOLO/Faster-rcnnv4系列算法改进：注意力机制（EMA）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/sdZq3AGcqc4rVywqaEmlYw\" rel=\"nofollow\"\u003e2023-07-18，YOLOv8/YOLOv7/YOLOv5/YOLOv4/Faster-rcnn系列算法改进：添加渐近特征金字塔网络\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/7_6wCWbjqLsv09pd_m2NIQ\" rel=\"nofollow\"\u003e2023-07-27，中科大提出PE-YOLO | 让YOLO家族算法直击黑夜目标检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/hKdFzeEvgOI-IkZebDxORQ\" rel=\"nofollow\"\u003e2023-07-28，YOLOv8/YOLOv7/YOLOv5/YOLOv4等系列算法改进：改进边框位置回归损失函数（MPDIoU损失函数）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qXFQeYOrdBNWEblVgodcfg\" rel=\"nofollow\"\u003e2023-07-31，远超YOLOP | 超轻超快的TwinLiteNet实现多任务自动驾驶感知\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/0ZT4YxAInMAy_3dy5YJ5-A\" rel=\"nofollow\"\u003e2024-05-22，YOLOv8算法改进【NO.132】利用HCANet中具有全局和局部信息的注意力机制CAFM进行DEA-Net形成二次创新模块\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ua3vW4MSdWk0Mc15q3bvJg\" rel=\"nofollow\"\u003e2024-05-23，YOLOv9/YOLOv8算法改进【NO.133】2024年最新MobileNetV4轻量算法作为YOLO算法的主干特征提取网络\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「所向披靡的张大刀」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/q308cHT0XliCK3NtIRjyqA\" rel=\"nofollow\"\u003e2022-04-24，【小白入坑篇】目标检测的评价指标map\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/DFSROue8InARk-96I_Kptg\" rel=\"nofollow\"\u003e2022-07-02，【yolov6系列】细节拆解网络框架\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/VEcUIaDrhc1ETIPr39l4rg\" rel=\"nofollow\"\u003e2022-07-13，【yolov7系列】网络框架细节拆解\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/nhZ3Q1NHm3op8abdVIGmLA\" rel=\"nofollow\"\u003e2022-07-23，【yolov7系列二】正负样本分配策略\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/S80mMimu4YpHwClHIH07eA\" rel=\"nofollow\"\u003e2022-07-29，【yolov7系列三】实战从0构建训练自己的数据集\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/kt3iIuOD3lsZBTIbOSGN0g\" rel=\"nofollow\"\u003e2022-10-23，万字长文解析cv中的注意力机制\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/YiK5kT-Yd-9k_V_aiSVYqw\" rel=\"nofollow\"\u003e2022-11-23，yolov5的持续发力|分类任务\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/JrkRpIgTDtq6WN-hM8NwSA\" rel=\"nofollow\"\u003e2023-07-12，算法部署服务实战--代码篇\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「集智书童」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/5SeD09vG6nv46-YuN_uU1w\" rel=\"nofollow\"\u003e2022-07-07，YOLOv7官方开源 | Alexey Bochkovskiy站台，精度速度超越所有YOLO，还得是AB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/clupheQ8iHnhR4FJcTtB8A\" rel=\"nofollow\"\u003e2022-07-27，YOLOU开源 | 汇集YOLO系列所有算法，集算法学习、科研改进、落地于一身！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/2XErHzw9hWrrBry9Ij2pjA\" rel=\"nofollow\"\u003e2022-09-25，连夜卷出 | 超越所有YOLO检测模型，mmdet开源当今最强最快目标检测模型！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/l3fzlPzMFIxXK18rhqX-kg\" rel=\"nofollow\"\u003e2023-01-09，YOLOv8来啦 | 详细解读YOLOv8的改进模块！YOLOv5官方出品YOLOv8，必卷！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/rIi1XBUh_SZuNqKz473tcQ\" rel=\"nofollow\"\u003e2023-01-10，从标注到部署，MMYOLO 保姆级教程！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/vUXOX71rcqb3IzDca0nKVQ\" rel=\"nofollow\"\u003e2023-01-13，YOLOv8实践 | 手把手教你用YOLOv8训练自己的数据集以及YOLOv8的多任务使用\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/AClsBD7jJPDUjJ_svwRplQ\" rel=\"nofollow\"\u003e2023-01-16，YOLOv8 + DeepSORT | YOLO与DeepSORT跟踪的难分难舍，直接用吧（附源码）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/8TS70TpbqgQ5GB37zVgERA\" rel=\"nofollow\"\u003e2023-02-01，YOLO涨点Trick | 超越CIOU/SIOU，Wise-IOU让Yolov7再涨1.5个点！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/BK3IRiJdKfPE53KFpvjTCg\" rel=\"nofollow\"\u003e2023-02-17，EdgeYOLO来袭 | Xaiver超实时，精度和速度完美超越YOLOX、v4、v5、v6\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/m09WRKRqC1bngCOzip_hFA\" rel=\"nofollow\"\u003e2023-02-22，YOLOv5抛弃Anchor-Base方法 | YOLOv5u正式加入Anchor-Free大家庭\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/p_c0w43ns7rFOzamtOSPVg\" rel=\"nofollow\"\u003e2023-03-08，全新剪枝框架 | YOLOv5模型缩减4倍，推理速度提升2倍\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/vgg_m80A06xFWQGgw2WhHg\" rel=\"nofollow\"\u003e2023-03-31 ，小目标检测 | 即插即用 | YOLOv5可以这样升级\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/L-TpXpBJI7y0wKmBr9arjQ\" rel=\"nofollow\"\u003e2023-03-14，实践教程｜TensorRT中对ONNX模型解析过程\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/spEL2hYmYykkQkc4aNxJAg\" rel=\"nofollow\"\u003e2023-03-24，目标检测Trick | SEA方法轻松抹平One-Stage与Two-Stage目标检测之间的差距\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/-a4Wz04jLHFiAU88pUyDNQ\" rel=\"nofollow\"\u003e2023-03-30，即插即用 | CEASA模块给你所有，小目标精度提升的同时速度也变快了\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/3_2Dcm8VpoGFksFZE6n2kQ\" rel=\"nofollow\"\u003e2023-04-05，部署技巧之PAGCP剪枝 | Yolov5/ResNet参数降低50%速度翻倍精度不减\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/-AtF3B_A0rzvS8cUcZQ6Hw\" rel=\"nofollow\"\u003e2023-04-12，Faster RCNN超快版本来啦 | TinyDet用小于1GFLOPS实现30+AP，小目标炸裂\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/lsOQiq9wXHxagE_uQ_yOiw\" rel=\"nofollow\"\u003e2023-04-13，即插即用模块 | RFAConv助力YOLOv8再涨2个点\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/V3MUXinJhpq8J4UWTUL17w\" rel=\"nofollow\"\u003e2023-04-19，YOLO超快时代终结了 | RT-DETR用114FPS实现54.8AP，远超YOLOv8\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/FlKgYYGUHtJAxCF2wrh4NA\" rel=\"nofollow\"\u003e2023-04-21，基于YOLOv5改进再设计 | M2S全面提升小目标精度\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/4eE5kWGF5FekHHCZOg9rNA\" rel=\"nofollow\"\u003e2023-06-06，一文全览 | 2023最新环视自动驾驶3D检测综述！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/kdxz3zn77031MDNxVm_k0Q\" rel=\"nofollow\"\u003e2023-06-21，AI模型部署实战 | 利用CV-CUDA加速视觉模型部署流程\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/kaAoqp-8af0bUA7byYKKPA\" rel=\"nofollow\"\u003e2023-07-20，Q-YOLOP来啦 | 一个具有量化感知全景驾驶感知模型\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/F0ZV9yTW8_UHJrvNew8qOA\" rel=\"nofollow\"\u003e2023-07-29，TensorRT部署系列 | 如何将模型从 PyTorch 转换为 TensorRT 并加速推理？\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/AzwdSKNs8SnIIRsdG0cZAg\" rel=\"nofollow\"\u003e2023-08-03，YOLO落地部署 | 一文全览YOLOv5最新的剪枝、量化的进展【必读】\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/erkyca0OtJoyXAXI_I6RmQ\" rel=\"nofollow\"\u003e2023-08-11，YOLOD也来啦 | 优化YOLOv5样本匹配，顺带设计了全新的模块\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/B1iFf936wAORB53QboTXjg\" rel=\"nofollow\"\u003e2023-09-05，YOLO 与 BEV 以及3D目标检测算法究竟应该怎么才可以更好的落地？\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Fj6wzARTo1l7UEwKxDAh6w\" rel=\"nofollow\"\u003e2024-02-01，太强！AI没有落下的腾讯出YOLO-World爆款 | 开集目标检测速度提升20倍，效果不减\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/8Lkl3aMwjESRyeZfLMu7Tw\" rel=\"nofollow\"\u003e2024-02-14，YOLOPoint开源 | 新年YOLO依然坚挺，通过结合YOLOv5\u0026amp;SuperPoint，成就多任务SOTA\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/A_BABGHKp5Icdmlk3q3lIA\" rel=\"nofollow\"\u003e2024-02-23，Focaler-IoU开源 | 高于SIoU+关注困难样本，让YOLOv5再涨1.9%，YOLOv8再涨点0.3%\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/31NlBknx4PcXipfuV2w6hw\" rel=\"nofollow\"\u003e2024-02-23，YOLOv9开源 | 架构图\u0026amp;模块改进\u0026amp;正负样本匹配\u0026amp;损失函数解读，5分钟即可理解YOLOv9\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/2Hlp_zaHN8TKyzk-1f1yjw\" rel=\"nofollow\"\u003e2024-03-18，D-YOLO解决落地困难 | 关注特征融合模块+无雾特征子网络，让YOLO家族无惧雨雾和风雪\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/6UzdFFKeNOCLK8YdhPYCaQ\" rel=\"nofollow\"\u003e2024-04-15，YOLC 来袭 | 遥遥领先 ！YOLO与CenterNet思想火花碰撞，让小目标的检测性能原地起飞，落地价值极大 !\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/6h7FY0U4hwbpOQ6AkH4IEg\" rel=\"nofollow\"\u003e2024-12-14，高效小目标识别，多帧运动检测与YOLO结合提高 UAV 检测精度 !\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「计算机视觉研究院」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Ytr1m2EOJMWF6WmHDmai2A\" rel=\"nofollow\"\u003e2022-10-30，YoloV：视频中目标实时检测依然很棒（附源代码下载）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/JVr1C9nPTYlHS4aei-Zqrg\" rel=\"nofollow\"\u003e2022-11-04，改进的YOLO：AF-FPN替换金字塔模块提升目标检测精度\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/0_sF3U232i0PEw1NHE2Efw\" rel=\"nofollow\"\u003e2022-12-31，Micro-YOLO：探索目标检测压缩模型的有效方法（附论文下载）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cQo7HMcWcbZgk7XIzj1q2A\" rel=\"nofollow\"\u003e2023-02-25，使用ONNXRuntime部署阿里达摩院开源DAMO-YOLO目标检测，一共包含27个onnx模型(代码开源)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/g8yUdF0SP-81VpVfFjTqNw\" rel=\"nofollow\"\u003e2023-04-03，CVPR 2023 论文分类汇总：一个专为计算机视觉领域研究者打造的学术资源宝库\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/xMq10ZZQnFyXaob0H-Z1qw\" rel=\"nofollow\"\u003e2023-04-07，Micro-YOLO：探索目标检测压缩模型的有效方法（附论文下载）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ny98FTagPQB1-GnHKFu2MA\" rel=\"nofollow\"\u003e2023-04-07，实用教程详解：模型部署，用DNN模块部署YOLO目标检测（附源代码）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/FPG44PhAxNi7cy_ALcNXmA\" rel=\"nofollow\"\u003e2023-04-20，全自动实时移动端AI框架 | YOLO-v4目标检测实时手机端实现\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/5sTxdjhKIPpQ-rCsWfe80A\" rel=\"nofollow\"\u003e2023-04-22，CVPR目标检测新框架：不再是YOLO，而是只需要一层特征（干货满满，建议收藏）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/wK-5i30X06SfLgASlRdqJw\" rel=\"nofollow\"\u003e2023-04-25，GPT-CV：基于Yolov5的半监督目标检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/zEFjvUKnrm5Iwa6e9Fy29Q\" rel=\"nofollow\"\u003e2023-04-25，EdgeYOLO：边缘设备上实时运行的目标检测器及Pytorch实现\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/xocZNuIOCgGynjZxX_xKgw\" rel=\"nofollow\"\u003e2023-04-26，改进的YOLO：AF-FPN替换金字塔模块提升目标检测精度\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/FqBq9gy-NKfp3W2qgKHb5w\" rel=\"nofollow\"\u003e2023-06-22，RestoreDet：低分辨率图像中目标检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/N4x0_Bu078g1zSMIDPwzZg\" rel=\"nofollow\"\u003e2023-07-12，GPT理解的CV：基于Yolov5的半监督目标检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ODIFRyvfbZOiEORLdWGc_A\" rel=\"nofollow\"\u003e2023-07-12，YoloV8与ChatGPT互通，这功能是真的强大！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/-G2TpQOOhLyYDw5wPODBkw\" rel=\"nofollow\"\u003e2023-07-24，YOLO-S预告：一种用于小目标检测的轻量级、精确的类YOLO网络\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/e0EJVHKW7nkfkMVurMgR2Q\" rel=\"nofollow\"\u003e2023-08-20，Yolo框架优化：黑夜中也可以实时目标检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ztdYjDbWzpx2LnWTiVWdrQ\" rel=\"nofollow\"\u003e2023-09-04，CRAS-YOLO：多类别船舶检测与分类模型\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/X4HGQhWaxy1bQssrQIYBmQ\" rel=\"nofollow\"\u003e2023-09-04，Drone-YOLO：一种有效的无人机图像目标检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/BaqXo4uTeqoY5FhD2jVuxA\" rel=\"nofollow\"\u003e2023-09-05，BFD-YOLO：基于YOLOv7的建筑外墙缺陷检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/damt3VWade0we1MSCe9_QA\" rel=\"nofollow\"\u003e2024-05-26，Yolov10：详解、部署、应用一站式齐全！\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「新机器视觉」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/0ALtok0vleMif-5_rgCycQ\" rel=\"nofollow\"\u003e​2023-03-22，YOLO系列的演进，从v1到v7\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/_aVWQ-NxGwZthA_D_drTRw\" rel=\"nofollow\"\u003e2023-03-23，​YOLO系列的演进，从v1到v7（二）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Ngz7SYEtQ8jsejKG0IknXg\" rel=\"nofollow\"\u003e2023-03-24，YOLO系列的演进，从v1到v7（三）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/UaqBSCWnGbLLCuy8cvJpkQ\" rel=\"nofollow\"\u003e2023-05-20，机器视觉和模式识别库汇总\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「OpenMMLab」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ZK1hzp6QJarS1xiqkBWcrg\" rel=\"nofollow\"\u003e2022-10-20，社区协作，简洁易用，快来开箱新一代 YOLO 系列开源库\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/iF2Upd2ThMBlWPim8Gj13g\" rel=\"nofollow\"\u003e2023-03-28，建议收藏！超实用的 YOLO 训练\u0026amp;测试技巧合集\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/_RNmB3KtYEt7UuDsCOJ3rQ\" rel=\"nofollow\"\u003e​2023-01-12，YOLOv8 深度详解！一文看懂，快速上手\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ilCMYZmG_XpvJ_ysB1cgkw\" rel=\"nofollow\"\u003e2023-04-04，显著提升模型精度！以 MMYOLO 为例 ，巧用 MMRazor 轻量级骨干网络\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「自动驾驶之心」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/M47rwwbU0FRrgd-Xg9c7ww\" rel=\"nofollow\"\u003e2022-10-26，手把手教学！TensorRT部署实战：YOLOv5的ONNX模型部署\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/FFRsxSaTeGvs1ssKGCD6lg\" rel=\"nofollow\"\u003e2022-11-12，SSDA-YOLO：用于跨域目标检测的半监督域自适应YOLO方法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/QYsCzgMhW9Mfsa6CYolVuQ\" rel=\"nofollow\"\u003e2022-11-30，达摩院 | DAMO-YOLO：兼顾速度与精度的新目标检测框架\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/WRVjub3ePxWoCBQXKhS__w\" rel=\"nofollow\"\u003e2022-12-23，通用小目标Trick | 深度学习检测小目标常用方法盘点\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/esGe2o3_pPXUlrysZoCQKQ\" rel=\"nofollow\"\u003e2023-01-12，纯量产经验 | 谈谈目标检测中正负样本的问题\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/EHTXisVDv7SV4UEbo7sdbQ\" rel=\"nofollow\"\u003e2023-05-15，最新！自动驾驶中用于目标检测和语义分割的Radar-Camera融合综述\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/79DskdwwSghyldvQF43l6A\" rel=\"nofollow\"\u003e2023-05-19，25FPS！英伟达首发BEVFusion部署源代码，边缘端实时运行！！！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/AhPaSVl2Gh8zWtJ74IUyzw\" rel=\"nofollow\"\u003e2023-05-21，保姆级开源教程 | 手把手教你部署FreeYOLO\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/i3lLadD3_Q5RX5D0JUocPQ\" rel=\"nofollow\"\u003e2023-05-29，最新SOTA！BEVFusion4D：BEVFusion升级版3D检测时空新框架！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/sEWfs2C62cuThZBXSM0fZA\" rel=\"nofollow\"\u003e2023-06-04，万字长文 | Transformer在BEV、2D/3D检测上的应用、量化与加速！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/WjBvj6hCWEYs7IL9DlrK2Q\" rel=\"nofollow\"\u003e2023-06-15，全搞定！基于TensorRT的CNN/Transformer/检测/BEV模型四大部署代码+CUDA加速！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/KsPb80tf_zxPyP0xu8ZmHA\" rel=\"nofollow\"\u003e2023-08-23，模型部署，今年的香饽饽！TensorRT详细入门指北\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/8pceyAzzGvwKNnRE9OJEOA\" rel=\"nofollow\"\u003e2024-01-10，YOLO进军BEV感知！YOLO+BEV在实时检测上的尝试\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「CVHub」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/22rRzyZj93-Y4msYwa_LKQ\" rel=\"nofollow\"\u003e2023-01-07，现代目标检测故事 | 40+种网络架构大盘点！从基础架构ResNet到最强检测器Yolov7再到最新部署神器GhostNetV2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/B0yHtFMTO5gwt0B-ra18QA\" rel=\"nofollow\"\u003e2023-02-19，阿里团队新作 | 探讨 YOLOv5 的高效进阶之路！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/W56LHZbZEqqoCPFVf612FA\" rel=\"nofollow\"\u003e2023-05-05，超强目标检测器 RT-DETR | Python/C++ 保姆级部署教程，从入门到精通\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qPbxjDuPOFSD2zsWAGmLQw\" rel=\"nofollow\"\u003e2023-06-04，中科院一区顶刊 TCSVT 2023 | DIAL-Filters: 显著提升模糊夜视场景下的检测和分割性能！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Us7IiYXFtUoQJ6btpcG1lw\" rel=\"nofollow\"\u003e2023-07-12，北航新作 | Q-YOLO: 基于 TensorRT 和 OpenVIVO 的目标检测量化实战方案\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Jl2mr7tszulZX19Fx4ZNgw\" rel=\"nofollow\"\u003e2023-07-30，大连理工联合阿里达摩院发布HQTrack | 高精度视频多目标跟踪大模型\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/foF9JDyAIk5pLN5F_6dw2g\" rel=\"nofollow\"\u003e2024-03-24，SeeClick: 手把手教你如何基于Qwen-VL搭建一个多模态智能体！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/IfOCnuvFCTIzKIQEFWFLdA\" rel=\"nofollow\"\u003e2024-09-30，Ultrylytics 官宣: YOLO11 全新发布！\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「人工智能感知信息处理算法研究院」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/GJza38BBYTl6XAWiiEzpHA\" rel=\"nofollow\"\u003e2023-06-15，改进YOLOV5小目标检测之VisDrone2019数据集\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/BXueTqerYFtGg9MOhJ7YYA\" rel=\"nofollow\"\u003e2023-06-16，改进YOLOV5小目标检测之数据预处理之一\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/NblhcYo-JWZuJkMS5015sw\" rel=\"nofollow\"\u003e2023-06-17，改进YOLOV5小目标检测之数据预处理之二\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/3_03EmF0wo4hmbes5o37NQ\" rel=\"nofollow\"\u003e2023-06-22，改进YOLOV5小目标检测消融实验之一\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/iEEGkLFICJT03kXWQwR_sA\" rel=\"nofollow\"\u003e2023-06-23，改进YOLOV5小目标检测消融实验之二\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ZIH6Y1d6yeUV-zE6AnEvuQ\" rel=\"nofollow\"\u003e2023-07-04，基于改进YOLOv5和可变形卷积的水下群体目标检测概述之一\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ptkTsyG2_mOFb6lGUCSkVA\" rel=\"nofollow\"\u003e2023-07-05，基于改进YOLOv5和可变形卷积的水下群体目标检测概述之二\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/XSBtVbtcQTrMf13E_HEeWw\" rel=\"nofollow\"\u003e2023-07-07，YOLOV5算法改进之自适应阈值模块\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/-0ZsO9D4o4UXuIy_a2gt0w\" rel=\"nofollow\"\u003e2023-07-10，改进YOLOV5算法之不同数据集测试\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/KIxhlNBuTnCLnqzKqD_GPA\" rel=\"nofollow\"\u003e2023-07-11，改进YOLOV5算法与同类算法的比较\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/WffWRa6MzaRN4oMF3BvOWg\" rel=\"nofollow\"\u003e2023-07-12，改进YOLOV5自适应阈值模块实验分析 \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/rYrdJPHYE57Kc8QzVDxUfg\" rel=\"nofollow\"\u003e2023-07-15，KAYOLO网络模型\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/x1WRIC9MNQWMTup9XHkwWg\" rel=\"nofollow\"\u003e2023-07-19，Yolov8n-IOU损失函数的改进\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/KnLwHIWqespSxO0v82cJ3A\" rel=\"nofollow\"\u003e2023-07-26，YOLOV7算法原理\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/9dwrXEAi5tht4-tNyZ4tYw\" rel=\"nofollow\"\u003e2023-07-30，Flask 部署 YOLOV5\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cX1WlVJqDNePZW18Jlf_Kg\" rel=\"nofollow\"\u003e2023-08-13，目标检测算法的应用\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「OneFlow」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/qfZIKgBdHNwPDp5ng0Y_Qw\" rel=\"nofollow\"\u003e2022-12-13，YOLOv5全面解析教程①：网络结构逐行代码解读\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/t4Ppf2qokpClRwCN52zF-g\" rel=\"nofollow\"\u003e2022-12-22，YOLOv5全面解析教程②：如何制作训练效果更好的数据集\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/LIOnJqJj_GrpakKbLeWEDQ\" rel=\"nofollow\"\u003e2023-02-02，YOLOv5全面解析教程③：更快更好的边界框回归损失\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/nvfAU6TwTDoZhF8zFpCaOw\" rel=\"nofollow\"\u003e2023-02-17，YOLOv5全面解析教程④：目标检测模型精确度评估\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ag7PkcRRSTppEG0GOysqpg\" rel=\"nofollow\"\u003e2023-02-24，YOLOv5全面解析教程⑤：计算mAP用到的Numpy函数详解\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/RriWDozw7ZHTBg7Rr38dNw\" rel=\"nofollow\"\u003e2023-03-09，YOLOv5全面解析教程⑥：模型训练流程详解\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/6PjD5k5o1GQO8v7jIydZ_w\" rel=\"nofollow\"\u003e2023-05-23，YOLOv5全面解析教程⑦：使用模型融合提升mAP和mAR\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/4yiN7JZrvAvMi4m5eusbMw\" rel=\"nofollow\"\u003e2023-05-23，YOLOv5全面解析教程⑧：将训练好的YOLOv5权重导为其它框架格式\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「AIWalker」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/E-TNeTKK5EV70zAenRVbwQ\" rel=\"nofollow\"\u003e2023-03-29，ChatGPT是如何看待YOLO系列算法的贡献呢？\u003cdel\u003e哈哈\u003c/del\u003e \u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/FsWSRguAn2WZKtmPhMbc6g\" rel=\"nofollow\"\u003e2023-05-07，YOLO-NAS | YOLO新高度，引入NAS，出于YOLOv8而优于YOLOv8\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Wk1sHIQKUe01PqMnpzcCfQ\" rel=\"nofollow\"\u003e2023-05-16，全网唯一复现！手机端 1ms 级延迟的主干网模型 MobileOne\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/FfG9vNM_a2k_zflWfuimsw\" rel=\"nofollow\"\u003e2023-08-15，南开大学提出YOLO-MS | 超越YOLOv8与RTMDet，即插即用打破性能瓶颈\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/yepStVzyrOE4MsgFFuwo0Q\" rel=\"nofollow\"\u003e2024-02-19，U版YOLO-World来了，YOLOv8再度升级，三行代码上手YOLO-World\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/tFavH5_Sqtnq1_NMRt_AUg\" rel=\"nofollow\"\u003e2024-02-23，YOLOv9来了，可编程梯度信息与广义高效层聚合网络 助力全新检测SOTA前沿\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「董董灿是个攻城狮」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/pA86udkaFzCogi2Qw8vBEA\" rel=\"nofollow\"\u003e2023-03-20，万字长文解析Resnet50的算法原理\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/3aNVGIPf5pLzEv67KI8M5w\" rel=\"nofollow\"\u003e2023-04-17，万字长文入门神经网络硬件加速\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/VlrglazJE54Xnm3tjM0uCg\" rel=\"nofollow\"\u003e2023-04-19，CUDA卷积算子手写详细实现\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「计算机视觉漫谈」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/EElv2Tc73JKS8jpejEGB1w\" rel=\"nofollow\"\u003e2020-02-22，YOLO v3实战之钢筋数量AI识别（一）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/lOeRqD2orcLw5FR496r4uw\" rel=\"nofollow\"\u003e2020-03-07，YOLO v3实战之钢筋智能识别改进方案分享（二）\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「智造情报局」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/IzMabvYts2BEa5IvAwUfrg\" rel=\"nofollow\"\u003e2022-11-07，项目实操：基于yolov5的PCB表面缺陷检测【附完整代码】\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「学姐带你玩AI」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/52Woexamu697tozevSiyQQ\" rel=\"nofollow\"\u003e2022-11-21，YOLOv5+Tesseract-OCR 实现车牌号文本识别【实战】\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「量子位」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/_ccYfjWm6CsH_vxpACUWEA\" rel=\"nofollow\"\u003e2023-01-12，YOLOv8已至，精度大涨！教你如何在自定义数据集上训练它\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「笑傲算法江湖」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/i_bF6_77MxKqEy7-y7LQdQ\" rel=\"nofollow\"\u003e2023-02-08，代码实战：YOLOv5实现钢材表面缺陷检测\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「OpenCV中文网」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/wF93AAVnGsQtHdB-DkSTPQ\" rel=\"nofollow\"\u003e2023-04-07，YOLOv8 全家桶再迎新成员！新增Pose Estimation模型!\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「深度学习与计算机视觉」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/vthdOoy3etZmybMLaGzoFg\" rel=\"nofollow\"\u003e2023-03-28，使用 YOLO 进行目标检测：如何提取人物图像\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「机器学习算法工程师」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/wgBaZ-CTB7B4nvYnobMDvw\" rel=\"nofollow\"\u003e2023-04-19，惊呆了！基于Transformer的检测模型RT-DETR竟然比YOLO还快！\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「计算机视觉与机器学习」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/oflfbPkhj3ka2ExK7ZZ0VA\" rel=\"nofollow\"\u003e2023-04-19，RT-DETR | 吊打YOLO系列的 DETR部署教程来啦，优雅而简洁！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/XwmQILnaLtWPfo-dysLeAA\" rel=\"nofollow\"\u003e2023-05-16，超强目标检测器 RT-DETR | Python/C++ 保姆级部署教程，从入门到精通\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「人工智能前沿讲习」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/FtVd37tOXMfu92eDSvdvbg\" rel=\"nofollow\"\u003e2023-04-19，【源头活水】CVPR 2023 | AbSViT：拥有自上而下注意力机制的视觉Transformer\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「AI科技与算法编程」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ofokLwCwgN1GNTqy3NuYmg\" rel=\"nofollow\"\u003e2023-04-11, YOLOv8 AS-One：目标检测AS-One 来了！（YOLO就是名副其实的卷王之王）\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「深度学习与NLP」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/RmM9ay4arJWBoNP11Bfbsw\" rel=\"nofollow\"\u003e2023-04-24，[万字干货]-如何给模型加入先验知识？\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「OpenCV与AI深度学习」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/NrT7aFurdz5IRr3bCFsHQA\" rel=\"nofollow\"\u003e2023-04-23，基于 YOLOv8 的自定义数据集训练\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/HldcdtBXzh5YawcS0Bb4KQ\" rel=\"nofollow\"\u003e2023-06-19，一文彻底搞懂YOLOv8【网络结构+代码+实操】\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/g6jEP5Y2R_DhrI30DBol5Q\" rel=\"nofollow\"\u003e2023-07-04，保姆教程 | YOLOv5在建筑工地中安全帽佩戴检测的应用\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/3WSmGP7xdQJc-5YdQXBPFg\" rel=\"nofollow\"\u003e2024-06-05，实战 | YOLOv10 自定义数据集训练实现车牌检测 (数据集+训练+预测 保姆级教程)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/xZ4HlfBPXFbf8OPxmXwbrQ\" rel=\"nofollow\"\u003e2024-06-21，YOLOv10在PyTorch和OpenVINO中推理对比\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/VcUifHycY9aw99d3WD1h1w\" rel=\"nofollow\"\u003e2024-07-08，实战 | YOLOv8使用TensorRT加速推理教程（步骤 + 代码）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/o-AECBLDucxVLr1Q0yxZ_g\" rel=\"nofollow\"\u003e2024-07-10，OpenCV使用CUDA加速资料汇总(pdf+视频+源码)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/S_yjuxHb8PD3B472mvizfg\" rel=\"nofollow\"\u003e2024-09-30，YOLOv11来了：将重新定义AI的可能性\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「嵌入式视觉」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/m4gZ1beM8QRzNegFPf3Mbg\" rel=\"nofollow\"\u003e2023-04-28，深度学习模型压缩方法概述\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/7BCQD1s_1AZJoowivTnxOg\" rel=\"nofollow\"\u003e2023-05-12，模型压缩-剪枝算法详解\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「机器学习算法那些事」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/4EFTj6RxOCvX2Wn5euhSAQ\" rel=\"nofollow\"\u003e2023-05-02，labelGo：基于 YOLOv5 的辅助标注工具\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「人工智能技术与咨询」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Mic_wLbfjQrtX7wLwW1SiA\" rel=\"nofollow\"\u003e2023-05-19，基于YOLOv5的光学遥感图像舰船目标检测算法\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/pBXUnMpSmLg1BTDrJ19tgQ\" rel=\"nofollow\"\u003e2023-06-06，面向弹载图像的深度学习网络压缩方法研究\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「StrongerTang」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/g3KpWyc0QpLseN5-0CKySQ\" rel=\"nofollow\"\u003e2022-10-07，自动驾驶多模态融合感知详解（研究现状及挑战）\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「北京大学王选计算机研究所」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/anth7mIqTGpJ4QWvTDbiSQ\" rel=\"nofollow\"\u003e2022-10-12，NeurIPS 2022 | 面向自动驾驶多模态感知的激光雷达-相机融合框架\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「计算机视觉深度学习和自动驾驶」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/maKDU3sXbPxlEFz372qZTA\" rel=\"nofollow\"\u003e2022-05-31，BEVFusion: 基于统一BEV表征的多任务多传感器融合\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「内推君SIR」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/3pUMSOq4-eS2N7WNtbv02A\" rel=\"nofollow\"\u003e2023-07-28，面经 | 计算机视觉 面经22\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「古月居」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/UshIczcC8l7eHNf2CSrMKw\" rel=\"nofollow\"\u003e2023-07-06，YOLOv5训练自己的数据集(超详细)\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「Streamlit」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/I1HQ_E4UerZLkDT2-ch2SQ\" rel=\"nofollow\"\u003e2023-05-18，Streamlit+Opencv打造人脸实时识别功能\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「FightingCV」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/smwx-Ievs3rWMw_D4lSwqg\" rel=\"nofollow\"\u003e2022-08-17，YOLOAir | 面向小白的目标检测库，更快更方便更完整的YOLO库\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/bCUMjzc-Ws0_qjusFjM5Xw\" rel=\"nofollow\"\u003e2023-07-29，自动驾驶新方法登Nature封面：让黑夜如白昼般清晰，浙大博士一作\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「AILab笔记」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/zCbFEl8pvPIfjnfIgv8Hqw\" rel=\"nofollow\"\u003e2023-06-08，【文献】视觉transformer研究进展——史上最全综述\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「CVer」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/t7jlTyUP6UxplpythX0dOw\" rel=\"nofollow\"\u003e2023-08-02，ICCV 2023｜目标检测新突破！AlignDet：支持各类检测器完全自监督预训练的框架\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「我爱计算机视觉」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/jWZuNKpVM4k5aDe2JmB-Tg\" rel=\"nofollow\"\u003e2023-06-09，[实践]YOLOv5提升10倍推理速度：利用TensorRT 在Jetson NX上的模型部署\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/LhodjnA87KrmqXV1ioUIng\" rel=\"nofollow\"\u003e2025-01-08，开放词汇检测新晋SOTA：地瓜机器人开源DOSOD实时检测算法\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「英特尔物联网」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/DTXVXwf_tPxwsWbSxBv9Sw\" rel=\"nofollow\"\u003e2022-08-11，基于 OpenVINO™️ 2022.1 POT API 实现 YOLOv5 模型 INT8 量化 | 开发者实战\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「数据科学与AI」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/v4y-vjsUrlow5EaP_VrF0A\" rel=\"nofollow\"\u003e2023-06-22，Win10环境下OpenVINO部署YOLOv5模型：从理论到实践\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「郭小喵玩AI」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/v4y-vjsUrlow5EaP_VrF0A\" rel=\"nofollow\"\u003e2023-06-22，Win10环境下OpenVINO部署YOLOv5模型：从理论到实践\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/KdoZnQArI95eWvqHMeqO0A\" rel=\"nofollow\"\u003e2023-09-04，超详细 | 使用Yolov8训练自己的数据集\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「郭小喵玩AI」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/CroC5jiTh6OXGtFUbWLZwQ\" rel=\"nofollow\"\u003e2023-02-13，如何用OpenVINO™让YOLOv8获得1000+ FPS性能？\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「AI视界引擎」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ypL9_QYcCFjxpdF9CrS2dw\" rel=\"nofollow\"\u003e2023-08-20，Fast-BEV的CUDA落地 | 5.9ms即可实现环视BEV 3D检测落地！代码开源\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/sDOtseu4icePW2oQObMoWQ\" rel=\"nofollow\"\u003e2024-01-03，Shape-IoU开源 | 同时关注Box形状和尺寸，完美超越SIoU/EIoU/CIoU等，YOLO又有福了\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/N-5nYylqOTx7tEISJYOuuw\" rel=\"nofollow\"\u003e2024-01-19，YOLOv4与卷积注意力以及ViT结合的进化版本YOLO-Former，精度稳步提升！\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「小白玩转Python」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/L_-Ii5QvnGgJwo5WYSUcVg\" rel=\"nofollow\"\u003e2023-12-22，基于 YOLOv8 的疲劳状态检测 | 附源码\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/pc7TzlZSULNJwIS-liCdzg\" rel=\"nofollow\"\u003e2024-01-22，YOLO-NAS 如何将 YOLO-v8 甩在身后？\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/42TqNGeaYpoZLBvBmeeAkg\" rel=\"nofollow\"\u003e2024-04-28，小目标检测实战\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「机器之心」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/HFyADfWKkyw0TivsqH6kXA\" rel=\"nofollow\"\u003e2024-02-23，目标检测新SOTA：YOLOv9问世，新架构让传统卷积重焕生机\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「码科智能」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cWRObjaRvL6RgabSdSxVBQ\" rel=\"nofollow\"\u003e2024-01-30，模型部署系列：10x速度提升，YoloV8目标检测模型稀疏化—CPU上超500FPS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/u4QBbOeNR48aF9YHWdCQsw\" rel=\"nofollow\"\u003e2024-02-19，基于YOLO-World+EfficientSAM的零样本目标检测与实例分割Demo\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/TAv_GY3d-tPOX9fKZNBwig\" rel=\"nofollow\"\u003e2024-02-23，YOLOv9来了! 抛开损失函数和网络结构，换个可编程梯度信息角度继续升级，目标检测新SOTA！\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「自动驾驶Daily」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/1i76NbtC5DD1lPMIMa9f8w\" rel=\"nofollow\"\u003e2024-02-23，YOLOv9终于来了！远超现有实时目标检测器！使用PGI学你想学！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/xxgvub-Y4RJLjbpY6YNxCQ\" rel=\"nofollow\"\u003e2024-05-25，YOLOv10来啦！真正实时端到端目标检测\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「3D视觉工坊」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Fbd-jarVO4LyjlhdxgmnsA\" rel=\"nofollow\"\u003e2024-02-23，YOLOv9震撼来袭！使用可编程梯度信息学习你想学习的内容！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/MeFXqAyU_OAGnh7qEIb3yQ\" rel=\"nofollow\"\u003e2024-06-18，YOLO跌落神坛？Mamba YOLO干翻YOLO系列模型！\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「DeepDriving」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/IQTCUs8CcfgHxJCyV6cm3w\" rel=\"nofollow\"\u003e2023-07-21，AI模型部署 | TensorRT模型INT8量化的Python实现\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/w0Ss9vcseNCEoK2UWugCNw\" rel=\"nofollow\"\u003e2024-05-29，YOLOv10来啦！ONNX模型部署和性能对比了解一下\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「CSharp与边缘模型部署」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/yijeZtkRhbQxuSE1AsyUhA\" rel=\"nofollow\"\u003e2024-06-04，使用 TensorRT C++ API 调用GPU加速部署 YOLOv10 实现 500FPS 推理速度——快到飞起！！\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「BestSongC」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/STAVjII8kAk3MMPbB9vJfQ\" rel=\"nofollow\"\u003e2024-05-24，基于YOLO系列算法（YOLOv5、YOLOv6、YOLOv8以及YOLOv9）和Streamlit框架的行人头盔检测系统\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Cuhwf2exVWFmoyZPQE_HmQ\" rel=\"nofollow\"\u003e2024-05-29，基于YOLO系列算法YOLOv5、YOLOv6、YOLOv8以及YOLOv9和Streamlit框架的工人头盔和安全背心检测系统\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ZIH1afBpKBa5DgvtHZU1Vg\" rel=\"nofollow\"\u003e2024-05-30，基于YOLO系列算法和Streamlit框架的六类水果目标检测系统\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cEhgZYp7rUBFz2BukacQQg\" rel=\"nofollow\"\u003e2024-06-11，基于YOLO系列算法（YOLOv5、YOLOv6、YOLOv8)以及YOLOv9）和Streamlit框架的五类动物目标检测系统\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/zPNGWQGNWDaMJHjxzlhRGA\" rel=\"nofollow\"\u003e2024-08-18，基于YOLO系列算法和Streamlit框架的车载摄像头下车辆检测系统\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「人工智能学习指南」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/JlGvYGvPa5NyxjEXHLO6uA\" rel=\"nofollow\"\u003e2024-05-28，用自己的数据集实测YOLOv10效果！\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「跨模态AGI」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/ASahqSAHoMFvRvBlnq5OzQ\" rel=\"nofollow\"\u003e2024-06-12，YOLO-NAS：开启实时目标检测新纪元\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/JMPBJfMhUHg0472javPlpg\" rel=\"nofollow\"\u003e2024-07-02，YOLOv10：实时目标检测的新星，引领AI视觉识别新纪元\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/WGMNf4u8bA-t534avapJQw\" rel=\"nofollow\"\u003e2024-07-05，揭秘YOLO-World：颠覆传统，开启实时开放词汇检测新时代\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「魔方AI空间」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/yQlkvlYnCz1H3JWTXCKc_A\" rel=\"nofollow\"\u003e2024-05-26，CV再放大招 | YOLOv10：毫秒级实时端到端目标检测开源模型\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/1DYhy-flED1HwUX8YCQUPg\" rel=\"nofollow\"\u003e2024-07-03，2万字长文｜YOLOv10的起源：YOLO系列的十年全面综述【YOLOv1-YOLOv10】(建议收藏)\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「槿墨AI」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/2DkhzmEllF5tom9FWHPz3g\" rel=\"nofollow\"\u003e2024-06-05，清华接棒YOLOv10开源，卷出毫秒级实时检测！\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/XQh4MxPwfsWzDnUoiW4jww\" rel=\"nofollow\"\u003e2024-06-12，【超全解读】Drone-YOLO：无人机图像中的实时目标检测\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「计算机视觉工坊」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/64HnNUs7r133hTFsmgWpEA\" rel=\"nofollow\"\u003e2024-06-21，目标检测的极限在哪里？LW-DETR：干翻YOLOv10！\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「遥感与深度学习」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/FqFDS2Ih0uA9nuWMpbBDEA\" rel=\"nofollow\"\u003e2024-06-28，论文赏读 | 结合YOLOv9和Mamba的遥感小目标检测\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/Td-hwr-4UkIUheF7RJAi7Q\" rel=\"nofollow\"\u003e2024-07-11，论文赏读 | Mamba YOLO: 基于SSM的YOLO 用于目标检测\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「算法美食屋」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/A1TCBqRJxXWzZKG1_KauMA\" rel=\"nofollow\"\u003e2024-06-08，30分钟吃掉pytorch转onnx及推理\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「人工智能学起来」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/xbUKj3mHOyou5KpCi-04xw\" rel=\"nofollow\"\u003e2024-06-25，小目标检测重大进展！速度提升10倍，GPU内存占用少73.4％\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「柴火创客空间」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/uzvWMoMndwPmyLyDMnDqOQ\" rel=\"nofollow\"\u003e2023-04-07，边缘计算 | 英伟达Jetson设备上的YOLOv8性能基准测试\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「小小cv笔记」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/0wOmtfkQNt9VpdlOPHgnkA\" rel=\"nofollow\"\u003e2024-08-12，微小目标检测中基于相似距离的标签分配(arxiv2024）\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「阿旭算法与机器学习」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/GUmql-aIgiFuJ9ll6dFucg\" rel=\"nofollow\"\u003e2024-06-28，【YOLOv8模型onnx部署详解】YOLOv8模型转onnx格式并使用onnxruntime 进行推理部署\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/3ZkVmxpIcB036mAvvYWbow\" rel=\"nofollow\"\u003e2024-10-14，YOLOv11与YOLOv8详细对比分析：mAP、Speed、Params、FLOPs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/K-kvKCl_yNclL8qTOrgCFA\" rel=\"nofollow\"\u003e2024-10-29，YOLO发展历程以及YOLOv8详解:基本架构、创新点与应用领域\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/cnpmKr04E1imBBnmx6VTQw\" rel=\"nofollow\"\u003e2024-11-19，【模型级联】YOLO-World与SAM2通过文本实现指定目标的零样本分割\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/gnoknU8iBjfbLo77vIbasw\" rel=\"nofollow\"\u003e2024-11-23，超详细！YOLO11模型架构详解、性能对比\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/-1q0SMdUkklGu7PsrOKpGQ\" rel=\"nofollow\"\u003e2024-11-24，【深度好文】目标检测技术深度剖析：发展历程、关键技术、常用目标检测算法说明及应用\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/dH5wFyOhevz37Lt4frVp0w\" rel=\"nofollow\"\u003e2024-12-02，【实战】使用GroundingDino实现零样本自动标注【附源码】\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/KTL-NeFO-eVmSm2RaLxYsw\" rel=\"nofollow\"\u003e2024-12-04，【实战教程】小目标检测利器：使用YOLOv8和SAHI进行视频检测，检测效果真心不错\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/LOD1xCKY08HVraxM-UDxvQ\" rel=\"nofollow\"\u003e2024-12-07，【实战教程】使用YOLOv8 OBB进行旋转框目标检测的数据集定义与训练【附源码】\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「人工智能与图像处理」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/lfulLTp5SDrpim7nU1ZebA\" rel=\"nofollow\"\u003e2023-05-26，目标检测算法-YOLOV5解析（附论文与源码）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/bG8KkDhs0ex8QZYS6QO5NA\" rel=\"nofollow\"\u003e2023-05-27，目标检测算法-YOLOV6解析（附论文与源码）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/58XnV1Dy-1gc1ZYuY1XsVQ\" rel=\"nofollow\"\u003e2023-05-28，目标检测算法-YOLOV7解析（附论文与源码）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/QwQhpEFX4Pxfik7PNOpwIA\" rel=\"nofollow\"\u003e2023-05-29，目标检测算法-YOLOV8解析（附论文和源码）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/u8x6ePRmWV6z_FFnGUfUYA\" rel=\"nofollow\"\u003e2024-04-13，目标检测算法-YOLOV9解析（附论文和源码）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/3fffqlYLit30dI34TRZ5dw\" rel=\"nofollow\"\u003e2024-10-28，模型轻量化之模型剪枝-Pruning\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「地瓜机器人」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/IroAN_R7IvIxKHw8i-_1XQ\" rel=\"nofollow\"\u003e2023-12-28，技术敲黑板 | 基于地平线RDK X3高效部署YOLOv5\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/zq4wLfEP3k5cns7xK4iSOg\" rel=\"nofollow\"\u003e2024-06-27，技术敲黑板 | YOLOv8目标检测算法在地平线RDK X3上高效部署\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「深度AI视野」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/jYPJ5JsJL0LWSlXMkvzBtA\" rel=\"nofollow\"\u003e2025-01-07，Yolo11框架解析与代码重构—开篇\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「PandaCVer」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/8eDJ86rPA-0cWnLQKHxfjw\" rel=\"nofollow\"\u003e2022-11-01, 目标检测算法——行人检测\u0026amp;人群计数数据集汇总(附下载链接)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/oRmPDF1YhIqYYdrgU7sTUQ\" rel=\"nofollow\"\u003e2022-11-21, 目标检测算法——工业缺陷数据集汇总1（附下载链接）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/9tGzWDAxp--42ofmKLlJRg\" rel=\"nofollow\"\u003e2022-12-01, 目标检测算法——图像分类开源数据集汇总（附下载链接）\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「自动驾驶之心」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/dCwtc-DI0KaPB4meJqewwA\" rel=\"nofollow\"\u003e2023-03-27, 目标跟踪方向开源数据集资源汇总\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/A-4ze7B3yQ-AYCe0DgHv-A\" rel=\"nofollow\"\u003e2023-04-12, 包罗万象！V3Det：1.3W类全新目标检测数据集（港中文\u0026amp;上海AI Lab）\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e微信公众号「整数智能AI研究院」\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/eoMa1eUXPaZBlHeZReR77A\" rel=\"nofollow\"\u003e2022-03-10, 最全自动驾驶数据集分享系列一｜目标检测数据集（1/3）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/nJFG6GHw60pRODoEKWj3bg\" rel=\"nofollow\"\u003e2022-03-21, 最全自动驾驶数据集分享系列一｜目标检测数据集（2/3）\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mp.weixin.qq.com/s/r9d7NmcA3dymKRUhWoIPzw\" rel=\"nofollow\"\u003e2022-04-24, 最全自动驾驶数据集分享系列一｜目标检测数据集（3/3）\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eVideos\u003c/h2\u003e\u003ca id=\"user-content-videos\" class=\"anchor\" aria-label=\"Permalink: Videos\" href=\"#videos\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003ebilibili「我是傅傅猪」\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://www.bilibili.com/video/BV1HV4y1A7H8\" rel=\"nofollow\"\u003e2022-12-14，自制深度学习推理框架\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.bilibili.com/video/BV118411f7yM/\" rel=\"nofollow\"\u003e2023-06-02，从零自制深度学习推理框架\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eStar History\u003c/h2\u003e\u003ca id=\"user-content-star-history\" class=\"anchor\" aria-label=\"Permalink: Star History\" href=\"#star-history\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/259a042401ab87b4596f31c2f486a7a6082f7f19ca98b7f4069a27536f2f7a10/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d636f6465726f6e696f6e2f617765736f6d652d796f6c6f2d6f626a6563742d646574656374696f6e26747970653d44617465\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/259a042401ab87b4596f31c2f486a7a6082f7f19ca98b7f4069a27536f2f7a10/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d636f6465726f6e696f6e2f617765736f6d652d796f6c6f2d6f626a6563742d646574656374696f6e26747970653d44617465\" alt=\"Star History Chart\" data-canonical-src=\"https://api.star-history.com/svg?repos=coderonion/awesome-yolo-object-detection\u0026amp;type=Date\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/article\u003e","loaded":true,"timedOut":false,"errorMessage":null,"headerInfo":{"toc":[{"level":1,"text":"Awesome-YOLO-Object-Detection","anchor":"awesome-yolo-object-detection","htmlText":"Awesome-YOLO-Object-Detection"},{"level":2,"text":"Contents","anchor":"contents","htmlText":"Contents"},{"level":2,"text":"Summary","anchor":"summary","htmlText":"Summary"},{"level":3,"text":"Famous YOLO","anchor":"famous-yolo","htmlText":"Famous YOLO"},{"level":3,"text":"Extensional Frameworks","anchor":"extensional-frameworks","htmlText":"Extensional Frameworks"},{"level":3,"text":"Awesome List","anchor":"awesome-list","htmlText":"Awesome List"},{"level":3,"text":"Paper and Code Overview","anchor":"paper-and-code-overview","htmlText":"Paper and Code Overview"},{"level":4,"text":"Paper Review","anchor":"paper-review","htmlText":"Paper Review"},{"level":4,"text":"Code Review","anchor":"code-review","htmlText":"Code Review"},{"level":3,"text":"Learning Resources","anchor":"learning-resources","htmlText":"Learning Resources"},{"level":2,"text":"Other Versions of YOLO","anchor":"other-versions-of-yolo","htmlText":"Other Versions of YOLO"},{"level":3,"text":"PyTorch Implementation","anchor":"pytorch-implementation","htmlText":"PyTorch Implementation"},{"level":3,"text":"C Implementation","anchor":"c-implementation","htmlText":"C Implementation"},{"level":3,"text":"CPP Implementation","anchor":"cpp-implementation","htmlText":"CPP Implementation"},{"level":3,"text":"ROS Implementation","anchor":"ros-implementation","htmlText":"ROS Implementation"},{"level":3,"text":"Mojo Implementation","anchor":"mojo-implementation","htmlText":"Mojo Implementation"},{"level":3,"text":"Rust Implementation","anchor":"rust-implementation","htmlText":"Rust Implementation"},{"level":3,"text":"Go Implementation","anchor":"go-implementation","htmlText":"Go Implementation"},{"level":3,"text":"CSharp Implementation","anchor":"csharp-implementation","htmlText":"CSharp Implementation"},{"level":3,"text":"Tensorflow and Keras Implementation","anchor":"tensorflow-and-keras-implementation","htmlText":"Tensorflow and Keras Implementation"},{"level":3,"text":"PaddlePaddle Implementation","anchor":"paddlepaddle-implementation","htmlText":"PaddlePaddle Implementation"},{"level":3,"text":"Caffe Implementation","anchor":"caffe-implementation","htmlText":"Caffe Implementation"},{"level":3,"text":"MXNet Implementation","anchor":"mxnet-implementation","htmlText":"MXNet Implementation"},{"level":3,"text":"Web Implementation","anchor":"web-implementation","htmlText":"Web Implementation"},{"level":3,"text":"Others","anchor":"others","htmlText":"Others"},{"level":2,"text":"Lighter and Deployment Frameworks","anchor":"lighter-and-deployment-frameworks","htmlText":"Lighter and Deployment Frameworks"},{"level":3,"text":"High-performance Inference Engine","anchor":"high-performance-inference-engine","htmlText":"High-performance Inference Engine"},{"level":4,"text":"高性能推理引擎","anchor":"高性能推理引擎","htmlText":"高性能推理引擎"},{"level":5,"text":"ONNX","anchor":"onnx","htmlText":"ONNX"},{"level":5,"text":"TensorRT","anchor":"tensorrt","htmlText":"TensorRT"},{"level":5,"text":"DeepStream","anchor":"deepstream","htmlText":"DeepStream"},{"level":5,"text":"OpenVINO","anchor":"openvino","htmlText":"OpenVINO"},{"level":5,"text":"NCNN","anchor":"ncnn","htmlText":"NCNN"},{"level":5,"text":"MNN","anchor":"mnn","htmlText":"MNN"},{"level":5,"text":"Other Engine","anchor":"other-engine","htmlText":"Other Engine"},{"level":3,"text":"NPU and FPGA Hardware Deployment","anchor":"npu-and-fpga-hardware-deployment","htmlText":"NPU and FPGA Hardware Deployment"},{"level":4,"text":"NPU 和 FPGA 硬件部署","anchor":"npu-和-fpga-硬件部署","htmlText":"NPU 和 FPGA 硬件部署"},{"level":5,"text":"RK3588","anchor":"rk3588","htmlText":"RK3588"},{"level":5,"text":"FPGA","anchor":"fpga","htmlText":"FPGA"},{"level":5,"text":"Other Hardware","anchor":"other-hardware","htmlText":"Other Hardware"},{"level":3,"text":"Pruning Knoweldge-Distillation Quantization","anchor":"pruning-knoweldge-distillation-quantization","htmlText":"Pruning Knoweldge-Distillation Quantization"},{"level":5,"text":"Pruning","anchor":"pruning","htmlText":"Pruning"},{"level":6,"text":"剪枝","anchor":"剪枝","htmlText":"剪枝"},{"level":5,"text":"Quantization","anchor":"quantization","htmlText":"Quantization"},{"level":6,"text":"量化","anchor":"量化","htmlText":"量化"},{"level":5,"text":"Knoweldge-Distillation","anchor":"knoweldge-distillation","htmlText":"Knoweldge-Distillation"},{"level":6,"text":"知识蒸馏","anchor":"知识蒸馏","htmlText":"知识蒸馏"},{"level":3,"text":"Lightweight Backbones and FPN","anchor":"lightweight-backbones-and-fpn","htmlText":"Lightweight Backbones and FPN"},{"level":4,"text":"轻量级骨干网络和特征金字塔网络","anchor":"轻量级骨干网络和特征金字塔网络","htmlText":"轻量级骨干网络和特征金字塔网络"},{"level":2,"text":"Object Detection Applications","anchor":"object-detection-applications","htmlText":"Object Detection Applications"},{"level":3,"text":"Open World Object Detection","anchor":"open-world-object-detection","htmlText":"Open World Object Detection"},{"level":4,"text":"开放世界目标检测","anchor":"开放世界目标检测","htmlText":"开放世界目标检测"},{"level":3,"text":"Few-shot Object Detection","anchor":"few-shot-object-detection","htmlText":"Few-shot Object Detection"},{"level":4,"text":"少样本目标检测","anchor":"少样本目标检测","htmlText":"少样本目标检测"},{"level":3,"text":"Small Object Detection","anchor":"small-object-detection","htmlText":"Small Object Detection"},{"level":4,"text":"小目标检测","anchor":"小目标检测","htmlText":"小目标检测"},{"level":4,"text":"Multimodal Image Detection","anchor":"multimodal-image-detection","htmlText":"Multimodal Image Detection"},{"level":4,"text":"多模态图像检测","anchor":"多模态图像检测","htmlText":"多模态图像检测"},{"level":3,"text":"Video Object Detection","anchor":"video-object-detection","htmlText":"Video Object Detection"},{"level":4,"text":"视频目标检测","anchor":"视频目标检测","htmlText":"视频目标检测"},{"level":3,"text":"Object Tracking","anchor":"object-tracking","htmlText":"Object Tracking"},{"level":4,"text":"目标跟踪","anchor":"目标跟踪","htmlText":"目标跟踪"},{"level":4,"text":"Multi-Object Tracking","anchor":"multi-object-tracking","htmlText":"Multi-Object Tracking"},{"level":5,"text":"多目标跟踪","anchor":"多目标跟踪","htmlText":"多目标跟踪"},{"level":4,"text":"Dynamic Object Tracking","anchor":"dynamic-object-tracking","htmlText":"Dynamic Object Tracking"},{"level":5,"text":"动态目标跟踪","anchor":"动态目标跟踪","htmlText":"动态目标跟踪"},{"level":4,"text":"Deep Reinforcement Learning","anchor":"deep-reinforcement-learning","htmlText":"Deep Reinforcement Learning"},{"level":4,"text":"深度强化学习","anchor":"深度强化学习","htmlText":"深度强化学习"},{"level":4,"text":"Motion Control Field","anchor":"motion-control-field","htmlText":"Motion Control Field"},{"level":4,"text":"运动控制领域","anchor":"运动控制领域","htmlText":"运动控制领域"},{"level":4,"text":"Super-Resolution Field","anchor":"super-resolution-field","htmlText":"Super-Resolution Field"},{"level":4,"text":"超分辨率领域","anchor":"超分辨率领域","htmlText":"超分辨率领域"},{"level":4,"text":"Spiking Neural Network","anchor":"spiking-neural-network","htmlText":"Spiking Neural Network"},{"level":4,"text":"SNN, 脉冲神经网络","anchor":"snn-脉冲神经网络","htmlText":"SNN, 脉冲神经网络"},{"level":4,"text":"Attention and Transformer","anchor":"attention-and-transformer","htmlText":"Attention and Transformer"},{"level":4,"text":"注意力机制","anchor":"注意力机制","htmlText":"注意力机制"},{"level":3,"text":"Oriented Object Detection","anchor":"oriented-object-detection","htmlText":"Oriented Object Detection"},{"level":4,"text":"旋转目标检测","anchor":"旋转目标检测","htmlText":"旋转目标检测"},{"level":3,"text":"Face Detection and Recognition","anchor":"face-detection-and-recognition","htmlText":"Face Detection and Recognition"},{"level":4,"text":"人脸检测与识别","anchor":"人脸检测与识别","htmlText":"人脸检测与识别"},{"level":4,"text":"Face Detection","anchor":"face-detection","htmlText":"Face Detection"},{"level":5,"text":"人脸检测","anchor":"人脸检测","htmlText":"人脸检测"},{"level":4,"text":"Face Recognition","anchor":"face-recognition","htmlText":"Face Recognition"},{"level":5,"text":"人脸识别","anchor":"人脸识别","htmlText":"人脸识别"},{"level":3,"text":"Face Mask Detection","anchor":"face-mask-detection","htmlText":"Face Mask Detection"},{"level":4,"text":"口罩检测","anchor":"口罩检测","htmlText":"口罩检测"},{"level":3,"text":"Social Distance Detection","anchor":"social-distance-detection","htmlText":"Social Distance Detection"},{"level":4,"text":"社交距离检测","anchor":"社交距离检测","htmlText":"社交距离检测"},{"level":3,"text":"Autonomous Driving Field Detection","anchor":"autonomous-driving-field-detection","htmlText":"Autonomous Driving Field Detection"},{"level":4,"text":"自动驾驶领域检测","anchor":"自动驾驶领域检测","htmlText":"自动驾驶领域检测"},{"level":4,"text":"Vehicle Detection","anchor":"vehicle-detection","htmlText":"Vehicle Detection"},{"level":5,"text":"车辆检测","anchor":"车辆检测","htmlText":"车辆检测"},{"level":4,"text":"License Plate Detection and Recognition","anchor":"license-plate-detection-and-recognition","htmlText":"License Plate Detection and Recognition"},{"level":5,"text":"车牌检测与识别","anchor":"车牌检测与识别","htmlText":"车牌检测与识别"},{"level":4,"text":"Lane Detection","anchor":"lane-detection","htmlText":"Lane Detection"},{"level":5,"text":"车道线检测","anchor":"车道线检测","htmlText":"车道线检测"},{"level":4,"text":"Driving Behavior Detection","anchor":"driving-behavior-detection","htmlText":"Driving Behavior Detection"},{"level":5,"text":"驾驶行为检测","anchor":"驾驶行为检测","htmlText":"驾驶行为检测"},{"level":4,"text":"Parking Slot Detection","anchor":"parking-slot-detection","htmlText":"Parking Slot Detection"},{"level":5,"text":"停车位检测","anchor":"停车位检测","htmlText":"停车位检测"},{"level":4,"text":"Traffic Light Detection","anchor":"traffic-light-detection","htmlText":"Traffic Light Detection"},{"level":5,"text":"交通灯检测","anchor":"交通灯检测","htmlText":"交通灯检测"},{"level":4,"text":"Traffic Sign Detection","anchor":"traffic-sign-detection","htmlText":"Traffic Sign Detection"},{"level":5,"text":"交通标志检测","anchor":"交通标志检测","htmlText":"交通标志检测"},{"level":4,"text":"Crosswalk Detection","anchor":"crosswalk-detection","htmlText":"Crosswalk Detection"},{"level":5,"text":"人行横道/斑马线检测","anchor":"人行横道斑马线检测","htmlText":"人行横道/斑马线检测"},{"level":4,"text":"Traffic Accidents Detection","anchor":"traffic-accidents-detection","htmlText":"Traffic Accidents Detection"},{"level":5,"text":"交通事故检测","anchor":"交通事故检测","htmlText":"交通事故检测"},{"level":4,"text":"Road Damage Detection","anchor":"road-damage-detection","htmlText":"Road Damage Detection"},{"level":5,"text":"道路损伤检测","anchor":"道路损伤检测","htmlText":"道路损伤检测"},{"level":3,"text":"Animal Detection","anchor":"animal-detection","htmlText":"Animal Detection"},{"level":4,"text":"动物检测","anchor":"动物检测","htmlText":"动物检测"},{"level":3,"text":"Helmet Detection","anchor":"helmet-detection","htmlText":"Helmet Detection"},{"level":4,"text":"头盔/安全帽检测","anchor":"头盔安全帽检测","htmlText":"头盔/安全帽检测"},{"level":3,"text":"Hand Detection","anchor":"hand-detection","htmlText":"Hand Detection"},{"level":4,"text":"手部检测","anchor":"手部检测","htmlText":"手部检测"},{"level":3,"text":"Gesture Recognition","anchor":"gesture-recognition","htmlText":"Gesture Recognition"},{"level":4,"text":"手势/手语识别","anchor":"手势手语识别","htmlText":"手势/手语识别"},{"level":3,"text":"Action Detection","anchor":"action-detection","htmlText":"Action Detection"},{"level":4,"text":"行为检测","anchor":"行为检测","htmlText":"行为检测"},{"level":3,"text":"Emotion Recognition","anchor":"emotion-recognition","htmlText":"Emotion Recognition"},{"level":4,"text":"情感识别","anchor":"情感识别","htmlText":"情感识别"},{"level":3,"text":"Human Pose Estimation","anchor":"human-pose-estimation","htmlText":"Human Pose Estimation"},{"level":4,"text":"人体姿态估计","anchor":"人体姿态估计","htmlText":"人体姿态估计"},{"level":3,"text":"Distance Measurement","anchor":"distance-measurement","htmlText":"Distance Measurement"},{"level":4,"text":"距离测量","anchor":"距离测量","htmlText":"距离测量"},{"level":3,"text":"Instance and Semantic Segmentation","anchor":"instance-and-semantic-segmentation","htmlText":"Instance and Semantic Segmentation"},{"level":4,"text":"实例和语义分割","anchor":"实例和语义分割","htmlText":"实例和语义分割"},{"level":3,"text":"3D Object Detection","anchor":"3d-object-detection","htmlText":"3D Object Detection"},{"level":4,"text":"三维目标检测","anchor":"三维目标检测","htmlText":"三维目标检测"},{"level":3,"text":"SLAM Field Detection","anchor":"slam-field-detection","htmlText":"SLAM Field Detection"},{"level":4,"text":"SLAM领域检测","anchor":"slam领域检测","htmlText":"SLAM领域检测"},{"level":3,"text":"Industrial Defect Detection","anchor":"industrial-defect-detection","htmlText":"Industrial Defect Detection"},{"level":4,"text":"工业缺陷检测","anchor":"工业缺陷检测","htmlText":"工业缺陷检测"},{"level":3,"text":"SAR Image Detection","anchor":"sar-image-detection","htmlText":"SAR Image Detection"},{"level":4,"text":"合成孔径雷达图像检测","anchor":"合成孔径雷达图像检测","htmlText":"合成孔径雷达图像检测"},{"level":3,"text":"Safety Monitoring Field Detection","anchor":"safety-monitoring-field-detection","htmlText":"Safety Monitoring Field Detection"},{"level":4,"text":"安防监控领域检测","anchor":"安防监控领域检测","htmlText":"安防监控领域检测"},{"level":3,"text":"Anti-UAV Field Detection","anchor":"anti-uav-field-detection","htmlText":"Anti-UAV Field Detection"},{"level":4,"text":"反无人机领域检测","anchor":"反无人机领域检测","htmlText":"反无人机领域检测"},{"level":3,"text":"Medical Field Detection","anchor":"medical-field-detection","htmlText":"Medical Field Detection"},{"level":4,"text":"医学领域检测","anchor":"医学领域检测","htmlText":"医学领域检测"},{"level":3,"text":"Chemistry Field Detection","anchor":"chemistry-field-detection","htmlText":"Chemistry Field Detection"},{"level":4,"text":"化学领域检测","anchor":"化学领域检测","htmlText":"化学领域检测"},{"level":3,"text":"Agricultural Field Detection","anchor":"agricultural-field-detection","htmlText":"Agricultural Field Detection"},{"level":4,"text":"农业领域检测","anchor":"农业领域检测","htmlText":"农业领域检测"},{"level":3,"text":"Sports Field Detection","anchor":"sports-field-detection","htmlText":"Sports Field Detection"},{"level":4,"text":"体育领域检测","anchor":"体育领域检测","htmlText":"体育领域检测"},{"level":3,"text":"Aerial Imagery Detection","anchor":"aerial-imagery-detection","htmlText":"Aerial Imagery Detection"},{"level":4,"text":"遥感图像检测","anchor":"遥感图像检测","htmlText":"遥感图像检测"},{"level":3,"text":"Adverse Weather Conditions","anchor":"adverse-weather-conditions","htmlText":"Adverse Weather Conditions"},{"level":4,"text":"恶劣天气情况","anchor":"恶劣天气情况","htmlText":"恶劣天气情况"},{"level":3,"text":"Adversarial Attack and Defense","anchor":"adversarial-attack-and-defense","htmlText":"Adversarial Attack and Defense"},{"level":4,"text":"对抗攻击与防御","anchor":"对抗攻击与防御","htmlText":"对抗攻击与防御"},{"level":3,"text":"Camouflaged Detection","anchor":"camouflaged-detection","htmlText":"Camouflaged Detection"},{"level":4,"text":"伪装目标检测","anchor":"伪装目标检测","htmlText":"伪装目标检测"},{"level":3,"text":"Game Field Detection","anchor":"game-field-detection","htmlText":"Game Field Detection"},{"level":4,"text":"游戏领域检测","anchor":"游戏领域检测","htmlText":"游戏领域检测"},{"level":3,"text":"Automatic Annotation Tools","anchor":"automatic-annotation-tools","htmlText":"Automatic Annotation Tools"},{"level":4,"text":"自动标注工具","anchor":"自动标注工具","htmlText":"自动标注工具"},{"level":3,"text":"Feature Map Visualization","anchor":"feature-map-visualization","htmlText":"Feature Map Visualization"},{"level":4,"text":"特征图可视化","anchor":"特征图可视化","htmlText":"特征图可视化"},{"level":3,"text":"Object Detection Evaluation Metrics","anchor":"object-detection-evaluation-metrics","htmlText":"Object Detection Evaluation Metrics"},{"level":4,"text":"目标检测性能评价指标","anchor":"目标检测性能评价指标","htmlText":"目标检测性能评价指标"},{"level":3,"text":"GUI","anchor":"gui","htmlText":"GUI"},{"level":4,"text":"图形用户界面","anchor":"图形用户界面","htmlText":"图形用户界面"},{"level":4,"text":"Swift-Related","anchor":"swift-related","htmlText":"Swift-Related"},{"level":4,"text":"Flutter-Related","anchor":"flutter-related","htmlText":"Flutter-Related"},{"level":4,"text":"Streamlit-Related","anchor":"streamlit-related","htmlText":"Streamlit-Related"},{"level":4,"text":"Gradio-Related","anchor":"gradio-related","htmlText":"Gradio-Related"},{"level":4,"text":"QT-Related","anchor":"qt-related","htmlText":"QT-Related"},{"level":4,"text":"PySide-Related","anchor":"pyside-related","htmlText":"PySide-Related"},{"level":3,"text":"Other Applications","anchor":"other-applications","htmlText":"Other Applications"},{"level":4,"text":"其它应用","anchor":"其它应用","htmlText":"其它应用"},{"level":2,"text":"Object Detection Datasets","anchor":"object-detection-datasets","htmlText":"Object Detection Datasets"},{"level":3,"text":"Datasets Share Platform","anchor":"datasets-share-platform","htmlText":"Datasets Share Platform"},{"level":3,"text":"Datasets Tools","anchor":"datasets-tools","htmlText":"Datasets Tools"},{"level":4,"text":"Data Annotation","anchor":"data-annotation","htmlText":"Data Annotation"},{"level":4,"text":"Data Augmentation","anchor":"data-augmentation","htmlText":"Data Augmentation"},{"level":4,"text":"Data Management","anchor":"data-management","htmlText":"Data Management"},{"level":3,"text":"General Detection and Recognition Datasets","anchor":"general-detection-and-recognition-datasets","htmlText":"General Detection and Recognition Datasets"},{"level":4,"text":"General Object Detection Datasets","anchor":"general-object-detection-datasets","htmlText":"General Object Detection Datasets"},{"level":4,"text":"General Object Recognition Datasets","anchor":"general-object-recognition-datasets","htmlText":"General Object Recognition Datasets"},{"level":3,"text":"Autonomous Driving Datasets","anchor":"autonomous-driving-datasets","htmlText":"Autonomous Driving Datasets"},{"level":4,"text":"Diverse Autonomous Driving Datasets","anchor":"diverse-autonomous-driving-datasets","htmlText":"Diverse Autonomous Driving Datasets"},{"level":4,"text":"Traffic Sign Detection Datasets","anchor":"traffic-sign-detection-datasets","htmlText":"Traffic Sign Detection Datasets"},{"level":4,"text":"License Plate Detection and Recognition Datasets","anchor":"license-plate-detection-and-recognition-datasets","htmlText":"License Plate Detection and Recognition Datasets"},{"level":3,"text":"Adverse Weather Datasets","anchor":"adverse-weather-datasets","htmlText":"Adverse Weather Datasets"},{"level":3,"text":"Person Detection Datasets","anchor":"person-detection-datasets","htmlText":"Person Detection Datasets"},{"level":2,"text":"Anti-UAV Datasets","anchor":"anti-uav-datasets","htmlText":"Anti-UAV Datasets"},{"level":3,"text":"Optical Aerial Imagery Datasets","anchor":"optical-aerial-imagery-datasets","htmlText":"Optical Aerial Imagery Datasets"},{"level":3,"text":"Low-light Image Datasets","anchor":"low-light-image-datasets","htmlText":"Low-light Image Datasets"},{"level":3,"text":"Infrared Image Datasets","anchor":"infrared-image-datasets","htmlText":"Infrared Image Datasets"},{"level":3,"text":"SAR Image Datasets","anchor":"sar-image-datasets","htmlText":"SAR Image Datasets"},{"level":3,"text":"Sonar Image Datasets","anchor":"sonar-image-datasets","htmlText":"Sonar Image Datasets"},{"level":3,"text":"Multimodal Image Datasets","anchor":"multimodal-image-datasets","htmlText":"Multimodal Image Datasets"},{"level":3,"text":"3D Object Detection Datasets","anchor":"3d-object-detection-datasets","htmlText":"3D Object Detection Datasets"},{"level":3,"text":"Vehicle-to-Everything Field Datasets","anchor":"vehicle-to-everything-field-datasets","htmlText":"Vehicle-to-Everything Field Datasets"},{"level":3,"text":"Super-Resolution Field Datasets","anchor":"super-resolution-field-datasets","htmlText":"Super-Resolution Field Datasets"},{"level":3,"text":"Face Detection and Recognition Datasets","anchor":"face-detection-and-recognition-datasets","htmlText":"Face Detection and Recognition Datasets"},{"level":4,"text":"Face Detection Datasets","anchor":"face-detection-datasets","htmlText":"Face Detection Datasets"},{"level":4,"text":"Face Recognition Datasets","anchor":"face-recognition-datasets","htmlText":"Face Recognition Datasets"},{"level":2,"text":"Blogs","anchor":"blogs","htmlText":"Blogs"},{"level":2,"text":"Videos","anchor":"videos","htmlText":"Videos"},{"level":2,"text":"Star History","anchor":"star-history","htmlText":"Star History"}],"siteNavLoginPath":"/login?return_to=https%3A%2F%2Fgithub.com%2Fcoderonion%2Fawesome-yolo-object-detection"}}],"overviewFilesProcessingTime":0,"copilotSWEAgentEnabled":false}},"appPayload":{"helpUrl":"https://docs.github.com","findFileWorkerPath":"/assets-cdn/worker/find-file-worker-9bd411a8e273.js","findInFileWorkerPath":"/assets-cdn/worker/find-in-file-worker-4747241b1152.js","githubDevUrl":null,"enabled_features":{"copilot_workspace":null,"code_nav_ui_events":false,"react_blob_overlay":false,"accessible_code_button":true}}}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>


      <input type="hidden" data-csrf="true" value="JuRQRXwLVB3oT/hbh8H50CIzu2kAZoiSPfgCWqd+mKbJs2B72Lkgw+dhwiIGr35Ro//UcEpTdxwWbWNlf5l4sg==" />
</div>
  <div data-view-component="true" class="Layout-sidebar">      

      <div class="BorderGrid about-margin" data-pjax>
        <div class="BorderGrid-row">
          <div class="BorderGrid-cell">
            <div class="hide-sm hide-md">
  <h2 class="mb-3 h4">About</h2>

      <p class="f4 my-3">
        🚀🚀🚀 A collection of some awesome public YOLO object detection series projects and the related object detection datasets.
      </p>

    <h3 class="sr-only">Topics</h3>
    <div class="my-3">
        <div class="f6">
      <a href="/topics/gui" title="Topic: gui" data-view-component="true" class="topic-tag topic-tag-link">
  gui
</a>
      <a href="/topics/cuda" title="Topic: cuda" data-view-component="true" class="topic-tag topic-tag-link">
  cuda
</a>
      <a href="/topics/yolo" title="Topic: yolo" data-view-component="true" class="topic-tag topic-tag-link">
  yolo
</a>
      <a href="/topics/llama" title="Topic: llama" data-view-component="true" class="topic-tag topic-tag-link">
  llama
</a>
      <a href="/topics/object-detection" title="Topic: object-detection" data-view-component="true" class="topic-tag topic-tag-link">
  object-detection
</a>
      <a href="/topics/datasets" title="Topic: datasets" data-view-component="true" class="topic-tag topic-tag-link">
  datasets
</a>
      <a href="/topics/vlm" title="Topic: vlm" data-view-component="true" class="topic-tag topic-tag-link">
  vlm
</a>
      <a href="/topics/tensorrt" title="Topic: tensorrt" data-view-component="true" class="topic-tag topic-tag-link">
  tensorrt
</a>
      <a href="/topics/snn" title="Topic: snn" data-view-component="true" class="topic-tag topic-tag-link">
  snn
</a>
      <a href="/topics/spiking-neural-network" title="Topic: spiking-neural-network" data-view-component="true" class="topic-tag topic-tag-link">
  spiking-neural-network
</a>
      <a href="/topics/few-shot-object-detection" title="Topic: few-shot-object-detection" data-view-component="true" class="topic-tag topic-tag-link">
  few-shot-object-detection
</a>
      <a href="/topics/yolov5" title="Topic: yolov5" data-view-component="true" class="topic-tag topic-tag-link">
  yolov5
</a>
      <a href="/topics/object-detection-datasets" title="Topic: object-detection-datasets" data-view-component="true" class="topic-tag topic-tag-link">
  object-detection-datasets
</a>
      <a href="/topics/rknn" title="Topic: rknn" data-view-component="true" class="topic-tag topic-tag-link">
  rknn
</a>
      <a href="/topics/llm" title="Topic: llm" data-view-component="true" class="topic-tag topic-tag-link">
  llm
</a>
      <a href="/topics/yolov8" title="Topic: yolov8" data-view-component="true" class="topic-tag topic-tag-link">
  yolov8
</a>
      <a href="/topics/mllm" title="Topic: mllm" data-view-component="true" class="topic-tag topic-tag-link">
  mllm
</a>
      <a href="/topics/open-world-object-detection" title="Topic: open-world-object-detection" data-view-component="true" class="topic-tag topic-tag-link">
  open-world-object-detection
</a>
      <a href="/topics/qwen" title="Topic: qwen" data-view-component="true" class="topic-tag topic-tag-link">
  qwen
</a>
      <a href="/topics/deepseek" title="Topic: deepseek" data-view-component="true" class="topic-tag topic-tag-link">
  deepseek
</a>
  </div>

    </div>

    <h3 class="sr-only">Resources</h3>
    <div class="mt-2">
      <a class="Link--muted" data-analytics-event="{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:readme&quot;}" href="#readme-ov-file">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-book mr-2">
    <path d="M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z"></path>
</svg>
        Readme
</a>    </div>

  





  <include-fragment src="/coderonion/awesome-yolo-object-detection/hovercards/citation/sidebar_partial?tree_name=main" data-nonce="v2:515a6721-8eb7-ba0a-7b66-e450a60aff90" data-view-component="true">
  

  <div data-show-on-forbidden-error hidden>
    <div class="Box">
  <div class="blankslate-container">
    <div data-view-component="true" class="blankslate blankslate-spacious color-bg-default rounded-2">
      

      <h3 data-view-component="true" class="blankslate-heading">        Uh oh!
</h3>
      <p data-view-component="true">        <p class="color-fg-muted my-2 mb-2 ws-normal">There was an error while loading. <a class="Link--inTextBlock" data-turbo="false" href="" aria-label="Please reload this page">Please reload this page</a>.</p>
</p>

</div>  </div>
</div>  </div>
</include-fragment>
  <div class="mt-2">
    <a href="/coderonion/awesome-yolo-object-detection/activity" data-view-component="true" class="Link Link--muted"><svg text="gray" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-pulse mr-2">
    <path d="M6 2c.306 0 .582.187.696.471L10 10.731l1.304-3.26A.751.751 0 0 1 12 7h3.25a.75.75 0 0 1 0 1.5h-2.742l-1.812 4.528a.751.751 0 0 1-1.392 0L6 4.77 4.696 8.03A.75.75 0 0 1 4 8.5H.75a.75.75 0 0 1 0-1.5h2.742l1.812-4.529A.751.751 0 0 1 6 2Z"></path>
</svg>
      <span class="color-fg-muted">Activity</span></a>  </div>


  <h3 class="sr-only">Stars</h3>
  <div class="mt-2">
    <a href="/coderonion/awesome-yolo-object-detection/stargazers" data-view-component="true" class="Link Link--muted"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-star mr-2">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
      <strong>1.6k</strong>
      stars</a>  </div>

  <h3 class="sr-only">Watchers</h3>
  <div class="mt-2">
    <a href="/coderonion/awesome-yolo-object-detection/watchers" data-view-component="true" class="Link Link--muted"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-eye mr-2">
    <path d="M8 2c1.981 0 3.671.992 4.933 2.078 1.27 1.091 2.187 2.345 2.637 3.023a1.62 1.62 0 0 1 0 1.798c-.45.678-1.367 1.932-2.637 3.023C11.67 13.008 9.981 14 8 14c-1.981 0-3.671-.992-4.933-2.078C1.797 10.83.88 9.576.43 8.898a1.62 1.62 0 0 1 0-1.798c.45-.677 1.367-1.931 2.637-3.022C4.33 2.992 6.019 2 8 2ZM1.679 7.932a.12.12 0 0 0 0 .136c.411.622 1.241 1.75 2.366 2.717C5.176 11.758 6.527 12.5 8 12.5c1.473 0 2.825-.742 3.955-1.715 1.124-.967 1.954-2.096 2.366-2.717a.12.12 0 0 0 0-.136c-.412-.621-1.242-1.75-2.366-2.717C10.824 4.242 9.473 3.5 8 3.5c-1.473 0-2.825.742-3.955 1.715-1.124.967-1.954 2.096-2.366 2.717ZM8 10a2 2 0 1 1-.001-3.999A2 2 0 0 1 8 10Z"></path>
</svg>
      <strong>34</strong>
      watching</a>  </div>

  <h3 class="sr-only">Forks</h3>
  <div class="mt-2">
    <a href="/coderonion/awesome-yolo-object-detection/forks" data-view-component="true" class="Link Link--muted"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo-forked mr-2">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>
      <strong>220</strong>
      forks</a>  </div>


    <div class="mt-2">
      <a class="Link--muted" href="/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fcoderonion%2Fawesome-yolo-object-detection&amp;report=coderonion+%28user%29">
          Report repository
</a>    </div>
</div>

          </div>
        </div>

        
            <div class="BorderGrid-row">
              <div class="BorderGrid-cell">
                <h2 class="h4 mb-3" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame">
  <a href="/coderonion/awesome-yolo-object-detection/releases" data-view-component="true" class="Link--primary no-underline Link">Releases</a></h2>

    <div class="text-small color-fg-muted">No releases published</div>

              </div>
            </div>

        
        
            <div class="BorderGrid-row">
              <div class="BorderGrid-cell">
                
  <h2 class="h4 mb-3">
  <a href="/users/coderonion/packages?repo_name=awesome-yolo-object-detection" data-view-component="true" class="Link--primary no-underline Link d-flex flex-items-center">Packages
      <span title="0" hidden="hidden" data-view-component="true" class="Counter ml-1">0</span></a></h2>


      <div class="text-small color-fg-muted" >
        No packages published <br>
      </div>



              </div>
            </div>

        
        
            <div class="BorderGrid-row">
              <div class="BorderGrid-cell">
                <h2 class="h4 mb-3">
  <a href="/coderonion/awesome-yolo-object-detection/graphs/contributors" data-view-component="true" class="Link--primary no-underline Link d-flex flex-items-center">Contributors
      <span title="5" data-view-component="true" class="Counter ml-1">5</span></a></h2>


    
  <ul class="list-style-none d-flex flex-wrap mb-n2">
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/coderonion"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/coderonion/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/99076655?s=64&amp;v=4" alt="@coderonion" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/kadirnar"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/kadirnar/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/36204372?s=64&amp;v=4" alt="@kadirnar" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/WangQvQ"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/WangQvQ/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/58406737?s=64&amp;v=4" alt="@WangQvQ" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/Shaing"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/Shaing/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/19544390?s=64&amp;v=4" alt="@Shaing" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/PetervanLunteren"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/PetervanLunteren/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/85185478?s=64&amp;v=4" alt="@PetervanLunteren" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
</ul>





              </div>
            </div>

        
        
              </div>
</div>
  
</div></div>

  </div>


  </div>

</turbo-frame>


    </main>
  </div>

  </div>

          <footer class="footer pt-8 pb-6 f6 color-fg-muted p-responsive" role="contentinfo" >
  <h2 class='sr-only'>Footer</h2>

  


  <div class="d-flex flex-justify-center flex-items-center flex-column-reverse flex-lg-row flex-wrap flex-lg-nowrap">
    <div class="d-flex flex-items-center flex-shrink-0 mx-2">
      <a aria-label="GitHub Homepage" class="footer-octicon mr-2" href="https://github.com">
        <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-mark-github">
    <path d="M12 1C5.923 1 1 5.923 1 12c0 4.867 3.149 8.979 7.521 10.436.55.096.756-.233.756-.522 0-.262-.013-1.128-.013-2.049-2.764.509-3.479-.674-3.699-1.292-.124-.317-.66-1.293-1.127-1.554-.385-.207-.936-.715-.014-.729.866-.014 1.485.797 1.691 1.128.99 1.663 2.571 1.196 3.204.907.096-.715.385-1.196.701-1.471-2.448-.275-5.005-1.224-5.005-5.432 0-1.196.426-2.186 1.128-2.956-.111-.275-.496-1.402.11-2.915 0 0 .921-.288 3.024 1.128a10.193 10.193 0 0 1 2.75-.371c.936 0 1.871.123 2.75.371 2.104-1.43 3.025-1.128 3.025-1.128.605 1.513.221 2.64.111 2.915.701.77 1.127 1.747 1.127 2.956 0 4.222-2.571 5.157-5.019 5.432.399.344.743 1.004.743 2.035 0 1.471-.014 2.654-.014 3.025 0 .289.206.632.756.522C19.851 20.979 23 16.854 23 12c0-6.077-4.922-11-11-11Z"></path>
</svg>
</a>
      <span>
        &copy; 2025 GitHub,&nbsp;Inc.
      </span>
    </div>

    <nav aria-label="Footer">
      <h3 class="sr-only" id="sr-footer-heading">Footer navigation</h3>

      <ul class="list-style-none d-flex flex-justify-center flex-wrap mb-2 mb-lg-0" aria-labelledby="sr-footer-heading">

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to Terms&quot;,&quot;label&quot;:&quot;text:terms&quot;}" href="https://docs.github.com/site-policy/github-terms/github-terms-of-service" data-view-component="true" class="Link--secondary Link">Terms</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to privacy&quot;,&quot;label&quot;:&quot;text:privacy&quot;}" href="https://docs.github.com/site-policy/privacy-policies/github-privacy-statement" data-view-component="true" class="Link--secondary Link">Privacy</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to security&quot;,&quot;label&quot;:&quot;text:security&quot;}" href="https://github.com/security" data-view-component="true" class="Link--secondary Link">Security</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to status&quot;,&quot;label&quot;:&quot;text:status&quot;}" href="https://www.githubstatus.com/" data-view-component="true" class="Link--secondary Link">Status</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to community&quot;,&quot;label&quot;:&quot;text:community&quot;}" href="https://github.community/" data-view-component="true" class="Link--secondary Link">Community</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to docs&quot;,&quot;label&quot;:&quot;text:docs&quot;}" href="https://docs.github.com/" data-view-component="true" class="Link--secondary Link">Docs</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to contact&quot;,&quot;label&quot;:&quot;text:contact&quot;}" href="https://support.github.com?tags=dotcom-footer" data-view-component="true" class="Link--secondary Link">Contact</a>
          </li>

          <li class="mx-2" >
  <cookie-consent-link>
    <button
      type="button"
      class="Link--secondary underline-on-hover border-0 p-0 color-bg-transparent"
      data-action="click:cookie-consent-link#showConsentManagement"
      data-analytics-event="{&quot;location&quot;:&quot;footer&quot;,&quot;action&quot;:&quot;cookies&quot;,&quot;context&quot;:&quot;subfooter&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;cookies_link_subfooter_footer&quot;}"
    >
       Manage cookies
    </button>
  </cookie-consent-link>
</li>

<li class="mx-2">
  <cookie-consent-link>
    <button
      type="button"
      class="Link--secondary underline-on-hover border-0 p-0 color-bg-transparent text-left"
      data-action="click:cookie-consent-link#showConsentManagement"
      data-analytics-event="{&quot;location&quot;:&quot;footer&quot;,&quot;action&quot;:&quot;dont_share_info&quot;,&quot;context&quot;:&quot;subfooter&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;dont_share_info_link_subfooter_footer&quot;}"
    >
      Do not share my personal information
    </button>
  </cookie-consent-link>
</li>

      </ul>
    </nav>
  </div>
</footer>



    <ghcc-consent id="ghcc" class="position-fixed bottom-0 left-0" style="z-index: 999999"
      data-locale="en"
      data-initial-cookie-consent-allowed=""
      data-cookie-consent-required="false"
    ></ghcc-consent>




  <div id="ajax-error-message" class="ajax-error-message flash flash-error" hidden>
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
    <button type="button" class="flash-close js-ajax-error-dismiss" aria-label="Dismiss error">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
    </button>
    You can’t perform that action at this time.
  </div>

    <template id="site-details-dialog">
  <details class="details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm" open>
    <summary role="button" aria-label="Close dialog"></summary>
    <details-dialog class="Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal">
      <button class="Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0" type="button" aria-label="Close dialog" data-close-dialog>
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
      </button>
      <div class="octocat-spinner my-6 js-details-dialog-spinner"></div>
    </details-dialog>
  </details>
</template>

    <div class="Popover js-hovercard-content position-absolute" style="display: none; outline: none;">
  <div class="Popover-message Popover-message--bottom-left Popover-message--large Box color-shadow-large" style="width:360px;">
  </div>
</div>

    <template id="snippet-clipboard-copy-button">
  <div class="zeroclipboard-container position-absolute right-0 top-0">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn js-clipboard-copy m-2 p-0" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon m-2">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>
<template id="snippet-clipboard-copy-button-unpositioned">
  <div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>




    </div>
    <div id="js-global-screen-reader-notice" class="sr-only mt-n1" aria-live="polite" aria-atomic="true" ></div>
    <div id="js-global-screen-reader-notice-assertive" class="sr-only mt-n1" aria-live="assertive" aria-atomic="true"></div>
  </body>
</html>

