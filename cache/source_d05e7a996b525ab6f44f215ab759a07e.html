






<!DOCTYPE html>
<html
  lang="en"
  
  data-color-mode="auto" data-light-theme="light" data-dark-theme="dark"
  data-a11y-animated-images="system" data-a11y-link-underlines="true"
  
  >




  <head>
    <meta charset="utf-8">
  <link rel="dns-prefetch" href="https://github.githubassets.com">
  <link rel="dns-prefetch" href="https://avatars.githubusercontent.com">
  <link rel="dns-prefetch" href="https://github-cloud.s3.amazonaws.com">
  <link rel="dns-prefetch" href="https://user-images.githubusercontent.com/">
  <link rel="preconnect" href="https://github.githubassets.com" crossorigin>
  <link rel="preconnect" href="https://avatars.githubusercontent.com">

  

  <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/light-44e67b0cd5d5.css" /><link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/light_high_contrast-b51c2fae25e8.css" /><link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/dark-cb035ed575b8.css" /><link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/dark_high_contrast-99e9b1169976.css" /><link data-color-theme="light" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light-44e67b0cd5d5.css" /><link data-color-theme="light_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light_high_contrast-b51c2fae25e8.css" /><link data-color-theme="light_colorblind" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light_colorblind-dadcba82130c.css" /><link data-color-theme="light_colorblind_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light_colorblind_high_contrast-cdc36145225e.css" /><link data-color-theme="light_tritanopia" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light_tritanopia-0ca195e3b5f3.css" /><link data-color-theme="light_tritanopia_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light_tritanopia_high_contrast-f9fb5556a83f.css" /><link data-color-theme="dark" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark-cb035ed575b8.css" /><link data-color-theme="dark_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_high_contrast-99e9b1169976.css" /><link data-color-theme="dark_colorblind" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_colorblind-9541c4141757.css" /><link data-color-theme="dark_colorblind_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_colorblind_high_contrast-bc604fc65912.css" /><link data-color-theme="dark_tritanopia" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_tritanopia-384776200fd7.css" /><link data-color-theme="dark_tritanopia_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_tritanopia_high_contrast-489c70dedd0a.css" /><link data-color-theme="dark_dimmed" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_dimmed-1545a2e9e540.css" /><link data-color-theme="dark_dimmed_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_dimmed_high_contrast-4c1792a987c3.css" />

  <style type="text/css">
    :root {
      --tab-size-preference: 4;
    }

    pre, code {
      tab-size: var(--tab-size-preference);
    }
  </style>

    <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-primitives-15839d47b75d.css" />
    <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-a5c85403da8c.css" />
    <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/global-4d11e88b2383.css" />
    <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/github-6aeb6451a33d.css" />
  <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/repository-5d735668c600.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/code-9c9b8dc61e74.css" />

  

  <script type="application/json" id="client-env">{"locale":"en","featureFlags":["alternate_user_config_repo","api_insights_show_missing_data_banner","attestations_filtering","attestations_sorting","billing_unfiltered_discounts","client_version_header","codespaces_prebuild_region_target_update","contentful_lp_footnotes","copilot_agent_cli_public_preview","copilot_agent_task_list_v2","copilot_agent_tasks_btn_code_nav","copilot_agent_tasks_btn_code_view","copilot_agent_tasks_btn_code_view_lines","copilot_api_agentic_issue_marshal_yaml","copilot_api_github_draft_update_issue_skill","copilot_chat_attach_multiple_images","copilot_chat_file_redirect","copilot_chat_reduce_quota_checks","copilot_chat_search_bar_redirect","copilot_chat_selection_attachments","copilot_chat_vision_in_claude","copilot_chat_vision_skip_thread_create","copilot_custom_copilots","copilot_custom_copilots_feature_preview","copilot_duplicate_thread","copilot_extensions_deprecation_notice","copilot_features_raycast_logo","copilot_file_block_ref_matching","copilot_free_to_paid_telem","copilot_ftp_hyperspace_upgrade_prompt","copilot_ftp_settings_upgrade","copilot_ftp_upgrade_to_pro_from_models","copilot_ftp_your_copilot_settings","copilot_generate_commit_message_dry_regenerate","copilot_immersive_structured_model_picker","copilot_immersive_task_within_chat_thread","copilot_insights_column_chart_axis_legibility_fix","copilot_insights_usage_export_ndjson","copilot_mission_control_feedback","copilot_mission_control_session_feedback","copilot_no_floating_button","copilot_read_shared_conversation","copilot_spaces_as_attachments","copilot_spaces_ga","copilot_spark_loading_webgl","copilot_spark_progressive_error_handling","copilot_spark_read_iteration_history_from_git_v2","copilot_spark_use_billing_headers","copilot_spark_write_iteration_history_to_git","copilot_stable_conversation_view","copilot_workbench_agent_seed_tool","copilot_workbench_cache","copilot_workbench_connection_reload_banner","copilot_workbench_preview_analytics","copilot_workbench_skip_repo_on_codespace","copilot_workbench_use_single_prompt","direct_to_salesforce","disable_dashboard_universe_2025_private_preview","dotcom_chat_client_side_skills","failbot_report_error_react_apps_on_page","ghost_pilot_confidence_truncation_25","ghost_pilot_confidence_truncation_40","global_search_multi_orgs","hpc_improve_dom_insertion_observer","inp_reduced_threshold","insert_before_patch","issue_fields_report_usage","issues_copilot_cross_repo_assign","issues_react_blur_item_picker_on_close","issues_react_bots_timeline_pagination","issues_react_prohibit_title_fallback","issues_react_remove_placeholders","issues_sticky_sidebar","kb_convert_to_space","lifecycle_label_name_updates","link_contact_sales_swp_marketo","marketing_pages_search_explore_provider","mcp_registry_install","memex_mwl_filter_field_delimiter","migrate_toasts_to_banners_web_notifications","new_traffic_page_banner","open_agent_session_in_vscode_insiders","pinned_issue_fields","primer_react_segmented_control_tooltip","primer_react_unified_portal_root","record_sso_banner_metrics","ref_selector_create_tag_dialog","remove_child_patch","repos_insights_remove_new_url","sample_network_conn_type","scheduled_reminders_updated_limits","site_homepage_collaborate_video","site_homepage_contentful","site_msbuild_webgl_hero","spark_fix_rename","spark_force_push_after_checkout","spark_kv_encocoded_keys","spark_show_data_access_on_publish","spark_sync_repository_after_iteration","viewscreen_sandbox","webp_support","workbench_store_readonly"],"copilotApiOverrideUrl":"https://api.githubcopilot.com"}</script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/high-contrast-cookie-f3788027bd8d.js"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/wp-runtime-b73258c5aaae.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_oddbird_popover-polyfill_dist_popover-fn_js-468bf7cab607.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_stacktrace-parser_dist_stack-trace-parser_esm_js-node_modules_github_bro-2f4e04-280c10ec004d.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/environment-b4e74adb6411.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_primer_behaviors_dist_esm_index_mjs-3eee64e5ddf0.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_selector-observer_dist_index_esm_js-9ab93471824e.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_relative-time-element_dist_index_js-ef89d23fcc0a.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_auto-complete-element_dist_index_js-node_modules_github_catalyst_-0d7d60-ad3a87b2f0eb.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_text-expander-element_dist_index_js-754f5b5e9e7e.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_filter-input-element_dist_index_js-node_modules_github_remote-inp-665e70-ac788066c220.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_markdown-toolbar-element_dist_index_js-d41270eb61be.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_file-attachment-element_dist_index_js-node_modules_primer_view-co-777ce2-9ec8c103bf42.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/github-elements-9e1d42c09c62.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/element-registry-212230e65885.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_braintree_browser-detection_dist_browser-detection_js-node_modules_githu-bb80ec-f11c694928ba.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_lit-html_lit-html_js-9012bef51135.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_mini-throttle_dist_index_js-node_modules_morphdom_dist_morphdom-e-c1896e-ba47f43192a8.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_remote-form_dist_index_js-node_modules_delegated-events_dist_inde-893f9f-9ba0881c72fb.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_turbo_dist_turbo_es2017-esm_js-8eb9b2209bcd.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_hotkey_dist_index_js-node_modules_github_hydro-analytics-client_d-dd3ec8-1f3d5f90de2b.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_quote-selection_dist_index_js-node_modules_github_session-resume_-31b9f3-9021ed20220b.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/packages_document-metadata_document-metadata_ts-packages_failbot_failbot_ts-06156f7d8d1a.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/packages_updatable-content_updatable-content_ts-38f5e2f7c2a7.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/app_assets_modules_github_behaviors_ajax-error_ts-app_assets_modules_github_behaviors_details-6493f1-cecb020e2bb7.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/app_assets_modules_github_behaviors_task-list_ts-app_assets_modules_github_throttled-input_ts-047775-cfe8770908d1.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/app_assets_modules_github_behaviors_commenting_edit_ts-app_assets_modules_github_behaviors_ht-83c235-d8c5bfe37d1d.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/behaviors-d431b500aedc.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_delegated-events_dist_index_js-node_modules_github_catalyst_lib_index_js-ef6d0f-20d6767cecc0.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/notifications-global-d89a4ddd4532.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_virtualized-list_es_index_js-node_modules_github_template-parts_lib_inde-f69fd1-ead47121f2f7.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_remote-form_dist_index_js-node_modules_delegated-events_dist_inde-0d71a9-129b4f34d384.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/app_assets_modules_github_ref-selector_ts-63ecfa2887c1.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/codespaces-8cfd06ba3e39.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_filter-input-element_dist_index_js-node_modules_github_remote-inp-3eebbd-7f6bf4b8b391.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_mini-throttle_dist_decorators_js-node_modules_delegated-events_di-e161aa-9086b9aee9d1.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_file-attachment-element_dist_index_js-node_modules_github_remote--abdaf7-71f92102de66.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/repositories-7c2a36f9c401.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_mini-throttle_dist_index_js-node_modules_github_catalyst_lib_inde-96937f-70732ff56a20.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/code-menu-614eb4e0c016.js" defer="defer"></script>
  
  <script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/primer-react-cdd6dd11a475.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/react-lib-25ef56e89e94.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/react-core-26c9e2751844.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/octicons-react-dfcd3f5e8531.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_emotion_is-prop-valid_dist_emotion-is-prop-valid_esm_js-node_modules_emo-825c28-cdae255a4bbc.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_mini-throttle_dist_index_js-node_modules_github_hydro-analytics-c-c228f9-e9af1d9bff76.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_tanstack_query-core_build_modern_mutation_js-node_modules_tanstack_query-9bf7e4-2246c69bea10.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_swc_helpers_esm__class_private_method_get_js-node_modules_swc_helpers_es-d6b1a6-13297632eddc.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/packages_notifications-subscriptions-menu_entry_ts-packages_promise-with-resolvers-polyfill_p-15cb60-9c0f034a796f.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/notifications-subscriptions-menu-c28df4f8626e.js" defer="defer"></script>
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.f595f41454298e934d3c.module.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/notifications-subscriptions-menu.bab8822ac328fb95c70d.module.css" />

  <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.f595f41454298e934d3c.module.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/notifications-subscriptions-menu.bab8822ac328fb95c70d.module.css" />


  <title>GitHub - codefuse-ai/Awesome-Code-LLM: [TMLR] A curated list of language modeling researches for code (and other software engineering activities), plus related datasets.</title>



  <meta name="route-pattern" content="/:user_id/:repository" data-turbo-transient>
  <meta name="route-controller" content="files" data-turbo-transient>
  <meta name="route-action" content="disambiguate" data-turbo-transient>
  <meta name="fetch-nonce" content="v2:6be41ebd-a31d-c9f7-f234-9eba816399f5">

    
  <meta name="current-catalog-service-hash" content="f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb">


  <meta name="request-id" content="DC02:1A434F:BBC1BA:102AFF8:68FB5637" data-pjax-transient="true"/><meta name="html-safe-nonce" content="6c5b79325121764f3e7b2f56b9c435114922256726d86663d3013d53b5286b15" data-pjax-transient="true"/><meta name="visitor-payload" content="eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiJEQzAyOjFBNDM0RjpCQkMxQkE6MTAyQUZGODo2OEZCNTYzNyIsInZpc2l0b3JfaWQiOiIxNzM1NDgyNjc5ODk0OTU1NTQ1IiwicmVnaW9uX2VkZ2UiOiJpYWQiLCJyZWdpb25fcmVuZGVyIjoiaWFkIn0=" data-pjax-transient="true"/><meta name="visitor-hmac" content="1c9cbe15646f61be8115ad30816c48c87179522e251a25b032f3eac90d4e8335" data-pjax-transient="true"/>


    <meta name="hovercard-subject-tag" content="repository:694517360" data-turbo-transient>


  <meta name="github-keyboard-shortcuts" content="repository,copilot" data-turbo-transient="true" />
  

  <meta name="selected-link" value="repo_source" data-turbo-transient>
  <link rel="assets" href="https://github.githubassets.com/">

    <meta name="google-site-verification" content="Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I">

<meta name="octolytics-url" content="https://collector.github.com/github/collect" />

  <meta name="analytics-location" content="/&lt;user-name&gt;/&lt;repo-name&gt;" data-turbo-transient="true" />

  




    <meta name="user-login" content="">

  

    <meta name="viewport" content="width=device-width">

    

      <meta name="description" content="[TMLR] A curated list of language modeling researches for code (and other software engineering activities), plus related datasets. - codefuse-ai/Awesome-Code-LLM">

      <link rel="search" type="application/opensearchdescription+xml" href="/opensearch.xml" title="GitHub">

    <link rel="fluid-icon" href="https://github.com/fluidicon.png" title="GitHub">
    <meta property="fb:app_id" content="1401488693436528">
    <meta name="apple-itunes-app" content="app-id=1477376905, app-argument=https://github.com/codefuse-ai/Awesome-Code-LLM" />

      <meta name="twitter:image" content="https://opengraph.githubassets.com/89ac15822e6145476d08584ff8303cc3bd26fe1865b2c90e0e73bf0fc97a0dd7/codefuse-ai/Awesome-Code-LLM" /><meta name="twitter:site" content="@github" /><meta name="twitter:card" content="summary_large_image" /><meta name="twitter:title" content="GitHub - codefuse-ai/Awesome-Code-LLM: [TMLR] A curated list of language modeling researches for code (and other software engineering activities), plus related datasets." /><meta name="twitter:description" content="[TMLR] A curated list of language modeling researches for code (and other software engineering activities), plus related datasets. - codefuse-ai/Awesome-Code-LLM" />
  <meta property="og:image" content="https://opengraph.githubassets.com/89ac15822e6145476d08584ff8303cc3bd26fe1865b2c90e0e73bf0fc97a0dd7/codefuse-ai/Awesome-Code-LLM" /><meta property="og:image:alt" content="[TMLR] A curated list of language modeling researches for code (and other software engineering activities), plus related datasets. - codefuse-ai/Awesome-Code-LLM" /><meta property="og:image:width" content="1200" /><meta property="og:image:height" content="600" /><meta property="og:site_name" content="GitHub" /><meta property="og:type" content="object" /><meta property="og:title" content="GitHub - codefuse-ai/Awesome-Code-LLM: [TMLR] A curated list of language modeling researches for code (and other software engineering activities), plus related datasets." /><meta property="og:url" content="https://github.com/codefuse-ai/Awesome-Code-LLM" /><meta property="og:description" content="[TMLR] A curated list of language modeling researches for code (and other software engineering activities), plus related datasets. - codefuse-ai/Awesome-Code-LLM" />
  




      <meta name="hostname" content="github.com">



        <meta name="expected-hostname" content="github.com">


  <meta http-equiv="x-pjax-version" content="edb0d926ab1906770550b20a43d9b38dd31aa9f43125e46b0f03b199f9f5ffc9" data-turbo-track="reload">
  <meta http-equiv="x-pjax-csp-version" content="21a43568025709b66240454fc92d4f09335a96863f8ab1c46b4a07f6a5b67102" data-turbo-track="reload">
  <meta http-equiv="x-pjax-css-version" content="9a5723604920ed305ee49e39cb1005f635d72600a9d3ee8570586b8be07865c3" data-turbo-track="reload">
  <meta http-equiv="x-pjax-js-version" content="e219e7f22a568c92e2760b3fa72fe03f661aed0635cfdd507899c28619d497b7" data-turbo-track="reload">

  <meta name="turbo-cache-control" content="no-preview" data-turbo-transient="">

      <meta data-hydrostats="publish">
  <meta name="go-import" content="github.com/codefuse-ai/Awesome-Code-LLM git https://github.com/codefuse-ai/Awesome-Code-LLM.git">

  <meta name="octolytics-dimension-user_id" content="143480819" /><meta name="octolytics-dimension-user_login" content="codefuse-ai" /><meta name="octolytics-dimension-repository_id" content="694517360" /><meta name="octolytics-dimension-repository_nwo" content="codefuse-ai/Awesome-Code-LLM" /><meta name="octolytics-dimension-repository_public" content="true" /><meta name="octolytics-dimension-repository_is_fork" content="false" /><meta name="octolytics-dimension-repository_network_root_id" content="694517360" /><meta name="octolytics-dimension-repository_network_root_nwo" content="codefuse-ai/Awesome-Code-LLM" />



      <link rel="canonical" href="https://github.com/codefuse-ai/Awesome-Code-LLM" data-turbo-transient>


    <meta name="turbo-body-classes" content="logged-out env-production page-responsive">


  <meta name="browser-stats-url" content="https://api.github.com/_private/browser/stats">

  <meta name="browser-errors-url" content="https://api.github.com/_private/browser/errors">

  <meta name="release" content="52b212fa9d89c9c0399bcd8a7727377c16297ef9">
  <meta name="ui-target" content="full">

  <link rel="mask-icon" href="https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg" color="#000000">
  <link rel="alternate icon" class="js-site-favicon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png">
  <link rel="icon" class="js-site-favicon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg" data-base-href="https://github.githubassets.com/favicons/favicon">

<meta name="theme-color" content="#1e2327">
<meta name="color-scheme" content="light dark" />


  <link rel="manifest" href="/manifest.json" crossOrigin="use-credentials">

  </head>

  <body class="logged-out env-production page-responsive" style="word-wrap: break-word;">
    <div data-turbo-body class="logged-out env-production page-responsive" style="word-wrap: break-word;">
      



    <div class="position-relative header-wrapper js-header-wrapper ">
      <a href="#start-of-content" data-skip-target-assigned="false" class="px-2 py-4 color-bg-accent-emphasis color-fg-on-emphasis show-on-focus js-skip-to-content">Skip to content</a>

      <span data-view-component="true" class="progress-pjax-loader Progress position-fixed width-full">
    <span style="width: 0%;" data-view-component="true" class="Progress-item progress-pjax-loader-bar left-0 top-0 color-bg-accent-emphasis"></span>
</span>      
      
      <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.f595f41454298e934d3c.module.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/keyboard-shortcuts-dialog.2de9c7d6456a311fce49.module.css" />

<react-partial
  partial-name="keyboard-shortcuts-dialog"
  data-ssr="false"
  data-attempted-ssr="false"
  data-react-profiling="false"
>
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{"docsUrl":"https://docs.github.com/get-started/accessibility/keyboard-shortcuts"}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>





      

          

              
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_gsap_index_js-6265bea06e74.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/vendors-node_modules_github_remote-form_dist_index_js-node_modules_delegated-events_dist_inde-94fd67-dc050877d1bf.js" defer="defer"></script>
<script crossorigin="anonymous" type="application/javascript" src="https://github.githubassets.com/assets/sessions-917229b8a853.js" defer="defer"></script>

<header class="HeaderMktg header-logged-out js-details-container js-header Details f4 py-3" role="banner" data-is-top="true" data-color-mode=light data-light-theme=light data-dark-theme=dark>
  <h2 class="sr-only">Navigation Menu</h2>

  <button type="button" class="HeaderMktg-backdrop d-lg-none border-0 position-fixed top-0 left-0 width-full height-full js-details-target" aria-label="Toggle navigation">
    <span class="d-none">Toggle navigation</span>
  </button>

  <div class="d-flex flex-column flex-lg-row flex-items-center px-3 px-md-4 px-lg-5 height-full position-relative z-1">
    <div class="d-flex flex-justify-between flex-items-center width-full width-lg-auto">
      <div class="flex-1">
        <button aria-label="Toggle navigation" aria-expanded="false" type="button" data-view-component="true" class="js-details-target js-nav-padding-recalculate js-header-menu-toggle Button--link Button--medium Button d-lg-none color-fg-inherit p-1">  <span class="Button-content">
    <span class="Button-label"><div class="HeaderMenu-toggle-bar rounded my-1"></div>
            <div class="HeaderMenu-toggle-bar rounded my-1"></div>
            <div class="HeaderMenu-toggle-bar rounded my-1"></div></span>
  </span>
</button>
      </div>

      <a class="mr-lg-3 color-fg-inherit flex-order-2 js-prevent-focus-on-mobile-nav"
        href="/"
        aria-label="Homepage"
        data-analytics-event="{&quot;category&quot;:&quot;Marketing nav&quot;,&quot;action&quot;:&quot;click to go to homepage&quot;,&quot;label&quot;:&quot;ref_page:Marketing;ref_cta:Logomark;ref_loc:Header&quot;}">
        <svg height="32" aria-hidden="true" viewBox="0 0 24 24" version="1.1" width="32" data-view-component="true" class="octicon octicon-mark-github">
    <path d="M12 1C5.923 1 1 5.923 1 12c0 4.867 3.149 8.979 7.521 10.436.55.096.756-.233.756-.522 0-.262-.013-1.128-.013-2.049-2.764.509-3.479-.674-3.699-1.292-.124-.317-.66-1.293-1.127-1.554-.385-.207-.936-.715-.014-.729.866-.014 1.485.797 1.691 1.128.99 1.663 2.571 1.196 3.204.907.096-.715.385-1.196.701-1.471-2.448-.275-5.005-1.224-5.005-5.432 0-1.196.426-2.186 1.128-2.956-.111-.275-.496-1.402.11-2.915 0 0 .921-.288 3.024 1.128a10.193 10.193 0 0 1 2.75-.371c.936 0 1.871.123 2.75.371 2.104-1.43 3.025-1.128 3.025-1.128.605 1.513.221 2.64.111 2.915.701.77 1.127 1.747 1.127 2.956 0 4.222-2.571 5.157-5.019 5.432.399.344.743 1.004.743 2.035 0 1.471-.014 2.654-.014 3.025 0 .289.206.632.756.522C19.851 20.979 23 16.854 23 12c0-6.077-4.922-11-11-11Z"></path>
</svg>
      </a>

      <div class="d-flex flex-1 flex-order-2 text-right d-lg-none gap-2 flex-justify-end">
          <a
            href="/login?return_to=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FAwesome-Code-LLM"
            class="HeaderMenu-link HeaderMenu-button d-inline-flex f5 no-underline border color-border-default rounded-2 px-2 py-1 color-fg-inherit js-prevent-focus-on-mobile-nav"
            data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/codefuse-ai/Awesome-Code-LLM&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="5cf797975042acba6e0763cfc87e32cacfe957ec57a5b8ac4e0012d4b04cd344"
            data-analytics-event="{&quot;category&quot;:&quot;Marketing nav&quot;,&quot;action&quot;:&quot;click to Sign in&quot;,&quot;label&quot;:&quot;ref_page:Marketing;ref_cta:Sign in;ref_loc:Header&quot;}"
          >
            Sign in
          </a>
              <div class="AppHeader-appearanceSettings">
    <react-partial-anchor>
      <button data-target="react-partial-anchor.anchor" id="icon-button-a3eb42f6-81a9-45fd-adcb-5a608c3423b9" aria-labelledby="tooltip-ad38a622-ee6c-49cf-b3a7-38f13889b3de" type="button" disabled="disabled" data-view-component="true" class="Button Button--iconOnly Button--invisible Button--medium AppHeader-button HeaderMenu-link border cursor-wait">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-sliders Button-visual">
    <path d="M15 2.75a.75.75 0 0 1-.75.75h-4a.75.75 0 0 1 0-1.5h4a.75.75 0 0 1 .75.75Zm-8.5.75v1.25a.75.75 0 0 0 1.5 0v-4a.75.75 0 0 0-1.5 0V2H1.75a.75.75 0 0 0 0 1.5H6.5Zm1.25 5.25a.75.75 0 0 0 0-1.5h-6a.75.75 0 0 0 0 1.5h6ZM15 8a.75.75 0 0 1-.75.75H11.5V10a.75.75 0 1 1-1.5 0V6a.75.75 0 0 1 1.5 0v1.25h2.75A.75.75 0 0 1 15 8Zm-9 5.25v-2a.75.75 0 0 0-1.5 0v1.25H1.75a.75.75 0 0 0 0 1.5H4.5v1.25a.75.75 0 0 0 1.5 0v-2Zm9 0a.75.75 0 0 1-.75.75h-6a.75.75 0 0 1 0-1.5h6a.75.75 0 0 1 .75.75Z"></path>
</svg>
</button><tool-tip id="tooltip-ad38a622-ee6c-49cf-b3a7-38f13889b3de" for="icon-button-a3eb42f6-81a9-45fd-adcb-5a608c3423b9" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.f595f41454298e934d3c.module.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.6c63a6de228d6520804d.module.css" />

<react-partial
  partial-name="appearance-settings"
  data-ssr="false"
  data-attempted-ssr="false"
  data-react-profiling="false"
>
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>


      </template>
    </react-partial-anchor>
  </div>

      </div>
    </div>


    <div class="HeaderMenu js-header-menu height-fit position-lg-relative d-lg-flex flex-column flex-auto top-0">
      <div class="HeaderMenu-wrapper d-flex flex-column flex-self-start flex-lg-row flex-auto rounded rounded-lg-0">
            <nav class="HeaderMenu-nav" aria-label="Global">
              <ul class="d-lg-flex list-style-none">
                  <li class="HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item">
      <button type="button" class="HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target" aria-expanded="false">
        Platform
        <svg opacity="0.5" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-down HeaderMenu-icon ml-1">
    <path d="M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z"></path>
</svg>
      </button>

      <div class="HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 pt-2 pt-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 dropdown-menu-wide">
        <div class="d-lg-flex dropdown-menu-wide">
            <div class="HeaderMenu-column px-lg-4">
                <div class="">

                  <ul class="list-style-none f5" >
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_platform_navbar&quot;}" href="https://github.com/features/copilot">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-copilot color-fg-subtle mr-3">
    <path d="M23.922 16.992c-.861 1.495-5.859 5.023-11.922 5.023-6.063 0-11.061-3.528-11.922-5.023A.641.641 0 0 1 0 16.736v-2.869a.841.841 0 0 1 .053-.22c.372-.935 1.347-2.292 2.605-2.656.167-.429.414-1.055.644-1.517a10.195 10.195 0 0 1-.052-1.086c0-1.331.282-2.499 1.132-3.368.397-.406.89-.717 1.474-.952 1.399-1.136 3.392-2.093 6.122-2.093 2.731 0 4.767.957 6.166 2.093.584.235 1.077.546 1.474.952.85.869 1.132 2.037 1.132 3.368 0 .368-.014.733-.052 1.086.23.462.477 1.088.644 1.517 1.258.364 2.233 1.721 2.605 2.656a.832.832 0 0 1 .053.22v2.869a.641.641 0 0 1-.078.256ZM12.172 11h-.344a4.323 4.323 0 0 1-.355.508C10.703 12.455 9.555 13 7.965 13c-1.725 0-2.989-.359-3.782-1.259a2.005 2.005 0 0 1-.085-.104L4 11.741v6.585c1.435.779 4.514 2.179 8 2.179 3.486 0 6.565-1.4 8-2.179v-6.585l-.098-.104s-.033.045-.085.104c-.793.9-2.057 1.259-3.782 1.259-1.59 0-2.738-.545-3.508-1.492a4.323 4.323 0 0 1-.355-.508h-.016.016Zm.641-2.935c.136 1.057.403 1.913.878 2.497.442.544 1.134.938 2.344.938 1.573 0 2.292-.337 2.657-.751.384-.435.558-1.15.558-2.361 0-1.14-.243-1.847-.705-2.319-.477-.488-1.319-.862-2.824-1.025-1.487-.161-2.192.138-2.533.529-.269.307-.437.808-.438 1.578v.021c0 .265.021.562.063.893Zm-1.626 0c.042-.331.063-.628.063-.894v-.02c-.001-.77-.169-1.271-.438-1.578-.341-.391-1.046-.69-2.533-.529-1.505.163-2.347.537-2.824 1.025-.462.472-.705 1.179-.705 2.319 0 1.211.175 1.926.558 2.361.365.414 1.084.751 2.657.751 1.21 0 1.902-.394 2.344-.938.475-.584.742-1.44.878-2.497Z"></path><path d="M14.5 14.25a1 1 0 0 1 1 1v2a1 1 0 0 1-2 0v-2a1 1 0 0 1 1-1Zm-5 0a1 1 0 0 1 1 1v2a1 1 0 0 1-2 0v-2a1 1 0 0 1 1-1Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          GitHub Copilot

        </div>

        Write better code with AI
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_spark&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_spark_link_platform_navbar&quot;}" href="https://github.com/features/spark">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-sparkle-fill color-fg-subtle mr-3">
    <path d="M11.296 1.924c.24-.656 1.168-.656 1.408 0l.717 1.958a11.25 11.25 0 0 0 6.697 6.697l1.958.717c.657.24.657 1.168 0 1.408l-1.958.717a11.25 11.25 0 0 0-6.697 6.697l-.717 1.958c-.24.657-1.168.657-1.408 0l-.717-1.958a11.25 11.25 0 0 0-6.697-6.697l-1.958-.717c-.656-.24-.656-1.168 0-1.408l1.958-.717a11.25 11.25 0 0 0 6.697-6.697l.717-1.958Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          GitHub Spark

            <span class="HeaderMenu-label">
              New
            </span>
        </div>

        Build and deploy intelligent apps
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_models&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_models_link_platform_navbar&quot;}" href="https://github.com/features/models">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-ai-model color-fg-subtle mr-3">
    <path d="M19.375 8.5a3.25 3.25 0 1 1-3.163 4h-3a3.252 3.252 0 0 1-4.443 2.509L7.214 17.76a3.25 3.25 0 1 1-1.342-.674l1.672-2.957A3.238 3.238 0 0 1 6.75 12c0-.907.371-1.727.97-2.316L6.117 6.846A3.253 3.253 0 0 1 1.875 3.75a3.25 3.25 0 1 1 5.526 2.32l1.603 2.836A3.25 3.25 0 0 1 13.093 11h3.119a3.252 3.252 0 0 1 3.163-2.5ZM10 10.25a1.75 1.75 0 1 0-.001 3.499A1.75 1.75 0 0 0 10 10.25ZM5.125 2a1.75 1.75 0 1 0 0 3.5 1.75 1.75 0 0 0 0-3.5Zm12.5 9.75a1.75 1.75 0 1 0 3.5 0 1.75 1.75 0 0 0-3.5 0Zm-14.25 8.5a1.75 1.75 0 1 0 3.501-.001 1.75 1.75 0 0 0-3.501.001Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          GitHub Models

            <span class="HeaderMenu-label">
              New
            </span>
        </div>

        Manage and compare prompts
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_platform_navbar&quot;}" href="https://github.com/security/advanced-security">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-shield-check color-fg-subtle mr-3">
    <path d="M16.53 9.78a.75.75 0 0 0-1.06-1.06L11 13.19l-1.97-1.97a.75.75 0 0 0-1.06 1.06l2.5 2.5a.75.75 0 0 0 1.06 0l5-5Z"></path><path d="m12.54.637 8.25 2.675A1.75 1.75 0 0 1 22 4.976V10c0 6.19-3.771 10.704-9.401 12.83a1.704 1.704 0 0 1-1.198 0C5.77 20.705 2 16.19 2 10V4.976c0-.758.489-1.43 1.21-1.664L11.46.637a1.748 1.748 0 0 1 1.08 0Zm-.617 1.426-8.25 2.676a.249.249 0 0 0-.173.237V10c0 5.46 3.28 9.483 8.43 11.426a.199.199 0 0 0 .14 0C17.22 19.483 20.5 15.461 20.5 10V4.976a.25.25 0 0 0-.173-.237l-8.25-2.676a.253.253 0 0 0-.154 0Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          GitHub Advanced Security

        </div>

        Find and fix vulnerabilities
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_platform_navbar&quot;}" href="https://github.com/features/actions">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-workflow color-fg-subtle mr-3">
    <path d="M1 3a2 2 0 0 1 2-2h6.5a2 2 0 0 1 2 2v6.5a2 2 0 0 1-2 2H7v4.063C7 16.355 7.644 17 8.438 17H12.5v-2.5a2 2 0 0 1 2-2H21a2 2 0 0 1 2 2V21a2 2 0 0 1-2 2h-6.5a2 2 0 0 1-2-2v-2.5H8.437A2.939 2.939 0 0 1 5.5 15.562V11.5H3a2 2 0 0 1-2-2Zm2-.5a.5.5 0 0 0-.5.5v6.5a.5.5 0 0 0 .5.5h6.5a.5.5 0 0 0 .5-.5V3a.5.5 0 0 0-.5-.5ZM14.5 14a.5.5 0 0 0-.5.5V21a.5.5 0 0 0 .5.5H21a.5.5 0 0 0 .5-.5v-6.5a.5.5 0 0 0-.5-.5Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Actions

        </div>

        Automate any workflow
      </div>

    
</a></li>

                  </ul>
                </div>
            </div>
            <div class="HeaderMenu-column px-lg-4 pb-3 pb-lg-0 border-lg-right">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 pb-3">

                  <ul class="list-style-none f5" >
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_platform_navbar&quot;}" href="https://github.com/features/codespaces">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-codespaces color-fg-subtle mr-3">
    <path d="M3.5 3.75C3.5 2.784 4.284 2 5.25 2h13.5c.966 0 1.75.784 1.75 1.75v7.5A1.75 1.75 0 0 1 18.75 13H5.25a1.75 1.75 0 0 1-1.75-1.75Zm-2 12c0-.966.784-1.75 1.75-1.75h17.5c.966 0 1.75.784 1.75 1.75v4a1.75 1.75 0 0 1-1.75 1.75H3.25a1.75 1.75 0 0 1-1.75-1.75ZM5.25 3.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h13.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Zm-2 12a.25.25 0 0 0-.25.25v4c0 .138.112.25.25.25h17.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25Z"></path><path d="M10 17.75a.75.75 0 0 1 .75-.75h6.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1-.75-.75Zm-4 0a.75.75 0 0 1 .75-.75h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1-.75-.75Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Codespaces

        </div>

        Instant dev environments
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_platform_navbar&quot;}" href="https://github.com/features/issues">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-issue-opened color-fg-subtle mr-3">
    <path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1ZM2.5 12a9.5 9.5 0 0 0 9.5 9.5 9.5 9.5 0 0 0 9.5-9.5A9.5 9.5 0 0 0 12 2.5 9.5 9.5 0 0 0 2.5 12Zm9.5 2a2 2 0 1 1-.001-3.999A2 2 0 0 1 12 14Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Issues

        </div>

        Plan and track work
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_platform_navbar&quot;}" href="https://github.com/features/code-review">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-code-review color-fg-subtle mr-3">
    <path d="M10.3 6.74a.75.75 0 0 1-.04 1.06l-2.908 2.7 2.908 2.7a.75.75 0 1 1-1.02 1.1l-3.5-3.25a.75.75 0 0 1 0-1.1l3.5-3.25a.75.75 0 0 1 1.06.04Zm3.44 1.06a.75.75 0 1 1 1.02-1.1l3.5 3.25a.75.75 0 0 1 0 1.1l-3.5 3.25a.75.75 0 1 1-1.02-1.1l2.908-2.7-2.908-2.7Z"></path><path d="M1.5 4.25c0-.966.784-1.75 1.75-1.75h17.5c.966 0 1.75.784 1.75 1.75v12.5a1.75 1.75 0 0 1-1.75 1.75h-9.69l-3.573 3.573A1.458 1.458 0 0 1 5 21.043V18.5H3.25a1.75 1.75 0 0 1-1.75-1.75ZM3.25 4a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h2.5a.75.75 0 0 1 .75.75v3.19l3.72-3.72a.749.749 0 0 1 .53-.22h10a.25.25 0 0 0 .25-.25V4.25a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Code Review

        </div>

        Manage code changes
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_platform_navbar&quot;}" href="https://github.com/features/discussions">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-comment-discussion color-fg-subtle mr-3">
    <path d="M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v9.5A1.75 1.75 0 0 1 14.25 14H8.061l-2.574 2.573A1.458 1.458 0 0 1 3 15.543V14H1.75A1.75 1.75 0 0 1 0 12.25v-9.5C0 1.784.784 1 1.75 1ZM1.5 2.75v9.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-9.5a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Z"></path><path d="M22.5 8.75a.25.25 0 0 0-.25-.25h-3.5a.75.75 0 0 1 0-1.5h3.5c.966 0 1.75.784 1.75 1.75v9.5A1.75 1.75 0 0 1 22.25 20H21v1.543a1.457 1.457 0 0 1-2.487 1.03L15.939 20H10.75A1.75 1.75 0 0 1 9 18.25v-1.465a.75.75 0 0 1 1.5 0v1.465c0 .138.112.25.25.25h5.5a.75.75 0 0 1 .53.22l2.72 2.72v-2.19a.75.75 0 0 1 .75-.75h2a.25.25 0 0 0 .25-.25v-9.5Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Discussions

        </div>

        Collaborate outside of code
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_platform_navbar&quot;}" href="https://github.com/features/code-search">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-code-square color-fg-subtle mr-3">
    <path d="M10.3 8.24a.75.75 0 0 1-.04 1.06L7.352 12l2.908 2.7a.75.75 0 1 1-1.02 1.1l-3.5-3.25a.75.75 0 0 1 0-1.1l3.5-3.25a.75.75 0 0 1 1.06.04Zm3.44 1.06a.75.75 0 1 1 1.02-1.1l3.5 3.25a.75.75 0 0 1 0 1.1l-3.5 3.25a.75.75 0 1 1-1.02-1.1l2.908-2.7-2.908-2.7Z"></path><path d="M2 3.75C2 2.784 2.784 2 3.75 2h16.5c.966 0 1.75.784 1.75 1.75v16.5A1.75 1.75 0 0 1 20.25 22H3.75A1.75 1.75 0 0 1 2 20.25Zm1.75-.25a.25.25 0 0 0-.25.25v16.5c0 .138.112.25.25.25h16.5a.25.25 0 0 0 .25-.25V3.75a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Code Search

        </div>

        Find more, search less
      </div>

    
</a></li>

                  </ul>
                </div>
            </div>
            <div class="HeaderMenu-column px-lg-4">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 mb-3 pb-3">

                      <span class="d-block h4 color-fg-default my-1" id="platform-explore-heading">Explore</span>

                  <ul class="list-style-none f5" aria-labelledby="platform-explore-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;why_github&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;why_github_link_platform_navbar&quot;}" href="https://github.com/why-github">
      Why GitHub

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary Link--external" target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;documentation&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;documentation_link_platform_navbar&quot;}" href="https://docs.github.com">
      Documentation

    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle">
    <path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path>
</svg>
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary Link--external" target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_skills&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_skills_link_platform_navbar&quot;}" href="https://skills.github.com">
      GitHub Skills

    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle">
    <path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path>
</svg>
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary Link--external" target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;blog&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;blog_link_platform_navbar&quot;}" href="https://github.blog">
      Blog

    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle">
    <path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path>
</svg>
</a></li>

                  </ul>
                </div>
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 pb-3">

                      <span class="d-block h4 color-fg-default my-1" id="platform-integrations-heading">Integrations</span>

                  <ul class="list-style-none f5" aria-labelledby="platform-integrations-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_marketplace&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_marketplace_link_platform_navbar&quot;}" href="https://github.com/marketplace">
      GitHub Marketplace

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;mcp_registry&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;mcp_registry_link_platform_navbar&quot;}" href="https://github.com/mcp">
      MCP Registry

    
</a></li>

                  </ul>
                </div>
            </div>
        </div>

          <div class="HeaderMenu-trailing-link rounded-bottom-2 mt-lg-4 px-lg-4 py-4 py-lg-3 f5 text-semibold">
            <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all_features&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_features_link_platform_navbar&quot;}" href="https://github.com/features">
              View all features
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-right HeaderMenu-trailing-link-icon">
    <path d="M6.22 3.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L9.94 8 6.22 4.28a.75.75 0 0 1 0-1.06Z"></path>
</svg>
</a>          </div>
      </div>
</li>


                  <li class="HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item">
      <button type="button" class="HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target" aria-expanded="false">
        Solutions
        <svg opacity="0.5" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-down HeaderMenu-icon ml-1">
    <path d="M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z"></path>
</svg>
      </button>

      <div class="HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 pt-2 pt-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 dropdown-menu-wide">
        <div class="d-lg-flex dropdown-menu-wide">
            <div class="HeaderMenu-column px-lg-4 pb-3 pb-lg-0 border-lg-right">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 pb-3">

                      <span class="d-block h4 color-fg-default my-1" id="solutions-by-company-size-heading">By company size</span>

                  <ul class="list-style-none f5" aria-labelledby="solutions-by-company-size-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprises&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprises_link_solutions_navbar&quot;}" href="https://github.com/enterprise">
      Enterprises

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;small_and_medium_teams&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;small_and_medium_teams_link_solutions_navbar&quot;}" href="https://github.com/team">
      Small and medium teams

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;startups&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;startups_link_solutions_navbar&quot;}" href="https://github.com/enterprise/startups">
      Startups

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;nonprofits&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;nonprofits_link_solutions_navbar&quot;}" href="/solutions/industry/nonprofits">
      Nonprofits

    
</a></li>

                  </ul>
                </div>
            </div>
            <div class="HeaderMenu-column px-lg-4 pb-3 pb-lg-0 border-lg-right">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 pb-3">

                      <span class="d-block h4 color-fg-default my-1" id="solutions-by-use-case-heading">By use case</span>

                  <ul class="list-style-none f5" aria-labelledby="solutions-by-use-case-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;app_modernization&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;app_modernization_link_solutions_navbar&quot;}" href="/solutions/use-case/app-modernization">
      App Modernization

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;devsecops&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;devsecops_link_solutions_navbar&quot;}" href="/solutions/use-case/devsecops">
      DevSecOps

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;devops&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;devops_link_solutions_navbar&quot;}" href="/solutions/use-case/devops">
      DevOps

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ci_cd&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ci_cd_link_solutions_navbar&quot;}" href="/solutions/use-case/ci-cd">
      CI/CD

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all_use_cases&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_use_cases_link_solutions_navbar&quot;}" href="/solutions/use-case">
      View all use cases

    
</a></li>

                  </ul>
                </div>
            </div>
            <div class="HeaderMenu-column px-lg-4">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 pb-3">

                      <span class="d-block h4 color-fg-default my-1" id="solutions-by-industry-heading">By industry</span>

                  <ul class="list-style-none f5" aria-labelledby="solutions-by-industry-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;healthcare&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;healthcare_link_solutions_navbar&quot;}" href="/solutions/industry/healthcare">
      Healthcare

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;financial_services&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;financial_services_link_solutions_navbar&quot;}" href="/solutions/industry/financial-services">
      Financial services

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;manufacturing&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;manufacturing_link_solutions_navbar&quot;}" href="/solutions/industry/manufacturing">
      Manufacturing

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;government&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;government_link_solutions_navbar&quot;}" href="/solutions/industry/government">
      Government

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all_industries&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_industries_link_solutions_navbar&quot;}" href="/solutions/industry">
      View all industries

    
</a></li>

                  </ul>
                </div>
            </div>
        </div>

          <div class="HeaderMenu-trailing-link rounded-bottom-2 mt-lg-4 px-lg-4 py-4 py-lg-3 f5 text-semibold">
            <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all_solutions&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_solutions_link_solutions_navbar&quot;}" href="/solutions">
              View all solutions
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-right HeaderMenu-trailing-link-icon">
    <path d="M6.22 3.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L9.94 8 6.22 4.28a.75.75 0 0 1 0-1.06Z"></path>
</svg>
</a>          </div>
      </div>
</li>


                  <li class="HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item">
      <button type="button" class="HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target" aria-expanded="false">
        Resources
        <svg opacity="0.5" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-down HeaderMenu-icon ml-1">
    <path d="M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z"></path>
</svg>
      </button>

      <div class="HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 pt-2 pt-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 pb-2 pb-lg-4 dropdown-menu-wide">
        <div class="d-lg-flex dropdown-menu-wide">
            <div class="HeaderMenu-column px-lg-4 pb-3 pb-lg-0 border-lg-right">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 pb-3">

                      <span class="d-block h4 color-fg-default my-1" id="resources-topics-heading">Topics</span>

                  <ul class="list-style-none f5" aria-labelledby="resources-topics-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ai&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ai_link_resources_navbar&quot;}" href="/resources/articles?topic=ai">
      AI

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;devops&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;devops_link_resources_navbar&quot;}" href="/resources/articles?topic=devops">
      DevOps

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;security&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;security_link_resources_navbar&quot;}" href="/resources/articles?topic=security">
      Security

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;software_development&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;software_development_link_resources_navbar&quot;}" href="/resources/articles?topic=software-development">
      Software Development

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;view_all&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;view_all_link_resources_navbar&quot;}" href="/resources/articles">
      View all

    
</a></li>

                  </ul>
                </div>
            </div>
            <div class="HeaderMenu-column px-lg-4">
                <div class="border-bottom border-lg-bottom-0 pb-lg-0 border-bottom-0">

                      <span class="d-block h4 color-fg-default my-1" id="resources-explore-heading">Explore</span>

                  <ul class="list-style-none f5" aria-labelledby="resources-explore-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary Link--external" target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-link-external HeaderMenu-external-icon color-fg-subtle">
    <path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path>
</svg>
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;events_amp_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;events_amp_webinars_link_resources_navbar&quot;}" href="https://github.com/resources/events">
      Events &amp; Webinars

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ebooks_amp_whitepapers&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ebooks_amp_whitepapers_link_resources_navbar&quot;}" href="https://github.com/resources/whitepapers">
      Ebooks &amp; Whitepapers

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://github.com/partners">
      Partners

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                  </ul>
                </div>
            </div>
        </div>

      </div>
</li>


                  <li class="HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item">
      <button type="button" class="HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target" aria-expanded="false">
        Open Source
        <svg opacity="0.5" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-down HeaderMenu-icon ml-1">
    <path d="M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z"></path>
</svg>
      </button>

      <div class="HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 pt-2 pt-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 pb-2 pb-lg-4">
        <div class="d-lg-flex dropdown-menu-wide">
            <div class="HeaderMenu-column px-lg-4">
                <div class="border-bottom mb-3 mb-lg-3 pb-3">

                  <ul class="list-style-none f5" >
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="/sponsors">
      
      <div>
        <div class="color-fg-default h4">
          GitHub Sponsors

        </div>

        Fund open source developers
      </div>

    
</a></li>

                  </ul>
                </div>
                <div class="border-bottom mb-3 mb-lg-3 pb-3">

                  <ul class="list-style-none f5" >
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
        <div class="color-fg-default h4">
          The ReadME Project

        </div>

        GitHub community articles
      </div>

    
</a></li>

                  </ul>
                </div>
                <div class="border-bottom border-bottom-0">

                      <span class="d-block h4 color-fg-default my-1" id="open-source-repositories-heading">Repositories</span>

                  <ul class="list-style-none f5" aria-labelledby="open-source-repositories-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;topics&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;topics_link_open_source_navbar&quot;}" href="https://github.com/topics">
      Topics

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;trending&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;trending_link_open_source_navbar&quot;}" href="https://github.com/trending">
      Trending

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;collections&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;collections_link_open_source_navbar&quot;}" href="https://github.com/collections">
      Collections

    
</a></li>

                  </ul>
                </div>
            </div>
        </div>

      </div>
</li>


                  <li class="HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item">
      <button type="button" class="HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target" aria-expanded="false">
        Enterprise
        <svg opacity="0.5" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-chevron-down HeaderMenu-icon ml-1">
    <path d="M12.78 5.22a.749.749 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.06 0L3.22 6.28a.749.749 0 1 1 1.06-1.06L8 8.939l3.72-3.719a.749.749 0 0 1 1.06 0Z"></path>
</svg>
      </button>

      <div class="HeaderMenu-dropdown dropdown-menu rounded m-0 p-0 pt-2 pt-lg-4 position-relative position-lg-absolute left-0 left-lg-n3 pb-2 pb-lg-4">
        <div class="d-lg-flex dropdown-menu-wide">
            <div class="HeaderMenu-column px-lg-4">
                <div class="border-bottom mb-3 mb-lg-3 pb-3">

                  <ul class="list-style-none f5" >
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="/enterprise">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-stack color-fg-subtle mr-3">
    <path d="M11.063 1.456a1.749 1.749 0 0 1 1.874 0l8.383 5.316a1.751 1.751 0 0 1 0 2.956l-8.383 5.316a1.749 1.749 0 0 1-1.874 0L2.68 9.728a1.751 1.751 0 0 1 0-2.956Zm1.071 1.267a.25.25 0 0 0-.268 0L3.483 8.039a.25.25 0 0 0 0 .422l8.383 5.316a.25.25 0 0 0 .268 0l8.383-5.316a.25.25 0 0 0 0-.422Z"></path><path d="M1.867 12.324a.75.75 0 0 1 1.035-.232l8.964 5.685a.25.25 0 0 0 .268 0l8.964-5.685a.75.75 0 0 1 .804 1.267l-8.965 5.685a1.749 1.749 0 0 1-1.874 0l-8.965-5.685a.75.75 0 0 1-.231-1.035Z"></path><path d="M1.867 16.324a.75.75 0 0 1 1.035-.232l8.964 5.685a.25.25 0 0 0 .268 0l8.964-5.685a.75.75 0 0 1 .804 1.267l-8.965 5.685a1.749 1.749 0 0 1-1.874 0l-8.965-5.685a.75.75 0 0 1-.231-1.035Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Enterprise platform

        </div>

        AI-powered developer platform
      </div>

    
</a></li>

                  </ul>
                </div>
                <div class="border-bottom border-bottom-0">

                      <span class="d-block h4 color-fg-default my-1" id="enterprise-available-add-ons-heading">Available add-ons</span>

                  <ul class="list-style-none f5" aria-labelledby="enterprise-available-add-ons-heading">
                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_enterprise_navbar&quot;}" href="https://github.com/security/advanced-security">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-shield-check color-fg-subtle mr-3">
    <path d="M16.53 9.78a.75.75 0 0 0-1.06-1.06L11 13.19l-1.97-1.97a.75.75 0 0 0-1.06 1.06l2.5 2.5a.75.75 0 0 0 1.06 0l5-5Z"></path><path d="m12.54.637 8.25 2.675A1.75 1.75 0 0 1 22 4.976V10c0 6.19-3.771 10.704-9.401 12.83a1.704 1.704 0 0 1-1.198 0C5.77 20.705 2 16.19 2 10V4.976c0-.758.489-1.43 1.21-1.664L11.46.637a1.748 1.748 0 0 1 1.08 0Zm-.617 1.426-8.25 2.676a.249.249 0 0 0-.173.237V10c0 5.46 3.28 9.483 8.43 11.426a.199.199 0 0 0 .14 0C17.22 19.483 20.5 15.461 20.5 10V4.976a.25.25 0 0 0-.173-.237l-8.25-2.676a.253.253 0 0 0-.154 0Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          GitHub Advanced Security

        </div>

        Enterprise-grade security features
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description mb-lg-3" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;copilot_for_business&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;copilot_for_business_link_enterprise_navbar&quot;}" href="/features/copilot/copilot-business">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-copilot color-fg-subtle mr-3">
    <path d="M23.922 16.992c-.861 1.495-5.859 5.023-11.922 5.023-6.063 0-11.061-3.528-11.922-5.023A.641.641 0 0 1 0 16.736v-2.869a.841.841 0 0 1 .053-.22c.372-.935 1.347-2.292 2.605-2.656.167-.429.414-1.055.644-1.517a10.195 10.195 0 0 1-.052-1.086c0-1.331.282-2.499 1.132-3.368.397-.406.89-.717 1.474-.952 1.399-1.136 3.392-2.093 6.122-2.093 2.731 0 4.767.957 6.166 2.093.584.235 1.077.546 1.474.952.85.869 1.132 2.037 1.132 3.368 0 .368-.014.733-.052 1.086.23.462.477 1.088.644 1.517 1.258.364 2.233 1.721 2.605 2.656a.832.832 0 0 1 .053.22v2.869a.641.641 0 0 1-.078.256ZM12.172 11h-.344a4.323 4.323 0 0 1-.355.508C10.703 12.455 9.555 13 7.965 13c-1.725 0-2.989-.359-3.782-1.259a2.005 2.005 0 0 1-.085-.104L4 11.741v6.585c1.435.779 4.514 2.179 8 2.179 3.486 0 6.565-1.4 8-2.179v-6.585l-.098-.104s-.033.045-.085.104c-.793.9-2.057 1.259-3.782 1.259-1.59 0-2.738-.545-3.508-1.492a4.323 4.323 0 0 1-.355-.508h-.016.016Zm.641-2.935c.136 1.057.403 1.913.878 2.497.442.544 1.134.938 2.344.938 1.573 0 2.292-.337 2.657-.751.384-.435.558-1.15.558-2.361 0-1.14-.243-1.847-.705-2.319-.477-.488-1.319-.862-2.824-1.025-1.487-.161-2.192.138-2.533.529-.269.307-.437.808-.438 1.578v.021c0 .265.021.562.063.893Zm-1.626 0c.042-.331.063-.628.063-.894v-.02c-.001-.77-.169-1.271-.438-1.578-.341-.391-1.046-.69-2.533-.529-1.505.163-2.347.537-2.824 1.025-.462.472-.705 1.179-.705 2.319 0 1.211.175 1.926.558 2.361.365.414 1.084.751 2.657.751 1.21 0 1.902-.394 2.344-.938.475-.584.742-1.44.878-2.497Z"></path><path d="M14.5 14.25a1 1 0 0 1 1 1v2a1 1 0 0 1-2 0v-2a1 1 0 0 1 1-1Zm-5 0a1 1 0 0 1 1 1v2a1 1 0 0 1-2 0v-2a1 1 0 0 1 1-1Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Copilot for business

        </div>

        Enterprise-grade AI features
      </div>

    
</a></li>

                      <li>
  <a class="HeaderMenu-dropdown-link d-block no-underline position-relative py-2 Link--secondary d-flex flex-items-center Link--has-description" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;premium_support&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;premium_support_link_enterprise_navbar&quot;}" href="/premium-support">
      <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-comment-discussion color-fg-subtle mr-3">
    <path d="M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v9.5A1.75 1.75 0 0 1 14.25 14H8.061l-2.574 2.573A1.458 1.458 0 0 1 3 15.543V14H1.75A1.75 1.75 0 0 1 0 12.25v-9.5C0 1.784.784 1 1.75 1ZM1.5 2.75v9.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-9.5a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Z"></path><path d="M22.5 8.75a.25.25 0 0 0-.25-.25h-3.5a.75.75 0 0 1 0-1.5h3.5c.966 0 1.75.784 1.75 1.75v9.5A1.75 1.75 0 0 1 22.25 20H21v1.543a1.457 1.457 0 0 1-2.487 1.03L15.939 20H10.75A1.75 1.75 0 0 1 9 18.25v-1.465a.75.75 0 0 1 1.5 0v1.465c0 .138.112.25.25.25h5.5a.75.75 0 0 1 .53.22l2.72 2.72v-2.19a.75.75 0 0 1 .75-.75h2a.25.25 0 0 0 .25-.25v-9.5Z"></path>
</svg>
      <div>
        <div class="color-fg-default h4">
          Premium Support

        </div>

        Enterprise-grade 24/7 support
      </div>

    
</a></li>

                  </ul>
                </div>
            </div>
        </div>

      </div>
</li>


                  <li class="HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item">
    <a class="HeaderMenu-link no-underline px-0 px-lg-2 py-3 py-lg-2 d-block d-lg-inline-block" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;platform&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;platform_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

              </ul>
            </nav>

        <div class="d-flex flex-column flex-lg-row width-full flex-justify-end flex-lg-items-center text-center mt-3 mt-lg-0 text-lg-left ml-lg-3">
                


<qbsearch-input class="search-input" data-scope="repo:codefuse-ai/Awesome-Code-LLM" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="esvQcSa6rNeJPq_7Yf9YPwkmjMMlxwb47kUvx2QAPGfD_cw2L5-MLo5wkLy0x4gWRl-lyLXMvjLaAgLHdxaVBg" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="codefuse-ai/Awesome-Code-LLM" data-current-org="codefuse-ai" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div
    class="search-input-container search-with-dialog position-relative d-flex flex-row flex-items-center mr-4 rounded"
    data-action="click:qbsearch-input#searchInputContainerClicked"
  >
      <button
        type="button"
        class="header-search-button placeholder  input-button form-control d-flex flex-1 flex-self-stretch flex-items-center no-wrap width-full py-0 pl-2 pr-0 text-left border-0 box-shadow-none"
        data-target="qbsearch-input.inputButton"
        aria-label="Search or jump to"
        aria-haspopup="dialog"
        placeholder="Search or jump to..."
        data-hotkey=s,/
        autocapitalize="off"
        data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;searchbar&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;input&quot;,&quot;label&quot;:&quot;searchbar_input_global_navbar&quot;}"
        data-action="click:qbsearch-input#handleExpand"
      >
        <div class="mr-2 color-fg-muted">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-search">
    <path d="M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z"></path>
</svg>
        </div>
        <span class="flex-1" data-target="qbsearch-input.inputButtonText">Search or jump to...</span>
          <div class="d-flex" data-target="qbsearch-input.hotkeyIndicator">
            <svg xmlns="http://www.w3.org/2000/svg" width="22" height="20" aria-hidden="true" class="mr-1"><path fill="none" stroke="#979A9C" opacity=".4" d="M3.5.5h12c1.7 0 3 1.3 3 3v13c0 1.7-1.3 3-3 3h-12c-1.7 0-3-1.3-3-3v-13c0-1.7 1.3-3 3-3z"></path><path fill="#979A9C" d="M11.8 6L8 15.1h-.9L10.8 6h1z"></path></svg>
          </div>
      </button>

    <input type="hidden" name="type" class="js-site-search-type-field">

    
<div class="Overlay--hidden " data-modal-dialog-overlay>
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true" class="Overlay Overlay--width-large Overlay--height-auto">
      <h1 id="search-suggestions-dialog-header" class="sr-only">Search code, repositories, users, issues, pull requests...</h1>
    <div class="Overlay-body Overlay-body--paddingNone">
      
          <div data-view-component="true">        <div class="search-suggestions position-fixed width-full color-shadow-large border color-fg-default color-bg-default overflow-hidden d-flex flex-column query-builder-container"
          style="border-radius: 12px;"
          data-target="qbsearch-input.queryBuilderContainer"
          hidden
        >
          <!-- '"` --><!-- </textarea></xmp> --></option></form><form id="query-builder-test-form" action="" accept-charset="UTF-8" method="get">
  <query-builder data-target="qbsearch-input.queryBuilder" id="query-builder-query-builder-test" data-filter-key=":" data-view-component="true" class="QueryBuilder search-query-builder">
    <div class="FormControl FormControl--fullWidth">
      <label id="query-builder-test-label" for="query-builder-test" class="FormControl-label sr-only">
        Search
      </label>
      <div
        class="QueryBuilder-StyledInput width-fit "
        data-target="query-builder.styledInput"
      >
          <span id="query-builder-test-leadingvisual-wrap" class="FormControl-input-leadingVisualWrap QueryBuilder-leadingVisualWrap">
            <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-search FormControl-input-leadingVisual">
    <path d="M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z"></path>
</svg>
          </span>
        <div data-target="query-builder.styledInputContainer" class="QueryBuilder-StyledInputContainer">
          <div
            aria-hidden="true"
            class="QueryBuilder-StyledInputContent"
            data-target="query-builder.styledInputContent"
          ></div>
          <div class="QueryBuilder-InputWrapper">
            <div aria-hidden="true" class="QueryBuilder-Sizer" data-target="query-builder.sizer"></div>
            <input id="query-builder-test" name="query-builder-test" value="" autocomplete="off" type="text" role="combobox" spellcheck="false" aria-expanded="false" aria-describedby="validation-088f4470-f4a7-438a-9c6b-2a302310d1e5" data-target="query-builder.input" data-action="
          input:query-builder#inputChange
          blur:query-builder#inputBlur
          keydown:query-builder#inputKeydown
          focus:query-builder#inputFocus
        " data-view-component="true" class="FormControl-input QueryBuilder-Input FormControl-medium" />
          </div>
        </div>
          <span class="sr-only" id="query-builder-test-clear">Clear</span>
          <button role="button" id="query-builder-test-clear-button" aria-labelledby="query-builder-test-clear query-builder-test-label" data-target="query-builder.clearButton" data-action="
                click:query-builder#clear
                focus:query-builder#clearButtonFocus
                blur:query-builder#clearButtonBlur
              " variant="small" hidden="hidden" type="button" data-view-component="true" class="Button Button--iconOnly Button--invisible Button--medium mr-1 px-2 py-0 d-flex flex-items-center rounded-1 color-fg-muted">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x-circle-fill Button-visual">
    <path d="M2.343 13.657A8 8 0 1 1 13.658 2.343 8 8 0 0 1 2.343 13.657ZM6.03 4.97a.751.751 0 0 0-1.042.018.751.751 0 0 0-.018 1.042L6.94 8 4.97 9.97a.749.749 0 0 0 .326 1.275.749.749 0 0 0 .734-.215L8 9.06l1.97 1.97a.749.749 0 0 0 1.275-.326.749.749 0 0 0-.215-.734L9.06 8l1.97-1.97a.749.749 0 0 0-.326-1.275.749.749 0 0 0-.734.215L8 6.94Z"></path>
</svg>
</button>

      </div>
      <template id="search-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-search">
    <path d="M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z"></path>
</svg>
</template>

<template id="code-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-code">
    <path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path>
</svg>
</template>

<template id="file-code-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-file-code">
    <path d="M4 1.75C4 .784 4.784 0 5.75 0h5.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v8.586A1.75 1.75 0 0 1 14.25 15h-9a.75.75 0 0 1 0-1.5h9a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 10 4.25V1.5H5.75a.25.25 0 0 0-.25.25v2.5a.75.75 0 0 1-1.5 0Zm1.72 4.97a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734l1.47-1.47-1.47-1.47a.75.75 0 0 1 0-1.06ZM3.28 7.78 1.81 9.25l1.47 1.47a.751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Zm8.22-6.218V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path>
</svg>
</template>

<template id="history-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-history">
    <path d="m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z"></path>
</svg>
</template>

<template id="repo-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo">
    <path d="M2 2.5A2.5 2.5 0 0 1 4.5 0h8.75a.75.75 0 0 1 .75.75v12.5a.75.75 0 0 1-.75.75h-2.5a.75.75 0 0 1 0-1.5h1.75v-2h-8a1 1 0 0 0-.714 1.7.75.75 0 1 1-1.072 1.05A2.495 2.495 0 0 1 2 11.5Zm10.5-1h-8a1 1 0 0 0-1 1v6.708A2.486 2.486 0 0 1 4.5 9h8ZM5 12.25a.25.25 0 0 1 .25-.25h3.5a.25.25 0 0 1 .25.25v3.25a.25.25 0 0 1-.4.2l-1.45-1.087a.249.249 0 0 0-.3 0L5.4 15.7a.25.25 0 0 1-.4-.2Z"></path>
</svg>
</template>

<template id="bookmark-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-bookmark">
    <path d="M3 2.75C3 1.784 3.784 1 4.75 1h6.5c.966 0 1.75.784 1.75 1.75v11.5a.75.75 0 0 1-1.227.579L8 11.722l-3.773 3.107A.751.751 0 0 1 3 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v9.91l3.023-2.489a.75.75 0 0 1 .954 0l3.023 2.49V2.75a.25.25 0 0 0-.25-.25Z"></path>
</svg>
</template>

<template id="plus-circle-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-plus-circle">
    <path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm7.25-3.25v2.5h2.5a.75.75 0 0 1 0 1.5h-2.5v2.5a.75.75 0 0 1-1.5 0v-2.5h-2.5a.75.75 0 0 1 0-1.5h2.5v-2.5a.75.75 0 0 1 1.5 0Z"></path>
</svg>
</template>

<template id="circle-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-dot-fill">
    <path d="M8 4a4 4 0 1 1 0 8 4 4 0 0 1 0-8Z"></path>
</svg>
</template>

<template id="trash-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-trash">
    <path d="M11 1.75V3h2.25a.75.75 0 0 1 0 1.5H2.75a.75.75 0 0 1 0-1.5H5V1.75C5 .784 5.784 0 6.75 0h2.5C10.216 0 11 .784 11 1.75ZM4.496 6.675l.66 6.6a.25.25 0 0 0 .249.225h5.19a.25.25 0 0 0 .249-.225l.66-6.6a.75.75 0 0 1 1.492.149l-.66 6.6A1.748 1.748 0 0 1 10.595 15h-5.19a1.75 1.75 0 0 1-1.741-1.575l-.66-6.6a.75.75 0 1 1 1.492-.15ZM6.5 1.75V3h3V1.75a.25.25 0 0 0-.25-.25h-2.5a.25.25 0 0 0-.25.25Z"></path>
</svg>
</template>

<template id="team-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-people">
    <path d="M2 5.5a3.5 3.5 0 1 1 5.898 2.549 5.508 5.508 0 0 1 3.034 4.084.75.75 0 1 1-1.482.235 4 4 0 0 0-7.9 0 .75.75 0 0 1-1.482-.236A5.507 5.507 0 0 1 3.102 8.05 3.493 3.493 0 0 1 2 5.5ZM11 4a3.001 3.001 0 0 1 2.22 5.018 5.01 5.01 0 0 1 2.56 3.012.749.749 0 0 1-.885.954.752.752 0 0 1-.549-.514 3.507 3.507 0 0 0-2.522-2.372.75.75 0 0 1-.574-.73v-.352a.75.75 0 0 1 .416-.672A1.5 1.5 0 0 0 11 5.5.75.75 0 0 1 11 4Zm-5.5-.5a2 2 0 1 0-.001 3.999A2 2 0 0 0 5.5 3.5Z"></path>
</svg>
</template>

<template id="project-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-project">
    <path d="M1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25V1.75C0 .784.784 0 1.75 0ZM1.5 1.75v12.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25ZM11.75 3a.75.75 0 0 1 .75.75v7.5a.75.75 0 0 1-1.5 0v-7.5a.75.75 0 0 1 .75-.75Zm-8.25.75a.75.75 0 0 1 1.5 0v5.5a.75.75 0 0 1-1.5 0ZM8 3a.75.75 0 0 1 .75.75v3.5a.75.75 0 0 1-1.5 0v-3.5A.75.75 0 0 1 8 3Z"></path>
</svg>
</template>

<template id="pencil-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-pencil">
    <path d="M11.013 1.427a1.75 1.75 0 0 1 2.474 0l1.086 1.086a1.75 1.75 0 0 1 0 2.474l-8.61 8.61c-.21.21-.47.364-.756.445l-3.251.93a.75.75 0 0 1-.927-.928l.929-3.25c.081-.286.235-.547.445-.758l8.61-8.61Zm.176 4.823L9.75 4.81l-6.286 6.287a.253.253 0 0 0-.064.108l-.558 1.953 1.953-.558a.253.253 0 0 0 .108-.064Zm1.238-3.763a.25.25 0 0 0-.354 0L10.811 3.75l1.439 1.44 1.263-1.263a.25.25 0 0 0 0-.354Z"></path>
</svg>
</template>

<template id="copilot-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copilot">
    <path d="M7.998 15.035c-4.562 0-7.873-2.914-7.998-3.749V9.338c.085-.628.677-1.686 1.588-2.065.013-.07.024-.143.036-.218.029-.183.06-.384.126-.612-.201-.508-.254-1.084-.254-1.656 0-.87.128-1.769.693-2.484.579-.733 1.494-1.124 2.724-1.261 1.206-.134 2.262.034 2.944.765.05.053.096.108.139.165.044-.057.094-.112.143-.165.682-.731 1.738-.899 2.944-.765 1.23.137 2.145.528 2.724 1.261.566.715.693 1.614.693 2.484 0 .572-.053 1.148-.254 1.656.066.228.098.429.126.612.012.076.024.148.037.218.924.385 1.522 1.471 1.591 2.095v1.872c0 .766-3.351 3.795-8.002 3.795Zm0-1.485c2.28 0 4.584-1.11 5.002-1.433V7.862l-.023-.116c-.49.21-1.075.291-1.727.291-1.146 0-2.059-.327-2.71-.991A3.222 3.222 0 0 1 8 6.303a3.24 3.24 0 0 1-.544.743c-.65.664-1.563.991-2.71.991-.652 0-1.236-.081-1.727-.291l-.023.116v4.255c.419.323 2.722 1.433 5.002 1.433ZM6.762 2.83c-.193-.206-.637-.413-1.682-.297-1.019.113-1.479.404-1.713.7-.247.312-.369.789-.369 1.554 0 .793.129 1.171.308 1.371.162.181.519.379 1.442.379.853 0 1.339-.235 1.638-.54.315-.322.527-.827.617-1.553.117-.935-.037-1.395-.241-1.614Zm4.155-.297c-1.044-.116-1.488.091-1.681.297-.204.219-.359.679-.242 1.614.091.726.303 1.231.618 1.553.299.305.784.54 1.638.54.922 0 1.28-.198 1.442-.379.179-.2.308-.578.308-1.371 0-.765-.123-1.242-.37-1.554-.233-.296-.693-.587-1.713-.7Z"></path><path d="M6.25 9.037a.75.75 0 0 1 .75.75v1.501a.75.75 0 0 1-1.5 0V9.787a.75.75 0 0 1 .75-.75Zm4.25.75v1.501a.75.75 0 0 1-1.5 0V9.787a.75.75 0 0 1 1.5 0Z"></path>
</svg>
</template>

<template id="copilot-error-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copilot-error">
    <path d="M16 11.24c0 .112-.072.274-.21.467L13 9.688V7.862l-.023-.116c-.49.21-1.075.291-1.727.291-.198 0-.388-.009-.571-.029L6.833 5.226a4.01 4.01 0 0 0 .17-.782c.117-.935-.037-1.395-.241-1.614-.193-.206-.637-.413-1.682-.297-.683.076-1.115.231-1.395.415l-1.257-.91c.579-.564 1.413-.877 2.485-.996 1.206-.134 2.262.034 2.944.765.05.053.096.108.139.165.044-.057.094-.112.143-.165.682-.731 1.738-.899 2.944-.765 1.23.137 2.145.528 2.724 1.261.566.715.693 1.614.693 2.484 0 .572-.053 1.148-.254 1.656.066.228.098.429.126.612.012.076.024.148.037.218.924.385 1.522 1.471 1.591 2.095Zm-5.083-8.707c-1.044-.116-1.488.091-1.681.297-.204.219-.359.679-.242 1.614.091.726.303 1.231.618 1.553.299.305.784.54 1.638.54.922 0 1.28-.198 1.442-.379.179-.2.308-.578.308-1.371 0-.765-.123-1.242-.37-1.554-.233-.296-.693-.587-1.713-.7Zm2.511 11.074c-1.393.776-3.272 1.428-5.43 1.428-4.562 0-7.873-2.914-7.998-3.749V9.338c.085-.628.677-1.686 1.588-2.065.013-.07.024-.143.036-.218.029-.183.06-.384.126-.612-.18-.455-.241-.963-.252-1.475L.31 4.107A.747.747 0 0 1 0 3.509V3.49a.748.748 0 0 1 .625-.73c.156-.026.306.047.435.139l14.667 10.578a.592.592 0 0 1 .227.264.752.752 0 0 1 .046.249v.022a.75.75 0 0 1-1.19.596Zm-1.367-.991L5.635 7.964a5.128 5.128 0 0 1-.889.073c-.652 0-1.236-.081-1.727-.291l-.023.116v4.255c.419.323 2.722 1.433 5.002 1.433 1.539 0 3.089-.505 4.063-.934Z"></path>
</svg>
</template>

<template id="workflow-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-workflow">
    <path d="M0 1.75C0 .784.784 0 1.75 0h3.5C6.216 0 7 .784 7 1.75v3.5A1.75 1.75 0 0 1 5.25 7H4v4a1 1 0 0 0 1 1h4v-1.25C9 9.784 9.784 9 10.75 9h3.5c.966 0 1.75.784 1.75 1.75v3.5A1.75 1.75 0 0 1 14.25 16h-3.5A1.75 1.75 0 0 1 9 14.25v-.75H5A2.5 2.5 0 0 1 2.5 11V7h-.75A1.75 1.75 0 0 1 0 5.25Zm1.75-.25a.25.25 0 0 0-.25.25v3.5c0 .138.112.25.25.25h3.5a.25.25 0 0 0 .25-.25v-3.5a.25.25 0 0 0-.25-.25Zm9 9a.25.25 0 0 0-.25.25v3.5c0 .138.112.25.25.25h3.5a.25.25 0 0 0 .25-.25v-3.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
</template>

<template id="book-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-book">
    <path d="M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z"></path>
</svg>
</template>

<template id="code-review-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-code-review">
    <path d="M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 13H8.061l-2.574 2.573A1.458 1.458 0 0 1 3 14.543V13H1.75A1.75 1.75 0 0 1 0 11.25v-8.5C0 1.784.784 1 1.75 1ZM1.5 2.75v8.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-8.5a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Zm5.28 1.72a.75.75 0 0 1 0 1.06L5.31 7l1.47 1.47a.751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.75.75 0 0 1 1.06 0Zm2.44 0a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L10.69 7 9.22 5.53a.75.75 0 0 1 0-1.06Z"></path>
</svg>
</template>

<template id="codespaces-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-codespaces">
    <path d="M0 11.25c0-.966.784-1.75 1.75-1.75h12.5c.966 0 1.75.784 1.75 1.75v3A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25Zm2-9.5C2 .784 2.784 0 3.75 0h8.5C13.216 0 14 .784 14 1.75v5a1.75 1.75 0 0 1-1.75 1.75h-8.5A1.75 1.75 0 0 1 2 6.75Zm1.75-.25a.25.25 0 0 0-.25.25v5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-5a.25.25 0 0 0-.25-.25Zm-2 9.5a.25.25 0 0 0-.25.25v3c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-3a.25.25 0 0 0-.25-.25Z"></path><path d="M7 12.75a.75.75 0 0 1 .75-.75h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1-.75-.75Zm-4 0a.75.75 0 0 1 .75-.75h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1-.75-.75Z"></path>
</svg>
</template>

<template id="comment-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-comment">
    <path d="M1 2.75C1 1.784 1.784 1 2.75 1h10.5c.966 0 1.75.784 1.75 1.75v7.5A1.75 1.75 0 0 1 13.25 12H9.06l-2.573 2.573A1.458 1.458 0 0 1 4 13.543V12H2.75A1.75 1.75 0 0 1 1 10.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h4.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
</template>

<template id="comment-discussion-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-comment-discussion">
    <path d="M1.75 1h8.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 10.25 10H7.061l-2.574 2.573A1.458 1.458 0 0 1 2 11.543V10h-.25A1.75 1.75 0 0 1 0 8.25v-5.5C0 1.784.784 1 1.75 1ZM1.5 2.75v5.5c0 .138.112.25.25.25h1a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h3.5a.25.25 0 0 0 .25-.25v-5.5a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25Zm13 2a.25.25 0 0 0-.25-.25h-.5a.75.75 0 0 1 0-1.5h.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 14.25 12H14v1.543a1.458 1.458 0 0 1-2.487 1.03L9.22 12.28a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215l2.22 2.22v-2.19a.75.75 0 0 1 .75-.75h1a.25.25 0 0 0 .25-.25Z"></path>
</svg>
</template>

<template id="organization-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-organization">
    <path d="M1.75 16A1.75 1.75 0 0 1 0 14.25V1.75C0 .784.784 0 1.75 0h8.5C11.216 0 12 .784 12 1.75v12.5c0 .085-.006.168-.018.25h2.268a.25.25 0 0 0 .25-.25V8.285a.25.25 0 0 0-.111-.208l-1.055-.703a.749.749 0 1 1 .832-1.248l1.055.703c.487.325.779.871.779 1.456v5.965A1.75 1.75 0 0 1 14.25 16h-3.5a.766.766 0 0 1-.197-.026c-.099.017-.2.026-.303.026h-3a.75.75 0 0 1-.75-.75V14h-1v1.25a.75.75 0 0 1-.75.75Zm-.25-1.75c0 .138.112.25.25.25H4v-1.25a.75.75 0 0 1 .75-.75h2.5a.75.75 0 0 1 .75.75v1.25h2.25a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25ZM3.75 6h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5ZM3 3.75A.75.75 0 0 1 3.75 3h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 3.75Zm4 3A.75.75 0 0 1 7.75 6h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 7 6.75ZM7.75 3h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5ZM3 9.75A.75.75 0 0 1 3.75 9h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 9.75ZM7.75 9h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5Z"></path>
</svg>
</template>

<template id="rocket-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-rocket">
    <path d="M14.064 0h.186C15.216 0 16 .784 16 1.75v.186a8.752 8.752 0 0 1-2.564 6.186l-.458.459c-.314.314-.641.616-.979.904v3.207c0 .608-.315 1.172-.833 1.49l-2.774 1.707a.749.749 0 0 1-1.11-.418l-.954-3.102a1.214 1.214 0 0 1-.145-.125L3.754 9.816a1.218 1.218 0 0 1-.124-.145L.528 8.717a.749.749 0 0 1-.418-1.11l1.71-2.774A1.748 1.748 0 0 1 3.31 4h3.204c.288-.338.59-.665.904-.979l.459-.458A8.749 8.749 0 0 1 14.064 0ZM8.938 3.623h-.002l-.458.458c-.76.76-1.437 1.598-2.02 2.5l-1.5 2.317 2.143 2.143 2.317-1.5c.902-.583 1.74-1.26 2.499-2.02l.459-.458a7.25 7.25 0 0 0 2.123-5.127V1.75a.25.25 0 0 0-.25-.25h-.186a7.249 7.249 0 0 0-5.125 2.123ZM3.56 14.56c-.732.732-2.334 1.045-3.005 1.148a.234.234 0 0 1-.201-.064.234.234 0 0 1-.064-.201c.103-.671.416-2.273 1.15-3.003a1.502 1.502 0 1 1 2.12 2.12Zm6.94-3.935c-.088.06-.177.118-.266.175l-2.35 1.521.548 1.783 1.949-1.2a.25.25 0 0 0 .119-.213ZM3.678 8.116 5.2 5.766c.058-.09.117-.178.176-.266H3.309a.25.25 0 0 0-.213.119l-1.2 1.95ZM12 5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
</template>

<template id="shield-check-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-shield-check">
    <path d="m8.533.133 5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667l5.25-1.68a1.748 1.748 0 0 1 1.066 0Zm-.61 1.429.001.001-5.25 1.68a.251.251 0 0 0-.174.237V7c0 1.36.275 2.666 1.057 3.859.784 1.194 2.121 2.342 4.366 3.298a.196.196 0 0 0 .154 0c2.245-.957 3.582-2.103 4.366-3.297C13.225 9.666 13.5 8.358 13.5 7V3.48a.25.25 0 0 0-.174-.238l-5.25-1.68a.25.25 0 0 0-.153 0ZM11.28 6.28l-3.5 3.5a.75.75 0 0 1-1.06 0l-1.5-1.5a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215l.97.97 2.97-2.97a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z"></path>
</svg>
</template>

<template id="heart-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-heart">
    <path d="m8 14.25.345.666a.75.75 0 0 1-.69 0l-.008-.004-.018-.01a7.152 7.152 0 0 1-.31-.17 22.055 22.055 0 0 1-3.434-2.414C2.045 10.731 0 8.35 0 5.5 0 2.836 2.086 1 4.25 1 5.797 1 7.153 1.802 8 3.02 8.847 1.802 10.203 1 11.75 1 13.914 1 16 2.836 16 5.5c0 2.85-2.045 5.231-3.885 6.818a22.066 22.066 0 0 1-3.744 2.584l-.018.01-.006.003h-.002ZM4.25 2.5c-1.336 0-2.75 1.164-2.75 3 0 2.15 1.58 4.144 3.365 5.682A20.58 20.58 0 0 0 8 13.393a20.58 20.58 0 0 0 3.135-2.211C12.92 9.644 14.5 7.65 14.5 5.5c0-1.836-1.414-3-2.75-3-1.373 0-2.609.986-3.029 2.456a.749.749 0 0 1-1.442 0C6.859 3.486 5.623 2.5 4.25 2.5Z"></path>
</svg>
</template>

<template id="server-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-server">
    <path d="M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v4c0 .372-.116.717-.314 1 .198.283.314.628.314 1v4a1.75 1.75 0 0 1-1.75 1.75H1.75A1.75 1.75 0 0 1 0 12.75v-4c0-.358.109-.707.314-1a1.739 1.739 0 0 1-.314-1v-4C0 1.784.784 1 1.75 1ZM1.5 2.75v4c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25Zm.25 5.75a.25.25 0 0 0-.25.25v4c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25ZM7 4.75A.75.75 0 0 1 7.75 4h4.5a.75.75 0 0 1 0 1.5h-4.5A.75.75 0 0 1 7 4.75ZM7.75 10h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5ZM3 4.75A.75.75 0 0 1 3.75 4h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 4.75ZM3.75 10h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5Z"></path>
</svg>
</template>

<template id="globe-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-globe">
    <path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM5.78 8.75a9.64 9.64 0 0 0 1.363 4.177c.255.426.542.832.857 1.215.245-.296.551-.705.857-1.215A9.64 9.64 0 0 0 10.22 8.75Zm4.44-1.5a9.64 9.64 0 0 0-1.363-4.177c-.307-.51-.612-.919-.857-1.215a9.927 9.927 0 0 0-.857 1.215A9.64 9.64 0 0 0 5.78 7.25Zm-5.944 1.5H1.543a6.507 6.507 0 0 0 4.666 5.5c-.123-.181-.24-.365-.352-.552-.715-1.192-1.437-2.874-1.581-4.948Zm-2.733-1.5h2.733c.144-2.074.866-3.756 1.58-4.948.12-.197.237-.381.353-.552a6.507 6.507 0 0 0-4.666 5.5Zm10.181 1.5c-.144 2.074-.866 3.756-1.58 4.948-.12.197-.237.381-.353.552a6.507 6.507 0 0 0 4.666-5.5Zm2.733-1.5a6.507 6.507 0 0 0-4.666-5.5c.123.181.24.365.353.552.714 1.192 1.436 2.874 1.58 4.948Z"></path>
</svg>
</template>

<template id="issue-opened-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-issue-opened">
    <path d="M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z"></path>
</svg>
</template>

<template id="device-mobile-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-device-mobile">
    <path d="M3.75 0h8.5C13.216 0 14 .784 14 1.75v12.5A1.75 1.75 0 0 1 12.25 16h-8.5A1.75 1.75 0 0 1 2 14.25V1.75C2 .784 2.784 0 3.75 0ZM3.5 1.75v12.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25ZM8 13a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path>
</svg>
</template>

<template id="package-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-package">
    <path d="m8.878.392 5.25 3.045c.54.314.872.89.872 1.514v6.098a1.75 1.75 0 0 1-.872 1.514l-5.25 3.045a1.75 1.75 0 0 1-1.756 0l-5.25-3.045A1.75 1.75 0 0 1 1 11.049V4.951c0-.624.332-1.201.872-1.514L7.122.392a1.75 1.75 0 0 1 1.756 0ZM7.875 1.69l-4.63 2.685L8 7.133l4.755-2.758-4.63-2.685a.248.248 0 0 0-.25 0ZM2.5 5.677v5.372c0 .09.047.171.125.216l4.625 2.683V8.432Zm6.25 8.271 4.625-2.683a.25.25 0 0 0 .125-.216V5.677L8.75 8.432Z"></path>
</svg>
</template>

<template id="credit-card-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-credit-card">
    <path d="M10.75 9a.75.75 0 0 0 0 1.5h1.5a.75.75 0 0 0 0-1.5h-1.5Z"></path><path d="M0 3.75C0 2.784.784 2 1.75 2h12.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 14H1.75A1.75 1.75 0 0 1 0 12.25ZM14.5 6.5h-13v5.75c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25Zm0-2.75a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25V5h13Z"></path>
</svg>
</template>

<template id="play-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-play">
    <path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z"></path>
</svg>
</template>

<template id="gift-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-gift">
    <path d="M2 2.75A2.75 2.75 0 0 1 4.75 0c.983 0 1.873.42 2.57 1.232.268.318.497.668.68 1.042.183-.375.411-.725.68-1.044C9.376.42 10.266 0 11.25 0a2.75 2.75 0 0 1 2.45 4h.55c.966 0 1.75.784 1.75 1.75v2c0 .698-.409 1.301-1 1.582v4.918A1.75 1.75 0 0 1 13.25 16H2.75A1.75 1.75 0 0 1 1 14.25V9.332C.409 9.05 0 8.448 0 7.75v-2C0 4.784.784 4 1.75 4h.55c-.192-.375-.3-.8-.3-1.25ZM7.25 9.5H2.5v4.75c0 .138.112.25.25.25h4.5Zm1.5 0v5h4.5a.25.25 0 0 0 .25-.25V9.5Zm0-4V8h5.5a.25.25 0 0 0 .25-.25v-2a.25.25 0 0 0-.25-.25Zm-7 0a.25.25 0 0 0-.25.25v2c0 .138.112.25.25.25h5.5V5.5h-5.5Zm3-4a1.25 1.25 0 0 0 0 2.5h2.309c-.233-.818-.542-1.401-.878-1.793-.43-.502-.915-.707-1.431-.707ZM8.941 4h2.309a1.25 1.25 0 0 0 0-2.5c-.516 0-1 .205-1.43.707-.337.392-.646.975-.879 1.793Z"></path>
</svg>
</template>

<template id="code-square-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-code-square">
    <path d="M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25V1.75a.25.25 0 0 0-.25-.25Zm7.47 3.97a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L10.69 8 9.22 6.53a.75.75 0 0 1 0-1.06ZM6.78 6.53 5.31 8l1.47 1.47a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215l-2-2a.75.75 0 0 1 0-1.06l2-2a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z"></path>
</svg>
</template>

<template id="device-desktop-icon">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-device-desktop">
    <path d="M14.25 1c.966 0 1.75.784 1.75 1.75v7.5A1.75 1.75 0 0 1 14.25 12h-3.727c.099 1.041.52 1.872 1.292 2.757A.752.752 0 0 1 11.25 16h-6.5a.75.75 0 0 1-.565-1.243c.772-.885 1.192-1.716 1.292-2.757H1.75A1.75 1.75 0 0 1 0 10.25v-7.5C0 1.784.784 1 1.75 1ZM1.75 2.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25ZM9.018 12H6.982a5.72 5.72 0 0 1-.765 2.5h3.566a5.72 5.72 0 0 1-.765-2.5Z"></path>
</svg>
</template>

        <div class="position-relative">
                <ul
                  role="listbox"
                  class="ActionListWrap QueryBuilder-ListWrap"
                  aria-label="Suggestions"
                  data-action="
                    combobox-commit:query-builder#comboboxCommit
                    mousedown:query-builder#resultsMousedown
                  "
                  data-target="query-builder.resultsList"
                  data-persist-list=false
                  id="query-builder-test-results"
                  tabindex="-1"
                ></ul>
        </div>
      <div class="FormControl-inlineValidation" id="validation-088f4470-f4a7-438a-9c6b-2a302310d1e5" hidden="hidden">
        <span class="FormControl-inlineValidation--visual">
          <svg aria-hidden="true" height="12" viewBox="0 0 12 12" version="1.1" width="12" data-view-component="true" class="octicon octicon-alert-fill">
    <path d="M4.855.708c.5-.896 1.79-.896 2.29 0l4.675 8.351a1.312 1.312 0 0 1-1.146 1.954H1.33A1.313 1.313 0 0 1 .183 9.058ZM7 7V3H5v4Zm-1 3a1 1 0 1 0 0-2 1 1 0 0 0 0 2Z"></path>
</svg>
        </span>
        <span></span>
</div>    </div>
    <div data-target="query-builder.screenReaderFeedback" aria-live="polite" aria-atomic="true" class="sr-only"></div>
</query-builder></form>
          <div class="d-flex flex-row color-fg-muted px-3 text-small color-bg-default search-feedback-prompt">
            <a target="_blank" href="https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax" data-view-component="true" class="Link color-fg-accent text-normal ml-2">Search syntax tips</a>            <div class="d-flex flex-1"></div>
          </div>
        </div>
</div>

    </div>
</modal-dialog></div>
  </div>
  <div data-action="click:qbsearch-input#retract" class="dark-backdrop position-fixed" hidden data-target="qbsearch-input.darkBackdrop"></div>
  <div class="color-fg-default">
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true" class="Overlay Overlay-whenNarrow Overlay--size-medium Overlay--motion-scaleFade Overlay--disableScroll">
    <div data-view-component="true" class="Overlay-header">
  <div class="Overlay-headerContentWrap">
    <div class="Overlay-titleWrap">
      <h1 class="Overlay-title " id="feedback-dialog-title">
        Provide feedback
      </h1>
        
    </div>
    <div class="Overlay-actionWrap">
      <button data-close-dialog-id="feedback-dialog" aria-label="Close" aria-label="Close" type="button" data-view-component="true" class="close-button Overlay-closeButton"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg></button>
    </div>
  </div>
  
</div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        <div data-view-component="true" class="Overlay-body">        <!-- '"` --><!-- </textarea></xmp> --></option></form><form id="code-search-feedback-form" data-turbo="false" action="/search/feedback" accept-charset="UTF-8" method="post"><input type="hidden" data-csrf="true" name="authenticity_token" value="+yhTpNbaw17wJNQ+pGXVum3NwBYCiuYJ6UJuL8CQZj+GaXDcHaPYEmCCJ+ge2GznjxufoMcTzDM7Dif0NE1u+w==" />
          <p>We read every piece of feedback, and take your input very seriously.</p>
          <textarea name="feedback" class="form-control width-full mb-2" style="height: 120px" id="feedback"></textarea>
          <input name="include_email" id="include_email" aria-label="Include my email address so I can be contacted" class="form-control mr-2" type="checkbox">
          <label for="include_email" style="font-weight: normal">Include my email address so I can be contacted</label>
</form></div>
      </scrollable-region>
      <div data-view-component="true" class="Overlay-footer Overlay-footer--alignEnd">          <button data-close-dialog-id="feedback-dialog" type="button" data-view-component="true" class="btn">    Cancel
</button>
          <button form="code-search-feedback-form" data-action="click:qbsearch-input#submitFeedback" type="submit" data-view-component="true" class="btn-primary btn">    Submit feedback
</button>
</div>
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true" class="Overlay Overlay-whenNarrow Overlay--size-medium Overlay--motion-scaleFade Overlay--disableScroll">
    <div data-view-component="true" class="Overlay-header Overlay-header--divided">
  <div class="Overlay-headerContentWrap">
    <div class="Overlay-titleWrap">
      <h1 class="Overlay-title " id="custom-scopes-dialog-title">
        Saved searches
      </h1>
        <h2 id="custom-scopes-dialog-description" class="Overlay-description">Use saved searches to filter your results more quickly</h2>
    </div>
    <div class="Overlay-actionWrap">
      <button data-close-dialog-id="custom-scopes-dialog" aria-label="Close" aria-label="Close" type="button" data-view-component="true" class="close-button Overlay-closeButton"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg></button>
    </div>
  </div>
  
</div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        <div data-view-component="true" class="Overlay-body">        <div data-target="custom-scopes.customScopesModalDialogFlash"></div>

        <div hidden class="create-custom-scope-form" data-target="custom-scopes.createCustomScopeForm">
        <!-- '"` --><!-- </textarea></xmp> --></option></form><form id="custom-scopes-dialog-form" data-turbo="false" action="/search/custom_scopes" accept-charset="UTF-8" method="post"><input type="hidden" data-csrf="true" name="authenticity_token" value="JlC5YnV75czVldEZ6rSbCsKMpMhojIG25Yp/o0vO+RH3gK9xPUyK/GvOtqtzwJz67g31CD9UAdJwUE0b2s34Tw==" />
          <div data-target="custom-scopes.customScopesModalDialogFlash"></div>

          <input type="hidden" id="custom_scope_id" name="custom_scope_id" data-target="custom-scopes.customScopesIdField">

          <div class="form-group">
            <label for="custom_scope_name">Name</label>
            <auto-check src="/search/custom_scopes/check_name" required>
              <input
                type="text"
                name="custom_scope_name"
                id="custom_scope_name"
                data-target="custom-scopes.customScopesNameField"
                class="form-control"
                autocomplete="off"
                placeholder="github-ruby"
                required
                maxlength="50">
              <input type="hidden" data-csrf="true" value="iBHbuz5CYqNLWAnV3b62e/CfXINtaDQMZ/WUK2W1F66rOF97SePtvhXF72QXYvGjzRxdIO5YAPV8Y+KLv5JNBg==" />
            </auto-check>
          </div>

          <div class="form-group">
            <label for="custom_scope_query">Query</label>
            <input
              type="text"
              name="custom_scope_query"
              id="custom_scope_query"
              data-target="custom-scopes.customScopesQueryField"
              class="form-control"
              autocomplete="off"
              placeholder="(repo:mona/a OR repo:mona/b) AND lang:python"
              required
              maxlength="500">
          </div>

          <p class="text-small color-fg-muted">
            To see all available qualifiers, see our <a class="Link--inTextBlock" href="https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax">documentation</a>.
          </p>
</form>        </div>

        <div data-target="custom-scopes.manageCustomScopesForm">
          <div data-target="custom-scopes.list"></div>
        </div>

</div>
      </scrollable-region>
      <div data-view-component="true" class="Overlay-footer Overlay-footer--alignEnd Overlay-footer--divided">          <button data-action="click:custom-scopes#customScopesCancel" type="button" data-view-component="true" class="btn">    Cancel
</button>
          <button form="custom-scopes-dialog-form" data-action="click:custom-scopes#customScopesSubmit" data-target="custom-scopes.customScopesSubmitButton" type="submit" data-view-component="true" class="btn-primary btn">    Create saved search
</button>
</div>
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            <div class="position-relative HeaderMenu-link-wrap d-lg-inline-block">
              <a
                href="/login?return_to=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FAwesome-Code-LLM"
                class="HeaderMenu-link HeaderMenu-link--sign-in HeaderMenu-button flex-shrink-0 no-underline d-none d-lg-inline-flex border border-lg-0 rounded px-2 py-1"
                style="margin-left: 12px;"
                data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/codefuse-ai/Awesome-Code-LLM&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="5cf797975042acba6e0763cfc87e32cacfe957ec57a5b8ac4e0012d4b04cd344"
                data-analytics-event="{&quot;category&quot;:&quot;Marketing nav&quot;,&quot;action&quot;:&quot;click to go to homepage&quot;,&quot;label&quot;:&quot;ref_page:Marketing;ref_cta:Sign in;ref_loc:Header&quot;}"
              >
                Sign in
              </a>
            </div>

              <a href="/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=codefuse-ai%2FAwesome-Code-LLM"
                class="HeaderMenu-link HeaderMenu-link--sign-up HeaderMenu-button flex-shrink-0 d-flex d-lg-inline-flex no-underline border color-border-default rounded px-2 py-1"
                data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/codefuse-ai/Awesome-Code-LLM&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="5cf797975042acba6e0763cfc87e32cacfe957ec57a5b8ac4e0012d4b04cd344"
                data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/&lt;user-name&gt;/&lt;repo-name&gt;;ref_cta:Sign up;ref_loc:header logged out&quot;}"
              >
                Sign up
              </a>

                <div class="AppHeader-appearanceSettings">
    <react-partial-anchor>
      <button data-target="react-partial-anchor.anchor" id="icon-button-50e71a21-5a8d-4267-96a2-26f2e8491eee" aria-labelledby="tooltip-38cf4ad0-c3d9-426e-b38d-639f9bb8d9ff" type="button" disabled="disabled" data-view-component="true" class="Button Button--iconOnly Button--invisible Button--medium AppHeader-button HeaderMenu-link border cursor-wait">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-sliders Button-visual">
    <path d="M15 2.75a.75.75 0 0 1-.75.75h-4a.75.75 0 0 1 0-1.5h4a.75.75 0 0 1 .75.75Zm-8.5.75v1.25a.75.75 0 0 0 1.5 0v-4a.75.75 0 0 0-1.5 0V2H1.75a.75.75 0 0 0 0 1.5H6.5Zm1.25 5.25a.75.75 0 0 0 0-1.5h-6a.75.75 0 0 0 0 1.5h6ZM15 8a.75.75 0 0 1-.75.75H11.5V10a.75.75 0 1 1-1.5 0V6a.75.75 0 0 1 1.5 0v1.25h2.75A.75.75 0 0 1 15 8Zm-9 5.25v-2a.75.75 0 0 0-1.5 0v1.25H1.75a.75.75 0 0 0 0 1.5H4.5v1.25a.75.75 0 0 0 1.5 0v-2Zm9 0a.75.75 0 0 1-.75.75h-6a.75.75 0 0 1 0-1.5h6a.75.75 0 0 1 .75.75Z"></path>
</svg>
</button><tool-tip id="tooltip-38cf4ad0-c3d9-426e-b38d-639f9bb8d9ff" for="icon-button-50e71a21-5a8d-4267-96a2-26f2e8491eee" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.f595f41454298e934d3c.module.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.6c63a6de228d6520804d.module.css" />

<react-partial
  partial-name="appearance-settings"
  data-ssr="false"
  data-attempted-ssr="false"
  data-react-profiling="false"
>
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>


      </template>
    </react-partial-anchor>
  </div>

          <button type="button" class="sr-only js-header-menu-focus-trap d-block d-lg-none">Resetting focus</button>
        </div>
      </div>
    </div>
  </div>
</header>

      <div hidden="hidden" data-view-component="true" class="js-stale-session-flash stale-session-flash flash flash-warn flash-full">
  
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
        <span class="js-stale-session-flash-signed-in" hidden>You signed in with another tab or window. <a class="Link--inTextBlock" href="">Reload</a> to refresh your session.</span>
        <span class="js-stale-session-flash-signed-out" hidden>You signed out in another tab or window. <a class="Link--inTextBlock" href="">Reload</a> to refresh your session.</span>
        <span class="js-stale-session-flash-switched" hidden>You switched accounts on another tab or window. <a class="Link--inTextBlock" href="">Reload</a> to refresh your session.</span>

    <button id="icon-button-ad2e4e82-bdc3-4ee1-a229-66d7dc591848" aria-labelledby="tooltip-c570beb7-2621-45d8-bbc2-ec159f852c8e" type="button" data-view-component="true" class="Button Button--iconOnly Button--invisible Button--medium flash-close js-flash-close">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x Button-visual">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
</button><tool-tip id="tooltip-c570beb7-2621-45d8-bbc2-ec159f852c8e" for="icon-button-ad2e4e82-bdc3-4ee1-a229-66d7dc591848" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute">Dismiss alert</tool-tip>


  
</div>
    </div>

  <div id="start-of-content" class="show-on-focus"></div>








    <div id="js-flash-container" class="flash-container" data-turbo-replace>




  <template class="js-flash-template">
    
<div class="flash flash-full   {{ className }}">
  <div >
    <button autofocus class="flash-close js-flash-close" type="button" aria-label="Dismiss this message">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
    </button>
    <div aria-atomic="true" role="alert" class="js-flash-alert">
      
      <div>{{ message }}</div>

    </div>
  </div>
</div>
  </template>
</div>


    






  <div
    class="application-main "
    data-commit-hovercards-enabled
    data-discussion-hovercards-enabled
    data-issue-and-pr-hovercards-enabled
    data-project-hovercards-enabled
  >
        <div itemscope itemtype="http://schema.org/SoftwareSourceCode" class="">
    <main id="js-repo-pjax-container" >
      
  





    
    

    






  
  <div id="repository-container-header"  class="pt-3 hide-full-screen" style="background-color: var(--page-header-bgColor, var(--color-page-header-bg));" data-turbo-replace>

      <div class="d-flex flex-nowrap flex-justify-end mb-3  px-3 px-lg-5" style="gap: 1rem;">

        <div class="flex-auto min-width-0 width-fit">
            
  <div class=" d-flex flex-wrap flex-items-center wb-break-word f3 text-normal">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo color-fg-muted mr-2">
    <path d="M2 2.5A2.5 2.5 0 0 1 4.5 0h8.75a.75.75 0 0 1 .75.75v12.5a.75.75 0 0 1-.75.75h-2.5a.75.75 0 0 1 0-1.5h1.75v-2h-8a1 1 0 0 0-.714 1.7.75.75 0 1 1-1.072 1.05A2.495 2.495 0 0 1 2 11.5Zm10.5-1h-8a1 1 0 0 0-1 1v6.708A2.486 2.486 0 0 1 4.5 9h8ZM5 12.25a.25.25 0 0 1 .25-.25h3.5a.25.25 0 0 1 .25.25v3.25a.25.25 0 0 1-.4.2l-1.45-1.087a.249.249 0 0 0-.3 0L5.4 15.7a.25.25 0 0 1-.4-.2Z"></path>
</svg>
    
    <span class="author flex-self-stretch" itemprop="author">
      <a class="url fn" rel="author" data-hovercard-type="organization" data-hovercard-url="/orgs/codefuse-ai/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="/codefuse-ai">
        codefuse-ai
</a>    </span>
    <span class="mx-1 flex-self-stretch color-fg-muted">/</span>
    <strong itemprop="name" class="mr-2 flex-self-stretch">
      <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="/codefuse-ai/Awesome-Code-LLM">Awesome-Code-LLM</a>
    </strong>

    <span></span><span class="Label Label--secondary v-align-middle mr-1">Public</span>
  </div>


        </div>

        <div id="repository-details-container" class="flex-shrink-0" data-turbo-replace style="max-width: 70%;">
            <ul class="pagehead-actions flex-shrink-0 d-none d-md-inline" style="padding: 2px 0;">
    
      

  <li>
            <a href="/login?return_to=%2Fcodefuse-ai%2FAwesome-Code-LLM" rel="nofollow" id="repository-details-watch-button" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/codefuse-ai/Awesome-Code-LLM&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="89990adb71f8d23ac95df7e3214e6f2a0b6bf1a6cd28b37c61d9a45dc93ef923" aria-label="You must be signed in to change notification settings" data-view-component="true" class="btn-sm btn">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-bell mr-2">
    <path d="M8 16a2 2 0 0 0 1.985-1.75c.017-.137-.097-.25-.235-.25h-3.5c-.138 0-.252.113-.235.25A2 2 0 0 0 8 16ZM3 5a5 5 0 0 1 10 0v2.947c0 .05.015.098.042.139l1.703 2.555A1.519 1.519 0 0 1 13.482 13H2.518a1.516 1.516 0 0 1-1.263-2.36l1.703-2.554A.255.255 0 0 0 3 7.947Zm5-3.5A3.5 3.5 0 0 0 4.5 5v2.947c0 .346-.102.683-.294.97l-1.703 2.556a.017.017 0 0 0-.003.01l.001.006c0 .002.002.004.004.006l.006.004.007.001h10.964l.007-.001.006-.004.004-.006.001-.007a.017.017 0 0 0-.003-.01l-1.703-2.554a1.745 1.745 0 0 1-.294-.97V5A3.5 3.5 0 0 0 8 1.5Z"></path>
</svg>Notifications
</a>    <tool-tip id="tooltip-9ed70326-e049-4947-825b-e95db15885e8" for="repository-details-watch-button" popover="manual" data-direction="s" data-type="description" data-view-component="true" class="sr-only position-absolute">You must be signed in to change notification settings</tool-tip>

  </li>

  <li>
          <a icon="repo-forked" id="fork-button" href="/login?return_to=%2Fcodefuse-ai%2FAwesome-Code-LLM" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:694517360,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/codefuse-ai/Awesome-Code-LLM&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="671c8f7b10089b8b34d1deb4e96264148f209162bae32cdce9196e8c509a2cbe" data-view-component="true" class="btn-sm btn">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo-forked mr-2">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>Fork
    <span id="repo-network-counter" data-pjax-replace="true" data-turbo-replace="true" title="193" data-view-component="true" class="Counter">193</span>
</a>
  </li>

  <li>
        <div data-view-component="true" class="BtnGroup d-flex">
        <a href="/login?return_to=%2Fcodefuse-ai%2FAwesome-Code-LLM" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:694517360,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/codefuse-ai/Awesome-Code-LLM&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="5798901296dc2f82960a1ebe2ec4ed12d652e8b0a1ed71fc8169fbe2542a1f73" aria-label="You must be signed in to star a repository" data-view-component="true" class="tooltipped tooltipped-sw btn-sm btn">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-star v-align-text-bottom d-inline-block mr-2">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg><span data-view-component="true" class="d-inline">
          Star
</span>          <span id="repo-stars-counter-star" aria-label="2975 users starred this repository" data-singular-suffix="user starred this repository" data-plural-suffix="users starred this repository" data-turbo-replace="true" title="2,975" data-view-component="true" class="Counter js-social-count">3k</span>
</a></div>
  </li>

</ul>

        </div>
      </div>

        <div id="responsive-meta-container" data-turbo-replace>
      <div class="d-block d-md-none mb-2 px-3 px-md-4 px-lg-5">
      <p class="f4 mb-3 ">
        [TMLR] A curated list of language modeling researches for code (and other software engineering activities), plus related datasets.
      </p>
      <div class="mb-2 d-flex flex-items-center Link--secondary">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-link flex-shrink-0 mr-2">
    <path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path>
</svg>
        <span class="flex-auto min-width-0 css-truncate css-truncate-target width-fit">
          <a title="https://arxiv.org/abs/2311.07989" role="link" target="_blank" class="text-bold" rel="noopener noreferrer" href="https://arxiv.org/abs/2311.07989">arxiv.org/abs/2311.07989</a>
        </span>
      </div>

    

    <div class="mb-3">
        <a class="Link--secondary no-underline mr-3" href="/codefuse-ai/Awesome-Code-LLM/stargazers">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-star mr-1">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
          <span class="text-bold">3k</span>
          stars
</a>        <a class="Link--secondary no-underline mr-3" href="/codefuse-ai/Awesome-Code-LLM/forks">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo-forked mr-1">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>
          <span class="text-bold">193</span>
          forks
</a>        <a class="Link--secondary no-underline mr-3 d-inline-block" href="/codefuse-ai/Awesome-Code-LLM/branches">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-git-branch mr-1">
    <path d="M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z"></path>
</svg>
          <span>Branches</span>
</a>        <a class="Link--secondary no-underline d-inline-block" href="/codefuse-ai/Awesome-Code-LLM/tags">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-tag mr-1">
    <path d="M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z"></path>
</svg>
          <span>Tags</span>
</a>        <a class="Link--secondary no-underline d-inline-block" href="/codefuse-ai/Awesome-Code-LLM/activity">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-pulse mr-1">
    <path d="M6 2c.306 0 .582.187.696.471L10 10.731l1.304-3.26A.751.751 0 0 1 12 7h3.25a.75.75 0 0 1 0 1.5h-2.742l-1.812 4.528a.751.751 0 0 1-1.392 0L6 4.77 4.696 8.03A.75.75 0 0 1 4 8.5H.75a.75.75 0 0 1 0-1.5h2.742l1.812-4.529A.751.751 0 0 1 6 2Z"></path>
</svg>
          <span>Activity</span>
</a>    </div>

      <div class="d-flex flex-wrap gap-2">
        <div class="flex-1">
            <div data-view-component="true" class="BtnGroup d-flex">
        <a href="/login?return_to=%2Fcodefuse-ai%2FAwesome-Code-LLM" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:694517360,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/codefuse-ai/Awesome-Code-LLM&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="5798901296dc2f82960a1ebe2ec4ed12d652e8b0a1ed71fc8169fbe2542a1f73" aria-label="You must be signed in to star a repository" data-view-component="true" class="tooltipped tooltipped-sw btn-sm btn btn-block">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-star v-align-text-bottom d-inline-block mr-2">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg><span data-view-component="true" class="d-inline">
          Star
</span>
</a></div>
        </div>
        <div class="flex-1">
                <a href="/login?return_to=%2Fcodefuse-ai%2FAwesome-Code-LLM" rel="nofollow" id="files-overview-watch-button" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/codefuse-ai/Awesome-Code-LLM&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="89990adb71f8d23ac95df7e3214e6f2a0b6bf1a6cd28b37c61d9a45dc93ef923" aria-label="You must be signed in to change notification settings" data-view-component="true" class="btn-sm btn btn-block">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-bell mr-2">
    <path d="M8 16a2 2 0 0 0 1.985-1.75c.017-.137-.097-.25-.235-.25h-3.5c-.138 0-.252.113-.235.25A2 2 0 0 0 8 16ZM3 5a5 5 0 0 1 10 0v2.947c0 .05.015.098.042.139l1.703 2.555A1.519 1.519 0 0 1 13.482 13H2.518a1.516 1.516 0 0 1-1.263-2.36l1.703-2.554A.255.255 0 0 0 3 7.947Zm5-3.5A3.5 3.5 0 0 0 4.5 5v2.947c0 .346-.102.683-.294.97l-1.703 2.556a.017.017 0 0 0-.003.01l.001.006c0 .002.002.004.004.006l.006.004.007.001h10.964l.007-.001.006-.004.004-.006.001-.007a.017.017 0 0 0-.003-.01l-1.703-2.554a1.745 1.745 0 0 1-.294-.97V5A3.5 3.5 0 0 0 8 1.5Z"></path>
</svg>Notifications
</a>    <tool-tip id="tooltip-417d5f32-a5d0-43d8-a86b-9271ee7bcb22" for="files-overview-watch-button" popover="manual" data-direction="s" data-type="description" data-view-component="true" class="sr-only position-absolute">You must be signed in to change notification settings</tool-tip>

        </div>
        <span>
          

        </span>
      </div>
  </div>

</div>


          <nav data-pjax="#js-repo-pjax-container" aria-label="Repository" data-view-component="true" class="js-repo-nav js-sidenav-container-pjax js-responsive-underlinenav overflow-hidden UnderlineNav px-3 px-md-4 px-lg-5">

  <ul data-view-component="true" class="UnderlineNav-body list-style-none">
      <li data-view-component="true" class="d-inline-flex">
  <a id="code-tab" href="/codefuse-ai/Awesome-Code-LLM" data-tab-item="i0code-tab" data-selected-links="repo_source repo_downloads repo_commits repo_releases repo_tags repo_branches repo_packages repo_deployments repo_attestations /codefuse-ai/Awesome-Code-LLM" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g c" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Code&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" aria-current="page" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item selected">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-code UnderlineNav-octicon d-none d-sm-inline">
    <path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path>
</svg>
        <span data-content="Code">Code</span>
          <span id="code-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true" class="Counter"></span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="issues-tab" href="/codefuse-ai/Awesome-Code-LLM/issues" data-tab-item="i1issues-tab" data-selected-links="repo_issues repo_labels repo_milestones /codefuse-ai/Awesome-Code-LLM/issues" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g i" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Issues&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-issue-opened UnderlineNav-octicon d-none d-sm-inline">
    <path d="M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z"></path>
</svg>
        <span data-content="Issues">Issues</span>
          <span id="issues-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="1" data-view-component="true" class="Counter">1</span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="pull-requests-tab" href="/codefuse-ai/Awesome-Code-LLM/pulls" data-tab-item="i2pull-requests-tab" data-selected-links="repo_pulls checks /codefuse-ai/Awesome-Code-LLM/pulls" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g p" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Pull requests&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-git-pull-request UnderlineNav-octicon d-none d-sm-inline">
    <path d="M1.5 3.25a2.25 2.25 0 1 1 3 2.122v5.256a2.251 2.251 0 1 1-1.5 0V5.372A2.25 2.25 0 0 1 1.5 3.25Zm5.677-.177L9.573.677A.25.25 0 0 1 10 .854V2.5h1A2.5 2.5 0 0 1 13.5 5v5.628a2.251 2.251 0 1 1-1.5 0V5a1 1 0 0 0-1-1h-1v1.646a.25.25 0 0 1-.427.177L7.177 3.427a.25.25 0 0 1 0-.354ZM3.75 2.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm0 9.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm8.25.75a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Z"></path>
</svg>
        <span data-content="Pull requests">Pull requests</span>
          <span id="pull-requests-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="0" hidden="hidden" data-view-component="true" class="Counter">0</span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="actions-tab" href="/codefuse-ai/Awesome-Code-LLM/actions" data-tab-item="i3actions-tab" data-selected-links="repo_actions /codefuse-ai/Awesome-Code-LLM/actions" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g a" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Actions&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-play UnderlineNav-octicon d-none d-sm-inline">
    <path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z"></path>
</svg>
        <span data-content="Actions">Actions</span>
          <span id="actions-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true" class="Counter"></span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="projects-tab" href="/codefuse-ai/Awesome-Code-LLM/projects" data-tab-item="i4projects-tab" data-selected-links="repo_projects new_repo_project repo_project /codefuse-ai/Awesome-Code-LLM/projects" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g b" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Projects&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-table UnderlineNav-octicon d-none d-sm-inline">
    <path d="M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25ZM6.5 6.5v8h7.75a.25.25 0 0 0 .25-.25V6.5Zm8-1.5V1.75a.25.25 0 0 0-.25-.25H6.5V5Zm-13 1.5v7.75c0 .138.112.25.25.25H5v-8ZM5 5V1.5H1.75a.25.25 0 0 0-.25.25V5Z"></path>
</svg>
        <span data-content="Projects">Projects</span>
          <span id="projects-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="0" hidden="hidden" data-view-component="true" class="Counter">0</span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="security-tab" href="/codefuse-ai/Awesome-Code-LLM/security" data-tab-item="i5security-tab" data-selected-links="security overview alerts policy token_scanning code_scanning /codefuse-ai/Awesome-Code-LLM/security" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g s" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Security&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-shield UnderlineNav-octicon d-none d-sm-inline">
    <path d="M7.467.133a1.748 1.748 0 0 1 1.066 0l5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667Zm.61 1.429a.25.25 0 0 0-.153 0l-5.25 1.68a.25.25 0 0 0-.174.238V7c0 1.358.275 2.666 1.057 3.86.784 1.194 2.121 2.34 4.366 3.297a.196.196 0 0 0 .154 0c2.245-.956 3.582-2.104 4.366-3.298C13.225 9.666 13.5 8.36 13.5 7V3.48a.251.251 0 0 0-.174-.237l-5.25-1.68ZM8.75 4.75v3a.75.75 0 0 1-1.5 0v-3a.75.75 0 0 1 1.5 0ZM9 10.5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
        <span data-content="Security">Security</span>
          <include-fragment src="/codefuse-ai/Awesome-Code-LLM/security/overall-count" accept="text/fragment+html" data-nonce="v2:6be41ebd-a31d-c9f7-f234-9eba816399f5" data-view-component="true">
  
  <div data-show-on-forbidden-error hidden>
    <div class="Box">
  <div class="blankslate-container">
    <div data-view-component="true" class="blankslate blankslate-spacious color-bg-default rounded-2">
      

      <h3 data-view-component="true" class="blankslate-heading">        Uh oh!
</h3>
      <p data-view-component="true">        <p class="color-fg-muted my-2 mb-2 ws-normal">There was an error while loading. <a class="Link--inTextBlock" data-turbo="false" href="" aria-label="Please reload this page">Please reload this page</a>.</p>
</p>

</div>  </div>
</div>  </div>
</include-fragment>

    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="insights-tab" href="/codefuse-ai/Awesome-Code-LLM/pulse" data-tab-item="i6insights-tab" data-selected-links="repo_graphs repo_contributors dependency_graph dependabot_updates pulse people community /codefuse-ai/Awesome-Code-LLM/pulse" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Insights&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-graph UnderlineNav-octicon d-none d-sm-inline">
    <path d="M1.5 1.75V13.5h13.75a.75.75 0 0 1 0 1.5H.75a.75.75 0 0 1-.75-.75V1.75a.75.75 0 0 1 1.5 0Zm14.28 2.53-5.25 5.25a.75.75 0 0 1-1.06 0L7 7.06 4.28 9.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.25-3.25a.75.75 0 0 1 1.06 0L10 7.94l4.72-4.72a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z"></path>
</svg>
        <span data-content="Insights">Insights</span>
          <span id="insights-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true" class="Counter"></span>


    
</a></li>
</ul>
    <div style="visibility:hidden;" data-view-component="true" class="UnderlineNav-actions js-responsive-underlinenav-overflow position-absolute pr-3 pr-md-4 pr-lg-5 right-0">      <action-menu data-select-variant="none" data-view-component="true">
  <focus-group direction="vertical" mnemonics retain>
    <button id="action-menu-80365f18-5a7e-46c3-b84e-75ecc99ebc57-button" popovertarget="action-menu-80365f18-5a7e-46c3-b84e-75ecc99ebc57-overlay" aria-controls="action-menu-80365f18-5a7e-46c3-b84e-75ecc99ebc57-list" aria-haspopup="true" aria-labelledby="tooltip-977ceb1f-32dc-4fcf-b476-1503d0dd36f0" type="button" data-view-component="true" class="Button Button--iconOnly Button--secondary Button--medium UnderlineNav-item">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-kebab-horizontal Button-visual">
    <path d="M8 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3ZM1.5 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Zm13 0a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path>
</svg>
</button><tool-tip id="tooltip-977ceb1f-32dc-4fcf-b476-1503d0dd36f0" for="action-menu-80365f18-5a7e-46c3-b84e-75ecc99ebc57-button" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute">Additional navigation options</tool-tip>


<anchored-position data-target="action-menu.overlay" id="action-menu-80365f18-5a7e-46c3-b84e-75ecc99ebc57-overlay" anchor="action-menu-80365f18-5a7e-46c3-b84e-75ecc99ebc57-button" align="start" side="outside-bottom" anchor-offset="normal" popover="auto" data-view-component="true">
  <div data-view-component="true" class="Overlay Overlay--size-auto">
    
      <div data-view-component="true" class="Overlay-body Overlay-body--paddingNone">          <action-list>
  <div data-view-component="true">
    <ul aria-labelledby="action-menu-80365f18-5a7e-46c3-b84e-75ecc99ebc57-button" id="action-menu-80365f18-5a7e-46c3-b84e-75ecc99ebc57-list" role="menu" data-view-component="true" class="ActionListWrap--inset ActionListWrap">
        <li hidden="hidden" data-menu-item="i0code-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-ea271a77-a009-45c9-a287-f702c521fa6c" href="/codefuse-ai/Awesome-Code-LLM" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-code">
    <path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Code
</span>      
</a>
  
</li>
        <li hidden="hidden" data-menu-item="i1issues-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-94fc41f3-ea1b-4fe7-9213-da8ea49a26fa" href="/codefuse-ai/Awesome-Code-LLM/issues" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-issue-opened">
    <path d="M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Issues
</span>      
</a>
  
</li>
        <li hidden="hidden" data-menu-item="i2pull-requests-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-9ac13414-a170-43e8-b852-747912b2bb0d" href="/codefuse-ai/Awesome-Code-LLM/pulls" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-git-pull-request">
    <path d="M1.5 3.25a2.25 2.25 0 1 1 3 2.122v5.256a2.251 2.251 0 1 1-1.5 0V5.372A2.25 2.25 0 0 1 1.5 3.25Zm5.677-.177L9.573.677A.25.25 0 0 1 10 .854V2.5h1A2.5 2.5 0 0 1 13.5 5v5.628a2.251 2.251 0 1 1-1.5 0V5a1 1 0 0 0-1-1h-1v1.646a.25.25 0 0 1-.427.177L7.177 3.427a.25.25 0 0 1 0-.354ZM3.75 2.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm0 9.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm8.25.75a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Pull requests
</span>      
</a>
  
</li>
        <li hidden="hidden" data-menu-item="i3actions-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-3e8039a5-94db-43cb-95f3-7b60d7d4a7fc" href="/codefuse-ai/Awesome-Code-LLM/actions" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-play">
    <path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Actions
</span>      
</a>
  
</li>
        <li hidden="hidden" data-menu-item="i4projects-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-46d5ac52-2078-4b07-8e58-9aeee5fa3030" href="/codefuse-ai/Awesome-Code-LLM/projects" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-table">
    <path d="M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25ZM6.5 6.5v8h7.75a.25.25 0 0 0 .25-.25V6.5Zm8-1.5V1.75a.25.25 0 0 0-.25-.25H6.5V5Zm-13 1.5v7.75c0 .138.112.25.25.25H5v-8ZM5 5V1.5H1.75a.25.25 0 0 0-.25.25V5Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Projects
</span>      
</a>
  
</li>
        <li hidden="hidden" data-menu-item="i5security-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-21d4102f-c33b-4799-ab2d-5234f4c37742" href="/codefuse-ai/Awesome-Code-LLM/security" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-shield">
    <path d="M7.467.133a1.748 1.748 0 0 1 1.066 0l5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667Zm.61 1.429a.25.25 0 0 0-.153 0l-5.25 1.68a.25.25 0 0 0-.174.238V7c0 1.358.275 2.666 1.057 3.86.784 1.194 2.121 2.34 4.366 3.297a.196.196 0 0 0 .154 0c2.245-.956 3.582-2.104 4.366-3.298C13.225 9.666 13.5 8.36 13.5 7V3.48a.251.251 0 0 0-.174-.237l-5.25-1.68ZM8.75 4.75v3a.75.75 0 0 1-1.5 0v-3a.75.75 0 0 1 1.5 0ZM9 10.5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Security
</span>      
</a>
  
</li>
        <li hidden="hidden" data-menu-item="i6insights-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-7e4ef438-53c4-4ecf-897c-803ed7dd4b8f" href="/codefuse-ai/Awesome-Code-LLM/pulse" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-graph">
    <path d="M1.5 1.75V13.5h13.75a.75.75 0 0 1 0 1.5H.75a.75.75 0 0 1-.75-.75V1.75a.75.75 0 0 1 1.5 0Zm14.28 2.53-5.25 5.25a.75.75 0 0 1-1.06 0L7 7.06 4.28 9.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.25-3.25a.75.75 0 0 1 1.06 0L10 7.94l4.72-4.72a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Insights
</span>      
</a>
  
</li>
</ul>    
</div></action-list>


</div>
      
</div></anchored-position>  </focus-group>
</action-menu></div>
</nav>

  </div>

  



<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance" class="">
    <div id="repo-content-pjax-container" class="repository-content " >
    



    
      
  <h1 class='sr-only'>codefuse-ai/Awesome-Code-LLM</h1>
  <div class="clearfix container-xl px-md-4 px-lg-5 px-3">
    <div>

  <div style="max-width: 100%" data-view-component="true" class="Layout Layout--flowRow-until-md react-repos-overview-margin Layout--sidebarPosition-end Layout--sidebarPosition-flowRow-end">
  <div data-view-component="true" class="Layout-main">      <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.f595f41454298e934d3c.module.css" />
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/app_assets_modules_react-partials_repos-overview_components_OverviewContent_module_css-app_as-2f8a17.0268c3a576b1dbc77d72.module.css" />

<react-partial
  partial-name="repos-overview"
  data-ssr="true"
  data-attempted-ssr="true"
  data-react-profiling="false"
>
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{"initialPayload":{"allShortcutsEnabled":false,"path":"/","repo":{"id":694517360,"defaultBranch":"main","name":"Awesome-Code-LLM","ownerLogin":"codefuse-ai","currentUserCanPush":false,"isFork":false,"isEmpty":false,"createdAt":"2023-09-21T06:49:47.000Z","ownerAvatar":"https://avatars.githubusercontent.com/u/143480819?v=4","public":true,"private":false,"isOrgOwned":true},"currentUser":null,"refInfo":{"name":"main","listCacheKey":"v0:1761213609.0","canEdit":false,"refType":"branch","currentOid":"8fc20081acd02a926575fb4b095e16e071683283"},"tree":{"items":[{"name":"imgs","path":"imgs","contentType":"directory"},{"name":"README.md","path":"README.md","contentType":"file"}],"templateDirectorySuggestionUrl":null,"readme":null,"totalCount":2,"showBranchInfobar":false},"fileTree":null,"fileTreeProcessingTime":null,"foldersToFetch":[],"treeExpanded":false,"symbolsExpanded":false,"copilotSWEAgentEnabled":false,"isOverview":true,"overview":{"banners":{"shouldRecommendReadme":false,"isPersonalRepo":false,"showUseActionBanner":false,"actionSlug":null,"actionId":null,"showProtectBranchBanner":false,"publishBannersInfo":{"dismissActionNoticePath":"/settings/dismiss-notice/publish_action_from_repo","releasePath":"/codefuse-ai/Awesome-Code-LLM/releases/new?marketplace=true","showPublishActionBanner":false},"interactionLimitBanner":null,"showInvitationBanner":false,"inviterName":null,"actionsMigrationBannerInfo":{"releaseTags":[],"showImmutableActionsMigrationBanner":false,"initialMigrationStatus":null},"showDeployBanner":false,"detectedStack":{"framework":null,"packageManager":null}},"codeButton":{"contactPath":"/contact","isEnterprise":false,"local":{"protocolInfo":{"httpAvailable":true,"sshAvailable":null,"httpUrl":"https://github.com/codefuse-ai/Awesome-Code-LLM.git","showCloneWarning":null,"sshUrl":null,"sshCertificatesRequired":null,"sshCertificatesAvailable":null,"ghCliUrl":"gh repo clone codefuse-ai/Awesome-Code-LLM","defaultProtocol":"http","newSshKeyUrl":"/settings/ssh/new","setProtocolPath":"/users/set_protocol"},"platformInfo":{"cloneUrl":"https://desktop.github.com","showVisualStudioCloneButton":false,"visualStudioCloneUrl":"https://windows.github.com","showXcodeCloneButton":false,"xcodeCloneUrl":"xcode://clone?repo=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FAwesome-Code-LLM","zipballUrl":"/codefuse-ai/Awesome-Code-LLM/archive/refs/heads/main.zip"}},"newCodespacePath":"/codespaces/new?hide_repo_select=true\u0026repo=694517360"},"popovers":{"rename":null,"renamedParentRepo":null},"commitCount":"207","overviewFiles":[{"displayName":"README.md","repoName":"Awesome-Code-LLM","refName":"main","path":"README.md","preferredFileType":"readme","tabName":"README","richText":"\u003carticle class=\"markdown-body entry-content container-lg\" itemprop=\"text\"\u003e\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch1 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAwesome-Code-LLM\u003c/h1\u003e\u003ca id=\"user-content-awesome-code-llm\" class=\"anchor\" aria-label=\"Permalink: Awesome-Code-LLM\" href=\"#awesome-code-llm\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp align=\"center\" dir=\"auto\"\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"/codefuse-ai/Awesome-Code-LLM/blob/main/imgs/wordcloud.png\"\u003e\u003cimg src=\"/codefuse-ai/Awesome-Code-LLM/raw/main/imgs/wordcloud.png\" style=\"width: 100%; max-width: 100%;\"\u003e\u003c/a\u003e\n\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eThis is the repo for our TMLR \u003ca href=\"https://arxiv.org/abs/2311.07989\" rel=\"nofollow\"\u003ecode LLM survey\u003c/a\u003e. If you find this repo helpful, please support us by citing:\u003c/p\u003e\n\u003cdiv class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"@article{zhang2024unifying,\n   title={Unifying the Perspectives of {NLP} and Software Engineering: A Survey on Language Models for Code},\n   author={Ziyin Zhang and Chaoyu Chen and Bingchang Liu and Cong Liao and Zi Gong and Hang Yu and Jianguo Li and Rui Wang},\n   journal={Transactions on Machine Learning Research},\n   issn={2835-8856},\n   year={2024},\n   url={https://openreview.net/forum?id=hkNnGqZnpa}\n}\"\u003e\u003cpre class=\"notranslate\"\u003e\u003ccode\u003e@article{zhang2024unifying,\n   title={Unifying the Perspectives of {NLP} and Software Engineering: A Survey on Language Models for Code},\n   author={Ziyin Zhang and Chaoyu Chen and Bingchang Liu and Cong Liao and Zi Gong and Hang Yu and Jianguo Li and Rui Wang},\n   journal={Transactions on Machine Learning Research},\n   issn={2835-8856},\n   year={2024},\n   url={https://openreview.net/forum?id=hkNnGqZnpa}\n}\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eNews\u003c/h2\u003e\u003ca id=\"user-content-news\" class=\"anchor\" aria-label=\"Permalink: News\" href=\"#news\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003e [2025/10/23] Featured papers:\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e \u003ca href=\"https://arxiv.org/abs/2510.18855\" rel=\"nofollow\"\u003eEvery Step Evolves: Scaling Reinforcement Learning for Trillion-Scale Thinking Model\u003c/a\u003e from Ant Group.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e \u003ca href=\"https://arxiv.org/abs/2510.17891\" rel=\"nofollow\"\u003eTritonRL: Training LLMs to Think and Code Triton Without Cheating\u003c/a\u003e from Carnegie Mellon University.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e \u003ca href=\"https://arxiv.org/abs/2510.09595\" rel=\"nofollow\"\u003eLiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?\u003c/a\u003e from University of Michigan.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e \u003ca href=\"https://arxiv.org/abs/2510.08702\" rel=\"nofollow\"\u003eScaling Laws for Code: A More Data-Hungry Regime\u003c/a\u003e from Harbin Institute of Technology.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e \u003ca href=\"https://arxiv.org/abs/2510.08697\" rel=\"nofollow\"\u003eBigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution\u003c/a\u003e from Monash University.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp dir=\"auto\"\u003e [2025/08/24] 29 papers from ICML 2025 have been added. Search for the keyword \"ICML 2025\"!\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e [2025/08/15] 80 papers from ACL 2025 have been added. Search for the keyword \"ACL 2025\"!\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e [2024/09/06] \u003cstrong\u003eOur survey has been accepted for publication by \u003ca href=\"https://jmlr.org/tmlr/\" rel=\"nofollow\"\u003eTransactions on Machine Learning Research (TMLR)\u003c/a\u003e.\u003c/strong\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e [2025/09/22] News from Codefuse\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eWe released \u003ca href=\"https://arxiv.org/abs/2510.02294\" rel=\"nofollow\"\u003eF2LLM\u003c/a\u003e, a fully open embedding model striking a strong balance between model size, training data, and embedding performance. [\u003ca href=\"https://github.com/codefuse-ai/CodeFuse-Embeddings\"\u003ecode\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/collections/codefuse-ai/codefuse-embeddings-68d4b32da791bbba993f8d14\" rel=\"nofollow\"\u003emodel \u0026amp; data\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eWe released a new benchmark focusing on code review: \u003ca href=\"https://arxiv.org/abs/2509.14856\" rel=\"nofollow\"\u003eCodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://arxiv.org/abs/2505.16901\" rel=\"nofollow\"\u003eCGM (Code Graph Model)\u003c/a\u003e is accepted to NeurIPS 2025. CGM currently ranks 1st among open-weight models on \u003ca href=\"https://www.swebench.com/\" rel=\"nofollow\"\u003eSWE-Bench-Lite leaderboard\u003c/a\u003e. [\u003ca href=\"https://github.com/codefuse-ai/CodeFuse-CGM\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://arxiv.org/abs/2409.04183\" rel=\"nofollow\"\u003eGALLa: Graph Aligned Large Language Models\u003c/a\u003e is accepted by ACL 2025 main conference. [\u003ca href=\"https://github.com/codefuse-ai/GALLa\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eHow to Contribute\u003c/h4\u003e\u003ca id=\"user-content-how-to-contribute\" class=\"anchor\" aria-label=\"Permalink: How to Contribute\" href=\"#how-to-contribute\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eIf you find a paper to be missing from this repository, misplaced in a category, or lacking a reference to its journal/conference information, please do not hesitate to create an issue.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eTable of Contents\u003c/h2\u003e\u003ca id=\"user-content-table-of-contents\" class=\"anchor\" aria-label=\"Permalink: Table of Contents\" href=\"#table-of-contents\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"#1-surveys\"\u003eSurveys\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"#2-models\"\u003eModels\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e2.1 \u003ca href=\"#21-base-llms-and-pretraining-strategies\"\u003eBase LLMs and Pretraining Strategies\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e2.2 \u003ca href=\"#22-existing-llm-adapted-to-code\"\u003eExisting LLM Adapted to Code\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e2.3 \u003ca href=\"#23-general-pretraining-on-code\"\u003eGeneral Pretraining on Code\u003c/a\u003e\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#encoder\"\u003eEncoder\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#decoder\"\u003eDecoder\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#encoder-decoder\"\u003eEncoder-Decoder\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#unilm\"\u003eUniLM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#other-models\"\u003eOther Models\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp dir=\"auto\"\u003e2.4 \u003ca href=\"#24-instruction-fine-tuning-on-code\"\u003e(Instruction) Fine-Tuning on Code\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e2.5 \u003ca href=\"#25-reinforcement-learning-on-code\"\u003eReinforcement Learning on Code\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"#3-when-coding-meets-reasoning\"\u003eWhen Coding Meets Reasoning\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e3.1 \u003ca href=\"#31-coding-for-reasoning\"\u003eCoding for Reasoning\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e3.2 \u003ca href=\"#32-code-simulation\"\u003eCode Simulation\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e3.3 \u003ca href=\"#33-code-agents\"\u003eCode Agents\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e3.4 \u003ca href=\"#34-interactive-coding\"\u003eInteractive Coding\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e3.5 \u003ca href=\"#35-frontend-navigation\"\u003eFrontend Navigation\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"#4-code-llm-for-low-resource-low-level-and-domain-specific-languages\"\u003eCode LLM for Low-Resource, Low-Level, and Domain-Specific Languages\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"#5-methodsmodels-for-downstream-tasks\"\u003eMethods/Models for Downstream Tasks\u003c/a\u003e\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eProgramming\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#code-generation\"\u003eCode Generation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#code-rag\"\u003eCode RAG\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#code-ranking\"\u003eCode Ranking\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#code-translation\"\u003eCode Translation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#code-commenting-and-summarization\"\u003eCode Commenting and Summarization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#program-repair\"\u003eProgram Repair\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#code-similarity-and-embedding-clone-detection-code-search\"\u003eCode Similarity and Embedding (Clone Detection, Code Search)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#code-refactoring-and-migration\"\u003eCode Refactoring and Migration\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#type-prediction\"\u003eType Prediction\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#repository-level-coding\"\u003eRepository-Level Coding\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#issue-resolution\"\u003eIssue Resolution\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#frontend-development\"\u003eFrontend Development\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#automated-machine-learning\"\u003eAutomated Machine Learning\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#text-to-sql\"\u003eText-To-SQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#program-proof\"\u003eProgram Proof\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eTesting and Deployment\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#test-generation\"\u003eTest Generation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#oracle-generation\"\u003eOracle Generation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#mutation-testing\"\u003eMutation Testing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#fuzz-testing\"\u003eFuzz Testing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#vulnerability-detection\"\u003eVulnerability Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#malicious-code-detection\"\u003eMalicious Code Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#compiler-optimization\"\u003eCompiler Optimization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#binary-analysis-and-decompilation\"\u003eBinary Analysis and Decompilation\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eDevOps\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#commit-message-generation\"\u003eCommit Message Generation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#code-review\"\u003eCode Review\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#log-analysis\"\u003eLog Analysis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#software-configuration\"\u003eSoftware Configuration\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#code-qa--reasoning\"\u003eCode QA \u0026amp; Reasoning\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003eRequirement\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#software-modeling\"\u003eSoftware Modeling\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#requirement-engineering\"\u003eRequirement Engineering\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"#6-analysis-of-ai-generated-code\"\u003eAnalysis of AI-Generated Code\u003c/a\u003e\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#security-and-vulnerabilities\"\u003eSecurity and Vulnerabilities\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#correctness\"\u003eCorrectness\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#hallucination\"\u003eHallucination\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#efficiency\"\u003eEfficiency\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#robustness\"\u003eRobustness\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#interpretability\"\u003eInterpretability\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#api-usage\"\u003eAPI Usage\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#privacy\"\u003ePrivacy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#bias\"\u003eBias\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#contamination\"\u003eContamination\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#ai-generated-code-detection\"\u003eAI-Generated Code Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#others\"\u003eOthers\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"#7-human-llm-interaction\"\u003eHuman-LLM Interaction\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"#8-datasets\"\u003eDatasets\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e8.1 \u003ca href=\"#81-pretraining\"\u003ePretraining\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e8.2 \u003ca href=\"#82-benchmarks\"\u003eBenchmarks\u003c/a\u003e\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"#integrated-benchmarks\"\u003eIntegrated Benchmarks\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#evaluation-metrics\"\u003eEvaluation Metrics\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#program-synthesis\"\u003eProgram Synthesis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#visually-grounded-program-synthesis\"\u003eVisually Grounded Program Synthesis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#code-reasoning-and-qa\"\u003eCode Reasoning and QA\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#text-to-sql-1\"\u003eText-to-SQL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#code-translation-1\"\u003eCode Translation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#program-repair-1\"\u003eProgram Repair\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#code-summarization\"\u003eCode Summarization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#defectvulnerability-detection\"\u003eDefect/Vulnerability Detection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#code-retrieval\"\u003eCode Retrieval\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#type-inference\"\u003eType Inference\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#commit-message-generation-1\"\u003eCommit Message Generation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#repo-level-coding\"\u003eRepo-Level Coding\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"#9-recommended-readings\"\u003eRecommended Readings\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"#citation\"\u003eCitation\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"#star-history\"\u003eStar History\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"#join-us\"\u003eJoin Us\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e1. Surveys\u003c/h2\u003e\u003ca id=\"user-content-1-surveys\" class=\"anchor\" aria-label=\"Permalink: 1. Surveys\" href=\"#1-surveys\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eWe list several recent surveys on similar topics. While they are all about language models for code, 1-2 focus on NLP side; 3-6 focus on SE side; 7-11 are released after ours.\u003c/p\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models Meet NL2Code: A Survey\" [2022-12] [ACL 2023] [\u003ca href=\"https://arxiv.org/abs/2212.09420\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Survey on Pretrained Language Models for Neural Code Intelligence\" [2022-12] [\u003ca href=\"https://arxiv.org/abs/2212.10079\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Empirical Comparison of Pre-Trained Models of Source Code\" [2023-02] [ICSE 2023] [\u003ca href=\"https://arxiv.org/abs/2302.04026\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models for Software Engineering: A Systematic Literature Review\" [2023-08] [\u003ca href=\"https://arxiv.org/abs/2308.10620\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards an Understanding of Large Language Models in Software Engineering Tasks\" [2023-08] [\u003ca href=\"https://arxiv.org/abs/2308.11396\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Pitfalls in Language Models for Code Intelligence: A Taxonomy and Survey\" [2023-10] [\u003ca href=\"https://arxiv.org/abs/2310.17903\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Survey on Large Language Models for Software Engineering\" [2023-12] [\u003ca href=\"https://arxiv.org/abs/2312.15223\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Deep Learning for Code Intelligence: Survey, Benchmark and Toolkit\" [2023-12] [\u003ca href=\"https://arxiv.org/abs/2401.00288\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.14734\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Tasks People Prompt: A Taxonomy of LLM Downstream Tasks in Software Verification and Falsification Approaches\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.09384\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automatic Programming: Large Language Models and Beyond\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.02213\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Software Engineering and Foundation Models: Insights from Industry Blogs Using a Jury of Foundation Models\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.09012\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Deep Learning-based Software Engineering: Progress, Challenges, and Opportunities\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.13110\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models (LLMs) for Source Code Analysis: applications, models and datasets\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.17502\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Challenges and Paths Towards AI for Software Engineering\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.22625\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Software Development Life Cycle Perspective: A Survey of Benchmarks for CodeLLMs and Agents\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.05283\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e2. Models\u003c/h2\u003e\u003ca id=\"user-content-2-models\" class=\"anchor\" aria-label=\"Permalink: 2. Models\" href=\"#2-models\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp align=\"center\" dir=\"auto\"\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"/codefuse-ai/Awesome-Code-LLM/blob/main/imgs/overview.png\"\u003e\u003cimg src=\"/codefuse-ai/Awesome-Code-LLM/raw/main/imgs/overview.png\" style=\"width: 80%; max-width: 100%;\"\u003e\u003c/a\u003e\n\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e2.1 Base LLMs and Pretraining Strategies\u003c/h3\u003e\u003ca id=\"user-content-21-base-llms-and-pretraining-strategies\" class=\"anchor\" aria-label=\"Permalink: 2.1 Base LLMs and Pretraining Strategies\" href=\"#21-base-llms-and-pretraining-strategies\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eThese LLMs are not specifically trained for code, but have demonstrated varying coding capability.\u003c/p\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLaMDA\u003c/strong\u003e: \"LaMDA: Language Models for Dialog Applications\" [2022-01] [\u003ca href=\"https://arxiv.org/abs/2201.08239\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePaLM\u003c/strong\u003e: \"PaLM: Scaling Language Modeling with Pathways\" [2022-04] [JMLR] [\u003ca href=\"https://arxiv.org/abs/2204.02311\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGPT-NeoX\u003c/strong\u003e: \"GPT-NeoX-20B: An Open-Source Autoregressive Language Model\" [2022-04] [ACL 2022 Workshop on Challenges \u0026amp; Perspectives in Creating LLMs] [\u003ca href=\"https://arxiv.org/abs/2204.06745\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/EleutherAI/gpt-neox\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eBLOOM\u003c/strong\u003e: \"BLOOM: A 176B-Parameter Open-Access Multilingual Language Model\" [2022-11] [\u003ca href=\"https://arxiv.org/abs/2211.05100\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/models?search=bigscience/bloom\" rel=\"nofollow\"\u003emodel\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLLaMA\u003c/strong\u003e: \"LLaMA: Open and Efficient Foundation Language Models\" [2023-02] [\u003ca href=\"https://arxiv.org/abs/2302.13971\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGPT-4\u003c/strong\u003e: \"GPT-4 Technical Report\" [2023-03] [\u003ca href=\"https://arxiv.org/abs/2303.08774\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLLaMA 2\u003c/strong\u003e: \"Llama 2: Open Foundation and Fine-Tuned Chat Models\" [2023-07] [\u003ca href=\"https://arxiv.org/abs/2307.09288\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/facebookresearch/llama\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePhi-1.5\u003c/strong\u003e: \"Textbooks Are All You Need II: phi-1.5 technical report\" [2023-09] [\u003ca href=\"https://arxiv.org/abs/2309.05463\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/microsoft/phi-1_5\" rel=\"nofollow\"\u003emodel\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eBaichuan 2\u003c/strong\u003e: \"Baichuan 2: Open Large-scale Language Models\" [2023-09] [\u003ca href=\"https://arxiv.org/abs/2309.10305\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/baichuan-inc/Baichuan2\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eQwen\u003c/strong\u003e: \"Qwen Technical Report\" [2023-09] [\u003ca href=\"https://arxiv.org/abs/2309.16609\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/QwenLM/Qwen\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMistral\u003c/strong\u003e: \"Mistral 7B\" [2023-10] [\u003ca href=\"https://arxiv.org/abs/2310.06825\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/mistralai/mistral-src\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGemini\u003c/strong\u003e: \"Gemini: A Family of Highly Capable Multimodal Models\" [2023-12] [\u003ca href=\"https://arxiv.org/abs/2312.11805\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePhi-2\u003c/strong\u003e: \"Phi-2: The surprising power of small language models\" [2023-12] [\u003ca href=\"https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/\" rel=\"nofollow\"\u003eblog\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eYAYI2\u003c/strong\u003e: \"YAYI 2: Multilingual Open-Source Large Language Models\" [2023-12] [\u003ca href=\"https://arxiv.org/abs/2312.14862\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/wenge-research/YAYI2\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDeepSeek\u003c/strong\u003e: \"DeepSeek LLM: Scaling Open-Source Language Models with Longtermism\" [2024-01] [\u003ca href=\"https://arxiv.org/abs/2401.02954\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/deepseek-ai/DeepSeek-LLM\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMixtral\u003c/strong\u003e: \"Mixtral of Experts\" [2024-01] [\u003ca href=\"https://arxiv.org/abs/2401.04088\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://mistral.ai/news/mixtral-of-experts/\" rel=\"nofollow\"\u003eblog\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDeepSeekMoE\u003c/strong\u003e: \"DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models\" [2024-01] [\u003ca href=\"https://arxiv.org/abs/2401.12246\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/deepseek-ai/DeepSeek-MoE\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eOrion\u003c/strong\u003e: \"Orion-14B: Open-source Multilingual Large Language Models\" [2024-01] [\u003ca href=\"https://arxiv.org/abs/2401.06066\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/OrionStarAI/Orion\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eOLMo\u003c/strong\u003e: \"OLMo: Accelerating the Science of Language Models\" [2024-02] [\u003ca href=\"https://arxiv.org/abs/2402.00838\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/allenai/OLMo\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGemma\u003c/strong\u003e: \"Gemma: Open Models Based on Gemini Research and Technology\" [2024-02] [\u003ca href=\"https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://blog.google/technology/developers/gemma-open-models/\" rel=\"nofollow\"\u003eblog\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eClaude 3\u003c/strong\u003e: \"The Claude 3 Model Family: Opus, Sonnet, Haiku\" [2024-03] [\u003ca href=\"https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://www.anthropic.com/news/claude-3-family\" rel=\"nofollow\"\u003eblog\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eYi\u003c/strong\u003e: \"Yi: Open Foundation Models by 01.AI\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.04652\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/01-ai/Yi\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePoro\u003c/strong\u003e: \"Poro 34B and the Blessing of Multilinguality\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.01856\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/LumiOpen/Poro-34B\" rel=\"nofollow\"\u003emodel\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eJetMoE\u003c/strong\u003e: \"JetMoE: Reaching Llama2 Performance with 0.1M Dollars\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.07413\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/myshell-ai/JetMoE\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLLaMA 3\u003c/strong\u003e: \"The Llama 3 Herd of Models\" [2024-04] [\u003ca href=\"https://ai.meta.com/blog/meta-llama-3/\" rel=\"nofollow\"\u003eblog\u003c/a\u003e] [\u003ca href=\"https://github.com/meta-llama/llama3\"\u003erepo\u003c/a\u003e] [\u003ca href=\"https://arxiv.org/abs/2407.21783\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eReka Core\u003c/strong\u003e: \"Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language Models\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.12387\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePhi-3\u003c/strong\u003e: \"Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.14219\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eOpenELM\u003c/strong\u003e: \"OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.14619\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/apple/corenet/tree/main/projects/openelm\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eTele-FLM\u003c/strong\u003e: \"Tele-FLM Technical Report\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.16645\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/CofeAI/Tele-FLM\" rel=\"nofollow\"\u003emodel\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDeepSeek-V2\u003c/strong\u003e: \"DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.04434\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/deepseek-ai/DeepSeek-V2\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGECKO\u003c/strong\u003e: \"GECKO: Generative Language Model for English, Code and Korean\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.15640\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/kifai/GECKO-7B\" rel=\"nofollow\"\u003emodel\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMAP-Neo\u003c/strong\u003e: \"MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.19327\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/multimodal-art-projection/MAP-NEO\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eZyda\u003c/strong\u003e: \"Zyda: A 1.3T Dataset for Open Language Modeling\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.01981\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSkywork-MoE\u003c/strong\u003e: \"Skywork-MoE: A Deep Dive into Training Techniques for Mixture-of-Experts Language Models\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.06563\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eXmodel-LM\u003c/strong\u003e: \"Xmodel-LM Technical Report\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.02856\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGEB\u003c/strong\u003e: \"GEB-1.3B: Open Lightweight Large Language Model\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.09900\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eHARE\u003c/strong\u003e: \"HARE: HumAn pRiors, a key to small language model Efficiency\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.11410\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDCLM\u003c/strong\u003e: \"DataComp-LM: In search of the next generation of training sets for language models\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.11794\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eNemotron-4\u003c/strong\u003e: \"Nemotron-4 340B Technical Report\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.11704\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eChatGLM\u003c/strong\u003e: \"ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.12793\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eFineWeb\u003c/strong\u003e: \"The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.17557\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eYuLan\u003c/strong\u003e: \"YuLan: An Open-source Large Language Model\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.19853\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGemma 2\u003c/strong\u003e: \"Gemma 2: Improving Open Language Models at a Practical Size\" [2024-06] [\u003ca href=\"https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eH2O-Danube3\u003c/strong\u003e: \"H2O-Danube3 Technical Report\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.09276\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eQwen2\u003c/strong\u003e: \"Qwen2 Technical Report\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.10671\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eALLaM\u003c/strong\u003e: \"ALLaM: Large Language Models for Arabic and English\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.15390\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSeaLLMs 3\u003c/strong\u003e: \"SeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for Southeast Asian Languages\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.19672\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAFM\u003c/strong\u003e: \"Apple Intelligence Foundation Language Models\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.21075\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"To Code, or Not To Code? Exploring Impact of Code in Pre-training\" [2024-08] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2408.10914\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eOLMoE\u003c/strong\u003e: \"OLMoE: Open Mixture-of-Experts Language Models\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.02060\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How Does Code Pretraining Affect Language Model Task Performance?\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.04556\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eEuroLLM\u003c/strong\u003e: \"EuroLLM: Multilingual Language Models for Europe\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.16235\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?\" [2024-10] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2410.06735\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGPT-4o\u003c/strong\u003e: \"GPT-4o System Card\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.21276\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eHunyuan-Large\u003c/strong\u003e: \"Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.02265\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCrystal\u003c/strong\u003e: \"Crystal: Illuminating LLM Abilities on Language and Code\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.04156\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eZyda-2\u003c/strong\u003e: \"Zyda-2: a 5 Trillion Token High-Quality Dataset\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.06068\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eXmodel-1.5\u003c/strong\u003e: \"Xmodel-1.5: An 1B-scale Multilingual LLM\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.10083\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eYi-Lightning\u003c/strong\u003e: \"Yi-Lightning Technical Report\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.01253\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RedStone: Curating General, Code, Math, and QA Data for Large Language Models\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.03398\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eEXAONE 3.5\u003c/strong\u003e: \"EXAONE 3.5: Series of Large Language Models for Real-world Use Cases\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.04862\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Rise and Down of Babel Tower: Investigating the Evolution Process of Multilingual Code Large Language Model\" [2024-12] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2412.07298\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePhi-4\u003c/strong\u003e: \"Phi-4 Technical Report\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.08905\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eTyphoon 2\u003c/strong\u003e: \"Typhoon 2: A Family of Open Text and Multimodal Thai Large Language Models\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.13702\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eQwen2.5\u003c/strong\u003e: \"Qwen2.5 Technical Report\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.15115\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eYuLan-Mini\u003c/strong\u003e: \"YuLan-Mini: An Open Data-efficient Language Model\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.17743\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDeepSeek-V3\u003c/strong\u003e: \"DeepSeek-V3 Technical Report\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.19437\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eOLMo 2\u003c/strong\u003e: \"2 OLMo 2 Furious\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2501.00656\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eFinerWeb\u003c/strong\u003e: \"FinerWeb-10BT: Refining Web Data with LLM-Based Line-Level Filtering\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.07314\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMiniMax-01\u003c/strong\u003e: \"MiniMax-01: Scaling Foundation Models with Lightning Attention\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.08313\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSmolLM2\u003c/strong\u003e: \"SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language Model\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.02737\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSalamandra\u003c/strong\u003e: \"Salamandra Technical Report\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.08489\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eKanana\u003c/strong\u003e: \"Kanana: Compute-efficient Bilingual Language Models\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.18934\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePhi-4-Mini\u003c/strong\u003e: \"Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.01743\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLing\u003c/strong\u003e: \"Every FLOP Counts: Scaling a 300B Mixture-of-Experts LING LLM without Premium GPUs\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.05139\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGemma 3\u003c/strong\u003e: \"Gemma 3 Technical Report\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.19786\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCommand A\u003c/strong\u003e: \"Command A: An Enterprise-Ready Large Language Model\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.00698\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLlama-Nemotron\u003c/strong\u003e: \"Llama-Nemotron: Efficient Reasoning Models\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.00949\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMiMo\u003c/strong\u003e: \"MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.07608\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003exGen-small\u003c/strong\u003e: \"xGen-small Technical Report\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.06496\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eQwen3\u003c/strong\u003e: \"Qwen3 Technical Report\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.09388\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eHunyuan-TurboS\u003c/strong\u003e: \"Hunyuan-TurboS: Advancing Large Language Models through Mamba-Transformer Synergy and Adaptive Chain-of-Thought\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.15431\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eEuroLLM-9B\u003c/strong\u003e: \"EuroLLM-9B: Technical Report\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.04079\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGemini 2.5\u003c/strong\u003e: \"Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.06261\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eEXAONE 4.0\u003c/strong\u003e: \"EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and Reasoning Modes\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.11407\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eTeleChat2\u003c/strong\u003e: \"Technical Report of TeleChat2, TeleChat2.5 and T1\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.18013\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eKimi K2\u003c/strong\u003e: \"Kimi K2: Open Agentic Intelligence\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.20534\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGLM-4.5\u003c/strong\u003e: \"GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.06471\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGPT-OSS\u003c/strong\u003e: \"gpt-oss-120b \u0026amp; gpt-oss-20b Model Card\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.10925\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLongCat-Flash\u003c/strong\u003e: \"LongCat-Flash Technical Report\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.01322\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLLaDA-MoE\u003c/strong\u003e: \"LLaDA-MoE: A Sparse MoE Diffusion Language Model\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.24389\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eRing-1T\u003c/strong\u003e: \"Every Step Evolves: Scaling Reinforcement Learning for Trillion-Scale Thinking Model\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.18855\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e2.2 Existing LLM Adapted to Code\u003c/h3\u003e\u003ca id=\"user-content-22-existing-llm-adapted-to-code\" class=\"anchor\" aria-label=\"Permalink: 2.2 Existing LLM Adapted to Code\" href=\"#22-existing-llm-adapted-to-code\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eThese models are general-purpose LLMs further pretrained on code-related data.\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodex\u003c/strong\u003e (GPT-3): \"Evaluating Large Language Models Trained on Code\" [2021-07] [\u003ca href=\"https://arxiv.org/abs/2107.03374\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePaLM Coder\u003c/strong\u003e (PaLM): \"PaLM: Scaling Language Modeling with Pathways\" [2022-04] [JMLR] [\u003ca href=\"https://arxiv.org/abs/2204.02311\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMinerva\u003c/strong\u003e (PaLM): \"Solving Quantitative Reasoning Problems with Language Models\" [2022-06] [\u003ca href=\"https://arxiv.org/abs/2206.14858\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePaLM 2 *\u003c/strong\u003e (PaLM 2): \"PaLM 2 Technical Report\" [2023-05] [\u003ca href=\"https://arxiv.org/abs/2305.10403\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCode LLaMA\u003c/strong\u003e (LLaMA 2): \"Code Llama: Open Foundation Models for Code\" [2023-08] [\u003ca href=\"https://arxiv.org/abs/2308.12950\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/facebookresearch/codellama\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLemur\u003c/strong\u003e (LLaMA 2): \"Lemur: Harmonizing Natural Language and Code for Language Agents\" [2023-10] [ICLR 2024 Spotlight] [\u003ca href=\"https://arxiv.org/abs/2310.06830\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eBTX\u003c/strong\u003e (LLaMA 2): \"Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.07816\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eHiRoPE\u003c/strong\u003e: \"HiRoPE: Length Extrapolation for Code Models Using Hierarchical Position\" [2024-03] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2403.19115\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Mastering Text, Code and Math Simultaneously via Fusing Highly Specialized Language Models\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.08281\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeGemma\u003c/strong\u003e: \"CodeGemma: Open Code Models Based on Gemma\" [2024-04] [\u003ca href=\"https://storage.googleapis.com/deepmind-media/gemma/codegemma_report.pdf\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/models?search=google/codegemma\" rel=\"nofollow\"\u003emodel\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDeepSeek-Coder-V2\u003c/strong\u003e: \"DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.11931\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Promise and Peril of Collaborative Code Generation Models: Balancing Effectiveness and Memorization\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.12020\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eQwen2.5-Coder\u003c/strong\u003e: \"Qwen2.5-Coder Technical Report\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.12186\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLingma SWE-GPT\u003c/strong\u003e: \"Lingma SWE-GPT: An Open Development-Process-Centric Language Model for Automated Software Improvement\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.00622\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLing-Coder-Lite\u003c/strong\u003e: \"Every Sample Matters: Leveraging Mixture-of-Experts and High-Quality Data for Efficient and Accurate Code LLM\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.17793\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e2.3 General Pretraining on Code\u003c/h3\u003e\u003ca id=\"user-content-23-general-pretraining-on-code\" class=\"anchor\" aria-label=\"Permalink: 2.3 General Pretraining on Code\" href=\"#23-general-pretraining-on-code\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eThese models are Transformer encoders, decoders, and encoder-decoders pretrained from scratch using existing objectives for general language modeling.\u003c/p\u003e\n\u003cp align=\"center\" dir=\"auto\"\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"/codefuse-ai/Awesome-Code-LLM/blob/main/imgs/model_detail.png\"\u003e\u003cimg src=\"/codefuse-ai/Awesome-Code-LLM/raw/main/imgs/model_detail.png\" style=\"width: 90%; max-width: 100%;\"\u003e\u003c/a\u003e\n\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eEncoder\u003c/h4\u003e\u003ca id=\"user-content-encoder\" class=\"anchor\" aria-label=\"Permalink: Encoder\" href=\"#encoder\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCuBERT\u003c/strong\u003e (MLM + NSP): \"Learning and Evaluating Contextual Embedding of Source Code\" [2019-12] [ICML 2020] [\u003ca href=\"https://arxiv.org/abs/2001.00059\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/google-research/google-research/tree/master/cubert\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeBERT\u003c/strong\u003e (MLM + RTD): \"CodeBERT: A Pre-Trained Model for Programming and Natural Languages\" [2020-02] [EMNLP 2020 findings] [\u003ca href=\"https://arxiv.org/abs/2002.08155\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/microsoft/CodeBERT\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGraphCodeBERT\u003c/strong\u003e (MLM + DFG Edge Prediction + DFG Node Alignment): \"GraphCodeBERT: Pre-training Code Representations with Data Flow\" [2020-09] [ICLR 2021] [\u003ca href=\"https://arxiv.org/abs/2009.08366\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/microsoft/CodeBERT\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSynCoBERT\u003c/strong\u003e (MLM + Identifier Prediction + AST Edge Prediction + Contrastive Learning): \"SynCoBERT: Syntax-Guided Multi-Modal Contrastive Pre-Training for Code Representation\" [2021-08] [\u003ca href=\"https://arxiv.org/abs/2108.04556\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDISCO\u003c/strong\u003e (MLM + Node Type MLM + Contrastive Learning): \"Towards Learning (Dis)-Similarity of Source Code from Program Contrasts\" [2021-10] [ACL 2022] [\u003ca href=\"https://arxiv.org/abs/2110.03868\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCode-MVP\u003c/strong\u003e (MLM + Type Inference + Contrastive Learning): \"CODE-MVP: Learning to Represent Source Code from Multiple Views with Contrastive Pre-Training\" [2022-05] [NAACL 2022 Technical Track] [\u003ca href=\"https://arxiv.org/abs/2205.02029\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeSage\u003c/strong\u003e (MLM + Deobfuscation + Contrastive Learning): \"Code Representation Learning At Scale\" [2024-02] [ICLR 2024] [\u003ca href=\"https://arxiv.org/abs/2402.01935\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCoLSBERT\u003c/strong\u003e (MLM): \"Scaling Laws Behind Code Understanding Model\" [2024-02] [\u003ca href=\"https://arxiv.org/abs/2402.12813\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eBiGSCoder\u003c/strong\u003e: \"BiGSCoder: State Space Model for Code Understanding\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.01475\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eDecoder\u003c/h4\u003e\u003ca id=\"user-content-decoder\" class=\"anchor\" aria-label=\"Permalink: Decoder\" href=\"#decoder\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGPT-C\u003c/strong\u003e (CLM): \"IntelliCode Compose: Code Generation Using Transformer\" [2020-05] [ESEC/FSE 2020] [\u003ca href=\"https://arxiv.org/abs/2005.08025\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeGPT\u003c/strong\u003e (CLM): \"CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation\" [2021-02] [NeurIPS Datasets and Benchmarks 2021] [\u003ca href=\"https://arxiv.org/abs/2102.04664\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/microsoft/CodeXGLUE\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeParrot\u003c/strong\u003e (CLM) [2021-12] [\u003ca href=\"https://huggingface.co/blog/codeparrot\" rel=\"nofollow\"\u003eblog\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePolyCoder\u003c/strong\u003e (CLM): \"A Systematic Evaluation of Large Language Models of Code\" [2022-02] [DL4C@ICLR 2022] [\u003ca href=\"https://arxiv.org/abs/2202.13169\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/VHellendoorn/Code-LMs\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeGen\u003c/strong\u003e (CLM): \"CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis\" [2022-03] [ICLR 2023] [\u003ca href=\"https://arxiv.org/abs/2203.13474\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/salesforce/CodeGen\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eInCoder\u003c/strong\u003e (Causal Masking): \"InCoder: A Generative Model for Code Infilling and Synthesis\" [2022-04] [ICLR 2023] [\u003ca href=\"https://arxiv.org/abs/2204.05999\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/dpfried/incoder\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePyCodeGPT\u003c/strong\u003e (CLM): \"CERT: Continual Pre-Training on Sketches for Library-Oriented Code Generation\" [2022-06] [IJCAI-ECAI 2022] [\u003ca href=\"https://arxiv.org/abs/2206.06888\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/microsoft/PyCodeGPT\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePanGu-Coder\u003c/strong\u003e (CLM): \"PanGu-Coder: Program Synthesis with Function-Level Language Modeling\" [2022-07] [\u003ca href=\"https://arxiv.org/abs/2207.11280\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSantaCoder\u003c/strong\u003e (FIM): \"SantaCoder: don't reach for the stars!\" [2023-01] [\u003ca href=\"https://arxiv.org/abs/2301.03988\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/bigcode/santacoder\" rel=\"nofollow\"\u003emodel\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeGeeX\u003c/strong\u003e (CLM): \"CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X\" [2023-03] [\u003ca href=\"https://arxiv.org/abs/2303.17568\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/THUDM/CodeGeeX\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eStarCoder\u003c/strong\u003e (FIM): \"StarCoder: may the source be with you!\" [2023-05] [\u003ca href=\"https://arxiv.org/abs/2305.06161\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/bigcode/starcoder\" rel=\"nofollow\"\u003emodel\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePhi-1\u003c/strong\u003e (CLM): \"Textbooks Are All You Need\" [2023-06] [\u003ca href=\"https://arxiv.org/abs/2306.11644\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/microsoft/phi-1\" rel=\"nofollow\"\u003emodel\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeFuse\u003c/strong\u003e (CLM): \"CodeFuse-13B: A Pretrained Multi-lingual Code Large Language Model\" [2023-10] [\u003ca href=\"https://arxiv.org/abs/2310.06266\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/codefuse-ai/CodeFuse-13B\" rel=\"nofollow\"\u003emodel\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDeepSeek Coder\u003c/strong\u003e (CLM+FIM): \"DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence\" [2024-01] [\u003ca href=\"https://arxiv.org/abs/2401.14196\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/deepseek-ai/DeepSeek-Coder\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eStarCoder2\u003c/strong\u003e (CLM+FIM): \"StarCoder 2 and The Stack v2: The Next Generation\" [2024-02] [\u003ca href=\"https://arxiv.org/abs/2402.19173\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/bigcode-project/starcoder2\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeShell\u003c/strong\u003e (CLM+FIM): \"CodeShell Technical Report\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.15747\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/WisdomShell/codeshell\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeQwen1.5\u003c/strong\u003e [2024-04] [\u003ca href=\"https://qwenlm.github.io/blog/codeqwen1.5/\" rel=\"nofollow\"\u003eblog\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGranite\u003c/strong\u003e: \"Granite Code Models: A Family of Open Foundation Models for Code Intelligence\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.04324\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] \"Scaling Granite Code Models to 128K Context\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.13739\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eNT-Java\u003c/strong\u003e: \"Narrow Transformer: Starcoder-Based Java-LM For Desktop\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.03941\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eArctic-SnowCoder\u003c/strong\u003e: \"Arctic-SnowCoder: Demystifying High-Quality Data in Code Pretraining\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.02326\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eaiXcoder\u003c/strong\u003e: \"aiXcoder-7B: A Lightweight and Effective Large Language Model for Code Completion\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.13187\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eOpenCoder\u003c/strong\u003e: \"OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models\" [2024-11] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2411.04905\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eObscuraCoder\u003c/strong\u003e: \"ObscuraCoder: Powering Efficient Code LM Pre-Training Via Obfuscation Grounding\" [2025-03] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2504.00019\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Structure-Aware Fill-in-the-Middle Pretraining for Code\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2506.00204\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSeed-Coder\u003c/strong\u003e: \"Seed-Coder: Let the Code Model Curate Data for Itself\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.03524\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCWM\u003c/strong\u003e: \"CWM: An Open-Weights LLM for Research on Code Generation with World Models\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2510.02387\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMellum\u003c/strong\u003e: \"Mellum: Production-Grade in-IDE Contextual Code Completion with Multi-File Project Understanding\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.05788\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Scaling Laws for Code: A More Data-Hungry Regime\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.08702\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eEncoder-Decoder\u003c/h4\u003e\u003ca id=\"user-content-encoder-decoder\" class=\"anchor\" aria-label=\"Permalink: Encoder-Decoder\" href=\"#encoder-decoder\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePyMT5\u003c/strong\u003e (Span Corruption): \"PyMT5: multi-mode translation of natural language and Python code with transformers\" [2020-10] [EMNLP 2020] [\u003ca href=\"https://arxiv.org/abs/2010.03150\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMastropaolo et al.\u003c/strong\u003e (MLM + Deobfuscation): \"DOBF: A Deobfuscation Pre-Training Objective for Programming Languages\" [2021-02] [ICSE 2021] [\u003ca href=\"https://arxiv.org/abs/2102.02017\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/antonio-mastropaolo/TransferLearning4Code\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDOBF\u003c/strong\u003e (Span Corruption): \"Studying the Usage of Text-To-Text Transfer Transformer to Support Code-Related Tasks\" [2021-02] [NeurIPS 2021] [\u003ca href=\"https://arxiv.org/abs/2102.07492\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/facebookresearch/CodeGen/blob/main/docs/dobf.md\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePLBART\u003c/strong\u003e (DAE): \"Unified Pre-training for Program Understanding and Generation\" [2021-03] [NAACL 2021] [\u003ca href=\"https://arxiv.org/abs/2103.06333\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/wasiahmad/PLBART\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeT5\u003c/strong\u003e (Span Corruption + Identifier Tagging + Masked Identifier Prediction + Text2Code + Code2Text): \"CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation\" [2021-09] [EMNLP 2021] [\u003ca href=\"https://arxiv.org/abs/2109.00859\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/salesforce/CodeT5\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSPT-Code\u003c/strong\u003e (Span Corruption + NSP + Method Name Prediction): \"SPT-Code: Sequence-to-Sequence Pre-Training for Learning Source Code Representations\" [2022-01] [ICSE 2022 Technical Track] [\u003ca href=\"https://arxiv.org/abs/2201.01549\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAlphaCode\u003c/strong\u003e (MLM + CLM): \"Competition-Level Code Generation with AlphaCode\" [2022-02] [Science] [\u003ca href=\"https://arxiv.org/abs/2203.07814\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://deepmind.google/discover/blog/competitive-programming-with-alphacode/\" rel=\"nofollow\"\u003eblog\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eNatGen\u003c/strong\u003e (Code Naturalization): \"NatGen: Generative pre-training by \"Naturalizing\" source code\" [2022-06] [ESEC/FSE 2022] [\u003ca href=\"https://arxiv.org/abs/2206.07585\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/saikat107/NatGen\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eERNIE-Code\u003c/strong\u003e (Span Corruption + Pivot-based Translation LM): \"ERNIE-Code: Beyond English-Centric Cross-lingual Pretraining for Programming Languages\" [2022-12] [ACL23 (Findings)] [\u003ca href=\"https://aclanthology.org/2023.findings-acl.676.pdf\" rel=\"nofollow\"\u003epaper\u003c/a\u003e][\u003ca href=\"https://github.com/PaddlePaddle/PaddleNLP/tree/develop/model_zoo/ernie-code\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeT5+\u003c/strong\u003e (Span Corruption + CLM + Text-Code Contrastive Learning + Text-Code Translation): \"CodeT5+: Open Code Large Language Models for Code Understanding and Generation\" [2023-05] [EMNLP 2023] [\u003ca href=\"https://arxiv.org/abs/2305.07922\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/salesforce/CodeT5\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAST-T5\u003c/strong\u003e (Span Corruption): \"AST-T5: Structure-Aware Pretraining for Code Generation and Understanding\" [2024-01] [ICML 2024] [\u003ca href=\"https://arxiv.org/abs/2401.03003\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDivoT5\u003c/strong\u003e: \"Directional Diffusion-Style Code Editing Pre-training\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.12079\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eUniLM\u003c/h4\u003e\u003ca id=\"user-content-unilm\" class=\"anchor\" aria-label=\"Permalink: UniLM\" href=\"#unilm\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCugLM\u003c/strong\u003e (MLM + NSP + CLM): \"Multi-task Learning based Pre-trained Language Model for Code Completion\" [2020-12] [ASE 2020] [\u003ca href=\"https://arxiv.org/abs/2012.14631\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eUniXcoder\u003c/strong\u003e (MLM + NSP + CLM + Span Corruption + Contrastive Learning + Code2Text): \"UniXcoder: Unified Cross-Modal Pre-training for Code Representation\" [2022-03] [ACL 2022] [\u003ca href=\"https://arxiv.org/abs/2203.03850\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/microsoft/CodeBERT\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOther Models\u003c/h4\u003e\u003ca id=\"user-content-other-models\" class=\"anchor\" aria-label=\"Permalink: Other Models\" href=\"#other-models\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDiffuCoder\u003c/strong\u003e: \"DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.20639\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDream-Coder\u003c/strong\u003e: \"Dream-Coder 7B: An Open Diffusion Language Model for Code\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.01142\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Beyond Autoregression: An Empirical Study of Diffusion Large Language Models for Code Generation\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.11252\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCoDA\u003c/strong\u003e: \"CoDA: Coding LM via Diffusion Adaptation\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.03270\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e2.4 (Instruction) Fine-Tuning on Code\u003c/h3\u003e\u003ca id=\"user-content-24-instruction-fine-tuning-on-code\" class=\"anchor\" aria-label=\"Permalink: 2.4 (Instruction) Fine-Tuning on Code\" href=\"#24-instruction-fine-tuning-on-code\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eThese models apply Instruction Fine-Tuning techniques to enhance the capacities of Code LLMs.\u003c/p\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eWizardCoder\u003c/strong\u003e (StarCoder + Evol-Instruct): \"WizardCoder: Empowering Code Large Language Models with Evol-Instruct\" [2023-06] [ICLR 2024] [\u003ca href=\"https://arxiv.org/abs/2306.08568\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/nlpxucan/WizardLM\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePanGu-Coder 2\u003c/strong\u003e (StarCoder + Evol-Instruct + RRTF): \"PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback\" [2023-07] [\u003ca href=\"https://arxiv.org/abs/2307.14936\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eOctoCoder\u003c/strong\u003e (StarCoder) / \u003cstrong\u003eOctoGeeX\u003c/strong\u003e (CodeGeeX2): \"OctoPack: Instruction Tuning Code Large Language Models\" [2023-08] [ICLR 2024 Spotlight] [\u003ca href=\"https://arxiv.org/abs/2308.07124\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/bigcode-project/octopack\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"At Which Training Stage Does Code Data Help LLMs Reasoning\" [2023-09] [ICLR 2024 Spotlight] [\u003ca href=\"https://arxiv.org/abs/2309.16298\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eInstructCoder\u003c/strong\u003e: \"InstructCoder: Instruction Tuning Large Language Models for Code Editing\" [\u003ca href=\"https://arxiv.org/abs/2310.20329\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/qishenghu/CodeInstruct\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMFTCoder\u003c/strong\u003e: \"MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning\" [2023-11] [KDD 2024] [\u003ca href=\"https://arxiv.org/abs/2311.02303\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/codefuse-ai/MFTCoder\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM-Assisted Code Cleaning For Training Accurate Code Generators\" [2023-11] [ICLR 2024] [\u003ca href=\"https://arxiv.org/abs/2311.14904\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMagicoder\u003c/strong\u003e: \"Magicoder: Empowering Code Generation with OSS-Instruct\" [2023-12] [ICML 2024] [\u003ca href=\"https://arxiv.org/abs/2312.02120\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eWaveCoder\u003c/strong\u003e: \"WaveCoder: Widespread And Versatile Enhancement For Code Large Language Models By Instruction Tuning\" [2023-12] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2312.14187\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAstraios\u003c/strong\u003e: \"Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models\" [2024-01] [\u003ca href=\"https://arxiv.org/abs/2401.00788\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDolphCoder\u003c/strong\u003e: \"DolphCoder: Echo-Locating Code Large Language Models with Diverse and Multi-Objective Instruction Tuning\" [2024-02] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2402.09136\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSafeCoder\u003c/strong\u003e: \"Instruction Tuning for Secure Code Generation\" [2024-02] [ICML 2024] [\u003ca href=\"https://arxiv.org/abs/2402.09497\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Needs Comments: Enhancing Code LLMs with Comment Augmentation\" [ACL 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2402.13013\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCCT\u003c/strong\u003e: \"Code Comparison Tuning for Code Large Language Models\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.19121\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSAT\u003c/strong\u003e: \"Structure-aware Fine-tuning for Code Pre-trained Models\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.07471\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeFort\u003c/strong\u003e: \"CodeFort: Robust Training for Code Generation Models\" [2024-04] [EMNLP 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2405.01567\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eXFT\u003c/strong\u003e: \"XFT: Unlocking the Power of Code Instruction Tuning by Simply Merging Upcycled Mixture-of-Experts\" [2024-04] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2404.15247\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/ise-uiuc/xft\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAIEV-Instruct\u003c/strong\u003e: \"AutoCoder: Enhancing Code Large Language Model with AIEV-Instruct\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.14906\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAlchemistCoder\u003c/strong\u003e: \"AlchemistCoder: Harmonizing and Eliciting Code Capability by Hindsight Tuning on Multi-source Data\" [2024-05] [NeurIPS 2024] [\u003ca href=\"https://arxiv.org/abs/2405.19265\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"From Symbolic Tasks to Code Generation: Diversification Yields Better Task Performers\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.19787\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Unveiling the Impact of Coding Data Instruction Fine-Tuning on Large Language Models Reasoning\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.20535\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSemCoder\u003c/strong\u003e: \"SemCoder: Training Code Language Models with Comprehensive Semantics Reasoning\" [2024-06] [NeurIPS 2024] [\u003ca href=\"https://arxiv.org/abs/2406.01006\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePLUM\u003c/strong\u003e: \"PLUM: Preference Learning Plus Test Cases Yields Better Code Language Models\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.06887\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003emCoder\u003c/strong\u003e: \"McEval: Massively Multilingual Code Evaluation\" [2024-06] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2406.07436\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Unlock the Correlation between Supervised Fine-Tuning and Reinforcement Learning in Training Code Large Language Models\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.10305\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCode-Optimise\u003c/strong\u003e: \"Code-Optimise: Self-Generated Preference Data for Correctness and Efficiency\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.12502\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eUniCoder\u003c/strong\u003e: \"UniCoder: Scaling Code Large Language Model via Universal Code\" [2024-06] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2406.16441\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Brevity is the soul of wit: Pruning long files for code generation\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2407.00434\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Less, Align More: Efficient LLM Fine-tuning for Code Generation with Data Pruning\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.05040\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eInverseCoder\u003c/strong\u003e: \"InverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.05700\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Curriculum Learning for Small Code Language Models\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.10194\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGenetic-Instruct\u003c/strong\u003e: \"Genetic Instruct: Scaling up Synthetic Generation of Coding Instructions for Large Language Models\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.21077\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDataScope\u003c/strong\u003e: \"API-guided Dataset Synthesis to Finetune Large Code Models\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.08343\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eXCoder\u003c/strong\u003e: \"How Do Your Code LLMs Perform? Empowering Code Instruction Tuning with High-Quality Data\" [2024-09] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2409.03810\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGALLa\u003c/strong\u003e: \"GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding\" [2024-09] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2409.04183\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eHexaCoder\u003c/strong\u003e: \"HexaCoder: Secure Code Generation via Oracle-Guided Synthetic Training Data\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.06446\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAMR-Evol\u003c/strong\u003e: \"AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation\" [2024-10] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2410.00558\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLintSeq\u003c/strong\u003e: \"Training Language Models on Synthetic Edit Sequences Improves Code Synthesis\" [2024-10] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2410.02749\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCoBa\u003c/strong\u003e: \"CoBa: Convergence Balancer for Multitask Finetuning of Large Language Models\" [2024-10] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2410.06741\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCursorCore\u003c/strong\u003e: \"CursorCore: Assist Programming through Aligning Anything\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.07002\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSelfCodeAlign\u003c/strong\u003e: \"SelfCodeAlign: Self-Alignment for Code Generation\" [2024-10] [NeurIPS 2024] [\u003ca href=\"https://arxiv.org/abs/2410.24198\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Mastering the Craft of Data Synthesis for CodeLLMs\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2411.00005\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeLutra\u003c/strong\u003e: \"CodeLutra: Boosting LLM Code Generation via Preference-Guided Refinement\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.05199\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDSTC\u003c/strong\u003e: \"DSTC: Direct Preference Learning with Only Self-Generated Tests and Code to Improve Code LMs\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.13611\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eWarriorCoder\u003c/strong\u003e: \"WarriorCoder: Learning from Expert Battles to Augment Code Large Language Models\" [2024-12] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2412.17395\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eEpiCoder\u003c/strong\u003e: \"EpiCoder: Encompassing Diversity and Complexity in Code Generation\" [2025-01] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2501.04694\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eQwen2.5-xCoder\u003c/strong\u003e: \"Multi-Agent Collaboration for Multilingual Code Instruction Tuning\" [2025-02] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2502.07487\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eUnitCoder\u003c/strong\u003e: \"UnitCoder: Scalable Iterative Code Synthesis with Unit Test Guidance\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.11460\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGiFT\u003c/strong\u003e: \"GiFT: Gibbs Fine-Tuning for Code Generation\" [2025-02] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2502.11466\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eKODCODE\u003c/strong\u003e: \"KodCode: A Diverse, Challenging, and Verifiable Synthetic Dataset for Coding\" [2025-03] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2503.02951\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eNextCoder\u003c/strong\u003e: \"NextCoder: Robust Adaptation of Code LMs to Diverse Code Edits\" [2025-03] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2503.03656\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eFAIT\u003c/strong\u003e: \"FAIT: Fault-Aware Fine-Tuning for Better Code Generation\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.16913\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eZ1\u003c/strong\u003e: \"Z1: Efficient Test-time Scaling with Code\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.00810\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eOpenCodeReasoning\u003c/strong\u003e: \"OpenCodeReasoning: Advancing Data Distillation for Competitive Coding\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.01943\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eOpenCodeInstruct\u003c/strong\u003e: \"OpenCodeInstruct: A Large-scale Instruction Tuning Dataset for Code LLMs\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.04030\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Data-efficient LLM Fine-tuning for Code Generation\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.12687\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AKD : Adversarial Knowledge Distillation For Large Language Models Alignment on Coding tasks\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.06267\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CRPE: Expanding The Reasoning Capability of Large Language Model for Code Generation\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.10594\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eVisCoder\u003c/strong\u003e: \"VisCoder: Fine-Tuning LLMs for Executable Python Visualization Code Generation\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2506.03930\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AceReason-Nemotron 1.1: Advancing Math and Code Reasoning through SFT and RL Synergy\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.13284\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMoLE\u003c/strong\u003e: \"Mix-of-Language-Experts Architecture for Multilingual Programming\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.18923\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eOpenCodeReasoning-II\u003c/strong\u003e: \"OpenCodeReasoning-II: A Simple Test Time Scaling Approach via Self-Critique\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.09075\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeEvo: Interaction-Driven Synthesis of Code-centric Data through Hybrid and Iterative Feedback\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.22080\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eTree-of-Evolution\u003c/strong\u003e: \"Tree-of-Evolution: Tree-Structured Instruction Evolution for Code Generation in Large Language Models\" [2025-07] [ACL 2025] [\u003ca href=\"https://aclanthology.org/2025.acl-long.14/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSCoder\u003c/strong\u003e: \"SCoder: Iterative Self-Distillation for Bootstrapping Small-Scale Data Synthesizers to Empower Code LLMs\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.07858\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Do Code Semantics Help? A Comprehensive Study on Execution Trace-Based Information for Code Large Language Models\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.11686\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SCoGen: Scenario-Centric Graph-Based Synthesis of Real-World Code Problems\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.14281\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Verification Limits Code LLM Training\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.20837\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e2.5 Reinforcement Learning on Code\u003c/h3\u003e\u003ca id=\"user-content-25-reinforcement-learning-on-code\" class=\"anchor\" aria-label=\"Permalink: 2.5 Reinforcement Learning on Code\" href=\"#25-reinforcement-learning-on-code\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCompCoder\u003c/strong\u003e: \"Compilable Neural Code Generation with Compiler Feedback\" [2022-03] [ACL 2022] [\u003ca href=\"https://arxiv.org/abs/2203.05132\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeRL\u003c/strong\u003e: \"CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning\" [2022-07] [NeurIPS 2022] [\u003ca href=\"https://arxiv.org/abs/2207.01780\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/salesforce/CodeRL\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePPOCoder\u003c/strong\u003e: \"Execution-based Code Generation using Deep Reinforcement Learning\" [2023-01] [TMLR 2023] [\u003ca href=\"https://arxiv.org/abs/2301.13816\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/reddy-lab-code-research/PPOCoder\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eRLTF\u003c/strong\u003e: \"RLTF: Reinforcement Learning from Unit Test Feedback\" [2023-07] [\u003ca href=\"https://arxiv.org/abs/2307.04349\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/Zyq-scut/RLTF\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eB-Coder\u003c/strong\u003e: \"B-Coder: Value-Based Deep Reinforcement Learning for Program Synthesis\" [2023-10] [ICLR 2024] [\u003ca href=\"https://arxiv.org/abs/2310.03173\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eIRCoCo\u003c/strong\u003e: \"IRCoCo: Immediate Rewards-Guided Deep Reinforcement Learning for Code Completion\" [2024-01] [FSE 2024] [\u003ca href=\"https://arxiv.org/abs/2401.16637\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eStepCoder\u003c/strong\u003e: \"StepCoder: Improve Code Generation with Reinforcement Learning from Compiler Feedback\" [2024-02] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2402.01391\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eRLPF \u0026amp; DPA\u003c/strong\u003e: \"Performance-Aligned LLMs for Generating Fast Code\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.18864\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Measuring memorization in RLHF for code completion\" [2024-06] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2406.11715\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Applying RLAIF for Code Generation with API-usage in Lightweight LLMs\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.20060\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eRLCoder\u003c/strong\u003e: \"RLCoder: Reinforcement Learning for Repository-Level Code Completion\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.19487\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePF-PPO\u003c/strong\u003e: \"Policy Filtration in RLHF to Fine-Tune LLM for Code Generation\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.06957\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCoffee-Gym\u003c/strong\u003e: \"Coffee-Gym: An Environment for Evaluating and Improving Natural Language Feedback on Erroneous Code\" [2024-09] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2409.19715\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eRLEF\u003c/strong\u003e: \"RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning\" [2024-10] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2410.02089\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodePMP\u003c/strong\u003e: \"CodePMP: Scalable Preference Model Pretraining for Large Language Model Reasoning\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.02229\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeDPO\u003c/strong\u003e: \"CodeDPO: Aligning Code Models with Self Generated and Verified Source Code\" [2024-10] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2410.05605\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Process Supervision-Guided Policy Optimization for Code Generation\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.17621\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Aligning CodeLLMs with Direct Preference Optimization\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.18585\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eFALCON\u003c/strong\u003e: \"FALCON: Feedback-driven Adaptive Long/short-term memory reinforced Coding Optimization system\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.21349\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePFPO\u003c/strong\u003e: \"Preference Optimization for Reasoning with Pseudo Feedback\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.16345\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eo1-Coder\u003c/strong\u003e: \"o1-Coder: an o1 Replication for Coding\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2412.00154\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePRLCoder\u003c/strong\u003e: \"Process-Supervised Reinforcement Learning for Code Generation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.01715\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAceCoder\u003c/strong\u003e: \"ACECODER: Acing Coder RL via Automated Test-Case Synthesis\" [2025-02] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2502.01718\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eFocused-DPO\u003c/strong\u003e: \"Focused-DPO: Enhancing Code Generation Through Focused Preference Optimization on Error-Prone Points\" [2025-02] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2502.11475\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSWE-RL\u003c/strong\u003e: \"SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.18449\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAceReason-Nemotron\u003c/strong\u003e: \"AceReason-Nemotron: Advancing Math and Code Reasoning through Reinforcement Learning\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.16400\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003erStar-Coder\u003c/strong\u003e: \"rStar-Coder: Scaling Competitive Code Reasoning with a Large-Scale Verified Dataset\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.21297\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCURE\u003c/strong\u003e: \"Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.03136\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMagistral\u003c/strong\u003e [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.10910\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eRing-lite\u003c/strong\u003e: \"Ring-lite: Scalable Reasoning via C3PO-Stabilized Reinforcement Learning for LLMs\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.14731\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eReST-RL\u003c/strong\u003e: \"ReST-RL: Achieving Accurate Code Reasoning of LLMs with Optimized Self-Training and Decoding\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.19576\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards Better Correctness and Efficiency in Code Generation\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.20124\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Building Coding Agents via Entropy-Enhanced Multi-Turn Preference Optimization\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.12434\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DELTA-Code: How Does RL Unlock and Transfer New Programming Algorithms in LLMs?\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.21016\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCritique-Coder\u003c/strong\u003e: \"Critique-Coder: Enhancing Coder Models by Critique Reinforcement Learning\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.22824\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeRL+\u003c/strong\u003e: \"CodeRL+: Improving Code Generation via Reinforcement with Execution Semantics Alignment\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.18471\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e3. When Coding Meets Reasoning\u003c/h2\u003e\u003ca id=\"user-content-3-when-coding-meets-reasoning\" class=\"anchor\" aria-label=\"Permalink: 3. When Coding Meets Reasoning\" href=\"#3-when-coding-meets-reasoning\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e3.1 Coding for Reasoning\u003c/h3\u003e\u003ca id=\"user-content-31-coding-for-reasoning\" class=\"anchor\" aria-label=\"Permalink: 3.1 Coding for Reasoning\" href=\"#31-coding-for-reasoning\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePAL\u003c/strong\u003e: \"PAL: Program-aided Language Models\" [2022-11] [ICML 2023] [\u003ca href=\"https://arxiv.org/abs/2211.10435\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/reasoning-machines/pal\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePoT\u003c/strong\u003e: \"Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks\" [2022-11] [TMLR 2023] [\u003ca href=\"https://arxiv.org/abs/2211.12588\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/wenhuchen/Program-of-Thoughts\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePaD\u003c/strong\u003e: \"PaD: Program-aided Distillation Can Teach Small Models Reasoning Better than Chain-of-thought Fine-tuning\" [2023-05] [NAACL 2024] [\u003ca href=\"https://arxiv.org/abs/2305.13888\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCSV\u003c/strong\u003e: \"Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification\" [2023-08] [ICLR 2024] [\u003ca href=\"https://arxiv.org/abs/2308.07921\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMathCoder\u003c/strong\u003e: \"MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning\" [2023-10] [ICLR 2024] [\u003ca href=\"https://arxiv.org/abs/2310.03731\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCoC\u003c/strong\u003e: \"Chain of Code: Reasoning with a Language Model-Augmented Code Emulator\" [2023-12] [ICML 2024] [\u003ca href=\"https://arxiv.org/abs/2312.04474\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eEHRAgent\u003c/strong\u003e: \"EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records\" [2024-01] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2401.07128\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMARIO\u003c/strong\u003e: \"MARIO: MAth Reasoning with code Interpreter Output -- A Reproducible Pipeline\" [2024-01] [ACL 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2401.08190\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs\" [2024-01] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2401.10065\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eReGAL\u003c/strong\u003e: \"ReGAL: Refactoring Programs to Discover Generalizable Abstractions\" [2024-01] [ICML 2024] [\u003ca href=\"https://arxiv.org/abs/2401.16467\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeAct\u003c/strong\u003e: \"Executable Code Actions Elicit Better LLM Agents\" [2024-02] [ICML 2024] [\u003ca href=\"https://arxiv.org/abs/2402.01030\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMultiPoT\u003c/strong\u003e: \"Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts\" [2024-02] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2402.10691\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eHProPro\u003c/strong\u003e: \"Exploring Hybrid Question Answering via Program-based Prompting\" [2024-02] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2402.10812\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eHTL\u003c/strong\u003e: \"How Do Humans Write Code? Large Models Do It the Same Way Too\" [2024-02] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2402.15729\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003exSTREET\u003c/strong\u003e: \"Eliciting Better Multilingual Structured Reasoning from LLMs through Code\" [2024-03] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2403.02567\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eFlowMind\u003c/strong\u003e: \"FlowMind: Automatic Workflow Generation with LLMs\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2404.13050\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eThink-and-Execute\u003c/strong\u003e: \"Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models\" [2024-04] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2404.02575\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCoRE\u003c/strong\u003e: \"CoRE: LLM as Interpreter for Natural Language Programming, Pseudo-Code Programming, and Flow Programming of AI Agents\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.06907\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMuMath-Code\u003c/strong\u003e: \"MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning\" [2024-05] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2405.07551\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCOGEX\u003c/strong\u003e: \"Learning to Reason via Program Generation, Emulation, and Search\" [2024-05] [NeurIPS 2024] [\u003ca href=\"https://arxiv.org/abs/2405.16337\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Arithmetic Reasoning with LLM: Prolog Generation \u0026amp; Permutation\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.17893\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can LLMs Reason in the Wild with Programs?\" [2024-06] [EMNLP 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2406.13764\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDotaMath\u003c/strong\u003e: \"DotaMath: Decomposition of Thought with Code Assistance and Self-correction for Mathematical Reasoning\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.04078\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCIBench\u003c/strong\u003e: \"CIBench: Evaluating Your LLMs with a Code Interpreter Plugin\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.10499\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePyBench\u003c/strong\u003e: \"PyBench: Evaluating LLM Agent on various real-world coding tasks\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.16732\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAdaCoder\u003c/strong\u003e: \"AdaCoder: Adaptive Prompt Compression for Programmatic Visual Question Answering\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.19410\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePyramidCoder\u003c/strong\u003e: \"Pyramid Coder: Hierarchical Code Generator for Compositional Visual Question Answering\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.20563\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeGraph\u003c/strong\u003e: \"CodeGraph: Enhancing Graph Reasoning of LLMs with Code\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.13863\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSIaM\u003c/strong\u003e: \"SIaM: Self-Improving Code-Assisted Mathematical Reasoning of Large Language Models\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.15565\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodePlan\u003c/strong\u003e: \"CodePlan: Unlocking Reasoning Potential in Large Langauge Models by Scaling Code-form Planning\" [2024-09] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2409.12452\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePoT\u003c/strong\u003e: \"Proof of Thought : Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.17270\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMetaMath\u003c/strong\u003e: \"MetaMath: Integrating Natural Language and Code for Enhanced Mathematical Reasoning in Large Language Models\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.19381\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"BabelBench: An Omni Benchmark for Code-Driven Analysis of Multimodal and Multistructured Data\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.00773\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeSteer\u003c/strong\u003e: \"Steering Large Language Models between Code Execution and Textual Reasoning\" [2024-10] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2410.03524\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMathCoder2\u003c/strong\u003e: \"MathCoder2: Better Math Reasoning from Continued Pretraining on Model-translated Mathematical Code\" [2024-10] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2410.08196\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLLMFP\u003c/strong\u003e: \"Planning Anything with Rigor: General-Purpose Zero-Shot Planning with LLM-based Formalized Programming\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.12112\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eProve\u003c/strong\u003e: \"Not All Votes Count! Programs as Verifiers Improve Self-Consistency of Language Models for Math Reasoning\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.12608\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePROVE\u003c/strong\u003e: \"Trust but Verify: Programmatic VLM Evaluation in the Wild\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.13121\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGeoCoder\u003c/strong\u003e: \"GeoCoder: Solving Geometry Problems by Generating Modular Code through Vision-Language Models\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.13510\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eReasonAgain\u003c/strong\u003e: \"ReasonAgain: Using Extractable Symbolic Programs to Evaluate Mathematical Reasoning\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.19056\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGFP\u003c/strong\u003e: \"Gap-Filling Prompting Enhances Code-Assisted Mathematical Reasoning\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.05407\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eUTMath\u003c/strong\u003e: \"UTMath: Math Evaluation with Unit Test via Reasoning-to-Coding Thoughts\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.07240\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCoCoP\u003c/strong\u003e: \"CoCoP: Enhancing Text Classification with LLM through Code Completion Prompt\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.08979\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eREPL-Plan\u003c/strong\u003e: \"Interactive and Expressive Code-Augmented Planning with Large Language Models\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.13826\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCrossPAL\u003c/strong\u003e: \"Empowering Multi-step Reasoning across Languages via Program-Aided Language Models\" [2024-11] [EMNLP 2024] [\u003ca href=\"https://aclanthology.org/2024.emnlp-main.678/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"From Code to Play: Benchmarking Program Search for Games Using Large Language Models\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.04057\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCoinMath\u003c/strong\u003e: \"CoinMath: Harnessing the Power of Coding Instruction for Math LLMs\" [2024-12] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2412.11699\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMultiLingPoT\u003c/strong\u003e: \"MultiLingPoT: Enhancing Mathematical Reasoning with Multilingual Program Fine-tuning\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.12609\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eProgCo\u003c/strong\u003e: \"ProgCo: Program Helps Self-Correction of Large Language Models\" [2025-01] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2501.01264\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePIE\u003c/strong\u003e: \"Pseudocode-Injection Magic: Enabling LLMs to Tackle Graph Computational Tasks\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.13731\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAutoCode4Math\u003c/strong\u003e: \"Learning Autonomous Code Integration for Math Language Models\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.00691\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMIHTCCT\u003c/strong\u003e: \"MIH-TCCT: Mitigating Inconsistent Hallucinations in LLMs via Event-Driven Text-Code Cyclic Training\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.08904\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eToolCoder\u003c/strong\u003e: \"ToolCoder: A Systematic Code-Empowered Tool Learning Framework for Large Language Models\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.11404\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eRM-PoT\u003c/strong\u003e: \"RM-PoT: Reformulating Mathematical Problems and Solving via Program of Thoughts\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.12589\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSBSC\u003c/strong\u003e: \"SBSC: Step-By-Step Coding for Improving Mathematical Olympiad Performance\" [2025-02] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2502.16666\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards Better Understanding of Program-of-Thought Reasoning in Cross-Lingual and Multilingual Environments\" [2025-02] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2502.17956\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code to Think, Think to Code: A Survey on Code-Enhanced Reasoning and Reasoning-Driven Code Intelligence in LLMs\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.19411\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The KoLMogorov Test: Compression by Code Generation\" [2025-03] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2503.13992\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMathCoder-VL\u003c/strong\u003e: \"MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning\" [2025-05] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2505.10557\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eR1-Code-Interpreter\u003c/strong\u003e: \"R1-Code-Interpreter: Training LLMs to Reason with Code via Supervised and Reinforcement Learning\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.21668\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards Effective Code-Integrated Reasoning\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.24480\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CoRT: Code-integrated Reasoning within Thinking\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.09820\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Execution as Grounded Supervision for LLM Reasoning\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.10343\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePBB\u003c/strong\u003e: \"Programming by Backprop: LLMs Acquire Reusable Algorithmic Abstractions During Code Training\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.18777\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"On Code-Induced Reasoning in LLMs\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.21499\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e3.2 Code Simulation\u003c/h3\u003e\u003ca id=\"user-content-32-code-simulation\" class=\"anchor\" aria-label=\"Permalink: 3.2 Code Simulation\" href=\"#32-code-simulation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Simulation Challenges for Large Language Models\" [2024-01] [\u003ca href=\"https://arxiv.org/abs/2401.09074\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeMind: A Framework to Challenge Large Language Models for Code Reasoning\" [2024-02] [\u003ca href=\"https://arxiv.org/abs/2402.09664\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Executing Natural Language-Described Algorithms with Large Language Models: An Investigation\" [2024-02] [\u003ca href=\"https://arxiv.org/abs/2403.00795\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can Language Models Pretend Solvers? Logic Code Simulation with LLMs\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.16097\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating Large Language Models with Runtime Behavior of Program Execution\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.16437\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"NExT: Teaching Large Language Models to Reason about Code Execution\" [2024-04] [ICML 2024] [\u003ca href=\"https://arxiv.org/abs/2404.14662\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SelfPiCo: Self-Guided Partial Code Execution with LLMs\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.16974\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models as Code Executors: An Exploratory Study\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.06667\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"VISUALCODER: Guiding Large Language Models in Code Execution with Fine-grained Multimodal Chain-of-Thought Reasoning\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.23402\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CoCoNUT: Structural Code Understanding does not fall out of a tree\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.16456\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction\" [2025-02] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2502.07316\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SURGE: On the Potential of Large Language Models as General-Purpose Surrogate Code Executors\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.11167\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"What I cannot execute, I do not understand: Training and Evaluating LLMs on Program Execution Traces\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2503.05703\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"L0-Reasoning Bench: Evaluating Procedural Correctness in Language Models via Simple Program Execution\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.22832\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"PLSemanticsBench: Large Language Models As Programming Language Interpreters\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.03415\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Metric Calculating Benchmark: Code-Verifiable Complicate Instruction Following Benchmark for Large Language Models\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.07892\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e3.3 Code Agents\u003c/h3\u003e\u003ca id=\"user-content-33-code-agents\" class=\"anchor\" aria-label=\"Permalink: 3.3 Code Agents\" href=\"#33-code-agents\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSelf-collaboration\u003c/strong\u003e: \"Self-collaboration Code Generation via ChatGPT\" [2023-04] [\u003ca href=\"https://arxiv.org/abs/2304.07590\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eChatDev\u003c/strong\u003e: \"Communicative Agents for Software Development\" [2023-07] [\u003ca href=\"https://arxiv.org/abs/2307.07924\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/OpenBMB/ChatDev\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMetaGPT\u003c/strong\u003e: \"MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework\" [2023-08] [\u003ca href=\"https://arxiv.org/abs/2308.00352\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/geekan/MetaGPT\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeChain\u003c/strong\u003e: \"CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules\" [2023-10] [ICLR 2024] [\u003ca href=\"https://arxiv.org/abs/2310.08992\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeAgent\u003c/strong\u003e: \"CodeAgent: Enhancing Code Generation with Tool-Integrated Agent Systems for Real-World Repo-level Coding Challenges\" [2024-01] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2401.07339\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCONLINE\u003c/strong\u003e: \"CoCoST: Automatic Complex Code Generation with Online Searching and Correctness Testing\" [2024-03] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2403.13583\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLCG\u003c/strong\u003e: \"When LLM-based Code Generation Meets the Software Development Process\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.15852\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eRepairAgent\u003c/strong\u003e: \"RepairAgent: An Autonomous, LLM-Based Agent for Program Repair\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.17134\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMAGIS:\u003c/strong\u003e: \"MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.17927\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSoA\u003c/strong\u003e: \"Self-Organized Agents: A LLM Multi-Agent Framework toward Ultra Large-Scale Code Generation and Optimization\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.02183\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAutoCodeRover\u003c/strong\u003e: \"AutoCodeRover: Autonomous Program Improvement\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.05427\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSWE-agent\u003c/strong\u003e: \"SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.15793\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMapCoder\u003c/strong\u003e: \"MapCoder: Multi-Agent Code Generation for Competitive Problem Solving\" [2024-05] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2405.11403\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Fight Fire with Fire: How Much Can We Trust ChatGPT on Source Code-Related Tasks?\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.12641\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eFunCoder\u003c/strong\u003e: \"Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in Code Generation\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.20092\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCTC\u003c/strong\u003e: \"Multi-Agent Software Development through Cross-Team Collaboration\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.08979\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMASAI\u003c/strong\u003e: \"MASAI: Modular Architecture for Software-engineering AI Agents\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.11638\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAgileCoder\u003c/strong\u003e: \"AgileCoder: Dynamic Collaborative Agents for Software Development based on Agile Methodology\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.11912\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeNav\u003c/strong\u003e: \"CodeNav: Beyond tool-use to using real-world codebases with LLM agents\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.12276\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eINDICT\u003c/strong\u003e: \"INDICT: Code Generation with Internal Dialogues of Critiques for Both Security and Helpfulness\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2407.02518\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAppWorld\u003c/strong\u003e: \"AppWorld: A Controllable World of Apps and People for Benchmarking Interactive Coding Agents\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.18901\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCortexCompile\u003c/strong\u003e: \"CortexCompile: Harnessing Cortical-Inspired Architectures for Enhanced Multi-Agent NLP Code Synthesis\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2409.02938\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDEI\u003c/strong\u003e: \"Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents\" [2024-08] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2408.07060\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSurvey\u003c/strong\u003e: \"Large Language Model-Based Agents for Software Engineering: A Survey\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.02977\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePairCoder\u003c/strong\u003e: \"A Pair Programming Framework for Code Generation via Multi-Plan Exploration and Feedback-Driven Refinement\" [2024-09] [ASE 2024] [\u003ca href=\"https://arxiv.org/abs/2409.05001\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/nju-websoft/PairCoder\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAutoSafeCoder\u003c/strong\u003e: \"AutoSafeCoder: A Multi-Agent Framework for Securing LLM Code Generation through Static Analysis and Fuzz Testing\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.10737\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSuperCoder2.0\u003c/strong\u003e: \"SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.11190\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSurvey\u003c/strong\u003e: \"Agents in Software Engineering: Survey, Landscape, and Vision\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.09030\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMOSS\u003c/strong\u003e: \"MOSS: Enabling Code-Driven Evolution and Context Management for AI Agents\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.16120\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eHyperAgent\u003c/strong\u003e: \"HyperAgent: Generalist Software Engineering Agents to Solve Coding Tasks at Scale\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.16299\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Compositional Hardness of Code in Large Language Models -- A Probabilistic Perspective\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.18028\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eRGD\u003c/strong\u003e: \"RGD: Multi-LLM Based Agent Debugger via Refinement and Generation Guidance\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.01242\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSeeker\u003c/strong\u003e: \"Seeker: Enhancing Exception Handling in Code with LLM-based Multi-Agent Approach\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.06949\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eREDO\u003c/strong\u003e: \"REDO: Execution-Free Runtime Error Detection for COding Agents\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.09117\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating Software Development Agents: Patch Patterns, Code Quality, and Issue Complexity in Real-World GitHub Scenarios\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.12468\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eEvoMAC\u003c/strong\u003e: \"Self-Evolving Multi-Agent Collaboration Networks for Software Development\" [2024-10] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2410.16946\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eVisionCoder\u003c/strong\u003e: \"VisionCoder: Empowering Multi-Agent Auto-Programming for Image Processing with Hybrid LLMs\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.19245\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAutoKaggle\u003c/strong\u003e: \"AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.20424\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eWatson\u003c/strong\u003e: \"Watson: A Cognitive Observability Framework for the Reasoning of Foundation Model-Powered Agents\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.03455\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeTree\u003c/strong\u003e: \"CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.04329\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eEvoCoder\u003c/strong\u003e: \"LLMs as Continuous Learners: Improving the Reproduction of Defective Code in Software Issues\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.13941\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAEGIS\u003c/strong\u003e: \"AEGIS: An Agent-based Framework for General Bug Reproduction from Issue Descriptions\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.18015\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eExecutionAgent\u003c/strong\u003e: \"You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.10133\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eGHIssueMarket\u003c/strong\u003e: \"GHIssuemarket: A Sandbox Environment for SWE-Agents Economic Experimentation\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.11722\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSWE-Gym\u003c/strong\u003e: \"Training Software Engineering Agents and Verifiers with SWE-Gym\" [2024-12] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2412.21139\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSWE-Fixer\u003c/strong\u003e: \"SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution\" [2025-01] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2501.05040\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeCoR\u003c/strong\u003e: \"CodeCoR: An LLM-Based Self-Reflective Multi-Agent Framework for Code Generation\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.07811\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eQualityFlow\u003c/strong\u003e: \"QualityFlow: An Agentic Workflow for Program Synthesis Controlled by LLM Quality Checks\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.17167\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCogito\u003c/strong\u003e: \"Cogito, ergo sum: A Neurobiologically-Inspired Cognition-Memory-Growth System for Code Generation\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.18653\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eOrcaLoca\u003c/strong\u003e: \"OrcaLoca: An LLM Agent Framework for Software Issue Localization\" [2025-02] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2502.00350\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eBRT Agent\u003c/strong\u003e: \"Agentic Bug Reproduction for Effective Automated Program Repair at Google\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.01821\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeSim\u003c/strong\u003e: \"CODESIM: Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debugging\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.05664\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSyncMind\u003c/strong\u003e: \"SyncMind: Measuring Agent Out-of-Sync Recovery in Collaborative Software Engineering\" [2025-02] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2502.06994\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSoRFT\u003c/strong\u003e: \"SoRFT: Issue Resolving with Subtask-oriented Reinforced Fine-Tuning\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.20127\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Is Multi-Agent Debate (MAD) the Silver Bullet? An Empirical Analysis of MAD in Code Summarization and Translation\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.12029\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDARS\u003c/strong\u003e: \"DARS: Dynamic Action Re-Sampling to Enhance Coding Agent Performance by Adaptive Tree Traversal\" [2025-03] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2503.14269\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSEAlign\u003c/strong\u003e: \"SEAlign: Alignment Training for Software Engineering Agent\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.18455\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSWE-SynInfer\u003c/strong\u003e: \"Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.23803\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAdaCoder\u003c/strong\u003e: \"AdaCoder: An Adaptive Planning and Multi-Agent Framework for Function-Level Code Generation\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.04220\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSICA\u003c/strong\u003e: \"A Self-Improving Coding Agent\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.15228\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSWE-smith\u003c/strong\u003e: \"SWE-smith: Scaling Data for Software Engineering Agents\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.21798\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing LLM Code Generation: A Systematic Evaluation of Multi-Agent Collaboration and Runtime Debugging for Improved Accuracy, Reliability, and Latency\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.02133\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSEW\u003c/strong\u003e: \"SEW: Self-Evolving Agentic Workflows for Automated Code Generation\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.18646\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eRepoMaster\u003c/strong\u003e: \"RepoMaster: Autonomous Exploration and Understanding of GitHub Repositories for Complex Task Solving\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.21577\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCode Researcher\u003c/strong\u003e: \"Code Researcher: Deep Research Agent for Large Systems Code and Commit History\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2506.11060\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and Improve\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.23946\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"EvoGit: Decentralized Code Evolution via Git-Based Multi-Agent Collaboration\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.02049\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSWE-Factory\u003c/strong\u003e: \"SWE-Factory: Your Automated Factory for Issue Resolution Training Data and Evaluation Benchmarks\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.10954\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAgent-RLVR\u003c/strong\u003e: \"Agent-RLVR: Training Software Engineering Agents via Guidance and Environment Rewards\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.11425\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eAlphaEvolve\u003c/strong\u003e: \"AlphaEvolve: A coding agent for scientific and algorithmic discovery\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.13131\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eUSEagent\u003c/strong\u003e: \"Unified Software Engineering agent as AI Software Engineer\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.14683\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSemAgent\u003c/strong\u003e: \"SemAgent: A Semantics Aware Program Repair Agent\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.16650\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eTrae Agent\u003c/strong\u003e: \"Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.23370\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Nemotron-CORTEXA: Enhancing LLM Agents for Software Engineering Tasks via Improved Localization and Solution Diversity\" [2025-07] [ICML 2025] [\u003ca href=\"https://icml.cc/virtual/2025/poster/44274\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDebateCoder\u003c/strong\u003e: \"DebateCoder: Towards Collective Intelligence of LLMs via Test Case Driven LLM Debate for Code Generation\" [2025-07] [ACL 2025] [\u003ca href=\"https://aclanthology.org/2025.acl-long.589/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"GitTaskBench: A Benchmark for Code Agents Solving Real-World Tasks Through Code Repository Leveraging\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.18993\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMapCoder-Lite\u003c/strong\u003e: \"MapCoder-Lite: Squeezing Multi-Agent Coding into a Single Small LLM\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.17489\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDevstral\u003c/strong\u003e: \"Devstral: Fine-tuning Language Models for Coding Agent Applications\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.25193\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLita\u003c/strong\u003e: \"Lita: Light Agent Uncovers the Agentic Coding Capabilities of LLMs\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.25873\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eKimi-Dev\u003c/strong\u003e: \"Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.23045\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eVeriGuard\u003c/strong\u003e: \"VeriGuard: Enhancing LLM Agent Safety via Verified Code Generation\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.05156\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eKAT-Coder\u003c/strong\u003e: \"KAT-Coder Technical Report\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.18779\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e3.4 Interactive Coding\u003c/h3\u003e\u003ca id=\"user-content-34-interactive-coding\" class=\"anchor\" aria-label=\"Permalink: 3.4 Interactive Coding\" href=\"#34-interactive-coding\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Interactive Program Synthesis\" [2017-03] [\u003ca href=\"https://arxiv.org/abs/1703.03539\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Question selection for interactive program synthesis\" [2020-06] [PLDI 2020] [\u003ca href=\"https://dl.acm.org/doi/10.1145/3385412.3386025\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Interactive Code Generation via Test-Driven User-Intent Formalization\" [2022-08] [\u003ca href=\"https://arxiv.org/abs/2208.05950\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Improving Code Generation by Training with Natural Language Feedback\" [2023-03] [TMLR] [\u003ca href=\"https://arxiv.org/abs/2303.16749\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Self-Refine: Iterative Refinement with Self-Feedback\" [2023-03] [NeurIPS 2023] [\u003ca href=\"https://arxiv.org/abs/2303.17651\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Teaching Large Language Models to Self-Debug\" [2023-04] [\u003ca href=\"https://arxiv.org/abs/2304.05128\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Self-Edit: Fault-Aware Code Editor for Code Generation\" [2023-05] [ACL 2023] [\u003ca href=\"https://arxiv.org/abs/2305.04087\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LeTI: Learning to Generate from Textual Interactions\" [2023-05] [\u003ca href=\"https://arxiv.org/abs/2305.10314\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Is Self-Repair a Silver Bullet for Code Generation?\" [2023-06] [ICLR 2024] [\u003ca href=\"https://arxiv.org/abs/2306.09896\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback\" [2023-06] [NeurIPS 2023] [\u003ca href=\"https://arxiv.org/abs/2306.14898\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"INTERVENOR: Prompting the Coding Ability of Large Language Models with the Interactive Chain of Repair\" [2023-11] [ACL 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2311.09868\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement\" [2024-02] [ACL 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2402.14658\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Iterative Refinement of Project-Level Code Context for Precise Code Generation with Compiler Feedback\" [2024-03] [ACL 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2403.16792\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CYCLE: Learning to Self-Refine the Code Generation\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.18746\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM-based Test-driven Interactive Code Generation: User Study and Empirical Evaluation\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.10100\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SOAP: Enhancing Efficiency of Generated Code via Self-Optimization\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.15189\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Repair with LLMs gives an Exploration-Exploitation Tradeoff\" [2024-05] [NeurIPS 2024] [\u003ca href=\"https://arxiv.org/abs/2405.17503\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ReflectionCoder: Learning from Reflection Sequence for Enhanced One-off Code Generation\" [2024-05] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2405.17057\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Training LLMs to Better Self-Debug and Explain Code\" [2024-05] [NeurIPS 2024] [\u003ca href=\"https://arxiv.org/abs/2405.18649\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Requirements are All You Need: From Requirements to Code with LLMs\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.10101\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"I Need Help! Evaluating LLM's Ability to Ask for Users' Support: A Case Study on Text-to-SQL Generation\" [2024-07] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2407.14767\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Empirical Study on Self-correcting Large Language Models for Data Science Code Generation\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.15658\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RethinkMCTS: Refining Erroneous Thoughts in Monte Carlo Tree Search for Code Generation\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.09584\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"From Code to Correctness: Closing the Last Mile of Code Generation with Hierarchical Debugging\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.01215\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/YerbaPage/MGDebugger\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"What Makes Large Language Models Reason in (Multi-Turn) Code Generation?\" [2024-10] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2410.08105\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The First Prompt Counts the Most! An Evaluation of Large Language Models on Iterative Example-based Code Generation\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.06774\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Planning-Driven Programming: A Large Language Model Programming Workflow\" [2024-11] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2411.14503\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ConAIR:Consistency-Augmented Iterative Interaction Framework to Enhance the Reliability of Code Generation\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.15587\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation\" [2024-11] [EMNLP 2024 Findings] [\u003ca href=\"https://aclanthology.org/2024.findings-emnlp.908/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"PerfCodeGen: Improving Performance of LLM Generated Code with Execution Feedback\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2412.03578\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"GenX: Mastering Code and Test Generation with Execution Feedback\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.13464\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Helping LLMs Improve Code Generation Using Feedback from Testing and Static Analysis\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.14841\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Outcome-Refining Process Supervision for Code Generation\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.15118\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Tree-of-Code: A Tree-Structured Exploring Framework for End-to-End Code Generation and Execution in Complex Task Handling\" [2024-12] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2412.15305\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Dynamic Scaling of Unit Tests for Code Reward Modeling\" [2025-01] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2501.01054\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Revisit Self-Debugging with Self-Generated Tests for Code Generation\" [2025-01] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2501.12793\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Learning to Generate Unit Tests for Automated Debugging\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.01619\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Model Guided Self-Debugging Code Generation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.02928\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"On Iterative Evaluation and Enhancement of Code Quality Using GPT-4o\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.07399\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Intention is All You Need: Refining Your Code from Your Intention\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.08172\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RefineCoder: Iterative Improving of Large Language Models via Adaptive Critique Refinement for Code Generation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.09183\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"VisPath: Automated Visualization Code Synthesis via Multi-Path Reasoning and Feedback-Driven Optimization\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.11140\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"S*: Test Time Scaling for Code Generation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.14382\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"When Benchmarks Talk: Re-Evaluating Code LLMs with Interactive Feedback\" [2025-02] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2502.18413\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM4EFFI: Leveraging Large Language Models to Enhance Code Efficiency and Correctness\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.18489\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Multi-Turn Code Generation Through Single-Step Rewards\" [2025-02] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2502.20380\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ConvCodeWorld: Benchmarking Conversational Code Generation in Reproducible Feedback Environments\" [2025-02] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2502.19852\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"IterPref: Focal Preference Learning for Code Generation via Iterative Debugging\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.02783\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"debug-gym: A Text-Based Environment for Interactive Debugging\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.21557\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeIF-Bench: Evaluating Instruction-Following Capabilities of Large Language Models in Interactive Code Generation\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.22688\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeFlowBench: A Multi-turn, Iterative Benchmark for Complex Code Generation\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.21751\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Use Property-Based Testing to Bridge LLM Code Generation and Validation\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.18315\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeAssistBench (CAB): Dataset \u0026amp; Benchmarking for Multi-turn Chat-Based Code Assistance\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.10646\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SR-Eval: Evaluating LLMs on Code Generation under Stepwise Requirement Refinement\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.18808\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Benchmarking Correctness and Security in Multi-Turn Code Generation\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.13859\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e3.5 Frontend Navigation\u003c/h3\u003e\u003ca id=\"user-content-35-frontend-navigation\" class=\"anchor\" aria-label=\"Permalink: 3.5 Frontend Navigation\" href=\"#35-frontend-navigation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding\" [2021-10] [ACL 2022] [\u003ca href=\"https://arxiv.org/abs/2110.08518\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WebKE: Knowledge Extraction from Semi-structured Web with Pre-trained Markup Language Model\" [2021-10] [CIKM 2021] [\u003ca href=\"https://dl.acm.org/doi/abs/10.1145/3459637.3482491\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WebGPT: Browser-assisted question-answering with human feedback\" [2021-12] [\u003ca href=\"https://arxiv.org/abs/2112.09332\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CM3: A Causal Masked Multimodal Model of the Internet\" [2022-01] [\u003ca href=\"https://arxiv.org/abs/2201.07520\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DOM-LM: Learning Generalizable Representations for HTML Documents\" [2022-01] [\u003ca href=\"https://arxiv.org/abs/2201.10608\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WebFormer: The Web-page Transformer for Structure Information Extraction\" [2022-02] [WWW 2022] [\u003ca href=\"https://arxiv.org/abs/2202.00217\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Dataset for Interactive Vision-Language Navigation with Unknown Command Feasibility\" [2022-02] [ECCV 2022] [\u003ca href=\"https://arxiv.org/abs/2202.02312\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents\" [2022-07] [NeurIPS 2022] [\u003ca href=\"https://arxiv.org/abs/2207.01206\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding\" [2022-10] [ICML 2023] [\u003ca href=\"https://arxiv.org/abs/2210.03347\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Understanding HTML with Large Language Models\" [2022-10] [EMNLP 2023 findings] [\u003ca href=\"https://arxiv.org/abs/2210.03945\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics\" [2023-01] [CHI 2023] [\u003ca href=\"https://arxiv.org/abs/2301.13280\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Mind2Web: Towards a Generalist Agent for the Web\" [2023-06] [NeurIPS 2023] [\u003ca href=\"https://arxiv.org/abs/2306.06070\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis\", [2023-07] [ICLR 2024] [\u003ca href=\"https://arxiv.org/abs/2307.12856\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WebArena: A Realistic Web Environment for Building Autonomous Agents\" [2023-07] [\u003ca href=\"https://arxiv.org/abs/2307.13854\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CogAgent: A Visual Language Model for GUI Agents\" [2023-12] [\u003ca href=\"https://arxiv.org/abs/2312.08914\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"GPT-4V(ision) is a Generalist Web Agent, if Grounded\" [2024-01] [\u003ca href=\"https://arxiv.org/abs/2401.01614\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models\" [2024-01] [\u003ca href=\"https://arxiv.org/abs/2401.13919\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WebLINX: Real-World Website Navigation with Multi-Turn Dialogue\" [2024-02] [\u003ca href=\"https://arxiv.org/abs/2402.05930\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web\" [2024-02] [\u003ca href=\"https://arxiv.org/abs/2402.17553\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.03648\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.05902\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AutoCrawler: A Progressive Understanding Web Agent for Web Crawler Generation\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.12753\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"GUICourse: From General Vision Language Models to Versatile GUI Agents\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.11317\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"NaviQAte: Functionality-Guided Web Application Navigation\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.10741\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.14818\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Multimodal Auto Validation For Self-Refinement in Web Agents\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.00689\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.05243\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.13232\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Harnessing Webpage UIs for Text-Rich Visual Understanding\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.13824\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.13825\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Beyond Browsing: API-Based Web Agents\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.16464\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models Empowered Personalized Web Agents\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.17236\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AdvWeb: Controllable Black-box Attacks on VLM-powered Web Agents\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.17401\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.22552\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"OS-ATLAS: A Foundation Action Model for Generalist GUI Agents\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.23218\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"From Context to Action: Analysis of the Impact of State Representation and Context on the Generalization of Multi-Turn Web Navigation Agents\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.23555\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AutoGLM: Autonomous Foundation Agents for GUIs\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2411.00820\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.02337\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Dawn of GUI Agent: A Preliminary Case Study with Claude 3.5 Computer Use\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.10323\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ScribeAgent: Towards Specialized Web Agents Using Production-Scale Workflow Data\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.15004\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ShowUI: One Vision-Language-Action Model for GUI Visual Agent\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.17465\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Model-Brained GUI Agents: A Survey\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.18279\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Free your mouse! Command Large Language Models to Generate Code to Format Word Documents\" [2024-11] [EMNLP 2024] [\u003ca href=\"https://aclanthology.org/2024.emnlp-main.902/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Aguvis: Unified Pure Vision Agents for Autonomous GUI Interaction\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.04454\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Falcon-UI: Understanding GUI Before Following User Instructions\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.09362\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WEPO: Web Element Preference Optimization for LLM-based Web Navigation\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.10742\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AutoDroid-V2: Boosting SLM-based GUI Agents via Code Generation\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.18116\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Beyond Pass or Fail: A Multi-dimensional Benchmark for Mobile UI Navigation\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.02863\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WebWalker: Benchmarking LLMs in Web Traversal\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.07572\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"GUI-Bee: Align GUI Action Grounding to Novel Environments via Autonomous Exploration\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.13896\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"UI-TARS: Pioneering Automated GUI Interaction with Native Agents\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.12326\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Smoothing Grounding and Reasoning for MLLM-Powered GUI Agents with Query-Oriented Pivot Tasks\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.00401\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web Tasks\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.01952\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"UI-Venus Technical Report: Building High-performance UI Agents with RFT\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.10833\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Mano Report\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.17336\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e4. Code LLM for Low-Resource, Low-Level, and Domain-Specific Languages\u003c/h2\u003e\u003ca id=\"user-content-4-code-llm-for-low-resource-low-level-and-domain-specific-languages\" class=\"anchor\" aria-label=\"Permalink: 4. Code LLM for Low-Resource, Low-Level, and Domain-Specific Languages\" href=\"#4-code-llm-for-low-resource-low-level-and-domain-specific-languages\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eRuby\u003c/strong\u003e] \"On the Transferability of Pre-trained Language Models for Low-Resource Programming Languages\" [2022-04] [ICPC 2022] [\u003ca href=\"https://arxiv.org/abs/2204.09653\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"Benchmarking Large Language Models for Automated Verilog RTL Code Generation\" [2022-12] [DATE 2023] [\u003ca href=\"https://arxiv.org/abs/2212.11140\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eOCL\u003c/strong\u003e] \"On Codex Prompt Engineering for OCL Generation: An Empirical Study\" [2023-03] [MSR 2023] [\u003ca href=\"https://arxiv.org/abs/2303.16244\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eAnsible-YAML\u003c/strong\u003e] \"Automated Code generation for Information Technology Tasks in YAML through Large Language Models\" [2023-05] [DAC 2023] [\u003ca href=\"https://arxiv.org/abs/2305.02783\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eHansl\u003c/strong\u003e] \"The potential of LLMs for coding with low-resource and domain-specific programming languages\" [2023-07] [\u003ca href=\"https://arxiv.org/abs/2307.13018\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"VeriGen: A Large Language Model for Verilog Code Generation\" [2023-07] [\u003ca href=\"https://arxiv.org/abs/2308.00708\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"RTLLM: An Open-Source Benchmark for Design RTL Generation with Large Language Model\" [2023-08] [\u003ca href=\"https://arxiv.org/abs/2308.05345\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eRacket, OCaml, Lua, R, Julia\u003c/strong\u003e] \"Knowledge Transfer from High-Resource to Low-Resource Programming Languages for Code LLMs\" [2023-08] [\u003ca href=\"https://arxiv.org/abs/2308.09895\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"VerilogEval: Evaluating Large Language Models for Verilog Code Generation\" [2023-09] [ICCAD 2023] [\u003ca href=\"https://arxiv.org/abs/2309.07544\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"RTLFixer: Automatically Fixing RTL Syntax Errors with Large Language Models\" [2023-11] [\u003ca href=\"https://arxiv.org/abs/2311.16543\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"Advanced Large Language Model (LLM)-Driven Verilog Development: Enhancing Power, Performance, and Area Optimization in Code Synthesis\" [2023-12] [\u003ca href=\"https://arxiv.org/abs/2312.01022\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"RTLCoder: Outperforming GPT-3.5 in Design RTL Generation with Our Open-Source Dataset and Lightweight Solution\" [2023-12] [\u003ca href=\"https://arxiv.org/abs/2312.08617\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"BetterV: Controlled Verilog Generation with Discriminative Guidance\" [2024-02] [ICML 2024] [\u003ca href=\"https://arxiv.org/abs/2402.03375\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eR\u003c/strong\u003e] \"Empirical Studies of Parameter Efficient Methods for Large Language Models of Code and Knowledge Transfer to R\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2405.01553\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eHaskell\u003c/strong\u003e] \"Investigating the Performance of Language Models for Completing Code in Functional Programming Languages: a Haskell Case Study\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.15185\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"A Multi-Expert Large Language Model Architecture for Verilog Code Generation\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.08029\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"CreativEval: Evaluating Creativity of LLM-Based Hardware Code Generation\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.08806\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eAlloy\u003c/strong\u003e] \"An Empirical Evaluation of Pre-trained Large Language Models for Repairing Declarative Formal Specifications\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.11050\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"Evaluating LLMs for Hardware Design and Test\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2405.02326\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eKotlin, Swift, and Rust\u003c/strong\u003e] \"Software Vulnerability Prediction in Low-Resource Languages: An Empirical Study of CodeBERT and ChatGPT\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.17110\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"MEIC: Re-thinking RTL Debug Automation using LLMs\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.06840\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eBash\u003c/strong\u003e] \"Tackling Execution-Based Evaluation for NL2Bash\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.06807\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eFortran, Julia, Matlab, R, Rust\u003c/strong\u003e] \"Evaluating AI-generated code for C++, Fortran, Go, Java, Julia, Matlab, Python, R, and Rust\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.13101\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eOpenAPI\u003c/strong\u003e] \"Optimizing Large Language Models for OpenAPI Code Completion\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.15729\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eKotlin\u003c/strong\u003e] \"Kotlin ML Pack: Technical Report\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.19250\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eUCLID5\u003c/strong\u003e] \"Synthetic Programming Elicitation for Text-to-Code in Very Low-Resource Programming and Formal Languages\" [2024-06] [NeurIPS 2024] [\u003ca href=\"https://arxiv.org/abs/2406.03636\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"VerilogReader: LLM-Aided Hardware Test Generation\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.04373\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Benchmarking Generative Models on Computational Thinking Tests in Elementary Visual Programming\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.09891\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eLogo\u003c/strong\u003e] \"Program Synthesis Benchmark for Visual Programming in XLogoOnline Environment\" [2024-06] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2406.11334\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eAnsible YAML, Bash\u003c/strong\u003e] \"DocCGen: Document-based Controlled Code Generation\" [2024-06] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2406.11925\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eQiskit\u003c/strong\u003e] \"Qiskit HumanEval: An Evaluation Benchmark For Quantum Code Generative Models\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.14712\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003ePerl, Golang, Swift\u003c/strong\u003e] \"DistiLRR: Transferring Code Repair for Low-Resource Programming Languages\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.14867\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"AssertionBench: A Benchmark to Evaluate Large-Language Models for Assertion Generation\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.18627\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Comparative Study of DSL Code Generation: Fine-Tuning vs. Optimized Retrieval Augmentation\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.02742\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eJson, XLM, YAML\u003c/strong\u003e] \"ConCodeEval: Evaluating Large Language Models for Code Constraints in Domain-Specific Languages\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.03387\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"AutoBench: Automatic Testbench Generation and Evaluation Using LLMs for HDL Design\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.03891\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"CodeV: Empowering LLMs for Verilog Generation through Multi-Level Summarization\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.10424\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"ITERTL: An Iterative Framework for Fine-tuning LLMs for RTL Code Generation\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.12022\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"OriGen:Enhancing RTL Code Generation with Code-to-Code Augmentation and Self-Reflection\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.16237\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"Large Language Model for Verilog Generation with Golden Code Feedback\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.18271\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"AutoVCoder: A Systematic Framework for Automated Verilog Code Generation using LLMs\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.18333\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eRPA\u003c/strong\u003e] \"Plan with Code: Comparing approaches for robust NL to DSL generation\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.08335\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"VerilogCoder: Autonomous Verilog Coding Agents with Graph-based Planning and Abstract Syntax Tree (AST)-based Waveform Tracing Tool\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.08927\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"Revisiting VerilogEval: Newer LLMs, In-Context Learning, and Specification-to-RTL Tasks\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.11053\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eMaxMSP, Web Audio\u003c/strong\u003e] \"Benchmarking LLM Code Generation for Audio Programming with Visual Dataflow Languages\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.00856\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"RTLRewriter: Methodologies for Large Models aided RTL Code Optimization\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.11414\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"CraftRTL: High-quality Synthetic Data Generation for Verilog Code Models with Correct-by-Construction Non-Textual Representations and Targeted Code Repair\" [2024-09] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2409.12993\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eBash\u003c/strong\u003e] \"ScriptSmith: A Unified LLM Framework for Enhancing IT Operations via Automated Bash Script Generation, Assessment, and Refinement\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.17166\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eSurvey\u003c/strong\u003e] \"Survey on Code Generation for Low resource and Domain Specific Programming Languages\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.03981\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eR\u003c/strong\u003e] \"Do Current Language Models Support Code Intelligence for R Programming Language?\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.07793\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003ePLC\u003c/strong\u003e] \"Agents4PLC: Automating Closed-loop PLC Code Generation and Verification in Industrial Control Systems using LLM-based Agents\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.14209\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eLua\u003c/strong\u003e] \"Evaluating Quantized Large Language Models for Code Generation on Low-Resource Language Benchmarks\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.14766\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Improving Parallel Program Performance Through DSL-Driven Code Generation with LLM Optimizers\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.15625\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eR, D, Racket, Bash\u003c/strong\u003e]: \"Bridge-Coder: Unlocking LLMs' Potential to Overcome Language Gaps in Low-Resource Code\" [2024-10] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2410.18957\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eSPICE\u003c/strong\u003e]: \"SPICEPilot: Navigating SPICE Code Generation and Simulation with AI Guidance\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.20553\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eIEC 61131-3 ST\u003c/strong\u003e]: \"Training LLMs for Generating IEC 61131-3 Structured Text with Online Feedback\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.22159\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"MetRex: A Benchmark for Verilog Code Metric Reasoning Using LLMs\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.03471\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"CorrectBench: Automatic Testbench Generation with Functional Self-Correction using LLMs for HDL Design\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.08510\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eMUMPS, ALC\u003c/strong\u003e] \"Leveraging LLMs for Legacy Code Modernization: Challenges and Opportunities for LLM-Generated Documentation\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.14971\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003ePower Query M, OfficeScript, Excel formulas\u003c/strong\u003e] \"RAR: Retrieval-augmented retrieval for code generation in low resource languages\" [2024-11] [EMNLP 2024] [\u003ca href=\"https://aclanthology.org/2024.emnlp-main.1199/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eST\u003c/strong\u003e] \"A Multi-Agent Framework for Extensible Structured Text Generation in PLCs\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.02410\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"PromptV: Leveraging LLM-powered Multi-Agent Prompting for High-quality Verilog Generation\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.11014\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eHPC\u003c/strong\u003e] \"HPC-Coder-V2: Studying Code LLMs Across Low-Resource Parallel Languages\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.15178\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"RTLSquad: Multi-Agent Based Interpretable RTL Design\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.05470\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eG\u003c/strong\u003e] \"GLLM: Self-Corrective G-Code Generation using Large Language Models with User Feedback\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.17584\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eJulia, Lua, R, Racket\u003c/strong\u003e] \"Enhancing Code Generation for Low-Resource Languages: No Silver Bullet\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.19085\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eF\u003c/strong\u003e*] \"Building A Proof-Oriented Programmer That Is 64% Better Than GPT-4o Under Data Scarsity\" [2025-02] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2502.11901\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Exploring Code Language Models for Automated HLS-based Hardware Generation: Benchmark, Infrastructure and Analysis\" [2025-02] [ASP-DAC 2025] [\u003ca href=\"https://arxiv.org/abs/2502.13921\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eAlloy\u003c/strong\u003e*] \"On the Effectiveness of Large Language Models in Writing Alloy Formulas\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.15441\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eSolidity\u003c/strong\u003e] \"SolEval: Benchmarking Large Language Models for Repository-level Solidity Code Generation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.18793\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003ePennyLane\u003c/strong\u003e] \"PennyLang: Pioneering LLM-Based Quantum Code Generation with a Novel PennyLane-Centric Dataset\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.02497\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"VeriMind: Agentic LLM for Automated Verilog Generation with a Novel Evaluation Metric\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.16514\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eModelica\u003c/strong\u003e] \"ModiGen: A Large Language Model-Based Workflow for Multi-Task Modelica Code Generation\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.18460\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eExcel\u003c/strong\u003e] \"Synthetic Function Demonstrations Improve Generation in Low-Resource Programming Languages\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.18760\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RTLRepoCoder: Repository-Level RTL Code Completion through the Combination of Fine-Tuning and Retrieval Augmentation\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.08862\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"SymRTLO: Enhancing RTL Code Optimization with LLMs and Neuron-Inspired Symbolic Reasoning\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.10369\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"ReasoningV: Efficient Verilog Code Generation with Adaptive Hybrid Reasoning Model\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.14560\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"VeriCoder: Enhancing LLM-Based RTL Code Generation through Functional Correctness Validation\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.15659\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eChisel\u003c/strong\u003e] \"ChiseLLM: Unleashing the Power of Reasoning LLMs for Chisel Agile Hardware Development\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.19144\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"ComplexVCoder: An LLM-Driven Framework for Systematic Generation of Complex Verilog Code\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.20653\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eLean\u003c/strong\u003e] \"CLEVER: A Curated Benchmark for Formally Verified Code Generation\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.13938\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"VeriThoughts: Enabling Automated Verilog Code Generation using Reasoning and Formal Verification\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.20302\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"hdl2v: A Code Translation Dataset for Enhanced LLM Verilog Generation\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.04544\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"ScaleRTL: Scaling LLMs with Reasoning Data and Test-Time Compute for Accurate RTL Code Generation\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.05566\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eLaTeX\u003c/strong\u003e] \"TeXpert: A Multi-Level Benchmark for Evaluating LaTeX Code Generation by LLMs\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.16990\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"EvoVerilog: Large Langugage Model Assisted Evolution of Verilog Code\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2508.13156\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eTriton\u003c/strong\u003e] \"AutoTriton: Automatic Triton Programming with Reinforcement Learning in LLMs\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.05687\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eCUDA\u003c/strong\u003e] \"Kevin: Multi-Turn RL for Generating CUDA Kernels\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.11948\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eSIMD intrinsics\u003c/strong\u003e] \"SimdBench: Benchmarking Large Language Models for SIMD-Intrinsic Code Generation\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.15224\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eTriton\u003c/strong\u003e] \"Geak: Introducing Triton Kernel AI Agent \u0026amp; Evaluation Benchmarks\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.23194\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"VERIRL: Boosting the LLM-based Verilog Code Generation via Reinforcement Learning\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.18462\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MultiPL-MoE: Multi-Programming-Lingual Extension of Large Language Models through Hybrid Mixture-of-Experts\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.19268\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eCUDA\u003c/strong\u003e] \"Astra: A Multi-Agent System for GPU Kernel Performance Optimization\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.07506\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eLaTeX\u003c/strong\u003e] \"Table2LaTeX-RL: High-Fidelity LaTeX Code Generation from Table Images via Reinforced Multimodal Language Models\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.17589\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeChemist: Functional Knowledge Transfer for Low-Resource Code Generation via Test-Time Scaling\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.00501\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eCUDA\u003c/strong\u003e] \"EvoEngineer: Mastering Automated CUDA Kernel Code Evolution with Large Language Models\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.03760\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eVerilog\u003c/strong\u003e] \"Pluto: A Benchmark for Evaluating Efficiency of LLM-generated Hardware Code\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.14756\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eCUDA\u003c/strong\u003e] \"Integrating Performance Tools in Model Reasoning for GPU Kernel Optimization\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.17158\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e[\u003cstrong\u003eTriton\u003c/strong\u003e] \"TritonRL: Training LLMs to Think and Code Triton Without Cheating\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.17891\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e5. Methods/Models for Downstream Tasks\u003c/h2\u003e\u003ca id=\"user-content-5-methodsmodels-for-downstream-tasks\" class=\"anchor\" aria-label=\"Permalink: 5. Methods/Models for Downstream Tasks\" href=\"#5-methodsmodels-for-downstream-tasks\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eFor each task, the first column contains non-neural methods (e.g. n-gram, TF-IDF, and (occasionally) static program analysis); the second column contains non-Transformer neural methods (e.g. LSTM, CNN, GNN); the third column contains Transformer based methods (e.g. BERT, GPT, T5).\u003c/p\u003e\n\u003cp align=\"center\" dir=\"auto\"\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"/codefuse-ai/Awesome-Code-LLM/blob/main/imgs/downstream-1.png\"\u003e\u003cimg src=\"/codefuse-ai/Awesome-Code-LLM/raw/main/imgs/downstream-1.png\" style=\"width: 100%; max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"/codefuse-ai/Awesome-Code-LLM/blob/main/imgs/downstream-2.png\"\u003e\u003cimg src=\"/codefuse-ai/Awesome-Code-LLM/raw/main/imgs/downstream-2.png\" style=\"width: 100%; max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"/codefuse-ai/Awesome-Code-LLM/blob/main/imgs/downstream-3.png\"\u003e\u003cimg src=\"/codefuse-ai/Awesome-Code-LLM/raw/main/imgs/downstream-3.png\" style=\"width: 100%; max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"/codefuse-ai/Awesome-Code-LLM/blob/main/imgs/downstream-4.png\"\u003e\u003cimg src=\"/codefuse-ai/Awesome-Code-LLM/raw/main/imgs/downstream-4.png\" style=\"width: 100%; max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"/codefuse-ai/Awesome-Code-LLM/blob/main/imgs/downstream-5.png\"\u003e\u003cimg src=\"/codefuse-ai/Awesome-Code-LLM/raw/main/imgs/downstream-5.png\" style=\"width: 100%; max-width: 100%;\"\u003e\u003c/a\u003e\n\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCode Generation\u003c/h3\u003e\u003ca id=\"user-content-code-generation\" class=\"anchor\" aria-label=\"Permalink: Code Generation\" href=\"#code-generation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Large Language Models in Coding Through Multi-Perspective Self-Consistency\" [2023-09] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2309.17272\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Self-Infilling Code Generation\" [2023-11] [ICML 2024] [\u003ca href=\"https://arxiv.org/abs/2311.17972\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"JumpCoder: Go Beyond Autoregressive Coder via Online Modification\" [2024-01] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2401.07870\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Larger the Better? Improved LLM Code-Generation via Budget Reallocation\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2404.00725\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Comments as Natural Logic Pivots: Improve Code Generation via Comment Perspective\" [2024-04] [ACL 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2404.07549\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Distilling Algorithmic Reasoning from LLMs via Explaining Solution Programs\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.08148\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Quality Assessment of Prompts Used in Code Generation\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.10155\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Model Cascading for Code: Reducing Inference Costs with Model Cascading for LLM Based Code Generation\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.15842\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Survey on Large Language Models for Code Generation\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.00515\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Is Programming by Example solved by LLMs?\" [2024-06] [NeurIPS 2024] [\u003ca href=\"https://arxiv.org/abs/2406.08316\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Benchmarks and Metrics for Evaluations of Code Generation: A Critical Review\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.12655\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MPCODER: Multi-user Personalized Code Generator with Explicit and Implicit Style Representation Learning\" [2024-06] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2406.17255\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Revisiting the Impact of Pursuing Modularity for Code Generation\" [2024-07] [EMNLP 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2407.11406\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating Long Range Dependency Handling in Code Generation Models using Multi-Step Key Retrieval\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.21049\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"When to Stop? Towards Efficient Code Generation in LLMs with Excess Token Prevention\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.20042\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Assessing Programming Task Difficulty for Efficient Evaluation of Large Language Models\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.21227\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ArchCode: Incorporating Software Requirements in Code Generation with Large Language Models\" [2024-08] [ACL 2024] [\u003ca href=\"https://www.arxiv.org/abs/2408.00994\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Fine-tuning Language Models for Joint Rewriting and Completion of Code with Potential Bugs\" [2024-08] [ACL 2024 Findings] [\u003ca href=\"https://aclanthology.org/2024.findings-acl.938/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Selective Prompt Anchoring for Code Generation\" [2024-08] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2408.09121\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Bridging the Language Gap: Enhancing Multilingual Prompt-Based Code Generation in LLMs via Zero-Shot Cross-Lingual Transfer\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.09701\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"No Man is an Island: Towards Fully Automatic Programming by Code Search, Code Generation and Program Repair\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.03267\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Planning In Natural Language Improves LLM Search For Code Generation\" [2024-09] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2409.03733\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Multi-Programming Language Ensemble for Code Generation in Large Language Model\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.04114\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"USCD: Improving Code Generation of LLMs by Uncertainty-Aware Selective Contrastive Decoding\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.05923\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Eliciting Instruction-tuned Code Language Models' Capabilities to Utilize Auxiliary Function for Code Generation\" [2024-09] [EMNLP 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2409.13928\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Selection of Prompt Engineering Techniques for Code Generation through Predicting Code Complexity\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.16416\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Horizon-Length Prediction: Advancing Fill-in-the-Middle Capabilities for Code Generation with Lookahead Planning\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.03103\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Showing LLM-Generated Code Selectively Based on Confidence of LLMs\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.03234\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AutoFeedback: An LLM-based Framework for Efficient and Accurate API Request Generation\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.06943\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing LLM Agents for Code Generation with Possibility and Pass-rate Prioritized Experience Replay\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.12236\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"From Solitary Directives to Interactive Encouragement! LLM Secure Code Generation by Natural Language Prompting\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.14321\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Self-Explained Keywords Empower Large Language Models for Code Generation\" [2024-10] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2410.15966\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Context-Augmented Code Generation Using Programming Knowledge Graphs\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.18251\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"In-Context Code-Text Learning for Bimodal Software Engineering\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.18107\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Combining LLM Code Generation with Formal Specifications and Reactive Program Synthesis\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.19736\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Less is More: DocString Compression in Code Generation\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.22793\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Multi-Programming Language Sandbox for LLMs\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.23074\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Personality-Guided Code Generation Using Large Language Models\" [2024-10] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2411.00006\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Scattered Forest Search: Smarter Code Space Exploration with LLMs\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.05010\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Anchor Attention, Small Cache: Code Generation with Large Language Models\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.06680\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ROCODE: Integrating Backtracking Mechanism and Program Analysis in Large Language Models for Code Generation\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.07112\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SRA-MCTS: Self-driven Reasoning Aurmentation with Monte Carlo Tree Search for Enhanced Code Generation\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.11053\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Language-to-Code Translation with a Single Labeled Example\" [2024-11] [EMNLP 2024] [\u003ca href=\"https://aclanthology.org/2024.emnlp-main.462/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"VeCoGen: Automating Generation of Formally Verified C Code with Large Language Models\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.19275\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Seed-CTS: Unleashing the Power of Tree Search for Superior Performance in Competitive Coding Tasks\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.12544\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LoGFiLM: Fine-Tuning A Large Language Model for Automated Generation of Log Statements\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.18835\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Impact of Prompt Programming on Function-Level Code Generation\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.20545\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Leveraging Metamemory Mechanisms for Enhanced Data-Free Code Generation in LLMs\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.07892\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"GREEN-CODE: Optimizing Energy Efficiency in Large Language Models for Code Generation\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.11006\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Chain of Grounded Objectives: Bridging Process and Goal-oriented Prompting for Code Generation\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.13978\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CoCoEvo: Co-Evolution of Programs and Test Cases to Enhance Code Generation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.10802\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Boost, Disentangle, and Customize: A Robust System2-to-System1 Pipeline for Code Generation\" [2025-02] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2502.12492\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Learning to Solve and Verify: A Self-Play Framework for Code and Test Generation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.14948\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Thinking Before Running! Efficient Code Generation with Thorough Exploration and Optimal Refinement\" [2025-02] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2502.17442\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Grammar-Based Code Representation: Is It a Worthy Pursuit for LLMs?\" [2025-03] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2503.05507\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing High-Quality Code Generation in Large Language Models with Comparative Prefix-Tuning\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.09020\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Modularization is Better: Effective Code Generation with Modular Prompting\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.12483\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Semantic-based Optimization Approach for Repairing LLMs: Case Study on Code Generation\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.12899\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Uncertainty-Guided Chain-of-Thought for Code Generation with LLMs\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.15341\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.23145\" rel=\"nofollow\"\u003eppaer\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Prism: Dynamic and Flexible Benchmarking of LLMs Code Generation with Monte Carlo Tree Search\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.05500\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Chart-to-Code Generation in Multimodal Large Language Models via Iterative Dual Preference Learning\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.02906\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"From Token to Line: Enhancing Code Generation with a Long-Term Perspective\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.07433\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Multilingual Multimodal Software Developer for Code Generation\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.08719\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Revisiting Chain-of-Thought in Code Generation: Do Language Models Need to Learn Reasoning before Coding?\" [2025-07] [ICML 2025] [\u003ca href=\"https://icml.cc/virtual/2025/poster/43621\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Beyond Sequences: Two-dimensional Representation and Dependency Encoding for Code Generation\" [2025-07] [ACL 2025] [\u003ca href=\"https://aclanthology.org/2025.acl-long.308/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodePRM: Execution Feedback-enhanced Process Reward Model for Code Generation\" [2025-07] [ACL 2025 Findings] [\u003ca href=\"https://aclanthology.org/2025.findings-acl.428/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.05988\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Let's Revise Step-by-Step: A Unified Local Search Framework for Code Generation with LLMs\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.07434\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Alignment with Fill-In-the-Middle for Enhancing Code Generation\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.19532\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"TigerCoder: A Novel Suite of LLMs for Code Generation in Bangla\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.09101\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SemGuard: Real-Time Semantic Evaluator for Correcting LLM-Generated Code\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.24507\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LongCodeZip: Compress Long Context for Code Language Models\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.00446\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Scaling Test-Time Compute to Achieve IOI Gold Medal with Open-Weight Models\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.14232\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCode RAG\u003c/h3\u003e\u003ca id=\"user-content-code-rag\" class=\"anchor\" aria-label=\"Permalink: Code RAG\" href=\"#code-rag\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeGRAG: Extracting Composed Syntax Graphs for Retrieval Augmented Cross-Lingual Code Generation\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.02355\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Prompt-based Code Completion via Multi-Retrieval Augmented Generation\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.07530\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Lightweight Framework for Adaptive Retrieval In Code Completion With Critique Model\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.10263\" rel=\"nofollow\"\u003epapaer\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Preference-Guided Refactored Tuning for Retrieval Augmented Code Generation\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.15895\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Building A Coding Assistant via the Retrieval-Augmented Language Model\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.16229\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DroidCoder: Enhanced Android Code Completion with Context-Enriched Retrieval-Augmented Generation\" [2024-10] [ASE 2024] [\u003ca href=\"https://dl.acm.org/doi/10.1145/3691620.3695063\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Assessing the Answerability of Queries in Retrieval-Augmented Code Generation\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.05547\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"EvoR: Evolving Retrieval for Code Generation\" [2024-11] [EMNLP 2024 Findings] [\u003ca href=\"https://aclanthology.org/2024.findings-emnlp.143/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"PERC: Plan-As-Query Example Retrieval for Underrepresented Code Generation\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.12447\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Empirical Study of Retrieval-Augmented Code Generation: Challenges and Opportunities\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.13742\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CODEPROMPTZIP: Code-specific Prompt Compression for Retrieval-Augmented Generation in Coding Tasks with LMs\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.14925\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeSwift: Accelerating LLM Inference for Efficient Code Generation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.17139\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SOSecure: Safer Code Generation with RAG and StackOverflow Discussions\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.13654\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"When LLMs Meet API Documentation: Can Retrieval Augmentation Aid Code Generation Just as It Helps Developers?\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.15231\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"What to Retrieve for Effective Retrieval-Augmented Code Generation? An Empirical Study and Beyond\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.20589\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Across Programming Language Silos: A Study on Cross-Lingual Retrieval-augmented Code Generation\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.03535\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.15655\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SACL: Understanding and Combating Textual Bias in Code Retrieval with Semantic-Augmented Reranking and Localization\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.20081\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Deep Dive into Retrieval-Augmented Generation for Code Completion: Experience on WeChat\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.18515\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Impact-driven Context Filtering For Cross-file Code Completion\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.05970\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Retrieval-Augmented Code Generation: A Survey with Focus on Repository-Level Approaches\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.04905\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCode Ranking\u003c/h3\u003e\u003ca id=\"user-content-code-ranking\" class=\"anchor\" aria-label=\"Permalink: Code Ranking\" href=\"#code-ranking\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Fault-Aware Neural Code Rankers\" [2022-06] [NeurIPS 2022] [\u003ca href=\"https://arxiv.org/abs/2206.03865\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Coder Reviewer Reranking for Code Generation\" [2022-11] [ICML 2023] [\u003ca href=\"https://arxiv.org/abs/2211.16490\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LEVER: Learning to Verify Language-to-Code Generation with Execution\" [2023-02] [ICML 2023] [\u003ca href=\"https://arxiv.org/abs/2302.08468\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Functional Overlap Reranking for Neural Code Generation\" [2023-10] [ACL 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2311.03366\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Top Pass: Improve Code Generation by Pass@k-Maximized Code Ranking\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.05715\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DOCE: Finding the Sweet Spot for Execution-Based Code Generation\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.13745\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Sifting through the Chaff: On Utilizing Execution Feedback for Ranking the Generated Code Candidates\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.13976\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"B4: Towards Optimal Assessment of Plausible Code Solutions with Plausible Tests\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.08692\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Learning Code Preference via Synthetic Evolution\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.03837\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Condor: A Code Discriminator Integrating General Semantics with Code Details\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.17429\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Scoring Verifiers: Evaluating Synthetic Verification in Code and Reasoning\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.13820\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Pragmatic Reasoning improves LLM Code Generation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.15835\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SweRank: Software Issue Localization with Code Ranking\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.07849\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Reward Models Enable Scalable Code Verification by Trading Accuracy for Throughput\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.10056\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCode Translation\u003c/h3\u003e\u003ca id=\"user-content-code-translation\" class=\"anchor\" aria-label=\"Permalink: Code Translation\" href=\"#code-translation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Tree-to-tree Neural Networks for Program Translation\" [2018-02] [NeurIPS 2018] [\u003ca href=\"https://arxiv.org/abs/1802.03691\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Program Language Translation Using a Grammar-Driven Tree-to-Tree Model\" [2018-07] [\u003ca href=\"https://arxiv.org/abs/1807.01784\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Unsupervised Translation of Programming Languages\" [2020-06] [NeurIPS 2020] [\u003ca href=\"https://arxiv.org/abs/2006.03511\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Leveraging Automated Unit Tests for Unsupervised Code Translation\" [2021-10] [ICLR 2022] \u003ca href=\"https://arxiv.org/abs/2110.06773\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Translation with Compiler Representations\" [2022-06] [ICLR 2023] [\u003ca href=\"https://arxiv.org/abs/2207.03578\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Multilingual Code Snippets Training for Program Translation\" [2022-06] [AAAI 2022] [\u003ca href=\"https://ojs.aaai.org/index.php/AAAI/article/view/21434\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"BabelTower: Learning to Auto-parallelized Program Translation\" [2022-07] [ICML 2022] [\u003ca href=\"https://proceedings.mlr.press/v162/wen22b.html\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Syntax and Domain Aware Model for Unsupervised Program Translation\" [2023-02] [ICSE 2023] [\u003ca href=\"https://arxiv.org/abs/2302.03908\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CoTran: An LLM-based Code Translator using Reinforcement Learning with Feedback from Compiler and Symbolic Execution\" [2023-06] [\u003ca href=\"https://arxiv.org/abs/2306.06755\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Lost in Translation: A Study of Bugs Introduced by Large Language Models while Translating Code\" [2023-08] [ICSE 2024] [\u003ca href=\"https://arxiv.org/abs/2308.03109\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"On the Evaluation of Neural Code Translation: Taxonomy and Benchmark\", 2023-08, ASE 2023, [\u003ca href=\"https://arxiv.org/abs/2308.08961\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Program Translation via Code Distillation\" [2023-10] [EMNLP 2023] [\u003ca href=\"https://arxiv.org/abs/2310.11476\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Explain-then-Translate: An Analysis on Improving Program Translation with Self-generated Explanations\" [2023-11] [EMNLP 2023 Findings] [\u003ca href=\"https://arxiv.org/abs/2311.07070\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Exploring the Impact of the Output Format on the Evaluation of Large Language Models for Code Translation\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.17214\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Exploring and Unleashing the Power of Large Language Models in Automated Code Translation\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.14646\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"VERT: Verified Equivalent Rust Transpilation with Few-Shot Learning\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.18852\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards Translating Real-World Code with LLMs: A Study of Translating to Rust\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.11514\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An interpretable error correction method for enhancing code-to-code translation\" [2024-05] [ICLR 2024] [\u003ca href=\"https://openreview.net/forum?id=fVxIEHGnVT\u0026amp;noteId=CyxZE2UbHF\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LASSI: An LLM-based Automated Self-Correcting Pipeline for Translating Parallel Scientific Codes\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2407.01638\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Rectifier: Code Translation with Corrector via LLMs\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.07472\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Code Translation in Language Models with Few-Shot Learning via Retrieval-Augmented Generation\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.19619\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Joint Learning Model with Variational Interaction for Multilingual Program Translation\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.14515\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automatic Library Migration Using Large Language Models: First Results\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.16151\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Context-aware Code Segmentation for C-to-Rust Translation using Large Language Models\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.10506\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2409.19894\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Unraveling the Potential of Large Language Models in Code Translation: How Far Are We?\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.09812\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeRosetta: Pushing the Boundaries of Unsupervised Code Translation for Parallel Programming\" [2024-10] [NeurIPS 2024] [\u003ca href=\"https://arxiv.org/abs/2410.20527\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A test-free semantic mistakes localization framework in Neural Code Translation\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.22818\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Repository-Level Compositional Code Translation and Validation\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.24117\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Leveraging Large Language Models for Code Translation and Software Development in Scientific Computing\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.24119\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"InterTrans: Leveraging Transitive Intermediate Translations to Enhance LLM-based Code Translation\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.01063\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Translating C To Rust: Lessons from a User Study\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.14174\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Specification-Driven Code Translation Powered by Large Language Models: How Far Are We?\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.04590\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Cross-Language Code Translation via Task-Specific Embedding Alignment in Retrieval-Augmented Generation\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.05159\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Scalable, Validated Code Translation of Entire Projects using Large Language Models\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.08035\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Syzygy: Dual Code-Test C to (safe) Rust Translation using LLMs and Dynamic Analysis\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.14234\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"I Can't Share Code, but I need Translation -- An Empirical Study on Code Translation through Federated LLM\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.05724\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Guided Debugging of Auto-Translated Code Using Differential Testing\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.09475\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"C2SaferRust: Transforming C Projects into Safer Rust with NeuroSymbolic Techniques\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.14257\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ExeCoder: Empowering Large Language Models with Executability Representation for Code Translation\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.18460\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM-Driven Multi-step Translation from C to Rust using Static Analysis\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.12511\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing LLM-based Code Translation in Repository Context via Triple Knowledge-Augmented\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.18305\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing LLMs in Long Code Translation through Instrumentation and Program State Alignment\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.02017\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Systematic Literature Review on Neural Code Translation\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.07425\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Model-Powered Agent for C to Rust Code Translation\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.15858\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"On-Policy Optimization with Group Equivalent Preference for Multi-Programming Language Understanding\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.12723\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Function-to-Style Guidance of LLMs for Code Translation\" [2025-07] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2507.11083\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"EffiReasonTrans: RL-Optimized Reasoning for Code Translation\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.18863\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCode Commenting and Summarization\u003c/h3\u003e\u003ca id=\"user-content-code-commenting-and-summarization\" class=\"anchor\" aria-label=\"Permalink: Code Commenting and Summarization\" href=\"#code-commenting-and-summarization\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Transformer-based Approach for Source Code Summarization\" [2020-05] [ACL 2020] [\u003ca href=\"https://arxiv.org/abs/2005.00653\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Summarization with Structure-induced Transformer\" [2020-12] [ACL 2021 Findings] [\u003ca href=\"https://arxiv.org/abs/2012.14710\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Structure Guided Transformer for Source Code Summarization\" [2021-04] [ACM TSEM] [\u003ca href=\"https://arxiv.org/abs/2104.09340\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"M2TS: Multi-Scale Multi-Modal Approach Based on Transformer for Source Code Summarization\" [2022-03] [ICPC 2022] [\u003ca href=\"https://arxiv.org/abs/2203.09707\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AST-trans: code summarization with efficient tree-structured attention\" [2022-05] [ICSE 2022] [\u003ca href=\"https://dl.acm.org/doi/abs/10.1145/3510003.3510224\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CoSS: Leveraging Statement Semantics for Code Summarization\" [2023-03] [IEEE TSE] [\u003ca href=\"https://ieeexplore.ieee.org/document/10068264\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automatic Code Summarization via ChatGPT: How Far Are We?\" [2023-05] [\u003ca href=\"https://arxiv.org/abs/2305.12865\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Semantic Similarity Loss for Neural Source Code Summarization\" [2023-08] [\u003ca href=\"https://arxiv.org/abs/2308.07429\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Distilled GPT for Source Code Summarization\" [2023-08] [ASE] [\u003ca href=\"https://arxiv.org/abs/2308.14731\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CSA-Trans: Code Structure Aware Transformer for AST\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.05767\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Analyzing the Performance of Large Language Models on Code Summarization\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.08018\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Trust in LLM-Generated Code Summaries with Calibrated Confidence Scores\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.19318\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DocuMint: Docstring Generation for Python using Small Language Models\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.10243\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/Docu-Mint/DocuMint\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Natural Is The Best: Model-Agnostic Code Simplification for Pre-trained Large Language Models\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.11196\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Exploring the Efficacy of Large Language Models (GPT-4) in Binary Reverse Engineering\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.06637\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Identifying Inaccurate Descriptions in LLM-generated Code Comments via Test Execution\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.14836\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MALSIGHT: Exploring Malicious Source Code and Benign Pseudocode for Iterative Binary Malware Summarization\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.18379\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Source Code Summarization in the Era of Large Language Models\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.07959\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Natural Language Outlines for Code: Literate Programming in the LLM Era\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.04820\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Context-aware Code Summary Generation\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.09006\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AUTOGENICS: Automated Generation of Context-Aware Inline Comments for Code Snippets on Programming Q\u0026amp;A Sites Using LLM\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.15411\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLMs as Evaluators: A Novel Approach to Evaluate Bug Report Summarization\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.00630\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Generating Equivalent Representations of Code By A Self-Reflection Approach\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.03351\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A review of automatic source code summarization\" [2024-10] [Empirical Software Engineering] [\u003ca href=\"https://link.springer.com/article/10.1007/s10664-024-10553-6\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can Large Language Models Serve as Evaluators for Code Summarization?\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.01333\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Selective Shot Learning for Code Explanation\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.12852\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot In-Context Learning for SQL2Text\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.03166\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Hierarchical Repository-Level Code Summarization for Business Applications Using Local LLMs\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.07857\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"From Critique to Clarity: A Pathway to Faithful and Personalized Code Explanations with Large Language Models\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.14731\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"METAMON: Finding Inconsistencies between Program Documentation and Behavior using Metamorphic LLM Queries\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.02794\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Should Code Models Learn Pedagogically? A Preliminary Evaluation of Curriculum Learning for Real-World Software Engineering Tasks\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.03806\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Optimizing Datasets for Code Summarization: Is Code-Comment Coherence Enough?\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.07611\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Summarization Beyond Function Level\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.16704\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ReadMe.LLM: A Framework to Help LLMs Understand Your Library\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.09798\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DocAgent: A Multi-Agent System for Automated Code Documentation Generation\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.08725\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"HGAdapter: Hypergraph-based Adapters in Language Models for Code Summarization and Clone Detection\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.17591\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eProgram Repair\u003c/h3\u003e\u003ca id=\"user-content-program-repair\" class=\"anchor\" aria-label=\"Permalink: Program Repair\" href=\"#program-repair\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CURE: Code-Aware Neural Machine Translation for Automatic Program Repair\" [2021-02] [ICSE 2021] [\u003ca href=\"https://arxiv.org/abs/2103.00073\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DeepDebug: Fixing Python Bugs Using Stack Traces, Backtranslation, and Code Skeletons\" [2021-05] [\u003ca href=\"https://arxiv.org/abs/2105.09352\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Break-It-Fix-It: Unsupervised Learning for Program Repair\" [2021-06] [ICML 2021] [\u003ca href=\"https://arxiv.org/abs/2106.06600\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"TFix: Learning to Fix Coding Errors with a Text-to-Text Transformer\" [2021-07] [ICML 2021] [\u003ca href=\"https://proceedings.mlr.press/v139/berabi21a.html\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automated Repair of Programs from Large Language Models\" [2022-05] [ICSE 2023] [\u003ca href=\"https://arxiv.org/abs/2205.10583\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Less Training, More Repairing Please: Revisiting Automated Program Repair via Zero-shot Learning\" [2022-07] [ESEC/FSE 2022] [\u003ca href=\"https://arxiv.org/abs/2207.08281\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Repair Is Nearly Generation: Multilingual Program Repair with LLMs\" [2022-08] [AAAI 2023] [\u003ca href=\"https://arxiv.org/abs/2208.11640\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Practical Program Repair in the Era of Large Pre-trained Language Models\" [2022-10] [\u003ca href=\"https://arxiv.org/abs/2210.14179\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"VulRepair: a T5-based automated software vulnerability repair\" [2022-11] [ESEC/FSE 2022] [\u003ca href=\"https://dl.acm.org/doi/abs/10.1145/3540250.3549098\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Conversational Automated Program Repair\" [2023-01] [\u003ca href=\"https://arxiv.org/abs/2301.13246\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Impact of Code Language Models on Automated Program Repair\" [2023-02] [ICSE 2023] [\u003ca href=\"https://arxiv.org/abs/2302.05020\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"InferFix: End-to-End Program Repair with LLMs\" [2023-03] [ESEC/FSE 2023] [\u003ca href=\"https://arxiv.org/abs/2303.07263\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Automated Program Repair through Fine-tuning and Prompt Engineering\" [2023-04] [\u003ca href=\"https://arxiv.org/abs/2304.07840\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A study on Prompt Design, Advantages and Limitations of ChatGPT for Deep Learning Program Repair\" [2023-04] [\u003ca href=\"https://arxiv.org/abs/2304.08191\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Domain Knowledge Matters: Improving Prompts with Fix Templates for Repairing Python Type Errors\" [2023-06] [ICSE 2024] [\u003ca href=\"https://arxiv.org/abs/2306.01394\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RepairLLaMA: Efficient Representations and Fine-Tuned Adapters for Program Repair\" [2023-12] [\u003ca href=\"https://arxiv.org/abs/2312.15698\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Fact Selection Problem in LLM-Based Program Repair\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.05520\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Aligning LLMs for FL-free Program Repair\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.08877\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Deep Dive into Large Language Models for Automated Bug Localization and Repair\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.11595\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Multi-Objective Fine-Tuning for Enhanced Program Repair with LLMs\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.12636\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How Far Can We Go with Practical Function-Level Program Repair?\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.12833\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Revisiting Unnaturalness for Automated Program Repair in the Era of Large Language Models\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.15236\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Unified Debugging Approach via LLM-Based Multi-Agent Synergy\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.17153\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Systematic Literature Review on Large Language Models for Automated Program Repair\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.01466\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"NAVRepair: Node-type Aware C/C++ Code Vulnerability Repair\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.04994\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automated Program Repair: Emerging trends pose and expose problems for benchmarks\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.05455\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automated Repair of AI Code with Large Language Models and Formal Verification\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.08848\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Case Study of LLM for Automated Vulnerability Repair: Assessing Impact of Reasoning and Patch Validation Feedback\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.15690\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CREF: An LLM-based Conversational Software Repair Framework for Programming Tutors\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.13972\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards Practical and Useful Automated Program Repair for Debugging\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.08958\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ThinkRepair: Self-Directed Automated Program Repair\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.20898\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MergeRepair: An Exploratory Study on Merging Task-Specific Adapters in Code LLMs for Automated Program Repair\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.09568\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RePair: Automated Program Repair with Process-based Feedback\" [2024-08] [ACL 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2408.11296\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing LLM-Based Automated Program Repair with Design Rationales\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.12056\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automated Software Vulnerability Patching using Large Language Models\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.13597\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Source Code Security with LLMs: Demystifying The Challenges and Generating Reliable Repairs\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.00571\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MarsCode Agent: AI-native Automated Bug Fixing\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.00899\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Co-Learning: Code Learning for Multi-Agent Reinforcement Collaborative Framework with Conversational Natural Language Interfaces\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.00985\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Debugging with Open-Source Large Language Models: An Evaluation\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.03031\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"VulnLLMEval: A Framework for Evaluating Large Language Models in Software Vulnerability Detection and Patching\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.10756\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can GPT-O1 Kill All Bugs? An Evaluation of GPT-Family LLMs on QuixBugs\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.10033\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Exploring and Lifting the Robustness of LLM-powered Automated Program Repair with Metamorphic Testing\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.07516\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LecPrompt: A Prompt-based Approach for Logical Error Correction with CodeBERT\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.08241\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Semantic-guided Search for Efficient Program Repair with Large Language Models\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.16655\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Comprehensive Survey of AI-Driven Advancements and Techniques in Automated Program Repair and Code Generation\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.07586\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"From Defects to Demands: A Unified, Iterative, and Heuristically Guided LLM-Based Framework for Automated Software Repair and Requirement Realization\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.05098\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Integrating Various Software Artifacts for Better LLM-based Bug Localization and Program Repair\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.03905\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM4CVE: Enabling Iterative Automated Vulnerability Repair with Large Language Models\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.03446\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating Agent-based Program Repair at Google\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.07531\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"HAFix: History-Augmented Large Language Models for Bug Fixing\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.09135\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MultiMend: Multilingual Program Repair with Context Augmentation and Multi-Hunk Patch Generation\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.16044\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"PATCH: Empowering Large Language Model with Programmer-Intent Guidance and Collaborative-Behavior Simulation for Automatic Bug Fixing\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.16149\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Counterexample Guided Program Repair Using Zero-Shot Learning and MaxSAT-based Fault Localization\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.07786\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Knowledge-Enhanced Program Repair for Data Science Code\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.09771\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AuPair: Golden Example Pairs for Code Repair\" [2025-02] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2502.18487\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Less is More: Adaptive Program Repair with Bug Localization and Preference Learning\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.06510\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"UTFix: Change Aware Unit Test Repairing using LLM\" [2025-03][OOPSLA 2025] [\u003ca href=\"https://dl.acm.org/doi/10.1145/3720419\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Unlocking LLM Repair Capabilities in Low-Resource Programming Languages Through Cross-Language Translation and Multi-Agent Refinement\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.22512\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"FeedbackEval: A Benchmark for Evaluating Large Language Models in Feedback-Driven Code Repair Tasks\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2504.06939\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"NL-Debugging: Exploiting Natural Language as an Intermediate Representation for Code Debugging\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.15356\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Art of Repair: Optimizing Iterative Program Repair with Instruction-Tuned Models\" [2025-05] [EASE, June 2025] [\u003ca href=\"https://arxiv.org/abs/2505.02931\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Adversarial Reasoning for Repair Based on Inferred Program Intent\" [2025-05] [ISSTA 2025] [\u003ca href=\"https://arxiv.org/abs/2505.13008\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Empirical Evaluation of Generalizable Automated Program Repair with Large Language Models\" [2025-06] [ICSE 2025] [\u003ca href=\"https://arxiv.org/abs/2506.03283\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Boosting Open-Source LLMs for Program Repair via Reasoning Transfer and LLM-Guided Reinforcement Learning\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.03921\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"EXPEREPAIR: Dual-Memory Enhanced LLM-based Repository-Level Program Repair\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.10484\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SynFix: Dependency-Aware Program Repair via RelationGraph Analysis\" [2025-07] [ACL 2025 Findings] [\u003ca href=\"https://aclanthology.org/2025.findings-acl.252/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Agentic Program Repair from Test Failures at Scale: A Neuro-symbolic approach with static analysis and test execution feedback\" [2025-07] [TSE, July 2025] [\u003ca href=\"https://arxiv.org/abs/2507.18755\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Impact of Fine-tuning Large Language Models on Automated Program Repair\" [2025-07] [ICSME 2025] [\u003ca href=\"https://arxiv.org/abs/2507.19909\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How Small is Enough? Empirical Evidence of Quantized Small Language Models for Automated Program Repair\" [2025-08] [ESEM 2025] [\u003ca href=\"https://arxiv.org/abs/2508.16499\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"InspectCoder: Dynamic Analysis-Enabled Self Repair through interactive LLM-Debugger Collaboration\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.18327\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCode Similarity and Embedding (Clone Detection, Code Search)\u003c/h3\u003e\u003ca id=\"user-content-code-similarity-and-embedding-clone-detection-code-search\" class=\"anchor\" aria-label=\"Permalink: Code Similarity and Embedding (Clone Detection, Code Search)\" href=\"#code-similarity-and-embedding-clone-detection-code-search\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Self-Supervised Contrastive Learning for Code Retrieval and Summarization via Semantic-Preserving Transformations\" [2020-09] [SIGIR 2021] [\u003ca href=\"https://arxiv.org/abs/2009.02731\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"REINFOREST: Reinforcing Semantic Code Similarity for Cross-Lingual Code Search Models\" [2023-05] [\u003ca href=\"https://arxiv.org/abs/2305.03843\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search\" [2024-01] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2401.04514\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Revisiting Code Similarity Evaluation with Abstract Syntax Tree Edit Distance\" [2024-04] [ACL 2024 short] [\u003ca href=\"https://arxiv.org/abs/2404.08817\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Is Next Token Prediction Sufficient for GPT? Exploration on Code Logic Comprehension\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.08885\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Refining Joint Text and Source Code Embeddings for Retrieval Task with Parameter-Efficient Fine-Tuning\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.04126\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Typhon: Automatic Recommendation of Relevant Code Cells in Jupyter Notebooks\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.09075\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Toward Exploring the Code Understanding Capabilities of Pre-trained Code Generation Models\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.12326\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Aligning Programming Language and Natural Language: Exploring Design Choices in Multi-Modal Transformer-Based Embedding for Bug Localization\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.17615\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Assessing the Code Clone Detection Capability of Large Language Models\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.02402\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeCSE: A Simple Multilingual Model for Code and Comment Sentence Embeddings\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.06360\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models for cross-language code clone detection\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.04430\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Coding-PTMs: How to Find Optimal Code Pre-trained Models for Code Embedding in Vulnerability Detection?\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.04863\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"You Augment Me: Exploring ChatGPT-based Data Augmentation for Semantic Code Search\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.05542\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Improving Source Code Similarity Detection Through GraphCodeBERT and Integration of Additional Features\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.08903\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM Agents Improve Semantic Code Search\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.11058\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"zsLLMCode: An Effective Approach for Functional Code Embedding via LLM with Zero-Shot Learning\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.14644\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Exploring Demonstration Retrievers in RAG for Coding Tasks: Yeas and Nays!\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.09662\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Instructive Code Retriever: Learn from Large Language Model's Feedback for Code Intelligence Tasks\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.11300\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Binary Code Similarity Detection via Graph Contrastive Learning on Intermediate Representations\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.18561\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Are Decoder-Only Large Language Models the Silver Bullet for Code Search?\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.22240\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeXEmbed: A Generalist Embedding Model Family for Multiligual and Multi-task Code Retrieval\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.12644\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeSAM: Source Code Representation Learning by Infusing Self-Attention with Multi-Code-View Graphs\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.14611\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"EnStack: An Ensemble Stacking Framework of Large Language Models for Enhanced Vulnerability Detection in Source Code\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.16561\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Isotropy Matters: Soft-ZCA Whitening of Embeddings for Semantic Code Search\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.17538\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Optimizing Code Retrieval: High-Quality and Scalable Dataset Annotation through Large Language Models\" [2024-11] [EMNLP 2024] [\u003ca href=\"https://aclanthology.org/2024.emnlp-main.123/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Learning-Based Binary Code Similarity Detection Model through Adversarial Training with Multiple Function Variants\" [2024-11] [EMNLP 2024 Findings] [\u003ca href=\"https://aclanthology.org/2024.findings-emnlp.673/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CoRNStack: High-Quality Contrastive Data for Better Code Retrieval and Reranking\" [2024-12] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2412.01007\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"OASIS: Order-Augmented Strategy for Improved Code Search\" [2025-03] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2503.08161\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Zero-Shot Cross-Domain Code Search without Fine-Tuning\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.07740\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LEANCODE: Understanding Models Better for Code Simplification of Pre-trained Large Language Models\" [2025-05] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2505.14759\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CoRet: Improved Retriever for Code Editing\" [2025-05] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2505.24715\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Efficient Code Embeddings from Code Generation Models\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.21290\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCode Refactoring and Migration\u003c/h3\u003e\u003ca id=\"user-content-code-refactoring-and-migration\" class=\"anchor\" aria-label=\"Permalink: Code Refactoring and Migration\" href=\"#code-refactoring-and-migration\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Empirical Study on the Code Refactoring Capability of Large Language Models\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.02320\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automated Update of Android Deprecated API Usages with Large Language Models\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.04387\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Empirical Study on the Potential of LLMs in Automated Software Refactoring\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.04444\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CODECLEANER: Elevating Standards with A Robust Data Contamination Mitigation Toolkit\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.10842\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Instruct or Interact? Exploring and Eliciting LLMs' Capability in Code Snippet Adaptation Through Prompt Engineering\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.15501\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Generating refactored code accurately using reinforcement learning\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.18035\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How is Google using AI for internal code migrations?\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.06972\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automated Refactoring of Non-Idiomatic Python Code: A Differentiated Replication with LLMs\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.17024\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Autonomous Legacy Web Application Upgrades Using a Multi-Agent System\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.19204\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating the Effectiveness of LLMs in Fixing Maintainability Issues in Real-World Projects\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.02368\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Distributed Approach to Haskell Based Applications Refactoring with LLMs Based Multi-Agent Systems\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.07928\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RefactorBench: Evaluating Stateful Reasoning in Language Agents Through Code\" [2025-03] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2503.07832\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MANTRA: Enhancing Automated Method-Level Refactoring with Contextual RAG and Multi-Agent LLM Collaboration\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.14340\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ECO: An LLM-Driven Efficient Code Optimizer for Warehouse Scale Computers\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.15669\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Migrating Code At Scale With LLMs At Google\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.09691\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Using LLMs for Library Migration\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.13272\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Leveraging LLMs to Automate Energy-Aware Refactoring of Parallel Scientific Codes\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.02184\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MIGRATION-BENCH: Repository-Level Code Migration Benchmark from Java 8\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.09569\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CODEMENV: Benchmarking Large Language Models on Code Migration\" [2025-05] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2506.00894\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eType Prediction\u003c/h3\u003e\u003ca id=\"user-content-type-prediction\" class=\"anchor\" aria-label=\"Permalink: Type Prediction\" href=\"#type-prediction\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Learning type annotation: is big data enough?\" [2021-08] [ESEC/FSE 2021] [\u003ca href=\"https://dl.acm.org/doi/10.1145/3468264.3473135\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Do Machine Learning Models Produce TypeScript Types That Type Check?\" [2023-02] [ECOOP 2023] [\u003ca href=\"https://arxiv.org/abs/2302.12163\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"TypeT5: Seq2seq Type Inference using Static Analysis\" [2023-03] [ICLR 2023] [\u003ca href=\"https://arxiv.org/abs/2303.09564\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Type Prediction With Program Decomposition and Fill-in-the-Type Training\" [2023-05] [\u003ca href=\"https://arxiv.org/abs/2305.17145\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Generative Type Inference for Python\" [2023-07] [ASE 2023] [\u003ca href=\"https://arxiv.org/abs/2307.09163\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Activation Steering for Robust Type Prediction in CodeLLMs\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.01903\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Empirical Study of Large Language Models for Type and Call Graph Analysis\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.00603\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eRepository-Level Coding\u003c/h3\u003e\u003ca id=\"user-content-repository-level-coding\" class=\"anchor\" aria-label=\"Permalink: Repository-Level Coding\" href=\"#repository-level-coding\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Repository-Level Prompt Generation for Large Language Models of Code\" [2022-06] [ICML 2023] [\u003ca href=\"https://arxiv.org/abs/2206.12839\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CoCoMIC: Code Completion By Jointly Modeling In-file and Cross-file Context\" [2022-12] [\u003ca href=\"https://arxiv.org/abs/2212.10007\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation\" [2023-03] [EMNLP 2023] [\u003ca href=\"https://arxiv.org/abs/2303.12570\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Coeditor: Leveraging Repo-level Diffs for Code Auto-editing\" [2023-05] [ICLR 2024 Spotlight] [\u003ca href=\"https://arxiv.org/abs/2305.18584\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems\" [2023-06] [ICLR 2024] [\u003ca href=\"https://arxiv.org/abs/2306.03091\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Guiding Language Models of Code with Global Context using Monitors\" [2023-06] [\u003ca href=\"https://arxiv.org/abs/2306.10763\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RepoFusion: Training Code Models to Understand Your Repository\" [2023-06] [\u003ca href=\"https://arxiv.org/abs/2306.10998\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodePlan: Repository-level Coding using LLMs and Planning\" [2023-09] [\u003ca href=\"https://arxiv.org/abs/2306.10998\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code Completion\" [2023-10] [NeurIPS 2023] [\u003ca href=\"https://arxiv.org/abs/2310.11248\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A^3-CodGen: A Repository-Level Code Generation Framework for Code Reuse with Local-Aware, Global-Aware, and Third-Party-Library-Aware\" [2023-12] [\u003ca href=\"https://arxiv.org/abs/2312.05772\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Teaching Code LLMs to Use Autocompletion Tools in Repository-Level Code Generation\" [2024-01] [\u003ca href=\"https://arxiv.org/abs/2401.06391\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RepoHyper: Better Context Retrieval Is All You Need for Repository-Level Code Completion\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.06095\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Repoformer: Selective Retrieval for Repository-Level Code Completion\" [2024-03] [ICML 2024] [\u003ca href=\"https://arxiv.org/abs/2403.10059\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeS: Natural Language to Code Repository via Multi-Layer Sketch\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.16443\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Class-Level Code Generation from Natural Language Using Iterative, Tool-Enhanced Reasoning over Repository\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2405.01573\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Contextual API Completion for Unseen Repositories Using LLMs\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.04600\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Dataflow-Guided Retrieval Augmentation for Repository-Level Code Completion\" [2024-05][ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2405.19782\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How to Understand Whole Software Repository?\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.01422\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"R2C2-Coder: Enhancing and Benchmarking Real-world Repository-level Code Completion Abilities of Code Large Language Models\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.01359\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Repository-Level Code Generation with Integrated Contextual Information\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.03283\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"On The Importance of Reasoning for Context Retrieval in Repository-Level Code Editing\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.04464\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"GraphCoder: Enhancing Repository-Level Code Completion via Code Context Graph-based Retrieval and Language Model\" [2024-06] [ASE 2024] [\u003ca href=\"https://arxiv.org/abs/2406.07003\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"STALL+: Boosting LLM-based Repository-level Code Completion with Static Analysis\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.10018\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Hierarchical Context Pruning: Optimizing Real-World Code Completion with Repository-Level Pretrained Code LLMs\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.18294\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RLCoder: Reinforcement Learning for Repository-Level Code Completion\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.19487\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CoEdPilot: Recommending Code Edits with Learned Prior Edit Relevance, Project-wise Awareness, and Interactive Nature\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.01733\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/code-philia/CoEdPilot\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RAMBO: Enhancing RAG-based Repository-Level Method Body Completion\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.15204\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RepoGraph: Enhancing AI Software Engineering with Repository-level Code Graph\" [2024-10] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2410.14684\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"See-Saw Generative Mechanism for Scalable Recursive Code Generation with Generative AI\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.10861\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Beyond pip install: Evaluating LLM Agents for the Automated Installation of Python Projects\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.06294\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ContextModule: Improving Code Completion via Repository-level Contextual Information\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.08063\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MutaGReP: Execution-Free Repository-Grounded Plan Search for Code-Use\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.15872\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"aiXcoder-7B-v2: Training LLMs to Fully Utilize the Long Context in Repository-level Code Completion\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.15301\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Repository-Level Software Repair via Repository-Aware Knowledge Graphs\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.21710\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SRLCG: Self-Rectified Large-Scale Code Generation with Multidimensional Chain-of-Thought and Dynamic Backtracking\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.00532\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Knowledge Graph Based Repository-Level Code Generation\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.14394\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.16901\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Empirical Study on Strong-Weak Model Collaboration for Repo-level Code Generation\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.20182\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.10068\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"GRACE: Graph-Guided Repository-Aware Code Completion through Hierarchical Code Fusion\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.05980\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeRAG: Finding Relevant and Necessary Knowledge for Retrieval-Augmented Repository-Level Code Completion\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.16112\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.16198\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"On Pretraining for Project-Level Code Completion\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.13697\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eIssue Resolution\u003c/h3\u003e\u003ca id=\"user-content-issue-resolution\" class=\"anchor\" aria-label=\"Permalink: Issue Resolution\" href=\"#issue-resolution\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SWE-bench: Can Language Models Resolve Real-World GitHub Issues?\" [2023-10] [ICLR 2024] [\u003ca href=\"https://arxiv.org/abs/2310.06770\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeR: Issue Resolving with Multi-Agent and Task Graphs\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.01304\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Agentless: Demystifying LLM-based Software Engineering Agents\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.01489\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Exploring the Potential of Conversational Test Suite Based Program Repair on SWE-bench\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.04485\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Repository Structure-Aware Training Makes SLMs Better Issue Resolver\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.19031\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"PatchPilot: A Cost-Efficient Software Engineering Agent with Early Attempts on Formal Verification\" [2025-02] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2502.02747\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SWE-Synth: Synthesizing Verifiable Bug-Fix Data to Enable Large Language Models in Resolving Real-World Bugs\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.14757\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Guided Search Strategies in Non-Serializable Environments with Applications to Software Engineering Agents\" [2025-05] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2505.13652\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SWE-Dev: Building Software Engineering Agents with Training and Inference Scaling\" [2025-06] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2506.07636\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SWE-Flow: Synthesizing Software Engineering Data in a Test-Driven Manner\" [2025-06] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2506.09003\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"UTBoost: Rigorous Evaluation of Coding Agents on SWE-Bench\" [2025-06] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2506.09289\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The SWE-Bench Illusion: When State-of-the-Art LLMs Remember Instead of Reason\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.12286\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.19290\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SWE-Bench-CL: Continual Learning for Coding Agents\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2507.00014\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.23348\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SWE-Exp: Experience-Driven Software Issue Resolution\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.23361\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.03501\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Empirical Study on Failures in Automated Issue Solving\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.13941\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFrontend Development\u003c/h3\u003e\u003ca id=\"user-content-frontend-development\" class=\"anchor\" aria-label=\"Permalink: Frontend Development\" href=\"#frontend-development\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Seeking the user interface\", 2014-09, ASE 2014, [\u003ca href=\"https://dl.acm.org/doi/10.1145/2642937.2642976\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"pix2code: Generating Code from a Graphical User Interface Screenshot\", 2017-05, EICS 2018, [\u003ca href=\"https://arxiv.org/abs/1705.07962\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Machine Learning-Based Prototyping of Graphical User Interfaces for Mobile Apps\", 2018-02, TSE 2020, [\u003ca href=\"https://arxiv.org/abs/1802.02312\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automatic HTML Code Generation from Mock-Up Images Using Machine Learning Techniques\", 2019-04, EBBT 2019, [\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/8741736\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Sketch2code: Generating a website from a paper mockup\", 2019-05, [\u003ca href=\"https://arxiv.org/abs/1905.13750\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"HTLM: Hyper-Text Pre-Training and Prompting of Language Models\", 2021-07, ICLR 2022, [\u003ca href=\"https://arxiv.org/abs/2107.06955\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Learning UI-to-Code Reverse Generator Using Visual Critic Without Rendering\", 2023-05, [\u003ca href=\"https://arxiv.org/abs/2305.14637\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Design2Code: How Far Are We From Automating Front-End Engineering?\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.03163\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Unlocking the conversion of Web Screenshots into HTML Code with the WebSight Dataset\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.09029\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"VISION2UI: A Real-World Dataset with Layout for Code Generation from UI Designs\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.06369\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LogoMotion: Visually Grounded Code Generation for Content-Aware Animation\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.07065\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"PosterLLaVa: Constructing a Unified Multi-modal Layout Generator with LLM\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.02884\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"UICoder: Finetuning Large Language Models to Generate User Interface Code through Automated Feedback\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.07739\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"On AI-Inspired UI-Design\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.13631\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Identifying User Goals from UI Trajectories\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.14314\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automatically Generating UI Code from Screenshot: A Divide-and-Conquer-Based Approach\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.16386\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework for Multimodal LLMs\" [2024-06] [NeurIPS 2024] [\u003ca href=\"https://arxiv.org/abs/2406.20098\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Vision-driven Automated Mobile GUI Testing via Multimodal Large Language Model\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.03037\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AUITestAgent: Automatic Requirements Oriented GUI Function Testing\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.09018\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM-based Abstraction and Concretization for GUI Test Migration\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.05028\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enabling Cost-Effective UI Automation Testing with Retrieval-Based LLMs: A Case Study in WeChat\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.07829\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Self-Elicitation of Requirements with Automated GUI Prototyping\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.16388\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Infering Alt-text For UI Icons With Large Language Models During App Development\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.18060\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Leveraging Large Vision Language Model For Better Automatic Web GUI Testing\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.12157\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Sketch2Code: Evaluating Vision-Language Models for Interactive Web Design Prototyping\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.16232\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WAFFLE: Multi-Modal Model for Automated Front-End Development\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.18362\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DesignRepair: Dual-Stream Design Guideline-Aware Frontend Repair with Large Language Models\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.01606\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Interaction2Code: How Far Are We From Automatic Interactive Webpage Generation?\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.03292\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.07098\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automated Test Transfer Across Android Apps Using Large Language Models\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.17933\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Zero-Shot Prompting Approaches for LLM-based Graphical User Interface Generation\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.11328\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MRWeb: An Exploration of Generating Multi-Page Resource-Aware Web Code from UI Designs\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.15310\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Combining Language and App UI Analysis for the Automated Assessment of Bug Reproduction Steps\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.04251\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ReaderLM-v2: Small Language Model for HTML to Markdown and JSON\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.01151\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional Websites from Scratch\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.03733\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Web-Bench: A LLM Code Benchmark Based on Web Standards and Frameworks\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.07473\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WebUIBench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in WebUI-to-Code\" [2025-06] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2506.07818\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A11YN: aligning LLMs for accessible web UI code generation\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.13914\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WebDevJudge: Evaluating (M)LLMs as Critiques for Web Development Quality\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.18560\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAutomated Machine Learning\u003c/h3\u003e\u003ca id=\"user-content-automated-machine-learning\" class=\"anchor\" aria-label=\"Permalink: Automated Machine Learning\" href=\"#automated-machine-learning\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models Synergize with Automated Machine Learning\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.03727\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.02958\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.07095\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"UniAutoML: A Human-Centered Framework for Unified Discriminative and Generative AutoML with Large Language Models\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.12841\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"BudgetMLAgent: A Cost-Effective LLM Multi-Agent system for Automating Machine Learning Tasks\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.07464\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Performance of the LSTM-based Code Generated by Large Language Models (LLMs) in Forecasting Time Series Data\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.18731\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ML-Dev-Bench: Comparative Analysis of AI Agents on ML development workflows\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.00964\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CSR-Bench: Benchmarking LLM Agents in Deployment of Computer Science Research Repositories\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.06111\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AIDE: AI-Driven Exploration in the Space of Code\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.13138\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MLGym: A New Framework and Benchmark for Advancing AI Research Agents\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.14499\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MAS-GPT: Training LLMs to Build LLM-based Multi-Agent Systems\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.03686\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SciReplicate-Bench: Benchmarking LLMs in Agent-driven Algorithmic Reproduction from Research Papers\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2504.00255\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"PaperBench: Evaluating AI's Ability to Replicate AI Research\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.01848\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.17192\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AutoP2C: An LLM-Based Agent Framework for Code Repository Generation from Multimodal Content in Academic Papers\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.20115\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ResearchCodeAgent: An LLM Multi-Agent System for Automated Codification of Research Methodologies\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.20117\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MLZero: A Multi-Agent System for End-to-end Machine Learning Automation\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.13941\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.19955\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ResearchCodeBench: Benchmarking LLMs on Implementing Novel Machine Learning Research Code\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.02314\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"From Reproduction to Replication: Evaluating Research Agents with Progressive Code Masking\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.19724\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.02554\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ML2B: Multi-Lingual ML Benchmark For AutoML\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.22768\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RECODE-H: A Benchmark for Research Code Development with Interactive Human Feedback\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.06186\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AutoMLGen: Navigating Fine-Grained Optimization for Coding Agents\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.08511\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eText-To-SQL\u003c/h3\u003e\u003ca id=\"user-content-text-to-sql\" class=\"anchor\" aria-label=\"Permalink: Text-To-SQL\" href=\"#text-to-sql\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models\" [2021-09] [EMNLP 2021] [\u003ca href=\"https://arxiv.org/abs/2109.05093\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodexDB: Generating Code for Processing SQL Queries using GPT-3 Codex\" [2022-04] [\u003ca href=\"https://arxiv.org/abs/2204.08941\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"T5QL: Taming language models for SQL generation\" [2022-09] [\u003ca href=\"https://arxiv.org/abs/2209.10254\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards Generalizable and Robust Text-to-SQL Parsing\" [2022-10] [EMNLP 2022 Findings] [\u003ca href=\"https://arxiv.org/abs/2210.12674\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"XRICL: Cross-lingual Retrieval-Augmented In-Context Learning for Cross-lingual Text-to-SQL Semantic Parsing\" [2022-10] [EMNLP 2022 Findings] [\u003ca href=\"https://arxiv.org/abs/2210.13693\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A comprehensive evaluation of ChatGPT's zero-shot Text-to-SQL capability\" [2023-03] [\u003ca href=\"https://arxiv.org/abs/2303.13547\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction\" [2023-04] [NeurIPS 2023] [\u003ca href=\"https://arxiv.org/abs/2304.11015\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings\" [2023-05] [\u003ca href=\"https://arxiv.org/abs/2305.11853\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Few-shot Text-to-SQL Capabilities of Large Language Models: A Study on Prompt Design Strategies\" [2023-05] [\u003ca href=\"https://arxiv.org/abs/2305.12586\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SQL-PaLM: Improved Large Language Model Adaptation for Text-to-SQL\" [2023-05] [\u003ca href=\"https://arxiv.org/abs/2306.00739\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Retrieval-augmented GPT-3.5-based Text-to-SQL Framework with Sample-aware Prompting and Dynamic Revision Chain\" [2023-07] [ICONIP 2023] [\u003ca href=\"https://arxiv.org/abs/2307.05074\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation\" [2023-08] [\u003ca href=\"https://arxiv.org/abs/2308.15363\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MAC-SQL: A Multi-Agent Collaborative Framework for Text-to-SQL\" [2023-12] [\u003ca href=\"https://arxiv.org/abs/2312.11242\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models\" [2024-02] [EMNLP 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2402.01117\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Improving Demonstration Diversity by Human-Free Fusing for Text-to-SQL\" [2024-02] [EMNLP 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2402.10663\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Decomposition for Enhancing Attention: Improving LLM-based Text-to-SQL through Workflow Paradigm\" [2024-02] [ACL 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2402.10671\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Knowledge-to-SQL: Enhancing SQL Generation with Data Expert LLM\" [2024-02] [ACL 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2402.11517\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Understanding the Effects of Noise in Text-to-SQL: An Examination of the BIRD-Bench Benchmark\" [2024-02] [ACL 2024 short] [\u003ca href=\"https://arxiv.org/abs/2402.12243\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Structure Guided Large Language Model for SQL Generation\" [2024-02] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2402.13284\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SQL-Encoder: Improving NL2SQL In-Context Learning Through a Context-Aware Encoder\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.16204\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM-R2: A Large Language Model Enhanced Rule-based Rewrite System for Boosting Query Efficiency\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.12872\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Dubo-SQL: Diverse Retrieval-Augmented Generation and Fine Tuning for Text-to-SQL\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.12560\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"EPI-SQL: Enhancing Text-to-SQL Translation with Error-Prevention Instructions\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.14453\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ProbGate at EHRSQL 2024: Enhancing SQL Query Generation Accuracy through Probabilistic Threshold Filtering and Error Handling\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.16659\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CoE-SQL: In-Context Learning for Multi-Turn Text-to-SQL with Chain-of-Editions\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.02712\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Open-SQL Framework: Enhancing Text-to-SQL on Open-source Large Language Models\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.06674\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MCS-SQL: Leveraging Multiple Prompts and Multiple-Choice Selection For Text-to-SQL Generation\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.07467\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"PromptMind Team at EHRSQL-2024: Improving Reliability of SQL Generation using Ensemble LLMs\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.08839\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LG AI Research \u0026amp; KAIST at EHRSQL 2024: Self-Training Large Language Models with Pseudo-Labeled Unanswerable Questions for a Reliable Text-to-SQL System on EHRs\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.11162\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Before Generation, Align it! A Novel and Effective Strategy for Mitigating Hallucinations in Text-to-SQL Generation\" [2024-05] [ACL 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2405.15307\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CHESS: Contextual Harnessing for Efficient SQL Synthesis\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.16755\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DeTriever: Decoder-representation-based Retriever for Improving NL2SQL In-Context Learning\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.07913\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Next-Generation Database Interfaces: A Survey of LLM-based Text-to-SQL\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.08426\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RH-SQL: Refined Schema and Hardness Prompt for Text-to-SQL\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.09133\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"QDA-SQL: Questions Enhanced Dialogue Augmentation for Multi-Turn Text-to-SQL\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.10593\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"End-to-end Text-to-SQL Generation within an Analytics Insight Engine\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.12104\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MAGIC: Generating Self-Correction Guideline for In-Context Text-to-SQL\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.12692\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SQLFixAgent: Towards Semantic-Accurate SQL Generation via Multi-Agent Collaboration\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.13408\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Unmasking Database Vulnerabilities: Zero-Knowledge Schema Inference Attacks in Text-to-SQL Systems\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.14545\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning\" [2024-07] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2407.03227\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Lucy: Think and Reason to Solve Text-to-SQL\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.05153\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ESM+: Modern Insights into Perspective on Text-to-SQL Evaluation in the Age of Large Language Models\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.07313\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RB-SQL: A Retrieval-based LLM Framework for Text-to-SQL\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.08273\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AI-Assisted SQL Authoring at Industry Scale\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.13280\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SQLfuse: Enhancing Text-to-SQL Performance through Comprehensive LLM Synergy\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.14568\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Survey on Employing Large Language Models for Text-to-SQL Tasks\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.15186\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards Automated Data Sciences with Natural Language and SageCopilot: Practices and Lessons Learned\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.21040\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating LLMs for Text-to-SQL Generation With Complex SQL Workload\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.19517\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Synthesizing Text-to-SQL Data from Weak and Strong LLMs\" [2024-08] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2408.03256\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Improving Relational Database Interactions with Large Language Models: Column Descriptions and Their Impact on Text-to-SQL Performance\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.04691\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.07702\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MAG-SQL: Multi-Agent Generative Approach with Soft Schema Linking and Iterative Sub-SQL Refinement for Text-to-SQL\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.07930\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Text-to-SQL Parsing through Question Rewriting and Execution-Guided Refinement\" [2024-08] [ACL 2024 Findings] [\u003ca href=\"https://aclanthology.org/2024.findings-acl.120/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DAC: Decomposed Automation Correction for Text-to-SQL\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.08779\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Interactive-T2S: Multi-Turn Interactions for Text-to-SQL with Large Language Models\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.11062\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SQL-GEN: Bridging the Dialect Gap for Text-to-SQL Via Synthetic Data And Model Merging\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.12733\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing SQL Query Generation with Neurosymbolic Reasoning\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.13888\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Text2SQL is Not Enough: Unifying AI and Databases with TAG\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.14717\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Tool-Assisted Agent on SQL Inspection and Refinement in Real-World Scenarios\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.16991\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SelECT-SQL: Self-correcting ensemble Chain-of-Thought for Text-to-SQL\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.10007\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"You Only Read Once (YORO): Learning to Internalize Database Knowledge for Text-to-SQL\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.12172\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL\" [2024-09] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2409.14082\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Text-to-SQL Capabilities of Large Language Models via Domain Database Knowledge Injection\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.15907\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DataGpt-SQL-7B: An Open-Source Language Model for Text-to-SQL\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.15985\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"E-SQL: Direct Schema Linking via Question Enrichment in Text-to-SQL\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.16751\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"FLEX: Expert-level False-Less EXecution Metric for Reliable Text-to-SQL Benchmark\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.19014\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing LLM Fine-tuning for Text-to-SQLs by SQL Quality Measurement\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.01869\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"From Natural Language to SQL: Review of LLM-based Text-to-SQL Systems\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.01066\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CHASE-SQL: Multi-Path Reasoning and Preference Optimized Candidate Selection in Text-to-SQL\" [2024-10] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2410.01943\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Context-Aware SQL Error Correction Using Few-Shot Learning -- A Novel Approach Based on NLQ, Error, and SQL Similarity\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.09174\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Learning from Imperfect Data: Towards Efficient Knowledge Distillation of Autoregressive Language Models for Text-to-SQL\" [2024-10] [EMNLP 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2410.11371\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LR-SQL: A Supervised Fine-Tuning Method for Text2SQL Tasks under Low-Resource Scenarios\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.11457\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MSc-SQL: Multi-Sample Critiquing Small Language Models For Text-To-SQL Translation\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.12916\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Learning Metadata-Agnostic Representations for Text-to-SQL In-Context Example Selection\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.14049\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Actor-Critic Approach to Boosting Text-to-SQL Large Language Model\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.22082\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RSL-SQL: Robust Schema Linking in Text-to-SQL Generation\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2411.00073\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"KeyInst: Keyword Instruction for Improving SQL Formulation in Text-to-SQL\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2411.00788\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Grounding Natural Language to SQL Translation with Data-Based Self-Explanations\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.02948\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"PDC \u0026amp; DM-SFT: A Road for LLM SQL Bug-Fix Enhancing\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.06767\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"XiYan-SQL: A Multi-Generator Ensemble Framework for Text-to-SQL\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.08599\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Leveraging Prior Experience: An Expandable Auxiliary Knowledge Base for Text-to-SQL\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.13244\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Text-to-SQL Calibration: No Need to Ask -- Just Rescale Model Probabilities\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.16742\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SecureSQL: Evaluating Data Leakage of Large Language Models as Natural Language Interfaces to Databases\" [2024-11] [EMNLP 2024 Findings] [\u003ca href=\"https://aclanthology.org/2024.findings-emnlp.346/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Survey of Large Language Model-Based Generative AI for Text-to-SQL: Benchmarks, Applications, Use Cases, and Challenges\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.05208\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Cooperative SQL Generation for Segmented Databases By Using Multi-functional LLM Agents\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.05850\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ROUTE: Robust Multitask Tuning and Collaboration for Text-to-SQL\" [2024-12] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2412.10138\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Solid-SQL: Enhanced Schema-linking based In-context Learning for Robust Text-to-SQL\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.12522\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating and Enhancing LLMs for Multi-turn Text-to-SQL with Multiple Question Types\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.17867\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Study of In-Context-Learning-Based Text-to-SQL Errors\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.09310\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Confidence Estimation for Error Detection in Text-to-SQL Systems\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.09527\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Reliable Text-to-SQL with Adaptive Abstention\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.10858\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Is Long Context All You Need? Leveraging LLM's Extended Context for NL2SQL\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.12372\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Text-to-SQL based on Large Language Models and Database Keyword Search\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.13594\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MCTS-SQL: An Effective Framework for Text-to-SQL with Monte Carlo Tree Search\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.16607\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Extractive Schema Linking for Text-to-SQL\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.17174\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ReFoRCE: A Text-to-SQL Agent with Self-Refinement, Format Restriction, and Column Exploration\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.00675\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"PSM-SQL: Progressive Schema Learning with Multi-granularity Semantics for Text-to-SQL\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.05237\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Rationalization Models for Text-to-SQL\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.06759\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"BASE-SQL: A powerful open source Text-To-SQL baseline approach\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.10739\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MultiTEND: A Multilingual Benchmark for Natural Language to NoSQL Query Translation\" [2025-02] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2502.11022\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Bridging the Gap: Enabling Natural Language Queries for NoSQL Databases through Text-to-NoSQL Translation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.11201\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SAFE-SQL: Self-Augmented In-Context Learning with Fine-grained Example Selection for Text-to-SQL\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.11438\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Uncovering the Impact of Chain-of-Thought Reasoning for Direct Preference Optimization: Lessons from Text-to-SQL\" [2025-02] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2502.11656\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SQL-o1: A Self-Reward Heuristic Dynamic Search Method for Text-to-SQL\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.11741\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Knapsack Optimization-based Schema Linking for LLM-based Text-to-SQL Generation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.12911\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"STaR-SQL: Self-Taught Reasoner for Text-to-SQL\" [2025-02] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2502.13550\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Bridging the Gap: Transforming Natural Language Questions into SQL Queries via Abstract Query Pattern and Contextual Schema Markup\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.14682\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"OpenSearch-SQL: Enhancing Text-to-SQL with Dynamic Few-shot and Consistency Alignment\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.14913\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SQLong: Enhanced NL2SQL for Longer Contexts with LLMs\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.16747\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Alpha-SQL: Zero-Shot Text-to-SQL using Monte Carlo Tree Search\" [2025-02] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2502.17248\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"OmniSQL: Synthesizing High-quality Text-to-SQL Data at Scale\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.02240\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DB-Explore: Automated Database Exploration and Instruction Synthesis for Text-to-SQL\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.04959\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SQLCritic: Correcting Text-to-SQL Generation via Clause-wise Critic\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.07996\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"TinySQL: A Progressive Text-to-SQL Dataset for Mechanistic Interpretability Research\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.12730\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Feather-SQL: A Lightweight NL2SQL Framework with Dual-Model Collaboration Paradigm for Small Language Models\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.17811\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LinkAlign: Scalable Schema Linking for Real-World Large-Scale Multi-Database Text-to-SQL\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.18596\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ExCoT: Optimizing Reasoning for Text-to-SQL with Execution Feedback\" [2025-03] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2503.19988\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"EllieSQL: Cost-Efficient Text-to-SQL with Complexity-Aware Routing\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.22402\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Reasoning-SQL: Reinforcement Learning with SQL Tailored Partial Rewards for Reasoning-Enhanced Text-to-SQL\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.23157\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Distill-C: Enhanced NL2SQL via Distilled Customization with LLMs\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2504.00048\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Reward-SQL: Boosting Text-to-SQL via Stepwise Reasoning and Process-Supervised Rewards\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.04671\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ReEx-SQL: Reasoning with Execution-Aware Reinforcement Learning for Text-to-SQL\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.12768\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CSC-SQL: Corrective Self-Consistency in Text-to-SQL via Reinforcement Learning\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.13271\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SQLForge: Synthesizing Reliable and Diverse Data to Enhance Text-to-SQL Reasoning in LLMs\" [2025-05] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2505.13725\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Cheaper, Better, Faster, Stronger: Robust Text-to-SQL without Chain-of-Thought or Fine-Tuning\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.14174\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"JOLT-SQL: Joint Loss Tuning of Text-to-SQL with Confusion-aware Noisy Schema Sampling\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.14305\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"UNJOIN: Enhancing Multi-Table Text-to-SQL Generation via Schema Simplification\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.18122\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SchemaGraphSQL: Efficient Schema Linking with Pathfinding Graph Algorithms for Text-to-SQL on Large-Scale Databases\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.18363\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DCG-SQL: Enhancing In-Context Learning for Text-to-SQL with Deep Contextual Schema Link Graph\" [2025-05] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2505.19956\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Arctic-Text2SQL-R1: Simple Rewards, Strong Reasoning in Text-to-SQL\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.20315\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Pi-SQL: Enhancing Text-to-SQL with Fine-Grained Guidance from Pivot Programming Languages\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2506.00912\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SHARE: An SLM-based Hierarchical Action CorREction Assistant for Text-to-SQL\" [2025-05] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2506.00391\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SDE-SQL: Enhancing Text-to-SQL Generation in Large Language Models via Self-Driven Exploration with SQL Probes\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.07245\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in Real-World Applications\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.18951\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"GradeSQL: Outcome Reward Models for Ranking SQL Queries from Large Language Models\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.01308\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SPFT-SQL: Enhancing Large Language Model for Text-to-SQL Parsing by Self-Play Fine-Tuning\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.03937\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating NL2SQL via SQL2NL\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.04657\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DeKeyNLU: Enhancing Natural Language to SQL Generation through Task Decomposition and Keyword Extraction\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.14507\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A State-of-the-Art SQL Reasoning Model using RLVR\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.21459\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Agentar-Scale-SQL: Advancing Text-to-SQL through Orchestrated Test-Time Scaling\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.24403\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MTSQL-R1: Towards Long-Horizon Multi-Turn Text-to-SQL via Agentic Training\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.12831\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Rethinking Schema Linking: A Context-Aware Bidirectional Retrieval Approach for Text-to-SQL\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.14296\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eProgram Proof\u003c/h3\u003e\u003ca id=\"user-content-program-proof\" class=\"anchor\" aria-label=\"Permalink: Program Proof\" href=\"#program-proof\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Baldur: Whole-Proof Generation and Repair with Large Language Models\" [2023-03] [FSE 2023] [\u003ca href=\"https://arxiv.org/abs/2303.04910\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An In-Context Learning Agent for Formal Theorem-Proving\" [2023-10] [\u003ca href=\"https://arxiv.org/abs/2310.04353\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards General Loop Invariant Generation: A Benchmark of Programs with Memory Manipulation\" [2023-11] [NeurIPS 2024] [\u003ca href=\"https://arxiv.org/abs/2311.10483\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards AI-Assisted Synthesis of Verified Dafny Methods\" [2024-02] [FSE 2024] [\u003ca href=\"https://arxiv.org/abs/2402.00247\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards Neural Synthesis for SMT-Assisted Proof-Oriented Programming\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.01787\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Laurel: Generating Dafny Assertions Using Large Language Models\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.16792\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AutoVerus: Automated Proof Generation for Rust Code\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.13082\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Proof Automation with Large Language Models\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.14274\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automated Proof Generation for Rust Code via Self-Evolution\" [2024-10] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2410.15756\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CoqPilot, a plugin for LLM-based generation of proofs\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.19605\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"dafny-annotator: AI-Assisted Verification of Dafny Programs\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.15143\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AlphaVerus: Bootstrapping Formally Verified Code Generation through Self-Improving Translation and Treefinement\" [2024-12] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2412.06176\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Automated Loop Invariant Generation for Complex Programs with Large Language Models\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.10483\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Rango: Adaptive Retrieval-Augmented Proving for Automated Software Verification\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.14063\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Dafny as Verification-Aware Intermediate Language for Code Generation\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.06283\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Next Steps in LLM-Supported Java Verification\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.01573\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Verifying LLM-Generated Code in the Context of Software Verification with Ada/SPARK\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.07728\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RAG-Verus: Repository-Level Program Verification with LLMs using Retrieval Augmented Generation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.05344\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"FormalSpecCpp: A Dataset of C++ Formal Specifications created using LLMs\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.15217\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can LLMs Reason About Program Semantics? A Comprehensive Evaluation of LLMs on Formal Specification Inference\" [2025-02] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2503.04779\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can LLMs Formally Reason as Abstract Interpreters for Program Analysis?\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.12686\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can LLMs Enable Verification in Mainstream Programming?\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.14183\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Re:Form -- Reducing Human Priors in Scalable Formal Software Verification with RL in LLMs: A Preliminary Study on Dafny\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.16331\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"PyVeritas: On Verifying Python via LLM-Based Transpilation and Bounded Model Checking for C\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.08171\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"InvBench: Can LLMs Accelerate Program Verification with Invariant Synthesis?\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.21629\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards Repository-Level Program Verification with Large Language Models\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.25197\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eTest Generation\u003c/h3\u003e\u003ca id=\"user-content-test-generation\" class=\"anchor\" aria-label=\"Permalink: Test Generation\" href=\"#test-generation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Unit Test Case Generation with Transformers and Focal Context\" [2020-09] [AST@ICSE 2022] [\u003ca href=\"https://arxiv.org/abs/2009.05617\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation\" [2023-02] [IEEE TSE] [\u003ca href=\"https://arxiv.org/abs/2302.06527\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A3Test: Assertion-Augmented Automated Test Case Generation\" [2023-02] [\u003ca href=\"https://arxiv.org/abs/2302.10352\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Learning Deep Semantics for Test Completion\" [2023-02] [ICSE 2023] [\u003ca href=\"https://arxiv.org/abs/2302.10166\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Using Large Language Models to Generate JUnit Tests: An Empirical Study\" [2023-04] [EASE 2024] [\u003ca href=\"https://arxiv.org/abs/2305.00418\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodaMosa: Escaping Coverage Plateaus in Test Generation with Pre-Trained Large Language Models\" [2023-05] [ICSE 2023] [\u003ca href=\"https://dl.acm.org/doi/abs/10.1109/ICSE48619.2023.00085\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"No More Manual Tests? Evaluating and Improving ChatGPT for Unit Test Generation\" [2023-05] [\u003ca href=\"https://arxiv.org/abs/2305.04207\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ChatUniTest: a ChatGPT-based automated unit test generation tool\" [2023-05] [\u003ca href=\"https://arxiv.org/abs/2305.04764\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ChatGPT vs SBST: A Comparative Assessment of Unit Test Suite Generation\" [2023-07] [\u003ca href=\"https://arxiv.org/abs/2307.00588\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can Large Language Models Write Good Property-Based Tests?\" [2023-07] [\u003ca href=\"https://arxiv.org/abs/2307.04346\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Domain Adaptation for Deep Unit Test Case Generation\" [2023-08] [\u003ca href=\"https://arxiv.org/abs/2308.08033\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Effective Test Generation Using Pre-trained Large Language Models and Mutation Testing\" [2023-08] [\u003ca href=\"https://arxiv.org/abs/2308.16557\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How well does LLM generate security tests?\" [2023-10] [\u003ca href=\"https://arxiv.org/abs/2310.00710\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Reinforcement Learning from Automatic Feedback for High-Quality Unit Test Generation\" [2023-10] [\u003ca href=\"https://arxiv.org/abs/2310.02368\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An initial investigation of ChatGPT unit test generation capability\" [2023-10] [SAST 2023] [\u003ca href=\"https://dl.acm.org/doi/abs/10.1145/3624032.3624035\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CoverUp: Coverage-Guided LLM-Based Test Generation\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.16218\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing LLM-based Test Generation for Hard-to-Cover Branches via Program Analysis\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.04966\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models for Mobile GUI Text Input Generation: An Empirical Study\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.08948\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Test Code Generation for Telecom Software Systems using Two-Stage Generative Model\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.09249\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM-Powered Test Case Generation for Detecting Bugs in Plausible Programs\" [2024-04] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2404.10304\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Generating Test Scenarios from NL Requirements using Retrieval-Augmented LLMs: An Industrial Study\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.12772\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models as Test Case Generators: Performance Evaluation and Enhancement\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.13340\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Leveraging Large Language Models for Automated Web-Form-Test Generation: An Empirical Study\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.09965\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.07944\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Exploring Fuzzing as Data Augmentation for Neural Test Generation\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.08665\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Mokav: Execution-driven Differential Testing with LLMs\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.10375\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SWT-Bench: Testing and Validating Real-World Bug-Fixes with Code Agents\" [2024-06] [NeurIPS 2024] [\u003ca href=\"https://arxiv.org/abs/2406.12952\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CasModaTest: A Cascaded and Model-agnostic Self-directed Framework for Unit Test Generation\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.15743\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Empirical Study of Unit Test Generation with Large Language Models\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.18181\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large-scale, Independent and Comprehensive study of the power of LLMs for test case generation\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2407.00225\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Augmenting LLMs to Repair Obsolete Test Cases with Static Collector and Neural Reranker\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.03625\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Harnessing the Power of LLMs: Automating Unit Test Generation for High-Performance Computing\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.05202\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An LLM-based Readability Measurement for Unit Tests' Context-aware Inputs\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.21369\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A System for Automated Unit Test Generation Using Large Language Models and Assessment of Generated Test Suites\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.07846\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Leveraging Large Language Models for Enhancing the Understandability of Generated Unit Tests\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.11710\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Multi-language Unit Test Generation using LLMs\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.03093\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Exploring the Integration of Large Language Models in Industrial Test Maintenance Processes\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.06416\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Python Symbolic Execution with LLM-powered Code Generation\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.09271\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Rethinking the Influence of Source Code on Test Case Generation\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.09464\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"On the Effectiveness of LLMs for Manual Test Verifications\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.12405\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Retrieval-Augmented Test Generation: How Far Are We?\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.12682\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Context-Enhanced LLM-Based Framework for Automatic Test Refactoring\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.16739\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"TestBench: Evaluating Class-Level Test Case Generation Capability of Large Language Models\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.17561\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Advancing Bug Detection in Fastjson2 with Large Language Models Driven Unit Test Generation\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.09414\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Test smells in LLM-Generated Unit Tests\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.10628\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM-based Unit Test Generation via Property Retrieval\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.13542\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Disrupting Test Development with AI Assistants\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.02328\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Parameter-Efficient Fine-Tuning of Large Language Models for Unit Test Generation: An Empirical Study\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.02462\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"VALTEST: Automated Validation of Language Model Generated Test Cases\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.08254\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"REACCEPT: Automated Co-evolution of Production and Test Code Based on Dynamic Validation and Large Language Models\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.11033\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"What You See Is What You Get: Attention-based Self-guided Automatic Unit Test Generation\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.00828\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"System Test Case Design from Requirements Specifications: Insights and Challenges of Using ChatGPT\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.03693\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"TDD-Bench Verified: Can LLMs Generate Tests for Issues Before They Get Resolved?\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.02883\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CPP-UT-Bench: Can LLMs Write Complex Unit Tests in C++?\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.02735\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Design choices made by LLM-based test generators prevent them from finding bugs\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.14137\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Large-scale Empirical Study on Fine-tuning Large Language Models for Unit Testing\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.16620\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Improving the Readability of Automatically Generated Tests using Large Language Models\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.18843\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Potential of LLMs in Automating Software Testing: From Generation to Reporting\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2501.00217\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Prompt Alchemist: Automated LLM-Tailored Prompt Optimization for Test Case Generation\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.01329\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Contextual Information Injection\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.07425\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Test Wars: A Comparative Study of SBST, Symbolic Execution, and LLM-Based Approaches to Unit Test Generation\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.10200\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can LLM Generate Regression Tests for Software Commits?\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.11086\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Boundary Value Test Input Generation Using Prompt Engineering with LLMs: Fault Detection and Coverage Analysis\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.14465\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Systematic Approach for Assessing Large Language Models' Test Case Generation Capability\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.02866\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ProjectTest: A Project-level LLM Unit Test Generation Benchmark and Impact of Error Fixing Mechanisms\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.06556\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CLOVER: A Test Case Generation Benchmark with Coverage, Long-Context, and Verification\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.08806\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM-based Unit Test Generation for Dynamically-Typed Programs\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.14000\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM Test Generation via Iterative Hybrid Program Analysis\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.13580\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"TestForge: Feedback-Driven, Agentic Test Suite Generation\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.14713\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Unify and Triumph: Polyglot, Diverse, and Self-Consistent Generation of Unit Tests with LLMs\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.16144\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Issue2Test: Generating Reproducing Test Cases from Issue Reports\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.16320\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"HardTests: Synthesizing High-Quality Test Cases for LLM Coding\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.24098\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeContests+: High-Quality Test Case Generation for Competitive Programming\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.05817\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can LLMs Generate Reliable Test Case Generators? A Study on Competition-Level Programming Problems\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.06821\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Rethinking Verification for LLM Code Generation: From Generation to Testing\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.06920\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Klear-CodeTest: Scalable Test Case Generation for Code Reinforcement Learning\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.05710\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Navigating the Labyrinth: Path-Sensitive Unit Test Generation with Large Language Models\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.23812\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOracle Generation\u003c/h3\u003e\u003ca id=\"user-content-oracle-generation\" class=\"anchor\" aria-label=\"Permalink: Oracle Generation\" href=\"#oracle-generation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Generating Accurate Assert Statements for Unit Test Cases using Pretrained Transformers\" [2020-09] [\u003ca href=\"https://arxiv.org/abs/2009.05634\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"TOGA: A Neural Method for Test Oracle Generation\" [2021-09] [ICSE 2022] [\u003ca href=\"https://arxiv.org/abs/2109.09262\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"TOGLL: Correct and Strong Test Oracle Generation with LLMs\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.03786\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Test Oracle Automation in the era of LLMs\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.12766\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Beyond Code Generation: Assessing Code LLM Maturity with Postconditions\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.14118\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Chat-like Asserts Prediction with the Support of Large Language Model\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.21429\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Do LLMs generate test oracles that capture the actual or the expected program behaviour?\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.21136\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Generating executable oracles to check conformance of client code to requirements of JDK Javadocs using LLMs\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.01789\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automatically Write Code Checker: An LLM-based Approach with Logic-guided API Retrieval and Case by Case Iteration\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.06796\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ASSERTIFY: Utilizing Large Language Models to Generate Assertions for Production Code\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.16927\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DeCon: Detecting Incorrect Assertions via Postconditions Generated by a Large Language Model\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.02901\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AugmenTest: Enhancing Tests with LLM-Driven Oracles\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.17461\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AsserT5: Test Assertion Generation Using a Fine-Tuned Code Language Model\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.02708\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Improving Retrieval-Augmented Deep Assertion Generation via Joint Training\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.10696\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Improving Deep Assertion Generation via Fine-Tuning Retrieval-Augmented Pre-trained Language Models\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.16071\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eMutation Testing\u003c/h3\u003e\u003ca id=\"user-content-mutation-testing\" class=\"anchor\" aria-label=\"Permalink: Mutation Testing\" href=\"#mutation-testing\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"BERT: Mutation Testing using Pre-Trained Language Models\" [2022-03] [\u003ca href=\"https://arxiv.org/abs/2203.03289\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Efficient Mutation Testing via Pre-Trained Language Models\" [2023-01] [\u003ca href=\"https://arxiv.org/abs/2301.03543\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLMorpheus: Mutation Testing using Large Language Models\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.09952\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Exploratory Study on Using Large Language Models for Mutation Testing\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.09843\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Fine-Tuning LLMs for Code Mutation: A New Era of Cyber Threats\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.22293\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Simulink Mutation Testing using CodeBERT\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.07553\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Mutation-Guided LLM-based Test Generation at Meta\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.12862\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFuzz Testing\u003c/h3\u003e\u003ca id=\"user-content-fuzz-testing\" class=\"anchor\" aria-label=\"Permalink: Fuzz Testing\" href=\"#fuzz-testing\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models\" [2022-12] [\u003ca href=\"https://arxiv.org/abs/2212.14834\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Fuzz4All: Universal Fuzzing with Large Language Models\" [2023-08] [\u003ca href=\"https://arxiv.org/abs/2308.04748\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WhiteFox: White-Box Compiler Fuzzing Empowered by Large Language Models\" [2023-10] [\u003ca href=\"https://arxiv.org/abs/2310.15991\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLAMAFUZZ: Large Language Model Enhanced Greybox Fuzzing\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.07714\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"FuzzCoder: Byte-level Fuzzing Test via Large Language Model\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.01944\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ISC4DGF: Enhancing Directed Grey-box Fuzzing with LLM-Driven Initial Seed Corpus Generation\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.14329\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models Based JSON Parser Fuzzing for Bug Discovery and Behavioral Analysis\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.21806\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Fixing Security Vulnerabilities with AI in OSS-Fuzz\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.03346\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Code Knowledge Graph-Enhanced System for LLM-Based Fuzz Driver Generation\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.11532\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Harnessing Large Language Models for Seed Generation in Greybox Fuzzing\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.18143\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Model assisted Hybrid Fuzzing\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.15931\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Your Fix Is My Exploit: Enabling Comprehensive DL Library API Fuzzing with Large Language Models\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.04312\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eVulnerability Detection\u003c/h3\u003e\u003ca id=\"user-content-vulnerability-detection\" class=\"anchor\" aria-label=\"Permalink: Vulnerability Detection\" href=\"#vulnerability-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"VulDeePecker: A Deep Learning-Based System for Vulnerability Detection\" [2018-01] [NDSS 2018] [\u003ca href=\"https://arxiv.org/abs/1801.01681\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DeepBugs: A Learning Approach to Name-based Bug Detection\" [2018-04] [Proc. ACM Program. Lang.] [\u003ca href=\"https://arxiv.org/abs/1805.11683\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automated Vulnerability Detection in Source Code Using Deep Representation Learning\" [2018-07] [ICMLA 2018] [\u003ca href=\"https://arxiv.org/abs/1807.04320\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SySeVR: A Framework for Using Deep Learning to Detect Software Vulnerabilities\" [2018-07] [IEEE TDSC] [\u003ca href=\"https://arxiv.org/abs/1807.06756\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks\" [2019-09] [NeurIPS 2019] [\u003ca href=\"https://arxiv.org/abs/1909.03496\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Improving bug detection via context-based code representation learning and attention-based neural networks\" [2019-10] [Proc. ACM Program. Lang.] [\u003ca href=\"https://dl.acm.org/doi/10.1145/3360588\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Global Relational Models of Source Code\" [2019-12] [ICLR 2020] [\u003ca href=\"https://openreview.net/forum?id=B1lnbRNtwr\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"VulDeeLocator: A Deep Learning-based Fine-grained Vulnerability Detector\" [2020-01] [IEEE TDSC] [\u003ca href=\"https://arxiv.org/abs/2001.02350\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Deep Learning based Vulnerability Detection: Are We There Yet?\" [2020-09] [IEEE TSE] [\u003ca href=\"https://arxiv.org/abs/2009.07235\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Security Vulnerability Detection Using Deep Learning Natural Language Processing\" [2021-05] [INFOCOM Workshops 2021] [\u003ca href=\"https://arxiv.org/abs/2105.02388\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Self-Supervised Bug Detection and Repair\" [2021-05] [NeurIPS 2021] [\u003ca href=\"https://arxiv.org/abs/2105.12787\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Vulnerability Detection with Fine-grained Interpretations\" [2021-06] [ESEC/SIGSOFT FSE 2021] [\u003ca href=\"https://arxiv.org/abs/2106.10478\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ReGVD: Revisiting Graph Neural Networks for Vulnerability Detection\" [2021-10] [ICSE Companion 2022] [\u003ca href=\"https://arxiv.org/abs/2110.07317\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"VUDENC: Vulnerability Detection with Deep Learning on a Natural Codebase for Python\" [2022-01] [Inf. Softw. Technol] [\u003ca href=\"https://arxiv.org/abs/2201.08441\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Transformer-Based Language Models for Software Vulnerability Detection\" [222-04] [ACSAC 2022] [\u003ca href=\"https://arxiv.org/abs/2204.03214\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LineVul: A Transformer-based Line-Level Vulnerability Prediction\" [2022-05] [MSR 2022] [\u003ca href=\"https://ieeexplore.ieee.org/document/9796256\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"VulBERTa: Simplified Source Code Pre-Training for Vulnerability Detection\" [2022-05] [IJCNN 2022] [\u003ca href=\"https://arxiv.org/abs/2205.12424\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Open Science in Software Engineering: A Study on Deep Learning-Based Vulnerability Detection\" [2022-09] [IEEE TSE] [\u003ca href=\"https://ieeexplore.ieee.org/document/9894099\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Empirical Study of Deep Learning Models for Vulnerability Detection\" [2022-12] [ICSE 2023] [\u003ca href=\"https://arxiv.org/abs/2212.08109\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CSGVD: A deep learning approach combining sequence and graph embedding for source code vulnerability detection\" [2023-01] [J. Syst. Softw.] [\u003ca href=\"https://www.sciencedirect.com/science/article/pii/S0164121223000183\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Benchmarking Software Vulnerability Detection Techniques: A Survey\" [2023-03] [\u003ca href=\"https://arxiv.org/abs/2303.16362\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Transformer-based Vulnerability Detection in Code at EditTime: Zero-shot, Few-shot, or Fine-tuning?\" [2023-05] [\u003ca href=\"https://arxiv.org/abs/2306.01754\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Survey on Automated Software Vulnerability Detection Using Machine Learning and Deep Learning\" [2023-06] [\u003ca href=\"https://arxiv.org/abs/2306.11673\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Limits of Machine Learning for Automatic Vulnerability Detection\" [2023-06] [\u003ca href=\"https://arxiv.org/abs/2306.17193\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation\" [2023-08] [\u003ca href=\"https://arxiv.org/abs/2308.01240\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Prompt-Enhanced Software Vulnerability Detection Using ChatGPT\" [2023-08] [\u003ca href=\"https://arxiv.org/abs/2308.12697\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards Causal Deep Learning for Vulnerability Detection\" [2023-10] [\u003ca href=\"https://arxiv.org/abs/2310.07958\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Understanding the Effectiveness of Large Language Models in Detecting Security Vulnerabilities\" [2023-11] [\u003ca href=\"https://arxiv.org/abs/2311.16169\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How Far Have We Gone in Vulnerability Detection Using Large Language Models\" [2023-11] [\u003ca href=\"https://arxiv.org/abs/2311.12420\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can Large Language Models Identify And Reason About Security Vulnerabilities? Not Yet\" [2023-12] [\u003ca href=\"https://arxiv.org/abs/2312.12575\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM4Vuln: A Unified Evaluation Framework for Decoupling and Enhancing LLMs' Vulnerability Reasoning\" [2024-01] [\u003ca href=\"https://arxiv.org/abs/2401.16185\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Security Code Review by LLMs: A Deep Dive into Responses\" [2024-01] [\u003ca href=\"https://arxiv.org/abs/2401.16310\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLMDFA: Analyzing Dataflow in Code with Large Language Models\" [2024-02] [NeurIPS 2024] [\u003ca href=\"https://arxiv.org/abs/2402.10754\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Chain-of-Thought Prompting of Large Language Models for Discovering and Fixing Software Vulnerabilities\" [2024-02] [\u003ca href=\"https://arxiv.org/abs/2402.17230\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Multi-role Consensus through LLMs Discussions for Vulnerability Detection\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.14274\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Comprehensive Study of the Capabilities of Large Language Models for Vulnerability Detection\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.17218\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Vulnerability Detection with Code Language Models: How Far Are We?\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.18624\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Multitask-based Evaluation of Open-Source LLM on Software Vulnerability\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.02056\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Model for Vulnerability Detection and Repair: Literature Review and Roadmap\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.02525\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Pros and Cons! Evaluating ChatGPT on Software Vulnerability\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.03994\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"VulEval: Towards Repository-Level Evaluation of Software Vulnerability Detection\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.15596\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DLAP: A Deep Learning Augmented Large Language Model Prompting Framework for Software Vulnerability Detection\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.01202\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Bridging the Gap: A Study of AI-based Vulnerability Management between Industry and Academia\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.02435\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Bridge and Hint: Extending Pre-trained Language Models for Long-Range Code\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.11233\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Harnessing Large Language Models for Software Vulnerability Detection: A Comprehensive Benchmarking Study\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.15614\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM-Assisted Static Analysis for Detecting Security Vulnerabilities\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.17238\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Generalization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning\" [2024-06] [ACL 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2406.03718\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Security Vulnerability Detection with Multitask Self-Instructed Fine-Tuning of Large Language Models\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.05892\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"M2CVD: Multi-Model Collaboration for Code Vulnerability Detection\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.05940\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards Effectively Detecting and Explaining Vulnerabilities Using Large Language Models\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.09701\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Vul-RAG: Enhancing LLM-based Vulnerability Detection via Knowledge-level RAG\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.11147\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Bug In the Code Stack: Can LLMs Find Bugs in Large Python Code Stacks\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.15325\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Supporting Cross-language Cross-project Bug Localization Using Pre-trained Language Models\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.02732\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ALPINE: An adaptive language-agnostic pruning method for language models for code\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.04147\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SCoPE: Evaluating LLMs for Software Vulnerability Detection\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.14372\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Comparison of Static Application Security Testing Tools and Large Language Models for Repo-level Vulnerability Detection\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.16235\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Structure-Aware through Line-level Semantic Learning for Code Vulnerability Detection\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.18877\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Study of Using Multimodal LLMs for Non-Crash Functional Bug Detection in Android Apps\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.19053\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"EaTVul: ChatGPT-based Evasion Attack Against Software Vulnerability Detection\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.19216\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating Large Language Models in Detecting Test Smells\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.19261\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automated Software Vulnerability Static Code Analysis Using Generative Pre-Trained Transformer Models\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2408.00197\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Qualitative Study on Using ChatGPT for Software Security: Perception vs. Practicality\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.00435\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models for Secure Code Assessment: A Multi-Language Empirical Study\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.06428\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"VulCatch: Enhancing Binary Vulnerability Detection through CodeT5 Decompilation and KAN Advanced Feature Extraction\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.07181\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Impact of Large Language Models of Code on Fault Localization\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.09657\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Better Debugging: Combining Static Analysis and LLMs for Explainable Crashing Fault Localization\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.12070\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Beyond ChatGPT: Enhancing Software Quality Assurance Tasks with Diverse LLMs and Validation Techniques\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.01001\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CLNX: Bridging Code and Natural Language for C/C++ Vulnerability-Contributing Commits Identification\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.07407\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Vulnerability Detection: A Comparative Analysis of Emerging Large Language Models\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.10490\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Program Slicing in the Era of Large Language Models\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.12369\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Generating API Parameter Security Rules with LLM for API Misuse Detection\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.09288\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Fault Localization Through Ordered Code Analysis with LLM Agents and Self-Reflection\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.13642\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Comparing Unidirectional, Bidirectional, and Word2vec Models for Discovering Vulnerabilities in Compiled Lifted Code\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.17513\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Pre-Trained Language Models for Vulnerability Detection via Semantic-Preserving Data Augmentation\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.00249\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"StagedVulBERT: Multi-Granular Vulnerability Detection with a Novel Pre-trained Code Model\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.05766\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Understanding the AI-powered Binary Code Similarity Detection\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.07537\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RealVul: Can We Detect Vulnerabilities in Web Applications with LLM?\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.07573\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Just-In-Time Software Defect Prediction via Bi-modal Change Representation Learning\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.12107\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DFEPT: Data Flow Embedding for Enhancing Pre-Trained Model Based Vulnerability Detection\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.18479\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Utilizing Precise and Complete Code Context to Guide LLM in Automatic False Positive Mitigation\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.03079\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Smart-LLaMA: Two-Stage Post-Training of Large Language Models for Smart Contract Vulnerability Detection and Explanation\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.06221\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"FlexFL: Flexible and Effective Fault Localization with Open-Source Large Language Models\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.10714\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Breaking the Cycle of Recurring Failures: Applying Generative AI to Root Cause Analysis in Legacy Banking Systems\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.13017\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Are Large Language Models Memorizing Bug Benchmarks?\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.13323\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Empirical Study of Vulnerability Detection using Federated Learning\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.16099\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Fault Localization from the Semantic Code Search Perspective\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.17230\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Applying Contrastive Learning to Code Vulnerability Type Classification\" [2024-11] [EMNLP 2024] [\u003ca href=\"https://aclanthology.org/2024.emnlp-main.666/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing IR-based Fault Localization using Large Language Models\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.03754\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can LLM Prompting Serve as a Proxy for Static Analysis in Vulnerability Detection\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.12039\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Large Language Model Approach to Identify Flakiness in C++ Projects\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.12340\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on Method-Level Code Smell Detection\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.13801\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Closing the Gap: A User Study on the Real-world Usefulness of AI-powered Vulnerability Detection \u0026amp; Repair in the IDE\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.14306\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models and Code Security: A Systematic Literature Review\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.15004\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Vulnerability Detection in Popular Programming Languages with Language Models\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.15905\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.18260\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Impact of Input Order Bias on Large Language Models for Software Fault Localization\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.18750\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CGP-Tuning: Structure-Aware Soft Prompt Tuning for Code Vulnerability Detection\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.04510\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automating the Detection of Code Vulnerabilities by Analyzing GitHub Issues\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.05258\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Improved IR-based Bug Localization with Intelligent Relevance Feedback\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.10542\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Assessing Large Language Models in Comprehending and Verifying Concurrent Programs across Memory Models\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.14326\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RepoAudit: An Autonomous LLM-Agent for Repository-Level Code Auditing\" [2025-01] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2501.18160\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Streamlining Security Vulnerability Triage with Large Language Models\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.18908\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"COSMosFL: Ensemble of Small Language Models for Fault Localisation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.02908\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models for In-File Vulnerability Localization Can Be \"Lost in the End\"\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.06898\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Where's the Bug? Attention Probing for Scalable Fault Localization\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.13966\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Bridging Bug Localization and Issue Fixing: A Hierarchical Localization Framework Leveraging Large Language Models\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.15292\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Contemporary Survey of Large Language Model Assisted Program Analysis\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.18474\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Beyond Natural Language Perplexity: Detecting Dead Code Poisoning in Code Generation Datasets\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.20246\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Benchmarking LLMs and LLM-based Agents in Practical Vulnerability Detection for Code Repositories\" [2025-03] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2503.03586\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LocAgent: Graph-Guided LLM Agents for Code Localization\" [2025-03] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2503.09089\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"HALURust: Exploiting Hallucinations of Large Language Models to Detect Vulnerabilities in Rust\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.10793\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CoSIL: Software Issue Localization via LLM-Driven Code Repository Graph Searching\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.22424\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How Accurately Do Large Language Models Understand Code?\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.04372\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Program Semantic Inequivalence Game with Large Language Models\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.03818\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Preliminary Study of Large Language Models for Multilingual Vulnerability Detection\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.07376\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Learning to Focus: Context Extraction for Efficient Code Vulnerability Detection with Language Models\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.17460\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.07390\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MLDebugging: Towards Benchmarking Code Debugging Across Multi-Library Scenarios\" [2025-06] [ACL 2025 Findings] [\u003ca href=\"https://www.arxiv.org/abs/2506.13824\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Smart-LLaMA-DPO: Reinforced Large Language Model for Explainable Smart Contract Vulnerability Detection\" [2025-06] [ISSTA 2025] [\u003ca href=\"https://arxiv.org/abs/2506.18245\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Black-Box Test Code Fault Localization Driven by Large Language Models and Execution Estimation\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.19045\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CLeVeR: Multi-modal Contrastive Learning for Vulnerability Code Representation\" [2025-07] [ACL 2025 Findings] [\u003ca href=\"https://aclanthology.org/2025.findings-acl.414/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code-SPA: Style Preference Alignment to Large Language Models for Effective and Robust Code Debugging\" [2025-07] [ACL 2025 Findings] [\u003ca href=\"https://aclanthology.org/2025.findings-acl.912/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLaVul: A Multimodal LLM for Interpretable Vulnerability Reasoning about Source Code\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.17337\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Improving Code Localization with Repository Memory\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.01003\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Vul-R2: A Reasoning LLM for Automated Vulnerability Repair\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.05480\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eMalicious Code Detection\u003c/h3\u003e\u003ca id=\"user-content-malicious-code-detection\" class=\"anchor\" aria-label=\"Permalink: Malicious Code Detection\" href=\"#malicious-code-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"I-MAD: Interpretable Malware Detector Using Galaxy Transformer\", 2019-09, Comput. Secur. 2021, [\u003ca href=\"https://arxiv.org/abs/1909.06865\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Malbert: A novel pre-training method for malware detection\", 2021-09, Comput. Secur. 2021, [\u003ca href=\"https://www.sciencedirect.com/science/article/pii/S0167404821002820\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Single-Shot Black-Box Adversarial Attacks Against Malware Detectors: A Causal Language Model Approach\", 2021-12, ISI 2021, [\u003ca href=\"https://arxiv.org/abs/2112.01724\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"M2VMapper: Malware-to-Vulnerability mapping for Android using text processing\", 2021-12, Expert Syst. Appl. 2022, [\u003ca href=\"https://www.sciencedirect.com/science/article/pii/S0957417421016572\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Ensemble of Pre-trained Transformer Models For Imbalanced Multiclass Malware Classification\", 2021-12, Comput. Secur. 2022, [\u003ca href=\"https://arxiv.org/abs/2112.13236\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Static Malware Detection Using Stacked BiLSTM and GPT-2\", 2022-05, IEEE Access 2022, [\u003ca href=\"https://ieeexplore.ieee.org/document/9785789\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"APT Malicious Sample Organization Traceability Based on Text Transformer Model\", 2022-07, PRML 2022, [\u003ca href=\"https://ieeexplore.ieee.org/document/9882232\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Self-Supervised Vision Transformers for Malware Detection\", 2022-08, IEEE Access 2022, [\u003ca href=\"https://arxiv.org/abs/2208.07049\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Survey of Recent Advances in Deep Learning Models for Detecting Malware in Desktop and Mobile Platforms\", 2022-09, ACM Computing Surveys, [\u003ca href=\"https://dl.acm.org/doi/abs/10.1145/3638240\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Malicious Source Code Detection Using Transformer\", 2022-09, [\u003ca href=\"https://arxiv.org/abs/2209.07957\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MalBERTv2: Code Aware BERT-Based Model for Malware Identification\" [2023-03] [Big Data Cogn. Comput. 2023] [\u003ca href=\"https://www.mdpi.com/2504-2289/7/2/60\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"GPThreats-3: Is Automatic Malware Generation a Threat?\" [2023-05] [SPW 2023] [\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/10188649\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"GitHub Copilot: A Threat to High School Security? Exploring GitHub Copilot's Proficiency in Generating Malware from Simple User Prompts\" [2023-08] [ETNCC 2023] [\u003ca href=\"https://ieeexplore.ieee.org/abstract/document/10284976\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Attackers Dream? Exploring the Capabilities of ChatGPT for Developing Malware\" [2023-08] [CSET 2023] [\u003ca href=\"https://dl.acm.org/doi/abs/10.1145/3607505.3607513\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Malicious code detection in android: the role of sequence characteristics and disassembling methods\" [2023-12] [Int. J. Inf. Sec. 2023] [\u003ca href=\"https://arxiv.org/abs/2312.01113\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4\" [2023-12] [\u003ca href=\"https://arxiv.org/abs/2312.08317\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Shifting the Lens: Detecting Malware in npm Ecosystem with Large Language Models\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.12196\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AppPoet: Large Language Model based Android malware detection via multi-view prompt engineering\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.18816\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Tactics, Techniques, and Procedures (TTPs) in Interpreted Malware: A Zero-Shot Generation with Large Language Models\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.08532\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DetectBERT: Towards Full App-Level Representation Learning to Detect Android Malware\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.16353\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"PackageIntel: Leveraging Large Language Models for Automated Intelligence Extraction in Package Ecosystems\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.15049\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AgentDroid: A Multi-Agent Framework for Detecting Fraudulent Android Applications\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.12163\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Model (LLM) for Software Security: Code Analysis, Malware Analysis, Reverse Engineering\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.07137\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCompiler Optimization\u003c/h3\u003e\u003ca id=\"user-content-compiler-optimization\" class=\"anchor\" aria-label=\"Permalink: Compiler Optimization\" href=\"#compiler-optimization\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Learning Performance-Improving Code Edits\" [2023-06] [ICLR 2024 Spotlight] [\u003ca href=\"https://arxiv.org/abs/2302.07867\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models for Compiler Optimization\" [2023-09] [\u003ca href=\"https://arxiv.org/abs/2309.07062\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Refining Decompiled C Code with Large Language Models\" [2023-10] [\u003ca href=\"https://arxiv.org/abs/2310.06530\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Priority Sampling of Large Language Models for Compilers\" [2024-02] [\u003ca href=\"https://arxiv.org/abs/2402.18734\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Should AI Optimize Your Code? A Comparative Study of Current Large Language Models Versus Classical Optimizing Compilers\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.12146\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Iterative or Innovative? A Problem-Oriented Perspective for Code Optimization\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.11935\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Meta Large Language Model Compiler: Foundation Models of Compiler Optimization\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2407.02524\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ViC: Virtual Compiler Is All You Need For Assembly Code Search\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.06385\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Search-Based LLMs for Code Optimization\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.12159\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"E-code: Mastering Efficient Code Generation through Pretrained Models and Expert Encoder Group\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.12948\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models for Energy-Efficient Code: Emerging Results and Future Directions\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.09241\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly\" [2024-11] [EMNLP 2024 Findings] [\u003ca href=\"https://aclanthology.org/2024.findings-emnlp.55/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards LLM-based optimization compilers. Can LLMs learn how to apply a single peephole optimization? Reasoning is all LLMs need!\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.12163\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can LLMs Obfuscate Code? A Systematic Analysis of Large Language Models into Assembly Code Obfuscation\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.16135\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Finding Missed Code Size Optimizations in Compilers using LLMs\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2501.00655\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Optimizing Code Runtime Performance through Context-Aware Retrieval-Augmented Generation\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.16692\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"VecTrans: LLM Transformation Framework for Better Auto-vectorization on High-performance CPU\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.19449\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Improving Assembly Code Performance with Large Language Models via Reinforcement Learning\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.11480\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Autocomp: LLM-Driven Code Optimization for Tensor Accelerators\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.18574\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.14111\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Speed Up Your Code: Progressive Code Acceleration Through Bidirectional Tree Editing\" [2025-07] [ACL 2025] [\u003ca href=\"https://aclanthology.org/2025.acl-long.1387/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ECO: Enhanced Code Optimization via Performance-Aware Prompting for Code-LLMs\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.10517\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eBinary Analysis and Decompilation\u003c/h3\u003e\u003ca id=\"user-content-binary-analysis-and-decompilation\" class=\"anchor\" aria-label=\"Permalink: Binary Analysis and Decompilation\" href=\"#binary-analysis-and-decompilation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Using recurrent neural networks for decompilation\" [2018-03] [SANER 2018] [\u003ca href=\"https://ieeexplore.ieee.org/document/8330222\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evolving Exact Decompilation\" [2018] [\u003ca href=\"https://eschulte.github.io/data/bed.pdf\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards Neural Decompilation\" [2019-05] [\u003ca href=\"https://arxiv.org/abs/1905.08325\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Coda: An End-to-End Neural Program Decompiler\" [2019-06] [NeurIPS 2019] [\u003ca href=\"https://arxiv.org/abs/1906.12029\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"N-Bref : A High-fidelity Decompiler Exploiting Programming Structures\" [2020-09] [\u003ca href=\"https://openreview.net/forum?id=6GkL6qM3LV\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Neutron: an attention-based neural decompiler\" [2021-03] [Cybersecurity 2021] [\u003ca href=\"https://cybersecurity.springeropen.com/articles/10.1186/s42400-021-00070-0\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Beyond the C: Retargetable Decompilation using Neural Machine Translation\" [2022-12] [\u003ca href=\"https://arxiv.org/abs/2212.08950\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Boosting Neural Networks to Decompile Optimized Binaries\" [2023-01] [ACSAC 2022] [\u003ca href=\"https://arxiv.org/abs/2301.00969\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SLaDe: A Portable Small Language Model Decompiler for Optimized Assembly\" [2023-05] [\u003ca href=\"https://arxiv.org/abs/2305.12520\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Nova: Generative Language Models for Assembly Code with Hierarchical Attention and Contrastive Learning\" [2023-11] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2311.13721\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeArt: Better Code Models by Attention Regularization When Symbols Are Lacking\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2402.11842\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM4Decompile: Decompiling Binary Code with Large Language Models\" [2024-03] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2403.05286\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"WaDec: Decompile WebAssembly Using Large Language Model\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.11346\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MAD: Move AI Decompiler to Improve Transparency and Auditability on Non-Open-Source Blockchain Smart Contract\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.15275\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Source Code Foundation Models are Transferable Binary Analysis Knowledge Bases\" [2024-11] [NeurIPS 2024] [\u003ca href=\"https://arxiv.org/abs/2405.19581\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Progressive Transformer for Unifying Binary Code Embedding and Knowledge Transfer\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.11177\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Augmenting Smart Contract Decompiler Output through Fine-grained Dependency Analysis and LLM-facilitated Semantic Recovery\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.08670\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Idioms: Neural Decompilation With Joint Code and Type Prediction\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.04536\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can Large Language Models Understand Intermediate Representations?\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.06854\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"On the Role of Pre-trained Embeddings in Binary Code Analysis\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.08682\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Control Flow-Augmented Decompiler based on Large Language Model\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.07215\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ASMA-Tune: Unlocking LLMs' Assembly Code Comprehension via Structural-Semantic Instruction Tuning\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.11617\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"BinMetric: A Comprehensive Binary Analysis Benchmark for Large Language Models\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.07360\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCommit Message Generation\u003c/h3\u003e\u003ca id=\"user-content-commit-message-generation\" class=\"anchor\" aria-label=\"Permalink: Commit Message Generation\" href=\"#commit-message-generation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automated Commit Message Generation with Large Language Models: An Empirical Study and Beyond\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.14824\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards Realistic Evaluation of Commit Message Generation by Matching Online and Offline Settings\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.12046\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Optimization is Better than Generation: Optimizing Commit Message Leveraging Human-written Commit Message\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.09861\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Empirical Study on Commit Message Generation using LLMs via In-Context Learning\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.18904\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Consider What Humans Consider: Optimizing Commit Message Leveraging Contexts Considered By Human\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.11960\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating Generated Commit Messages with Large Language Models\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.10906\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CoRaCMG: Contextual Retrieval-Augmented Framework for Commit Message Generation\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.18337\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCode Review\u003c/h3\u003e\u003ca id=\"user-content-code-review\" class=\"anchor\" aria-label=\"Permalink: Code Review\" href=\"#code-review\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Using Pre-Trained Models to Boost Code Review Automation\" [2022-01] [ICSE 2022] [\u003ca href=\"https://arxiv.org/abs/2201.06850\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AUGER: Automatically Generating Review Comments with Pre-training Models\" [2022-08] [ESEC/FSE 2022] [\u003ca href=\"https://arxiv.org/abs/2208.08014\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automatic Code Review by Learning the Structure Information of Code Graph\" [2023-02] [Sensors] [\u003ca href=\"https://www.mdpi.com/1424-8220/23/5/2551\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLaMA-Reviewer: Advancing Code Review Automation with Large Language Models through Parameter-Efficient Fine-Tuning\" [2023-08] [ISSRE 2023] [\u003ca href=\"https://arxiv.org/abs/2308.11148\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeAgent: Autonomous Communicative Agents for Code Review\" [2024-02] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2402.02172\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AI-powered Code Review with LLMs: Early Results\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.18496\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AI-Assisted Assessment of Coding Practices in Modern Code Review\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.13565\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A GPT-based Code Review System for Programming Language Learning\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.04722\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM Critics Help Catch LLM Bugs\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2407.00215\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Exploring the Capabilities of LLMs for Code Change Related Tasks\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.02824\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating Language Models for Generating and Judging Programming Feedback\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.04873\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can LLMs Replace Manual Annotation of Software Engineering Artifacts?\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.05534\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Leveraging Reviewer Experience in Code Review Comment Generation\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.10959\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CRScore: Grounding Automated Evaluation of Code Review Comments in Code Claims and Smells\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.19801\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Code Annotation Reliability: Generative AI's Role in Comment Quality Assessment Models\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.22323\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Knowledge-Guided Prompt Learning for Request Quality Assurance in Public Code Review\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.21673\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Impact of LLM-based Review Comment Generation in Practice: A Mixed Open-/Closed-source User Study\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.07091\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.10129\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Deep Learning-based Code Reviews: A Paradigm Shift or a Double-Edged Sword?\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.11401\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Redefining Crowdsourced Test Report Prioritization: An Innovative Approach with Large Language Model\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.17045\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Exploring the Potential of Llama Models in Automated Code Refinement: A Replication Study\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.02789\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automated Code Review In Practice\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.18531\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Review Automation Via Multi-task Federated LLM -- An Empirical Study\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.15676\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DeepCRCEval: Revisiting the Evaluation of Code Review Comment Generation\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.18291\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Distilling Desired Comments for Enhanced Code Review with Large Language Models\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.20340\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Deep Assessment of Code Review Generation Approaches: Beyond Lexical Similarity\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.05176\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Debugging Without Error Messages: How LLM Prompting Strategy Affects Programming Error Explanation Effectiveness\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.05706\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"I Can Find You in Seconds! Leveraging Large Language Models for Code Authorship Attribution\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.08165\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Change Intention, Development Artifact and History Vulnerability: Putting Them Together for Vulnerability Fix Detection by LLM\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.14983\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"BitsAI-CR: Automated Code Review via LLM in Practice\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.15134\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Model Critics for Execution-Free Evaluation of Code Changes\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.16655\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Too Noisy To Learn: Enhancing Data Quality for Code Review C\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.02757\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Harnessing Large Language Models for Curated Code Reviews\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.03425\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Combining Large Language Models with Static Analyzers for Code Review Generation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.06633\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automating Code Review: A Systematic Literature Review\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.09510\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards Practical Defect-Focused Automated Code Review\" [2025-05] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2505.17928\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CRScore++: Reinforcement Learning with Verifiable Tool and AI Feedback for Code Review\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2506.00296\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Fine-Tuning Multilingual Language Models for Code Review: An Empirical Study on Industrial C# Projects\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.19271\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.14856\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Fine-Tuning LLMs to Analyze Multiple Dimensions of Code Review: A Maximum Entropy Regulated Long Chain-of-Thought Approach\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.21170\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eLog Analysis\u003c/h3\u003e\u003ca id=\"user-content-log-analysis\" class=\"anchor\" aria-label=\"Permalink: Log Analysis\" href=\"#log-analysis\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LogStamp: Automatic Online Log Parsing Based on Sequence Labelling\" [2022-08] [\u003ca href=\"https://arxiv.org/abs/2208.10282\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Log Parsing with Prompt-based Few-shot Learning\" [2023-02] [ICSE 2023] [\u003ca href=\"https://arxiv.org/abs/2302.07435\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Log Parsing: How Far Can ChatGPT Go?\" [2023-06] [ASE 2023] [\u003ca href=\"https://arxiv.org/abs/2306.01590\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis\" [2023-08] [\u003ca href=\"https://arxiv.org/abs/2308.07610\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection\" [2023-09] [\u003ca href=\"https://arxiv.org/abs/2309.01189\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Assessment of ChatGPT on Log Data\" [2023-09] [\u003ca href=\"https://arxiv.org/abs/2309.07938\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LILAC: Log Parsing using LLMs with Adaptive Parsing Cache\" [2023-10] [\u003ca href=\"https://arxiv.org/abs/2310.01796\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLMParser: An Exploratory Study on Using Large Language Models for Log Parsing\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.18001\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"On the Influence of Data Resampling for Deep Learning-Based Log Anomaly Detection: Insights and Recommendations\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.03489\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Log Parsing with Self-Generated In-Context Learning and Self-Correction\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.03376\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Stronger, Faster, and Cheaper Log Parsing with LLMs\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.06156\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ULog: Unsupervised Log Parsing with Large Language Models through Log Contrastive Units\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.07174\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Anomaly Detection on Unstable Logs with GPT Models\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.07467\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LogParser-LLM: Advancing Efficient Log Parsing with Large Language Models\" [2024-08] [KDD 2024] [\u003ca href=\"https://arxiv.org/abs/2408.13727\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LUK: Empowering Log Understanding with Expert Knowledge from Large Language Models\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.01909\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Comparative Study on Large Language Models for Log Parsing\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.02474\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"What Information Contributes to Log-based Anomaly Detection? Insights from a Configurable Transformer-Based Approach\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2409.20503\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LogLM: From Task-based to Instruction-based Automated Log Analysis\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.09352\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LogLLM: Log-based Anomaly Detection Using Large Language Models\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.08561\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Adapting Large Language Models to Log Analysis with Interpretable Domain Knowledge\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.01377\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Chatting with Logs: An exploratory study on Finetuning LLMs for LogQL\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.03612\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LogBabylon: A Unified Framework for Cross-Log File Integration and Analysis\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.12364\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AdaptiveLog: An Adaptive Log Analysis Framework with the Collaboration of Large and Small Language Model\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.11031\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Explaining GitHub Actions Failures with Large Language Models: Challenges, Insights, and Limitations\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.16495\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSoftware Configuration\u003c/h3\u003e\u003ca id=\"user-content-software-configuration\" class=\"anchor\" aria-label=\"Permalink: Software Configuration\" href=\"#software-configuration\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Configuration Validation with Large Language Models\" [2023-10] [\u003ca href=\"https://arxiv.org/abs/2310.09690\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CloudEval-YAML: A Practical Benchmark for Cloud Configuration Generation\" [2023-11] [\u003ca href=\"https://arxiv.org/abs/2401.06786\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can LLMs Configure Software Tools\" [2023-12] [\u003ca href=\"https://arxiv.org/abs/2312.06121\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LuaTaint: A Static Analysis System for Web Configuration Interface Vulnerability of Internet of Things Devices\" [2024-02] [IOT] [\u003ca href=\"https://arxiv.org/abs/2402.16043\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM-Based Misconfiguration Detection for AWS Serverless Computing\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.00642\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Leveraging LLM Agents for Translating Network Configurations\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.08760\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Raiders of the Lost Dependency: Fixing Dependency Conflicts in Python using LLMs\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.16191\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enabling Autonomic Microservice Management through Self-Learning Agents\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.19056\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLMSecConfig: An LLM-Based Approach for Fixing Software Container Misconfigurations\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.02009\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An LLM-based Agent for Reliable Docker Environment Configuration\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.13681\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automated Benchmark Generation for Repository-Level Coding Tasks\" [2025-03] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2503.07701\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"BYOS: Knowledge-driven Large Language Models Bring Your Own Operating System More Excellent\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.09663\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"EnvBench: A Benchmark for Automated Environment Setup\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.14443\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Prompting for Performance: Exploring LLMs for Configuring Software\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.09790\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.25248\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCode QA \u0026amp; Reasoning\u003c/h3\u003e\u003ca id=\"user-content-code-qa--reasoning\" class=\"anchor\" aria-label=\"Permalink: Code QA \u0026amp; Reasoning\" href=\"#code-qa--reasoning\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DialogAgent: An Auto-engagement Agent for Code Question Answering Data Production\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.08069\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Unveiling the Magic of Code Reasoning through Hypothesis Decomposition and Amendment\" [2025-02] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2502.13170\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeReviewQA: The Code Review Comprehension Assessment for Large Language Models\" [2025-03] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2503.16167\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating the Generalization Capabilities of Large Language Models on Code Reasoning\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.05518\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Code Barrier: What LLMs Actually Understand?\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.10557\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can Large Language Models Predict Parallel Code Performance?\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.03988\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LongCodeBench: Evaluating Coding LLMs at 1M Context Windows\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.07897\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Do Code LLMs Do Static Analysis?\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.12118\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Sense and Sensitivity: Examining the Influence of Semantic Recall on Long Context Code Reasoning\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.13353\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MARCO: Meta-Reflection with Cross-Referencing for Code Reasoning\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.17481\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Complex Logical Instruction Generation\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.09125\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Regression Language Models for Code\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.26476\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"When Names Disappear: Revealing What LLMs Actually Understand About Code\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.03178\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MEC3O: Multi-Expert Consensus for Code Time Complexity Prediction\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.09049\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSoftware Modeling\u003c/h3\u003e\u003ca id=\"user-content-software-modeling\" class=\"anchor\" aria-label=\"Permalink: Software Modeling\" href=\"#software-modeling\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards using Few-Shot Prompt Learning for Automating Model Completion\" [2022-12] [\u003ca href=\"https://arxiv.org/abs/2212.03404\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Model Generation from Requirements with LLMs: an Exploratory Study\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.06371\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How LLMs Aid in UML Modeling: An Exploratory Study with Novice Analysts\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.17739\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Leveraging Large Language Models for Software Model Completion: Results from Industrial and Public Datasets\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.17651\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Studying and Benchmarking Large Language Models For Log Level Suggestion\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.08499\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Model Is Not Built By A Single Prompt: LLM-Based Domain Modeling With Question Decomposition\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.09854\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"On the Utility of Domain Modeling Assistance with Large Language Models\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.12577\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"On the use of Large Language Models in Model-Driven Engineering\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.17370\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM as a code generator in Agile Model Driven Development\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.18489\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Assessing UML Models by ChatGPT: Implications for Education\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.17200\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eRequirement Engineering\u003c/h3\u003e\u003ca id=\"user-content-requirement-engineering\" class=\"anchor\" aria-label=\"Permalink: Requirement Engineering\" href=\"#requirement-engineering\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Transformer-based Approach for Abstractive Summarization of Requirements from Obligations in Software Engineering Contracts\" [2023-09] [RE 2023] [\u003ca href=\"https://ieeexplore.ieee.org/document/10260954\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Advancing Requirements Engineering through Generative AI: Assessing the Role of LLMs\" [2023-10] [\u003ca href=\"https://arxiv.org/abs/2310.13976\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Requirements Engineering using Generative AI: Prompts and Prompting Patterns\" [2023-11] [\u003ca href=\"https://arxiv.org/abs/2311.03832\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Prioritizing Software Requirements Using Large Language Models\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2405.01564\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Lessons from the Use of Natural Language Inference (NLI) in Requirements Engineering Tasks\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2405.05135\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Legal Compliance and Regulation Analysis with Large Language Models\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.17522\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MARE: Multi-Agents Collaboration Framework for Requirements Engineering\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.03256\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Natural Language Processing for Requirements Traceability\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.10845\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Multilingual Crowd-Based Requirements Engineering Using Large Language Models\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.06505\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"From Specifications to Prompts: On the Future of Generative LLMs in Requirements Engineering\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.09127\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Leveraging LLMs for the Quality Assurance of Software Requirements\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.10886\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Generative AI for Requirements Engineering: A Systematic Literature Review\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.06741\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Fine-grained Sentiment Analysis of App Reviews using Large Language Models: An Evaluation Study\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.07162\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Leveraging Large Language Models for Predicting Cost and Duration in Software Engineering Projects\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.09617\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Privacy Policy Analysis through Prompt Engineering for LLMs\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.14879\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Exploring Requirements Elicitation from App Store User Reviews Using Large Language Models\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.15473\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM-Cure: LLM-based Competitor User Review Analysis for Feature Enhancement\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.15724\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automatic Instantiation of Assurance Cases from Patterns Using Large Language Models\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.05488\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Whose fault is it anyway? SILC: Safe Integration of LLM-Generated Code\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.18703\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Assured Automatic Programming via Large Language Models\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.18494\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Does GenAI Make Usability Testing Obsolete?\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.00634\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Exploring LLMs for Verifying Technical System Specifications Against Requirements\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.11582\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards the LLM-Based Generation of Formal Specifications from Natural-Language Contracts: Early Experiments with Symboleo\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.15898\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"PassionNet: An Innovative Framework for Duplicate and Conflicting Requirements Identification\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.01657\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Generative Language Models Potential for Requirement Engineering Applications: Insights into Current Strengths and Limitations\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.00959\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LicenseGPT: A Fine-tuned Foundation Model for Publicly Available Dataset License Compliance\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2501.00106\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"On the Impact of Requirements Smells in Prompts: The Case of Automated Traceability\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.04810\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Analysis of LLMs vs Human Experts in Requirements Engineering\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.19297\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e6. Analysis of AI-Generated Code\u003c/h2\u003e\u003ca id=\"user-content-6-analysis-of-ai-generated-code\" class=\"anchor\" aria-label=\"Permalink: 6. Analysis of AI-Generated Code\" href=\"#6-analysis-of-ai-generated-code\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eSecurity and Vulnerabilities\u003c/h3\u003e\u003ca id=\"user-content-security-and-vulnerabilities\" class=\"anchor\" aria-label=\"Permalink: Security and Vulnerabilities\" href=\"#security-and-vulnerabilities\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion\" [2021-08] [USENIX Security Symposium 2021] [\u003ca href=\"https://www.usenix.org/conference/usenixsecurity21/presentation/schuster\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Is GitHub's Copilot as Bad as Humans at Introducing Vulnerabilities in Code?\" [2022-04] [Empir. Softw. Eng.] [\u003ca href=\"https://arxiv.org/abs/2204.04741\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Lost at C: A User Study on the Security Implications of Large Language Model Code Assistants\" [2022-08] [USENIX Security Symposium 2023] [\u003ca href=\"https://arxiv.org/abs/2208.09727\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Do Users Write More Insecure Code with AI Assistants?\" [2022-1] [CCS 2023] [\u003ca href=\"https://arxiv.org/abs/2211.03622\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models for Code: Security Hardening and Adversarial Testing\" [2023-02] [CCS 2023] [\u003ca href=\"https://arxiv.org/abs/2302.05319\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Purple Llama CyberSecEval: A Secure Coding Benchmark for Language Models\" [2023-12] [\u003ca href=\"https://arxiv.org/abs/2312.04724\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeAttack: Revealing Safety Generalization Challenges of Large Language Models via Code Completion\" [2024-03] [ACL 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2403.07865\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Just another copy and paste? Comparing the security vulnerabilities of ChatGPT generated code and StackOverflow answers\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.15600\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DeVAIC: A Tool for Security Assessment of AI-generated Code\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.07548\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CyberSecEval 2: A Wide-Ranging Cybersecurity Evaluation Suite for Large Language Models\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.13161\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLMs in Web-Development: Evaluating LLM-Generated PHP code unveiling vulnerabilities and limitations\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.14459\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Do Neutral Prompts Produce Insecure Code? FormAI-v2 Dataset: Labelling Vulnerabilities in Code Generated by Large Language Models\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.18353\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Codexity: Secure AI-assisted Code Generation\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.03927\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Measuring Impacts of Poisoning on Model Parameters and Embeddings for Large Language Models of Code\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.11466\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.06822\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Is Your AI-Generated Code Really Secure? Evaluating Large Language Models on Secure Code Generation with CodeSecEval\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.02395\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Prompting Techniques for Secure Code Generation: A Systematic Investigation\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.07064\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"TAPI: Towards Target-Specific and Adversarial Prompt Injection against Code LLMs\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.09164\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MaPPing Your Model: Assessing the Impact of Adversarial Attacks on LLM-based Programming Assistants\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.11072\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Black-Box Adversarial Attacks on LLM-Based Code Completion\" [2024-08] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2408.02509\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Eliminating Backdoors in Neural Code Models via Trigger Inversion\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.04683\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"\"You still have to study\" -- On the Security of LLM generated code\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.07106\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How Well Do Large Language Models Serve as End-to-End Secure Code Producers?\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.10495\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"While GitHub Copilot Excels at Coding, Does It Ensure Responsible Output?\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.11006\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"PromSec: Prompt Optimization for Secure Generation of Functional Source Code with Large Language Models (LLMs)\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.12699\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RMCBench: Benchmarking Large Language Models' Resistance to Malicious Code\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.15154\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Artificial-Intelligence Generated Code Considered Harmful: A Road Map for Secure and High-Quality Code Generation\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.19182\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SecCoder: Towards Generalizable and Robust Secure Code Generation\" [2024-10] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2410.01488\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Demonstration Attack against In-Context Learning for Code Intelligence\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.02841\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Hallucinating AI Hijacking Attack: Large Language Models and Malicious Code Recommenders\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.06462\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SecCodePLT: A Unified Platform for Evaluating the Security of Code GenAI\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.11096\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Security of Language Models for Code: A Systematic Literature Review\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.15631\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RedCode: Risky Code Execution and Generation Benchmark for Code Agents\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.07781\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ProSec: Fortifying Code LLMs with Proactive Security Alignment\" [2024-11] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2411.12882\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.18216\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SABER: Model-agnostic Backdoor Attack on Chain-of-Thought in Neural Code Generation\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.05829\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CWEval: Outcome-driven Evaluation on Functionality and Security of LLM Code Generation\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.08200\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Security and Quality in LLM-Generated Code: A Multi-Language, Multi-Model Analysis\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.01853\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Exploring the Security Threats of Knowledge Base Poisoning in Retrieval-Augmented Code Generation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.03233\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Benchmarking Prompt Engineering Techniques for Secure Code Generation with GPT Models\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.06039\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Do LLMs Consider Security? An Empirical Study on Responses to Programming Questions\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.14202\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"XOXO: Stealthy Cross-Origin Context Poisoning Attacks against AI Coding Assistants\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.14281\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Comprehensive Study of LLM Secure Code Generation\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.15554\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Smoke and Mirrors: Jailbreaking LLM-based Code Generation via Implicit Malicious Prompts\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.17953\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge Injection\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.16429\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can You Really Trust Code Copilots? Evaluating Large Language Models from a Code Security Perspective\" [2025-05] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2505.10494\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Teaching an Old LLM Secure Coding: Localized Preference Optimization on Distilled Preferences\" [2025-05] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2506.00419\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.05692\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"PurpCode: Reasoning for Safer Code Generation\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.19060\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RedCoder: Automated Multi-Turn Red Teaming for Code LLMs\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2507.22063\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A.S.E: A Repository-Level Benchmark for Evaluating Security in AI-Generated Code\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.18106\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Localizing Malicious Outputs from CodeLLM\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.17070\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"SecureAgentBench: Benchmarking Secure Code Generation under Realistic Vulnerability Scenarios\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.22097\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Breaking the Code: Security Assessment of AI Code Agents Through Systematic Jailbreaking Attacks\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.01359\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"When \"Correct\" Is Not Safe: Can We Trust Functionally Correct Patches Generated by Code Agents?\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.17862\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCorrectness\u003c/h3\u003e\u003ca id=\"user-content-correctness\" class=\"anchor\" aria-label=\"Permalink: Correctness\" href=\"#correctness\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Empirical Evaluation of GitHub Copilot's Code Suggestions\" [2022-05] [MSR 2022] [\u003ca href=\"https://ieeexplore.ieee.org/document/9796235\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models and Simple, Stupid Bugs\" [2023-03] [MSR 2023] [\u003ca href=\"https://arxiv.org/abs/2303.11455\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating the Code Quality of AI-Assisted Code Generation Tools: An Empirical Study on GitHub Copilot, Amazon CodeWhisperer, and ChatGPT\" [2023-04] [\u003ca href=\"https://arxiv.org/abs/2304.10778\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"No Need to Lift a Finger Anymore? Assessing the Quality of Code Generation by ChatGPT\" [2023-08] [\u003ca href=\"https://arxiv.org/abs/2308.04838\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?\" [2024-02] [ACL 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2402.19475\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Bugs in Large Language Models Generated Code: An Empirical Study\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.08937\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ChatGPT Incorrectness Detection in Software Reviews\" [2024-03] [\u003ca href=\"https://arxiv.org/abs/2403.16347\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Validating LLM-Generated Programs with Metamorphic Prompt Testing\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.06864\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Where Do Large Language Models Fail When Generating Code?\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.08731\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"GitHub Copilot: the perfect Code compLeeter?\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.11326\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"What's Wrong with Your Code Generated by Large Language Models? An Extensive Study\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.06153\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Uncovering Weaknesses in Neural Code Generation\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.09793\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Understanding Defects in Generated Codes by Language Models\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.13372\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeSift: An LLM-Based Reference-Less Framework for Automatic Code Validation\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.15630\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Examination of Code generated by Large Language Models\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.16601\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Fixing Code Generation Errors for Large Language Models\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.00676\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can OpenSource beat ChatGPT? -- A Comparative Study of Large Language Models for Text-to-Code Generation\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.04164\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Insights from Benchmarking Frontier Language Models on Web App Code Generation\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.05177\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating the Performance of Large Language Models in Competitive Programming: A Multi-Year, Multi-Grade Analysis\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.09054\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Case Study of Web App Coding with OpenAI Reasoning Models\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.13773\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An evaluation of LLM code generation capabilities through graded exercises\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.16292\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Deep Dive Into Large Language Model Code Generation Mistakes: What and Why?\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.01414\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating ChatGPT-3.5 Efficiency in Solving Coding Problems of Different Complexity Levels: An Empirical Analysis\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.07529\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM4DS: Evaluating Large Language Models for Data Science Code Generation\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.11908\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Preliminary Study of Multilingual Code Language Models for Code Generation Task Using Translated Benchmarks\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.15470\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Analyzing the Energy and Accuracy of LLMs in Software Development\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2412.00329\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How Well Do LLMs Generate Code for Different Application Domains? Benchmark and Evaluation\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.18573\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM-ProS: Analyzing Large Language Models' Performance in Competitive Problem Solving\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.04355\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Assessing Correctness in LLM-Based Code Generation via Uncertainty Estimation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.11620\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Performance Evaluation of Large Language Models in Statistical Programming\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.13117\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Unveiling Pitfalls: Understanding Why AI-driven Code Agents Fail at GitHub Issue Resolution\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.12374\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Are \"Solved Issues\" in SWE-bench Really Solved Correctly? An Empirical Study\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.15223\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eHallucination\u003c/h3\u003e\u003ca id=\"user-content-hallucination\" class=\"anchor\" aria-label=\"Permalink: Hallucination\" href=\"#hallucination\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Exploring and Evaluating Hallucinations in LLM-Powered Code Generation\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.00971\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeHalu: Code Hallucinations in LLMs Driven by Execution-based Verification\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2405.00253\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.10279\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Hallucination\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.04831\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"On Mitigating Code LLM Hallucinations with API Documentation\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.09726\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeMirage: Hallucinations in Code Generated by Large Language Models\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.08333\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLM Hallucinations in Practical Code Generation: Phenomena, Mechanism, and Mitigation\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.20550\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Collu-Bench: A Benchmark for Predicting Language Model Hallucinations in Code\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.09997\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ETF: An Entity Tracing Framework for Hallucination Detection in Code Summaries\" [2024-10] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2410.14748\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Hallucination by Code Generation LLMs: Taxonomy, Benchmarks, Mitigation, and Challenges\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.20799\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Hallucinations in Code Change to Natural Language Generation: Prevalence and Evaluation of Detection Metrics\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.08661\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eEfficiency\u003c/h3\u003e\u003ca id=\"user-content-efficiency\" class=\"anchor\" aria-label=\"Permalink: Efficiency\" href=\"#efficiency\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"EffiBench: Benchmarking the Efficiency of Automatically Generated Code\" [2024-02] [NeurIPS 2024] [\u003ca href=\"https://arxiv.org/abs/2402.02037\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Mercury: A Code Efficiency Benchmark for Code Large Language Models\" [2024-02] [NeurIPS 2024] [\u003ca href=\"https://arxiv.org/abs/2402.07844\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"On Evaluating the Efficiency of Source Code Generated by LLMs\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.06041\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Controlled Experiment on the Energy Efficiency of the Source Code Generated by Code Llama\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.03616\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"From Effectiveness to Efficiency: Comparative Evaluation of Code Generated by LCGMs for Bilingual Programming Questions\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.00602\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How Efficient is LLM-Generated Code? A Rigorous \u0026amp; High-Standard Benchmark\" [2024-06] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2406.06647\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?\" [2024-07] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2407.14044\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Performance Study of LLM-Generated Code on Leetcode\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.21579\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating Language Models for Efficient Code Generation\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.06450\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"EffiCoder: Enhancing Code Generation in Large Language Models through Efficiency-Aware Fine-tuning\" [2024-10] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2410.10209\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Rethinking Code Refinement: Learning to Judge Code Efficiency\" [2024-10] [EMNLP 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2410.22375\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Generating Energy-efficient code with LLMs\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.10599\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An exploration of the effect of quantisation on energy consumption and inference time of StarCoder2\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.12758\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ACECode: A Reinforcement Learning Framework for Aligning Code Efficiency and Correctness in Code Language Models\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.17264\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AI-Powered, But Power-Hungry? Energy Efficiency of LLM-Generated Code\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.02412\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Unveiling Inefficiencies in LLM-Generated Code: Toward a Comprehensive Taxonomy\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.06327\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"EffiBench-X: A Multi-Language Benchmark for Measuring Efficiency of LLM-Generated Code\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.13004\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Evaluating the Energy-Efficiency of the Code Generated by LLMs\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.20324\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eRobustness\u003c/h3\u003e\u003ca id=\"user-content-robustness\" class=\"anchor\" aria-label=\"Permalink: Robustness\" href=\"#robustness\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Beyond Accuracy: Evaluating Self-Consistency of Code Large Language Models with IdentityChain\" [2023-10] [\u003ca href=\"https://arxiv.org/abs/2310.14053\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Do Large Code Models Understand Programming Concepts? A Black-box Approach\" [2024-02] [ICML 2024] [\u003ca href=\"https://arxiv.org/abs/2402.05980\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Syntactic Robustness for LLM-based Code Generation\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.01535\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"NLPerturbator: Studying the Robustness of Code LLMs to Natural Language Variations\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.19783\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Empirical Study on Capability of Large Language Models in Understanding Code Semantics\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.03611\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Comparing Robustness Against Adversarial Attacks in Code Generation: LLM-Generated vs. Human-Written\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.10565\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"On the Adversarial Robustness of Instruction-Tuned Large Language Models for Code\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.19508\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"What You See Is Not Always What You Get: An Empirical Study of Code Comprehension by Large Language Models\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.08098\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing the Robustness of LLM-Generated Code: Empirical Study and Framework\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.20197\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CODECRASH: Stress Testing LLM Reasoning under Structural and Semantic Perturbations\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.14119\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Success is in the Details: Evaluate and Enhance Details Sensitivity of Code LLMs through Counterfactuals\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.14597\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Prompt Variability Effects On LLM Code Generation\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.10204\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MOCHA: Are Code Language Models Robust Against Multi-Turn Malicious Coding Prompts?\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.19598\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"When Prompts Go Wrong: Evaluating Code Model Robustness to Ambiguous, Contradictory, and Incomplete Task Descriptions\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.20439\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Prompt Stability in Code LLMs: Measuring Sensitivity across Emotion- and Personality-Driven Variations\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.13680\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eInterpretability\u003c/h3\u003e\u003ca id=\"user-content-interpretability\" class=\"anchor\" aria-label=\"Permalink: Interpretability\" href=\"#interpretability\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Critical Study of What Code-LLMs (Do Not) Learn\" [2024-06] [ACL 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2406.11930\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Looking into Black Box Code Language Models\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.04868\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DeepCodeProbe: Towards Understanding What Models Trained on Code Learn\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.08890\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.08983\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Exploring Coding Spot: Understanding Parametric Contributions to LLM Coding Performance\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.07113\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Correctness Assessment of Code Generated by Large Language Models Using Internal Representations\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.12934\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeSCM: Causal Analysis for Multi-Modal Code Generation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.05150\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Mechanistic Understanding of Language Models in Syntactic Code Completion\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.18499\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"On Explaining (Large) Language Models For Code Using Global Code-Based Explanations\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.16771\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How Programming Concepts and Neurons Are Shared in Code Language Models\" [2025-06] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2506.01074\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Analyzing Latent Concepts in Code Language Models\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.00476\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAPI Usage\u003c/h3\u003e\u003ca id=\"user-content-api-usage\" class=\"anchor\" aria-label=\"Permalink: API Usage\" href=\"#api-usage\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.09834\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Is ChatGPT a Good Software Librarian? An Exploratory Study on the Use of ChatGPT for Software Library Recommendations\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.05128\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Systematic Evaluation of Large Code Models in API Suggestion: When, Which, and How\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.13178\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AutoAPIEval: A Framework for Automated Evaluation of LLMs in API-Oriented Code Generation\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.15228\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ExploraCoder: Advancing code generation for multiple unseen APIs via planning and chained exploration\" [2024-12] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2412.05366\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ADC: Enhancing Function Calling Via Adversarial Datasets and Code Line-Level Feedback\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.17754\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CODESYNC: Synchronizing Large Language Models with Dynamic Code Evolution at Scale\" [2025-02] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2502.16645\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"RustEvo^2: An Evolving Benchmark for API Evolution in LLM-based Rust Code Generation\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.16922\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Identifying and Mitigating API Misuse in Large Language Models\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.22821\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ReCode: Updating Code API Knowledge with Reinforcement Learning\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.20495\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003ePrivacy\u003c/h3\u003e\u003ca id=\"user-content-privacy\" class=\"anchor\" aria-label=\"Permalink: Privacy\" href=\"#privacy\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Does Your Neural Code Completion Model Use My Code? A Membership Inference Approach\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.14296\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeCipher: Learning to Obfuscate Source Code Against LLMs\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.05797\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Decoding Secret Memorization in Code LLMs Through Token-Level Characterization\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.08858\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"When Fine-Tuning LLMs Meets Data Privacy: An Empirical Study of Federated Learning in LLM-Based Program Repair\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.01072\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CallNavi: A Study and Challenge on Function Calling Routing and Invocation in Large Language Models\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.05255\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Mitigating Sensitive Information Leakage in LLMs4Code through Machine Unlearning\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.05739\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards Mitigating API Hallucination in Code Generated by LLMs with Hierarchical Dependency Aware\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.05057\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eBias\u003c/h3\u003e\u003ca id=\"user-content-bias\" class=\"anchor\" aria-label=\"Permalink: Bias\" href=\"#bias\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Exploring Multi-Lingual Bias of Large Code Models in Code Generation\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.19368\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Mitigating Gender Bias in Code Large Language Models via Model Editing\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.07820\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Bias Unveiled: Investigating Social Bias in LLM-Generated Code\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.10351\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"FairCode: Evaluating Social Bias of LLMs in Code Generation\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.05396\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Invisible Hand: Unveiling Provider Bias in Large Language Models for Code Generation\" [2025-01] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2501.07849\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Addressing Popularity Bias in Third-Party Library Recommendations Using LLMs\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.10313\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLMs Love Python: A Study of LLMs' Bias for Programming Languages and Libraries\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.17181\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eContamination\u003c/h3\u003e\u003ca id=\"user-content-contamination\" class=\"anchor\" aria-label=\"Permalink: Contamination\" href=\"#contamination\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Investigating the Impact of Data Contamination of Large Language Models in Text-to-SQL Translation\" [2024-02] [ACL 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2402.08100\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Quantifying Contamination in Evaluating Code Generation Capabilities of Language Models\" [2024-03] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2403.04811\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Rethinking the effects of data contamination in Code Intelligence\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.02791\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAI-Generated Code Detection\u003c/h3\u003e\u003ca id=\"user-content-ai-generated-code-detection\" class=\"anchor\" aria-label=\"Permalink: AI-Generated Code Detection\" href=\"#ai-generated-code-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Who Wrote this Code? Watermarking for Code Generation\" [2023-05] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2305.15060\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Zero-Shot Detection of Machine-Generated Codes\" [2023-10] [\u003ca href=\"https://arxiv.org/abs/2310.05103\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers\" [2024-01] [ICSE 2025] [\u003ca href=\"https://arxiv.org/abs/2401.06461\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code\" [2024-04] [EMNLP 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2404.15639\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ChatGPT Code Detection: Techniques for Uncovering the Source of Code\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.15512\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Uncovering LLM-Generated Code: A Zero-Shot Synthetic Code Detector via Code Rewriting\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.16133\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automatic Detection of LLM-generated Code: A Case Study of Claude 3 Haiku\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.01382\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Empirical Study on Automatically Detecting AI-Generated Source Code: How Far Are We?\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.04299\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Distinguishing LLM-generated from Human-written Code by Contrastive Learning\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.04704\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Is This You, LLM? Recognizing AI-written Programs with Multilingual Code Stylometry\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.14611\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Investigating Efficacy of Perplexity in Detecting LLM-Generated Code\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.16525\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"AIGCodeSet: A New Annotated Dataset for AI Generated Code Detection\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.16594\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeVision: Detecting LLM-Generated Code Using 2D Token Probability Maps and Vision Models\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.03288\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Robust and Secure Code Watermarking for Large Language Models via ML/Crypto Codesign\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.02068\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Detection of LLM-Generated Java Code Using Discretized Nested Bigrams\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.15740\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Detection of LLM-Paraphrased Code and Identification of the Responsible LLM Using Coding Style Features\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.17749\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Marking Code Without Breaking It: Code Watermarking for Detecting LLM-Generated Code\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.18851\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual, Multi-Generator and Multi-Domain Settings\" [2025-03] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2503.13733\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeMirage: A Multi-Lingual Benchmark for Detecting AI-Generated and Paraphrased Source Code from Production-Level LLMs\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2506.11059\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"I Know Which LLM Wrote Your Code Last Summer: LLM generated Code Stylometry for Authorship Attribution\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.17323\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Disappearing Ink: Obfuscation Breaks N-gram Code Watermarks in Theory and Practice\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.05512\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Droid: A Resource Suite for AI-Generated Code Detection\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.10583\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Optimizing Token Choice for Code Watermarking: A RL Approach\" [2025-08] [\u003ca href=\"https://arxiv.org/abs/2508.11925\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models Are Effective Code Watermarkers\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.11251\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOthers\u003c/h3\u003e\u003ca id=\"user-content-others\" class=\"anchor\" aria-label=\"Permalink: Others\" href=\"#others\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Membership Inference for Detecting Unauthorized Data Use in Code Pre-trained Language Models\" [2023-12] [EMNLP 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2312.07200\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Testing the Effect of Code Documentation on Large Language Model Code Understanding\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.03114\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Where Are Large Language Models for Code Generation on GitHub?\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.19544\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Beyond Functional Correctness: Investigating Coding Style Inconsistencies in Large Language Models\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2407.00456\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Benchmarking Language Model Creativity: A Case Study on Code Generation\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.09007\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Beyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.11470\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Is Functional Correctness Enough to Evaluate Code Language Models? Exploring Diversity of Generated Codes\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.14504\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Strategic Optimization and Challenges of Large Language Models in Object-Oriented Programming\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.14834\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Survey on Evaluating Large Language Models in Code Generation Tasks\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.16498\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An exploratory analysis of Community-based Question-Answering Platforms and GPT-3-driven Generative AI: Is it the end of online community-based learning?\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.17473\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Generation and Algorithmic Problem Solving Using Llama 3.1 405B\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.19027\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Benchmarking ChatGPT, Codeium, and GitHub Copilot: A Comparative Study of AI-Driven Programming and Debugging Assistants\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.19922\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Model Editing for LLMs4Code: How Far are We?\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.06638\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"An Empirical Study on LLM-based Agents for Automated Bug Fixing\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.10213\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Precision or Peril: Evaluating Code Quality from Quantized Large Language Models\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.10656\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Measuring Emergent Capabilities of LLMs for Software Engineering: How Far Are We?\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.17927\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Addressing Data Leakage in HumanEval Using Combinatorial Test Design\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.01526\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Less is More: Towards Green Code Large Language Models via Unified Structural Pruning\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.15921\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How Propense Are Large Language Models at Producing Code Smells? A Benchmarking Study\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.18989\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Deriving Coding-Specific Sub-Models from LLMs using Resource-Efficient Pruning\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.05248\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Do LLMs Provide Links to Code Similar to what they Generate? A Study with Gemini and Bing CoPilot\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.12134\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Comparing Human and LLM Generated Code: The Jury is Still Out!\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.16857\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"On the Possibility of Breaking Copyleft Licenses When Reusing Code Generated by ChatGPT\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.05023\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeIF: Benchmarking the Instruction-Following Capabilities of Large Language Models for Code Generation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.19166\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How Diversely Can Language Models Solve Problems? Exploring the Algorithmic Diversity of Model-Generated Code\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.00691\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Memorize or Generalize? Evaluating LLM Code Generation with Evolved Questions\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.02296\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Human or LLM? A Comparative Study on Accessible Code Generation Capability\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.15885\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Automated Harmfulness Testing for Code Large Language Models\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.16740\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code Red! On the Harmfulness of Applying Off-the-shelf Large Language Models to Programming Tasks\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.01850\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Rethinking Repetition Problems of LLMs in Code Generation\" [2025-05] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2505.10402\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Style2Code: A Style-Controllable Code Generation Framework with Dual-Modal Contrastive Representation Learning\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.19442\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e7. Human-LLM Interaction\u003c/h2\u003e\u003ca id=\"user-content-7-human-llm-interaction\" class=\"anchor\" aria-label=\"Permalink: 7. Human-LLM Interaction\" href=\"#7-human-llm-interaction\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models\" [2022-04] [CHI EA 2022] [\u003ca href=\"https://dl.acm.org/doi/abs/10.1145/3491101.3519665\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Grounded Copilot: How Programmers Interact with Code-Generating Models\" [2022-06] [OOPSLA 2023] [\u003ca href=\"https://arxiv.org/abs/2206.15000\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming\" [2022-10] [\u003ca href=\"https://arxiv.org/abs/2210.14306\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Impact of AI on Developer Productivity: Evidence from GitHub Copilot\" [2023-02] [\u003ca href=\"https://arxiv.org/abs/2302.06590\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Programmer's Assistant: Conversational Interaction with a Large Language Model for Software Development\" [2023-02] [IUI 2023] [\u003ca href=\"https://arxiv.org/abs/2302.07080\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"\"It's Weird That it Knows What I Want\": Usability and Interactions with Copilot for Novice Programmers\" [2023-04] [ACM TCHI] [\u003ca href=\"https://arxiv.org/abs/2304.02491\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"DevGPT: Studying Developer-ChatGPT Conversations\" [2023-08] [\u003ca href=\"https://arxiv.org/abs/2309.03914\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How Do Analysts Understand and Verify AI-Assisted Data Analyses?\" [2023-09] [\u003ca href=\"https://arxiv.org/abs/2309.10947\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How Novices Use LLM-Based Code Generators to Solve CS1 Coding Tasks in a Self-Paced Learning Environment\" [2023-09] [Koli Calling 2023] [\u003ca href=\"https://arxiv.org/abs/2309.14049\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Conversational Challenges in AI-Powered Data Science: Obstacles, Needs, and Design Opportunities\" [2023-10] [\u003ca href=\"https://arxiv.org/abs/2310.16164\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The RealHumanEval: Evaluating Large Language Models' Abilities to Support Programmers\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.02806\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Unlocking Adaptive User Experience with Generative AI\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.05442\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"BISCUIT: Scaffolding LLM-Generated Code with Ephemeral UIs in Computational Notebooks\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.07387\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How far are AI-powered programming assistants from meeting developers' needs?\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.12000\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Beyond Code Generation: An Observational Study of ChatGPT Usage in Software Engineering Practice\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.14901\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The GPT Surprise: Offering Large Language Model Chat in a Massive Coding Class Reduced Engagement but Increased Adopters Exam Performances\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2407.09975\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"amplified.dev: a living document that begins to sketch a vision for a future where developers are amplified, not automated\" [2024-05] [\u003ca href=\"https://amplified.dev\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Sketch Then Generate: Providing Incremental User Feedback and Guiding LLM Code Generation through Language-Oriented Code Sketches\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.03998\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Using AI Assistants in Software Development: A Qualitative Study on Security Practices and Concerns\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.06371\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Full Line Code Completion: Bringing AI to Desktop\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.08704\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Developers' Perceptions on the Impact of ChatGPT in Software Development: A Survey\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.12195\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Transformer-Based Approach for Smart Invocation of Automatic Code Completion\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.14753\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"A Study on Developer Behaviors for Validating and Repairing LLM-Generated Code Using Eye Tracking and IDE Actions\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.16081\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Analyzing Chat Protocols of Novice Programmers Solving Introductory Programming Tasks with ChatGPT\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2405.19132\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Benchmarking the Communication Competence of Code Generation for LLMs and LLM Agent\" [2024-05] [\u003ca href=\"https://arxiv.org/abs/2406.00215\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Learning Task Decomposition to Assist Humans in Competitive Programming\" [2024-06] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2406.04604\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Hints-In-Browser: Benchmarking Language Models for Programming Feedback Generation\" [2024-07] [NeurIPS 2024] [\u003ca href=\"https://arxiv.org/abs/2406.05053\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Impact of AI-tooling on the Engineering Workspace\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.07683\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Using AI-Based Coding Assistants in Practice: State of Affairs, Perceptions, and Ways Forward\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.07765\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging\" [2024-06] [EMNLP 2024 Findings] [\u003ca href=\"https://arxiv.org/abs/2406.11709\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Transforming Software Development: Evaluating the Efficiency and Challenges of GitHub Copilot in Real-World Projects\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.17910\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Let the Code LLM Edit Itself When You Edit the Code\" [2024-07] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2407.03157\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Enhancing Computer Programming Education with LLMs: A Study on Effective Prompt Engineering for Python Code Generation\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.05437\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How Novice Programmers Use and Experience ChatGPT when Solving Programming Exercises in an Introductory Course\" [2024-07] [\u003ca href=\"https://arxiv.org/abs/2407.20792\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can Developers Prompt? A Controlled Experiment for Code Documentation Generation\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.00686\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Impact of Generative AI-Powered Code Generation Tools on Software Engineer Hiring: Recruiters' Experiences, Perceptions, and Strategies\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.00875\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Investigating the Role of Cultural Values in Adopting Large Language Models for Software Engineering\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.05055\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Impact of Large Language Models on Open-source Innovation: Evidence from GitHub Copilot\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.08379\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"\"I Don't Use AI for Everything\": Exploring Utility, Attitude, and Responsibility of AI-empowered Tools in Software Development\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.13343\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Harnessing the Potential of Gen-AI Coding Assistants in Public Sector Software Development\" [2024-09] [\u003ca href=\"https://arxiv.org/abs/2409.17434\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Understanding the Human-LLM Dynamic: A Literature Survey of LLM Use in Programming Tasks\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.01026\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Code-Survey: An LLM-Driven Methodology for Analyzing Large-Scale Codebases\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.01837\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The potential of LLM-generated reports in DevSecOps\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.01899\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"The Impact of Generative AI on Collaborative Open-Source Software Development: Evidence from GitHub Copilot\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.02091\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Exploring the Design Space of Cognitive Engagement Techniques with AI-Generated Code for Enhanced Learning\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.08922\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"One Step at a Time: Combining LLMs and Static Analysis to Generate Next-Step Hints for Programming Tasks\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.09268\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How much does AI impact development speed? An enterprise-based randomized controlled trial\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.12944\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Understanding the Effect of Algorithm Transparency of Model Explanations in Text-to-SQL Semantic Parsing\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.16283\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Dear Diary: A randomized controlled trial of Generative AI coding tools in the workplace\" [2024-10] [\u003ca href=\"https://arxiv.org/abs/2410.18334\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"LLMs are Imperfect, Then What? An Empirical Study on LLM Failures in Software Engineering\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.09916\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Human-In-the-Loop Software Development Agents\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.12924\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Amplifying human performance in combinatorial competitive programming\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2411.19744\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Why Do Developers Engage with ChatGPT in Issue-Tracker? Investigating Usage and Reliance on ChatGPT-Generated Code\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.06757\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Examining the Use and Impact of an AI Code Assistant on Developer Productivity and Experience in the Enterprise\" [2024-12] [\u003ca href=\"https://arxiv.org/abs/2412.06603\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Human and Machine: How Software Engineers Perceive and Engage with AI-Assisted Code Reviews Compared to Their Peers\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.02092\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards Decoding Developer Cognition in the Age of AI Assistants\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.02684\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Simulated Interactive Debugging\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.09694\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Towards Detecting Prompt Knowledge Gaps for Improved LLM-guided Issue Resolution\" [2025-01] [MSR 2025] [\u003ca href=\"https://arxiv.org/abs/2501.11709\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Experience with GitHub Copilot for Developer Productivity at Zoominfo\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.13282\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Analysis of Student-LLM Interaction in a Software Engineering Project\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.01273\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Understanding User Mental Models in AI-Driven Code Completion Tools: Insights from an Elicitation Study\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.02194\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeA11y: Making AI Coding Assistants Useful for Accessible Web Development\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.10884\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Training Turn-by-Turn Verifiers for Dialogue Tutoring Agents: The Curious Case of LLMs as Your Coding Tutors\" [2025-02] [ACL 2025 Findings] [\u003ca href=\"https://arxiv.org/abs/2502.13311\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"From Tools to Teammates: Evaluating LLMs in Multi-Session Coding Interactions\" [2025-02] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2502.13791\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How Scientists Use Large Language Models to Program\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.17348\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Do Comments and Expertise Still Matter? An Experiment on Programmers' Adoption of AI-Generated JavaScript Code\" [2025-03] [\u003ca href=\"https://arxiv.org/abs/2503.11453\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Prompting LLMs for Code Editing: Struggles and Remedies\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.20196\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming\" [2025-05] [ACL 2025] [\u003ca href=\"https://arxiv.org/abs/2505.16667\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Intuition to Evidence: Measuring AI's True Impact on Developer Productivity\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.19708\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e8. Datasets\u003c/h2\u003e\u003ca id=\"user-content-8-datasets\" class=\"anchor\" aria-label=\"Permalink: 8. Datasets\" href=\"#8-datasets\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e8.1 Pretraining\u003c/h3\u003e\u003ca id=\"user-content-81-pretraining\" class=\"anchor\" aria-label=\"Permalink: 8.1 Pretraining\" href=\"#81-pretraining\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeSearchNet\u003c/strong\u003e: \"CodeSearchNet Challenge: Evaluating the State of Semantic Code Search\" [2019-09] [\u003ca href=\"https://arxiv.org/abs/1909.09436\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/github/CodeSearchNet\"\u003erepo\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/code_search_net\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eThe Pile\u003c/strong\u003e: \"The Pile: An 800GB Dataset of Diverse Text for Language Modeling\" [2020-12], [\u003ca href=\"https://arxiv.org/abs/2101.00027\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://pile.eleuther.ai/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeParrot\u003c/strong\u003e, 2022-02, [\u003ca href=\"https://huggingface.co/datasets/codeparrot/github-code\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eThe Stack\u003c/strong\u003e: \"The Stack: 3 TB of permissively licensed source code\" [2022-11] [\u003ca href=\"https://arxiv.org/abs/2211.15533\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/bigcode/the-stack\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eROOTS\u003c/strong\u003e: \"The BigScience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset\" [2023-03] [NeurIPS 2022 Datasets and Benchmarks Track] [\u003ca href=\"https://arxiv.org/abs/2303.03915\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets?search=bigscience-data/roots\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eThe Stack v2\u003c/strong\u003e: \"StarCoder 2 and The Stack v2: The Next Generation\" [2024-02] [\u003ca href=\"https://arxiv.org/abs/2402.19173\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/bigcode/the-stack-v2-dedup\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eThe Heap\u003c/strong\u003e: \"The Heap: A Contamination-Free Multilingual Code Dataset for Evaluating Large Language Models\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.09653\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Large Language Models are Qualified Benchmark Builders: Rebuilding Pre-Training Datasets for Advancing Code Intelligence Tasks\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.19444\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e8.2 Benchmarks\u003c/h3\u003e\u003ca id=\"user-content-82-benchmarks\" class=\"anchor\" aria-label=\"Permalink: 8.2 Benchmarks\" href=\"#82-benchmarks\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eIntegrated Benchmarks\u003c/h4\u003e\u003ca id=\"user-content-integrated-benchmarks\" class=\"anchor\" aria-label=\"Permalink: Integrated Benchmarks\" href=\"#integrated-benchmarks\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeXGLUE\u003c/strong\u003e: \"CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation\" [2021-02] [NeurIPS Datasets and Benchmarks 2021] [\u003ca href=\"https://arxiv.org/abs/2102.04664\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/microsoft/CodeXGLUE\"\u003erepo\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets?search=code_x_glue\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodefuseEval\u003c/strong\u003e: \"CodeFuse-13B: A Pretrained Multi-lingual Code Large Language Model\" [2023-10] [\u003ca href=\"https://arxiv.org/abs/2310.06266\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/codefuse-ai/codefuse-evaluation\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeScope\u003c/strong\u003e: \"CodeScope: An Execution-based Multilingual Multitask Multidimensional Benchmark for Evaluating LLMs on Code Understanding and Generation\" [2023-11] [ACL 2024] [\u003ca href=\"https://arxiv.org/abs/2311.08588\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/WeixiangYAN/CodeScope\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLiveCodeBench\u003c/strong\u003e: \"LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code\" [2024-03] [ICLR 2025] [\u003ca href=\"https://arxiv.org/abs/2403.07974\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/LiveCodeBench/LiveCodeBench\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeEditorBench\u003c/strong\u003e: \"CodeEditorBench: Evaluating Code Editing Capability of Large Language Models\" [2024-04] [\u003ca href=\"https://arxiv.org/abs/2404.03543\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/CodeEditorBench/CodeEditorBench\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLong Code Arena\u003c/strong\u003e: \"Long Code Arena: a Set of Benchmarks for Long-Context Code Models\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.11612\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/JetBrains-Research/lca-baselines\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCodeRAG-Bench\u003c/strong\u003e: \"CodeRAG-Bench: Can Retrieval Augment Code Generation?\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.14497\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/code-rag-bench/code-rag-bench\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLiveBench\u003c/strong\u003e: \"LiveBench: A Challenging, Contamination-Free LLM Benchmark\" [2024-06] [\u003ca href=\"https://arxiv.org/abs/2406.19314\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/livebench/livebench\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eDebugEval\u003c/strong\u003e: \"Enhancing the Code Debugging Ability of LLMs via Communicative Agent Based Data Refinement\" [2024-08] [\u003ca href=\"https://arxiv.org/abs/2408.05006\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/NEUIR/DebugEval\"\u003erepo\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eFullStack Bench\u003c/strong\u003e: \"FullStack Bench: Evaluating LLMs as Full Stack Coder\" [2024-11] [\u003ca href=\"https://arxiv.org/abs/2412.00535\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/bytedance/FullStackBench\"\u003edata\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eStackEval\u003c/strong\u003e: \"StackEval: Benchmarking LLMs in Coding Assistance\" [2024-12] [NeurIPS 2024] [\u003ca href=\"https://arxiv.org/abs/2412.05288\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/ProsusAI/stack-eval\"\u003edata\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How Should I Build A Benchmark?\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.10711\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eHLE\u003c/strong\u003e: \"Humanity's Last Exam\" [2025-01] [\u003ca href=\"https://arxiv.org/abs/2501.14249\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/centerforaisafety/hle\"\u003edata\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSuperGPQA\u003c/strong\u003e: \"SuperGPQA: Scaling LLM Evaluation across 285 Graduate Disciplines\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.14739\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eBBEH\u003c/strong\u003e: \"BIG-Bench Extra Hard\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.19187\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/google-deepmind/bbeh\"\u003edata\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"\u003cstrong\u003eCoCo-Bench\u003c/strong\u003e: A Comprehensive Code Benchmark For Multi-task Large Language Model Evaluation\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.20673\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eSELU\u003c/strong\u003e: \"Evaluating Large Language Models on Non-Code Software Engineering Tasks\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2506.10833\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eMERA Code\u003c/strong\u003e: \"MERA Code: A Unified Framework for Evaluating Code Generation Across Tasks\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.12284\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/MERA-Evaluation/MERA_CODE\"\u003edata\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eLoCoBench\u003c/strong\u003e: \"LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering\" [2025-09] [\u003ca href=\"https://arxiv.org/abs/2509.09614\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eTREAT\u003c/strong\u003e: \"TREAT: A Code LLMs Trustworthiness / Reliability Evaluation and Testing Framework\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.17163\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eEvaluation Metrics\u003c/h4\u003e\u003ca id=\"user-content-evaluation-metrics\" class=\"anchor\" aria-label=\"Permalink: Evaluation Metrics\" href=\"#evaluation-metrics\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeBLEU: a Method for Automatic Evaluation of Code Synthesis\" [2020-09] [\u003ca href=\"https://arxiv.org/abs/2009.10297\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code\" [2023-02] [EMNLP 2023] [\u003ca href=\"https://arxiv.org/abs/2302.05527\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Unsupervised Evaluation of Code LLMs with Round-Trip Correctness\" [2024-02] [ICML 2024] [\u003ca href=\"https://arxiv.org/abs/2402.08699\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeJudge: Evaluating Code Generation with Large Language Models\" [2024-10] [EMNLP 2024] [\u003ca href=\"https://arxiv.org/abs/2410.02184\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can LLMs Replace Human Evaluators? An Empirical Study of LLM-as-a-Judge in Software Engineering\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.06193\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Bridging LLM-Generated Code and Requirements: Reverse Generation technique and SBC Metric for Developer Insights\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.07835\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Copilot Arena: A Platform for Code LLM Evaluation in the Wild\" [2025-02] [ICML 2025] [\u003ca href=\"https://arxiv.org/abs/2502.09328\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"MCTS-Judge: Test-Time Scaling in LLM-as-a-Judge for Code Correctness Evaluation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.12468\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeCriticBench: A Holistic Code Critique Benchmark for Large Language Models\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.16614\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Disproving Program Equivalence with LLMs\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.18473\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Can Language Models Falsify? Evaluating Algorithmic Reasoning with Counterexample Creation\" [2025-02] [\u003ca href=\"https://arxiv.org/abs/2502.19414\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeVisionary: An Agent-based Framework for Evaluating Large Language Models in Code Generation\" [2025-04] [\u003ca href=\"https://arxiv.org/abs/2504.13472\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"EVALOOP: Assessing LLM Robustness in Programming from a Self-consistency Perspective\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.12185\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Don't Judge Code by Its Cover: Exploring Biases in LLM Judges for Code Evaluation\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.16222\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CODE-DITING: A Reasoning-Based Metric for Functional Alignment in Code Evaluation\" [2025-05] [\u003ca href=\"https://arxiv.org/abs/2505.19502\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"Estimating Correctness Without Oracles in LLM-Based Code Generation\" [2025-06] [\u003ca href=\"https://arxiv.org/abs/2507.00057\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.10535\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.08697\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp dir=\"auto\"\u003e\"How Many Code and Test Cases Are Enough? Evaluating Test Cases Generation from a Binary-Matrix Perspective\" [2025-10] [\u003ca href=\"https://arxiv.org/abs/2510.08720\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eProgram Synthesis\u003c/h4\u003e\u003ca id=\"user-content-program-synthesis\" class=\"anchor\" aria-label=\"Permalink: Program Synthesis\" href=\"#program-synthesis\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cmarkdown-accessiblity-table\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eDate\u003c/th\u003e\n\u003cth\u003eVenue\u003c/th\u003e\n\u003cth\u003eBenchmark\u003c/th\u003e\n\u003cth\u003eSize\u003c/th\u003e\n\u003cth\u003eLanguage\u003c/th\u003e\n\u003cth\u003eSource\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e2018-02\u003c/td\u003e\n\u003ctd\u003eLREC 2018\u003c/td\u003e\n\u003ctd\u003eNL2Bash\u003c/td\u003e\n\u003ctd\u003e9305\u003c/td\u003e\n\u003ctd\u003eBash\u003c/td\u003e\n\u003ctd\u003e\"NL2Bash: A Corpus and Semantic Parser for Natural Language Interface to the Linux Operating System\" [\u003ca href=\"https://arxiv.org/abs/1802.08979\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/TellinaTool/nl2bash\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2018-08\u003c/td\u003e\n\u003ctd\u003eEMNLP 2018\u003c/td\u003e\n\u003ctd\u003eCONCODE\u003c/td\u003e\n\u003ctd\u003e104K\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Mapping Language to Code in Programmatic Context\" [\u003ca href=\"https://arxiv.org/abs/1808.09588\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/sriniiyer/concode\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-10\u003c/td\u003e\n\u003ctd\u003eEMNLP-IJCNLP 2019\u003c/td\u003e\n\u003ctd\u003eJuICe\u003c/td\u003e\n\u003ctd\u003e1.5M/3725 *\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"JuICe: A Large Scale Distantly Supervised Dataset for Open Domain Context-based Code Generation\" [\u003ca href=\"https://arxiv.org/abs/1910.02216\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/rajasagashe/juice\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-05\u003c/td\u003e\n\u003ctd\u003eNeurIPS 2021\u003c/td\u003e\n\u003ctd\u003eAPPS\u003c/td\u003e\n\u003ctd\u003e10000\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Measuring Coding Challenge Competence With APPS\" [\u003ca href=\"https://arxiv.org/abs/2105.09938\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/hendrycks/apps\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-07\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eHumanEval\u003c/td\u003e\n\u003ctd\u003e164\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Evaluating Large Language Models Trained on Code\" [\u003ca href=\"https://arxiv.org/abs/2107.03374\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/openai/human-eval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-08\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eMBPP/MathQA-Python\u003c/td\u003e\n\u003ctd\u003e974/23914\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Program Synthesis with Large Language Models\" [\u003ca href=\"https://arxiv.org/abs/2108.07732\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/google-research/google-research/tree/master/mbpp\"\u003eMBPP\u003c/a\u003e] [\u003ca href=\"https://github.com/google/trax/blob/master/trax/examples/MathQA_Python_generation_notebook.ipynb\"\u003eMathQA-Python\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-08\u003c/td\u003e\n\u003ctd\u003eACL/IJCNLP 2021\u003c/td\u003e\n\u003ctd\u003ePlotCoder\u003c/td\u003e\n\u003ctd\u003e40797\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"PlotCoder: Hierarchical Decoding for Synthesizing Visualization Code in Programmatic Context\" [\u003ca href=\"https://aclanthology.org/2021.acl-long.169/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/jungyhuk/plotcoder\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-01\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eDSP\u003c/td\u003e\n\u003ctd\u003e1119\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Training and Evaluating a Jupyter Notebook Data Science Assistant\" [\u003ca href=\"https://arxiv.org/abs/2201.12901\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/microsoft/DataScienceProblems\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-02\u003c/td\u003e\n\u003ctd\u003eScience\u003c/td\u003e\n\u003ctd\u003eCodeContests\u003c/td\u003e\n\u003ctd\u003e13610\u003c/td\u003e\n\u003ctd\u003eC++, Python, Java\u003c/td\u003e\n\u003ctd\u003e\"Competition-Level Code Generation with AlphaCode\" [\u003ca href=\"https://arxiv.org/abs/2203.07814\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/google-deepmind/code_contests\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-03\u003c/td\u003e\n\u003ctd\u003eEACL 2023 Findings\u003c/td\u003e\n\u003ctd\u003eMCoNaLa\u003c/td\u003e\n\u003ctd\u003e896\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"MCoNaLa: A Benchmark for Code Generation from Multiple Natural Languages\" [\u003ca href=\"https://arxiv.org/abs/2203.08388\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/zorazrw/multilingual-conala\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-06\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eAixBench\u003c/td\u003e\n\u003ctd\u003e336\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"AixBench: A Code Generation Benchmark Dataset\" [\u003ca href=\"https://arxiv.org/abs/2206.13179\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/aixcoder-plugin/nl2code-dataset\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-08\u003c/td\u003e\n\u003ctd\u003eIEEE Trans. Software Engineering\u003c/td\u003e\n\u003ctd\u003eMultiPL-E\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"MultiPL-E: A Scalable and Extensible Approach to Benchmarking Neural Code Generation\", [\u003ca href=\"https://arxiv.org/abs/2208.08227\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/nuprl/MultiPL-E\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-10\u003c/td\u003e\n\u003ctd\u003eICLR 2023\u003c/td\u003e\n\u003ctd\u003eMBXP\u003c/td\u003e\n\u003ctd\u003e12.4K\u003c/td\u003e\n\u003ctd\u003ePython, Java, JS, TypeScript, Go, C#, PHP, Ruby, Kotlin, C++, Perl, Scala, Swift\u003c/td\u003e\n\u003ctd\u003e\"Multi-lingual Evaluation of Code Generation Models\" [\u003ca href=\"https://arxiv.org/abs/2210.14868\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/amazon-science/mxeval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-10\u003c/td\u003e\n\u003ctd\u003eICLR 2023\u003c/td\u003e\n\u003ctd\u003eMultilingual HumanEval\u003c/td\u003e\n\u003ctd\u003e1.9K\u003c/td\u003e\n\u003ctd\u003ePython, Java, JS, TypeScript, Go, C#, PHP, Ruby, Kotlin, Perl, Scala, Swift\u003c/td\u003e\n\u003ctd\u003e\"Multi-lingual Evaluation of Code Generation Models\" [\u003ca href=\"https://arxiv.org/abs/2210.14868\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/amazon-science/mxeval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-10\u003c/td\u003e\n\u003ctd\u003eICLR 2023\u003c/td\u003e\n\u003ctd\u003eMathQA-X\u003c/td\u003e\n\u003ctd\u003e5.6K\u003c/td\u003e\n\u003ctd\u003ePython, Java, JS\u003c/td\u003e\n\u003ctd\u003e\"Multi-lingual Evaluation of Code Generation Models\" [\u003ca href=\"https://arxiv.org/abs/2210.14868\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/amazon-science/mxeval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-11\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eExeDS\u003c/td\u003e\n\u003ctd\u003e534\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Execution-based Evaluation for Data Science Code Generation Models\" [\u003ca href=\"https://arxiv.org/abs/2211.09374\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/Jun-jie-Huang/ExeDS\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-11\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eDS-1000\u003c/td\u003e\n\u003ctd\u003e1000\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2211.11501\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/xlang-ai/DS-1000\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-12\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eODEX\u003c/td\u003e\n\u003ctd\u003e945\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Execution-Based Evaluation for Open-Domain Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2212.10481\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/zorazrw/odex\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-02\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCoderEval\u003c/td\u003e\n\u003ctd\u003e460\u003c/td\u003e\n\u003ctd\u003ePython, Java\u003c/td\u003e\n\u003ctd\u003e\"CoderEval: A Benchmark of Pragmatic Code Generation with Generative Pre-trained Models\" [\u003ca href=\"https://arxiv.org/abs/2302.00288\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/CoderEval/CoderEval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-03\u003c/td\u003e\n\u003ctd\u003eACL 2024\u003c/td\u003e\n\u003ctd\u003exCodeEval\u003c/td\u003e\n\u003ctd\u003e5.5M\u003c/td\u003e\n\u003ctd\u003eC, C#, C++, Go, Java, JS, Kotlin, PHP, Python, Ruby, Rust\u003c/td\u003e\n\u003ctd\u003e\"XCodeEval: An Execution-based Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval\" [\u003ca href=\"https://arxiv.org/abs/2303.03004\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/ntunlp/xCodeEval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-03\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eHumanEval-X\u003c/td\u003e\n\u003ctd\u003e820\u003c/td\u003e\n\u003ctd\u003ePython, C++, Java, JS, Go\u003c/td\u003e\n\u003ctd\u003e\"CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X\" [\u003ca href=\"https://arxiv.org/abs/2303.17568\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://hub.docker.com/r/codegeex/codegeex\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eHumanEval+\u003c/td\u003e\n\u003ctd\u003e164\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2305.01210\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/evalplus/evalplus\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-06\u003c/td\u003e\n\u003ctd\u003eACL 2024 Findings\u003c/td\u003e\n\u003ctd\u003eStudentEval\u003c/td\u003e\n\u003ctd\u003e1749 \u003cmath-renderer class=\"js-inline-math\" style=\"display: inline-block\" data-run-id=\"b3caf4e842e88b86948a693f78d2e24c\"\u003e$^\\dagger$\u003c/math-renderer\u003e\n\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"StudentEval: A Benchmark of Student-Written Prompts for Large Language Models of Code\" [\u003ca href=\"https://arxiv.org/abs/2306.04556\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/wellesley-easel/StudentEval\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-08\u003c/td\u003e\n\u003ctd\u003eICLR 2024 Spotlight\u003c/td\u003e\n\u003ctd\u003eHumanEvalPack\u003c/td\u003e\n\u003ctd\u003e984\u003c/td\u003e\n\u003ctd\u003ePython, JS, Go, Java, C++, Rust\u003c/td\u003e\n\u003ctd\u003e\"OctoPack: Instruction Tuning Code Large Language Models\" [\u003ca href=\"https://arxiv.org/abs/2308.07124\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/bigcode/humanevalpack\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-06\u003c/td\u003e\n\u003ctd\u003eNeurIPS 2023\u003c/td\u003e\n\u003ctd\u003eDotPrompts\u003c/td\u003e\n\u003ctd\u003e10538 \u003cmath-renderer class=\"js-inline-math\" style=\"display: inline-block\" data-run-id=\"b3caf4e842e88b86948a693f78d2e24c\"\u003e$^\\ddagger$\u003c/math-renderer\u003e\n\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Guiding Language Models of Code with Global Context using Monitors\" [\u003ca href=\"https://arxiv.org/abs/2306.10763\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/microsoft/monitors4codegen\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-09\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCodeApex\u003c/td\u003e\n\u003ctd\u003e476\u003c/td\u003e\n\u003ctd\u003eC++\u003c/td\u003e\n\u003ctd\u003e\"CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models\" [\u003ca href=\"https://arxiv.org/abs/2309.01940\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/APEXLAB/CodeApex\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-09\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eVerilogEval\u003c/td\u003e\n\u003ctd\u003e8645/156 \u003cmath-renderer class=\"js-inline-math\" style=\"display: inline-block\" data-run-id=\"b3caf4e842e88b86948a693f78d2e24c\"\u003e$^\\diamond$\u003c/math-renderer\u003e\n\u003c/td\u003e\n\u003ctd\u003eVerilog\u003c/td\u003e\n\u003ctd\u003e\"VerilogEval: Evaluating Large Language Models for Verilog Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2309.07544\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/NVlabs/verilog-eval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-11\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eML-Bench\u003c/td\u003e\n\u003ctd\u003e10040\u003c/td\u003e\n\u003ctd\u003eBash\u003c/td\u003e\n\u003ctd\u003e\"ML-Bench: Large Language Models Leverage Open-source Libraries for Machine Learning Tasks\" [\u003ca href=\"https://arxiv.org/abs/2311.09835\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://ml-bench.github.io/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-12\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eTACO\u003c/td\u003e\n\u003ctd\u003e26,433\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"TACO: Topics in Algorithmic COde generation dataset\" [\u003ca href=\"https://arxiv.org/abs/2312.14852\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/FlagOpen/TACO\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-01\u003c/td\u003e\n\u003ctd\u003eEMNLP 2024 Findings\u003c/td\u003e\n\u003ctd\u003ePythonSaga\u003c/td\u003e\n\u003ctd\u003e185\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"PythonSaga: Redefining the Benchmark to Evaluate Code Generating LLMs\" [\u003ca href=\"https://arxiv.org/abs/2401.03855\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://anonymous.4open.science/r/PythonSaga/README.md\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-01\u003c/td\u003e\n\u003ctd\u003eHPDC\u003c/td\u003e\n\u003ctd\u003eParEval\u003c/td\u003e\n\u003ctd\u003e420\u003c/td\u003e\n\u003ctd\u003eC++, CUDA, HIP\u003c/td\u003e\n\u003ctd\u003e\"Can Large Language Models Write Parallel Code?\" [\u003ca href=\"https://arxiv.org/abs/2401.12554\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/parallelcodefoundry/ParEval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-02\u003c/td\u003e\n\u003ctd\u003eACL 2024 Findings\u003c/td\u003e\n\u003ctd\u003eOOP\u003c/td\u003e\n\u003ctd\u003e431\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"OOP: Object-Oriented Programming Evaluation Benchmark for Large Language Models\" [\u003ca href=\"https://arxiv.org/abs/2401.06628\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/alphadl/OOP-eval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-02\u003c/td\u003e\n\u003ctd\u003eLREC-COLING 2024\u003c/td\u003e\n\u003ctd\u003eHumanEval-XL\u003c/td\u003e\n\u003ctd\u003e22080\u003c/td\u003e\n\u003ctd\u003e23NL, 12PL\u003c/td\u003e\n\u003ctd\u003e\"HumanEval-XL: A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization\" [\u003ca href=\"https://arxiv.org/abs/2402.16694\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/FloatAI/humaneval-xl\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-04\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eUSACO\u003c/td\u003e\n\u003ctd\u003e307\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Can Language Models Solve Olympiad Programming?\" [\u003ca href=\"https://arxiv.org/abs/2404.10952\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/princeton-nlp/USACO\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-04\u003c/td\u003e\n\u003ctd\u003eLREC-COLING 2024\u003c/td\u003e\n\u003ctd\u003ePECC\u003c/td\u003e\n\u003ctd\u003e2396\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"PECC: Problem Extraction and Coding Challenges\" [\u003ca href=\"https://arxiv.org/abs/2404.18766\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/HallerPatrick/pecc\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-04\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCodeGuard+\u003c/td\u003e\n\u003ctd\u003e23\u003c/td\u003e\n\u003ctd\u003ePython, C\u003c/td\u003e\n\u003ctd\u003e\"Constrained Decoding for Secure Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2405.00218\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/Dynamite321/CodeGuardPlus\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-05\u003c/td\u003e\n\u003ctd\u003eACL 2024 Findings\u003c/td\u003e\n\u003ctd\u003eNaturalCodeBench\u003c/td\u003e\n\u003ctd\u003e402\u003c/td\u003e\n\u003ctd\u003ePython, Java\u003c/td\u003e\n\u003ctd\u003e\"NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and Natural User Prompts\" [\u003ca href=\"https://arxiv.org/abs/2405.04520\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/THUDM/NaturalCodeBench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eMHPP\u003c/td\u003e\n\u003ctd\u003e140\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"MHPP: Exploring the Capabilities and Limitations of Language Models Beyond Basic Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2405.11430\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/SparksofAGI/MHPP\"\u003erepo\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-06\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eVHDL-Eval\u003c/td\u003e\n\u003ctd\u003e202\u003c/td\u003e\n\u003ctd\u003eVHDL\u003c/td\u003e\n\u003ctd\u003e\"VHDL-Eval: A Framework for Evaluating Large Language Models in VHDL Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2406.04379\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-06\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eAICoderEval\u003c/td\u003e\n\u003ctd\u003e492\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"AICoderEval: Improving AI Domain Code Generation of Large Language Models\" [\u003ca href=\"https://arxiv.org/abs/2406.04712\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/vixuowis/AICoderEval\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-06\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eVersiCode\u003c/td\u003e\n\u003ctd\u003e98,692\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"VersiCode: Towards Version-controllable Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2406.07411\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/wutong8023/VersiCode\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-06\u003c/td\u003e\n\u003ctd\u003eIEEE AITest 2024\u003c/td\u003e\n\u003ctd\u003eScenEval\u003c/td\u003e\n\u003ctd\u003e12,864\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"ScenEval: A Benchmark for Scenario-Based Evaluation of Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2406.12635\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-06\u003c/td\u003e\n\u003ctd\u003eICLR 2025\u003c/td\u003e\n\u003ctd\u003eBigCodeBench\u003c/td\u003e\n\u003ctd\u003e1,140\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions\" [\u003ca href=\"https://arxiv.org/abs/2406.15877\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/bigcode-project/bigcodebench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-07\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCodeUpdateArena\u003c/td\u003e\n\u003ctd\u003e670\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"CodeUpdateArena: Benchmarking Knowledge Editing on API Updates\" [\u003ca href=\"https://arxiv.org/abs/2407.06249\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/leo-liuzy/CodeUpdateArena\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-07\u003c/td\u003e\n\u003ctd\u003eEMNLP 2024 Findings\u003c/td\u003e\n\u003ctd\u003eLBPP\u003c/td\u003e\n\u003ctd\u003e161\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"On Leakage of Code Generation Evaluation Datasets\" [\u003ca href=\"https://arxiv.org/abs/2407.07565\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/CohereForAI/lbpp\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-07\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eNoviCode\u003c/td\u003e\n\u003ctd\u003e150\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"NoviCode: Generating Programs from Natural Language Utterances by Novices\" [\u003ca href=\"https://arxiv.org/abs/2407.10626\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/BIU-NLP/novicode\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-07\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCase2Code\u003c/td\u003e\n\u003ctd\u003e1.3M\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Case2Code: Learning Inductive Reasoning with Synthetic Data\" [\u003ca href=\"https://arxiv.org/abs/2407.12504\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/choosewhatulike/case2code\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-07\u003c/td\u003e\n\u003ctd\u003eNeurIPS 2024\u003c/td\u003e\n\u003ctd\u003eSciCode\u003c/td\u003e\n\u003ctd\u003e338\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"SciCode: A Research Coding Benchmark Curated by Scientists\" [\u003ca href=\"https://arxiv.org/abs/2407.13168\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/scicode-bench/SciCode\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-07\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eauto-regression\u003c/td\u003e\n\u003ctd\u003e460\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Generating Unseen Code Tests In Infinitum\" [\u003ca href=\"https://arxiv.org/abs/2407.19772\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-07\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eWebApp1K\u003c/td\u003e\n\u003ctd\u003e1000\u003c/td\u003e\n\u003ctd\u003eJavaScript\u003c/td\u003e\n\u003ctd\u003e\"WebApp1K: A Practical Code-Generation Benchmark for Web App Development\" [\u003ca href=\"https://arxiv.org/abs/2408.00019\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/onekq-ai/WebApp1K-React\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-08\u003c/td\u003e\n\u003ctd\u003eACL 2024 Findings\u003c/td\u003e\n\u003ctd\u003eCodeInsight\u003c/td\u003e\n\u003ctd\u003e3409\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"CodeInsight: A Curated Dataset of Practical Coding Solutions from Stack Overflow\" [\u003ca href=\"https://arxiv.org/abs/2409.16819\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/NathanaelBeau/CodeInsight\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-08\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eDomainEval\u003c/td\u003e\n\u003ctd\u003e2454\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"DOMAINEVAL: An Auto-Constructed Benchmark for Multi-Domain Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2408.13204\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/domaineval/DomainEval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-09\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eComplexCodeEval\u003c/td\u003e\n\u003ctd\u003e7184/3897\u003c/td\u003e\n\u003ctd\u003ePython/Java\u003c/td\u003e\n\u003ctd\u003e\"ComplexCodeEval: A Benchmark for Evaluating Large Code Models on More Complex Code\" [\u003ca href=\"https://arxiv.org/abs/2409.10280\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/ComplexCodeEval/ComplexCodeEval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-09\u003c/td\u003e\n\u003ctd\u003eASE 2024\u003c/td\u003e\n\u003ctd\u003eCoCoNote\u003c/td\u003e\n\u003ctd\u003e58221\u003c/td\u003e\n\u003ctd\u003ePython Notebook\u003c/td\u003e\n\u003ctd\u003e\"Contextualized Data-Wrangling Code Generation in Computational Notebooks\" [\u003ca href=\"https://arxiv.org/abs/2409.13551\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/Jun-jie-Huang/CoCoNote\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-10\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eunnamed\u003c/td\u003e\n\u003ctd\u003e77\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Evaluation of Code LLMs on Geospatial Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2410.04617\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/kraina-ai/geospatial-code-llms-dataset\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-10\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003emHumanEval\u003c/td\u003e\n\u003ctd\u003e836,400\u003c/td\u003e\n\u003ctd\u003e25PL, 204NL\u003c/td\u003e\n\u003ctd\u003e\"mHumanEval -- A Multilingual Benchmark to Evaluate Large Language Models for Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2410.15037\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/mraihan-gmu/mHumanEval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-10\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eFeatEng\u003c/td\u003e\n\u003ctd\u003e103\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Can Models Help Us Create Better Models? Evaluating LLMs as Data Scientists\" [\u003ca href=\"https://arxiv.org/abs/2410.23331\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/FeatEng/FeatEng\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-11\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eGitChameleon\u003c/td\u003e\n\u003ctd\u003e116\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"GitChameleon: Unmasking the Version-Switching Capabilities of Code Generation Models\" [\u003ca href=\"https://arxiv.org/abs/2411.05830\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/NizarIslah/GitChameleon\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-11\u003c/td\u003e\n\u003ctd\u003eEMNLP 2024 Findings\u003c/td\u003e\n\u003ctd\u003eMBUPP\u003c/td\u003e\n\u003ctd\u003e466\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"One-to-many testing for code generation from (just) natural language\" [\u003ca href=\"https://aclanthology.org/2024.findings-emnlp.902/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/microsoft/prose-benchmarks/tree/main/MBUPP\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-11\u003c/td\u003e\n\u003ctd\u003eNAACL 2025\u003c/td\u003e\n\u003ctd\u003eLibEvolutionEval\u003c/td\u003e\n\u003ctd\u003e34.7K\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"LibEvolutionEval: A Benchmark and Study for Version-Specific Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2412.04478\" rel=\"nofollow\"\u003epaper\u003c/a\u003e][\u003ca href=\"https://lib-evolution-eval.github.io/\" rel=\"nofollow\"\u003ewebsite\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-12\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003ePandasPlotBench\u003c/td\u003e\n\u003ctd\u003e175\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Drawing Pandas: A Benchmark for LLMs in Generating Plotting Code\" [\u003ca href=\"https://arxiv.org/abs/2412.02764\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/JetBrains-Research/plot_bench\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-12\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCodeArena\u003c/td\u003e\n\u003ctd\u003e397\u003c/td\u003e\n\u003ctd\u003e44\u003c/td\u003e\n\u003ctd\u003e\"Evaluating and Aligning CodeLLMs on Human Preference\" [\u003ca href=\"https://arxiv.org/abs/2412.05210\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/QwenLM/Qwen2.5-Coder/tree/main/qwencoder-eval/instruct/CodeArena\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-12\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eOBFUSEVAL\u003c/td\u003e\n\u003ctd\u003e1354\u003c/td\u003e\n\u003ctd\u003eC\u003c/td\u003e\n\u003ctd\u003e\"Unseen Horizons: Unveiling the Real Capability of LLM Code Generation Beyond the Familiar\" [\u003ca href=\"https://arxiv.org/abs/2412.08109\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/zhangbuzhang/ObfusEval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-12\u003c/td\u003e\n\u003ctd\u003eACL 2025 Findings\u003c/td\u003e\n\u003ctd\u003eHumanEval Pro / MBPP Pro / BigCodeBench-Lite Pro\u003c/td\u003e\n\u003ctd\u003e164/378/57\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"HumanEval Pro and MBPP Pro: Evaluating Large Language Models on Self-invoking Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2412.21199\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/CodeEval-Pro/CodeEval-Pro/tree/main\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-01\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCodeElo\u003c/td\u003e\n\u003ctd\u003e387\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003e\"CodeElo: Benchmarking Competition-level Code Generation of LLMs with Human-comparable Elo Ratings\" [\u003ca href=\"https://arxiv.org/abs/2501.01257\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://codeelo-bench.github.io/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-02\u003c/td\u003e\n\u003ctd\u003eFSE 2025\u003c/td\u003e\n\u003ctd\u003eCOFFE\u003c/td\u003e\n\u003ctd\u003e756\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"COFFE: A Code Efficiency Benchmark for Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2502.02827\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/JohnnyPeng18/Coffe\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-02\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eFVAPPS\u003c/td\u003e\n\u003ctd\u003e4715\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Proving the Coding Interview: A Benchmark for Formally Verified Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2502.05714\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/quinn-dougherty/fvapps\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-02\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eKernelBench\u003c/td\u003e\n\u003ctd\u003e250\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"KernelBench: Can LLMs Write Efficient GPU Kernels?\" [\u003ca href=\"https://arxiv.org/abs/2502.10517\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-02\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eBaxBench\u003c/td\u003e\n\u003ctd\u003e392\u003c/td\u003e\n\u003ctd\u003eGo, JS, PHP, Python, Ruby, Rust\u003c/td\u003e\n\u003ctd\u003e\"BaxBench: Can LLMs Generate Correct and Secure Backends?\" [\u003ca href=\"https://arxiv.org/abs/2502.11844\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://baxbench.com/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-02\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eDataSciBench\u003c/td\u003e\n\u003ctd\u003e222\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"DataSciBench: An LLM Agent Benchmark for Data Science\" [\u003ca href=\"https://arxiv.org/abs/2502.13897\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/THUDM/DataSciBench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-02\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eTritonBench\u003c/td\u003e\n\u003ctd\u003e184\u003c/td\u003e\n\u003ctd\u003eTriton\u003c/td\u003e\n\u003ctd\u003e\"TritonBench: Benchmarking Large Language Model Capabilities for Generating Triton Operators\" [\u003ca href=\"https://arxiv.org/abs/2502.14752\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/thunlp/TritonBench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-02\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eDeep-Bench\u003c/td\u003e\n\u003ctd\u003e520\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Deep-Bench: Deep Learning Benchmark Dataset for Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2502.18726\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://anonymous.4open.science/r/DL-Bench-D65E/README.md\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-02\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eIndicEval-XL\u003c/td\u003e\n\u003ctd\u003e6720\u003c/td\u003e\n\u003ctd\u003e12\u003c/td\u003e\n\u003ctd\u003e\"IndicEval-XL: Bridging Linguistic Diversity in Code Generation Across Indic Languages\" [\u003ca href=\"https://arxiv.org/abs/2502.19067\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/telekom/IndicEval-XL\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-02\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003ePseudoEval\u003c/td\u003e\n\u003ctd\u003e1059\u003c/td\u003e\n\u003ctd\u003ePython, C++, Rust\u003c/td\u003e\n\u003ctd\u003e\"Isolating Language-Coding from Problem-Solving: Benchmarking LLMs with PseudoEval\" [\u003ca href=\"https://arxiv.org/abs/2502.19149\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://anonymous.4open.science/r/PseudocodeACL25-7B74/README.md\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-02\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eProBench\u003c/td\u003e\n\u003ctd\u003e790\u003c/td\u003e\n\u003ctd\u003eC++, Java, Python\u003c/td\u003e\n\u003ctd\u003e\"ProBench: Benchmarking Large Language Models in Competitive Programming\" [\u003ca href=\"https://arxiv.org/abs/2502.20868\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/YL-9/probench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-03\u003c/td\u003e\n\u003ctd\u003eICML 2025\u003c/td\u003e\n\u003ctd\u003eDyCodeEval\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003e\"Dynamic Benchmarking of Reasoning Capabilities in Code Large Language Models Under Data Contamination\" [\u003ca href=\"https://arxiv.org/abs/2503.04149\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-03\u003c/td\u003e\n\u003ctd\u003eACL 2025 Findings\u003c/td\u003e\n\u003ctd\u003eDynaCode\u003c/td\u003e\n\u003ctd\u003e405\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"DynaCode: A Dynamic Complexity-Aware Code Benchmark for Evaluating Large Language Models in Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2503.10452\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-03\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eBigO(Bench)\u003c/td\u003e\n\u003ctd\u003e3105\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"BigO(Bench) -- Can LLMs Generate Code with Controlled Time and Space Complexity?\" [\u003ca href=\"https://arxiv.org/abs/2503.15242\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/facebookresearch/bigobench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-04\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003e842K\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"A Large-scale Class-level Benchmark Dataset for Code Generation with LLMs\" [\u003ca href=\"https://arxiv.org/abs/2504.15564\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://anonymous.4open.science/r/class-level-benchmark-dataset-B132/README.md\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eYABLoCo\u003c/td\u003e\n\u003ctd\u003e215\u003c/td\u003e\n\u003ctd\u003eC, C++\u003c/td\u003e\n\u003ctd\u003e\"YABLoCo: Yet Another Benchmark for Long Context Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2505.04406\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/yabloco-codegen/yabloco-benchmark\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eOSS-Bench\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003e\"OSS-Bench: Benchmark Generator for Coding LLMs\" [\u003ca href=\"https://arxiv.org/abs/2505.12331\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/oss-bench/oss-bench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eDS-Bench\u003c/td\u003e\n\u003ctd\u003e1000\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"DS-Bench: A Realistic Benchmark for Data Science Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2505.15621\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/ShuyinOuyang/DS_bench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-06\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eICPC-Eval\u003c/td\u003e\n\u003ctd\u003e118\u003c/td\u003e\n\u003ctd\u003eC++\u003c/td\u003e\n\u003ctd\u003e\"ICPC-Eval: Probing the Frontiers of LLM Reasoning with Competitive Programming Contests\" [\u003ca href=\"https://arxiv.org/abs/2506.04894\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-06\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eLiveCodeBench Pro\u003c/td\u003e\n\u003ctd\u003e584\u003c/td\u003e\n\u003ctd\u003eC++\u003c/td\u003e\n\u003ctd\u003e\"LiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive Programming?\" [\u003ca href=\"https://arxiv.org/abs/2506.11928\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/GavinZhengOI/LiveCodeBench-Pro\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-06\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eHLCE\u003c/td\u003e\n\u003ctd\u003e235\u003c/td\u003e\n\u003ctd\u003eC++, Python\u003c/td\u003e\n\u003ctd\u003e\"Humanity's Last Code Exam: Can Advanced LLMs Conquer Human's Hardest Code Competition?\" [\u003ca href=\"https://arxiv.org/abs/2506.12713\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/Humanity-s-Last-Code-Exam/HLCE\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-06\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eOJBench\u003c/td\u003e\n\u003ctd\u003e232\u003c/td\u003e\n\u003ctd\u003eC++, Python\u003c/td\u003e\n\u003ctd\u003e\"OJBench: A Competition Level Code Benchmark For Large Language Models\" [\u003ca href=\"https://arxiv.org/abs/2506.16395\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/He-Ren/OJBench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-07\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eIFEvalCode\u003c/td\u003e\n\u003ctd\u003e1.6K\u003c/td\u003e\n\u003ctd\u003ePython, Java, JS, TS, Shell, C++, PHP, C#\u003c/td\u003e\n\u003ctd\u003e\"IFEvalCode: Controlled Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2507.22462\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://ifevalcode.github.io/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-08\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eFPBench\u003c/td\u003e\n\u003ctd\u003e1800\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Refining Critical Thinking in LLM Code Generation: A Faulty Premise-based Evaluation Framework\" [\u003ca href=\"https://arxiv.org/abs/2508.03622\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/JialinLi13/FaultyPremise\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-08\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eAutoCodeBench\u003c/td\u003e\n\u003ctd\u003e3,920\u003c/td\u003e\n\u003ctd\u003e20\u003c/td\u003e\n\u003ctd\u003e\"AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators\" [\u003ca href=\"https://arxiv.org/abs/2508.09101\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://autocodebench.github.io/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-08\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eAetherCode\u003c/td\u003e\n\u003ctd\u003e456\u003c/td\u003e\n\u003ctd\u003eC++\u003c/td\u003e\n\u003ctd\u003e\"AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions\" [\u003ca href=\"https://arxiv.org/abs/2508.16402\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/m-a-p/AetherCode\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-10\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eLiveOIBench\u003c/td\u003e\n\u003ctd\u003e403\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?\" [\u003ca href=\"https://arxiv.org/abs/2510.09595\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://liveoibench.github.io/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-10\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eAutoCode\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003e\"AutoCode: LLMs as Problem Setters for Competitive Programming\" [\u003ca href=\"https://arxiv.org/abs/2510.12803\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-10\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eUniCode\u003c/td\u003e\n\u003ctd\u003e492\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003e\"UniCode: A Framework for Generating High Quality Competitive Coding Problems\" [\u003ca href=\"https://arxiv.org/abs/2510.17868\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\u003c/markdown-accessiblity-table\u003e\n\u003cp dir=\"auto\"\u003e* Automatically mined/human-annotated\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003cmath-renderer class=\"js-inline-math\" style=\"display: inline-block\" data-run-id=\"b3caf4e842e88b86948a693f78d2e24c\"\u003e$^\\dagger$\u003c/math-renderer\u003e 1749 prompts for 48 problems\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003cmath-renderer class=\"js-inline-math\" style=\"display: inline-block\" data-run-id=\"b3caf4e842e88b86948a693f78d2e24c\"\u003e$^\\ddagger$\u003c/math-renderer\u003e 10538 prompts for 1420 problems\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003cmath-renderer class=\"js-inline-math\" style=\"display: inline-block\" data-run-id=\"b3caf4e842e88b86948a693f78d2e24c\"\u003e$^\\diamond$\u003c/math-renderer\u003e Machine/human prompts\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eVisually Grounded Program Synthesis\u003c/h4\u003e\u003ca id=\"user-content-visually-grounded-program-synthesis\" class=\"anchor\" aria-label=\"Permalink: Visually Grounded Program Synthesis\" href=\"#visually-grounded-program-synthesis\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cmarkdown-accessiblity-table\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eDate\u003c/th\u003e\n\u003cth\u003eVenue\u003c/th\u003e\n\u003cth\u003eBenchmark\u003c/th\u003e\n\u003cth\u003eSize\u003c/th\u003e\n\u003cth\u003eLanguage\u003c/th\u003e\n\u003cth\u003eSource\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-04\u003c/td\u003e\n\u003ctd\u003eEMNLP 2024 Findings\u003c/td\u003e\n\u003ctd\u003eMMCode\u003c/td\u003e\n\u003ctd\u003e3548\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"MMCode: Evaluating Multi-Modal Code Large Language Models with Visually Rich Programming Problems\" [\u003ca href=\"https://arxiv.org/abs/2404.09486\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/happylkx/MMCode\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003ePlot2Code\u003c/td\u003e\n\u003ctd\u003e132\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots\" [\u003ca href=\"https://arxiv.org/abs/2405.07990\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/TencentARC/Plot2Code\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-06\u003c/td\u003e\n\u003ctd\u003eICLR 2025\u003c/td\u003e\n\u003ctd\u003eChartMimic\u003c/td\u003e\n\u003ctd\u003e1000\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"ChartMimic: Evaluating LMM's Cross-Modal Reasoning Capability via Chart-to-Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2406.09961\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/ChartMimic/ChartMimic\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-10\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eHumanEval-V\u003c/td\u003e\n\u003ctd\u003e108\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"HumanEval-V: Evaluating Visual Understanding and Reasoning Abilities of Large Multimodal Models Through Coding Tasks\" [\u003ca href=\"https://arxiv.org/abs/2410.12381\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/HumanEval-V/HumanEval-V-Benchmark\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-10\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eTurtleBench\u003c/td\u003e\n\u003ctd\u003e260\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"TurtleBench: A Visual Programming Benchmark in Turtle Geometry\" [\u003ca href=\"https://arxiv.org/abs/2411.00264\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/sinaris76/TurtleBench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-12\u003c/td\u003e\n\u003ctd\u003eICLR 2025\u003c/td\u003e\n\u003ctd\u003eBigDocs\u003c/td\u003e\n\u003ctd\u003e7.5M\u003c/td\u003e\n\u003ctd\u003eHTML, LaTeX, SVG, JSON, Markdown, etc\u003c/td\u003e\n\u003ctd\u003e\"BigDocs: An Open and Permissively-Licensed Dataset for Training Multimodal Models on Document and Code Tasks\" [\u003ca href=\"https://arxiv.org/abs/2412.04626\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://bigdocs.github.io/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-12\u003c/td\u003e\n\u003ctd\u003eACL 2025 Findings\u003c/td\u003e\n\u003ctd\u003eVisual SWEbench\u003c/td\u003e\n\u003ctd\u003e133\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"CodeV: Issue Resolving with Visual Data\" [\u003ca href=\"https://arxiv.org/abs/2412.17315\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/luolin101/CodeV\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-02\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCode-Vision\u003c/td\u003e\n\u003ctd\u003e438\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Code-Vision: Evaluating Multimodal LLMs Logic Understanding and Code Generation Capabilities\" [\u003ca href=\"https://arxiv.org/abs/2502.11829\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/wanghanbinpanda/CodeVision\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-06\u003c/td\u003e\n\u003ctd\u003eACL 2025 Findings\u003c/td\u003e\n\u003ctd\u003eFlow2Code\u003c/td\u003e\n\u003ctd\u003e5622\u003c/td\u003e\n\u003ctd\u003e15\u003c/td\u003e\n\u003ctd\u003e\"Flow2Code: Evaluating Large Language Models for Flowchart-based Code Generation Capability\" [\u003ca href=\"https://arxiv.org/abs/2506.02073\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/hml-github/Flow2Code\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-07\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eArtifactsBench\u003c/td\u003e\n\u003ctd\u003e1825\u003c/td\u003e\n\u003ctd\u003eHTML/JavaScript\u003c/td\u003e\n\u003ctd\u003e\"ArtifactsBench: Bridging the Visual-Interactive Gap in LLM Code Generation Evaluation\" [\u003ca href=\"https://arxiv.org/abs/2507.04952\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/Tencent-Hunyuan/ArtifactsBenchmark\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-08\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eMCD\u003c/td\u003e\n\u003ctd\u003e598K\u003c/td\u003e\n\u003ctd\u003eHTML, Python\u003c/td\u003e\n\u003ctd\u003e\"VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models\" [\u003ca href=\"https://arxiv.org/abs/2508.09945\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/JackLingjie/VisCodex\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\u003c/markdown-accessiblity-table\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCode Reasoning and QA\u003c/h4\u003e\u003ca id=\"user-content-code-reasoning-and-qa\" class=\"anchor\" aria-label=\"Permalink: Code Reasoning and QA\" href=\"#code-reasoning-and-qa\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cmarkdown-accessiblity-table\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eDate\u003c/th\u003e\n\u003cth\u003eVenue\u003c/th\u003e\n\u003cth\u003eBenchmark\u003c/th\u003e\n\u003cth\u003eSize\u003c/th\u003e\n\u003cth\u003eLanguage\u003c/th\u003e\n\u003cth\u003eSource\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-09\u003c/td\u003e\n\u003ctd\u003eEMNLP 2021 Findings\u003c/td\u003e\n\u003ctd\u003eCodeQA\u003c/td\u003e\n\u003ctd\u003e120K/70K\u003c/td\u003e\n\u003ctd\u003eJava/Python\u003c/td\u003e\n\u003ctd\u003e\"CodeQA: A Question Answering Dataset for Source Code Comprehension\" [\u003ca href=\"https://arxiv.org/abs/2109.08365\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/jadecxliu/CodeQA\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-10\u003c/td\u003e\n\u003ctd\u003eNAACL 2022\u003c/td\u003e\n\u003ctd\u003eCS1QA\u003c/td\u003e\n\u003ctd\u003e9237\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"CS1QA: A Dataset for Assisting Code-based Question Answering in an Introductory Programming Course\" [\u003ca href=\"https://arxiv.org/abs/2210.14494\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/cyoon47/CS1QA\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-09\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCodeApex\u003c/td\u003e\n\u003ctd\u003e250\u003c/td\u003e\n\u003ctd\u003eC++\u003c/td\u003e\n\u003ctd\u003e\"CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models\" [\u003ca href=\"https://arxiv.org/abs/2309.01940\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/APEXLAB/CodeApex\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-01\u003c/td\u003e\n\u003ctd\u003eICML 2024\u003c/td\u003e\n\u003ctd\u003eCRUXEval\u003c/td\u003e\n\u003ctd\u003e800\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution\" [\u003ca href=\"https://arxiv.org/abs/2401.03065\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/facebookresearch/cruxeval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003ePythonIO\u003c/td\u003e\n\u003ctd\u003e2650\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Multiple-Choice Questions are Efficient and Robust LLM Evaluators\" [\u003ca href=\"https://arxiv.org/abs/2405.11966\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/Geralt-Targaryen/MC-Evaluation\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eStaCCQA\u003c/td\u003e\n\u003ctd\u003e270K\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Aligning LLMs through Multi-perspective User Preference Ranking-based Feedback for Programming Question Answering\" [\u003ca href=\"https://arxiv.org/abs/2406.00037\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://anonymous.4open.science/r/PETCoQA-810A\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-06\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eRepoQA\u003c/td\u003e\n\u003ctd\u003e500\u003c/td\u003e\n\u003ctd\u003ePython, C++, Java, Rust, TypeScript\u003c/td\u003e\n\u003ctd\u003e\"RepoQA: Evaluating Long Context Code Understanding\" [\u003ca href=\"https://arxiv.org/abs/2406.06025\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/evalplus/repoqa\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-08\u003c/td\u003e\n\u003ctd\u003eACL 2025\u003c/td\u003e\n\u003ctd\u003eCruxEval-X\u003c/td\u003e\n\u003ctd\u003e12.6K\u003c/td\u003e\n\u003ctd\u003e19\u003c/td\u003e\n\u003ctd\u003e\"CRUXEval-X: A Benchmark for Multilingual Code Reasoning, Understanding and Execution\" [\u003ca href=\"https://arxiv.org/abs/2408.13001\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/CRUXEVAL-X/cruxeval-x\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-09\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eSpecEval\u003c/td\u003e\n\u003ctd\u003e204\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"SpecEval: Evaluating Code Comprehension in Large Language Models via Program Specifications\" [\u003ca href=\"https://arxiv.org/abs/2409.12866\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://sites.google.com/view/speceval/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-10\u003c/td\u003e\n\u003ctd\u003eICLR 2025\u003c/td\u003e\n\u003ctd\u003eCodeMMLU\u003c/td\u003e\n\u003ctd\u003e19912\u003c/td\u003e\n\u003ctd\u003e13\u003c/td\u003e\n\u003ctd\u003e\"CodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding Capabilities of CodeLLMs\" [\u003ca href=\"https://arxiv.org/abs/2410.01999\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/FSoft-AI4Code/CodeMMLU\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-11\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eunnamed\u003c/td\u003e\n\u003ctd\u003e80232\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Leveraging Large Language Models in Code Question Answering: Baselines and Issues\" [\u003ca href=\"https://arxiv.org/abs/2411.03012\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/IU-AES-AI4Code/CodeQuestionAnswering\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-11\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eScratchEval\u003c/td\u003e\n\u003ctd\u003e305\u003c/td\u003e\n\u003ctd\u003eScratch\u003c/td\u003e\n\u003ctd\u003e\"ScratchEval: Are GPT-4o Smarter than My Child? Evaluating Large Multimodal Models with Visual Programming Challenges\" [\u003ca href=\"https://arxiv.org/abs/2411.18932\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/HKBUNLP/ScratchEval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-12\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCodeRepoQA\u003c/td\u003e\n\u003ctd\u003e585,687\u003c/td\u003e\n\u003ctd\u003ePython, Java, TS, JS, Go\u003c/td\u003e\n\u003ctd\u003e\"CodeRepoQA: A Large-scale Benchmark for Software Engineering Question Answering\" [\u003ca href=\"https://arxiv.org/abs/2412.14764\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/kinesiatricssxilm14/CodeRepoQA\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-01\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCoReQA\u003c/td\u003e\n\u003ctd\u003e1,563\u003c/td\u003e\n\u003ctd\u003ePython, Java, Go, TS\u003c/td\u003e\n\u003ctd\u003e\"CoReQA: Uncovering Potentials of Language Models in Code Repository Question Answering\" [\u003ca href=\"https://arxiv.org/abs/2501.03447\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-02\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eEquiBench\u003c/td\u003e\n\u003ctd\u003e2400\u003c/td\u003e\n\u003ctd\u003eC, CUDA, x86-64, Python\u003c/td\u003e\n\u003ctd\u003e\"EquiBench: Benchmarking Code Reasoning Capabilities of Large Language Models via Equivalence Checking\" [\u003ca href=\"https://arxiv.org/abs/2502.12466\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-03\u003c/td\u003e\n\u003ctd\u003eACL 2025\u003c/td\u003e\n\u003ctd\u003eLONGCODEU\u003c/td\u003e\n\u003ctd\u003e3983\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"LONGCODEU: Benchmarking Long-Context Language Models on Long Code Understanding\" [\u003ca href=\"https://arxiv.org/abs/2503.04359\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCodeSense\u003c/td\u003e\n\u003ctd\u003e4495\u003c/td\u003e\n\u003ctd\u003ePython, C, Java\u003c/td\u003e\n\u003ctd\u003e\"CodeSense: a Real-World Benchmark and Dataset for Code Semantic Reasoning\" [\u003ca href=\"https://arxiv.org/abs/2506.00750\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://codesense-bench.github.io/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-07\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCORE\u003c/td\u003e\n\u003ctd\u003e12,533\u003c/td\u003e\n\u003ctd\u003eC/C++, Java, Python\u003c/td\u003e\n\u003ctd\u003e\"CORE: Benchmarking LLMs Code Reasoning Capabilities through Static Analysis Tasks\" [\u003ca href=\"https://arxiv.org/abs/2507.05269\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://corebench.github.io/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-09\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eSWE-QA\u003c/td\u003e\n\u003ctd\u003e576\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"SWE-QA: Can Language Models Answer Repository-level Code Questions?\" [\u003ca href=\"https://arxiv.org/abs/2509.14635\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/peng-weihan/SWE-QA-Bench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\u003c/markdown-accessiblity-table\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eText-to-SQL\u003c/h4\u003e\u003ca id=\"user-content-text-to-sql-1\" class=\"anchor\" aria-label=\"Permalink: Text-to-SQL\" href=\"#text-to-sql-1\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\"Deep learning driven natural languages text to SQL query conversion: A survey\", 2022-08, arXiv, [\u003ca href=\"https://arxiv.org/abs/2208.04415\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/li\u003e\n\u003cli\u003e\"Recent Advances in Text-to-SQL: A Survey of What We Have and What We Expect\", 2022-08, COLING 2022, [\u003ca href=\"https://arxiv.org/abs/2208.10099\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/li\u003e\n\u003cli\u003e\"A Survey on Text-to-SQL Parsing: Concepts, Methods, and Future Directions\", 2022-08, arXiv, [\u003ca href=\"https://arxiv.org/abs/2208.13629\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/li\u003e\n\u003cli\u003e\"A survey on deep learning approaches for text-to-SQL\", 2023-01, VLDB J., [\u003ca href=\"https://link.springer.com/article/10.1007/s00778-022-00776-8\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/li\u003e\n\u003c/ul\u003e\n\u003cmarkdown-accessiblity-table\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eDate\u003c/th\u003e\n\u003cth\u003eVenue\u003c/th\u003e\n\u003cth\u003eBenchmark\u003c/th\u003e\n\u003cth\u003eSize\u003c/th\u003e\n\u003cth\u003eLanguage\u003c/th\u003e\n\u003cth\u003eSource\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e2017-08\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eWikiSQL\u003c/td\u003e\n\u003ctd\u003e80654\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning\" [\u003ca href=\"https://arxiv.org/abs/1709.00103\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/salesforce/WikiSQL\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2018-06\u003c/td\u003e\n\u003ctd\u003eCL 2018\u003c/td\u003e\n\u003ctd\u003eAdvising\u003c/td\u003e\n\u003ctd\u003e4570\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"Improving Text-to-SQL Evaluation Methodology\" [\u003ca href=\"https://arxiv.org/abs/1806.09029\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/jkkummerfeld/text2sql-data/\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2018-09\u003c/td\u003e\n\u003ctd\u003eEMNLP 2018\u003c/td\u003e\n\u003ctd\u003eSpider\u003c/td\u003e\n\u003ctd\u003e10181\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task\" [\u003ca href=\"https://arxiv.org/abs/1809.08887\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://yale-lily.github.io/spider\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-06\u003c/td\u003e\n\u003ctd\u003eACL 2019\u003c/td\u003e\n\u003ctd\u003eSParC\u003c/td\u003e\n\u003ctd\u003e12726\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"SParC: Cross-Domain Semantic Parsing in Context\" [\u003ca href=\"https://arxiv.org/abs/1906.02285\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://yale-lily.github.io/sparc\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-07\u003c/td\u003e\n\u003ctd\u003eWWW 2020\u003c/td\u003e\n\u003ctd\u003eMIMICSQL\u003c/td\u003e\n\u003ctd\u003e10000\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"Text-to-SQL Generation for Question Answering on Electronic Medical Records\" [\u003ca href=\"https://arxiv.org/abs/1908.01839\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/wangpinggl/TREQS\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-09\u003c/td\u003e\n\u003ctd\u003eEMNLP-IJCNLP 2019\u003c/td\u003e\n\u003ctd\u003eCoSQL\u003c/td\u003e\n\u003ctd\u003e15598\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"CoSQL: A Conversational Text-to-SQL Challenge Towards Cross-Domain Natural Language Interfaces to Databases\" [\u003ca href=\"https://arxiv.org/abs/1909.05378\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://yale-lily.github.io/cosql\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2020-05\u003c/td\u003e\n\u003ctd\u003eLREC 2020\u003c/td\u003e\n\u003ctd\u003eCriteria-to-SQL\u003c/td\u003e\n\u003ctd\u003e2003\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"Dataset and Enhanced Model for Eligibility Criteria-to-SQL Semantic Parsing\" [\u003ca href=\"https://aclanthology.org/2020.lrec-1.714/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/xiaojingyu92/Criteria2SQL\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2020-10\u003c/td\u003e\n\u003ctd\u003eEMNLP 2020 Findings\u003c/td\u003e\n\u003ctd\u003eSquall\u003c/td\u003e\n\u003ctd\u003e11276\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"On the Potential of Lexico-logical Alignments for Semantic Parsing to SQL Queries\" [\u003ca href=\"https://arxiv.org/abs/2010.11246\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/tzshi/squall\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2020-10\u003c/td\u003e\n\u003ctd\u003eNAACL-HLT 2021\u003c/td\u003e\n\u003ctd\u003eSpider-Realistic\u003c/td\u003e\n\u003ctd\u003e508\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"Structure-Grounded Pretraining for Text-to-SQL\" [\u003ca href=\"https://arxiv.org/abs/2010.12773\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://zenodo.org/records/5205322\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-06\u003c/td\u003e\n\u003ctd\u003eACL/IJCNLP 2021\u003c/td\u003e\n\u003ctd\u003eSpider-Syn\u003c/td\u003e\n\u003ctd\u003e8034\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"Towards Robustness of Text-to-SQL Models against Synonym Substitution\" [\u003ca href=\"https://arxiv.org/abs/2106.01065\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://arxiv.org/abs/2106.01065\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-06\u003c/td\u003e\n\u003ctd\u003eNLP4Prog 2021\u003c/td\u003e\n\u003ctd\u003eSEDE\u003c/td\u003e\n\u003ctd\u003e12023\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"Text-to-SQL in the Wild: A Naturally-Occurring Dataset Based on Stack Exchange Data\" [\u003ca href=\"https://arxiv.org/abs/2106.05006\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/hirupert/sede\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-06\u003c/td\u003e\n\u003ctd\u003eACL/IJCNLP 2021\u003c/td\u003e\n\u003ctd\u003eKaggleDBQA\u003c/td\u003e\n\u003ctd\u003e400\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"KaggleDBQA: Realistic Evaluation of Text-to-SQL Parsers\" [\u003ca href=\"https://arxiv.org/abs/2106.11455\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/chiahsuan156/KaggleDBQA\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-09\u003c/td\u003e\n\u003ctd\u003eEMNLP\u003c/td\u003e\n\u003ctd\u003eSpider-DK\u003c/td\u003e\n\u003ctd\u003e535\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"Exploring Underexplored Limitations of Cross-Domain Text-to-SQL Generalization\" [\u003ca href=\"https://arxiv.org/abs/2109.05157\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/ygan/Spider-DK\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-05\u003c/td\u003e\n\u003ctd\u003eNAACL 2022 Findings\u003c/td\u003e\n\u003ctd\u003eSpider-SS/CG\u003c/td\u003e\n\u003ctd\u003e8034/45599\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"Measuring and Improving Compositional Generalization in Text-to-SQL via Component Alignment\" [\u003ca href=\"https://arxiv.org/abs/2205.02054\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/ygan/SpiderSS-SpiderCG\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eBIRD\u003c/td\u003e\n\u003ctd\u003e12751\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs\" [\u003ca href=\"https://arxiv.org/abs/2305.03111\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://bird-bench.github.io/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-06\u003c/td\u003e\n\u003ctd\u003eACL 2023\u003c/td\u003e\n\u003ctd\u003eXSemPLR\u003c/td\u003e\n\u003ctd\u003e24.4K\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations\" [\u003ca href=\"https://arxiv.org/abs/2306.04085\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/psunlpgroup/XSemPLR\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-05\u003c/td\u003e\n\u003ctd\u003eACL 2024 Findings\u003c/td\u003e\n\u003ctd\u003eEHR-SeqSQL\u003c/td\u003e\n\u003ctd\u003e31669\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"EHR-SeqSQL : A Sequential Text-to-SQL Dataset For Interactively Exploring Electronic Health Records\" [\u003ca href=\"https://arxiv.org/abs/2406.00019\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-06\u003c/td\u003e\n\u003ctd\u003eNAACL 2024\u003c/td\u003e\n\u003ctd\u003eBookSQL\u003c/td\u003e\n\u003ctd\u003e100K\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"BookSQL: A Large Scale Text-to-SQL Dataset for Accounting Domain\" [\u003ca href=\"https://arxiv.org/abs/2406.07860\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/Exploration-Lab/BookSQL\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-08\u003c/td\u003e\n\u003ctd\u003eACL 2024 Findings\u003c/td\u003e\n\u003ctd\u003eMultiSQL\u003c/td\u003e\n\u003ctd\u003e9257\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"MultiSQL: A Schema-Integrated Context-Dependent Text2SQL Dataset with Diverse SQL Operations\" [\u003ca href=\"https://aclanthology.org/2024.findings-acl.823/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/grandchicken/MultiSQL\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-09\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eBEAVER\u003c/td\u003e\n\u003ctd\u003e93\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"BEAVER: An Enterprise Benchmark for Text-to-SQL\" [\u003ca href=\"https://arxiv.org/abs/2409.02038\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-10\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003ePRACTIQ\u003c/td\u003e\n\u003ctd\u003e2812\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"PRACTIQ: A Practical Conversational Text-to-SQL dataset with Ambiguous and Unanswerable Queries\" [\u003ca href=\"https://arxiv.org/abs/2410.11076\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-10\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eBIS\u003c/td\u003e\n\u003ctd\u003e239\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"BIS: NL2SQL Service Evaluation Benchmark for Business Intelligence Scenarios\" [\u003ca href=\"https://arxiv.org/abs/2410.22925\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/boracaglayan/bis-nl2sql\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-11\u003c/td\u003e\n\u003ctd\u003eICLR 2025\u003c/td\u003e\n\u003ctd\u003eSpider 2.0\u003c/td\u003e\n\u003ctd\u003e632\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"Spider 2.0: Evaluating Language Models on Real-World Enterprise Text-to-SQL Workflows\" [\u003ca href=\"https://arxiv.org/abs/2411.07763\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/xlang-ai/Spider2\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-01\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eDialect2SQL\u003c/td\u003e\n\u003ctd\u003e9428\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"Dialect2SQL: A Novel Text-to-SQL Dataset for Arabic Dialects with a Focus on Moroccan Darija\" [\u003ca href=\"https://arxiv.org/abs/2501.11498\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eLogicCat\u003c/td\u003e\n\u003ctd\u003e4038\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"LogicCat: A Chain-of-Thought Text-to-SQL Benchmark for Multi-Domain Reasoning Challenges\" [\u003ca href=\"https://arxiv.org/abs/2505.18744\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eBiomedSQL\u003c/td\u003e\n\u003ctd\u003e68,000\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"BiomedSQL: Text-to-SQL for Scientific Reasoning on Biomedical Knowledge Bases\" [\u003ca href=\"https://arxiv.org/abs/2505.20321\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/NIH-CARD/biomedsql\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-09\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003ePARROT\u003c/td\u003e\n\u003ctd\u003e598\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"PARROT: A Benchmark for Evaluating LLMs in Cross-System SQL Translation\" [\u003ca href=\"https://arxiv.org/abs/2509.23338\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/weAIDB/PARROT\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-09\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eMultiSpider 2.0\u003c/td\u003e\n\u003ctd\u003e5056\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"Multilingual Text-to-SQL: Benchmarking the Limits of Language Models with Collaborative Language Agents\" [\u003ca href=\"https://arxiv.org/abs/2509.24405\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/phkhanhtrinh23/Multilingual_Text_to_SQL\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-10\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eBIRD-INTERACT\u003c/td\u003e\n\u003ctd\u003e600\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language Models via Lens of Dynamic Interactions\" [\u003ca href=\"https://arxiv.org/abs/2510.05318\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://bird-interact.github.io/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\u003c/markdown-accessiblity-table\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCode Translation\u003c/h4\u003e\u003ca id=\"user-content-code-translation-1\" class=\"anchor\" aria-label=\"Permalink: Code Translation\" href=\"#code-translation-1\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cmarkdown-accessiblity-table\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eDate\u003c/th\u003e\n\u003cth\u003eVenue\u003c/th\u003e\n\u003cth\u003eBenchmark\u003c/th\u003e\n\u003cth\u003eSize\u003c/th\u003e\n\u003cth\u003eLanguage\u003c/th\u003e\n\u003cth\u003eSource\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e2020-06\u003c/td\u003e\n\u003ctd\u003eNeurIPS 2020\u003c/td\u003e\n\u003ctd\u003eTranscoder GeeksforGeeks\u003c/td\u003e\n\u003ctd\u003e1.4K\u003c/td\u003e\n\u003ctd\u003eC++, Java, Python\u003c/td\u003e\n\u003ctd\u003e\"Unsupervised Translation of Programming Languages\" [\u003ca href=\"https://arxiv.org/abs/2006.03511\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/facebookresearch/TransCoder\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-02\u003c/td\u003e\n\u003ctd\u003eNeurIPS Datasets and Benchmarks 2021\u003c/td\u003e\n\u003ctd\u003eCodeTrans\u003c/td\u003e\n\u003ctd\u003e11.8K\u003c/td\u003e\n\u003ctd\u003eJava, C#\u003c/td\u003e\n\u003ctd\u003e\"CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation\" [\u003ca href=\"https://arxiv.org/abs/2102.04664\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/code_x_glue_cc_code_to_code_trans\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-08\u003c/td\u003e\n\u003ctd\u003eACL 2023 Findings\u003c/td\u003e\n\u003ctd\u003eAvatar\u003c/td\u003e\n\u003ctd\u003e9515\u003c/td\u003e\n\u003ctd\u003eJava, Python\u003c/td\u003e\n\u003ctd\u003e\"AVATAR: A Parallel Corpus for Java-Python Program Translation\" [\u003ca href=\"https://arxiv.org/abs/2108.11590\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/wasiahmad/AVATAR\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-06\u003c/td\u003e\n\u003ctd\u003eAAAI 2022\u003c/td\u003e\n\u003ctd\u003eCoST\u003c/td\u003e\n\u003ctd\u003e132K\u003c/td\u003e\n\u003ctd\u003eC++, Java, Python, C#, JS, PHP, C\u003c/td\u003e\n\u003ctd\u003e\"Multilingual Code Snippets Training for Program Translation\" [\u003ca href=\"https://ojs.aaai.org/index.php/AAAI/article/view/21434\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/reddy-lab-code-research/MuST-CoST\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-06\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eXLCoST\u003c/td\u003e\n\u003ctd\u003e567K\u003c/td\u003e\n\u003ctd\u003eC++, Java, Python, C#, JS, PHP, C\u003c/td\u003e\n\u003ctd\u003e\"XLCoST: A Benchmark Dataset for Cross-lingual Code Intelligence\" [\u003ca href=\"https://arxiv.org/abs/2206.08474\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/reddy-lab-code-research/XLCoST\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-03\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003exCodeEval\u003c/td\u003e\n\u003ctd\u003e5.6M\u003c/td\u003e\n\u003ctd\u003eC, C#, C++, Go, Java, JS, Kotlin, PHP, Python, Ruby, Rust\u003c/td\u003e\n\u003ctd\u003e\"xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval\" [\u003ca href=\"https://arxiv.org/abs/2303.03004\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/ntunlp/xCodeEval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-03\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eHumanEval-X\u003c/td\u003e\n\u003ctd\u003e1640\u003c/td\u003e\n\u003ctd\u003ePython, C++, Java, JS, Go\u003c/td\u003e\n\u003ctd\u003e\"CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X\" [\u003ca href=\"https://arxiv.org/abs/2303.17568\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/THUDM/CodeGeeX\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-08\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eG-TransEval\u003c/td\u003e\n\u003ctd\u003e4000\u003c/td\u003e\n\u003ctd\u003eC++, Java, C#, JS, Python\u003c/td\u003e\n\u003ctd\u003e\"On the Evaluation of Neural Code Translation: Taxonomy and Benchmark\" [\u003ca href=\"https://arxiv.org/abs/2308.08961\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/PolyEval/G-TransEval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-10\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCodeTransOcean\u003c/td\u003e\n\u003ctd\u003e270.5K\u003c/td\u003e\n\u003ctd\u003e45\u003c/td\u003e\n\u003ctd\u003e\"CodeTransOcean: A Comprehensive Multilingual Benchmark for Code Translation\" [\u003ca href=\"https://arxiv.org/abs/2310.04951\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/WeixiangYAN/CodeTransOcean\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-11\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eClasseval-T\u003c/td\u003e\n\u003ctd\u003e94\u003c/td\u003e\n\u003ctd\u003ePython, Java, C++\u003c/td\u003e\n\u003ctd\u003e\"Escalating LLM-based Code Translation Benchmarking into the Class-level Era\" [\u003ca href=\"https://arxiv.org/abs/2411.06145\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-11\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eRustRepoTrans\u003c/td\u003e\n\u003ctd\u003e375\u003c/td\u003e\n\u003ctd\u003eC++, Java, Python, Rust\u003c/td\u003e\n\u003ctd\u003e\"Repository-level Code Translation Benchmark Targeting Rust\" [\u003ca href=\"https://arxiv.org/abs/2411.13990\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/TrustedGPT/RustRepoTrans\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-12\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eRepoTransBench\u003c/td\u003e\n\u003ctd\u003e100\u003c/td\u003e\n\u003ctd\u003ePython, Java\u003c/td\u003e\n\u003ctd\u003e\"RepoTransBench: A Real-World Benchmark for Repository-Level Code Translation\" [\u003ca href=\"https://arxiv.org/abs/2412.17744\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-01\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eTransRepo-Bench\u003c/td\u003e\n\u003ctd\u003e13\u003c/td\u003e\n\u003ctd\u003eJava, C#\u003c/td\u003e\n\u003ctd\u003e\"Skeleton-Guided-Translation: A Benchmarking Framework for Code Repository Translation with Fine-Grained Quality Evaluation\" [\u003ca href=\"https://arxiv.org/abs/2501.16050\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-04\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCRUST-Bench\u003c/td\u003e\n\u003ctd\u003e100\u003c/td\u003e\n\u003ctd\u003eC, Rust\u003c/td\u003e\n\u003ctd\u003e\"CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation\" [\u003ca href=\"https://arxiv.org/abs/2504.15254\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/anirudhkhatry/CRUST-bench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\u003c/markdown-accessiblity-table\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eProgram Repair\u003c/h4\u003e\u003ca id=\"user-content-program-repair-1\" class=\"anchor\" aria-label=\"Permalink: Program Repair\" href=\"#program-repair-1\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\"Neural Program Repair: Systems, Challenges and Solutions\", 2022-02, Internetware 2022, [\u003ca href=\"https://arxiv.org/abs/2202.10868\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/li\u003e\n\u003cli\u003e\"A Survey of Learning-based Automated Program Repair\", 2023-01, arXiv, [\u003ca href=\"https://arxiv.org/abs/2301.03270\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/li\u003e\n\u003cli\u003e\"A Survey on Automated Program Repair Techniques\", 2023-03, arXiv, [\u003ca href=\"https://arxiv.org/abs/2303.18184\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/li\u003e\n\u003c/ul\u003e\n\u003cmarkdown-accessiblity-table\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eDate\u003c/th\u003e\n\u003cth\u003eVenue\u003c/th\u003e\n\u003cth\u003eBenchmark\u003c/th\u003e\n\u003cth\u003eSize\u003c/th\u003e\n\u003cth\u003eLanguage\u003c/th\u003e\n\u003cth\u003eSource\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e2014-07\u003c/td\u003e\n\u003ctd\u003eISSTA 2014\u003c/td\u003e\n\u003ctd\u003eDefects4J\u003c/td\u003e\n\u003ctd\u003e357\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Defects4J: A Database of Existing Faults to Enable Controlled Testing Studies for Java Programs\" [\u003ca href=\"https://dl.acm.org/doi/10.1145/2610384.2628055\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/rjust/defects4j\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2015-12\u003c/td\u003e\n\u003ctd\u003eIEEE Trans. Software Engineering\u003c/td\u003e\n\u003ctd\u003eManyBugs/IntroClass\u003c/td\u003e\n\u003ctd\u003e185/998\u003c/td\u003e\n\u003ctd\u003eC\u003c/td\u003e\n\u003ctd\u003e\"The ManyBugs and IntroClass Benchmarks for Automated Repair of C Programs\" [\u003ca href=\"https://ieeexplore.ieee.org/document/7153570\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://repairbenchmarks.cs.umass.edu/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2016-11\u003c/td\u003e\n\u003ctd\u003eFSE 2016\u003c/td\u003e\n\u003ctd\u003eBugAID\u003c/td\u003e\n\u003ctd\u003e105K\u003c/td\u003e\n\u003ctd\u003eJS\u003c/td\u003e\n\u003ctd\u003e\"Discovering Bug Patterns in JavaScript\" [\u003ca href=\"https://dl.acm.org/doi/10.1145/2950290.2950308\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://salt.ece.ubc.ca/software/bugaid/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2017-02\u003c/td\u003e\n\u003ctd\u003eAAAI 2017\u003c/td\u003e\n\u003ctd\u003eDeepFix\u003c/td\u003e\n\u003ctd\u003e6971\u003c/td\u003e\n\u003ctd\u003eC\u003c/td\u003e\n\u003ctd\u003e\"DeepFix: Fixing Common C Language Errors by Deep Learning\" [\u003ca href=\"https://ojs.aaai.org/index.php/AAAI/article/view/10742\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://bitbucket.org/iiscseal/deepfix/src/master/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2017-05\u003c/td\u003e\n\u003ctd\u003eICSE-C 2017\u003c/td\u003e\n\u003ctd\u003eCodeflaws\u003c/td\u003e\n\u003ctd\u003e3902\u003c/td\u003e\n\u003ctd\u003eC\u003c/td\u003e\n\u003ctd\u003e\"DeepFix: Fixing Common C Language Errors by Deep Learning\" [\u003ca href=\"https://dl.acm.org/doi/10.1109/ICSE-C.2017.76\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://codeflaws.github.io/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2017-10\u003c/td\u003e\n\u003ctd\u003eSPLASH 2017\u003c/td\u003e\n\u003ctd\u003eQuixBugs\u003c/td\u003e\n\u003ctd\u003e80\u003c/td\u003e\n\u003ctd\u003eJava, Python\u003c/td\u003e\n\u003ctd\u003e\"QuixBugs: a multi-lingual program repair benchmark set based on the quixey challenge\" [\u003ca href=\"https://dl.acm.org/doi/10.1145/3135932.3135941\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/jkoppel/QuixBugs\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2018-05\u003c/td\u003e\n\u003ctd\u003eMSR 2018\u003c/td\u003e\n\u003ctd\u003eBugs.jar\u003c/td\u003e\n\u003ctd\u003e1158\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Bugs.jar: a large-scale, diverse dataset of real-world Java bugs\" [\u003ca href=\"https://dl.acm.org/doi/10.1145/3196398.3196473\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/bugs-dot-jar/bugs-dot-jar\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2018-12\u003c/td\u003e\n\u003ctd\u003eACM Trans. Softw. Eng. Methodol.\u003c/td\u003e\n\u003ctd\u003eBFP\u003c/td\u003e\n\u003ctd\u003e124K\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"An Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation\" [\u003ca href=\"https://arxiv.org/abs/1812.08693\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://sites.google.com/view/learning-fixes\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-01\u003c/td\u003e\n\u003ctd\u003eSANER 2019\u003c/td\u003e\n\u003ctd\u003eBears\u003c/td\u003e\n\u003ctd\u003e251\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Bears: An Extensible Java Bug Benchmark for Automatic Program Repair Studies\" [\u003ca href=\"https://arxiv.org/abs/1901.06024\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/bears-bugs/bears-benchmark\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-01\u003c/td\u003e\n\u003ctd\u003eICSE 2019\u003c/td\u003e\n\u003ctd\u003eunnamed\u003c/td\u003e\n\u003ctd\u003e21.8K *\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"On Learning Meaningful Code Changes via Neural Machine Translation\" [\u003ca href=\"https://arxiv.org/abs/1901.09102\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://sites.google.com/view/learning-codechanges\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-04\u003c/td\u003e\n\u003ctd\u003eICST 2019\u003c/td\u003e\n\u003ctd\u003eBugsJS\u003c/td\u003e\n\u003ctd\u003e453\u003c/td\u003e\n\u003ctd\u003eJS\u003c/td\u003e\n\u003ctd\u003e\"BugsJS: a Benchmark of JavaScript Bugs\" [\u003ca href=\"https://ieeexplore.ieee.org/document/8730197\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://bugsjs.github.io/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-05\u003c/td\u003e\n\u003ctd\u003eICSE 2019\u003c/td\u003e\n\u003ctd\u003eBugSwarm\u003c/td\u003e\n\u003ctd\u003e1827/1264\u003c/td\u003e\n\u003ctd\u003eJava/Python\u003c/td\u003e\n\u003ctd\u003e\"BugSwarm: mining and continuously growing a dataset of reproducible failures and fixes\" [\u003ca href=\"https://dl.acm.org/doi/10.1109/ICSE.2019.00048\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://www.bugswarm.org/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-05\u003c/td\u003e\n\u003ctd\u003eICSE 2019\u003c/td\u003e\n\u003ctd\u003eCPatMiner\u003c/td\u003e\n\u003ctd\u003e17K *\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Graph-based mining of in-the-wild, fine-grained, semantic code change patterns\" [\u003ca href=\"https://dl.acm.org/doi/10.1109/ICSE.2019.00089\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://nguyenhoan.github.io/CPatMiner/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-05\u003c/td\u003e\n\u003ctd\u003eMSR 2020\u003c/td\u003e\n\u003ctd\u003eManySStuBs4J\u003c/td\u003e\n\u003ctd\u003e154K\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"How Often Do Single-Statement Bugs Occur? The ManySStuBs4J Dataset\" [\u003ca href=\"https://arxiv.org/abs/1905.13334\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/mast-group/mineSStuBs\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-11\u003c/td\u003e\n\u003ctd\u003eASE 2019\u003c/td\u003e\n\u003ctd\u003eRefactory\u003c/td\u003e\n\u003ctd\u003e1783\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Re-factoring based program repair applied to programming assignments\" [\u003ca href=\"https://dl.acm.org/doi/10.1109/ASE.2019.00044\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/githubhuyang/refactory\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2020-07\u003c/td\u003e\n\u003ctd\u003eISSTA 2020\u003c/td\u003e\n\u003ctd\u003eCoCoNut\u003c/td\u003e\n\u003ctd\u003e24M\u003c/td\u003e\n\u003ctd\u003eJava, Python, C, JS\u003c/td\u003e\n\u003ctd\u003e\"CoCoNuT: combining context-aware neural translation models using ensemble for program repair\" [\u003ca href=\"https://dl.acm.org/doi/10.1145/3395363.3397369\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/lin-tan/CoCoNut-Artifact\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2020-10\u003c/td\u003e\n\u003ctd\u003eInf. Softw. Technol.\u003c/td\u003e\n\u003ctd\u003eReview4Repair\u003c/td\u003e\n\u003ctd\u003e58021\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Review4Repair: Code Review Aided Automatic Program Repairing\" [\u003ca href=\"https://arxiv.org/abs/2010.01544\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/Review4Repair/Review4Repair\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2020-11\u003c/td\u003e\n\u003ctd\u003eESEC/FSE 2020\u003c/td\u003e\n\u003ctd\u003eBugsInPy\u003c/td\u003e\n\u003ctd\u003e493\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"BugsInPy: A Database of Existing Bugs in Python Programs to Enable Controlled Testing and Debugging Studies\" [\u003ca href=\"https://dl.acm.org/doi/abs/10.1145/3368089.3417943\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/soarsmu/BugsInPy\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-07\u003c/td\u003e\n\u003ctd\u003eICML 2021\u003c/td\u003e\n\u003ctd\u003eTFix\u003c/td\u003e\n\u003ctd\u003e105K\u003c/td\u003e\n\u003ctd\u003eJS\u003c/td\u003e\n\u003ctd\u003e\"TFix: Learning to Fix Coding Errors with a Text-to-Text Transformer\" [\u003ca href=\"https://proceedings.mlr.press/v139/berabi21a.html\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/eth-sri/TFix\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-08\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eMegadiff\u003c/td\u003e\n\u003ctd\u003e663K *\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Megadiff: A Dataset of 600k Java Source Code Changes Categorized by Diff Size\" [\u003ca href=\"https://arxiv.org/abs/2108.04631\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/ASSERT-KTH/megadiff\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-01\u003c/td\u003e\n\u003ctd\u003eSSB/TSSB\u003c/td\u003e\n\u003ctd\u003eMSR 2022\u003c/td\u003e\n\u003ctd\u003e9M/3M\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"TSSB-3M: Mining single statement bugs at massive scale\" [\u003ca href=\"https://arxiv.org/abs/2201.12046\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://cedricrupb.github.io/TSSB3M/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-10\u003c/td\u003e\n\u003ctd\u003eMSR 2022\u003c/td\u003e\n\u003ctd\u003eFixJS\u003c/td\u003e\n\u003ctd\u003e324K\u003c/td\u003e\n\u003ctd\u003eJS\u003c/td\u003e\n\u003ctd\u003e\"FixJS: a dataset of bug-fixing JavaScript commits\" [\u003ca href=\"https://dl.acm.org/doi/abs/10.1145/3524842.3528480\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/AAI-USZ/FixJS\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-11\u003c/td\u003e\n\u003ctd\u003eESEC/FSE 2022\u003c/td\u003e\n\u003ctd\u003eTypeBugs\u003c/td\u003e\n\u003ctd\u003e93\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"PyTER: Effective Program Repair for Python Type Errors\" [\u003ca href=\"https://dl.acm.org/doi/abs/10.1145/3540250.3549130\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/kupl/PyTER\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-03\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003exCodeEval\u003c/td\u003e\n\u003ctd\u003e4.7M\u003c/td\u003e\n\u003ctd\u003eC, C#, C++, Go, Java, JS, Kotlin, PHP, Python, Ruby, Rust\u003c/td\u003e\n\u003ctd\u003e\"xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval\" [\u003ca href=\"https://arxiv.org/abs/2303.03004\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/ntunlp/xCodeEval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-04\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eRunBugRun\u003c/td\u003e\n\u003ctd\u003e450K\u003c/td\u003e\n\u003ctd\u003eC, C++, Java, Python, JS, Ruby, Go, PHP\u003c/td\u003e\n\u003ctd\u003e\"RunBugRun -- An Executable Dataset for Automated Program Repair\" [\u003ca href=\"https://arxiv.org/abs/2304.01102\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/giganticode/run_bug_run\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-08\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eHumanEvalPack\u003c/td\u003e\n\u003ctd\u003e984\u003c/td\u003e\n\u003ctd\u003ePython, JS, Go, Java, C++, Rust\u003c/td\u003e\n\u003ctd\u003e\"OctoPack: Instruction Tuning Code Large Language Models\" [\u003ca href=\"https://arxiv.org/abs/2308.07124\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/bigcode/humanevalpack\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-01\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eDebugBench\u003c/td\u003e\n\u003ctd\u003e4253\u003c/td\u003e\n\u003ctd\u003eC++, Java, Python\u003c/td\u003e\n\u003ctd\u003e\"DebugBench: Evaluating Debugging Capability of Large Language Models\" [\u003ca href=\"https://arxiv.org/abs/2401.04621\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/thunlp/DebugBench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-11\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eMdEval\u003c/td\u003e\n\u003ctd\u003e3513\u003c/td\u003e\n\u003ctd\u003e18\u003c/td\u003e\n\u003ctd\u003e\"MdEval: Massively Multilingual Code Debugging\" [\u003ca href=\"https://arxiv.org/abs/2411.02310\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-01\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eunnamed\u003c/td\u003e\n\u003ctd\u003e48,398\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Suggesting Code Edits in Interactive Machine Learning Notebooks Using Large Language Models\" [\u003ca href=\"https://arxiv.org/abs/2501.09745\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://zenodo.org/records/14281690\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-09\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eAgentPack\u003c/td\u003e\n\u003ctd\u003e1.3M\u003c/td\u003e\n\u003ctd\u003e20+\u003c/td\u003e\n\u003ctd\u003e\"AgentPack: A Dataset of Code Changes, Co-Authored by Agents and Humans\" [\u003ca href=\"https://arxiv.org/abs/2509.21891\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/nuprl/AgentPack\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-09\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eOCEDataFT\u003c/td\u003e\n\u003ctd\u003e20K\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Generating High-Quality Datasets for Code Editing via Open-Source Language Models\" [\u003ca href=\"https://arxiv.org/abs/2509.25203\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/zkzhang88/OpenCodeEdit\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\u003c/markdown-accessiblity-table\u003e\n\u003cp dir=\"auto\"\u003e* These are code-change datasest, and only a subset therein concerns bug fixing.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCode Summarization\u003c/h4\u003e\u003ca id=\"user-content-code-summarization\" class=\"anchor\" aria-label=\"Permalink: Code Summarization\" href=\"#code-summarization\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\"A Survey of Automatic Source Code Summarization\", 2022-02, Symmetry, [\u003ca href=\"https://www.mdpi.com/2073-8994/14/3/471\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/li\u003e\n\u003c/ul\u003e\n\u003cmarkdown-accessiblity-table\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eDate\u003c/th\u003e\n\u003cth\u003eVenue\u003c/th\u003e\n\u003cth\u003eBenchmark\u003c/th\u003e\n\u003cth\u003eSize\u003c/th\u003e\n\u003cth\u003eLanguage\u003c/th\u003e\n\u003cth\u003eSource\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e2016-08\u003c/td\u003e\n\u003ctd\u003eACL 2016\u003c/td\u003e\n\u003ctd\u003eCODE-NN\u003c/td\u003e\n\u003ctd\u003e66K/32K\u003c/td\u003e\n\u003ctd\u003eC#/SQL\u003c/td\u003e\n\u003ctd\u003e\"Summarizing Source Code using a Neural Attention Model\" [\u003ca href=\"https://aclanthology.org/P16-1195/\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/sriniiyer/codenn\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2017-07\u003c/td\u003e\n\u003ctd\u003eIJCNLP 2017\u003c/td\u003e\n\u003ctd\u003eunnamed\u003c/td\u003e\n\u003ctd\u003e150K\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"A parallel corpus of Python functions and documentation strings for automated code documentation and code generation\" [\u003ca href=\"https://arxiv.org/abs/1707.02275\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/EdinburghNLP/code-docstring-corpus\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2018-05\u003c/td\u003e\n\u003ctd\u003eICPC 2018\u003c/td\u003e\n\u003ctd\u003eDeepCom\u003c/td\u003e\n\u003ctd\u003e588K\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Deep code comment generation\" [\u003ca href=\"https://dl.acm.org/doi/10.1145/3196321.3196334\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/xing-hu/DeepCom\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2018-07\u003c/td\u003e\n\u003ctd\u003eIJCAI 2018\u003c/td\u003e\n\u003ctd\u003eTL-CodeSum\u003c/td\u003e\n\u003ctd\u003e411K\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Summarizing Source Code with Transferred API Knowledge\" [\u003ca href=\"https://www.ijcai.org/proceedings/2018/314\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/xing-hu/TL-CodeSum\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2018-11\u003c/td\u003e\n\u003ctd\u003eASE 2018\u003c/td\u003e\n\u003ctd\u003eunnamed\u003c/td\u003e\n\u003ctd\u003e109K\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Improving Automatic Source Code Summarization via Deep Reinforcement Learning\" [\u003ca href=\"https://arxiv.org/abs/1811.07234\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/wanyao1992/code_summarization_public\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-09\u003c/td\u003e\n\u003ctd\u003earxiv\u003c/td\u003e\n\u003ctd\u003eCodeSearchNet\u003c/td\u003e\n\u003ctd\u003e2.3M\u003c/td\u003e\n\u003ctd\u003eGo, JS, Python, PHP, Java, Ruby\u003c/td\u003e\n\u003ctd\u003e\"CodeSearchNet Challenge: Evaluating the State of Semantic Code Search\" [\u003ca href=\"https://arxiv.org/abs/1909.09436\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/github/CodeSearchNet\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-08\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eHumanEvalPack\u003c/td\u003e\n\u003ctd\u003e984\u003c/td\u003e\n\u003ctd\u003ePython, JS, Go, Java, C++, Rust\u003c/td\u003e\n\u003ctd\u003e\"OctoPack: Instruction Tuning Code Large Language Models\" [\u003ca href=\"https://arxiv.org/abs/2308.07124\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/bigcode/humanevalpack\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\u003c/markdown-accessiblity-table\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eDefect/Vulnerability Detection\u003c/h4\u003e\u003ca id=\"user-content-defectvulnerability-detection\" class=\"anchor\" aria-label=\"Permalink: Defect/Vulnerability Detection\" href=\"#defectvulnerability-detection\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\"Benchmarking Software Vulnerability Detection Techniques: A Survey\", 2023-03, arXiv, [\u003ca href=\"https://arxiv.org/abs/2303.16362\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/li\u003e\n\u003c/ul\u003e\n\u003cmarkdown-accessiblity-table\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eDate\u003c/th\u003e\n\u003cth\u003eVenue\u003c/th\u003e\n\u003cth\u003eBenchmark\u003c/th\u003e\n\u003cth\u003eSize\u003c/th\u003e\n\u003cth\u003eLanguage\u003c/th\u003e\n\u003cth\u003eSource\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e2018-01\u003c/td\u003e\n\u003ctd\u003eNDSS 2018\u003c/td\u003e\n\u003ctd\u003eCGD\u003c/td\u003e\n\u003ctd\u003e62K\u003c/td\u003e\n\u003ctd\u003eC, C++\u003c/td\u003e\n\u003ctd\u003e\"VulDeePecker: A Deep Learning-Based System for Vulnerability Detection\" [\u003ca href=\"https://arxiv.org/abs/1801.01681\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/CGCL-codes/VulDeePecker\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2018-04\u003c/td\u003e\n\u003ctd\u003eIEEE Trans. Ind. Informatics\u003c/td\u003e\n\u003ctd\u003eunnamed\u003c/td\u003e\n\u003ctd\u003e32988\u003c/td\u003e\n\u003ctd\u003eC, C++\u003c/td\u003e\n\u003ctd\u003e\"Cross-Project Transfer Representation Learning for Vulnerable Function Discovery\" [\u003ca href=\"https://ieeexplore.ieee.org/document/8329207\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/DanielLin1986/TransferRepresentationLearning\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2018-07\u003c/td\u003e\n\u003ctd\u003eICMLA 2018\u003c/td\u003e\n\u003ctd\u003eDraper VDISC\u003c/td\u003e\n\u003ctd\u003e12.8M\u003c/td\u003e\n\u003ctd\u003eC, C++\u003c/td\u003e\n\u003ctd\u003e\"Automated Vulnerability Detection in Source Code Using Deep Representation Learning\" [\u003ca href=\"https://arxiv.org/abs/1807.04320\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://osf.io/d45bw/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2018-07\u003c/td\u003e\n\u003ctd\u003eIEEE TDSC\u003c/td\u003e\n\u003ctd\u003eSySeVR\u003c/td\u003e\n\u003ctd\u003e15591\u003c/td\u003e\n\u003ctd\u003eC, C++\u003c/td\u003e\n\u003ctd\u003e\"SySeVR: A Framework for Using Deep Learning to Detect Software Vulnerabilities\" [\u003ca href=\"https://arxiv.org/abs/1807.06756\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/SySeVR/SySeVR\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-02\u003c/td\u003e\n\u003ctd\u003eMSR 2019\u003c/td\u003e\n\u003ctd\u003eunnamed\u003c/td\u003e\n\u003ctd\u003e624\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"A Manually-Curated Dataset of Fixes to Vulnerabilities of Open-Source Software\" [\u003ca href=\"https://arxiv.org/abs/1902.02595\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/SAP/project-kb/tree/main/MSR2019\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-09\u003c/td\u003e\n\u003ctd\u003eNeurIPS 2019\u003c/td\u003e\n\u003ctd\u003eDevign\u003c/td\u003e\n\u003ctd\u003e49K\u003c/td\u003e\n\u003ctd\u003eC\u003c/td\u003e\n\u003ctd\u003e\"Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks\" [\u003ca href=\"https://arxiv.org/abs/1909.03496\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://sites.google.com/view/devign\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-11\u003c/td\u003e\n\u003ctd\u003eIEEE TDSC\u003c/td\u003e\n\u003ctd\u003eunnamed\u003c/td\u003e\n\u003ctd\u003e170K\u003c/td\u003e\n\u003ctd\u003eC, C++\u003c/td\u003e\n\u003ctd\u003e\"Software Vulnerability Discovery via Learning Multi-Domain Knowledge Bases\" [\u003ca href=\"https://ieeexplore.ieee.org/document/8906156\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/DanielLin1986/RepresentationsLearningFromMulti_domain\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-12\u003c/td\u003e\n\u003ctd\u003eICLR 2020\u003c/td\u003e\n\u003ctd\u003eGREAT\u003c/td\u003e\n\u003ctd\u003e2.8M\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Global Relational Models of Source Code\" [\u003ca href=\"https://openreview.net/forum?id=B1lnbRNtwr\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://zenodo.org/records/3954944\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2020-01\u003c/td\u003e\n\u003ctd\u003eIEEE TDSC\u003c/td\u003e\n\u003ctd\u003eMVD\u003c/td\u003e\n\u003ctd\u003e182K\u003c/td\u003e\n\u003ctd\u003eC, C++\u003c/td\u003e\n\u003ctd\u003e\"VulDeePecker: A Deep Learning-Based System for Multiclass Vulnerability Detection\" [\u003ca href=\"https://arxiv.org/abs/2001.02334\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/muVulDeePecker/muVulDeePecker\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2020-02\u003c/td\u003e\n\u003ctd\u003eICICS 2019\u003c/td\u003e\n\u003ctd\u003eunnamed\u003c/td\u003e\n\u003ctd\u003e1471\u003c/td\u003e\n\u003ctd\u003eC\u003c/td\u003e\n\u003ctd\u003e\"Deep Learning-Based Vulnerable Function Detection: A Benchmark\" [\u003ca href=\"https://link.springer.com/chapter/10.1007/978-3-030-41579-2_13\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/DanielLin1986/Function-level-Vulnerability-Detection\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2020-09\u003c/td\u003e\n\u003ctd\u003eIEEE Trans. Software Eng.\u003c/td\u003e\n\u003ctd\u003eReVeal\u003c/td\u003e\n\u003ctd\u003e18K\u003c/td\u003e\n\u003ctd\u003eC\u003c/td\u003e\n\u003ctd\u003e\"Deep Learning based Vulnerability Detection: Are We There Yet?\" [\u003ca href=\"https://arxiv.org/abs/2009.07235\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://bit.ly/3bX30ai\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2020-09\u003c/td\u003e\n\u003ctd\u003eMSR 2020\u003c/td\u003e\n\u003ctd\u003eBig-Vul\u003c/td\u003e\n\u003ctd\u003e265K\u003c/td\u003e\n\u003ctd\u003eC, C++\u003c/td\u003e\n\u003ctd\u003e\"A C/C++ Code Vulnerability Dataset with Code Changes and CVE Summaries\" [\u003ca href=\"https://dl.acm.org/doi/10.1145/3379597.3387501\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/ZeoVan/MSR_20_Code_Vulnerability_CSV_Dataset\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-02\u003c/td\u003e\n\u003ctd\u003eICSE (SEIP) 2021\u003c/td\u003e\n\u003ctd\u003eD2A\u003c/td\u003e\n\u003ctd\u003e1.3M\u003c/td\u003e\n\u003ctd\u003eC, C++\u003c/td\u003e\n\u003ctd\u003e\"D2A: A Dataset Built for AI-Based Vulnerability Detection Methods Using Differential Analysis\" [\u003ca href=\"https://arxiv.org/abs/2102.07995\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/ibm/D2A\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-05\u003c/td\u003e\n\u003ctd\u003eNeurIPS 2021\u003c/td\u003e\n\u003ctd\u003ePyPIBugs\u003c/td\u003e\n\u003ctd\u003e2374\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Self-Supervised Bug Detection and Repair\" [\u003ca href=\"https://arxiv.org/abs/2105.12787\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://www.microsoft.com/en-us/download/103554\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-07\u003c/td\u003e\n\u003ctd\u003eIn PROMISE 2021\u003c/td\u003e\n\u003ctd\u003eCVEfixes\u003c/td\u003e\n\u003ctd\u003e5495\u003c/td\u003e\n\u003ctd\u003e27\u003c/td\u003e\n\u003ctd\u003e\"CVEfixes: Automated Collection of Vulnerabilities and Their Fixes from Open-Source Software\" [\u003ca href=\"https://arxiv.org/abs/2107.08760\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://zenodo.org/records/7029359\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-08\u003c/td\u003e\n\u003ctd\u003eESEC/FSE 2021\u003c/td\u003e\n\u003ctd\u003eCrossVul\u003c/td\u003e\n\u003ctd\u003e27476\u003c/td\u003e\n\u003ctd\u003e40+\u003c/td\u003e\n\u003ctd\u003e\"CrossVul: a cross-language vulnerability dataset with commit data\" [\u003ca href=\"https://dl.acm.org/doi/10.1145/3468264.3473122\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://zenodo.org/records/4734050\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-04\u003c/td\u003e\n\u003ctd\u003eRAID 2023\u003c/td\u003e\n\u003ctd\u003eDiverseVul\u003c/td\u003e\n\u003ctd\u003e349K\u003c/td\u003e\n\u003ctd\u003eC, C++\u003c/td\u003e\n\u003ctd\u003e\"DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection\" [\u003ca href=\"https://arxiv.org/abs/2304.00409\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/wagner-group/diversevul\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-06\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eVulnPatchPairs\u003c/td\u003e\n\u003ctd\u003e26K\u003c/td\u003e\n\u003ctd\u003eC\u003c/td\u003e\n\u003ctd\u003e\"Limits of Machine Learning for Automatic Vulnerability Detection\" [\u003ca href=\"https://arxiv.org/abs/2306.17193\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/niklasrisse/LimitsOfML4Vuln\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-11\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eVulBench\u003c/td\u003e\n\u003ctd\u003e455\u003c/td\u003e\n\u003ctd\u003eC\u003c/td\u003e\n\u003ctd\u003e\"How Far Have We Gone in Vulnerability Detection Using Large Language Models\" [\u003ca href=\"https://arxiv.org/abs/2311.12420\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://anonymous.4open.science/r/VulBench-EA6F/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-03\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003ePrimeVul\u003c/td\u003e\n\u003ctd\u003e236K\u003c/td\u003e\n\u003ctd\u003eC/C++\u003c/td\u003e\n\u003ctd\u003e\"Vulnerability Detection with Code Language Models: How Far Are We?\" [\u003ca href=\"https://arxiv.org/abs/2403.18624\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-06\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eVulDetectBench\u003c/td\u003e\n\u003ctd\u003e1000\u003c/td\u003e\n\u003ctd\u003eC/C++\u003c/td\u003e\n\u003ctd\u003e\"VulDetectBench: Evaluating the Deep Capability of Vulnerability Detection with Large Language Models\" [\u003ca href=\"https://arxiv.org/abs/2406.07595\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/Sweetaroo/VulDetectBench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-08\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCodeJudge-Eval\u003c/td\u003e\n\u003ctd\u003e1860\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"CodeJudge-Eval: Can Large Language Models be Good Judges in Code Understanding?\" [\u003ca href=\"https://arxiv.org/abs/2408.10718\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/CodeLLM-Research/CodeJudge-Eval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-11\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCleanVul\u003c/td\u003e\n\u003ctd\u003e11632\u003c/td\u003e\n\u003ctd\u003eJava, Python, JS, C#, C/C++\u003c/td\u003e\n\u003ctd\u003e\"CleanVul: Automatic Function-Level Vulnerability Detection in Code Commits Using LLM Heuristics\" [\u003ca href=\"https://arxiv.org/abs/2411.17274\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/yikun-li/CleanVul\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-03\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCASTLE\u003c/td\u003e\n\u003ctd\u003e250\u003c/td\u003e\n\u003ctd\u003eC\u003c/td\u003e\n\u003ctd\u003e\"CASTLE: Benchmarking Dataset for Static Code Analyzers and LLMs towards CWE Detection\" [\u003ca href=\"https://arxiv.org/abs/2503.09433\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/CASTLE-Benchmark/Tests-C250\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-03\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eDSDBench\u003c/td\u003e\n\u003ctd\u003e1117\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Why Stop at One Error? Benchmarking LLMs as Data Science Code Debuggers for Multi-Hop and Multi-Bug Errors\" [\u003ca href=\"https://arxiv.org/abs/2503.22388\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/KevinCL16/DSDBench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eSecVulEval\u003c/td\u003e\n\u003ctd\u003e25440\u003c/td\u003e\n\u003ctd\u003eC/C++\u003c/td\u003e\n\u003ctd\u003e\"SecVulEval: Benchmarking LLMs for Real-World C/C++ Vulnerability Detection\" [\u003ca href=\"https://arxiv.org/abs/2505.19828\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/basimbd/SecVulEval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eSV-TrustEval-C\u003c/td\u003e\n\u003ctd\u003e3,337\u003c/td\u003e\n\u003ctd\u003eC\u003c/td\u003e\n\u003ctd\u003e\"SV-TrustEval-C: Evaluating Structure and Semantic Reasoning in Large Language Models for Source Code Vulnerability Analysis\" [\u003ca href=\"https://arxiv.org/abs/2505.20630\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/Jackline97/SV-TrustEval-C\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-09\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eMULocBench\u003c/td\u003e\n\u003ctd\u003e1,100\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"A Benchmark for Localizing Code and Non-Code Issues in Software Projects\" [\u003ca href=\"https://arxiv.org/abs/2509.25242\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/somethingone/MULocBench\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\u003c/markdown-accessiblity-table\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCode Retrieval\u003c/h4\u003e\u003ca id=\"user-content-code-retrieval\" class=\"anchor\" aria-label=\"Permalink: Code Retrieval\" href=\"#code-retrieval\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\"Code Search: A Survey of Techniques for Finding Code\", 2022-04, ICSME 2021, [[paper](ACM Comput. Surv)]\u003c/li\u003e\n\u003cli\u003e\"A Survey of Deep Code Search\", 2023-05, arXiv, [\u003ca href=\"https://arxiv.org/abs/2305.05959\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/li\u003e\n\u003c/ul\u003e\n\u003cmarkdown-accessiblity-table\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eDate\u003c/th\u003e\n\u003cth\u003eVenue\u003c/th\u003e\n\u003cth\u003eBenchmark\u003c/th\u003e\n\u003cth\u003eSize\u003c/th\u003e\n\u003cth\u003eLanguage\u003c/th\u003e\n\u003cth\u003eSource\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e2018-03\u003c/td\u003e\n\u003ctd\u003eWWW 2018\u003c/td\u003e\n\u003ctd\u003eStaQC\u003c/td\u003e\n\u003ctd\u003e148K/120K\u003c/td\u003e\n\u003ctd\u003ePython/SQL\u003c/td\u003e\n\u003ctd\u003e\"StaQC: A Systematically Mined Question-Code Dataset from Stack Overflow\" [\u003ca href=\"https://arxiv.org/abs/1803.09371\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/LittleYUYU/StackOverflow-Question-Code-Dataset\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2018-05\u003c/td\u003e\n\u003ctd\u003eICSE 2018\u003c/td\u003e\n\u003ctd\u003eDeepCS\u003c/td\u003e\n\u003ctd\u003e16.2M\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Deep Code Search\" [\u003ca href=\"https://dl.acm.org/doi/10.1145/3180155.3180167\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/guxd/deep-code-search\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2018-05\u003c/td\u003e\n\u003ctd\u003eMSR 2018\u003c/td\u003e\n\u003ctd\u003eCoNaLa\u003c/td\u003e\n\u003ctd\u003e600K/2.9K\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Learning to Mine Aligned Code and Natural Language Pairs from Stack Overflow\" [\u003ca href=\"https://arxiv.org/abs/1805.08949\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://conala-corpus.github.io/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-08\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eunnamed\u003c/td\u003e\n\u003ctd\u003e287\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Neural Code Search Evaluation Dataset\" [\u003ca href=\"https://arxiv.org/abs/1908.09804\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/facebookresearch/Neural-Code-Search-Evaluation-Dataset\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-09\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCodeSearchNet\u003c/td\u003e\n\u003ctd\u003e2.3M/99\u003c/td\u003e\n\u003ctd\u003eGo, PHP, JS, Python, Java, Ruby\u003c/td\u003e\n\u003ctd\u003e\"CodeSearchNet Challenge: Evaluating the State of Semantic Code Search\" [\u003ca href=\"https://arxiv.org/abs/1909.09436\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/github/CodeSearchNet\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2020-02\u003c/td\u003e\n\u003ctd\u003eSANER 2020\u003c/td\u003e\n\u003ctd\u003eCosBench\u003c/td\u003e\n\u003ctd\u003e52\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Are the Code Snippets What We Are Searching for? A Benchmark and an Empirical Study on Code Search with Natural-Language Queries\" [\u003ca href=\"https://ieeexplore.ieee.org/document/9054840\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/BASE-LAB-SJTU/CosBench/wiki\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2020-08\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eSO-DS\u003c/td\u003e\n\u003ctd\u003e2.2K\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Neural Code Search Revisited: Enhancing Code Snippet Retrieval through Natural Language Intent\" [\u003ca href=\"https://arxiv.org/abs/2008.12193\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/nokia/codesearch\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2020-10\u003c/td\u003e\n\u003ctd\u003eACM Trans. Knowl. Discov. Data\u003c/td\u003e\n\u003ctd\u003eFB-Java\u003c/td\u003e\n\u003ctd\u003e249K\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Deep Graph Matching and Searching for Semantic Code Retrieval\" [\u003ca href=\"https://arxiv.org/abs/2010.12908\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/ryderling/DGMS\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-02\u003c/td\u003e\n\u003ctd\u003eNeurIPS Datasets and Benchmarks 2021\u003c/td\u003e\n\u003ctd\u003eAdvTest/WebQueryTest\u003c/td\u003e\n\u003ctd\u003e280K/1K\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation\" [\u003ca href=\"https://arxiv.org/abs/2102.04664\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [[data]]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-05\u003c/td\u003e\n\u003ctd\u003eACL/IJCNLP 2021\u003c/td\u003e\n\u003ctd\u003eCoSQA\u003c/td\u003e\n\u003ctd\u003e21K\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"CoSQA: 20,000+ Web Queries for Code Search and Question Answering\" [\u003ca href=\"https://arxiv.org/abs/2105.13239\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/microsoft/CodeXGLUE/tree/main/Text-Code/NL-code-search-WebQuery\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-03\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eProCQA\u003c/td\u003e\n\u003ctd\u003e5.2M\u003c/td\u003e\n\u003ctd\u003eC, C++, Java, Python, Ruby, Lisp, JS, C#, Go, Rust, PHP\u003c/td\u003e\n\u003ctd\u003e\"ProCQA: A Large-scale Community-based Programming Question Answering Dataset for Code Search\" [\u003ca href=\"https://arxiv.org/abs/2403.16702\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/jordane95/procqa\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-06\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCoSQA+\u003c/td\u003e\n\u003ctd\u003e109K\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"CoSQA+: Enhancing Code Search Dataset with Matching Code\" [\u003ca href=\"https://arxiv.org/abs/2406.11589\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/DeepSoftwareAnalytics/CoSQA_Plus\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-07\u003c/td\u003e\n\u003ctd\u003eACL 2025\u003c/td\u003e\n\u003ctd\u003eCoIR\u003c/td\u003e\n\u003ctd\u003e~2M\u003c/td\u003e\n\u003ctd\u003e14\u003c/td\u003e\n\u003ctd\u003e\"CoIR: A Comprehensive Benchmark for Code Information Retrieval Models\" [\u003ca href=\"https://arxiv.org/abs/2407.02883\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/CoIR-team/coir\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-08\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eSeqCoBench\u003c/td\u003e\n\u003ctd\u003e14.5K\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"What can Large Language Models Capture about Code Functional Equivalence?\" [\u003ca href=\"https://arxiv.org/abs/2408.11081\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCoQuIR\u003c/td\u003e\n\u003ctd\u003e42,725\u003c/td\u003e\n\u003ctd\u003e11\u003c/td\u003e\n\u003ctd\u003e\"CoQuIR: A Comprehensive Benchmark for Code Quality-Aware Information Retrieval\" [\u003ca href=\"https://arxiv.org/abs/2506.11066\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/TRUMANCFY/CoQuIR\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\u003c/markdown-accessiblity-table\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eType Inference\u003c/h4\u003e\u003ca id=\"user-content-type-inference\" class=\"anchor\" aria-label=\"Permalink: Type Inference\" href=\"#type-inference\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cmarkdown-accessiblity-table\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eDate\u003c/th\u003e\n\u003cth\u003eVenue\u003c/th\u003e\n\u003cth\u003eBenchmark\u003c/th\u003e\n\u003cth\u003eSize\u003c/th\u003e\n\u003cth\u003eLanguage\u003c/th\u003e\n\u003cth\u003eSource\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-12\u003c/td\u003e\n\u003ctd\u003eESEC/FSE 2020\u003c/td\u003e\n\u003ctd\u003eTypeWriter OSS\u003c/td\u003e\n\u003ctd\u003e208K\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"TypeWriter: Neural Type Prediction with Search-based Validation\" [\u003ca href=\"https://arxiv.org/abs/1912.03768\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"http://software-lab.org/projects/TypeWriter/data.tar.gz\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2020-04\u003c/td\u003e\n\u003ctd\u003ePLDI 2020\u003c/td\u003e\n\u003ctd\u003eTypilus\u003c/td\u003e\n\u003ctd\u003e252K\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Typilus: Neural Type Hints\" [\u003ca href=\"https://arxiv.org/abs/2004.10657\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/typilus/typilus\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2020-04\u003c/td\u003e\n\u003ctd\u003eICLR 2020\u003c/td\u003e\n\u003ctd\u003eLambdaNet\u003c/td\u003e\n\u003ctd\u003e300 *\u003c/td\u003e\n\u003ctd\u003eTypeScript\u003c/td\u003e\n\u003ctd\u003e\"LambdaNet: Probabilistic Type Inference using Graph Neural Networks\" [\u003ca href=\"https://arxiv.org/abs/2005.02161\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/MrVPlusOne/LambdaNet\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-04\u003c/td\u003e\n\u003ctd\u003eMSR 2021\u003c/td\u003e\n\u003ctd\u003eManyTypes4Py\u003c/td\u003e\n\u003ctd\u003e869K\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"ManyTypes4Py: A Benchmark Python Dataset for Machine Learning-based Type Inference\" [\u003ca href=\"https://arxiv.org/abs/2104.04706\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/saltudelft/many-types-4-py-dataset\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2022-10\u003c/td\u003e\n\u003ctd\u003eMSR 2022\u003c/td\u003e\n\u003ctd\u003eManyTypes4TypeScript\u003c/td\u003e\n\u003ctd\u003e9.1M\u003c/td\u003e\n\u003ctd\u003eTypeScript\u003c/td\u003e\n\u003ctd\u003e\"ManyTypes4TypeScript: a comprehensive TypeScript dataset for sequence-based type inference\" [\u003ca href=\"https://dl.acm.org/doi/10.1145/3524842.3528507\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/kevinjesse/ManyTypes4TypeScript\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-02\u003c/td\u003e\n\u003ctd\u003eECOOP 2023\u003c/td\u003e\n\u003ctd\u003eTypeWeaver\u003c/td\u003e\n\u003ctd\u003e513 *\u003c/td\u003e\n\u003ctd\u003eTypeScript\u003c/td\u003e\n\u003ctd\u003e\"Do Machine Learning Models Produce TypeScript Types That Type Check?\" [\u003ca href=\"https://arxiv.org/abs/2302.12163\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://zenodo.org/records/7662708\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-03\u003c/td\u003e\n\u003ctd\u003eICLR 2023\u003c/td\u003e\n\u003ctd\u003eBetterTypes4Py/InferTypes4Py\u003c/td\u003e\n\u003ctd\u003e608K/4.6K\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"TypeT5: Seq2seq Type Inference using Static Analysis\" [\u003ca href=\"https://arxiv.org/abs/2303.09564\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/utopia-group/TypeT5\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eOpenTau\u003c/td\u003e\n\u003ctd\u003e744 *\u003c/td\u003e\n\u003ctd\u003eTypeScript\u003c/td\u003e\n\u003ctd\u003e\"Type Prediction With Program Decomposition and Fill-in-the-Type Training\" [\u003ca href=\"https://arxiv.org/abs/2305.17145\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/GammaTauAI/opentau\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\u003c/markdown-accessiblity-table\u003e\n\u003cp dir=\"auto\"\u003e* These are project counts.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCommit Message Generation\u003c/h4\u003e\u003ca id=\"user-content-commit-message-generation-1\" class=\"anchor\" aria-label=\"Permalink: Commit Message Generation\" href=\"#commit-message-generation-1\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\"On the Evaluation of Commit Message Generation Models: An Experimental Study\", 2021-07, ICSME 2021, [\u003ca href=\"https://arxiv.org/abs/2107.05373\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/li\u003e\n\u003c/ul\u003e\n\u003cmarkdown-accessiblity-table\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eDate\u003c/th\u003e\n\u003cth\u003eVenue\u003c/th\u003e\n\u003cth\u003eBenchmark\u003c/th\u003e\n\u003cth\u003eSize\u003c/th\u003e\n\u003cth\u003eLanguage\u003c/th\u003e\n\u003cth\u003eSource\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e2017-03\u003c/td\u003e\n\u003ctd\u003eICPC 2017\u003c/td\u003e\n\u003ctd\u003eunnamed\u003c/td\u003e\n\u003ctd\u003e509K\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Towards Automatic Generation of Short Summaries of Commits\" [\u003ca href=\"https://arxiv.org/abs/1703.09603\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://notredame.app.box.com/s/wghwpw46x41nu6iulm6qi8j42finuxni\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2017-04\u003c/td\u003e\n\u003ctd\u003eACL 2017\u003c/td\u003e\n\u003ctd\u003eCommitGen\u003c/td\u003e\n\u003ctd\u003e153K\u003c/td\u003e\n\u003ctd\u003ePython, JS, C++, Java\u003c/td\u003e\n\u003ctd\u003e\"A Neural Architecture for Generating Natural Language Descriptions from Source Code Changes\" [\u003ca href=\"https://arxiv.org/abs/1704.04856\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/epochx/commitgen\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2017-08\u003c/td\u003e\n\u003ctd\u003eASE 2017\u003c/td\u003e\n\u003ctd\u003eCommitGen\u003c/td\u003e\n\u003ctd\u003e32K/75K *\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Automatically Generating Commit Messages from Diffs using Neural Machine Translation\" [\u003ca href=\"https://arxiv.org/abs/1708.09492\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://notredame.app.box.com/s/wghwpw46x41nu6iulm6qi8j42finuxni\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2018-09\u003c/td\u003e\n\u003ctd\u003eASE 2018\u003c/td\u003e\n\u003ctd\u003eNNGen\u003c/td\u003e\n\u003ctd\u003e27K\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Neural-machine-translation-based commit message generation: how far are we?\" [\u003ca href=\"https://dl.acm.org/doi/10.1145/3238147.3238190\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/Tbabm/nngen\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-05\u003c/td\u003e\n\u003ctd\u003eMSR 2019\u003c/td\u003e\n\u003ctd\u003ePtrGNCMsg\u003c/td\u003e\n\u003ctd\u003e64.9K\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Generating commit messages from diffs using pointer-generator network\" [\u003ca href=\"https://dl.acm.org/doi/10.1109/MSR.2019.00056\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [[data(\u003ca href=\"https://zenodo.org/records/2593787\" rel=\"nofollow\"\u003ehttps://zenodo.org/records/2593787\u003c/a\u003e)]]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-08\u003c/td\u003e\n\u003ctd\u003eIJCAI 2019\u003c/td\u003e\n\u003ctd\u003eCoDiSum\u003c/td\u003e\n\u003ctd\u003e90.7K\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Commit message generation for source code changes\" [\u003ca href=\"https://www.ijcai.org/proceedings/2019/552\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/SoftWiser-group/CoDiSum\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2019-12\u003c/td\u003e\n\u003ctd\u003eIEEE Trans. Software Eng.\u003c/td\u003e\n\u003ctd\u003eATOM\u003c/td\u003e\n\u003ctd\u003e160K\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"ATOM: Commit Message Generation Based on Abstract Syntax Tree and Hybrid Ranking\" [\u003ca href=\"https://arxiv.org/abs/1912.02972\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://zenodo.org/records/4077754#.X4K2b5MzZTY\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCommitBERT\u003c/td\u003e\n\u003ctd\u003e346K\u003c/td\u003e\n\u003ctd\u003ePython, PHP, Go, Java, JS, Ruby\u003c/td\u003e\n\u003ctd\u003e\"CommitBERT: Commit Message Generation Using Pre-Trained Programming Language Model\" [\u003ca href=\"https://arxiv.org/abs/2105.14242\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/graykode/commit-autosuggestions\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-07\u003c/td\u003e\n\u003ctd\u003eICSME 2021\u003c/td\u003e\n\u003ctd\u003eMCMD\u003c/td\u003e\n\u003ctd\u003e2.25M\u003c/td\u003e\n\u003ctd\u003eJava, C#, C++, Python, JS\u003c/td\u003e\n\u003ctd\u003e\"On the Evaluation of Commit Message Generation Models: An Experimental Study\" [\u003ca href=\"https://arxiv.org/abs/2107.05373\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/DeepSoftwareAnalytics/CommitMsgEmpirical\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2021-07\u003c/td\u003e\n\u003ctd\u003eACM Trans. Softw. Eng. Methodol.\u003c/td\u003e\n\u003ctd\u003eCoRec\u003c/td\u003e\n\u003ctd\u003e107K\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Context-aware Retrieval-based Deep Commit Message Generation\" [\u003ca href=\"https://dl.acm.org/doi/10.1145/3464689\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://zenodo.org/records/3828107\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-07\u003c/td\u003e\n\u003ctd\u003eASE 2023\u003c/td\u003e\n\u003ctd\u003eExGroFi\u003c/td\u003e\n\u003ctd\u003e19263\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Delving into Commit-Issue Correlation to Enhance Commit Message Generation Models\" [\u003ca href=\"https://arxiv.org/abs/2308.00147\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://zenodo.org/records/7885748#.ZFDT5IJBxD8\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-08\u003c/td\u003e\n\u003ctd\u003eASE 2023\u003c/td\u003e\n\u003ctd\u003eCommitChronicle\u003c/td\u003e\n\u003ctd\u003e10.7M\u003c/td\u003e\n\u003ctd\u003e20\u003c/td\u003e\n\u003ctd\u003e\"From Commit Message Generation to History-Aware Commit Message Completion\" [\u003ca href=\"https://arxiv.org/abs/2308.07655\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/JetBrains-Research/commit_message_generation\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\u003c/markdown-accessiblity-table\u003e\n\u003cp dir=\"auto\"\u003e* with/without verb-direct object filter\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eRepo-Level Coding\u003c/h4\u003e\u003ca id=\"user-content-repo-level-coding\" class=\"anchor\" aria-label=\"Permalink: Repo-Level Coding\" href=\"#repo-level-coding\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cmarkdown-accessiblity-table\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eDate\u003c/th\u003e\n\u003cth\u003eVenue\u003c/th\u003e\n\u003cth\u003eBenchmark\u003c/th\u003e\n\u003cth\u003eSize\u003c/th\u003e\n\u003cth\u003eLanguage\u003c/th\u003e\n\u003cth\u003eSource\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-03\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eRepoEval\u003c/td\u003e\n\u003ctd\u003e1600/1600/373 *\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation\" [\u003ca href=\"https://arxiv.org/abs/2303.12570\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/microsoft/CodeT/tree/main/RepoCoder\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-06\u003c/td\u003e\n\u003ctd\u003eICLR 2024\u003c/td\u003e\n\u003ctd\u003eRepoBench\u003c/td\u003e\n\u003ctd\u003e890K/9M/43K \u003cmath-renderer class=\"js-inline-math\" style=\"display: inline-block\" data-run-id=\"b3caf4e842e88b86948a693f78d2e24c\"\u003e$^\\dagger$\u003c/math-renderer\u003e\n\u003c/td\u003e\n\u003ctd\u003ePython, Java\u003c/td\u003e\n\u003ctd\u003e\"RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems\" [\u003ca href=\"https://arxiv.org/abs/2306.03091\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/Leolty/repobench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-06\u003c/td\u003e\n\u003ctd\u003eNeurIPS 2023\u003c/td\u003e\n\u003ctd\u003ePragmaticCode\u003c/td\u003e\n\u003ctd\u003e880 **\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Guiding Language Models of Code with Global Context using Monitors\" [\u003ca href=\"https://arxiv.org/abs/2306.10763\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/microsoft/monitors4codegen\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-06\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eStack-Repo\u003c/td\u003e\n\u003ctd\u003e816K\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"RepoFusion: Training Code Models to Understand Your Repository\" [\u003ca href=\"https://arxiv.org/abs/2306.10998\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/RepoFusion\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-09\u003c/td\u003e\n\u003ctd\u003eISMB 2024\u003c/td\u003e\n\u003ctd\u003eBioCoder\u003c/td\u003e\n\u003ctd\u003e2269/460/460\u003c/td\u003e\n\u003ctd\u003ePython, Java\u003c/td\u003e\n\u003ctd\u003e\"BioCoder: A Benchmark for Bioinformatics Code Generation with Large Language Models\" [\u003ca href=\"https://arxiv.org/abs/2308.16458\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/lilbillbiscuit/biocoder_public\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-09\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCodePlan\u003c/td\u003e\n\u003ctd\u003e645/21 \u003cmath-renderer class=\"js-inline-math\" style=\"display: inline-block\" data-run-id=\"b3caf4e842e88b86948a693f78d2e24c\"\u003e$^\\ddagger$\u003c/math-renderer\u003e\n\u003c/td\u003e\n\u003ctd\u003eC#/Python \u003cmath-renderer class=\"js-inline-math\" style=\"display: inline-block\" data-run-id=\"b3caf4e842e88b86948a693f78d2e24c\"\u003e$^\\ddagger$\u003c/math-renderer\u003e\n\u003c/td\u003e\n\u003ctd\u003e\"CodePlan: Repository-level Coding using LLMs and Planning\" [\u003ca href=\"https://arxiv.org/abs/2309.12499\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://aka.ms/CodePlan\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-10\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eSWE-Bench\u003c/td\u003e\n\u003ctd\u003e2294\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"SWE-bench: Can Language Models Resolve Real-World GitHub Issues?\" [\u003ca href=\"https://arxiv.org/abs/2310.06770\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://www.swebench.com/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2023-10\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCrossCodeEval\u003c/td\u003e\n\u003ctd\u003e9928\u003c/td\u003e\n\u003ctd\u003ePython, Java, TypeScript, C#\u003c/td\u003e\n\u003ctd\u003e\"CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code Completion\" [\u003ca href=\"https://arxiv.org/abs/2310.11248\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://crosscodeeval.github.io/\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-03\u003c/td\u003e\n\u003ctd\u003eNeurIPS 2024\u003c/td\u003e\n\u003ctd\u003eEvoCodeBench\u003c/td\u003e\n\u003ctd\u003e275\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"EvoCodeBench: An Evolving Code Generation Benchmark Aligned with Real-World Code Repositories\" [\u003ca href=\"https://arxiv.org/abs/2404.00599\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/seketeam/EvoCodeBench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-05\u003c/td\u003e\n\u003ctd\u003eACL 2024 Findings\u003c/td\u003e\n\u003ctd\u003eDevEval\u003c/td\u003e\n\u003ctd\u003e1874\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"DevEval: A Manually-Annotated Code Generation Benchmark Aligned with Real-World Code Repositories\" [\u003ca href=\"https://arxiv.org/abs/2405.19856\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/seketeam/DevEval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-06\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eJavaBench\u003c/td\u003e\n\u003ctd\u003e389\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"Can AI Beat Undergraduates in Entry-level Java Assignments? Benchmarking Large Language Models on JavaBench\" [\u003ca href=\"https://arxiv.org/abs/2406.12902\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/java-bench/JavaBench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-06\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eHumanEvo\u003c/td\u003e\n\u003ctd\u003e200/200\u003c/td\u003e\n\u003ctd\u003ePython/Java\u003c/td\u003e\n\u003ctd\u003e\"Towards more realistic evaluation of LLM-based code generation: an experimental study and beyond\" [\u003ca href=\"https://arxiv.org/abs/2406.06918\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/DeepSoftwareAnalytics/EvoEval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-06\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eRepoExec\u003c/td\u003e\n\u003ctd\u003e355\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"REPOEXEC: Evaluate Code Generation with a Repository-Level Executable Benchmark\" [\u003ca href=\"https://arxiv.org/abs/2406.11927\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-06\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eRES-Q\u003c/td\u003e\n\u003ctd\u003e100\u003c/td\u003e\n\u003ctd\u003ePython, JavaScript\u003c/td\u003e\n\u003ctd\u003e\"RES-Q: Evaluating Code-Editing Large Language Model Systems at the Repository Scale\" [\u003ca href=\"https://arxiv.org/abs/2406.16801\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/Qurrent-AI/RES-Q\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-08\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eSWE-bench-java\u003c/td\u003e\n\u003ctd\u003e91\u003c/td\u003e\n\u003ctd\u003eJava\u003c/td\u003e\n\u003ctd\u003e\"SWE-bench-java: A GitHub Issue Resolving Benchmark for Java\" [\u003ca href=\"https://arxiv.org/abs/2408.14354\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/multi-swe-bench/multi-swe-bench.github.io\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-10\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCodev-Bench\u003c/td\u003e\n\u003ctd\u003e296\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Codev-Bench: How Do LLMs Understand Developer-Centric Code Completion?\" [\u003ca href=\"https://arxiv.org/abs/2410.01353\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/LingmaTongyi/Codev-Bench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-10\u003c/td\u003e\n\u003ctd\u003eICLR 2025\u003c/td\u003e\n\u003ctd\u003eSWE-bench M\u003c/td\u003e\n\u003ctd\u003e617\u003c/td\u003e\n\u003ctd\u003eJavaScript\u003c/td\u003e\n\u003ctd\u003e\"SWE-bench Multimodal: Do AI Systems Generalize to Visual Software Domains?\" [\u003ca href=\"https://arxiv.org/abs/2410.03859\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://www.swebench.com/multimodal\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-10\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eSWE-Bench+\u003c/td\u003e\n\u003ctd\u003e548\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"SWE-Bench+: Enhanced Coding Benchmark for LLMs\" [\u003ca href=\"https://arxiv.org/abs/2410.06992\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://zenodo.org/records/13879453\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-10\u003c/td\u003e\n\u003ctd\u003eEMNLP 2024\u003c/td\u003e\n\u003ctd\u003eDA-Code\u003c/td\u003e\n\u003ctd\u003e500\u003c/td\u003e\n\u003ctd\u003ePython, Bash, SQL\u003c/td\u003e\n\u003ctd\u003e\"DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models\" [\u003ca href=\"https://arxiv.org/abs/2410.07331\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/yiyihum/da-code\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-10\u003c/td\u003e\n\u003ctd\u003eACL 2025\u003c/td\u003e\n\u003ctd\u003eRepoCod\u003c/td\u003e\n\u003ctd\u003e980\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Can Language Models Replace Programmers? REPOCOD Says 'Not Yet'\" [\u003ca href=\"https://arxiv.org/abs/2410.21647\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-10\u003c/td\u003e\n\u003ctd\u003eACL 2025\u003c/td\u003e\n\u003ctd\u003eM2rc-Eval\u003c/td\u003e\n\u003ctd\u003e5993 repos\u003c/td\u003e\n\u003ctd\u003e18\u003c/td\u003e\n\u003ctd\u003e\"M2rc-Eval: Massively Multilingual Repository-level Code Completion Evaluation\" [\u003ca href=\"https://arxiv.org/abs/2410.21157\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/M2RC-Eval-Team/M2RC-Eval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-11\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eFAUN-Eval\u003c/td\u003e\n\u003ctd\u003e300\u003c/td\u003e\n\u003ctd\u003ePython, Java, JS, TS, Go\u003c/td\u003e\n\u003ctd\u003e\"A Real-World Benchmark for Evaluating Fine-Grained Issue Solving Capabilities of Large Language Models\" [\u003ca href=\"https://arxiv.org/abs/2411.18019\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://anonymous.4open.science/status/FAUN-Eval\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-12\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCommit0\u003c/td\u003e\n\u003ctd\u003e54\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"Commit0: Library Generation from Scratch\" [\u003ca href=\"https://arxiv.org/abs/2412.01769\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/commit-0/commit0\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-12\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eExecRepoBench\u003c/td\u003e\n\u003ctd\u003e1.2K\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"ExecRepoBench: Multi-level Executable Code Completion Evaluation\" [\u003ca href=\"https://arxiv.org/abs/2412.11990\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/QwenLM/Qwen2.5-Coder/tree/main/qwencoder-eval/instruct/CodeArena\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-01\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eDI-Bench\u003c/td\u003e\n\u003ctd\u003e581\u003c/td\u003e\n\u003ctd\u003ePython, C#, Rust, JS\u003c/td\u003e\n\u003ctd\u003e\"DI-BENCH: Benchmarking Large Language Models on Dependency Inference with Testable Repositories at Scale\" [\u003ca href=\"https://arxiv.org/abs/2501.13699\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/Microsoft/DI-Bench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-02\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eHackerRank-ASTRA\u003c/td\u003e\n\u003ctd\u003e65\u003c/td\u003e\n\u003ctd\u003efrontend\u003c/td\u003e\n\u003ctd\u003e\"HackerRank-ASTRA: Evaluating Correctness \u0026amp; Consistency of Large Language Models on cross-domain multi-file project problems\" [\u003ca href=\"https://arxiv.org/abs/2502.00226\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/hackerrank/astra-benchmark\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-02\u003c/td\u003e\n\u003ctd\u003eICML 2025\u003c/td\u003e\n\u003ctd\u003eSWE-Lancer\u003c/td\u003e\n\u003ctd\u003e237\u003c/td\u003e\n\u003ctd\u003eJS, TS\u003c/td\u003e\n\u003ctd\u003e\"SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?\" [\u003ca href=\"https://arxiv.org/abs/2502.12115\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/openai/SWELancer-Benchmark\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-03\u003c/td\u003e\n\u003ctd\u003eACL 2025\u003c/td\u003e\n\u003ctd\u003eFEA-Bench\u003c/td\u003e\n\u003ctd\u003e1401\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"FEA-Bench: A Benchmark for Evaluating Repository-Level Code Generation for Feature Implementation\" [\u003ca href=\"https://arxiv.org/abs/2503.06680\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-03\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eDependEval\u003c/td\u003e\n\u003ctd\u003e3.4K\u003c/td\u003e\n\u003ctd\u003e8\u003c/td\u003e\n\u003ctd\u003e\"DependEval: Benchmarking LLMs for Repository Dependency Understanding\" [\u003ca href=\"https://arxiv.org/abs/2503.06689\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/ink7-sudo/DependEval\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-03\u003c/td\u003e\n\u003ctd\u003eACL 2025 Findings\u003c/td\u003e\n\u003ctd\u003eProjectEval\u003c/td\u003e\n\u003ctd\u003e20\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"ProjectEval: A Benchmark for Programming Agents Automated Evaluation on Project-Level Code Generation\" [\u003ca href=\"https://arxiv.org/abs/2503.07010\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-03\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eRepoST-Eval\u003c/td\u003e\n\u003ctd\u003e296\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"RepoST: Scalable Repository-Level Coding Environment Construction with Sandbox Testing\" [\u003ca href=\"https://arxiv.org/abs/2503.07358\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/yiqingxyq/RepoST\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-04\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eMulti-SWE-bench\u003c/td\u003e\n\u003ctd\u003e1632\u003c/td\u003e\n\u003ctd\u003eJava, JS, TS, Go, Rust, C, C++\u003c/td\u003e\n\u003ctd\u003e\"Multi-SWE-bench: A Multilingual Benchmark for Issue Resolving\" [\u003ca href=\"https://arxiv.org/abs/2504.02605\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/multi-swe-bench/multi-swe-bench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-04\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eSWE-PolyBench\u003c/td\u003e\n\u003ctd\u003e2110\u003c/td\u003e\n\u003ctd\u003eJava, JS, TS, Python\u003c/td\u003e\n\u003ctd\u003e\"SWE-PolyBench: A multi-language benchmark for repository level evaluation of coding agents\" [\u003ca href=\"https://arxiv.org/abs/2504.08703\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/amazon-science/SWE-PolyBench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-04\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eSecRepoBench\u003c/td\u003e\n\u003ctd\u003e318\u003c/td\u003e\n\u003ctd\u003eC/C++\u003c/td\u003e\n\u003ctd\u003e\"SecRepoBench: Benchmarking LLMs for Secure Code Generation in Real-World Repositories\" [\u003ca href=\"https://arxiv.org/abs/2504.21205\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eOmniGIRL\u003c/td\u003e\n\u003ctd\u003e959\u003c/td\u003e\n\u003ctd\u003ePython, JS, TS, Java\u003c/td\u003e\n\u003ctd\u003e\"OmniGIRL: A Multilingual and Multimodal Benchmark for GitHub Issue Resolution\" [\u003ca href=\"https://arxiv.org/abs/2505.04606\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/DeepSoftwareAnalytics/OmniGIRL\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eSWE-Dev\u003c/td\u003e\n\u003ctd\u003e14500\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"SWE-Dev: Evaluating and Training Autonomous Feature-Driven Software Development\" [\u003ca href=\"https://arxiv.org/abs/2505.16975\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/justLittleWhite/SWE-Dev\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eSWE-rebench\u003c/td\u003e\n\u003ctd\u003e21,000\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"SWE-rebench: An Automated Pipeline for Task Collection and Decontaminated Evaluation of Software Engineering Agents\" [\u003ca href=\"https://arxiv.org/abs/2505.20411\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://huggingface.co/datasets/nebius/SWE-rebench\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eAgentIssue-Bench\u003c/td\u003e\n\u003ctd\u003e50\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"Can Agents Fix Agent Issues?\" [\u003ca href=\"https://arxiv.org/abs/2505.20749\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/alfin06/AgentIssue-Bench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eGitGoodBench\u003c/td\u003e\n\u003ctd\u003e900\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\"GitGoodBench: A Novel Benchmark For Evaluating Agentic Performance On Git\" [\u003ca href=\"https://arxiv.org/abs/2505.22583\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/JetBrains-Research/git-good-bench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-05\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eSwingArena\u003c/td\u003e\n\u003ctd\u003e400\u003c/td\u003e\n\u003ctd\u003eRust, Python, Go, C++\u003c/td\u003e\n\u003ctd\u003e\"SwingArena: Competitive Programming Arena for Long-context GitHub Issue Solving\" [\u003ca href=\"https://arxiv.org/abs/2505.23932\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://swing-bench.github.io\" rel=\"nofollow\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-07\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eCoreCodeBench\u003c/td\u003e\n\u003ctd\u003e1545\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"CoreCodeBench: A Configurable Multi-Scenario Repository-Level Benchmark\" [\u003ca href=\"https://arxiv.org/abs/2507.05281\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/AGI-Eval-Official/CoreCodeBench\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-07\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eLiveRepoReflection\u003c/td\u003e\n\u003ctd\u003e1888\u003c/td\u003e\n\u003ctd\u003eC++, Go, Java, JS, Python, Rust\u003c/td\u003e\n\u003ctd\u003e\"Turning the Tide: Repository-based Code Reflection\" [\u003ca href=\"https://arxiv.org/abs/2507.09866\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-07\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eSWE-Perf\u003c/td\u003e\n\u003ctd\u003e140\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"SWE-Perf: Can Language Models Optimize Code Performance on Real-World Repositories?\" [2025-07] [\u003ca href=\"https://arxiv.org/abs/2507.12415\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/swe-perf/swe-perf\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-09\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eRepoDebug\u003c/td\u003e\n\u003ctd\u003e30696\u003c/td\u003e\n\u003ctd\u003e8\u003c/td\u003e\n\u003ctd\u003e\"RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models\" [\u003ca href=\"https://arxiv.org/abs/2509.04078\" rel=\"nofollow\"\u003epaper\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-09\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eSWE-Bench Pro\u003c/td\u003e\n\u003ctd\u003e1865\u003c/td\u003e\n\u003ctd\u003ePython, Go, JS, TS\u003c/td\u003e\n\u003ctd\u003e\"SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?\" [\u003ca href=\"https://arxiv.org/abs/2509.16941\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/scaleapi/SWE-bench_Pro-os\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e2025-10\u003c/td\u003e\n\u003ctd\u003earXiv\u003c/td\u003e\n\u003ctd\u003eE2EDev\u003c/td\u003e\n\u003ctd\u003e46\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e\"E2Edev: Benchmarking Large Language Models in End-to-End Software Development Task\" [\u003ca href=\"https://arxiv.org/abs/2510.14509\" rel=\"nofollow\"\u003epaper\u003c/a\u003e] [\u003ca href=\"https://github.com/SCUNLP/E2EDev\"\u003edata\u003c/a\u003e]\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\u003c/markdown-accessiblity-table\u003e\n\u003cp dir=\"auto\"\u003e*Line Completion/API Invocation Completion/Function Completion\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003cmath-renderer class=\"js-inline-math\" style=\"display: inline-block\" data-run-id=\"b3caf4e842e88b86948a693f78d2e24c\"\u003e$^\\dagger$\u003c/math-renderer\u003e Retrieval/Completion/Pipeline\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e** File count\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003cmath-renderer class=\"js-inline-math\" style=\"display: inline-block\" data-run-id=\"b3caf4e842e88b86948a693f78d2e24c\"\u003e$^\\ddagger$\u003c/math-renderer\u003e Migration/Temporal Edit\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch4 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eOther tasks are coming soon!\u003c/h4\u003e\u003ca id=\"user-content-other-tasks-are-coming-soon\" class=\"anchor\" aria-label=\"Permalink: Other tasks are coming soon!\" href=\"#other-tasks-are-coming-soon\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e9. Recommended Readings\u003c/h2\u003e\u003ca id=\"user-content-9-recommended-readings\" class=\"anchor\" aria-label=\"Permalink: 9. Recommended Readings\" href=\"#9-recommended-readings\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003e30 papers as a primer on LLM.\u003c/p\u003e\n\u003cmarkdown-accessiblity-table\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth align=\"center\"\u003eDate\u003c/th\u003e\n\u003cth align=\"center\"\u003eKeyword\u003c/th\u003e\n\u003cth\u003ePaper\u003c/th\u003e\n\u003cth\u003eTL;DR\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2014-09\u003c/td\u003e\n\u003ctd align=\"center\"\u003eAttention\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/1409.0473\" rel=\"nofollow\"\u003eNeural Machine Translation by Jointly Learning to Align and Translate\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eThe original attention, proposed for encoder-decoder RNN\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2015-08\u003c/td\u003e\n\u003ctd align=\"center\"\u003eBPE\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/1508.07909\" rel=\"nofollow\"\u003eNeural Machine Translation of Rare Words with Subword Units\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eByte-pair encoding: split rare words into subword units\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2017-06\u003c/td\u003e\n\u003ctd align=\"center\"\u003eTransformer\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/1706.03762\" rel=\"nofollow\"\u003eAttention Is All You Need\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eReplace LSTM with self-attention for long-range dependency and parallel training\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2017-10\u003c/td\u003e\n\u003ctd align=\"center\"\u003eMixed Precision Training\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/1710.03740\" rel=\"nofollow\"\u003eMixed Precision Training\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eStore model weights in fp16 to save memory\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2018-04\u003c/td\u003e\n\u003ctd align=\"center\"\u003eGLUE\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/1804.07461\" rel=\"nofollow\"\u003eGLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eA language understanding benchmark\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2018-06\u003c/td\u003e\n\u003ctd align=\"center\"\u003eGPT\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf\" rel=\"nofollow\"\u003eImproving Language Understanding by Generative Pre-Training\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003ePretraining-finetuning paradigm applied to Transformer decoder\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2018-10\u003c/td\u003e\n\u003ctd align=\"center\"\u003eBERT\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/1810.04805\" rel=\"nofollow\"\u003eBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eMasked Language Modeling (MLM) applied to Transformer encoder for pretraining\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2019-02\u003c/td\u003e\n\u003ctd align=\"center\"\u003eGPT-2\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf\" rel=\"nofollow\"\u003eLanguage Models are Unsupervised Multitask Learners\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eGPT made larger (1.5B). They found language models implicitly learn about downstream tasks (such as translation) during pretraining.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2019-05\u003c/td\u003e\n\u003ctd align=\"center\"\u003eSuperGLUE\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/1905.00537\" rel=\"nofollow\"\u003eSuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eAnother language understanding benchmark\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2019-07\u003c/td\u003e\n\u003ctd align=\"center\"\u003eRoBERTa\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/1907.11692\" rel=\"nofollow\"\u003eRoBERTa: A Robustly Optimized BERT Pretraining Approach\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eAn optimized BERT\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2019-09\u003c/td\u003e\n\u003ctd align=\"center\"\u003eMegatron-LM\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/1909.08053\" rel=\"nofollow\"\u003eMegatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eModel parallelism\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2019-10\u003c/td\u003e\n\u003ctd align=\"center\"\u003eZeRO\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/1910.02054\" rel=\"nofollow\"\u003eZeRO: Memory Optimizations Toward Training Trillion Parameter Models\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eMemory-efficient distributed optimization\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2019-10\u003c/td\u003e\n\u003ctd align=\"center\"\u003eT5\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/1910.10683\" rel=\"nofollow\"\u003eExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eTransformer encoder-decoder pretrained with an MLM-like denoising objective\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2020-05\u003c/td\u003e\n\u003ctd align=\"center\"\u003eGPT-3\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/2005.14165\" rel=\"nofollow\"\u003eLanguage Models are Few-Shot Learners\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eBy training an even larger version of GPT-2 (175B), they discovered a new learning paradigm: In-Context Learning (ICL)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2020-09\u003c/td\u003e\n\u003ctd align=\"center\"\u003eMMLU\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/2009.03300\" rel=\"nofollow\"\u003eMeasuring Massive Multitask Language Understanding\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eA world-knowledge and complex reasoning benchmark\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2020-12\u003c/td\u003e\n\u003ctd align=\"center\"\u003ePile\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/2101.00027\" rel=\"nofollow\"\u003eThe Pile: An 800GB Dataset of Diverse Text for Language Modeling\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eA diverse pretraining dataset\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2021-04\u003c/td\u003e\n\u003ctd align=\"center\"\u003eRoPE\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/2104.09864\" rel=\"nofollow\"\u003eRoFormer: Enhanced Transformer with Rotary Position Embedding\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eRotary position embedding\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2021-06\u003c/td\u003e\n\u003ctd align=\"center\"\u003eLoRA\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/2106.09685\" rel=\"nofollow\"\u003eLoRA: Low-Rank Adaptation of Large Language Models\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eMemory-efficient finetuning\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2021-09\u003c/td\u003e\n\u003ctd align=\"center\"\u003eFLAN\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/2109.01652\" rel=\"nofollow\"\u003eFinetuned Language Models Are Zero-Shot Learners\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eInstruction-finetuning\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2021-10\u003c/td\u003e\n\u003ctd align=\"center\"\u003eT0\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/2110.08207\" rel=\"nofollow\"\u003eMultitask Prompted Training Enables Zero-Shot Task Generalization\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eAlso instruction finetuning, but applied to the much smaller T5\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2021-12\u003c/td\u003e\n\u003ctd align=\"center\"\u003eGopher\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/2112.11446\" rel=\"nofollow\"\u003eScaling Language Models: Methods, Analysis \u0026amp; Insights from Training Gopher\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eA 280B LLM with comprehensive experiments\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2022-01\u003c/td\u003e\n\u003ctd align=\"center\"\u003eCoT\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/2201.11903\" rel=\"nofollow\"\u003eChain-of-Thought Prompting Elicits Reasoning in Large Language Models\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eChain-of-Though reasoning\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2022-03\u003c/td\u003e\n\u003ctd align=\"center\"\u003eInstructGPT\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/2203.02155\" rel=\"nofollow\"\u003eTraining language models to follow instructions with human feedback\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eGPT-3 instruction finetuned with RLHF (reinforcement learning from human feedback)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2022-03\u003c/td\u003e\n\u003ctd align=\"center\"\u003eChinchilla\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/2203.15556\" rel=\"nofollow\"\u003eTraining Compute-Optimal Large Language Models\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eA smaller (70B) version of Gopher that's pretrained on more data\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2022-04\u003c/td\u003e\n\u003ctd align=\"center\"\u003ePaLM\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/2204.02311\" rel=\"nofollow\"\u003ePaLM: Scaling Language Modeling with Pathways\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eThe largest dense model ever (540B)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2022-05\u003c/td\u003e\n\u003ctd align=\"center\"\u003e0-shot CoT\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/2205.11916\" rel=\"nofollow\"\u003eLarge Language Models are Zero-Shot Reasoners\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eTell LLMs to think step by step, and they can actually do it\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2022-06\u003c/td\u003e\n\u003ctd align=\"center\"\u003eEmergent Ability\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/2206.07682\" rel=\"nofollow\"\u003eEmergent Abilities of Large Language Models\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eA review on emergent abilities\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2022-10\u003c/td\u003e\n\u003ctd align=\"center\"\u003eFlan\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/2210.11416\" rel=\"nofollow\"\u003eScaling Instruction-Finetuned Language Models\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eConsolidate all the existing instruction tuning datasets, and you get SOTA\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2022-11\u003c/td\u003e\n\u003ctd align=\"center\"\u003eBLOOM\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/2211.05100\" rel=\"nofollow\"\u003eBLOOM: A 176B-Parameter Open-Access Multilingual Language Model\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eThe largest open-source dense LLM, trained on 46 languages, with detailed discussion about training and evaluation\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003e2022-12\u003c/td\u003e\n\u003ctd align=\"center\"\u003eSelf-Instruct\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://arxiv.org/abs/2212.10560\" rel=\"nofollow\"\u003eSelf-Instruct: Aligning Language Models with Self-Generated Instructions\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eInstruction tuning using LLM-generated data\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\u003c/markdown-accessiblity-table\u003e\n\u003cp dir=\"auto\"\u003eThis list aims to provide the essential background for understanding current LLM technologies, and thus excludes more recent models such as \u003ca href=\"https://arxiv.org/abs/2302.13971\" rel=\"nofollow\"\u003eLLaMA\u003c/a\u003e, \u003ca href=\"https://arxiv.org/abs/2303.08774\" rel=\"nofollow\"\u003eGPT-4\u003c/a\u003e or \u003ca href=\"https://arxiv.org/abs/2305.10403\" rel=\"nofollow\"\u003ePaLM 2\u003c/a\u003e. For comprehensive reviews on these more general topics, we refer to other sources such as \u003ca href=\"https://github.com/Hannibal046/Awesome-LLM\"\u003eAwesome-LLM\u003c/a\u003e, \u003ca href=\"https://github.com/luban-agi/Awesome-AIGC-Tutorials\"\u003eAwesome AIGC Tutorials\u003c/a\u003e, or for LLM applications in other specific domains: \u003ca href=\"https://github.com/luban-agi/Awesome-Domain-LLM\"\u003eAwesome Domain LLM\u003c/a\u003e, \u003ca href=\"https://github.com/luban-agi/Awesome-Tool-Learning#awesome-tool-learning\"\u003eAwesome Tool Learning\u003c/a\u003e, \u003ca href=\"https://github.com/hsing-wang/Awesome-LLM-MT\"\u003eAwesome-LLM-MT\u003c/a\u003e, \u003ca href=\"https://github.com/Geralt-Targaryen/Awesome-Education-LLM\"\u003eAwesome Education LLM\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCitation\u003c/h2\u003e\u003ca id=\"user-content-citation\" class=\"anchor\" aria-label=\"Permalink: Citation\" href=\"#citation\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eIf you find this repo or our survey helpful, please consider citing us:\u003c/p\u003e\n\u003cdiv class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"@article{zhang2024unifying,\n   title={Unifying the Perspectives of {NLP} and Software Engineering: A Survey on Language Models for Code},\n   author={Ziyin Zhang and Chaoyu Chen and Bingchang Liu and Cong Liao and Zi Gong and Hang Yu and Jianguo Li and Rui Wang},\n   journal={Transactions on Machine Learning Research},\n   issn={2835-8856},\n   year={2024},\n   url={https://openreview.net/forum?id=hkNnGqZnpa},\n   note={}\n}\"\u003e\u003cpre class=\"notranslate\"\u003e\u003ccode\u003e@article{zhang2024unifying,\n   title={Unifying the Perspectives of {NLP} and Software Engineering: A Survey on Language Models for Code},\n   author={Ziyin Zhang and Chaoyu Chen and Bingchang Liu and Cong Liao and Zi Gong and Hang Yu and Jianguo Li and Rui Wang},\n   journal={Transactions on Machine Learning Research},\n   issn={2835-8856},\n   year={2024},\n   url={https://openreview.net/forum?id=hkNnGqZnpa},\n   note={}\n}\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eStar History\u003c/h2\u003e\u003ca id=\"user-content-star-history\" class=\"anchor\" aria-label=\"Permalink: Star History\" href=\"#star-history\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003e\u003ca href=\"https://star-history.com/#codefuse-ai/Awesome-Code-LLM\u0026amp;Date\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e6e364feee12fd4826ece726e7b236c1a982fe800d39d60fe0e95c228b737b48/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d636f6465667573652d61692f417765736f6d652d436f64652d4c4c4d26747970653d44617465\" alt=\"Star History Chart\" data-canonical-src=\"https://api.star-history.com/svg?repos=codefuse-ai/Awesome-Code-LLM\u0026amp;type=Date\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eJoin US\u003c/h2\u003e\u003ca id=\"user-content-join-us\" class=\"anchor\" aria-label=\"Permalink: Join US\" href=\"#join-us\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eRecruitment\u003c/h3\u003e\u003ca id=\"user-content-recruitment\" class=\"anchor\" aria-label=\"Permalink: Recruitment\" href=\"#recruitment\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdetails\u003e\n\u003csummary\u003eEnglish version\u003c/summary\u003e\nWe are the AI Native team within the Platform Technology Business Group at Ant Group, dedicated to the intelligentization of Ant Group's platform engineering. Established for over three years, our team has played a pivotal role in supporting the intelligent operation and maintenance of Ant Group's cloud computing infrastructure. Our mission is to build algorithm services and platforms with a wide user base through world-class technological innovation and impact, supporting the implementation of internal and external products and businesses.\nEmbracing an innovation-driven ethos, our team not only supports business implementation but also propels technological influence. Over the past three years, we have published more than 20 papers at top conferences like ICLR, NeurIPS, KDD, and ACL. Our innovative business outcomes have earned us two Ant Technology's highest T-Star awards and one SuperMA award from Ant Group. Our open-source project CodeFuse has received 4K stars as of February 2024, and our models have been downloaded over 1.5 million times on Huggingface and Modelscope.\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eWe are on the lookout for top talents to join our vibrant team! If you're eager to develop your career in an environment filled with energy, innovation, and a culture of excellence, we welcome you to explore our career opportunities for both campus and experienced hires. Join us and be a part of creating the next milestone in the industry.\u003c/strong\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eCampus Recruitment\u003c/strong\u003e: \u003ca href=\"https://hrrecommend.antgroup.com/guide.html?code=8uoP5mlus5DqQYbE_EnqcE2FD5JZH21MwvMUIb9mb6X3osXPuBraG54SyM8GLn_7\" rel=\"nofollow\"\u003ehttps://hrrecommend.antgroup.com/guide.html?code=8uoP5mlus5DqQYbE_EnqcE2FD5JZH21MwvMUIb9mb6X3osXPuBraG54SyM8GLn_7\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eExperienced Hires\u003c/strong\u003e: \u003ca href=\"https://talent.antgroup.com/off-campus-position?positionId=1933830\" rel=\"nofollow\"\u003ehttps://talent.antgroup.com/off-campus-position?positionId=1933830\u003c/a\u003e\u003c/p\u003e\n\u003c/details\u003e\n\u003cdetails\u003e\n\u003csummary\u003e\u003c/summary\u003e\n AI Native  3  Mission 3  ICLRNeurIPSKDDACL  20  T-Star1  SuperMA CodeFuse  4K (2024  2 )Huggingface  modelscope  150 \n\u003cp dir=\"auto\"\u003e\u003cstrong\u003e\u0026amp;\u003c/strong\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003e\u003c/strong\u003e\u003ca href=\"https://hrrecommend.antgroup.com/guide.html?code=8uoP5mlus5DqQYbE_EnqcE2FD5JZH21MwvMUIb9mb6X3osXPuBraG54SyM8GLn_7\" rel=\"nofollow\"\u003ehttps://hrrecommend.antgroup.com/guide.html?code=8uoP5mlus5DqQYbE_EnqcE2FD5JZH21MwvMUIb9mb6X3osXPuBraG54SyM8GLn_7\u003c/a\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003e\u003c/strong\u003e\u003ca href=\"https://talent.antgroup.com/off-campus-position?positionId=1933830\" rel=\"nofollow\"\u003ehttps://talent.antgroup.com/off-campus-position?positionId=1933830\u003c/a\u003e\u003c/p\u003e\n\u003c/details\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eContact Us (WeChat)\u003c/h3\u003e\u003ca id=\"user-content-contact-us-wechat\" class=\"anchor\" aria-label=\"Permalink: Contact Us (WeChat)\" href=\"#contact-us-wechat\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003e\u003c/p\u003e\n\u003cp align=\"center\" dir=\"auto\"\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"/codefuse-ai/Awesome-Code-LLM/blob/main/imgs/wechat.PNG\"\u003e\u003cimg src=\"/codefuse-ai/Awesome-Code-LLM/raw/main/imgs/wechat.PNG\" style=\"width: 40%; max-width: 100%;\"\u003e\u003c/a\u003e\n\u003c/p\u003e\n\u003c/article\u003e","loaded":true,"timedOut":false,"errorMessage":null,"headerInfo":{"toc":[{"level":1,"text":"Awesome-Code-LLM","anchor":"awesome-code-llm","htmlText":"Awesome-Code-LLM"},{"level":2,"text":"News","anchor":"news","htmlText":"News"},{"level":4,"text":"How to Contribute","anchor":"how-to-contribute","htmlText":"How to Contribute"},{"level":2,"text":"Table of Contents","anchor":"table-of-contents","htmlText":"Table of Contents"},{"level":2,"text":"1. Surveys","anchor":"1-surveys","htmlText":"1. Surveys"},{"level":2,"text":"2. Models","anchor":"2-models","htmlText":"2. Models"},{"level":3,"text":"2.1 Base LLMs and Pretraining Strategies","anchor":"21-base-llms-and-pretraining-strategies","htmlText":"2.1 Base LLMs and Pretraining Strategies"},{"level":3,"text":"2.2 Existing LLM Adapted to Code","anchor":"22-existing-llm-adapted-to-code","htmlText":"2.2 Existing LLM Adapted to Code"},{"level":3,"text":"2.3 General Pretraining on Code","anchor":"23-general-pretraining-on-code","htmlText":"2.3 General Pretraining on Code"},{"level":4,"text":"Encoder","anchor":"encoder","htmlText":"Encoder"},{"level":4,"text":"Decoder","anchor":"decoder","htmlText":"Decoder"},{"level":4,"text":"Encoder-Decoder","anchor":"encoder-decoder","htmlText":"Encoder-Decoder"},{"level":4,"text":"UniLM","anchor":"unilm","htmlText":"UniLM"},{"level":4,"text":"Other Models","anchor":"other-models","htmlText":"Other Models"},{"level":3,"text":"2.4 (Instruction) Fine-Tuning on Code","anchor":"24-instruction-fine-tuning-on-code","htmlText":"2.4 (Instruction) Fine-Tuning on Code"},{"level":3,"text":"2.5 Reinforcement Learning on Code","anchor":"25-reinforcement-learning-on-code","htmlText":"2.5 Reinforcement Learning on Code"},{"level":2,"text":"3. When Coding Meets Reasoning","anchor":"3-when-coding-meets-reasoning","htmlText":"3. When Coding Meets Reasoning"},{"level":3,"text":"3.1 Coding for Reasoning","anchor":"31-coding-for-reasoning","htmlText":"3.1 Coding for Reasoning"},{"level":3,"text":"3.2 Code Simulation","anchor":"32-code-simulation","htmlText":"3.2 Code Simulation"},{"level":3,"text":"3.3 Code Agents","anchor":"33-code-agents","htmlText":"3.3 Code Agents"},{"level":3,"text":"3.4 Interactive Coding","anchor":"34-interactive-coding","htmlText":"3.4 Interactive Coding"},{"level":3,"text":"3.5 Frontend Navigation","anchor":"35-frontend-navigation","htmlText":"3.5 Frontend Navigation"},{"level":2,"text":"4. Code LLM for Low-Resource, Low-Level, and Domain-Specific Languages","anchor":"4-code-llm-for-low-resource-low-level-and-domain-specific-languages","htmlText":"4. Code LLM for Low-Resource, Low-Level, and Domain-Specific Languages"},{"level":2,"text":"5. Methods/Models for Downstream Tasks","anchor":"5-methodsmodels-for-downstream-tasks","htmlText":"5. Methods/Models for Downstream Tasks"},{"level":3,"text":"Code Generation","anchor":"code-generation","htmlText":"Code Generation"},{"level":3,"text":"Code RAG","anchor":"code-rag","htmlText":"Code RAG"},{"level":3,"text":"Code Ranking","anchor":"code-ranking","htmlText":"Code Ranking"},{"level":3,"text":"Code Translation","anchor":"code-translation","htmlText":"Code Translation"},{"level":3,"text":"Code Commenting and Summarization","anchor":"code-commenting-and-summarization","htmlText":"Code Commenting and Summarization"},{"level":3,"text":"Program Repair","anchor":"program-repair","htmlText":"Program Repair"},{"level":3,"text":"Code Similarity and Embedding (Clone Detection, Code Search)","anchor":"code-similarity-and-embedding-clone-detection-code-search","htmlText":"Code Similarity and Embedding (Clone Detection, Code Search)"},{"level":3,"text":"Code Refactoring and Migration","anchor":"code-refactoring-and-migration","htmlText":"Code Refactoring and Migration"},{"level":3,"text":"Type Prediction","anchor":"type-prediction","htmlText":"Type Prediction"},{"level":3,"text":"Repository-Level Coding","anchor":"repository-level-coding","htmlText":"Repository-Level Coding"},{"level":3,"text":"Issue Resolution","anchor":"issue-resolution","htmlText":"Issue Resolution"},{"level":3,"text":"Frontend Development","anchor":"frontend-development","htmlText":"Frontend Development"},{"level":3,"text":"Automated Machine Learning","anchor":"automated-machine-learning","htmlText":"Automated Machine Learning"},{"level":3,"text":"Text-To-SQL","anchor":"text-to-sql","htmlText":"Text-To-SQL"},{"level":3,"text":"Program Proof","anchor":"program-proof","htmlText":"Program Proof"},{"level":3,"text":"Test Generation","anchor":"test-generation","htmlText":"Test Generation"},{"level":3,"text":"Oracle Generation","anchor":"oracle-generation","htmlText":"Oracle Generation"},{"level":3,"text":"Mutation Testing","anchor":"mutation-testing","htmlText":"Mutation Testing"},{"level":3,"text":"Fuzz Testing","anchor":"fuzz-testing","htmlText":"Fuzz Testing"},{"level":3,"text":"Vulnerability Detection","anchor":"vulnerability-detection","htmlText":"Vulnerability Detection"},{"level":3,"text":"Malicious Code Detection","anchor":"malicious-code-detection","htmlText":"Malicious Code Detection"},{"level":3,"text":"Compiler Optimization","anchor":"compiler-optimization","htmlText":"Compiler Optimization"},{"level":3,"text":"Binary Analysis and Decompilation","anchor":"binary-analysis-and-decompilation","htmlText":"Binary Analysis and Decompilation"},{"level":3,"text":"Commit Message Generation","anchor":"commit-message-generation","htmlText":"Commit Message Generation"},{"level":3,"text":"Code Review","anchor":"code-review","htmlText":"Code Review"},{"level":3,"text":"Log Analysis","anchor":"log-analysis","htmlText":"Log Analysis"},{"level":3,"text":"Software Configuration","anchor":"software-configuration","htmlText":"Software Configuration"},{"level":3,"text":"Code QA \u0026 Reasoning","anchor":"code-qa--reasoning","htmlText":"Code QA \u0026amp; Reasoning"},{"level":3,"text":"Software Modeling","anchor":"software-modeling","htmlText":"Software Modeling"},{"level":3,"text":"Requirement Engineering","anchor":"requirement-engineering","htmlText":"Requirement Engineering"},{"level":2,"text":"6. Analysis of AI-Generated Code","anchor":"6-analysis-of-ai-generated-code","htmlText":"6. Analysis of AI-Generated Code"},{"level":3,"text":"Security and Vulnerabilities","anchor":"security-and-vulnerabilities","htmlText":"Security and Vulnerabilities"},{"level":3,"text":"Correctness","anchor":"correctness","htmlText":"Correctness"},{"level":3,"text":"Hallucination","anchor":"hallucination","htmlText":"Hallucination"},{"level":3,"text":"Efficiency","anchor":"efficiency","htmlText":"Efficiency"},{"level":3,"text":"Robustness","anchor":"robustness","htmlText":"Robustness"},{"level":3,"text":"Interpretability","anchor":"interpretability","htmlText":"Interpretability"},{"level":3,"text":"API Usage","anchor":"api-usage","htmlText":"API Usage"},{"level":3,"text":"Privacy","anchor":"privacy","htmlText":"Privacy"},{"level":3,"text":"Bias","anchor":"bias","htmlText":"Bias"},{"level":3,"text":"Contamination","anchor":"contamination","htmlText":"Contamination"},{"level":3,"text":"AI-Generated Code Detection","anchor":"ai-generated-code-detection","htmlText":"AI-Generated Code Detection"},{"level":3,"text":"Others","anchor":"others","htmlText":"Others"},{"level":2,"text":"7. Human-LLM Interaction","anchor":"7-human-llm-interaction","htmlText":"7. Human-LLM Interaction"},{"level":2,"text":"8. Datasets","anchor":"8-datasets","htmlText":"8. Datasets"},{"level":3,"text":"8.1 Pretraining","anchor":"81-pretraining","htmlText":"8.1 Pretraining"},{"level":3,"text":"8.2 Benchmarks","anchor":"82-benchmarks","htmlText":"8.2 Benchmarks"},{"level":4,"text":"Integrated Benchmarks","anchor":"integrated-benchmarks","htmlText":"Integrated Benchmarks"},{"level":4,"text":"Evaluation Metrics","anchor":"evaluation-metrics","htmlText":"Evaluation Metrics"},{"level":4,"text":"Program Synthesis","anchor":"program-synthesis","htmlText":"Program Synthesis"},{"level":4,"text":"Visually Grounded Program Synthesis","anchor":"visually-grounded-program-synthesis","htmlText":"Visually Grounded Program Synthesis"},{"level":4,"text":"Code Reasoning and QA","anchor":"code-reasoning-and-qa","htmlText":"Code Reasoning and QA"},{"level":4,"text":"Text-to-SQL","anchor":"text-to-sql-1","htmlText":"Text-to-SQL"},{"level":4,"text":"Code Translation","anchor":"code-translation-1","htmlText":"Code Translation"},{"level":4,"text":"Program Repair","anchor":"program-repair-1","htmlText":"Program Repair"},{"level":4,"text":"Code Summarization","anchor":"code-summarization","htmlText":"Code Summarization"},{"level":4,"text":"Defect/Vulnerability Detection","anchor":"defectvulnerability-detection","htmlText":"Defect/Vulnerability Detection"},{"level":4,"text":"Code Retrieval","anchor":"code-retrieval","htmlText":"Code Retrieval"},{"level":4,"text":"Type Inference","anchor":"type-inference","htmlText":"Type Inference"},{"level":4,"text":"Commit Message Generation","anchor":"commit-message-generation-1","htmlText":"Commit Message Generation"},{"level":4,"text":"Repo-Level Coding","anchor":"repo-level-coding","htmlText":"Repo-Level Coding"},{"level":4,"text":"Other tasks are coming soon!","anchor":"other-tasks-are-coming-soon","htmlText":"Other tasks are coming soon!"},{"level":2,"text":"9. Recommended Readings","anchor":"9-recommended-readings","htmlText":"9. Recommended Readings"},{"level":2,"text":"Citation","anchor":"citation","htmlText":"Citation"},{"level":2,"text":"Star History","anchor":"star-history","htmlText":"Star History"},{"level":2,"text":"Join US","anchor":"join-us","htmlText":"Join US"},{"level":3,"text":"Recruitment","anchor":"recruitment","htmlText":"Recruitment"},{"level":3,"text":"Contact Us (WeChat)","anchor":"contact-us-wechat","htmlText":"Contact Us (WeChat)"}],"siteNavLoginPath":"/login?return_to=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FAwesome-Code-LLM"}}],"overviewFilesProcessingTime":0,"copilotSWEAgentEnabled":false}},"appPayload":{"helpUrl":"https://docs.github.com","findFileWorkerPath":"/assets-cdn/worker/find-file-worker-9bd411a8e273.js","findInFileWorkerPath":"/assets-cdn/worker/find-in-file-worker-4747241b1152.js","githubDevUrl":null,"enabled_features":{"copilot_workspace":null,"code_nav_ui_events":false,"react_blob_overlay":false,"accessible_code_button":true}}}}</script>
  <div data-target="react-partial.reactRoot"> <!-- --> <!-- --> <div class="OverviewContent-module__Box--uNd1J"><div class="OverviewHeader-module__Box--fFKf5"></div><div class="OverviewContent-module__Box_1--RhaEy"><div class="OverviewContent-module__Box_2--uHewD"><div class="OverviewContent-module__Box_3--NEYWl"><button type="button" aria-haspopup="true" aria-expanded="false" tabindex="0" style="min-width:0" aria-label="main branch" data-testid="anchor-button" class="prc-Button-ButtonBase-c50BI overview-ref-selector width-full RefSelectorAnchoredOverlay-module__RefSelectorOverlayBtn--D34zl" data-loading="false" data-size="medium" data-variant="default" aria-describedby="ref-picker-repos-header-ref-selector-loading-announcement" id="ref-picker-repos-header-ref-selector"><span data-component="buttonContent" data-align="center" class="prc-Button-ButtonContent-HKbr-"><span data-component="text" class="prc-Button-Label-pTQ3x"><div class="RefSelectorAnchoredOverlay-module__RefSelectorOverlayContainer--mCbv8"><div class="RefSelectorAnchoredOverlay-module__RefSelectorOverlayHeader--D4cnZ"><svg aria-hidden="true" focusable="false" class="octicon octicon-git-branch" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" display="inline-block" overflow="visible" style="vertical-align:text-bottom"><path d="M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z"></path></svg></div><div class="ref-selector-button-text-container RefSelectorAnchoredOverlay-module__RefSelectorBtnTextContainer--yO402"><span class="RefSelectorAnchoredOverlay-module__RefSelectorText--bxVhQ"><!-- -->main</span></div></div></span><span data-component="trailingVisual" class="prc-Button-Visual-2epfX prc-Button-VisualWrap-Db-eB"><svg aria-hidden="true" focusable="false" class="octicon octicon-triangle-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" display="inline-block" overflow="visible" style="vertical-align:text-bottom"><path d="m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z"></path></svg></span></span></button><button hidden="" data-testid="ref-selector-hotkey-button" data-hotkey-scope="read-only-cursor-text-area"></button></div><div class="OverviewContent-module__Box_4--rOz8J"><a type="button" href="/codefuse-ai/Awesome-Code-LLM/branches" class="prc-Button-ButtonBase-c50BI OverviewContent-module__Button--MDoYP" data-loading="false" data-size="medium" data-variant="invisible" aria-describedby=":Rclab:-loading-announcement"><span data-component="buttonContent" data-align="center" class="prc-Button-ButtonContent-HKbr-"><span data-component="leadingVisual" class="prc-Button-Visual-2epfX prc-Button-VisualWrap-Db-eB"><svg aria-hidden="true" focusable="false" class="octicon octicon-git-branch" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" display="inline-block" overflow="visible" style="vertical-align:text-bottom"><path d="M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z"></path></svg></span><span data-component="text" class="prc-Button-Label-pTQ3x">Branches</span></span></a><a type="button" href="/codefuse-ai/Awesome-Code-LLM/tags" class="prc-Button-ButtonBase-c50BI OverviewContent-module__Button--MDoYP" data-loading="false" data-size="medium" data-variant="invisible" aria-describedby=":Rklab:-loading-announcement"><span data-component="buttonContent" data-align="center" class="prc-Button-ButtonContent-HKbr-"><span data-component="leadingVisual" class="prc-Button-Visual-2epfX prc-Button-VisualWrap-Db-eB"><svg aria-hidden="true" focusable="false" class="octicon octicon-tag" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" display="inline-block" overflow="visible" style="vertical-align:text-bottom"><path d="M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z"></path></svg></span><span data-component="text" class="prc-Button-Label-pTQ3x">Tags</span></span></a></div><div class="OverviewContent-module__Box_5--PPbL1"><a type="button" aria-label="Go to Branches page" href="/codefuse-ai/Awesome-Code-LLM/branches" class="prc-Button-ButtonBase-c50BI OverviewContent-module__Button_1--_1Ng2" data-loading="false" data-no-visuals="true" data-size="medium" data-variant="invisible" aria-describedby=":Relab:-loading-announcement"><svg aria-hidden="true" focusable="false" class="octicon octicon-git-branch" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" display="inline-block" overflow="visible" style="vertical-align:text-bottom"><path d="M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z"></path></svg></a><a type="button" aria-label="Go to Tags page" href="/codefuse-ai/Awesome-Code-LLM/tags" class="prc-Button-ButtonBase-c50BI OverviewContent-module__Button_1--_1Ng2" data-loading="false" data-no-visuals="true" data-size="medium" data-variant="invisible" aria-describedby=":Rmlab:-loading-announcement"><svg aria-hidden="true" focusable="false" class="octicon octicon-tag" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" display="inline-block" overflow="visible" style="vertical-align:text-bottom"><path d="M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z"></path></svg></a></div></div><div class="OverviewContent-module__Box_6--wV7Tw"><div class="OverviewContent-module__Box_7--SbxdI"><div class="OverviewContent-module__Box_8--oumpR"><!--$--><div class="Box-sc-62in7e-0 OverviewContent-module__FileResultsList--irMg6"><span class="TextInput__StyledTextInput-sc-ttxlvl-0 d-flex FileResultsList-module__FilesSearchBox--fSAh3 TextInput-wrapper prc-components-TextInputWrapper-i1ofR prc-components-TextInputBaseWrapper-ueK9q" data-leading-visual="true" data-trailing-visual="true" aria-busy="false"><span class="TextInput-icon" id=":R535ab:" aria-hidden="true"><svg aria-hidden="true" focusable="false" class="octicon octicon-search" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" display="inline-block" overflow="visible" style="vertical-align:text-bottom"><path d="M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z"></path></svg></span><input type="text" aria-label="Go to file" role="combobox" aria-controls="file-results-list" aria-expanded="false" aria-haspopup="dialog" autoCorrect="off" spellcheck="false" placeholder="Go to file" aria-describedby=":R535ab: :R535abH1:" data-component="input" class="prc-components-Input-Ic-y8" value=""/><span class="TextInput-icon" id=":R535abH1:" aria-hidden="true"></span></span></div><!--/$--></div><div class="OverviewContent-module__Box_9--mQYON"><button type="button" class="prc-Button-ButtonBase-c50BI" data-loading="false" data-no-visuals="true" data-size="medium" data-variant="default" aria-describedby=":R1j5ab:-loading-announcement"><span data-component="buttonContent" data-align="center" class="prc-Button-ButtonContent-HKbr-"><span data-component="text" class="prc-Button-Label-pTQ3x">Go to file</span></span></button></div></div><button type="button" aria-haspopup="true" aria-expanded="false" tabindex="0" class="prc-Button-ButtonBase-c50BI" data-loading="false" data-size="medium" data-variant="primary" aria-describedby=":R75ab:-loading-announcement" id=":R75ab:"><span data-component="buttonContent" data-align="center" class="prc-Button-ButtonContent-HKbr-"><span data-component="leadingVisual" class="prc-Button-Visual-2epfX prc-Button-VisualWrap-Db-eB"><svg aria-hidden="true" focusable="false" class="octicon octicon-code hide-sm" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" display="inline-block" overflow="visible" style="vertical-align:text-bottom"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg></span><span data-component="text" class="prc-Button-Label-pTQ3x">Code</span><span data-component="trailingVisual" class="prc-Button-Visual-2epfX prc-Button-VisualWrap-Db-eB"><svg aria-hidden="true" focusable="false" class="octicon octicon-triangle-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" display="inline-block" overflow="visible" style="vertical-align:text-bottom"><path d="m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z"></path></svg></span></span></button><div class="OverviewContent-module__Box_10--ULKAG"><button data-component="IconButton" type="button" aria-haspopup="true" aria-expanded="false" tabindex="0" class="prc-Button-ButtonBase-c50BI prc-Button-IconButton-szpyj" data-loading="false" data-no-visuals="true" data-size="medium" data-variant="default" aria-describedby=":R95ab:-loading-announcement" aria-labelledby=":R7p5ab:" id=":R95ab:"><svg aria-hidden="true" focusable="false" class="octicon octicon-kebab-horizontal" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" display="inline-block" overflow="visible" style="vertical-align:text-bottom"><path d="M8 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3ZM1.5 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Zm13 0a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path></svg></button><span class="prc-TooltipV2-Tooltip-cYMVY" data-direction="n" aria-hidden="true" id=":R7p5ab:">Open more actions menu</span></div></div></div><div class="OverviewContent-module__Box_11--Tqhu2"><div data-hpc="true"><button hidden="" data-testid="focus-next-element-button" data-hotkey="j"></button><button hidden="" data-testid="focus-previous-element-button" data-hotkey="k"></button><h2 class="sr-only ScreenReaderHeading-module__userSelectNone--vlUbc prc-Heading-Heading-6CmGO" data-testid="screen-reader-heading" id="folders-and-files">Folders and files</h2><table class="Table-module__Box--KyMHK" aria-labelledby="folders-and-files"><thead class="DirectoryContent-module__OverviewHeaderRow--FlrUZ Table-module__Box_1--DkRqs"><tr class="Table-module__Box_2--l1wjV"><th colSpan="2" class="DirectoryContent-module__Box--y3Nvf"><span class="text-bold">Name</span></th><th colSpan="1" class="DirectoryContent-module__Box_1--xeAhp"><span class="text-bold">Name</span></th><th class="hide-sm"><div class="width-fit prc-Truncate-Truncate-A9Wn6" data-inline="true" title="Last commit message" style="--truncate-max-width:125px"><span class="text-bold">Last commit message</span></div></th><th colSpan="1" class="DirectoryContent-module__Box_2--h912w"><div class="width-fit prc-Truncate-Truncate-A9Wn6" data-inline="true" title="Last commit date" style="--truncate-max-width:125px"><span class="text-bold">Last commit date</span></div></th></tr></thead><tbody><tr class="DirectoryContent-module__Box_3--zI0N1"><td colSpan="3" class="bgColor-muted p-1 rounded-top-2"><div class="LatestCommit-module__Box--Fimpo"><h2 class="sr-only ScreenReaderHeading-module__userSelectNone--vlUbc prc-Heading-Heading-6CmGO" data-testid="screen-reader-heading">Latest commit</h2><div style="width:120px" class="Skeleton Skeleton--text" data-testid="loading"></div><div class="d-flex flex-shrink-0 gap-2"><div data-testid="latest-commit-details" class="d-none d-sm-flex flex-items-center"></div><div class="d-flex gap-2"><h2 class="sr-only ScreenReaderHeading-module__userSelectNone--vlUbc prc-Heading-Heading-6CmGO" data-testid="screen-reader-heading">History</h2><a href="/codefuse-ai/Awesome-Code-LLM/commits/main/" class="prc-Button-ButtonBase-c50BI d-none d-lg-flex LinkButton-module__code-view-link-button--thtqc flex-items-center fgColor-default" data-loading="false" data-size="small" data-variant="invisible" aria-describedby=":Raqj8pab:-loading-announcement"><span data-component="buttonContent" data-align="center" class="prc-Button-ButtonContent-HKbr-"><span data-component="leadingVisual" class="prc-Button-Visual-2epfX prc-Button-VisualWrap-Db-eB"><svg aria-hidden="true" focusable="false" class="octicon octicon-history" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" display="inline-block" overflow="visible" style="vertical-align:text-bottom"><path d="m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z"></path></svg></span><span data-component="text" class="prc-Button-Label-pTQ3x"><span class="fgColor-default">207 Commits</span></span></span></a><div class="d-sm-none"></div><div class="d-flex d-lg-none"><span role="tooltip" aria-label="207 Commits" id="history-icon-button-tooltip" class="prc-Tooltip-Tooltip--1XZX prc-Tooltip-Tooltip--n-BOOzB tooltipped-n"><a aria-label="View commit history for this file." href="/codefuse-ai/Awesome-Code-LLM/commits/main/" class="prc-Button-ButtonBase-c50BI LinkButton-module__code-view-link-button--thtqc flex-items-center fgColor-default" data-loading="false" data-size="small" data-variant="invisible" aria-describedby=":R1iqj8pab:-loading-announcement history-icon-button-tooltip"><span data-component="buttonContent" data-align="center" class="prc-Button-ButtonContent-HKbr-"><span data-component="leadingVisual" class="prc-Button-Visual-2epfX prc-Button-VisualWrap-Db-eB"><svg aria-hidden="true" focusable="false" class="octicon octicon-history" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" display="inline-block" overflow="visible" style="vertical-align:text-bottom"><path d="m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z"></path></svg></span></span></a></span></div></div></div></div></td></tr><tr class="react-directory-row undefined" id="folder-row-0"><td class="react-directory-row-name-cell-small-screen" colSpan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" class="octicon octicon-file-directory-fill icon-directory" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" display="inline-block" overflow="visible" style="vertical-align:text-bottom"><path d="M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="imgs" aria-label="imgs, (Directory)" class="Link--primary" href="/codefuse-ai/Awesome-Code-LLM/tree/main/imgs" data-discover="true">imgs</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colSpan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" class="octicon octicon-file-directory-fill icon-directory" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" display="inline-block" overflow="visible" style="vertical-align:text-bottom"><path d="M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="imgs" aria-label="imgs, (Directory)" class="Link--primary" href="/codefuse-ai/Awesome-Code-LLM/tree/main/imgs" data-discover="true">imgs</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div class="Skeleton Skeleton--text"></div></td><td><div class="Skeleton Skeleton--text"></div></td></tr><tr class="react-directory-row undefined" id="folder-row-1"><td class="react-directory-row-name-cell-small-screen" colSpan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" class="octicon octicon-file color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" display="inline-block" overflow="visible" style="vertical-align:text-bottom"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="README.md" aria-label="README.md, (File)" class="Link--primary" href="/codefuse-ai/Awesome-Code-LLM/blob/main/README.md" data-discover="true">README.md</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colSpan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" class="octicon octicon-file color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" display="inline-block" overflow="visible" style="vertical-align:text-bottom"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="README.md" aria-label="README.md, (File)" class="Link--primary" href="/codefuse-ai/Awesome-Code-LLM/blob/main/README.md" data-discover="true">README.md</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div class="Skeleton Skeleton--text"></div></td><td><div class="Skeleton Skeleton--text"></div></td></tr><tr class="d-none DirectoryContent-module__Box_4--QyUbd" data-testid="view-all-files-row"><td colSpan="3" class="DirectoryContent-module__Box_5--OJZQU"><div><button class="prc-Link-Link-85e08">View all files</button></div></td></tr></tbody></table></div><div class="OverviewRepoFiles-module__Box_1--xSt0T"><div class="OverviewRepoFiles-module__Box_2--yIjMp"><div itemscope="" itemType="https://schema.org/abstract" class="OverviewRepoFiles-module__Box_3--Bi2jM"><h2 class="prc-src-InternalVisuallyHidden-nlR9R">Repository files navigation</h2><nav class="prc-components-UnderlineWrapper-oOh5J OverviewRepoFiles-module__UnderlineNav--BHfFi" aria-label="Repository files" data-variant="inset"><ul class="prc-components-UnderlineItemList-b23Hf" role="list"><li class="prc-UnderlineNav-UnderlineNavItem--xDk1"><a href="#" aria-current="page" class="prc-components-UnderlineItem-lJsg-"><span data-component="icon"><svg aria-hidden="true" focusable="false" class="octicon octicon-book" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" display="inline-block" overflow="visible" style="vertical-align:text-bottom"><path d="M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z"></path></svg></span><span data-component="text" data-content="README">README</span></a></li></ul></nav><button type="button" aria-label="Outline" aria-haspopup="true" aria-expanded="false" tabindex="0" class="prc-Button-ButtonBase-c50BI OverviewRepoFiles-module__ActionMenu_Button--xB9DS" data-loading="false" data-size="medium" data-variant="invisible" aria-describedby=":Rr9ab:-loading-announcement" id=":Rr9ab:"><svg aria-hidden="true" focusable="false" class="octicon octicon-list-unordered" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" display="inline-block" overflow="visible" style="vertical-align:text-bottom"><path d="M5.75 2.5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5Zm0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5Zm0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5ZM2 14a1 1 0 1 1 0-2 1 1 0 0 1 0 2Zm1-6a1 1 0 1 1-2 0 1 1 0 0 1 2 0ZM2 4a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg></button></div><div class="Box-sc-62in7e-0 js-snippet-clipboard-copy-unpositioned DirectoryRichtextContent-module__SharedMarkdownContent--BTKsc" data-hpc="true"><article class="markdown-body entry-content container-lg" itemprop="text"><div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto">Awesome-Code-LLM</h1><a id="user-content-awesome-code-llm" class="anchor" aria-label="Permalink: Awesome-Code-LLM" href="#awesome-code-llm"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p align="center" dir="auto">
<a target="_blank" rel="noopener noreferrer" href="/codefuse-ai/Awesome-Code-LLM/blob/main/imgs/wordcloud.png"><img src="/codefuse-ai/Awesome-Code-LLM/raw/main/imgs/wordcloud.png" style="width: 100%; max-width: 100%;"></a>
</p>
<p dir="auto">This is the repo for our TMLR <a href="https://arxiv.org/abs/2311.07989" rel="nofollow">code LLM survey</a>. If you find this repo helpful, please support us by citing:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="@article{zhang2024unifying,
   title={Unifying the Perspectives of {NLP} and Software Engineering: A Survey on Language Models for Code},
   author={Ziyin Zhang and Chaoyu Chen and Bingchang Liu and Cong Liao and Zi Gong and Hang Yu and Jianguo Li and Rui Wang},
   journal={Transactions on Machine Learning Research},
   issn={2835-8856},
   year={2024},
   url={https://openreview.net/forum?id=hkNnGqZnpa}
}"><pre class="notranslate"><code>@article{zhang2024unifying,
   title={Unifying the Perspectives of {NLP} and Software Engineering: A Survey on Language Models for Code},
   author={Ziyin Zhang and Chaoyu Chen and Bingchang Liu and Cong Liao and Zi Gong and Hang Yu and Jianguo Li and Rui Wang},
   journal={Transactions on Machine Learning Research},
   issn={2835-8856},
   year={2024},
   url={https://openreview.net/forum?id=hkNnGqZnpa}
}
</code></pre></div>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">News</h2><a id="user-content-news" class="anchor" aria-label="Permalink: News" href="#news"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"> [2025/10/23] Featured papers:</p>
<ul dir="auto">
<li>
<p dir="auto"> <a href="https://arxiv.org/abs/2510.18855" rel="nofollow">Every Step Evolves: Scaling Reinforcement Learning for Trillion-Scale Thinking Model</a> from Ant Group.</p>
</li>
<li>
<p dir="auto"> <a href="https://arxiv.org/abs/2510.17891" rel="nofollow">TritonRL: Training LLMs to Think and Code Triton Without Cheating</a> from Carnegie Mellon University.</p>
</li>
<li>
<p dir="auto"> <a href="https://arxiv.org/abs/2510.09595" rel="nofollow">LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?</a> from University of Michigan.</p>
</li>
<li>
<p dir="auto"> <a href="https://arxiv.org/abs/2510.08702" rel="nofollow">Scaling Laws for Code: A More Data-Hungry Regime</a> from Harbin Institute of Technology.</p>
</li>
<li>
<p dir="auto"> <a href="https://arxiv.org/abs/2510.08697" rel="nofollow">BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution</a> from Monash University.</p>
</li>
</ul>
<p dir="auto"> [2025/08/24] 29 papers from ICML 2025 have been added. Search for the keyword "ICML 2025"!</p>
<p dir="auto"> [2025/08/15] 80 papers from ACL 2025 have been added. Search for the keyword "ACL 2025"!</p>
<p dir="auto"> [2024/09/06] <strong>Our survey has been accepted for publication by <a href="https://jmlr.org/tmlr/" rel="nofollow">Transactions on Machine Learning Research (TMLR)</a>.</strong></p>
<p dir="auto"> [2025/09/22] News from Codefuse</p>
<ul dir="auto">
<li>
<p dir="auto">We released <a href="https://arxiv.org/abs/2510.02294" rel="nofollow">F2LLM</a>, a fully open embedding model striking a strong balance between model size, training data, and embedding performance. [<a href="https://github.com/codefuse-ai/CodeFuse-Embeddings">code</a>] [<a href="https://huggingface.co/collections/codefuse-ai/codefuse-embeddings-68d4b32da791bbba993f8d14" rel="nofollow">model &amp; data</a>]</p>
</li>
<li>
<p dir="auto">We released a new benchmark focusing on code review: <a href="https://arxiv.org/abs/2509.14856" rel="nofollow">CodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects</a></p>
</li>
<li>
<p dir="auto"><a href="https://arxiv.org/abs/2505.16901" rel="nofollow">CGM (Code Graph Model)</a> is accepted to NeurIPS 2025. CGM currently ranks 1st among open-weight models on <a href="https://www.swebench.com/" rel="nofollow">SWE-Bench-Lite leaderboard</a>. [<a href="https://github.com/codefuse-ai/CodeFuse-CGM">repo</a>]</p>
</li>
<li>
<p dir="auto"><a href="https://arxiv.org/abs/2409.04183" rel="nofollow">GALLa: Graph Aligned Large Language Models</a> is accepted by ACL 2025 main conference. [<a href="https://github.com/codefuse-ai/GALLa">repo</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">How to Contribute</h4><a id="user-content-how-to-contribute" class="anchor" aria-label="Permalink: How to Contribute" href="#how-to-contribute"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">If you find a paper to be missing from this repository, misplaced in a category, or lacking a reference to its journal/conference information, please do not hesitate to create an issue.</p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" class="anchor" aria-label="Permalink: Table of Contents" href="#table-of-contents"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>
<p dir="auto"><a href="#1-surveys">Surveys</a></p>
</li>
<li>
<p dir="auto"><a href="#2-models">Models</a></p>
<p dir="auto">2.1 <a href="#21-base-llms-and-pretraining-strategies">Base LLMs and Pretraining Strategies</a></p>
<p dir="auto">2.2 <a href="#22-existing-llm-adapted-to-code">Existing LLM Adapted to Code</a></p>
<p dir="auto">2.3 <a href="#23-general-pretraining-on-code">General Pretraining on Code</a></p>
<ul dir="auto">
<li><a href="#encoder">Encoder</a></li>
<li><a href="#decoder">Decoder</a></li>
<li><a href="#encoder-decoder">Encoder-Decoder</a></li>
<li><a href="#unilm">UniLM</a></li>
<li><a href="#other-models">Other Models</a></li>
</ul>

<p dir="auto">2.4 <a href="#24-instruction-fine-tuning-on-code">(Instruction) Fine-Tuning on Code</a></p>
<p dir="auto">2.5 <a href="#25-reinforcement-learning-on-code">Reinforcement Learning on Code</a></p>
</li>
<li>
<p dir="auto"><a href="#3-when-coding-meets-reasoning">When Coding Meets Reasoning</a></p>
<p dir="auto">3.1 <a href="#31-coding-for-reasoning">Coding for Reasoning</a></p>
<p dir="auto">3.2 <a href="#32-code-simulation">Code Simulation</a></p>
<p dir="auto">3.3 <a href="#33-code-agents">Code Agents</a></p>
<p dir="auto">3.4 <a href="#34-interactive-coding">Interactive Coding</a></p>
<p dir="auto">3.5 <a href="#35-frontend-navigation">Frontend Navigation</a></p>
</li>
<li>
<p dir="auto"><a href="#4-code-llm-for-low-resource-low-level-and-domain-specific-languages">Code LLM for Low-Resource, Low-Level, and Domain-Specific Languages</a></p>
</li>
<li>
<p dir="auto"><a href="#5-methodsmodels-for-downstream-tasks">Methods/Models for Downstream Tasks</a></p>
<ul dir="auto">
<li>
<p dir="auto">Programming</p>
<ul dir="auto">
<li><a href="#code-generation">Code Generation</a></li>
<li><a href="#code-rag">Code RAG</a></li>
<li><a href="#code-ranking">Code Ranking</a></li>
<li><a href="#code-translation">Code Translation</a></li>
<li><a href="#code-commenting-and-summarization">Code Commenting and Summarization</a></li>
<li><a href="#program-repair">Program Repair</a></li>
<li><a href="#code-similarity-and-embedding-clone-detection-code-search">Code Similarity and Embedding (Clone Detection, Code Search)</a></li>
<li><a href="#code-refactoring-and-migration">Code Refactoring and Migration</a></li>
<li><a href="#type-prediction">Type Prediction</a></li>
<li><a href="#repository-level-coding">Repository-Level Coding</a></li>
<li><a href="#issue-resolution">Issue Resolution</a></li>
<li><a href="#frontend-development">Frontend Development</a></li>
<li><a href="#automated-machine-learning">Automated Machine Learning</a></li>
<li><a href="#text-to-sql">Text-To-SQL</a></li>
<li><a href="#program-proof">Program Proof</a></li>
</ul>
</li>
<li>
<p dir="auto">Testing and Deployment</p>
<ul dir="auto">
<li><a href="#test-generation">Test Generation</a></li>
<li><a href="#oracle-generation">Oracle Generation</a></li>
<li><a href="#mutation-testing">Mutation Testing</a></li>
<li><a href="#fuzz-testing">Fuzz Testing</a></li>
<li><a href="#vulnerability-detection">Vulnerability Detection</a></li>
<li><a href="#malicious-code-detection">Malicious Code Detection</a></li>
<li><a href="#compiler-optimization">Compiler Optimization</a></li>
<li><a href="#binary-analysis-and-decompilation">Binary Analysis and Decompilation</a></li>
</ul>
</li>
<li>
<p dir="auto">DevOps</p>
<ul dir="auto">
<li><a href="#commit-message-generation">Commit Message Generation</a></li>
<li><a href="#code-review">Code Review</a></li>
<li><a href="#log-analysis">Log Analysis</a></li>
<li><a href="#software-configuration">Software Configuration</a></li>
<li><a href="#code-qa--reasoning">Code QA &amp; Reasoning</a></li>
</ul>
</li>
<li>
<p dir="auto">Requirement</p>
<ul dir="auto">
<li><a href="#software-modeling">Software Modeling</a></li>
<li><a href="#requirement-engineering">Requirement Engineering</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto"><a href="#6-analysis-of-ai-generated-code">Analysis of AI-Generated Code</a></p>
<ul dir="auto">
<li><a href="#security-and-vulnerabilities">Security and Vulnerabilities</a></li>
<li><a href="#correctness">Correctness</a></li>
<li><a href="#hallucination">Hallucination</a></li>
<li><a href="#efficiency">Efficiency</a></li>
<li><a href="#robustness">Robustness</a></li>
<li><a href="#interpretability">Interpretability</a></li>
<li><a href="#api-usage">API Usage</a></li>
<li><a href="#privacy">Privacy</a></li>
<li><a href="#bias">Bias</a></li>
<li><a href="#contamination">Contamination</a></li>
<li><a href="#ai-generated-code-detection">AI-Generated Code Detection</a></li>
<li><a href="#others">Others</a></li>
</ul>
</li>
<li>
<p dir="auto"><a href="#7-human-llm-interaction">Human-LLM Interaction</a></p>
</li>
<li>
<p dir="auto"><a href="#8-datasets">Datasets</a></p>
<p dir="auto">8.1 <a href="#81-pretraining">Pretraining</a></p>
<p dir="auto">8.2 <a href="#82-benchmarks">Benchmarks</a></p>
<ul dir="auto">
<li><a href="#integrated-benchmarks">Integrated Benchmarks</a></li>
<li><a href="#evaluation-metrics">Evaluation Metrics</a></li>
<li><a href="#program-synthesis">Program Synthesis</a></li>
<li><a href="#visually-grounded-program-synthesis">Visually Grounded Program Synthesis</a></li>
<li><a href="#code-reasoning-and-qa">Code Reasoning and QA</a></li>
<li><a href="#text-to-sql-1">Text-to-SQL</a></li>
<li><a href="#code-translation-1">Code Translation</a></li>
<li><a href="#program-repair-1">Program Repair</a></li>
<li><a href="#code-summarization">Code Summarization</a></li>
<li><a href="#defectvulnerability-detection">Defect/Vulnerability Detection</a></li>
<li><a href="#code-retrieval">Code Retrieval</a></li>
<li><a href="#type-inference">Type Inference</a></li>
<li><a href="#commit-message-generation-1">Commit Message Generation</a></li>
<li><a href="#repo-level-coding">Repo-Level Coding</a></li>
</ul>
</li>
<li>
<p dir="auto"><a href="#9-recommended-readings">Recommended Readings</a></p>
</li>
<li>
<p dir="auto"><a href="#citation">Citation</a></p>
</li>
<li>
<p dir="auto"><a href="#star-history">Star History</a></p>
</li>
<li>
<p dir="auto"><a href="#join-us">Join Us</a></p>
</li>
</ol>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">1. Surveys</h2><a id="user-content-1-surveys" class="anchor" aria-label="Permalink: 1. Surveys" href="#1-surveys"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">We list several recent surveys on similar topics. While they are all about language models for code, 1-2 focus on NLP side; 3-6 focus on SE side; 7-11 are released after ours.</p>
<ol dir="auto">
<li>
<p dir="auto">"Large Language Models Meet NL2Code: A Survey" [2022-12] [ACL 2023] [<a href="https://arxiv.org/abs/2212.09420" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Survey on Pretrained Language Models for Neural Code Intelligence" [2022-12] [<a href="https://arxiv.org/abs/2212.10079" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Empirical Comparison of Pre-Trained Models of Source Code" [2023-02] [ICSE 2023] [<a href="https://arxiv.org/abs/2302.04026" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Models for Software Engineering: A Systematic Literature Review" [2023-08] [<a href="https://arxiv.org/abs/2308.10620" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards an Understanding of Large Language Models in Software Engineering Tasks" [2023-08] [<a href="https://arxiv.org/abs/2308.11396" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Pitfalls in Language Models for Code Intelligence: A Taxonomy and Survey" [2023-10] [<a href="https://arxiv.org/abs/2310.17903" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Survey on Large Language Models for Software Engineering" [2023-12] [<a href="https://arxiv.org/abs/2312.15223" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Deep Learning for Code Intelligence: Survey, Benchmark and Toolkit" [2023-12] [<a href="https://arxiv.org/abs/2401.00288" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond" [2024-03] [<a href="https://arxiv.org/abs/2403.14734" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Tasks People Prompt: A Taxonomy of LLM Downstream Tasks in Software Verification and Falsification Approaches" [2024-04] [<a href="https://arxiv.org/abs/2404.09384" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automatic Programming: Large Language Models and Beyond" [2024-05] [<a href="https://arxiv.org/abs/2405.02213" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Software Engineering and Foundation Models: Insights from Industry Blogs Using a Jury of Foundation Models" [2024-10] [<a href="https://arxiv.org/abs/2410.09012" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Deep Learning-based Software Engineering: Progress, Challenges, and Opportunities" [2024-10] [<a href="https://arxiv.org/abs/2410.13110" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Models (LLMs) for Source Code Analysis: applications, models and datasets" [2025-03] [<a href="https://arxiv.org/abs/2503.17502" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Challenges and Paths Towards AI for Software Engineering" [2025-03] [<a href="https://arxiv.org/abs/2503.22625" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Software Development Life Cycle Perspective: A Survey of Benchmarks for CodeLLMs and Agents" [2025-05] [<a href="https://arxiv.org/abs/2505.05283" rel="nofollow">paper</a>]</p>
</li>
</ol>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">2. Models</h2><a id="user-content-2-models" class="anchor" aria-label="Permalink: 2. Models" href="#2-models"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p align="center" dir="auto">
<a target="_blank" rel="noopener noreferrer" href="/codefuse-ai/Awesome-Code-LLM/blob/main/imgs/overview.png"><img src="/codefuse-ai/Awesome-Code-LLM/raw/main/imgs/overview.png" style="width: 80%; max-width: 100%;"></a>
</p>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">2.1 Base LLMs and Pretraining Strategies</h3><a id="user-content-21-base-llms-and-pretraining-strategies" class="anchor" aria-label="Permalink: 2.1 Base LLMs and Pretraining Strategies" href="#21-base-llms-and-pretraining-strategies"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">These LLMs are not specifically trained for code, but have demonstrated varying coding capability.</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>LaMDA</strong>: "LaMDA: Language Models for Dialog Applications" [2022-01] [<a href="https://arxiv.org/abs/2201.08239" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>PaLM</strong>: "PaLM: Scaling Language Modeling with Pathways" [2022-04] [JMLR] [<a href="https://arxiv.org/abs/2204.02311" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>GPT-NeoX</strong>: "GPT-NeoX-20B: An Open-Source Autoregressive Language Model" [2022-04] [ACL 2022 Workshop on Challenges &amp; Perspectives in Creating LLMs] [<a href="https://arxiv.org/abs/2204.06745" rel="nofollow">paper</a>] [<a href="https://github.com/EleutherAI/gpt-neox">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>BLOOM</strong>: "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model" [2022-11] [<a href="https://arxiv.org/abs/2211.05100" rel="nofollow">paper</a>] [<a href="https://huggingface.co/models?search=bigscience/bloom" rel="nofollow">model</a>]</p>
</li>
<li>
<p dir="auto"><strong>LLaMA</strong>: "LLaMA: Open and Efficient Foundation Language Models" [2023-02] [<a href="https://arxiv.org/abs/2302.13971" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>GPT-4</strong>: "GPT-4 Technical Report" [2023-03] [<a href="https://arxiv.org/abs/2303.08774" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>LLaMA 2</strong>: "Llama 2: Open Foundation and Fine-Tuned Chat Models" [2023-07] [<a href="https://arxiv.org/abs/2307.09288" rel="nofollow">paper</a>] [<a href="https://github.com/facebookresearch/llama">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>Phi-1.5</strong>: "Textbooks Are All You Need II: phi-1.5 technical report" [2023-09] [<a href="https://arxiv.org/abs/2309.05463" rel="nofollow">paper</a>] [<a href="https://huggingface.co/microsoft/phi-1_5" rel="nofollow">model</a>]</p>
</li>
<li>
<p dir="auto"><strong>Baichuan 2</strong>: "Baichuan 2: Open Large-scale Language Models" [2023-09] [<a href="https://arxiv.org/abs/2309.10305" rel="nofollow">paper</a>] [<a href="https://github.com/baichuan-inc/Baichuan2">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>Qwen</strong>: "Qwen Technical Report" [2023-09] [<a href="https://arxiv.org/abs/2309.16609" rel="nofollow">paper</a>] [<a href="https://github.com/QwenLM/Qwen">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>Mistral</strong>: "Mistral 7B" [2023-10] [<a href="https://arxiv.org/abs/2310.06825" rel="nofollow">paper</a>] [<a href="https://github.com/mistralai/mistral-src">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>Gemini</strong>: "Gemini: A Family of Highly Capable Multimodal Models" [2023-12] [<a href="https://arxiv.org/abs/2312.11805" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Phi-2</strong>: "Phi-2: The surprising power of small language models" [2023-12] [<a href="https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/" rel="nofollow">blog</a>]</p>
</li>
<li>
<p dir="auto"><strong>YAYI2</strong>: "YAYI 2: Multilingual Open-Source Large Language Models" [2023-12] [<a href="https://arxiv.org/abs/2312.14862" rel="nofollow">paper</a>] [<a href="https://github.com/wenge-research/YAYI2">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>DeepSeek</strong>: "DeepSeek LLM: Scaling Open-Source Language Models with Longtermism" [2024-01] [<a href="https://arxiv.org/abs/2401.02954" rel="nofollow">paper</a>] [<a href="https://github.com/deepseek-ai/DeepSeek-LLM">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>Mixtral</strong>: "Mixtral of Experts" [2024-01] [<a href="https://arxiv.org/abs/2401.04088" rel="nofollow">paper</a>] [<a href="https://mistral.ai/news/mixtral-of-experts/" rel="nofollow">blog</a>]</p>
</li>
<li>
<p dir="auto"><strong>DeepSeekMoE</strong>: "DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models" [2024-01] [<a href="https://arxiv.org/abs/2401.12246" rel="nofollow">paper</a>] [<a href="https://github.com/deepseek-ai/DeepSeek-MoE">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>Orion</strong>: "Orion-14B: Open-source Multilingual Large Language Models" [2024-01] [<a href="https://arxiv.org/abs/2401.06066" rel="nofollow">paper</a>] [<a href="https://github.com/OrionStarAI/Orion">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>OLMo</strong>: "OLMo: Accelerating the Science of Language Models" [2024-02] [<a href="https://arxiv.org/abs/2402.00838" rel="nofollow">paper</a>] [<a href="https://github.com/allenai/OLMo">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>Gemma</strong>: "Gemma: Open Models Based on Gemini Research and Technology" [2024-02] [<a href="https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf" rel="nofollow">paper</a>] [<a href="https://blog.google/technology/developers/gemma-open-models/" rel="nofollow">blog</a>]</p>
</li>
<li>
<p dir="auto"><strong>Claude 3</strong>: "The Claude 3 Model Family: Opus, Sonnet, Haiku" [2024-03] [<a href="https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf" rel="nofollow">paper</a>] [<a href="https://www.anthropic.com/news/claude-3-family" rel="nofollow">blog</a>]</p>
</li>
<li>
<p dir="auto"><strong>Yi</strong>: "Yi: Open Foundation Models by 01.AI" [2024-03] [<a href="https://arxiv.org/abs/2403.04652" rel="nofollow">paper</a>] [<a href="https://github.com/01-ai/Yi">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>Poro</strong>: "Poro 34B and the Blessing of Multilinguality" [2024-04] [<a href="https://arxiv.org/abs/2404.01856" rel="nofollow">paper</a>] [<a href="https://huggingface.co/LumiOpen/Poro-34B" rel="nofollow">model</a>]</p>
</li>
<li>
<p dir="auto"><strong>JetMoE</strong>: "JetMoE: Reaching Llama2 Performance with 0.1M Dollars" [2024-04] [<a href="https://arxiv.org/abs/2404.07413" rel="nofollow">paper</a>] [<a href="https://github.com/myshell-ai/JetMoE">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>LLaMA 3</strong>: "The Llama 3 Herd of Models" [2024-04] [<a href="https://ai.meta.com/blog/meta-llama-3/" rel="nofollow">blog</a>] [<a href="https://github.com/meta-llama/llama3">repo</a>] [<a href="https://arxiv.org/abs/2407.21783" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Reka Core</strong>: "Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language Models" [2024-04] [<a href="https://arxiv.org/abs/2404.12387" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Phi-3</strong>: "Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone" [2024-04] [<a href="https://arxiv.org/abs/2404.14219" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>OpenELM</strong>: "OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework" [2024-04] [<a href="https://arxiv.org/abs/2404.14619" rel="nofollow">paper</a>] [<a href="https://github.com/apple/corenet/tree/main/projects/openelm">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>Tele-FLM</strong>: "Tele-FLM Technical Report" [2024-04] [<a href="https://arxiv.org/abs/2404.16645" rel="nofollow">paper</a>] [<a href="https://huggingface.co/CofeAI/Tele-FLM" rel="nofollow">model</a>]</p>
</li>
<li>
<p dir="auto"><strong>DeepSeek-V2</strong>: "DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model" [2024-05] [<a href="https://arxiv.org/abs/2405.04434" rel="nofollow">paper</a>] [<a href="https://github.com/deepseek-ai/DeepSeek-V2">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>GECKO</strong>: "GECKO: Generative Language Model for English, Code and Korean" [2024-05] [<a href="https://arxiv.org/abs/2405.15640" rel="nofollow">paper</a>] [<a href="https://huggingface.co/kifai/GECKO-7B" rel="nofollow">model</a>]</p>
</li>
<li>
<p dir="auto"><strong>MAP-Neo</strong>: "MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series" [2024-05] [<a href="https://arxiv.org/abs/2405.19327" rel="nofollow">paper</a>] [<a href="https://github.com/multimodal-art-projection/MAP-NEO">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>Zyda</strong>: "Zyda: A 1.3T Dataset for Open Language Modeling" [2024-06] [<a href="https://arxiv.org/abs/2406.01981" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Skywork-MoE</strong>: "Skywork-MoE: A Deep Dive into Training Techniques for Mixture-of-Experts Language Models" [2024-06] [<a href="https://arxiv.org/abs/2406.06563" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Xmodel-LM</strong>: "Xmodel-LM Technical Report" [2024-06] [<a href="https://arxiv.org/abs/2406.02856" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>GEB</strong>: "GEB-1.3B: Open Lightweight Large Language Model" [2024-06] [<a href="https://arxiv.org/abs/2406.09900" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>HARE</strong>: "HARE: HumAn pRiors, a key to small language model Efficiency" [2024-06] [<a href="https://arxiv.org/abs/2406.11410" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>DCLM</strong>: "DataComp-LM: In search of the next generation of training sets for language models" [2024-06] [<a href="https://arxiv.org/abs/2406.11794" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Nemotron-4</strong>: "Nemotron-4 340B Technical Report" [2024-06] [<a href="https://arxiv.org/abs/2406.11704" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>ChatGLM</strong>: "ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools" [2024-06] [<a href="https://arxiv.org/abs/2406.12793" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>FineWeb</strong>: "The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale" [2024-06] [<a href="https://arxiv.org/abs/2406.17557" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>YuLan</strong>: "YuLan: An Open-source Large Language Model" [2024-06] [<a href="https://arxiv.org/abs/2406.19853" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Gemma 2</strong>: "Gemma 2: Improving Open Language Models at a Practical Size" [2024-06] [<a href="https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>H2O-Danube3</strong>: "H2O-Danube3 Technical Report" [2024-07] [<a href="https://arxiv.org/abs/2407.09276" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Qwen2</strong>: "Qwen2 Technical Report" [2024-07] [<a href="https://arxiv.org/abs/2407.10671" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>ALLaM</strong>: "ALLaM: Large Language Models for Arabic and English" [2024-07] [<a href="https://arxiv.org/abs/2407.15390" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SeaLLMs 3</strong>: "SeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for Southeast Asian Languages" [2024-07] [<a href="https://arxiv.org/abs/2407.19672" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>AFM</strong>: "Apple Intelligence Foundation Language Models" [2024-07] [<a href="https://arxiv.org/abs/2407.21075" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"To Code, or Not To Code? Exploring Impact of Code in Pre-training" [2024-08] [ICLR 2025] [<a href="https://arxiv.org/abs/2408.10914" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>OLMoE</strong>: "OLMoE: Open Mixture-of-Experts Language Models" [2024-09] [<a href="https://arxiv.org/abs/2409.02060" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How Does Code Pretraining Affect Language Model Task Performance?" [2024-09] [<a href="https://arxiv.org/abs/2409.04556" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>EuroLLM</strong>: "EuroLLM: Multilingual Language Models for Europe" [2024-09] [<a href="https://arxiv.org/abs/2409.16235" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?" [2024-10] [EMNLP 2024] [<a href="https://arxiv.org/abs/2410.06735" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>GPT-4o</strong>: "GPT-4o System Card" [2024-10] [<a href="https://arxiv.org/abs/2410.21276" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Hunyuan-Large</strong>: "Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent" [2024-11] [<a href="https://arxiv.org/abs/2411.02265" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Crystal</strong>: "Crystal: Illuminating LLM Abilities on Language and Code" [2024-11] [<a href="https://arxiv.org/abs/2411.04156" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Zyda-2</strong>: "Zyda-2: a 5 Trillion Token High-Quality Dataset" [2024-11] [<a href="https://arxiv.org/abs/2411.06068" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Xmodel-1.5</strong>: "Xmodel-1.5: An 1B-scale Multilingual LLM" [2024-11] [<a href="https://arxiv.org/abs/2411.10083" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Yi-Lightning</strong>: "Yi-Lightning Technical Report" [2024-12] [<a href="https://arxiv.org/abs/2412.01253" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RedStone: Curating General, Code, Math, and QA Data for Large Language Models" [2024-12] [<a href="https://arxiv.org/abs/2412.03398" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>EXAONE 3.5</strong>: "EXAONE 3.5: Series of Large Language Models for Real-world Use Cases" [2024-12] [<a href="https://arxiv.org/abs/2412.04862" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Rise and Down of Babel Tower: Investigating the Evolution Process of Multilingual Code Large Language Model" [2024-12] [ICLR 2025] [<a href="https://arxiv.org/abs/2412.07298" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Phi-4</strong>: "Phi-4 Technical Report" [2024-12] [<a href="https://arxiv.org/abs/2412.08905" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Typhoon 2</strong>: "Typhoon 2: A Family of Open Text and Multimodal Thai Large Language Models" [2024-12] [<a href="https://arxiv.org/abs/2412.13702" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Qwen2.5</strong>: "Qwen2.5 Technical Report" [2024-12] [<a href="https://arxiv.org/abs/2412.15115" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>YuLan-Mini</strong>: "YuLan-Mini: An Open Data-efficient Language Model" [2024-12] [<a href="https://arxiv.org/abs/2412.17743" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>DeepSeek-V3</strong>: "DeepSeek-V3 Technical Report" [2024-12] [<a href="https://arxiv.org/abs/2412.19437" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>OLMo 2</strong>: "2 OLMo 2 Furious" [2024-12] [<a href="https://arxiv.org/abs/2501.00656" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>FinerWeb</strong>: "FinerWeb-10BT: Refining Web Data with LLM-Based Line-Level Filtering" [2025-01] [<a href="https://arxiv.org/abs/2501.07314" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>MiniMax-01</strong>: "MiniMax-01: Scaling Foundation Models with Lightning Attention" [2025-01] [<a href="https://arxiv.org/abs/2501.08313" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SmolLM2</strong>: "SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language Model" [2025-02] [<a href="https://arxiv.org/abs/2502.02737" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Salamandra</strong>: "Salamandra Technical Report" [2025-02] [<a href="https://arxiv.org/abs/2502.08489" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Kanana</strong>: "Kanana: Compute-efficient Bilingual Language Models" [2025-02] [<a href="https://arxiv.org/abs/2502.18934" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Phi-4-Mini</strong>: "Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs" [2025-03] [<a href="https://arxiv.org/abs/2503.01743" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Ling</strong>: "Every FLOP Counts: Scaling a 300B Mixture-of-Experts LING LLM without Premium GPUs" [2025-03] [<a href="https://arxiv.org/abs/2503.05139" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Gemma 3</strong>: "Gemma 3 Technical Report" [2025-03] [<a href="https://arxiv.org/abs/2503.19786" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Command A</strong>: "Command A: An Enterprise-Ready Large Language Model" [2025-04] [<a href="https://arxiv.org/abs/2504.00698" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Llama-Nemotron</strong>: "Llama-Nemotron: Efficient Reasoning Models" [2025-05] [<a href="https://arxiv.org/abs/2505.00949" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>MiMo</strong>: "MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining" [2025-05] [<a href="https://arxiv.org/abs/2505.07608" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>xGen-small</strong>: "xGen-small Technical Report" [2025-05] [<a href="https://arxiv.org/abs/2505.06496" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Qwen3</strong>: "Qwen3 Technical Report" [2025-05] [<a href="https://arxiv.org/abs/2505.09388" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Hunyuan-TurboS</strong>: "Hunyuan-TurboS: Advancing Large Language Models through Mamba-Transformer Synergy and Adaptive Chain-of-Thought" [2025-05] [<a href="https://arxiv.org/abs/2505.15431" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>EuroLLM-9B</strong>: "EuroLLM-9B: Technical Report" [2025-06] [<a href="https://arxiv.org/abs/2506.04079" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Gemini 2.5</strong>: "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities" [2025-07] [<a href="https://arxiv.org/abs/2507.06261" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>EXAONE 4.0</strong>: "EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and Reasoning Modes" [2025-07] [<a href="https://arxiv.org/abs/2507.11407" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>TeleChat2</strong>: "Technical Report of TeleChat2, TeleChat2.5 and T1" [2025-07] [<a href="https://arxiv.org/abs/2507.18013" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Kimi K2</strong>: "Kimi K2: Open Agentic Intelligence" [2025-07] [<a href="https://arxiv.org/abs/2507.20534" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>GLM-4.5</strong>: "GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models" [2025-08] [<a href="https://arxiv.org/abs/2508.06471" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>GPT-OSS</strong>: "gpt-oss-120b &amp; gpt-oss-20b Model Card" [2025-08] [<a href="https://arxiv.org/abs/2508.10925" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>LongCat-Flash</strong>: "LongCat-Flash Technical Report" [2025-09] [<a href="https://arxiv.org/abs/2509.01322" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>LLaDA-MoE</strong>: "LLaDA-MoE: A Sparse MoE Diffusion Language Model" [2025-09] [<a href="https://arxiv.org/abs/2509.24389" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Ring-1T</strong>: "Every Step Evolves: Scaling Reinforcement Learning for Trillion-Scale Thinking Model" [2025-10] [<a href="https://arxiv.org/abs/2510.18855" rel="nofollow">paper</a>]</p>
</li>
</ol>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">2.2 Existing LLM Adapted to Code</h3><a id="user-content-22-existing-llm-adapted-to-code" class="anchor" aria-label="Permalink: 2.2 Existing LLM Adapted to Code" href="#22-existing-llm-adapted-to-code"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">These models are general-purpose LLMs further pretrained on code-related data.</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Codex</strong> (GPT-3): "Evaluating Large Language Models Trained on Code" [2021-07] [<a href="https://arxiv.org/abs/2107.03374" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>PaLM Coder</strong> (PaLM): "PaLM: Scaling Language Modeling with Pathways" [2022-04] [JMLR] [<a href="https://arxiv.org/abs/2204.02311" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Minerva</strong> (PaLM): "Solving Quantitative Reasoning Problems with Language Models" [2022-06] [<a href="https://arxiv.org/abs/2206.14858" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>PaLM 2 *</strong> (PaLM 2): "PaLM 2 Technical Report" [2023-05] [<a href="https://arxiv.org/abs/2305.10403" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Code LLaMA</strong> (LLaMA 2): "Code Llama: Open Foundation Models for Code" [2023-08] [<a href="https://arxiv.org/abs/2308.12950" rel="nofollow">paper</a>] [<a href="https://github.com/facebookresearch/codellama">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>Lemur</strong> (LLaMA 2): "Lemur: Harmonizing Natural Language and Code for Language Agents" [2023-10] [ICLR 2024 Spotlight] [<a href="https://arxiv.org/abs/2310.06830" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>BTX</strong> (LLaMA 2): "Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM" [2024-03] [<a href="https://arxiv.org/abs/2403.07816" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>HiRoPE</strong>: "HiRoPE: Length Extrapolation for Code Models Using Hierarchical Position" [2024-03] [ACL 2024] [<a href="https://arxiv.org/abs/2403.19115" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Mastering Text, Code and Math Simultaneously via Fusing Highly Specialized Language Models" [2024-03] [<a href="https://arxiv.org/abs/2403.08281" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeGemma</strong>: "CodeGemma: Open Code Models Based on Gemma" [2024-04] [<a href="https://storage.googleapis.com/deepmind-media/gemma/codegemma_report.pdf" rel="nofollow">paper</a>] [<a href="https://huggingface.co/models?search=google/codegemma" rel="nofollow">model</a>]</p>
</li>
<li>
<p dir="auto"><strong>DeepSeek-Coder-V2</strong>: "DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence" [2024-06] [<a href="https://arxiv.org/abs/2406.11931" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Promise and Peril of Collaborative Code Generation Models: Balancing Effectiveness and Memorization" [2024-09] [<a href="https://arxiv.org/abs/2409.12020" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Qwen2.5-Coder</strong>: "Qwen2.5-Coder Technical Report" [2024-09] [<a href="https://arxiv.org/abs/2409.12186" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Lingma SWE-GPT</strong>: "Lingma SWE-GPT: An Open Development-Process-Centric Language Model for Automated Software Improvement" [2024-11] [<a href="https://arxiv.org/abs/2411.00622" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Ling-Coder-Lite</strong>: "Every Sample Matters: Leveraging Mixture-of-Experts and High-Quality Data for Efficient and Accurate Code LLM" [2025-03] [<a href="https://arxiv.org/abs/2503.17793" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">2.3 General Pretraining on Code</h3><a id="user-content-23-general-pretraining-on-code" class="anchor" aria-label="Permalink: 2.3 General Pretraining on Code" href="#23-general-pretraining-on-code"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">These models are Transformer encoders, decoders, and encoder-decoders pretrained from scratch using existing objectives for general language modeling.</p>
<p align="center" dir="auto">
<a target="_blank" rel="noopener noreferrer" href="/codefuse-ai/Awesome-Code-LLM/blob/main/imgs/model_detail.png"><img src="/codefuse-ai/Awesome-Code-LLM/raw/main/imgs/model_detail.png" style="width: 90%; max-width: 100%;"></a>
</p>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Encoder</h4><a id="user-content-encoder" class="anchor" aria-label="Permalink: Encoder" href="#encoder"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>
<p dir="auto"><strong>CuBERT</strong> (MLM + NSP): "Learning and Evaluating Contextual Embedding of Source Code" [2019-12] [ICML 2020] [<a href="https://arxiv.org/abs/2001.00059" rel="nofollow">paper</a>] [<a href="https://github.com/google-research/google-research/tree/master/cubert">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeBERT</strong> (MLM + RTD): "CodeBERT: A Pre-Trained Model for Programming and Natural Languages" [2020-02] [EMNLP 2020 findings] [<a href="https://arxiv.org/abs/2002.08155" rel="nofollow">paper</a>] [<a href="https://github.com/microsoft/CodeBERT">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>GraphCodeBERT</strong> (MLM + DFG Edge Prediction + DFG Node Alignment): "GraphCodeBERT: Pre-training Code Representations with Data Flow" [2020-09] [ICLR 2021] [<a href="https://arxiv.org/abs/2009.08366" rel="nofollow">paper</a>] [<a href="https://github.com/microsoft/CodeBERT">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>SynCoBERT</strong> (MLM + Identifier Prediction + AST Edge Prediction + Contrastive Learning): "SynCoBERT: Syntax-Guided Multi-Modal Contrastive Pre-Training for Code Representation" [2021-08] [<a href="https://arxiv.org/abs/2108.04556" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>DISCO</strong> (MLM + Node Type MLM + Contrastive Learning): "Towards Learning (Dis)-Similarity of Source Code from Program Contrasts" [2021-10] [ACL 2022] [<a href="https://arxiv.org/abs/2110.03868" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Code-MVP</strong> (MLM + Type Inference + Contrastive Learning): "CODE-MVP: Learning to Represent Source Code from Multiple Views with Contrastive Pre-Training" [2022-05] [NAACL 2022 Technical Track] [<a href="https://arxiv.org/abs/2205.02029" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeSage</strong> (MLM + Deobfuscation + Contrastive Learning): "Code Representation Learning At Scale" [2024-02] [ICLR 2024] [<a href="https://arxiv.org/abs/2402.01935" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CoLSBERT</strong> (MLM): "Scaling Laws Behind Code Understanding Model" [2024-02] [<a href="https://arxiv.org/abs/2402.12813" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>BiGSCoder</strong>: "BiGSCoder: State Space Model for Code Understanding" [2025-05] [<a href="https://arxiv.org/abs/2505.01475" rel="nofollow">paper</a>]</p>
</li>
</ol>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Decoder</h4><a id="user-content-decoder" class="anchor" aria-label="Permalink: Decoder" href="#decoder"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>
<p dir="auto"><strong>GPT-C</strong> (CLM): "IntelliCode Compose: Code Generation Using Transformer" [2020-05] [ESEC/FSE 2020] [<a href="https://arxiv.org/abs/2005.08025" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeGPT</strong> (CLM): "CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation" [2021-02] [NeurIPS Datasets and Benchmarks 2021] [<a href="https://arxiv.org/abs/2102.04664" rel="nofollow">paper</a>] [<a href="https://github.com/microsoft/CodeXGLUE">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeParrot</strong> (CLM) [2021-12] [<a href="https://huggingface.co/blog/codeparrot" rel="nofollow">blog</a>]</p>
</li>
<li>
<p dir="auto"><strong>PolyCoder</strong> (CLM): "A Systematic Evaluation of Large Language Models of Code" [2022-02] [DL4C@ICLR 2022] [<a href="https://arxiv.org/abs/2202.13169" rel="nofollow">paper</a>] [<a href="https://github.com/VHellendoorn/Code-LMs">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeGen</strong> (CLM): "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis" [2022-03] [ICLR 2023] [<a href="https://arxiv.org/abs/2203.13474" rel="nofollow">paper</a>] [<a href="https://github.com/salesforce/CodeGen">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>InCoder</strong> (Causal Masking): "InCoder: A Generative Model for Code Infilling and Synthesis" [2022-04] [ICLR 2023] [<a href="https://arxiv.org/abs/2204.05999" rel="nofollow">paper</a>] [<a href="https://github.com/dpfried/incoder">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>PyCodeGPT</strong> (CLM): "CERT: Continual Pre-Training on Sketches for Library-Oriented Code Generation" [2022-06] [IJCAI-ECAI 2022] [<a href="https://arxiv.org/abs/2206.06888" rel="nofollow">paper</a>] [<a href="https://github.com/microsoft/PyCodeGPT">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>PanGu-Coder</strong> (CLM): "PanGu-Coder: Program Synthesis with Function-Level Language Modeling" [2022-07] [<a href="https://arxiv.org/abs/2207.11280" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SantaCoder</strong> (FIM): "SantaCoder: don't reach for the stars!" [2023-01] [<a href="https://arxiv.org/abs/2301.03988" rel="nofollow">paper</a>] [<a href="https://huggingface.co/bigcode/santacoder" rel="nofollow">model</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeGeeX</strong> (CLM): "CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X" [2023-03] [<a href="https://arxiv.org/abs/2303.17568" rel="nofollow">paper</a>] [<a href="https://github.com/THUDM/CodeGeeX">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>StarCoder</strong> (FIM): "StarCoder: may the source be with you!" [2023-05] [<a href="https://arxiv.org/abs/2305.06161" rel="nofollow">paper</a>] [<a href="https://huggingface.co/bigcode/starcoder" rel="nofollow">model</a>]</p>
</li>
<li>
<p dir="auto"><strong>Phi-1</strong> (CLM): "Textbooks Are All You Need" [2023-06] [<a href="https://arxiv.org/abs/2306.11644" rel="nofollow">paper</a>] [<a href="https://huggingface.co/microsoft/phi-1" rel="nofollow">model</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeFuse</strong> (CLM): "CodeFuse-13B: A Pretrained Multi-lingual Code Large Language Model" [2023-10] [<a href="https://arxiv.org/abs/2310.06266" rel="nofollow">paper</a>] [<a href="https://huggingface.co/codefuse-ai/CodeFuse-13B" rel="nofollow">model</a>]</p>
</li>
<li>
<p dir="auto"><strong>DeepSeek Coder</strong> (CLM+FIM): "DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence" [2024-01] [<a href="https://arxiv.org/abs/2401.14196" rel="nofollow">paper</a>] [<a href="https://github.com/deepseek-ai/DeepSeek-Coder">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>StarCoder2</strong> (CLM+FIM): "StarCoder 2 and The Stack v2: The Next Generation" [2024-02] [<a href="https://arxiv.org/abs/2402.19173" rel="nofollow">paper</a>] [<a href="https://github.com/bigcode-project/starcoder2">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeShell</strong> (CLM+FIM): "CodeShell Technical Report" [2024-03] [<a href="https://arxiv.org/abs/2403.15747" rel="nofollow">paper</a>] [<a href="https://github.com/WisdomShell/codeshell">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeQwen1.5</strong> [2024-04] [<a href="https://qwenlm.github.io/blog/codeqwen1.5/" rel="nofollow">blog</a>]</p>
</li>
<li>
<p dir="auto"><strong>Granite</strong>: "Granite Code Models: A Family of Open Foundation Models for Code Intelligence" [2024-05] [<a href="https://arxiv.org/abs/2405.04324" rel="nofollow">paper</a>] "Scaling Granite Code Models to 128K Context" [2024-07] [<a href="https://arxiv.org/abs/2407.13739" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>NT-Java</strong>: "Narrow Transformer: Starcoder-Based Java-LM For Desktop" [2024-07] [<a href="https://arxiv.org/abs/2407.03941" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Arctic-SnowCoder</strong>: "Arctic-SnowCoder: Demystifying High-Quality Data in Code Pretraining" [2024-09] [<a href="https://arxiv.org/abs/2409.02326" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>aiXcoder</strong>: "aiXcoder-7B: A Lightweight and Effective Large Language Model for Code Completion" [2024-10] [<a href="https://arxiv.org/abs/2410.13187" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>OpenCoder</strong>: "OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models" [2024-11] [ACL 2025] [<a href="https://arxiv.org/abs/2411.04905" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>ObscuraCoder</strong>: "ObscuraCoder: Powering Efficient Code LM Pre-Training Via Obfuscation Grounding" [2025-03] [ICLR 2025] [<a href="https://arxiv.org/abs/2504.00019" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Structure-Aware Fill-in-the-Middle Pretraining for Code" [2025-05] [<a href="https://arxiv.org/abs/2506.00204" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Seed-Coder</strong>: "Seed-Coder: Let the Code Model Curate Data for Itself" [2025-06] [<a href="https://arxiv.org/abs/2506.03524" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CWM</strong>: "CWM: An Open-Weights LLM for Research on Code Generation with World Models" [2025-09] [<a href="https://arxiv.org/abs/2510.02387" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Mellum</strong>: "Mellum: Production-Grade in-IDE Contextual Code Completion with Multi-File Project Understanding" [2025-10] [<a href="https://arxiv.org/abs/2510.05788" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Scaling Laws for Code: A More Data-Hungry Regime" [2025-10] [<a href="https://arxiv.org/abs/2510.08702" rel="nofollow">paper</a>]</p>
</li>
</ol>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Encoder-Decoder</h4><a id="user-content-encoder-decoder" class="anchor" aria-label="Permalink: Encoder-Decoder" href="#encoder-decoder"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>
<p dir="auto"><strong>PyMT5</strong> (Span Corruption): "PyMT5: multi-mode translation of natural language and Python code with transformers" [2020-10] [EMNLP 2020] [<a href="https://arxiv.org/abs/2010.03150" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Mastropaolo et al.</strong> (MLM + Deobfuscation): "DOBF: A Deobfuscation Pre-Training Objective for Programming Languages" [2021-02] [ICSE 2021] [<a href="https://arxiv.org/abs/2102.02017" rel="nofollow">paper</a>] [<a href="https://github.com/antonio-mastropaolo/TransferLearning4Code">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>DOBF</strong> (Span Corruption): "Studying the Usage of Text-To-Text Transfer Transformer to Support Code-Related Tasks" [2021-02] [NeurIPS 2021] [<a href="https://arxiv.org/abs/2102.07492" rel="nofollow">paper</a>] [<a href="https://github.com/facebookresearch/CodeGen/blob/main/docs/dobf.md">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>PLBART</strong> (DAE): "Unified Pre-training for Program Understanding and Generation" [2021-03] [NAACL 2021] [<a href="https://arxiv.org/abs/2103.06333" rel="nofollow">paper</a>] [<a href="https://github.com/wasiahmad/PLBART">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeT5</strong> (Span Corruption + Identifier Tagging + Masked Identifier Prediction + Text2Code + Code2Text): "CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation" [2021-09] [EMNLP 2021] [<a href="https://arxiv.org/abs/2109.00859" rel="nofollow">paper</a>] [<a href="https://github.com/salesforce/CodeT5">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>SPT-Code</strong> (Span Corruption + NSP + Method Name Prediction): "SPT-Code: Sequence-to-Sequence Pre-Training for Learning Source Code Representations" [2022-01] [ICSE 2022 Technical Track] [<a href="https://arxiv.org/abs/2201.01549" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>AlphaCode</strong> (MLM + CLM): "Competition-Level Code Generation with AlphaCode" [2022-02] [Science] [<a href="https://arxiv.org/abs/2203.07814" rel="nofollow">paper</a>] [<a href="https://deepmind.google/discover/blog/competitive-programming-with-alphacode/" rel="nofollow">blog</a>]</p>
</li>
<li>
<p dir="auto"><strong>NatGen</strong> (Code Naturalization): "NatGen: Generative pre-training by "Naturalizing" source code" [2022-06] [ESEC/FSE 2022] [<a href="https://arxiv.org/abs/2206.07585" rel="nofollow">paper</a>] [<a href="https://github.com/saikat107/NatGen">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>ERNIE-Code</strong> (Span Corruption + Pivot-based Translation LM): "ERNIE-Code: Beyond English-Centric Cross-lingual Pretraining for Programming Languages" [2022-12] [ACL23 (Findings)] [<a href="https://aclanthology.org/2023.findings-acl.676.pdf" rel="nofollow">paper</a>][<a href="https://github.com/PaddlePaddle/PaddleNLP/tree/develop/model_zoo/ernie-code">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeT5+</strong> (Span Corruption + CLM + Text-Code Contrastive Learning + Text-Code Translation): "CodeT5+: Open Code Large Language Models for Code Understanding and Generation" [2023-05] [EMNLP 2023] [<a href="https://arxiv.org/abs/2305.07922" rel="nofollow">paper</a>] [<a href="https://github.com/salesforce/CodeT5">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>AST-T5</strong> (Span Corruption): "AST-T5: Structure-Aware Pretraining for Code Generation and Understanding" [2024-01] [ICML 2024] [<a href="https://arxiv.org/abs/2401.03003" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>DivoT5</strong>: "Directional Diffusion-Style Code Editing Pre-training" [2025-01] [<a href="https://arxiv.org/abs/2501.12079" rel="nofollow">paper</a>]</p>
</li>
</ol>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">UniLM</h4><a id="user-content-unilm" class="anchor" aria-label="Permalink: UniLM" href="#unilm"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>
<p dir="auto"><strong>CugLM</strong> (MLM + NSP + CLM): "Multi-task Learning based Pre-trained Language Model for Code Completion" [2020-12] [ASE 2020] [<a href="https://arxiv.org/abs/2012.14631" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>UniXcoder</strong> (MLM + NSP + CLM + Span Corruption + Contrastive Learning + Code2Text): "UniXcoder: Unified Cross-Modal Pre-training for Code Representation" [2022-03] [ACL 2022] [<a href="https://arxiv.org/abs/2203.03850" rel="nofollow">paper</a>] [<a href="https://github.com/microsoft/CodeBERT">repo</a>]</p>
</li>
</ol>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Other Models</h4><a id="user-content-other-models" class="anchor" aria-label="Permalink: Other Models" href="#other-models"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>
<p dir="auto"><strong>DiffuCoder</strong>: "DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation" [2025-06] [<a href="https://arxiv.org/abs/2506.20639" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Dream-Coder</strong>: "Dream-Coder 7B: An Open Diffusion Language Model for Code" [2025-09] [<a href="https://arxiv.org/abs/2509.01142" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Beyond Autoregression: An Empirical Study of Diffusion Large Language Models for Code Generation" [2025-09] [<a href="https://arxiv.org/abs/2509.11252" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CoDA</strong>: "CoDA: Coding LM via Diffusion Adaptation" [2025-10] [<a href="https://arxiv.org/abs/2510.03270" rel="nofollow">paper</a>]</p>
</li>
</ol>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">2.4 (Instruction) Fine-Tuning on Code</h3><a id="user-content-24-instruction-fine-tuning-on-code" class="anchor" aria-label="Permalink: 2.4 (Instruction) Fine-Tuning on Code" href="#24-instruction-fine-tuning-on-code"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">These models apply Instruction Fine-Tuning techniques to enhance the capacities of Code LLMs.</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>WizardCoder</strong> (StarCoder + Evol-Instruct): "WizardCoder: Empowering Code Large Language Models with Evol-Instruct" [2023-06] [ICLR 2024] [<a href="https://arxiv.org/abs/2306.08568" rel="nofollow">paper</a>] [<a href="https://github.com/nlpxucan/WizardLM">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>PanGu-Coder 2</strong> (StarCoder + Evol-Instruct + RRTF): "PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback" [2023-07] [<a href="https://arxiv.org/abs/2307.14936" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>OctoCoder</strong> (StarCoder) / <strong>OctoGeeX</strong> (CodeGeeX2): "OctoPack: Instruction Tuning Code Large Language Models" [2023-08] [ICLR 2024 Spotlight] [<a href="https://arxiv.org/abs/2308.07124" rel="nofollow">paper</a>] [<a href="https://github.com/bigcode-project/octopack">repo</a>]</p>
</li>
<li>
<p dir="auto">"At Which Training Stage Does Code Data Help LLMs Reasoning" [2023-09] [ICLR 2024 Spotlight] [<a href="https://arxiv.org/abs/2309.16298" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>InstructCoder</strong>: "InstructCoder: Instruction Tuning Large Language Models for Code Editing" [<a href="https://arxiv.org/abs/2310.20329" rel="nofollow">paper</a>] [<a href="https://github.com/qishenghu/CodeInstruct">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>MFTCoder</strong>: "MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning" [2023-11] [KDD 2024] [<a href="https://arxiv.org/abs/2311.02303" rel="nofollow">paper</a>] [<a href="https://github.com/codefuse-ai/MFTCoder">repo</a>]</p>
</li>
<li>
<p dir="auto">"LLM-Assisted Code Cleaning For Training Accurate Code Generators" [2023-11] [ICLR 2024] [<a href="https://arxiv.org/abs/2311.14904" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Magicoder</strong>: "Magicoder: Empowering Code Generation with OSS-Instruct" [2023-12] [ICML 2024] [<a href="https://arxiv.org/abs/2312.02120" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>WaveCoder</strong>: "WaveCoder: Widespread And Versatile Enhancement For Code Large Language Models By Instruction Tuning" [2023-12] [ACL 2024] [<a href="https://arxiv.org/abs/2312.14187" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Astraios</strong>: "Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models" [2024-01] [<a href="https://arxiv.org/abs/2401.00788" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>DolphCoder</strong>: "DolphCoder: Echo-Locating Code Large Language Models with Diverse and Multi-Objective Instruction Tuning" [2024-02] [ACL 2024] [<a href="https://arxiv.org/abs/2402.09136" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SafeCoder</strong>: "Instruction Tuning for Secure Code Generation" [2024-02] [ICML 2024] [<a href="https://arxiv.org/abs/2402.09497" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code Needs Comments: Enhancing Code LLMs with Comment Augmentation" [ACL 2024 Findings] [<a href="https://arxiv.org/abs/2402.13013" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CCT</strong>: "Code Comparison Tuning for Code Large Language Models" [2024-03] [<a href="https://arxiv.org/abs/2403.19121" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SAT</strong>: "Structure-aware Fine-tuning for Code Pre-trained Models" [2024-04] [<a href="https://arxiv.org/abs/2404.07471" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeFort</strong>: "CodeFort: Robust Training for Code Generation Models" [2024-04] [EMNLP 2024 Findings] [<a href="https://arxiv.org/abs/2405.01567" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>XFT</strong>: "XFT: Unlocking the Power of Code Instruction Tuning by Simply Merging Upcycled Mixture-of-Experts" [2024-04] [ACL 2024] [<a href="https://arxiv.org/abs/2404.15247" rel="nofollow">paper</a>] [<a href="https://github.com/ise-uiuc/xft">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>AIEV-Instruct</strong>: "AutoCoder: Enhancing Code Large Language Model with AIEV-Instruct" [2024-05] [<a href="https://arxiv.org/abs/2405.14906" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>AlchemistCoder</strong>: "AlchemistCoder: Harmonizing and Eliciting Code Capability by Hindsight Tuning on Multi-source Data" [2024-05] [NeurIPS 2024] [<a href="https://arxiv.org/abs/2405.19265" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"From Symbolic Tasks to Code Generation: Diversification Yields Better Task Performers" [2024-05] [<a href="https://arxiv.org/abs/2405.19787" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Unveiling the Impact of Coding Data Instruction Fine-Tuning on Large Language Models Reasoning" [2024-05] [<a href="https://arxiv.org/abs/2405.20535" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SemCoder</strong>: "SemCoder: Training Code Language Models with Comprehensive Semantics Reasoning" [2024-06] [NeurIPS 2024] [<a href="https://arxiv.org/abs/2406.01006" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>PLUM</strong>: "PLUM: Preference Learning Plus Test Cases Yields Better Code Language Models" [2024-06] [<a href="https://arxiv.org/abs/2406.06887" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>mCoder</strong>: "McEval: Massively Multilingual Code Evaluation" [2024-06] [ICLR 2025] [<a href="https://arxiv.org/abs/2406.07436" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Unlock the Correlation between Supervised Fine-Tuning and Reinforcement Learning in Training Code Large Language Models" [2024-06] [<a href="https://arxiv.org/abs/2406.10305" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Code-Optimise</strong>: "Code-Optimise: Self-Generated Preference Data for Correctness and Efficiency" [2024-06] [<a href="https://arxiv.org/abs/2406.12502" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>UniCoder</strong>: "UniCoder: Scaling Code Large Language Model via Universal Code" [2024-06] [ACL 2024] [<a href="https://arxiv.org/abs/2406.16441" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Brevity is the soul of wit: Pruning long files for code generation" [2024-06] [<a href="https://arxiv.org/abs/2407.00434" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code Less, Align More: Efficient LLM Fine-tuning for Code Generation with Data Pruning" [2024-07] [<a href="https://arxiv.org/abs/2407.05040" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>InverseCoder</strong>: "InverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct" [2024-07] [<a href="https://arxiv.org/abs/2407.05700" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Curriculum Learning for Small Code Language Models" [2024-07] [<a href="https://arxiv.org/abs/2407.10194" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Genetic-Instruct</strong>: "Genetic Instruct: Scaling up Synthetic Generation of Coding Instructions for Large Language Models" [2024-07] [<a href="https://arxiv.org/abs/2407.21077" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>DataScope</strong>: "API-guided Dataset Synthesis to Finetune Large Code Models" [2024-08] [<a href="https://arxiv.org/abs/2408.08343" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>XCoder</strong>: "How Do Your Code LLMs Perform? Empowering Code Instruction Tuning with High-Quality Data" [2024-09] [EMNLP 2024] [<a href="https://arxiv.org/abs/2409.03810" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>GALLa</strong>: "GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding" [2024-09] [ACL 2025] [<a href="https://arxiv.org/abs/2409.04183" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>HexaCoder</strong>: "HexaCoder: Secure Code Generation via Oracle-Guided Synthetic Training Data" [2024-09] [<a href="https://arxiv.org/abs/2409.06446" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>AMR-Evol</strong>: "AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation" [2024-10] [EMNLP 2024] [<a href="https://arxiv.org/abs/2410.00558" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>LintSeq</strong>: "Training Language Models on Synthetic Edit Sequences Improves Code Synthesis" [2024-10] [ICLR 2025] [<a href="https://arxiv.org/abs/2410.02749" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CoBa</strong>: "CoBa: Convergence Balancer for Multitask Finetuning of Large Language Models" [2024-10] [EMNLP 2024] [<a href="https://arxiv.org/abs/2410.06741" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CursorCore</strong>: "CursorCore: Assist Programming through Aligning Anything" [2024-10] [<a href="https://arxiv.org/abs/2410.07002" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SelfCodeAlign</strong>: "SelfCodeAlign: Self-Alignment for Code Generation" [2024-10] [NeurIPS 2024] [<a href="https://arxiv.org/abs/2410.24198" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Mastering the Craft of Data Synthesis for CodeLLMs" [2024-10] [<a href="https://arxiv.org/abs/2411.00005" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeLutra</strong>: "CodeLutra: Boosting LLM Code Generation via Preference-Guided Refinement" [2024-11] [<a href="https://arxiv.org/abs/2411.05199" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>DSTC</strong>: "DSTC: Direct Preference Learning with Only Self-Generated Tests and Code to Improve Code LMs" [2024-11] [<a href="https://arxiv.org/abs/2411.13611" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>WarriorCoder</strong>: "WarriorCoder: Learning from Expert Battles to Augment Code Large Language Models" [2024-12] [ACL 2025] [<a href="https://arxiv.org/abs/2412.17395" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>EpiCoder</strong>: "EpiCoder: Encompassing Diversity and Complexity in Code Generation" [2025-01] [ICML 2025] [<a href="https://arxiv.org/abs/2501.04694" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Qwen2.5-xCoder</strong>: "Multi-Agent Collaboration for Multilingual Code Instruction Tuning" [2025-02] [ACL 2025] [<a href="https://arxiv.org/abs/2502.07487" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>UnitCoder</strong>: "UnitCoder: Scalable Iterative Code Synthesis with Unit Test Guidance" [2025-02] [<a href="https://arxiv.org/abs/2502.11460" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>GiFT</strong>: "GiFT: Gibbs Fine-Tuning for Code Generation" [2025-02] [ACL 2025] [<a href="https://arxiv.org/abs/2502.11466" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>KODCODE</strong>: "KodCode: A Diverse, Challenging, and Verifiable Synthetic Dataset for Coding" [2025-03] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2503.02951" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>NextCoder</strong>: "NextCoder: Robust Adaptation of Code LMs to Diverse Code Edits" [2025-03] [ICML 2025] [<a href="https://arxiv.org/abs/2503.03656" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>FAIT</strong>: "FAIT: Fault-Aware Fine-Tuning for Better Code Generation" [2025-03] [<a href="https://arxiv.org/abs/2503.16913" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Z1</strong>: "Z1: Efficient Test-time Scaling with Code" [2025-04] [<a href="https://arxiv.org/abs/2504.00810" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>OpenCodeReasoning</strong>: "OpenCodeReasoning: Advancing Data Distillation for Competitive Coding" [2025-04] [<a href="https://arxiv.org/abs/2504.01943" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>OpenCodeInstruct</strong>: "OpenCodeInstruct: A Large-scale Instruction Tuning Dataset for Code LLMs" [2025-04] [<a href="https://arxiv.org/abs/2504.04030" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Data-efficient LLM Fine-tuning for Code Generation" [2025-04] [<a href="https://arxiv.org/abs/2504.12687" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AKD : Adversarial Knowledge Distillation For Large Language Models Alignment on Coding tasks" [2025-05] [<a href="https://arxiv.org/abs/2505.06267" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CRPE: Expanding The Reasoning Capability of Large Language Model for Code Generation" [2025-05] [<a href="https://arxiv.org/abs/2505.10594" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>VisCoder</strong>: "VisCoder: Fine-Tuning LLMs for Executable Python Visualization Code Generation" [2025-05] [<a href="https://arxiv.org/abs/2506.03930" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AceReason-Nemotron 1.1: Advancing Math and Code Reasoning through SFT and RL Synergy" [2025-06] [<a href="https://arxiv.org/abs/2506.13284" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>MoLE</strong>: "Mix-of-Language-Experts Architecture for Multilingual Programming" [2025-06] [<a href="https://arxiv.org/abs/2506.18923" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>OpenCodeReasoning-II</strong>: "OpenCodeReasoning-II: A Simple Test Time Scaling Approach via Self-Critique" [2025-07] [<a href="https://arxiv.org/abs/2507.09075" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeEvo: Interaction-Driven Synthesis of Code-centric Data through Hybrid and Iterative Feedback" [2025-07] [<a href="https://arxiv.org/abs/2507.22080" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Tree-of-Evolution</strong>: "Tree-of-Evolution: Tree-Structured Instruction Evolution for Code Generation in Large Language Models" [2025-07] [ACL 2025] [<a href="https://aclanthology.org/2025.acl-long.14/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SCoder</strong>: "SCoder: Iterative Self-Distillation for Bootstrapping Small-Scale Data Synthesizers to Empower Code LLMs" [2025-09] [<a href="https://arxiv.org/abs/2509.07858" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Do Code Semantics Help? A Comprehensive Study on Execution Trace-Based Information for Code Large Language Models" [2025-09] [<a href="https://arxiv.org/abs/2509.11686" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SCoGen: Scenario-Centric Graph-Based Synthesis of Real-World Code Problems" [2025-09] [<a href="https://arxiv.org/abs/2509.14281" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Verification Limits Code LLM Training" [2025-09] [<a href="https://arxiv.org/abs/2509.20837" rel="nofollow">paper</a>]</p>
</li>
</ol>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">2.5 Reinforcement Learning on Code</h3><a id="user-content-25-reinforcement-learning-on-code" class="anchor" aria-label="Permalink: 2.5 Reinforcement Learning on Code" href="#25-reinforcement-learning-on-code"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>
<p dir="auto"><strong>CompCoder</strong>: "Compilable Neural Code Generation with Compiler Feedback" [2022-03] [ACL 2022] [<a href="https://arxiv.org/abs/2203.05132" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeRL</strong>: "CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning" [2022-07] [NeurIPS 2022] [<a href="https://arxiv.org/abs/2207.01780" rel="nofollow">paper</a>] [<a href="https://github.com/salesforce/CodeRL">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>PPOCoder</strong>: "Execution-based Code Generation using Deep Reinforcement Learning" [2023-01] [TMLR 2023] [<a href="https://arxiv.org/abs/2301.13816" rel="nofollow">paper</a>] [<a href="https://github.com/reddy-lab-code-research/PPOCoder">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>RLTF</strong>: "RLTF: Reinforcement Learning from Unit Test Feedback" [2023-07] [<a href="https://arxiv.org/abs/2307.04349" rel="nofollow">paper</a>] [<a href="https://github.com/Zyq-scut/RLTF">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>B-Coder</strong>: "B-Coder: Value-Based Deep Reinforcement Learning for Program Synthesis" [2023-10] [ICLR 2024] [<a href="https://arxiv.org/abs/2310.03173" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>IRCoCo</strong>: "IRCoCo: Immediate Rewards-Guided Deep Reinforcement Learning for Code Completion" [2024-01] [FSE 2024] [<a href="https://arxiv.org/abs/2401.16637" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>StepCoder</strong>: "StepCoder: Improve Code Generation with Reinforcement Learning from Compiler Feedback" [2024-02] [ACL 2024] [<a href="https://arxiv.org/abs/2402.01391" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>RLPF &amp; DPA</strong>: "Performance-Aligned LLMs for Generating Fast Code" [2024-04] [<a href="https://arxiv.org/abs/2404.18864" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Measuring memorization in RLHF for code completion" [2024-06] [ICLR 2025] [<a href="https://arxiv.org/abs/2406.11715" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Applying RLAIF for Code Generation with API-usage in Lightweight LLMs" [2024-06] [<a href="https://arxiv.org/abs/2406.20060" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>RLCoder</strong>: "RLCoder: Reinforcement Learning for Repository-Level Code Completion" [2024-07] [<a href="https://arxiv.org/abs/2407.19487" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>PF-PPO</strong>: "Policy Filtration in RLHF to Fine-Tune LLM for Code Generation" [2024-09] [<a href="https://arxiv.org/abs/2409.06957" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Coffee-Gym</strong>: "Coffee-Gym: An Environment for Evaluating and Improving Natural Language Feedback on Erroneous Code" [2024-09] [EMNLP 2024] [<a href="https://arxiv.org/abs/2409.19715" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>RLEF</strong>: "RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning" [2024-10] [ICML 2025] [<a href="https://arxiv.org/abs/2410.02089" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodePMP</strong>: "CodePMP: Scalable Preference Model Pretraining for Large Language Model Reasoning" [2024-10] [<a href="https://arxiv.org/abs/2410.02229" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeDPO</strong>: "CodeDPO: Aligning Code Models with Self Generated and Verified Source Code" [2024-10] [ACL 2025] [<a href="https://arxiv.org/abs/2410.05605" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Process Supervision-Guided Policy Optimization for Code Generation" [2024-10] [<a href="https://arxiv.org/abs/2410.17621" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Aligning CodeLLMs with Direct Preference Optimization" [2024-10] [<a href="https://arxiv.org/abs/2410.18585" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>FALCON</strong>: "FALCON: Feedback-driven Adaptive Long/short-term memory reinforced Coding Optimization system" [2024-10] [<a href="https://arxiv.org/abs/2410.21349" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>PFPO</strong>: "Preference Optimization for Reasoning with Pseudo Feedback" [2024-11] [<a href="https://arxiv.org/abs/2411.16345" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>o1-Coder</strong>: "o1-Coder: an o1 Replication for Coding" [2024-11] [<a href="https://arxiv.org/abs/2412.00154" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>PRLCoder</strong>: "Process-Supervised Reinforcement Learning for Code Generation" [2025-02] [<a href="https://arxiv.org/abs/2502.01715" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>AceCoder</strong>: "ACECODER: Acing Coder RL via Automated Test-Case Synthesis" [2025-02] [ACL 2025] [<a href="https://arxiv.org/abs/2502.01718" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Focused-DPO</strong>: "Focused-DPO: Enhancing Code Generation Through Focused Preference Optimization on Error-Prone Points" [2025-02] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2502.11475" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SWE-RL</strong>: "SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution" [2025-02] [<a href="https://arxiv.org/abs/2502.18449" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>AceReason-Nemotron</strong>: "AceReason-Nemotron: Advancing Math and Code Reasoning through Reinforcement Learning" [2025-05] [<a href="https://arxiv.org/abs/2505.16400" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>rStar-Coder</strong>: "rStar-Coder: Scaling Competitive Code Reasoning with a Large-Scale Verified Dataset" [2025-05] [<a href="https://arxiv.org/abs/2505.21297" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CURE</strong>: "Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning" [2025-06] [<a href="https://arxiv.org/abs/2506.03136" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Magistral</strong> [2025-06] [<a href="https://arxiv.org/abs/2506.10910" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Ring-lite</strong>: "Ring-lite: Scalable Reasoning via C3PO-Stabilized Reinforcement Learning for LLMs" [2025-06] [<a href="https://arxiv.org/abs/2506.14731" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>ReST-RL</strong>: "ReST-RL: Achieving Accurate Code Reasoning of LLMs with Optimized Self-Training and Decoding" [2025-08] [<a href="https://arxiv.org/abs/2508.19576" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards Better Correctness and Efficiency in Code Generation" [2025-08] [<a href="https://arxiv.org/abs/2508.20124" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Building Coding Agents via Entropy-Enhanced Multi-Turn Preference Optimization" [2025-09] [<a href="https://arxiv.org/abs/2509.12434" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DELTA-Code: How Does RL Unlock and Transfer New Programming Algorithms in LLMs?" [2025-09] [<a href="https://arxiv.org/abs/2509.21016" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Critique-Coder</strong>: "Critique-Coder: Enhancing Coder Models by Critique Reinforcement Learning" [2025-09] [<a href="https://arxiv.org/abs/2509.22824" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeRL+</strong>: "CodeRL+: Improving Code Generation via Reinforcement with Execution Semantics Alignment" [2025-10] [<a href="https://arxiv.org/abs/2510.18471" rel="nofollow">paper</a>]</p>
</li>
</ol>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">3. When Coding Meets Reasoning</h2><a id="user-content-3-when-coding-meets-reasoning" class="anchor" aria-label="Permalink: 3. When Coding Meets Reasoning" href="#3-when-coding-meets-reasoning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">3.1 Coding for Reasoning</h3><a id="user-content-31-coding-for-reasoning" class="anchor" aria-label="Permalink: 3.1 Coding for Reasoning" href="#31-coding-for-reasoning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>
<p dir="auto"><strong>PAL</strong>: "PAL: Program-aided Language Models" [2022-11] [ICML 2023] [<a href="https://arxiv.org/abs/2211.10435" rel="nofollow">paper</a>] [<a href="https://github.com/reasoning-machines/pal">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>PoT</strong>: "Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks" [2022-11] [TMLR 2023] [<a href="https://arxiv.org/abs/2211.12588" rel="nofollow">paper</a>] [<a href="https://github.com/wenhuchen/Program-of-Thoughts">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>PaD</strong>: "PaD: Program-aided Distillation Can Teach Small Models Reasoning Better than Chain-of-thought Fine-tuning" [2023-05] [NAACL 2024] [<a href="https://arxiv.org/abs/2305.13888" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CSV</strong>: "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification" [2023-08] [ICLR 2024] [<a href="https://arxiv.org/abs/2308.07921" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>MathCoder</strong>: "MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning" [2023-10] [ICLR 2024] [<a href="https://arxiv.org/abs/2310.03731" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CoC</strong>: "Chain of Code: Reasoning with a Language Model-Augmented Code Emulator" [2023-12] [ICML 2024] [<a href="https://arxiv.org/abs/2312.04474" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>EHRAgent</strong>: "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records" [2024-01] [EMNLP 2024] [<a href="https://arxiv.org/abs/2401.07128" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>MARIO</strong>: "MARIO: MAth Reasoning with code Interpreter Output -- A Reproducible Pipeline" [2024-01] [ACL 2024 Findings] [<a href="https://arxiv.org/abs/2401.08190" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs" [2024-01] [EMNLP 2024] [<a href="https://arxiv.org/abs/2401.10065" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>ReGAL</strong>: "ReGAL: Refactoring Programs to Discover Generalizable Abstractions" [2024-01] [ICML 2024] [<a href="https://arxiv.org/abs/2401.16467" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeAct</strong>: "Executable Code Actions Elicit Better LLM Agents" [2024-02] [ICML 2024] [<a href="https://arxiv.org/abs/2402.01030" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>MultiPoT</strong>: "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts" [2024-02] [EMNLP 2024] [<a href="https://arxiv.org/abs/2402.10691" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>HProPro</strong>: "Exploring Hybrid Question Answering via Program-based Prompting" [2024-02] [ACL 2024] [<a href="https://arxiv.org/abs/2402.10812" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>HTL</strong>: "How Do Humans Write Code? Large Models Do It the Same Way Too" [2024-02] [EMNLP 2024] [<a href="https://arxiv.org/abs/2402.15729" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>xSTREET</strong>: "Eliciting Better Multilingual Structured Reasoning from LLMs through Code" [2024-03] [ACL 2024] [<a href="https://arxiv.org/abs/2403.02567" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>FlowMind</strong>: "FlowMind: Automatic Workflow Generation with LLMs" [2024-03] [<a href="https://arxiv.org/abs/2404.13050" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Think-and-Execute</strong>: "Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models" [2024-04] [EMNLP 2024] [<a href="https://arxiv.org/abs/2404.02575" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CoRE</strong>: "CoRE: LLM as Interpreter for Natural Language Programming, Pseudo-Code Programming, and Flow Programming of AI Agents" [2024-05] [<a href="https://arxiv.org/abs/2405.06907" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>MuMath-Code</strong>: "MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning" [2024-05] [EMNLP 2024] [<a href="https://arxiv.org/abs/2405.07551" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>COGEX</strong>: "Learning to Reason via Program Generation, Emulation, and Search" [2024-05] [NeurIPS 2024] [<a href="https://arxiv.org/abs/2405.16337" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Arithmetic Reasoning with LLM: Prolog Generation &amp; Permutation" [2024-05] [<a href="https://arxiv.org/abs/2405.17893" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can LLMs Reason in the Wild with Programs?" [2024-06] [EMNLP 2024 Findings] [<a href="https://arxiv.org/abs/2406.13764" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>DotaMath</strong>: "DotaMath: Decomposition of Thought with Code Assistance and Self-correction for Mathematical Reasoning" [2024-07] [<a href="https://arxiv.org/abs/2407.04078" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CIBench</strong>: "CIBench: Evaluating Your LLMs with a Code Interpreter Plugin" [2024-07] [<a href="https://arxiv.org/abs/2407.10499" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>PyBench</strong>: "PyBench: Evaluating LLM Agent on various real-world coding tasks" [2024-07] [<a href="https://arxiv.org/abs/2407.16732" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>AdaCoder</strong>: "AdaCoder: Adaptive Prompt Compression for Programmatic Visual Question Answering" [2024-07] [<a href="https://arxiv.org/abs/2407.19410" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>PyramidCoder</strong>: "Pyramid Coder: Hierarchical Code Generator for Compositional Visual Question Answering" [2024-07] [<a href="https://arxiv.org/abs/2407.20563" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeGraph</strong>: "CodeGraph: Enhancing Graph Reasoning of LLMs with Code" [2024-08] [<a href="https://arxiv.org/abs/2408.13863" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SIaM</strong>: "SIaM: Self-Improving Code-Assisted Mathematical Reasoning of Large Language Models" [2024-08] [<a href="https://arxiv.org/abs/2408.15565" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodePlan</strong>: "CodePlan: Unlocking Reasoning Potential in Large Langauge Models by Scaling Code-form Planning" [2024-09] [ICLR 2025] [<a href="https://arxiv.org/abs/2409.12452" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>PoT</strong>: "Proof of Thought : Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning" [2024-09] [<a href="https://arxiv.org/abs/2409.17270" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>MetaMath</strong>: "MetaMath: Integrating Natural Language and Code for Enhanced Mathematical Reasoning in Large Language Models" [2024-09] [<a href="https://arxiv.org/abs/2409.19381" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"BabelBench: An Omni Benchmark for Code-Driven Analysis of Multimodal and Multistructured Data" [2024-10] [<a href="https://arxiv.org/abs/2410.00773" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeSteer</strong>: "Steering Large Language Models between Code Execution and Textual Reasoning" [2024-10] [ICLR 2025] [<a href="https://arxiv.org/abs/2410.03524" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>MathCoder2</strong>: "MathCoder2: Better Math Reasoning from Continued Pretraining on Model-translated Mathematical Code" [2024-10] [ICLR 2025] [<a href="https://arxiv.org/abs/2410.08196" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>LLMFP</strong>: "Planning Anything with Rigor: General-Purpose Zero-Shot Planning with LLM-based Formalized Programming" [2024-10] [<a href="https://arxiv.org/abs/2410.12112" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Prove</strong>: "Not All Votes Count! Programs as Verifiers Improve Self-Consistency of Language Models for Math Reasoning" [2024-10] [<a href="https://arxiv.org/abs/2410.12608" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>PROVE</strong>: "Trust but Verify: Programmatic VLM Evaluation in the Wild" [2024-10] [<a href="https://arxiv.org/abs/2410.13121" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>GeoCoder</strong>: "GeoCoder: Solving Geometry Problems by Generating Modular Code through Vision-Language Models" [2024-10] [<a href="https://arxiv.org/abs/2410.13510" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>ReasonAgain</strong>: "ReasonAgain: Using Extractable Symbolic Programs to Evaluate Mathematical Reasoning" [2024-10] [<a href="https://arxiv.org/abs/2410.19056" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>GFP</strong>: "Gap-Filling Prompting Enhances Code-Assisted Mathematical Reasoning" [2024-11] [<a href="https://arxiv.org/abs/2411.05407" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>UTMath</strong>: "UTMath: Math Evaluation with Unit Test via Reasoning-to-Coding Thoughts" [2024-11] [<a href="https://arxiv.org/abs/2411.07240" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CoCoP</strong>: "CoCoP: Enhancing Text Classification with LLM through Code Completion Prompt" [2024-11] [<a href="https://arxiv.org/abs/2411.08979" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>REPL-Plan</strong>: "Interactive and Expressive Code-Augmented Planning with Large Language Models" [2024-11] [<a href="https://arxiv.org/abs/2411.13826" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CrossPAL</strong>: "Empowering Multi-step Reasoning across Languages via Program-Aided Language Models" [2024-11] [EMNLP 2024] [<a href="https://aclanthology.org/2024.emnlp-main.678/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"From Code to Play: Benchmarking Program Search for Games Using Large Language Models" [2024-12] [<a href="https://arxiv.org/abs/2412.04057" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CoinMath</strong>: "CoinMath: Harnessing the Power of Coding Instruction for Math LLMs" [2024-12] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2412.11699" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>MultiLingPoT</strong>: "MultiLingPoT: Enhancing Mathematical Reasoning with Multilingual Program Fine-tuning" [2024-12] [<a href="https://arxiv.org/abs/2412.12609" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>ProgCo</strong>: "ProgCo: Program Helps Self-Correction of Large Language Models" [2025-01] [ACL 2025] [<a href="https://arxiv.org/abs/2501.01264" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>PIE</strong>: "Pseudocode-Injection Magic: Enabling LLMs to Tackle Graph Computational Tasks" [2025-01] [<a href="https://arxiv.org/abs/2501.13731" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>AutoCode4Math</strong>: "Learning Autonomous Code Integration for Math Language Models" [2025-02] [<a href="https://arxiv.org/abs/2502.00691" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>MIHTCCT</strong>: "MIH-TCCT: Mitigating Inconsistent Hallucinations in LLMs via Event-Driven Text-Code Cyclic Training" [2025-02] [<a href="https://arxiv.org/abs/2502.08904" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>ToolCoder</strong>: "ToolCoder: A Systematic Code-Empowered Tool Learning Framework for Large Language Models" [2025-02] [<a href="https://arxiv.org/abs/2502.11404" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>RM-PoT</strong>: "RM-PoT: Reformulating Mathematical Problems and Solving via Program of Thoughts" [2025-02] [<a href="https://arxiv.org/abs/2502.12589" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SBSC</strong>: "SBSC: Step-By-Step Coding for Improving Mathematical Olympiad Performance" [2025-02] [ICLR 2025] [<a href="https://arxiv.org/abs/2502.16666" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards Better Understanding of Program-of-Thought Reasoning in Cross-Lingual and Multilingual Environments" [2025-02] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2502.17956" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code to Think, Think to Code: A Survey on Code-Enhanced Reasoning and Reasoning-Driven Code Intelligence in LLMs" [2025-02] [<a href="https://arxiv.org/abs/2502.19411" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The KoLMogorov Test: Compression by Code Generation" [2025-03] [ICLR 2025] [<a href="https://arxiv.org/abs/2503.13992" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>MathCoder-VL</strong>: "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning" [2025-05] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2505.10557" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>R1-Code-Interpreter</strong>: "R1-Code-Interpreter: Training LLMs to Reason with Code via Supervised and Reinforcement Learning" [2025-05] [<a href="https://arxiv.org/abs/2505.21668" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards Effective Code-Integrated Reasoning" [2025-05] [<a href="https://arxiv.org/abs/2505.24480" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CoRT: Code-integrated Reasoning within Thinking" [2025-06] [<a href="https://arxiv.org/abs/2506.09820" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code Execution as Grounded Supervision for LLM Reasoning" [2025-06] [<a href="https://arxiv.org/abs/2506.10343" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>PBB</strong>: "Programming by Backprop: LLMs Acquire Reusable Algorithmic Abstractions During Code Training" [2025-06] [<a href="https://arxiv.org/abs/2506.18777" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"On Code-Induced Reasoning in LLMs" [2025-09] [<a href="https://arxiv.org/abs/2509.21499" rel="nofollow">paper</a>]</p>
</li>
</ol>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">3.2 Code Simulation</h3><a id="user-content-32-code-simulation" class="anchor" aria-label="Permalink: 3.2 Code Simulation" href="#32-code-simulation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Code Simulation Challenges for Large Language Models" [2024-01] [<a href="https://arxiv.org/abs/2401.09074" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeMind: A Framework to Challenge Large Language Models for Code Reasoning" [2024-02] [<a href="https://arxiv.org/abs/2402.09664" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Executing Natural Language-Described Algorithms with Large Language Models: An Investigation" [2024-02] [<a href="https://arxiv.org/abs/2403.00795" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can Language Models Pretend Solvers? Logic Code Simulation with LLMs" [2024-03] [<a href="https://arxiv.org/abs/2403.16097" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating Large Language Models with Runtime Behavior of Program Execution" [2024-03] [<a href="https://arxiv.org/abs/2403.16437" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"NExT: Teaching Large Language Models to Reason about Code Execution" [2024-04] [ICML 2024] [<a href="https://arxiv.org/abs/2404.14662" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SelfPiCo: Self-Guided Partial Code Execution with LLMs" [2024-07] [<a href="https://arxiv.org/abs/2407.16974" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Models as Code Executors: An Exploratory Study" [2024-10] [<a href="https://arxiv.org/abs/2410.06667" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"VISUALCODER: Guiding Large Language Models in Code Execution with Fine-grained Multimodal Chain-of-Thought Reasoning" [2024-10] [<a href="https://arxiv.org/abs/2410.23402" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CoCoNUT: Structural Code Understanding does not fall out of a tree" [2025-01] [<a href="https://arxiv.org/abs/2501.16456" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction" [2025-02] [ICML 2025] [<a href="https://arxiv.org/abs/2502.07316" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SURGE: On the Potential of Large Language Models as General-Purpose Surrogate Code Executors" [2025-02] [<a href="https://arxiv.org/abs/2502.11167" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"What I cannot execute, I do not understand: Training and Evaluating LLMs on Program Execution Traces" [2025-02] [<a href="https://arxiv.org/abs/2503.05703" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"L0-Reasoning Bench: Evaluating Procedural Correctness in Language Models via Simple Program Execution" [2025-03] [<a href="https://arxiv.org/abs/2503.22832" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"PLSemanticsBench: Large Language Models As Programming Language Interpreters" [2025-10] [<a href="https://arxiv.org/abs/2510.03415" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Metric Calculating Benchmark: Code-Verifiable Complicate Instruction Following Benchmark for Large Language Models" [2025-10] [<a href="https://arxiv.org/abs/2510.07892" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">3.3 Code Agents</h3><a id="user-content-33-code-agents" class="anchor" aria-label="Permalink: 3.3 Code Agents" href="#33-code-agents"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>
<p dir="auto"><strong>Self-collaboration</strong>: "Self-collaboration Code Generation via ChatGPT" [2023-04] [<a href="https://arxiv.org/abs/2304.07590" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>ChatDev</strong>: "Communicative Agents for Software Development" [2023-07] [<a href="https://arxiv.org/abs/2307.07924" rel="nofollow">paper</a>] [<a href="https://github.com/OpenBMB/ChatDev">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>MetaGPT</strong>: "MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework" [2023-08] [<a href="https://arxiv.org/abs/2308.00352" rel="nofollow">paper</a>] [<a href="https://github.com/geekan/MetaGPT">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeChain</strong>: "CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules" [2023-10] [ICLR 2024] [<a href="https://arxiv.org/abs/2310.08992" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeAgent</strong>: "CodeAgent: Enhancing Code Generation with Tool-Integrated Agent Systems for Real-World Repo-level Coding Challenges" [2024-01] [ACL 2024] [<a href="https://arxiv.org/abs/2401.07339" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CONLINE</strong>: "CoCoST: Automatic Complex Code Generation with Online Searching and Correctness Testing" [2024-03] [EMNLP 2024] [<a href="https://arxiv.org/abs/2403.13583" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>LCG</strong>: "When LLM-based Code Generation Meets the Software Development Process" [2024-03] [<a href="https://arxiv.org/abs/2403.15852" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>RepairAgent</strong>: "RepairAgent: An Autonomous, LLM-Based Agent for Program Repair" [2024-03] [<a href="https://arxiv.org/abs/2403.17134" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>MAGIS:</strong>: "MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution" [2024-03] [<a href="https://arxiv.org/abs/2403.17927" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SoA</strong>: "Self-Organized Agents: A LLM Multi-Agent Framework toward Ultra Large-Scale Code Generation and Optimization" [2024-04] [<a href="https://arxiv.org/abs/2404.02183" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>AutoCodeRover</strong>: "AutoCodeRover: Autonomous Program Improvement" [2024-04] [<a href="https://arxiv.org/abs/2404.05427" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SWE-agent</strong>: "SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering" [2024-05] [<a href="https://arxiv.org/abs/2405.15793" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>MapCoder</strong>: "MapCoder: Multi-Agent Code Generation for Competitive Problem Solving" [2024-05] [ACL 2024] [<a href="https://arxiv.org/abs/2405.11403" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Fight Fire with Fire: How Much Can We Trust ChatGPT on Source Code-Related Tasks?" [2024-05] [<a href="https://arxiv.org/abs/2405.12641" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>FunCoder</strong>: "Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in Code Generation" [2024-05] [<a href="https://arxiv.org/abs/2405.20092" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CTC</strong>: "Multi-Agent Software Development through Cross-Team Collaboration" [2024-06] [<a href="https://arxiv.org/abs/2406.08979" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>MASAI</strong>: "MASAI: Modular Architecture for Software-engineering AI Agents" [2024-06] [<a href="https://arxiv.org/abs/2406.11638" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>AgileCoder</strong>: "AgileCoder: Dynamic Collaborative Agents for Software Development based on Agile Methodology" [2024-06] [<a href="https://arxiv.org/abs/2406.11912" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeNav</strong>: "CodeNav: Beyond tool-use to using real-world codebases with LLM agents" [2024-06] [<a href="https://arxiv.org/abs/2406.12276" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>INDICT</strong>: "INDICT: Code Generation with Internal Dialogues of Critiques for Both Security and Helpfulness" [2024-06] [<a href="https://arxiv.org/abs/2407.02518" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>AppWorld</strong>: "AppWorld: A Controllable World of Apps and People for Benchmarking Interactive Coding Agents" [2024-07] [<a href="https://arxiv.org/abs/2407.18901" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CortexCompile</strong>: "CortexCompile: Harnessing Cortical-Inspired Architectures for Enhanced Multi-Agent NLP Code Synthesis" [2024-08] [<a href="https://arxiv.org/abs/2409.02938" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>DEI</strong>: "Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents" [2024-08] [ICLR 2025] [<a href="https://arxiv.org/abs/2408.07060" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Survey</strong>: "Large Language Model-Based Agents for Software Engineering: A Survey" [2024-09] [<a href="https://arxiv.org/abs/2409.02977" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>PairCoder</strong>: "A Pair Programming Framework for Code Generation via Multi-Plan Exploration and Feedback-Driven Refinement" [2024-09] [ASE 2024] [<a href="https://arxiv.org/abs/2409.05001" rel="nofollow">paper</a>] [<a href="https://github.com/nju-websoft/PairCoder">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>AutoSafeCoder</strong>: "AutoSafeCoder: A Multi-Agent Framework for Securing LLM Code Generation through Static Analysis and Fuzz Testing" [2024-09] [<a href="https://arxiv.org/abs/2409.10737" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SuperCoder2.0</strong>: "SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer" [2024-09] [<a href="https://arxiv.org/abs/2409.11190" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Survey</strong>: "Agents in Software Engineering: Survey, Landscape, and Vision" [2024-09] [<a href="https://arxiv.org/abs/2409.09030" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>MOSS</strong>: "MOSS: Enabling Code-Driven Evolution and Context Management for AI Agents" [2024-09] [<a href="https://arxiv.org/abs/2409.16120" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>HyperAgent</strong>: "HyperAgent: Generalist Software Engineering Agents to Solve Coding Tasks at Scale" [2024-09] [<a href="https://arxiv.org/abs/2409.16299" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Compositional Hardness of Code in Large Language Models -- A Probabilistic Perspective" [2024-09] [<a href="https://arxiv.org/abs/2409.18028" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>RGD</strong>: "RGD: Multi-LLM Based Agent Debugger via Refinement and Generation Guidance" [2024-10] [<a href="https://arxiv.org/abs/2410.01242" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Seeker</strong>: "Seeker: Enhancing Exception Handling in Code with LLM-based Multi-Agent Approach" [2024-10] [<a href="https://arxiv.org/abs/2410.06949" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>REDO</strong>: "REDO: Execution-Free Runtime Error Detection for COding Agents" [2024-10] [<a href="https://arxiv.org/abs/2410.09117" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating Software Development Agents: Patch Patterns, Code Quality, and Issue Complexity in Real-World GitHub Scenarios" [2024-10] [<a href="https://arxiv.org/abs/2410.12468" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>EvoMAC</strong>: "Self-Evolving Multi-Agent Collaboration Networks for Software Development" [2024-10] [ICLR 2025] [<a href="https://arxiv.org/abs/2410.16946" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>VisionCoder</strong>: "VisionCoder: Empowering Multi-Agent Auto-Programming for Image Processing with Hybrid LLMs" [2024-10] [<a href="https://arxiv.org/abs/2410.19245" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>AutoKaggle</strong>: "AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions" [2024-10] [<a href="https://arxiv.org/abs/2410.20424" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Watson</strong>: "Watson: A Cognitive Observability Framework for the Reasoning of Foundation Model-Powered Agents" [2024-11] [<a href="https://arxiv.org/abs/2411.03455" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeTree</strong>: "CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models" [2024-11] [<a href="https://arxiv.org/abs/2411.04329" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>EvoCoder</strong>: "LLMs as Continuous Learners: Improving the Reproduction of Defective Code in Software Issues" [2024-11] [<a href="https://arxiv.org/abs/2411.13941" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>AEGIS</strong>: "AEGIS: An Agent-based Framework for General Bug Reproduction from Issue Descriptions" [2024-11] [<a href="https://arxiv.org/abs/2411.18015" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>ExecutionAgent</strong>: "You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects" [2024-12] [<a href="https://arxiv.org/abs/2412.10133" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>GHIssueMarket</strong>: "GHIssuemarket: A Sandbox Environment for SWE-Agents Economic Experimentation" [2024-12] [<a href="https://arxiv.org/abs/2412.11722" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SWE-Gym</strong>: "Training Software Engineering Agents and Verifiers with SWE-Gym" [2024-12] [ICML 2025] [<a href="https://arxiv.org/abs/2412.21139" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SWE-Fixer</strong>: "SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution" [2025-01] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2501.05040" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeCoR</strong>: "CodeCoR: An LLM-Based Self-Reflective Multi-Agent Framework for Code Generation" [2025-01] [<a href="https://arxiv.org/abs/2501.07811" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>QualityFlow</strong>: "QualityFlow: An Agentic Workflow for Program Synthesis Controlled by LLM Quality Checks" [2025-01] [<a href="https://arxiv.org/abs/2501.17167" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Cogito</strong>: "Cogito, ergo sum: A Neurobiologically-Inspired Cognition-Memory-Growth System for Code Generation" [2025-01] [<a href="https://arxiv.org/abs/2501.18653" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>OrcaLoca</strong>: "OrcaLoca: An LLM Agent Framework for Software Issue Localization" [2025-02] [ICML 2025] [<a href="https://arxiv.org/abs/2502.00350" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>BRT Agent</strong>: "Agentic Bug Reproduction for Effective Automated Program Repair at Google" [2025-02] [<a href="https://arxiv.org/abs/2502.01821" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeSim</strong>: "CODESIM: Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debugging" [2025-02] [<a href="https://arxiv.org/abs/2502.05664" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SyncMind</strong>: "SyncMind: Measuring Agent Out-of-Sync Recovery in Collaborative Software Engineering" [2025-02] [ICML 2025] [<a href="https://arxiv.org/abs/2502.06994" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SoRFT</strong>: "SoRFT: Issue Resolving with Subtask-oriented Reinforced Fine-Tuning" [2025-02] [<a href="https://arxiv.org/abs/2502.20127" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Is Multi-Agent Debate (MAD) the Silver Bullet? An Empirical Analysis of MAD in Code Summarization and Translation" [2025-03] [<a href="https://arxiv.org/abs/2503.12029" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>DARS</strong>: "DARS: Dynamic Action Re-Sampling to Enhance Coding Agent Performance by Adaptive Tree Traversal" [2025-03] [ACL 2025] [<a href="https://arxiv.org/abs/2503.14269" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SEAlign</strong>: "SEAlign: Alignment Training for Software Engineering Agent" [2025-03] [<a href="https://arxiv.org/abs/2503.18455" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SWE-SynInfer</strong>: "Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute" [2025-03] [<a href="https://arxiv.org/abs/2503.23803" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>AdaCoder</strong>: "AdaCoder: An Adaptive Planning and Multi-Agent Framework for Function-Level Code Generation" [2025-04] [<a href="https://arxiv.org/abs/2504.04220" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SICA</strong>: "A Self-Improving Coding Agent" [2025-04] [<a href="https://arxiv.org/abs/2504.15228" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SWE-smith</strong>: "SWE-smith: Scaling Data for Software Engineering Agents" [2025-04] [<a href="https://arxiv.org/abs/2504.21798" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing LLM Code Generation: A Systematic Evaluation of Multi-Agent Collaboration and Runtime Debugging for Improved Accuracy, Reliability, and Latency" [2025-05] [<a href="https://arxiv.org/abs/2505.02133" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SEW</strong>: "SEW: Self-Evolving Agentic Workflows for Automated Code Generation" [2025-05] [<a href="https://arxiv.org/abs/2505.18646" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>RepoMaster</strong>: "RepoMaster: Autonomous Exploration and Understanding of GitHub Repositories for Complex Task Solving" [2025-05] [<a href="https://arxiv.org/abs/2505.21577" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Code Researcher</strong>: "Code Researcher: Deep Research Agent for Large Systems Code and Commit History" [2025-05] [<a href="https://arxiv.org/abs/2506.11060" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and Improve" [2025-05] [<a href="https://arxiv.org/abs/2505.23946" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"EvoGit: Decentralized Code Evolution via Git-Based Multi-Agent Collaboration" [2025-06] [<a href="https://arxiv.org/abs/2506.02049" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SWE-Factory</strong>: "SWE-Factory: Your Automated Factory for Issue Resolution Training Data and Evaluation Benchmarks" [2025-06] [<a href="https://arxiv.org/abs/2506.10954" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Agent-RLVR</strong>: "Agent-RLVR: Training Software Engineering Agents via Guidance and Environment Rewards" [2025-06] [<a href="https://arxiv.org/abs/2506.11425" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>AlphaEvolve</strong>: "AlphaEvolve: A coding agent for scientific and algorithmic discovery" [2025-06] [<a href="https://arxiv.org/abs/2506.13131" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>USEagent</strong>: "Unified Software Engineering agent as AI Software Engineer" [2025-06] [<a href="https://arxiv.org/abs/2506.14683" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SemAgent</strong>: "SemAgent: A Semantics Aware Program Repair Agent" [2025-06] [<a href="https://arxiv.org/abs/2506.16650" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Trae Agent</strong>: "Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling" [2025-07] [<a href="https://arxiv.org/abs/2507.23370" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Nemotron-CORTEXA: Enhancing LLM Agents for Software Engineering Tasks via Improved Localization and Solution Diversity" [2025-07] [ICML 2025] [<a href="https://icml.cc/virtual/2025/poster/44274" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>DebateCoder</strong>: "DebateCoder: Towards Collective Intelligence of LLMs via Test Case Driven LLM Debate for Code Generation" [2025-07] [ACL 2025] [<a href="https://aclanthology.org/2025.acl-long.589/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"GitTaskBench: A Benchmark for Code Agents Solving Real-World Tasks Through Code Repository Leveraging" [2025-08] [<a href="https://arxiv.org/abs/2508.18993" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>MapCoder-Lite</strong>: "MapCoder-Lite: Squeezing Multi-Agent Coding into a Single Small LLM" [2025-09] [<a href="https://arxiv.org/abs/2509.17489" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Devstral</strong>: "Devstral: Fine-tuning Language Models for Coding Agent Applications" [2025-09] [<a href="https://arxiv.org/abs/2509.25193" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Lita</strong>: "Lita: Light Agent Uncovers the Agentic Coding Capabilities of LLMs" [2025-09] [<a href="https://arxiv.org/abs/2509.25873" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>Kimi-Dev</strong>: "Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents" [2025-09] [<a href="https://arxiv.org/abs/2509.23045" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>VeriGuard</strong>: "VeriGuard: Enhancing LLM Agent Safety via Verified Code Generation" [2025-10] [<a href="https://arxiv.org/abs/2510.05156" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>KAT-Coder</strong>: "KAT-Coder Technical Report" [2025-10] [<a href="https://arxiv.org/abs/2510.18779" rel="nofollow">paper</a>]</p>
</li>
</ol>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">3.4 Interactive Coding</h3><a id="user-content-34-interactive-coding" class="anchor" aria-label="Permalink: 3.4 Interactive Coding" href="#34-interactive-coding"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Interactive Program Synthesis" [2017-03] [<a href="https://arxiv.org/abs/1703.03539" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Question selection for interactive program synthesis" [2020-06] [PLDI 2020] [<a href="https://dl.acm.org/doi/10.1145/3385412.3386025" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Interactive Code Generation via Test-Driven User-Intent Formalization" [2022-08] [<a href="https://arxiv.org/abs/2208.05950" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Improving Code Generation by Training with Natural Language Feedback" [2023-03] [TMLR] [<a href="https://arxiv.org/abs/2303.16749" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Self-Refine: Iterative Refinement with Self-Feedback" [2023-03] [NeurIPS 2023] [<a href="https://arxiv.org/abs/2303.17651" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Teaching Large Language Models to Self-Debug" [2023-04] [<a href="https://arxiv.org/abs/2304.05128" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Self-Edit: Fault-Aware Code Editor for Code Generation" [2023-05] [ACL 2023] [<a href="https://arxiv.org/abs/2305.04087" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LeTI: Learning to Generate from Textual Interactions" [2023-05] [<a href="https://arxiv.org/abs/2305.10314" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Is Self-Repair a Silver Bullet for Code Generation?" [2023-06] [ICLR 2024] [<a href="https://arxiv.org/abs/2306.09896" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback" [2023-06] [NeurIPS 2023] [<a href="https://arxiv.org/abs/2306.14898" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"INTERVENOR: Prompting the Coding Ability of Large Language Models with the Interactive Chain of Repair" [2023-11] [ACL 2024 Findings] [<a href="https://arxiv.org/abs/2311.09868" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement" [2024-02] [ACL 2024 Findings] [<a href="https://arxiv.org/abs/2402.14658" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Iterative Refinement of Project-Level Code Context for Precise Code Generation with Compiler Feedback" [2024-03] [ACL 2024 Findings] [<a href="https://arxiv.org/abs/2403.16792" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CYCLE: Learning to Self-Refine the Code Generation" [2024-03] [<a href="https://arxiv.org/abs/2403.18746" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM-based Test-driven Interactive Code Generation: User Study and Empirical Evaluation" [2024-04] [<a href="https://arxiv.org/abs/2404.10100" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SOAP: Enhancing Efficiency of Generated Code via Self-Optimization" [2024-05] [<a href="https://arxiv.org/abs/2405.15189" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code Repair with LLMs gives an Exploration-Exploitation Tradeoff" [2024-05] [NeurIPS 2024] [<a href="https://arxiv.org/abs/2405.17503" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ReflectionCoder: Learning from Reflection Sequence for Enhanced One-off Code Generation" [2024-05] [ACL 2025] [<a href="https://arxiv.org/abs/2405.17057" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Training LLMs to Better Self-Debug and Explain Code" [2024-05] [NeurIPS 2024] [<a href="https://arxiv.org/abs/2405.18649" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Requirements are All You Need: From Requirements to Code with LLMs" [2024-06] [<a href="https://arxiv.org/abs/2406.10101" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"I Need Help! Evaluating LLM's Ability to Ask for Users' Support: A Case Study on Text-to-SQL Generation" [2024-07] [EMNLP 2024] [<a href="https://arxiv.org/abs/2407.14767" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Empirical Study on Self-correcting Large Language Models for Data Science Code Generation" [2024-08] [<a href="https://arxiv.org/abs/2408.15658" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RethinkMCTS: Refining Erroneous Thoughts in Monte Carlo Tree Search for Code Generation" [2024-09] [<a href="https://arxiv.org/abs/2409.09584" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"From Code to Correctness: Closing the Last Mile of Code Generation with Hierarchical Debugging" [2024-10] [<a href="https://arxiv.org/abs/2410.01215" rel="nofollow">paper</a>] [<a href="https://github.com/YerbaPage/MGDebugger">repo</a>]</p>
</li>
<li>
<p dir="auto">"What Makes Large Language Models Reason in (Multi-Turn) Code Generation?" [2024-10] [ICLR 2025] [<a href="https://arxiv.org/abs/2410.08105" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The First Prompt Counts the Most! An Evaluation of Large Language Models on Iterative Example-based Code Generation" [2024-11] [<a href="https://arxiv.org/abs/2411.06774" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Planning-Driven Programming: A Large Language Model Programming Workflow" [2024-11] [ACL 2025] [<a href="https://arxiv.org/abs/2411.14503" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ConAIR:Consistency-Augmented Iterative Interaction Framework to Enhance the Reliability of Code Generation" [2024-11] [<a href="https://arxiv.org/abs/2411.15587" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Socratic Human Feedback (SoHF): Expert Steering Strategies for LLM Code Generation" [2024-11] [EMNLP 2024 Findings] [<a href="https://aclanthology.org/2024.findings-emnlp.908/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"PerfCodeGen: Improving Performance of LLM Generated Code with Execution Feedback" [2024-11] [<a href="https://arxiv.org/abs/2412.03578" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"GenX: Mastering Code and Test Generation with Execution Feedback" [2024-12] [<a href="https://arxiv.org/abs/2412.13464" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Helping LLMs Improve Code Generation Using Feedback from Testing and Static Analysis" [2024-12] [<a href="https://arxiv.org/abs/2412.14841" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Outcome-Refining Process Supervision for Code Generation" [2024-12] [<a href="https://arxiv.org/abs/2412.15118" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Tree-of-Code: A Tree-Structured Exploring Framework for End-to-End Code Generation and Execution in Complex Task Handling" [2024-12] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2412.15305" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Dynamic Scaling of Unit Tests for Code Reward Modeling" [2025-01] [ACL 2025] [<a href="https://arxiv.org/abs/2501.01054" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Revisit Self-Debugging with Self-Generated Tests for Code Generation" [2025-01] [ACL 2025] [<a href="https://arxiv.org/abs/2501.12793" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Learning to Generate Unit Tests for Automated Debugging" [2025-02] [<a href="https://arxiv.org/abs/2502.01619" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Model Guided Self-Debugging Code Generation" [2025-02] [<a href="https://arxiv.org/abs/2502.02928" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"On Iterative Evaluation and Enhancement of Code Quality Using GPT-4o" [2025-02] [<a href="https://arxiv.org/abs/2502.07399" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Intention is All You Need: Refining Your Code from Your Intention" [2025-02] [<a href="https://arxiv.org/abs/2502.08172" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RefineCoder: Iterative Improving of Large Language Models via Adaptive Critique Refinement for Code Generation" [2025-02] [<a href="https://arxiv.org/abs/2502.09183" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"VisPath: Automated Visualization Code Synthesis via Multi-Path Reasoning and Feedback-Driven Optimization" [2025-02] [<a href="https://arxiv.org/abs/2502.11140" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"S*: Test Time Scaling for Code Generation" [2025-02] [<a href="https://arxiv.org/abs/2502.14382" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"When Benchmarks Talk: Re-Evaluating Code LLMs with Interactive Feedback" [2025-02] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2502.18413" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM4EFFI: Leveraging Large Language Models to Enhance Code Efficiency and Correctness" [2025-02] [<a href="https://arxiv.org/abs/2502.18489" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Multi-Turn Code Generation Through Single-Step Rewards" [2025-02] [ICML 2025] [<a href="https://arxiv.org/abs/2502.20380" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ConvCodeWorld: Benchmarking Conversational Code Generation in Reproducible Feedback Environments" [2025-02] [ICLR 2025] [<a href="https://arxiv.org/abs/2502.19852" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"IterPref: Focal Preference Learning for Code Generation via Iterative Debugging" [2025-03] [<a href="https://arxiv.org/abs/2503.02783" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"debug-gym: A Text-Based Environment for Interactive Debugging" [2025-03] [<a href="https://arxiv.org/abs/2503.21557" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeIF-Bench: Evaluating Instruction-Following Capabilities of Large Language Models in Interactive Code Generation" [2025-03] [<a href="https://arxiv.org/abs/2503.22688" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeFlowBench: A Multi-turn, Iterative Benchmark for Complex Code Generation" [2025-04] [<a href="https://arxiv.org/abs/2504.21751" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Use Property-Based Testing to Bridge LLM Code Generation and Validation" [2025-06] [<a href="https://arxiv.org/abs/2506.18315" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeAssistBench (CAB): Dataset &amp; Benchmarking for Multi-turn Chat-Based Code Assistance" [2025-07] [<a href="https://arxiv.org/abs/2507.10646" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SR-Eval: Evaluating LLMs on Code Generation under Stepwise Requirement Refinement" [2025-09] [<a href="https://arxiv.org/abs/2509.18808" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Benchmarking Correctness and Security in Multi-Turn Code Generation" [2025-10] [<a href="https://arxiv.org/abs/2510.13859" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">3.5 Frontend Navigation</h3><a id="user-content-35-frontend-navigation" class="anchor" aria-label="Permalink: 3.5 Frontend Navigation" href="#35-frontend-navigation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding" [2021-10] [ACL 2022] [<a href="https://arxiv.org/abs/2110.08518" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WebKE: Knowledge Extraction from Semi-structured Web with Pre-trained Markup Language Model" [2021-10] [CIKM 2021] [<a href="https://dl.acm.org/doi/abs/10.1145/3459637.3482491" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WebGPT: Browser-assisted question-answering with human feedback" [2021-12] [<a href="https://arxiv.org/abs/2112.09332" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CM3: A Causal Masked Multimodal Model of the Internet" [2022-01] [<a href="https://arxiv.org/abs/2201.07520" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DOM-LM: Learning Generalizable Representations for HTML Documents" [2022-01] [<a href="https://arxiv.org/abs/2201.10608" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WebFormer: The Web-page Transformer for Structure Information Extraction" [2022-02] [WWW 2022] [<a href="https://arxiv.org/abs/2202.00217" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Dataset for Interactive Vision-Language Navigation with Unknown Command Feasibility" [2022-02] [ECCV 2022] [<a href="https://arxiv.org/abs/2202.02312" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents" [2022-07] [NeurIPS 2022] [<a href="https://arxiv.org/abs/2207.01206" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding" [2022-10] [ICML 2023] [<a href="https://arxiv.org/abs/2210.03347" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Understanding HTML with Large Language Models" [2022-10] [EMNLP 2023 findings] [<a href="https://arxiv.org/abs/2210.03945" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics" [2023-01] [CHI 2023] [<a href="https://arxiv.org/abs/2301.13280" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Mind2Web: Towards a Generalist Agent for the Web" [2023-06] [NeurIPS 2023] [<a href="https://arxiv.org/abs/2306.06070" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis", [2023-07] [ICLR 2024] [<a href="https://arxiv.org/abs/2307.12856" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WebArena: A Realistic Web Environment for Building Autonomous Agents" [2023-07] [<a href="https://arxiv.org/abs/2307.13854" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CogAgent: A Visual Language Model for GUI Agents" [2023-12] [<a href="https://arxiv.org/abs/2312.08914" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"GPT-4V(ision) is a Generalist Web Agent, if Grounded" [2024-01] [<a href="https://arxiv.org/abs/2401.01614" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models" [2024-01] [<a href="https://arxiv.org/abs/2401.13919" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WebLINX: Real-World Website Navigation with Multi-Turn Dialogue" [2024-02] [<a href="https://arxiv.org/abs/2402.05930" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web" [2024-02] [<a href="https://arxiv.org/abs/2402.17553" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent" [2024-04] [<a href="https://arxiv.org/abs/2404.03648" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents" [2024-04] [<a href="https://arxiv.org/abs/2404.05902" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AutoCrawler: A Progressive Understanding Web Agent for Web Crawler Generation" [2024-04] [<a href="https://arxiv.org/abs/2404.12753" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"GUICourse: From General Vision Language Models to Versatile GUI Agents" [2024-06] [<a href="https://arxiv.org/abs/2406.11317" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"NaviQAte: Functionality-Guided Web Application Navigation" [2024-09] [<a href="https://arxiv.org/abs/2409.10741" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding" [2024-09] [<a href="https://arxiv.org/abs/2409.14818" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Multimodal Auto Validation For Self-Refinement in Web Agents" [2024-10] [<a href="https://arxiv.org/abs/2410.00689" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents" [2024-10] [<a href="https://arxiv.org/abs/2410.05243" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation" [2024-10] [<a href="https://arxiv.org/abs/2410.13232" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Harnessing Webpage UIs for Text-Rich Visual Understanding" [2024-10] [<a href="https://arxiv.org/abs/2410.13824" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents" [2024-10] [<a href="https://arxiv.org/abs/2410.13825" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Beyond Browsing: API-Based Web Agents" [2024-10] [<a href="https://arxiv.org/abs/2410.16464" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Models Empowered Personalized Web Agents" [2024-10] [<a href="https://arxiv.org/abs/2410.17236" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AdvWeb: Controllable Black-box Attacks on VLM-powered Web Agents" [2024-10] [<a href="https://arxiv.org/abs/2410.17401" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents" [2024-10] [<a href="https://arxiv.org/abs/2410.22552" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"OS-ATLAS: A Foundation Action Model for Generalist GUI Agents" [2024-10] [<a href="https://arxiv.org/abs/2410.23218" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"From Context to Action: Analysis of the Impact of State Representation and Context on the Generalization of Multi-Turn Web Navigation Agents" [2024-10] [<a href="https://arxiv.org/abs/2410.23555" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AutoGLM: Autonomous Foundation Agents for GUIs" [2024-10] [<a href="https://arxiv.org/abs/2411.00820" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning" [2024-11] [<a href="https://arxiv.org/abs/2411.02337" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Dawn of GUI Agent: A Preliminary Case Study with Claude 3.5 Computer Use" [2024-11] [<a href="https://arxiv.org/abs/2411.10323" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ScribeAgent: Towards Specialized Web Agents Using Production-Scale Workflow Data" [2024-11] [<a href="https://arxiv.org/abs/2411.15004" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ShowUI: One Vision-Language-Action Model for GUI Visual Agent" [2024-11] [<a href="https://arxiv.org/abs/2411.17465" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Model-Brained GUI Agents: A Survey" [2024-11] [<a href="https://arxiv.org/abs/2411.18279" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Free your mouse! Command Large Language Models to Generate Code to Format Word Documents" [2024-11] [EMNLP 2024] [<a href="https://aclanthology.org/2024.emnlp-main.902/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Aguvis: Unified Pure Vision Agents for Autonomous GUI Interaction" [2024-12] [<a href="https://arxiv.org/abs/2412.04454" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Falcon-UI: Understanding GUI Before Following User Instructions" [2024-12] [<a href="https://arxiv.org/abs/2412.09362" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WEPO: Web Element Preference Optimization for LLM-based Web Navigation" [2024-12] [<a href="https://arxiv.org/abs/2412.10742" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AutoDroid-V2: Boosting SLM-based GUI Agents via Code Generation" [2024-12] [<a href="https://arxiv.org/abs/2412.18116" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Beyond Pass or Fail: A Multi-dimensional Benchmark for Mobile UI Navigation" [2025-01] [<a href="https://arxiv.org/abs/2501.02863" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WebWalker: Benchmarking LLMs in Web Traversal" [2025-01] [<a href="https://arxiv.org/abs/2501.07572" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"GUI-Bee: Align GUI Action Grounding to Novel Environments via Autonomous Exploration" [2025-01] [<a href="https://arxiv.org/abs/2501.13896" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"UI-TARS: Pioneering Automated GUI Interaction with Native Agents" [2025-01] [<a href="https://arxiv.org/abs/2501.12326" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Smoothing Grounding and Reasoning for MLLM-Powered GUI Agents with Query-Oriented Pivot Tasks" [2025-03] [<a href="https://arxiv.org/abs/2503.00401" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web Tasks" [2025-06] [<a href="https://arxiv.org/abs/2506.01952" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"UI-Venus Technical Report: Building High-performance UI Agents with RFT" [2025-08] [<a href="https://arxiv.org/abs/2508.10833" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Mano Report" [2025-09] [<a href="https://arxiv.org/abs/2509.17336" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">4. Code LLM for Low-Resource, Low-Level, and Domain-Specific Languages</h2><a id="user-content-4-code-llm-for-low-resource-low-level-and-domain-specific-languages" class="anchor" aria-label="Permalink: 4. Code LLM for Low-Resource, Low-Level, and Domain-Specific Languages" href="#4-code-llm-for-low-resource-low-level-and-domain-specific-languages"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">[<strong>Ruby</strong>] "On the Transferability of Pre-trained Language Models for Low-Resource Programming Languages" [2022-04] [ICPC 2022] [<a href="https://arxiv.org/abs/2204.09653" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "Benchmarking Large Language Models for Automated Verilog RTL Code Generation" [2022-12] [DATE 2023] [<a href="https://arxiv.org/abs/2212.11140" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>OCL</strong>] "On Codex Prompt Engineering for OCL Generation: An Empirical Study" [2023-03] [MSR 2023] [<a href="https://arxiv.org/abs/2303.16244" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Ansible-YAML</strong>] "Automated Code generation for Information Technology Tasks in YAML through Large Language Models" [2023-05] [DAC 2023] [<a href="https://arxiv.org/abs/2305.02783" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Hansl</strong>] "The potential of LLMs for coding with low-resource and domain-specific programming languages" [2023-07] [<a href="https://arxiv.org/abs/2307.13018" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "VeriGen: A Large Language Model for Verilog Code Generation" [2023-07] [<a href="https://arxiv.org/abs/2308.00708" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "RTLLM: An Open-Source Benchmark for Design RTL Generation with Large Language Model" [2023-08] [<a href="https://arxiv.org/abs/2308.05345" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Racket, OCaml, Lua, R, Julia</strong>] "Knowledge Transfer from High-Resource to Low-Resource Programming Languages for Code LLMs" [2023-08] [<a href="https://arxiv.org/abs/2308.09895" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "VerilogEval: Evaluating Large Language Models for Verilog Code Generation" [2023-09] [ICCAD 2023] [<a href="https://arxiv.org/abs/2309.07544" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "RTLFixer: Automatically Fixing RTL Syntax Errors with Large Language Models" [2023-11] [<a href="https://arxiv.org/abs/2311.16543" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "Advanced Large Language Model (LLM)-Driven Verilog Development: Enhancing Power, Performance, and Area Optimization in Code Synthesis" [2023-12] [<a href="https://arxiv.org/abs/2312.01022" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "RTLCoder: Outperforming GPT-3.5 in Design RTL Generation with Our Open-Source Dataset and Lightweight Solution" [2023-12] [<a href="https://arxiv.org/abs/2312.08617" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "BetterV: Controlled Verilog Generation with Discriminative Guidance" [2024-02] [ICML 2024] [<a href="https://arxiv.org/abs/2402.03375" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>R</strong>] "Empirical Studies of Parameter Efficient Methods for Large Language Models of Code and Knowledge Transfer to R" [2024-03] [<a href="https://arxiv.org/abs/2405.01553" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Haskell</strong>] "Investigating the Performance of Language Models for Completing Code in Functional Programming Languages: a Haskell Case Study" [2024-03] [<a href="https://arxiv.org/abs/2403.15185" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "A Multi-Expert Large Language Model Architecture for Verilog Code Generation" [2024-04] [<a href="https://arxiv.org/abs/2404.08029" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "CreativEval: Evaluating Creativity of LLM-Based Hardware Code Generation" [2024-04] [<a href="https://arxiv.org/abs/2404.08806" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Alloy</strong>] "An Empirical Evaluation of Pre-trained Large Language Models for Repairing Declarative Formal Specifications" [2024-04] [<a href="https://arxiv.org/abs/2404.11050" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "Evaluating LLMs for Hardware Design and Test" [2024-04] [<a href="https://arxiv.org/abs/2405.02326" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Kotlin, Swift, and Rust</strong>] "Software Vulnerability Prediction in Low-Resource Languages: An Empirical Study of CodeBERT and ChatGPT" [2024-04] [<a href="https://arxiv.org/abs/2404.17110" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "MEIC: Re-thinking RTL Debug Automation using LLMs" [2024-05] [<a href="https://arxiv.org/abs/2405.06840" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Bash</strong>] "Tackling Execution-Based Evaluation for NL2Bash" [2024-05] [<a href="https://arxiv.org/abs/2405.06807" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Fortran, Julia, Matlab, R, Rust</strong>] "Evaluating AI-generated code for C++, Fortran, Go, Java, Julia, Matlab, Python, R, and Rust" [2024-05] [<a href="https://arxiv.org/abs/2405.13101" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>OpenAPI</strong>] "Optimizing Large Language Models for OpenAPI Code Completion" [2024-05] [<a href="https://arxiv.org/abs/2405.15729" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Kotlin</strong>] "Kotlin ML Pack: Technical Report" [2024-05] [<a href="https://arxiv.org/abs/2405.19250" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>UCLID5</strong>] "Synthetic Programming Elicitation for Text-to-Code in Very Low-Resource Programming and Formal Languages" [2024-06] [NeurIPS 2024] [<a href="https://arxiv.org/abs/2406.03636" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "VerilogReader: LLM-Aided Hardware Test Generation" [2024-06] [<a href="https://arxiv.org/abs/2406.04373" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Benchmarking Generative Models on Computational Thinking Tests in Elementary Visual Programming" [2024-06] [<a href="https://arxiv.org/abs/2406.09891" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Logo</strong>] "Program Synthesis Benchmark for Visual Programming in XLogoOnline Environment" [2024-06] [ACL 2025] [<a href="https://arxiv.org/abs/2406.11334" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Ansible YAML, Bash</strong>] "DocCGen: Document-based Controlled Code Generation" [2024-06] [EMNLP 2024] [<a href="https://arxiv.org/abs/2406.11925" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Qiskit</strong>] "Qiskit HumanEval: An Evaluation Benchmark For Quantum Code Generative Models" [2024-06] [<a href="https://arxiv.org/abs/2406.14712" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Perl, Golang, Swift</strong>] "DistiLRR: Transferring Code Repair for Low-Resource Programming Languages" [2024-06] [<a href="https://arxiv.org/abs/2406.14867" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "AssertionBench: A Benchmark to Evaluate Large-Language Models for Assertion Generation" [2024-06] [<a href="https://arxiv.org/abs/2406.18627" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Comparative Study of DSL Code Generation: Fine-Tuning vs. Optimized Retrieval Augmentation" [2024-07] [<a href="https://arxiv.org/abs/2407.02742" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Json, XLM, YAML</strong>] "ConCodeEval: Evaluating Large Language Models for Code Constraints in Domain-Specific Languages" [2024-07] [<a href="https://arxiv.org/abs/2407.03387" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "AutoBench: Automatic Testbench Generation and Evaluation Using LLMs for HDL Design" [2024-07] [<a href="https://arxiv.org/abs/2407.03891" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "CodeV: Empowering LLMs for Verilog Generation through Multi-Level Summarization" [2024-07] [<a href="https://arxiv.org/abs/2407.10424" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "ITERTL: An Iterative Framework for Fine-tuning LLMs for RTL Code Generation" [2024-07] [<a href="https://arxiv.org/abs/2407.12022" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "OriGen:Enhancing RTL Code Generation with Code-to-Code Augmentation and Self-Reflection" [2024-07] [<a href="https://arxiv.org/abs/2407.16237" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "Large Language Model for Verilog Generation with Golden Code Feedback" [2024-07] [<a href="https://arxiv.org/abs/2407.18271" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "AutoVCoder: A Systematic Framework for Automated Verilog Code Generation using LLMs" [2024-07] [<a href="https://arxiv.org/abs/2407.18333" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>RPA</strong>] "Plan with Code: Comparing approaches for robust NL to DSL generation" [2024-08] [<a href="https://arxiv.org/abs/2408.08335" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "VerilogCoder: Autonomous Verilog Coding Agents with Graph-based Planning and Abstract Syntax Tree (AST)-based Waveform Tracing Tool" [2024-08] [<a href="https://arxiv.org/abs/2408.08927" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "Revisiting VerilogEval: Newer LLMs, In-Context Learning, and Specification-to-RTL Tasks" [2024-08] [<a href="https://arxiv.org/abs/2408.11053" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>MaxMSP, Web Audio</strong>] "Benchmarking LLM Code Generation for Audio Programming with Visual Dataflow Languages" [2024-09] [<a href="https://arxiv.org/abs/2409.00856" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "RTLRewriter: Methodologies for Large Models aided RTL Code Optimization" [2024-09] [<a href="https://arxiv.org/abs/2409.11414" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "CraftRTL: High-quality Synthetic Data Generation for Verilog Code Models with Correct-by-Construction Non-Textual Representations and Targeted Code Repair" [2024-09] [ICLR 2025] [<a href="https://arxiv.org/abs/2409.12993" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Bash</strong>] "ScriptSmith: A Unified LLM Framework for Enhancing IT Operations via Automated Bash Script Generation, Assessment, and Refinement" [2024-09] [<a href="https://arxiv.org/abs/2409.17166" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Survey</strong>] "Survey on Code Generation for Low resource and Domain Specific Programming Languages" [2024-10] [<a href="https://arxiv.org/abs/2410.03981" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>R</strong>] "Do Current Language Models Support Code Intelligence for R Programming Language?" [2024-10] [<a href="https://arxiv.org/abs/2410.07793" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>PLC</strong>] "Agents4PLC: Automating Closed-loop PLC Code Generation and Verification in Industrial Control Systems using LLM-based Agents" [2024-10] [<a href="https://arxiv.org/abs/2410.14209" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Lua</strong>] "Evaluating Quantized Large Language Models for Code Generation on Low-Resource Language Benchmarks" [2024-10] [<a href="https://arxiv.org/abs/2410.14766" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Improving Parallel Program Performance Through DSL-Driven Code Generation with LLM Optimizers" [2024-10] [<a href="https://arxiv.org/abs/2410.15625" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>R, D, Racket, Bash</strong>]: "Bridge-Coder: Unlocking LLMs' Potential to Overcome Language Gaps in Low-Resource Code" [2024-10] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2410.18957" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>SPICE</strong>]: "SPICEPilot: Navigating SPICE Code Generation and Simulation with AI Guidance" [2024-10] [<a href="https://arxiv.org/abs/2410.20553" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>IEC 61131-3 ST</strong>]: "Training LLMs for Generating IEC 61131-3 Structured Text with Online Feedback" [2024-10] [<a href="https://arxiv.org/abs/2410.22159" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "MetRex: A Benchmark for Verilog Code Metric Reasoning Using LLMs" [2024-11] [<a href="https://arxiv.org/abs/2411.03471" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "CorrectBench: Automatic Testbench Generation with Functional Self-Correction using LLMs for HDL Design" [2024-11] [<a href="https://arxiv.org/abs/2411.08510" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>MUMPS, ALC</strong>] "Leveraging LLMs for Legacy Code Modernization: Challenges and Opportunities for LLM-Generated Documentation" [2024-11] [<a href="https://arxiv.org/abs/2411.14971" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Power Query M, OfficeScript, Excel formulas</strong>] "RAR: Retrieval-augmented retrieval for code generation in low resource languages" [2024-11] [EMNLP 2024] [<a href="https://aclanthology.org/2024.emnlp-main.1199/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>ST</strong>] "A Multi-Agent Framework for Extensible Structured Text Generation in PLCs" [2024-12] [<a href="https://arxiv.org/abs/2412.02410" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "PromptV: Leveraging LLM-powered Multi-Agent Prompting for High-quality Verilog Generation" [2024-12] [<a href="https://arxiv.org/abs/2412.11014" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>HPC</strong>] "HPC-Coder-V2: Studying Code LLMs Across Low-Resource Parallel Languages" [2024-12] [<a href="https://arxiv.org/abs/2412.15178" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "RTLSquad: Multi-Agent Based Interpretable RTL Design" [2025-01] [<a href="https://arxiv.org/abs/2501.05470" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>G</strong>] "GLLM: Self-Corrective G-Code Generation using Large Language Models with User Feedback" [2025-01] [<a href="https://arxiv.org/abs/2501.17584" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Julia, Lua, R, Racket</strong>] "Enhancing Code Generation for Low-Resource Languages: No Silver Bullet" [2025-01] [<a href="https://arxiv.org/abs/2501.19085" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>F</strong>*] "Building A Proof-Oriented Programmer That Is 64% Better Than GPT-4o Under Data Scarsity" [2025-02] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2502.11901" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Exploring Code Language Models for Automated HLS-based Hardware Generation: Benchmark, Infrastructure and Analysis" [2025-02] [ASP-DAC 2025] [<a href="https://arxiv.org/abs/2502.13921" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Alloy</strong>*] "On the Effectiveness of Large Language Models in Writing Alloy Formulas" [2025-02] [<a href="https://arxiv.org/abs/2502.15441" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Solidity</strong>] "SolEval: Benchmarking Large Language Models for Repository-level Solidity Code Generation" [2025-02] [<a href="https://arxiv.org/abs/2502.18793" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>PennyLane</strong>] "PennyLang: Pioneering LLM-Based Quantum Code Generation with a Novel PennyLane-Centric Dataset" [2025-03] [<a href="https://arxiv.org/abs/2503.02497" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "VeriMind: Agentic LLM for Automated Verilog Generation with a Novel Evaluation Metric" [2025-03] [<a href="https://arxiv.org/abs/2503.16514" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Modelica</strong>] "ModiGen: A Large Language Model-Based Workflow for Multi-Task Modelica Code Generation" [2025-03] [<a href="https://arxiv.org/abs/2503.18460" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Excel</strong>] "Synthetic Function Demonstrations Improve Generation in Low-Resource Programming Languages" [2025-03] [<a href="https://arxiv.org/abs/2503.18760" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RTLRepoCoder: Repository-Level RTL Code Completion through the Combination of Fine-Tuning and Retrieval Augmentation" [2025-04] [<a href="https://arxiv.org/abs/2504.08862" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "SymRTLO: Enhancing RTL Code Optimization with LLMs and Neuron-Inspired Symbolic Reasoning" [2025-04] [<a href="https://arxiv.org/abs/2504.10369" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "ReasoningV: Efficient Verilog Code Generation with Adaptive Hybrid Reasoning Model" [2025-04] [<a href="https://arxiv.org/abs/2504.14560" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "VeriCoder: Enhancing LLM-Based RTL Code Generation through Functional Correctness Validation" [2025-04] [<a href="https://arxiv.org/abs/2504.15659" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Chisel</strong>] "ChiseLLM: Unleashing the Power of Reasoning LLMs for Chisel Agile Hardware Development" [2025-04] [<a href="https://arxiv.org/abs/2504.19144" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "ComplexVCoder: An LLM-Driven Framework for Systematic Generation of Complex Verilog Code" [2025-04] [<a href="https://arxiv.org/abs/2504.20653" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Lean</strong>] "CLEVER: A Curated Benchmark for Formally Verified Code Generation" [2025-05] [<a href="https://arxiv.org/abs/2505.13938" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "VeriThoughts: Enabling Automated Verilog Code Generation using Reasoning and Formal Verification" [2025-05] [<a href="https://arxiv.org/abs/2505.20302" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "hdl2v: A Code Translation Dataset for Enhanced LLM Verilog Generation" [2025-06] [<a href="https://arxiv.org/abs/2506.04544" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "ScaleRTL: Scaling LLMs with Reasoning Data and Test-Time Compute for Accurate RTL Code Generation" [2025-06] [<a href="https://arxiv.org/abs/2506.05566" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>LaTeX</strong>] "TeXpert: A Multi-Level Benchmark for Evaluating LaTeX Code Generation by LLMs" [2025-06] [<a href="https://arxiv.org/abs/2506.16990" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "EvoVerilog: Large Langugage Model Assisted Evolution of Verilog Code" [2025-06] [<a href="https://arxiv.org/abs/2508.13156" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Triton</strong>] "AutoTriton: Automatic Triton Programming with Reinforcement Learning in LLMs" [2025-07] [<a href="https://arxiv.org/abs/2507.05687" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>CUDA</strong>] "Kevin: Multi-Turn RL for Generating CUDA Kernels" [2025-07] [<a href="https://arxiv.org/abs/2507.11948" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>SIMD intrinsics</strong>] "SimdBench: Benchmarking Large Language Models for SIMD-Intrinsic Code Generation" [2025-07] [<a href="https://arxiv.org/abs/2507.15224" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Triton</strong>] "Geak: Introducing Triton Kernel AI Agent &amp; Evaluation Benchmarks" [2025-07] [<a href="https://arxiv.org/abs/2507.23194" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "VERIRL: Boosting the LLM-based Verilog Code Generation via Reinforcement Learning" [2025-08] [<a href="https://arxiv.org/abs/2508.18462" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MultiPL-MoE: Multi-Programming-Lingual Extension of Large Language Models through Hybrid Mixture-of-Experts" [2025-08] [<a href="https://arxiv.org/abs/2508.19268" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>CUDA</strong>] "Astra: A Multi-Agent System for GPU Kernel Performance Optimization" [2025-09] [<a href="https://arxiv.org/abs/2509.07506" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>LaTeX</strong>] "Table2LaTeX-RL: High-Fidelity LaTeX Code Generation from Table Images via Reinforced Multimodal Language Models" [2025-09] [<a href="https://arxiv.org/abs/2509.17589" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeChemist: Functional Knowledge Transfer for Low-Resource Code Generation via Test-Time Scaling" [2025-10] [<a href="https://arxiv.org/abs/2510.00501" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>CUDA</strong>] "EvoEngineer: Mastering Automated CUDA Kernel Code Evolution with Large Language Models" [2025-10] [<a href="https://arxiv.org/abs/2510.03760" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Verilog</strong>] "Pluto: A Benchmark for Evaluating Efficiency of LLM-generated Hardware Code" [2025-10] [<a href="https://arxiv.org/abs/2510.14756" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>CUDA</strong>] "Integrating Performance Tools in Model Reasoning for GPU Kernel Optimization" [2025-10] [<a href="https://arxiv.org/abs/2510.17158" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">[<strong>Triton</strong>] "TritonRL: Training LLMs to Think and Code Triton Without Cheating" [2025-10] [<a href="https://arxiv.org/abs/2510.17891" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">5. Methods/Models for Downstream Tasks</h2><a id="user-content-5-methodsmodels-for-downstream-tasks" class="anchor" aria-label="Permalink: 5. Methods/Models for Downstream Tasks" href="#5-methodsmodels-for-downstream-tasks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">For each task, the first column contains non-neural methods (e.g. n-gram, TF-IDF, and (occasionally) static program analysis); the second column contains non-Transformer neural methods (e.g. LSTM, CNN, GNN); the third column contains Transformer based methods (e.g. BERT, GPT, T5).</p>
<p align="center" dir="auto">
<a target="_blank" rel="noopener noreferrer" href="/codefuse-ai/Awesome-Code-LLM/blob/main/imgs/downstream-1.png"><img src="/codefuse-ai/Awesome-Code-LLM/raw/main/imgs/downstream-1.png" style="width: 100%; max-width: 100%;"></a>
<a target="_blank" rel="noopener noreferrer" href="/codefuse-ai/Awesome-Code-LLM/blob/main/imgs/downstream-2.png"><img src="/codefuse-ai/Awesome-Code-LLM/raw/main/imgs/downstream-2.png" style="width: 100%; max-width: 100%;"></a>
<a target="_blank" rel="noopener noreferrer" href="/codefuse-ai/Awesome-Code-LLM/blob/main/imgs/downstream-3.png"><img src="/codefuse-ai/Awesome-Code-LLM/raw/main/imgs/downstream-3.png" style="width: 100%; max-width: 100%;"></a>
<a target="_blank" rel="noopener noreferrer" href="/codefuse-ai/Awesome-Code-LLM/blob/main/imgs/downstream-4.png"><img src="/codefuse-ai/Awesome-Code-LLM/raw/main/imgs/downstream-4.png" style="width: 100%; max-width: 100%;"></a>
<a target="_blank" rel="noopener noreferrer" href="/codefuse-ai/Awesome-Code-LLM/blob/main/imgs/downstream-5.png"><img src="/codefuse-ai/Awesome-Code-LLM/raw/main/imgs/downstream-5.png" style="width: 100%; max-width: 100%;"></a>
</p>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Code Generation</h3><a id="user-content-code-generation" class="anchor" aria-label="Permalink: Code Generation" href="#code-generation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Enhancing Large Language Models in Coding Through Multi-Perspective Self-Consistency" [2023-09] [ACL 2024] [<a href="https://arxiv.org/abs/2309.17272" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Self-Infilling Code Generation" [2023-11] [ICML 2024] [<a href="https://arxiv.org/abs/2311.17972" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"JumpCoder: Go Beyond Autoregressive Coder via Online Modification" [2024-01] [ACL 2024] [<a href="https://arxiv.org/abs/2401.07870" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Larger the Better? Improved LLM Code-Generation via Budget Reallocation" [2024-03] [<a href="https://arxiv.org/abs/2404.00725" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Comments as Natural Logic Pivots: Improve Code Generation via Comment Perspective" [2024-04] [ACL 2024 Findings] [<a href="https://arxiv.org/abs/2404.07549" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Distilling Algorithmic Reasoning from LLMs via Explaining Solution Programs" [2024-04] [<a href="https://arxiv.org/abs/2404.08148" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Quality Assessment of Prompts Used in Code Generation" [2024-04] [<a href="https://arxiv.org/abs/2404.10155" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Model Cascading for Code: Reducing Inference Costs with Model Cascading for LLM Based Code Generation" [2024-05] [<a href="https://arxiv.org/abs/2405.15842" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Survey on Large Language Models for Code Generation" [2024-06] [<a href="https://arxiv.org/abs/2406.00515" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Is Programming by Example solved by LLMs?" [2024-06] [NeurIPS 2024] [<a href="https://arxiv.org/abs/2406.08316" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Benchmarks and Metrics for Evaluations of Code Generation: A Critical Review" [2024-06] [<a href="https://arxiv.org/abs/2406.12655" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MPCODER: Multi-user Personalized Code Generator with Explicit and Implicit Style Representation Learning" [2024-06] [ACL 2024] [<a href="https://arxiv.org/abs/2406.17255" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Revisiting the Impact of Pursuing Modularity for Code Generation" [2024-07] [EMNLP 2024 Findings] [<a href="https://arxiv.org/abs/2407.11406" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating Long Range Dependency Handling in Code Generation Models using Multi-Step Key Retrieval" [2024-07] [<a href="https://arxiv.org/abs/2407.21049" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"When to Stop? Towards Efficient Code Generation in LLMs with Excess Token Prevention" [2024-07] [<a href="https://arxiv.org/abs/2407.20042" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Assessing Programming Task Difficulty for Efficient Evaluation of Large Language Models" [2024-07] [<a href="https://arxiv.org/abs/2407.21227" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ArchCode: Incorporating Software Requirements in Code Generation with Large Language Models" [2024-08] [ACL 2024] [<a href="https://www.arxiv.org/abs/2408.00994" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Fine-tuning Language Models for Joint Rewriting and Completion of Code with Potential Bugs" [2024-08] [ACL 2024 Findings] [<a href="https://aclanthology.org/2024.findings-acl.938/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Selective Prompt Anchoring for Code Generation" [2024-08] [ICML 2025] [<a href="https://arxiv.org/abs/2408.09121" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Bridging the Language Gap: Enhancing Multilingual Prompt-Based Code Generation in LLMs via Zero-Shot Cross-Lingual Transfer" [2024-08] [<a href="https://arxiv.org/abs/2408.09701" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"No Man is an Island: Towards Fully Automatic Programming by Code Search, Code Generation and Program Repair" [2024-09] [<a href="https://arxiv.org/abs/2409.03267" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Planning In Natural Language Improves LLM Search For Code Generation" [2024-09] [ICLR 2025] [<a href="https://arxiv.org/abs/2409.03733" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Multi-Programming Language Ensemble for Code Generation in Large Language Model" [2024-09] [<a href="https://arxiv.org/abs/2409.04114" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"USCD: Improving Code Generation of LLMs by Uncertainty-Aware Selective Contrastive Decoding" [2024-09] [<a href="https://arxiv.org/abs/2409.05923" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Eliciting Instruction-tuned Code Language Models' Capabilities to Utilize Auxiliary Function for Code Generation" [2024-09] [EMNLP 2024 Findings] [<a href="https://arxiv.org/abs/2409.13928" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Selection of Prompt Engineering Techniques for Code Generation through Predicting Code Complexity" [2024-09] [<a href="https://arxiv.org/abs/2409.16416" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Horizon-Length Prediction: Advancing Fill-in-the-Middle Capabilities for Code Generation with Lookahead Planning" [2024-10] [<a href="https://arxiv.org/abs/2410.03103" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Showing LLM-Generated Code Selectively Based on Confidence of LLMs" [2024-10] [<a href="https://arxiv.org/abs/2410.03234" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AutoFeedback: An LLM-based Framework for Efficient and Accurate API Request Generation" [2024-10] [<a href="https://arxiv.org/abs/2410.06943" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing LLM Agents for Code Generation with Possibility and Pass-rate Prioritized Experience Replay" [2024-10] [<a href="https://arxiv.org/abs/2410.12236" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"From Solitary Directives to Interactive Encouragement! LLM Secure Code Generation by Natural Language Prompting" [2024-10] [<a href="https://arxiv.org/abs/2410.14321" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Self-Explained Keywords Empower Large Language Models for Code Generation" [2024-10] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2410.15966" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Context-Augmented Code Generation Using Programming Knowledge Graphs" [2024-10] [<a href="https://arxiv.org/abs/2410.18251" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"In-Context Code-Text Learning for Bimodal Software Engineering" [2024-10] [<a href="https://arxiv.org/abs/2410.18107" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Combining LLM Code Generation with Formal Specifications and Reactive Program Synthesis" [2024-10] [<a href="https://arxiv.org/abs/2410.19736" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Less is More: DocString Compression in Code Generation" [2024-10] [<a href="https://arxiv.org/abs/2410.22793" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Multi-Programming Language Sandbox for LLMs" [2024-10] [<a href="https://arxiv.org/abs/2410.23074" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Personality-Guided Code Generation Using Large Language Models" [2024-10] [ACL 2025] [<a href="https://arxiv.org/abs/2411.00006" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Scattered Forest Search: Smarter Code Space Exploration with LLMs" [2024-11] [<a href="https://arxiv.org/abs/2411.05010" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Anchor Attention, Small Cache: Code Generation with Large Language Models" [2024-11] [<a href="https://arxiv.org/abs/2411.06680" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ROCODE: Integrating Backtracking Mechanism and Program Analysis in Large Language Models for Code Generation" [2024-11] [<a href="https://arxiv.org/abs/2411.07112" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SRA-MCTS: Self-driven Reasoning Aurmentation with Monte Carlo Tree Search for Enhanced Code Generation" [2024-11] [<a href="https://arxiv.org/abs/2411.11053" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Language-to-Code Translation with a Single Labeled Example" [2024-11] [EMNLP 2024] [<a href="https://aclanthology.org/2024.emnlp-main.462/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"VeCoGen: Automating Generation of Formally Verified C Code with Large Language Models" [2024-11] [<a href="https://arxiv.org/abs/2411.19275" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Seed-CTS: Unleashing the Power of Tree Search for Superior Performance in Competitive Coding Tasks" [2024-12] [<a href="https://arxiv.org/abs/2412.12544" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LoGFiLM: Fine-Tuning A Large Language Model for Automated Generation of Log Statements" [2024-12] [<a href="https://arxiv.org/abs/2412.18835" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Impact of Prompt Programming on Function-Level Code Generation" [2024-12] [<a href="https://arxiv.org/abs/2412.20545" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Leveraging Metamemory Mechanisms for Enhanced Data-Free Code Generation in LLMs" [2025-01] [<a href="https://arxiv.org/abs/2501.07892" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"GREEN-CODE: Optimizing Energy Efficiency in Large Language Models for Code Generation" [2025-01] [<a href="https://arxiv.org/abs/2501.11006" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Chain of Grounded Objectives: Bridging Process and Goal-oriented Prompting for Code Generation" [2025-01] [<a href="https://arxiv.org/abs/2501.13978" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CoCoEvo: Co-Evolution of Programs and Test Cases to Enhance Code Generation" [2025-02] [<a href="https://arxiv.org/abs/2502.10802" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Boost, Disentangle, and Customize: A Robust System2-to-System1 Pipeline for Code Generation" [2025-02] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2502.12492" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Learning to Solve and Verify: A Self-Play Framework for Code and Test Generation" [2025-02] [<a href="https://arxiv.org/abs/2502.14948" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Thinking Before Running! Efficient Code Generation with Thorough Exploration and Optimal Refinement" [2025-02] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2502.17442" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Grammar-Based Code Representation: Is It a Worthy Pursuit for LLMs?" [2025-03] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2503.05507" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing High-Quality Code Generation in Large Language Models with Comparative Prefix-Tuning" [2025-03] [<a href="https://arxiv.org/abs/2503.09020" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Modularization is Better: Effective Code Generation with Modular Prompting" [2025-03] [<a href="https://arxiv.org/abs/2503.12483" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Semantic-based Optimization Approach for Repairing LLMs: Case Study on Code Generation" [2025-03] [<a href="https://arxiv.org/abs/2503.12899" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Uncertainty-Guided Chain-of-Thought for Code Generation with LLMs" [2025-03] [<a href="https://arxiv.org/abs/2503.15341" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis" [2025-03] [<a href="https://arxiv.org/abs/2503.23145" rel="nofollow">ppaer</a>]</p>
</li>
<li>
<p dir="auto">"Prism: Dynamic and Flexible Benchmarking of LLMs Code Generation with Monte Carlo Tree Search" [2025-04] [<a href="https://arxiv.org/abs/2504.05500" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing Chart-to-Code Generation in Multimodal Large Language Models via Iterative Dual Preference Learning" [2025-04] [<a href="https://arxiv.org/abs/2504.02906" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"From Token to Line: Enhancing Code Generation with a Long-Term Perspective" [2025-04] [<a href="https://arxiv.org/abs/2504.07433" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Multilingual Multimodal Software Developer for Code Generation" [2025-07] [<a href="https://arxiv.org/abs/2507.08719" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Revisiting Chain-of-Thought in Code Generation: Do Language Models Need to Learn Reasoning before Coding?" [2025-07] [ICML 2025] [<a href="https://icml.cc/virtual/2025/poster/43621" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Beyond Sequences: Two-dimensional Representation and Dependency Encoding for Code Generation" [2025-07] [ACL 2025] [<a href="https://aclanthology.org/2025.acl-long.308/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodePRM: Execution Feedback-enhanced Process Reward Model for Code Generation" [2025-07] [ACL 2025 Findings] [<a href="https://aclanthology.org/2025.findings-acl.428/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal" [2025-08] [<a href="https://arxiv.org/abs/2508.05988" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Let's Revise Step-by-Step: A Unified Local Search Framework for Code Generation with LLMs" [2025-08] [<a href="https://arxiv.org/abs/2508.07434" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Alignment with Fill-In-the-Middle for Enhancing Code Generation" [2025-08] [<a href="https://arxiv.org/abs/2508.19532" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"TigerCoder: A Novel Suite of LLMs for Code Generation in Bangla" [2025-09] [<a href="https://arxiv.org/abs/2509.09101" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SemGuard: Real-Time Semantic Evaluator for Correcting LLM-Generated Code" [2025-09] [<a href="https://arxiv.org/abs/2509.24507" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LongCodeZip: Compress Long Context for Code Language Models" [2025-10] [<a href="https://arxiv.org/abs/2510.00446" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Scaling Test-Time Compute to Achieve IOI Gold Medal with Open-Weight Models" [2025-10] [<a href="https://arxiv.org/abs/2510.14232" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Code RAG</h3><a id="user-content-code-rag" class="anchor" aria-label="Permalink: Code RAG" href="#code-rag"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"CodeGRAG: Extracting Composed Syntax Graphs for Retrieval Augmented Cross-Lingual Code Generation" [2024-05] [<a href="https://arxiv.org/abs/2405.02355" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Prompt-based Code Completion via Multi-Retrieval Augmented Generation" [2024-05] [<a href="https://arxiv.org/abs/2405.07530" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Lightweight Framework for Adaptive Retrieval In Code Completion With Critique Model" [2024-06] [<a href="https://arxiv.org/abs/2406.10263" rel="nofollow">papaer</a>]</p>
</li>
<li>
<p dir="auto">"Preference-Guided Refactored Tuning for Retrieval Augmented Code Generation" [2024-09] [<a href="https://arxiv.org/abs/2409.15895" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Building A Coding Assistant via the Retrieval-Augmented Language Model" [2024-10] [<a href="https://arxiv.org/abs/2410.16229" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DroidCoder: Enhanced Android Code Completion with Context-Enriched Retrieval-Augmented Generation" [2024-10] [ASE 2024] [<a href="https://dl.acm.org/doi/10.1145/3691620.3695063" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Assessing the Answerability of Queries in Retrieval-Augmented Code Generation" [2024-11] [<a href="https://arxiv.org/abs/2411.05547" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"EvoR: Evolving Retrieval for Code Generation" [2024-11] [EMNLP 2024 Findings] [<a href="https://aclanthology.org/2024.findings-emnlp.143/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"PERC: Plan-As-Query Example Retrieval for Underrepresented Code Generation" [2024-12] [<a href="https://arxiv.org/abs/2412.12447" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Empirical Study of Retrieval-Augmented Code Generation: Challenges and Opportunities" [2025-01] [<a href="https://arxiv.org/abs/2501.13742" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CODEPROMPTZIP: Code-specific Prompt Compression for Retrieval-Augmented Generation in Coding Tasks with LMs" [2025-02] [<a href="https://arxiv.org/abs/2502.14925" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeSwift: Accelerating LLM Inference for Efficient Code Generation" [2025-02] [<a href="https://arxiv.org/abs/2502.17139" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SOSecure: Safer Code Generation with RAG and StackOverflow Discussions" [2025-03] [<a href="https://arxiv.org/abs/2503.13654" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"When LLMs Meet API Documentation: Can Retrieval Augmentation Aid Code Generation Just as It Helps Developers?" [2025-03] [<a href="https://arxiv.org/abs/2503.15231" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"What to Retrieve for Effective Retrieval-Augmented Code Generation? An Empirical Study and Beyond" [2025-03] [<a href="https://arxiv.org/abs/2503.20589" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Across Programming Language Silos: A Study on Cross-Lingual Retrieval-augmented Code Generation" [2025-06] [<a href="https://arxiv.org/abs/2506.03535" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree" [2025-06] [<a href="https://arxiv.org/abs/2506.15655" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SACL: Understanding and Combating Textual Bias in Code Retrieval with Semantic-Augmented Reranking and Localization" [2025-06] [<a href="https://arxiv.org/abs/2506.20081" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Deep Dive into Retrieval-Augmented Generation for Code Completion: Experience on WeChat" [2025-07] [<a href="https://arxiv.org/abs/2507.18515" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Impact-driven Context Filtering For Cross-file Code Completion" [2025-08] [<a href="https://arxiv.org/abs/2508.05970" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Retrieval-Augmented Code Generation: A Survey with Focus on Repository-Level Approaches" [2025-10] [<a href="https://arxiv.org/abs/2510.04905" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Code Ranking</h3><a id="user-content-code-ranking" class="anchor" aria-label="Permalink: Code Ranking" href="#code-ranking"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Fault-Aware Neural Code Rankers" [2022-06] [NeurIPS 2022] [<a href="https://arxiv.org/abs/2206.03865" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Coder Reviewer Reranking for Code Generation" [2022-11] [ICML 2023] [<a href="https://arxiv.org/abs/2211.16490" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LEVER: Learning to Verify Language-to-Code Generation with Execution" [2023-02] [ICML 2023] [<a href="https://arxiv.org/abs/2302.08468" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Functional Overlap Reranking for Neural Code Generation" [2023-10] [ACL 2024 Findings] [<a href="https://arxiv.org/abs/2311.03366" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Top Pass: Improve Code Generation by Pass@k-Maximized Code Ranking" [2024-08] [<a href="https://arxiv.org/abs/2408.05715" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DOCE: Finding the Sweet Spot for Execution-Based Code Generation" [2024-08] [<a href="https://arxiv.org/abs/2408.13745" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Sifting through the Chaff: On Utilizing Execution Feedback for Ranking the Generated Code Candidates" [2024-08] [<a href="https://arxiv.org/abs/2408.13976" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"B4: Towards Optimal Assessment of Plausible Code Solutions with Plausible Tests" [2024-09] [<a href="https://arxiv.org/abs/2409.08692" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Learning Code Preference via Synthetic Evolution" [2024-10] [<a href="https://arxiv.org/abs/2410.03837" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Condor: A Code Discriminator Integrating General Semantics with Code Details" [2024-12] [<a href="https://arxiv.org/abs/2412.17429" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Scoring Verifiers: Evaluating Synthetic Verification in Code and Reasoning" [2025-02] [<a href="https://arxiv.org/abs/2502.13820" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Pragmatic Reasoning improves LLM Code Generation" [2025-02] [<a href="https://arxiv.org/abs/2502.15835" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SweRank: Software Issue Localization with Code Ranking" [2025-05] [<a href="https://arxiv.org/abs/2505.07849" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Reward Models Enable Scalable Code Verification by Trading Accuracy for Throughput" [2025-06] [<a href="https://arxiv.org/abs/2506.10056" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Code Translation</h3><a id="user-content-code-translation" class="anchor" aria-label="Permalink: Code Translation" href="#code-translation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Tree-to-tree Neural Networks for Program Translation" [2018-02] [NeurIPS 2018] [<a href="https://arxiv.org/abs/1802.03691" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Program Language Translation Using a Grammar-Driven Tree-to-Tree Model" [2018-07] [<a href="https://arxiv.org/abs/1807.01784" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Unsupervised Translation of Programming Languages" [2020-06] [NeurIPS 2020] [<a href="https://arxiv.org/abs/2006.03511" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Leveraging Automated Unit Tests for Unsupervised Code Translation" [2021-10] [ICLR 2022] <a href="https://arxiv.org/abs/2110.06773" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code Translation with Compiler Representations" [2022-06] [ICLR 2023] [<a href="https://arxiv.org/abs/2207.03578" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Multilingual Code Snippets Training for Program Translation" [2022-06] [AAAI 2022] [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/21434" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"BabelTower: Learning to Auto-parallelized Program Translation" [2022-07] [ICML 2022] [<a href="https://proceedings.mlr.press/v162/wen22b.html" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Syntax and Domain Aware Model for Unsupervised Program Translation" [2023-02] [ICSE 2023] [<a href="https://arxiv.org/abs/2302.03908" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CoTran: An LLM-based Code Translator using Reinforcement Learning with Feedback from Compiler and Symbolic Execution" [2023-06] [<a href="https://arxiv.org/abs/2306.06755" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Lost in Translation: A Study of Bugs Introduced by Large Language Models while Translating Code" [2023-08] [ICSE 2024] [<a href="https://arxiv.org/abs/2308.03109" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"On the Evaluation of Neural Code Translation: Taxonomy and Benchmark", 2023-08, ASE 2023, [<a href="https://arxiv.org/abs/2308.08961" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Program Translation via Code Distillation" [2023-10] [EMNLP 2023] [<a href="https://arxiv.org/abs/2310.11476" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Explain-then-Translate: An Analysis on Improving Program Translation with Self-generated Explanations" [2023-11] [EMNLP 2023 Findings] [<a href="https://arxiv.org/abs/2311.07070" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Exploring the Impact of the Output Format on the Evaluation of Large Language Models for Code Translation" [2024-03] [<a href="https://arxiv.org/abs/2403.17214" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Exploring and Unleashing the Power of Large Language Models in Automated Code Translation" [2024-04] [<a href="https://arxiv.org/abs/2404.14646" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"VERT: Verified Equivalent Rust Transpilation with Few-Shot Learning" [2024-04] [<a href="https://arxiv.org/abs/2404.18852" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards Translating Real-World Code with LLMs: A Study of Translating to Rust" [2024-05] [<a href="https://arxiv.org/abs/2405.11514" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An interpretable error correction method for enhancing code-to-code translation" [2024-05] [ICLR 2024] [<a href="https://openreview.net/forum?id=fVxIEHGnVT&amp;noteId=CyxZE2UbHF" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LASSI: An LLM-based Automated Self-Correcting Pipeline for Translating Parallel Scientific Codes" [2024-06] [<a href="https://arxiv.org/abs/2407.01638" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Rectifier: Code Translation with Corrector via LLMs" [2024-07] [<a href="https://arxiv.org/abs/2407.07472" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing Code Translation in Language Models with Few-Shot Learning via Retrieval-Augmented Generation" [2024-07] [<a href="https://arxiv.org/abs/2407.19619" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Joint Learning Model with Variational Interaction for Multilingual Program Translation" [2024-08] [<a href="https://arxiv.org/abs/2408.14515" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automatic Library Migration Using Large Language Models: First Results" [2024-08] [<a href="https://arxiv.org/abs/2408.16151" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Context-aware Code Segmentation for C-to-Rust Translation using Large Language Models" [2024-09] [<a href="https://arxiv.org/abs/2409.10506" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation" [2024-10] [<a href="https://arxiv.org/abs/2409.19894" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Unraveling the Potential of Large Language Models in Code Translation: How Far Are We?" [2024-10] [<a href="https://arxiv.org/abs/2410.09812" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeRosetta: Pushing the Boundaries of Unsupervised Code Translation for Parallel Programming" [2024-10] [NeurIPS 2024] [<a href="https://arxiv.org/abs/2410.20527" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A test-free semantic mistakes localization framework in Neural Code Translation" [2024-10] [<a href="https://arxiv.org/abs/2410.22818" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Repository-Level Compositional Code Translation and Validation" [2024-10] [<a href="https://arxiv.org/abs/2410.24117" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Leveraging Large Language Models for Code Translation and Software Development in Scientific Computing" [2024-10] [<a href="https://arxiv.org/abs/2410.24119" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"InterTrans: Leveraging Transitive Intermediate Translations to Enhance LLM-based Code Translation" [2024-11] [<a href="https://arxiv.org/abs/2411.01063" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Translating C To Rust: Lessons from a User Study" [2024-11] [<a href="https://arxiv.org/abs/2411.14174" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Specification-Driven Code Translation Powered by Large Language Models: How Far Are We?" [2024-12] [<a href="https://arxiv.org/abs/2412.04590" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing Cross-Language Code Translation via Task-Specific Embedding Alignment in Retrieval-Augmented Generation" [2024-12] [<a href="https://arxiv.org/abs/2412.05159" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Scalable, Validated Code Translation of Entire Projects using Large Language Models" [2024-12] [<a href="https://arxiv.org/abs/2412.08035" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Syzygy: Dual Code-Test C to (safe) Rust Translation using LLMs and Dynamic Analysis" [2024-12] [<a href="https://arxiv.org/abs/2412.14234" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"I Can't Share Code, but I need Translation -- An Empirical Study on Code Translation through Federated LLM" [2025-01] [<a href="https://arxiv.org/abs/2501.05724" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Guided Debugging of Auto-Translated Code Using Differential Testing" [2025-01] [<a href="https://arxiv.org/abs/2501.09475" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"C2SaferRust: Transforming C Projects into Safer Rust with NeuroSymbolic Techniques" [2025-01] [<a href="https://arxiv.org/abs/2501.14257" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ExeCoder: Empowering Large Language Models with Executability Representation for Code Translation" [2025-01] [<a href="https://arxiv.org/abs/2501.18460" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM-Driven Multi-step Translation from C to Rust using Static Analysis" [2025-03] [<a href="https://arxiv.org/abs/2503.12511" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing LLM-based Code Translation in Repository Context via Triple Knowledge-Augmented" [2025-03] [<a href="https://arxiv.org/abs/2503.18305" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing LLMs in Long Code Translation through Instrumentation and Program State Alignment" [2025-04] [<a href="https://arxiv.org/abs/2504.02017" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Systematic Literature Review on Neural Code Translation" [2025-05] [<a href="https://arxiv.org/abs/2505.07425" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Model-Powered Agent for C to Rust Code Translation" [2025-05] [<a href="https://arxiv.org/abs/2505.15858" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"On-Policy Optimization with Group Equivalent Preference for Multi-Programming Language Understanding" [2025-05] [<a href="https://arxiv.org/abs/2505.12723" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Function-to-Style Guidance of LLMs for Code Translation" [2025-07] [ICML 2025] [<a href="https://arxiv.org/abs/2507.11083" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"EffiReasonTrans: RL-Optimized Reasoning for Code Translation" [2025-10] [<a href="https://arxiv.org/abs/2510.18863" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Code Commenting and Summarization</h3><a id="user-content-code-commenting-and-summarization" class="anchor" aria-label="Permalink: Code Commenting and Summarization" href="#code-commenting-and-summarization"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"A Transformer-based Approach for Source Code Summarization" [2020-05] [ACL 2020] [<a href="https://arxiv.org/abs/2005.00653" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code Summarization with Structure-induced Transformer" [2020-12] [ACL 2021 Findings] [<a href="https://arxiv.org/abs/2012.14710" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code Structure Guided Transformer for Source Code Summarization" [2021-04] [ACM TSEM] [<a href="https://arxiv.org/abs/2104.09340" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"M2TS: Multi-Scale Multi-Modal Approach Based on Transformer for Source Code Summarization" [2022-03] [ICPC 2022] [<a href="https://arxiv.org/abs/2203.09707" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AST-trans: code summarization with efficient tree-structured attention" [2022-05] [ICSE 2022] [<a href="https://dl.acm.org/doi/abs/10.1145/3510003.3510224" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CoSS: Leveraging Statement Semantics for Code Summarization" [2023-03] [IEEE TSE] [<a href="https://ieeexplore.ieee.org/document/10068264" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automatic Code Summarization via ChatGPT: How Far Are We?" [2023-05] [<a href="https://arxiv.org/abs/2305.12865" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Semantic Similarity Loss for Neural Source Code Summarization" [2023-08] [<a href="https://arxiv.org/abs/2308.07429" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Distilled GPT for Source Code Summarization" [2023-08] [ASE] [<a href="https://arxiv.org/abs/2308.14731" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CSA-Trans: Code Structure Aware Transformer for AST" [2024-04] [<a href="https://arxiv.org/abs/2404.05767" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Analyzing the Performance of Large Language Models on Code Summarization" [2024-04] [<a href="https://arxiv.org/abs/2404.08018" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing Trust in LLM-Generated Code Summaries with Calibrated Confidence Scores" [2024-04] [<a href="https://arxiv.org/abs/2404.19318" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DocuMint: Docstring Generation for Python using Small Language Models" [2024-05] [<a href="https://arxiv.org/abs/2405.10243" rel="nofollow">paper</a>] [<a href="https://github.com/Docu-Mint/DocuMint">repo</a>]</p>
</li>
<li>
<p dir="auto">"Natural Is The Best: Model-Agnostic Code Simplification for Pre-trained Large Language Models" [2024-05] [<a href="https://arxiv.org/abs/2405.11196" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Exploring the Efficacy of Large Language Models (GPT-4) in Binary Reverse Engineering" [2024-06] [<a href="https://arxiv.org/abs/2406.06637" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Identifying Inaccurate Descriptions in LLM-generated Code Comments via Test Execution" [2024-06] [<a href="https://arxiv.org/abs/2406.14836" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MALSIGHT: Exploring Malicious Source Code and Benign Pseudocode for Iterative Binary Malware Summarization" [2024-06] [<a href="https://arxiv.org/abs/2406.18379" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Source Code Summarization in the Era of Large Language Models" [2024-07] [<a href="https://arxiv.org/abs/2407.07959" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Natural Language Outlines for Code: Literate Programming in the LLM Era" [2024-08] [<a href="https://arxiv.org/abs/2408.04820" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Context-aware Code Summary Generation" [2024-08] [<a href="https://arxiv.org/abs/2408.09006" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AUTOGENICS: Automated Generation of Context-Aware Inline Comments for Code Snippets on Programming Q&amp;A Sites Using LLM" [2024-08] [<a href="https://arxiv.org/abs/2408.15411" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLMs as Evaluators: A Novel Approach to Evaluate Bug Report Summarization" [2024-09] [<a href="https://arxiv.org/abs/2409.00630" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Generating Equivalent Representations of Code By A Self-Reflection Approach" [2024-10] [<a href="https://arxiv.org/abs/2410.03351" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A review of automatic source code summarization" [2024-10] [Empirical Software Engineering] [<a href="https://link.springer.com/article/10.1007/s10664-024-10553-6" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can Large Language Models Serve as Evaluators for Code Summarization?" [2024-12] [<a href="https://arxiv.org/abs/2412.01333" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Selective Shot Learning for Code Explanation" [2024-12] [<a href="https://arxiv.org/abs/2412.12852" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot In-Context Learning for SQL2Text" [2025-01] [<a href="https://arxiv.org/abs/2501.03166" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Hierarchical Repository-Level Code Summarization for Business Applications Using Local LLMs" [2025-01] [<a href="https://arxiv.org/abs/2501.07857" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"From Critique to Clarity: A Pathway to Faithful and Personalized Code Explanations with Large Language Models" [2025-01] [<a href="https://arxiv.org/abs/2501.14731" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"METAMON: Finding Inconsistencies between Program Documentation and Behavior using Metamorphic LLM Queries" [2025-02] [<a href="https://arxiv.org/abs/2502.02794" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Should Code Models Learn Pedagogically? A Preliminary Evaluation of Curriculum Learning for Real-World Software Engineering Tasks" [2025-02] [<a href="https://arxiv.org/abs/2502.03806" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Optimizing Datasets for Code Summarization: Is Code-Comment Coherence Enough?" [2025-02] [<a href="https://arxiv.org/abs/2502.07611" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code Summarization Beyond Function Level" [2025-02] [<a href="https://arxiv.org/abs/2502.16704" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ReadMe.LLM: A Framework to Help LLMs Understand Your Library" [2025-04] [<a href="https://arxiv.org/abs/2504.09798" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DocAgent: A Multi-Agent System for Automated Code Documentation Generation" [2025-04] [<a href="https://arxiv.org/abs/2504.08725" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"HGAdapter: Hypergraph-based Adapters in Language Models for Code Summarization and Clone Detection" [2025-10] [<a href="https://arxiv.org/abs/2510.17591" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Program Repair</h3><a id="user-content-program-repair" class="anchor" aria-label="Permalink: Program Repair" href="#program-repair"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"CURE: Code-Aware Neural Machine Translation for Automatic Program Repair" [2021-02] [ICSE 2021] [<a href="https://arxiv.org/abs/2103.00073" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DeepDebug: Fixing Python Bugs Using Stack Traces, Backtranslation, and Code Skeletons" [2021-05] [<a href="https://arxiv.org/abs/2105.09352" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Break-It-Fix-It: Unsupervised Learning for Program Repair" [2021-06] [ICML 2021] [<a href="https://arxiv.org/abs/2106.06600" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"TFix: Learning to Fix Coding Errors with a Text-to-Text Transformer" [2021-07] [ICML 2021] [<a href="https://proceedings.mlr.press/v139/berabi21a.html" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automated Repair of Programs from Large Language Models" [2022-05] [ICSE 2023] [<a href="https://arxiv.org/abs/2205.10583" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Less Training, More Repairing Please: Revisiting Automated Program Repair via Zero-shot Learning" [2022-07] [ESEC/FSE 2022] [<a href="https://arxiv.org/abs/2207.08281" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Repair Is Nearly Generation: Multilingual Program Repair with LLMs" [2022-08] [AAAI 2023] [<a href="https://arxiv.org/abs/2208.11640" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Practical Program Repair in the Era of Large Pre-trained Language Models" [2022-10] [<a href="https://arxiv.org/abs/2210.14179" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"VulRepair: a T5-based automated software vulnerability repair" [2022-11] [ESEC/FSE 2022] [<a href="https://dl.acm.org/doi/abs/10.1145/3540250.3549098" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Conversational Automated Program Repair" [2023-01] [<a href="https://arxiv.org/abs/2301.13246" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Impact of Code Language Models on Automated Program Repair" [2023-02] [ICSE 2023] [<a href="https://arxiv.org/abs/2302.05020" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"InferFix: End-to-End Program Repair with LLMs" [2023-03] [ESEC/FSE 2023] [<a href="https://arxiv.org/abs/2303.07263" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing Automated Program Repair through Fine-tuning and Prompt Engineering" [2023-04] [<a href="https://arxiv.org/abs/2304.07840" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A study on Prompt Design, Advantages and Limitations of ChatGPT for Deep Learning Program Repair" [2023-04] [<a href="https://arxiv.org/abs/2304.08191" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Domain Knowledge Matters: Improving Prompts with Fix Templates for Repairing Python Type Errors" [2023-06] [ICSE 2024] [<a href="https://arxiv.org/abs/2306.01394" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RepairLLaMA: Efficient Representations and Fine-Tuned Adapters for Program Repair" [2023-12] [<a href="https://arxiv.org/abs/2312.15698" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Fact Selection Problem in LLM-Based Program Repair" [2024-04] [<a href="https://arxiv.org/abs/2404.05520" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Aligning LLMs for FL-free Program Repair" [2024-04] [<a href="https://arxiv.org/abs/2404.08877" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Deep Dive into Large Language Models for Automated Bug Localization and Repair" [2024-04] [<a href="https://arxiv.org/abs/2404.11595" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Multi-Objective Fine-Tuning for Enhanced Program Repair with LLMs" [2024-04] [<a href="https://arxiv.org/abs/2404.12636" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How Far Can We Go with Practical Function-Level Program Repair?" [2024-04] [<a href="https://arxiv.org/abs/2404.12833" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Revisiting Unnaturalness for Automated Program Repair in the Era of Large Language Models" [2024-04] [<a href="https://arxiv.org/abs/2404.15236" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Unified Debugging Approach via LLM-Based Multi-Agent Synergy" [2024-04] [<a href="https://arxiv.org/abs/2404.17153" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Systematic Literature Review on Large Language Models for Automated Program Repair" [2024-05] [<a href="https://arxiv.org/abs/2405.01466" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"NAVRepair: Node-type Aware C/C++ Code Vulnerability Repair" [2024-05] [<a href="https://arxiv.org/abs/2405.04994" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automated Program Repair: Emerging trends pose and expose problems for benchmarks" [2024-05] [<a href="https://arxiv.org/abs/2405.05455" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automated Repair of AI Code with Large Language Models and Formal Verification" [2024-05] [<a href="https://arxiv.org/abs/2405.08848" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Case Study of LLM for Automated Vulnerability Repair: Assessing Impact of Reasoning and Patch Validation Feedback" [2024-05] [<a href="https://arxiv.org/abs/2405.15690" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CREF: An LLM-based Conversational Software Repair Framework for Programming Tutors" [2024-06] [<a href="https://arxiv.org/abs/2406.13972" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards Practical and Useful Automated Program Repair for Debugging" [2024-07] [<a href="https://arxiv.org/abs/2407.08958" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ThinkRepair: Self-Directed Automated Program Repair" [2024-07] [<a href="https://arxiv.org/abs/2407.20898" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MergeRepair: An Exploratory Study on Merging Task-Specific Adapters in Code LLMs for Automated Program Repair" [2024-08] [<a href="https://arxiv.org/abs/2408.09568" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RePair: Automated Program Repair with Process-based Feedback" [2024-08] [ACL 2024 Findings] [<a href="https://arxiv.org/abs/2408.11296" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing LLM-Based Automated Program Repair with Design Rationales" [2024-08] [<a href="https://arxiv.org/abs/2408.12056" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automated Software Vulnerability Patching using Large Language Models" [2024-08] [<a href="https://arxiv.org/abs/2408.13597" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing Source Code Security with LLMs: Demystifying The Challenges and Generating Reliable Repairs" [2024-09] [<a href="https://arxiv.org/abs/2409.00571" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MarsCode Agent: AI-native Automated Bug Fixing" [2024-09] [<a href="https://arxiv.org/abs/2409.00899" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Co-Learning: Code Learning for Multi-Agent Reinforcement Collaborative Framework with Conversational Natural Language Interfaces" [2024-09] [<a href="https://arxiv.org/abs/2409.00985" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Debugging with Open-Source Large Language Models: An Evaluation" [2024-09] [<a href="https://arxiv.org/abs/2409.03031" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"VulnLLMEval: A Framework for Evaluating Large Language Models in Software Vulnerability Detection and Patching" [2024-09] [<a href="https://arxiv.org/abs/2409.10756" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can GPT-O1 Kill All Bugs? An Evaluation of GPT-Family LLMs on QuixBugs" [2024-09] [<a href="https://arxiv.org/abs/2409.10033" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Exploring and Lifting the Robustness of LLM-powered Automated Program Repair with Metamorphic Testing" [2024-10] [<a href="https://arxiv.org/abs/2410.07516" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LecPrompt: A Prompt-based Approach for Logical Error Correction with CodeBERT" [2024-10] [<a href="https://arxiv.org/abs/2410.08241" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Semantic-guided Search for Efficient Program Repair with Large Language Models" [2024-10] [<a href="https://arxiv.org/abs/2410.16655" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Comprehensive Survey of AI-Driven Advancements and Techniques in Automated Program Repair and Code Generation" [2024-11] [<a href="https://arxiv.org/abs/2411.07586" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"From Defects to Demands: A Unified, Iterative, and Heuristically Guided LLM-Based Framework for Automated Software Repair and Requirement Realization" [2024-12] [<a href="https://arxiv.org/abs/2412.05098" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Integrating Various Software Artifacts for Better LLM-based Bug Localization and Program Repair" [2024-12] [<a href="https://arxiv.org/abs/2412.03905" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM4CVE: Enabling Iterative Automated Vulnerability Repair with Large Language Models" [2025-01] [<a href="https://arxiv.org/abs/2501.03446" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating Agent-based Program Repair at Google" [2025-01] [<a href="https://arxiv.org/abs/2501.07531" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"HAFix: History-Augmented Large Language Models for Bug Fixing" [2025-01] [<a href="https://arxiv.org/abs/2501.09135" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MultiMend: Multilingual Program Repair with Context Augmentation and Multi-Hunk Patch Generation" [2025-01] [<a href="https://arxiv.org/abs/2501.16044" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"PATCH: Empowering Large Language Model with Programmer-Intent Guidance and Collaborative-Behavior Simulation for Automatic Bug Fixing" [2025-01] [<a href="https://arxiv.org/abs/2501.16149" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Counterexample Guided Program Repair Using Zero-Shot Learning and MaxSAT-based Fault Localization" [2025-02] [<a href="https://arxiv.org/abs/2502.07786" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Knowledge-Enhanced Program Repair for Data Science Code" [2025-02] [<a href="https://arxiv.org/abs/2502.09771" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AuPair: Golden Example Pairs for Code Repair" [2025-02] [ICML 2025] [<a href="https://arxiv.org/abs/2502.18487" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Less is More: Adaptive Program Repair with Bug Localization and Preference Learning" [2025-03] [<a href="https://arxiv.org/abs/2503.06510" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"UTFix: Change Aware Unit Test Repairing using LLM" [2025-03][OOPSLA 2025] [<a href="https://dl.acm.org/doi/10.1145/3720419" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Unlocking LLM Repair Capabilities in Low-Resource Programming Languages Through Cross-Language Translation and Multi-Agent Refinement" [2025-03] [<a href="https://arxiv.org/abs/2503.22512" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"FeedbackEval: A Benchmark for Evaluating Large Language Models in Feedback-Driven Code Repair Tasks" [2025-03] [<a href="https://arxiv.org/abs/2504.06939" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"NL-Debugging: Exploiting Natural Language as an Intermediate Representation for Code Debugging" [2025-05] [<a href="https://arxiv.org/abs/2505.15356" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Art of Repair: Optimizing Iterative Program Repair with Instruction-Tuned Models" [2025-05] [EASE, June 2025] [<a href="https://arxiv.org/abs/2505.02931" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Adversarial Reasoning for Repair Based on Inferred Program Intent" [2025-05] [ISSTA 2025] [<a href="https://arxiv.org/abs/2505.13008" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Empirical Evaluation of Generalizable Automated Program Repair with Large Language Models" [2025-06] [ICSE 2025] [<a href="https://arxiv.org/abs/2506.03283" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Boosting Open-Source LLMs for Program Repair via Reasoning Transfer and LLM-Guided Reinforcement Learning" [2025-06] [<a href="https://arxiv.org/abs/2506.03921" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"EXPEREPAIR: Dual-Memory Enhanced LLM-based Repository-Level Program Repair" [2025-06] [<a href="https://arxiv.org/abs/2506.10484" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SynFix: Dependency-Aware Program Repair via RelationGraph Analysis" [2025-07] [ACL 2025 Findings] [<a href="https://aclanthology.org/2025.findings-acl.252/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Agentic Program Repair from Test Failures at Scale: A Neuro-symbolic approach with static analysis and test execution feedback" [2025-07] [TSE, July 2025] [<a href="https://arxiv.org/abs/2507.18755" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Impact of Fine-tuning Large Language Models on Automated Program Repair" [2025-07] [ICSME 2025] [<a href="https://arxiv.org/abs/2507.19909" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How Small is Enough? Empirical Evidence of Quantized Small Language Models for Automated Program Repair" [2025-08] [ESEM 2025] [<a href="https://arxiv.org/abs/2508.16499" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"InspectCoder: Dynamic Analysis-Enabled Self Repair through interactive LLM-Debugger Collaboration" [2025-10] [<a href="https://arxiv.org/abs/2510.18327" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Code Similarity and Embedding (Clone Detection, Code Search)</h3><a id="user-content-code-similarity-and-embedding-clone-detection-code-search" class="anchor" aria-label="Permalink: Code Similarity and Embedding (Clone Detection, Code Search)" href="#code-similarity-and-embedding-clone-detection-code-search"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Self-Supervised Contrastive Learning for Code Retrieval and Summarization via Semantic-Preserving Transformations" [2020-09] [SIGIR 2021] [<a href="https://arxiv.org/abs/2009.02731" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"REINFOREST: Reinforcing Semantic Code Similarity for Cross-Lingual Code Search Models" [2023-05] [<a href="https://arxiv.org/abs/2305.03843" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search" [2024-01] [ACL 2024] [<a href="https://arxiv.org/abs/2401.04514" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Revisiting Code Similarity Evaluation with Abstract Syntax Tree Edit Distance" [2024-04] [ACL 2024 short] [<a href="https://arxiv.org/abs/2404.08817" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Is Next Token Prediction Sufficient for GPT? Exploration on Code Logic Comprehension" [2024-04] [<a href="https://arxiv.org/abs/2404.08885" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Refining Joint Text and Source Code Embeddings for Retrieval Task with Parameter-Efficient Fine-Tuning" [2024-05] [<a href="https://arxiv.org/abs/2405.04126" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Typhon: Automatic Recommendation of Relevant Code Cells in Jupyter Notebooks" [2024-05] [<a href="https://arxiv.org/abs/2405.09075" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Toward Exploring the Code Understanding Capabilities of Pre-trained Code Generation Models" [2024-06] [<a href="https://arxiv.org/abs/2406.12326" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Aligning Programming Language and Natural Language: Exploring Design Choices in Multi-Modal Transformer-Based Embedding for Bug Localization" [2024-06] [<a href="https://arxiv.org/abs/2406.17615" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Assessing the Code Clone Detection Capability of Large Language Models" [2024-07] [<a href="https://arxiv.org/abs/2407.02402" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeCSE: A Simple Multilingual Model for Code and Comment Sentence Embeddings" [2024-07] [<a href="https://arxiv.org/abs/2407.06360" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Models for cross-language code clone detection" [2024-08] [<a href="https://arxiv.org/abs/2408.04430" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Coding-PTMs: How to Find Optimal Code Pre-trained Models for Code Embedding in Vulnerability Detection?" [2024-08] [<a href="https://arxiv.org/abs/2408.04863" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"You Augment Me: Exploring ChatGPT-based Data Augmentation for Semantic Code Search" [2024-08] [<a href="https://arxiv.org/abs/2408.05542" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Improving Source Code Similarity Detection Through GraphCodeBERT and Integration of Additional Features" [2024-08] [<a href="https://arxiv.org/abs/2408.08903" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM Agents Improve Semantic Code Search" [2024-08] [<a href="https://arxiv.org/abs/2408.11058" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"zsLLMCode: An Effective Approach for Functional Code Embedding via LLM with Zero-Shot Learning" [2024-09] [<a href="https://arxiv.org/abs/2409.14644" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Exploring Demonstration Retrievers in RAG for Coding Tasks: Yeas and Nays!" [2024-10] [<a href="https://arxiv.org/abs/2410.09662" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Instructive Code Retriever: Learn from Large Language Model's Feedback for Code Intelligence Tasks" [2024-10] [<a href="https://arxiv.org/abs/2410.11300" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Binary Code Similarity Detection via Graph Contrastive Learning on Intermediate Representations" [2024-10] [<a href="https://arxiv.org/abs/2410.18561" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Are Decoder-Only Large Language Models the Silver Bullet for Code Search?" [2024-10] [<a href="https://arxiv.org/abs/2410.22240" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeXEmbed: A Generalist Embedding Model Family for Multiligual and Multi-task Code Retrieval" [2024-11] [<a href="https://arxiv.org/abs/2411.12644" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeSAM: Source Code Representation Learning by Infusing Self-Attention with Multi-Code-View Graphs" [2024-11] [<a href="https://arxiv.org/abs/2411.14611" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"EnStack: An Ensemble Stacking Framework of Large Language Models for Enhanced Vulnerability Detection in Source Code" [2024-11] [<a href="https://arxiv.org/abs/2411.16561" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Isotropy Matters: Soft-ZCA Whitening of Embeddings for Semantic Code Search" [2024-11] [<a href="https://arxiv.org/abs/2411.17538" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Optimizing Code Retrieval: High-Quality and Scalable Dataset Annotation through Large Language Models" [2024-11] [EMNLP 2024] [<a href="https://aclanthology.org/2024.emnlp-main.123/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing Learning-Based Binary Code Similarity Detection Model through Adversarial Training with Multiple Function Variants" [2024-11] [EMNLP 2024 Findings] [<a href="https://aclanthology.org/2024.findings-emnlp.673/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CoRNStack: High-Quality Contrastive Data for Better Code Retrieval and Reranking" [2024-12] [ICLR 2025] [<a href="https://arxiv.org/abs/2412.01007" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"OASIS: Order-Augmented Strategy for Improved Code Search" [2025-03] [ACL 2025] [<a href="https://arxiv.org/abs/2503.08161" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Zero-Shot Cross-Domain Code Search without Fine-Tuning" [2025-04] [<a href="https://arxiv.org/abs/2504.07740" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LEANCODE: Understanding Models Better for Code Simplification of Pre-trained Large Language Models" [2025-05] [ACL 2025] [<a href="https://arxiv.org/abs/2505.14759" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CoRet: Improved Retriever for Code Editing" [2025-05] [ACL 2025] [<a href="https://arxiv.org/abs/2505.24715" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Efficient Code Embeddings from Code Generation Models" [2025-08] [<a href="https://arxiv.org/abs/2508.21290" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Code Refactoring and Migration</h3><a id="user-content-code-refactoring-and-migration" class="anchor" aria-label="Permalink: Code Refactoring and Migration" href="#code-refactoring-and-migration"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"An Empirical Study on the Code Refactoring Capability of Large Language Models" [2024-11] [<a href="https://arxiv.org/abs/2411.02320" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automated Update of Android Deprecated API Usages with Large Language Models" [2024-11] [<a href="https://arxiv.org/abs/2411.04387" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Empirical Study on the Potential of LLMs in Automated Software Refactoring" [2024-11] [<a href="https://arxiv.org/abs/2411.04444" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CODECLEANER: Elevating Standards with A Robust Data Contamination Mitigation Toolkit" [2024-11] [<a href="https://arxiv.org/abs/2411.10842" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Instruct or Interact? Exploring and Eliciting LLMs' Capability in Code Snippet Adaptation Through Prompt Engineering" [2024-11] [<a href="https://arxiv.org/abs/2411.15501" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Generating refactored code accurately using reinforcement learning" [2024-12] [<a href="https://arxiv.org/abs/2412.18035" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How is Google using AI for internal code migrations?" [2025-01] [<a href="https://arxiv.org/abs/2501.06972" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automated Refactoring of Non-Idiomatic Python Code: A Differentiated Replication with LLMs" [2025-01] [<a href="https://arxiv.org/abs/2501.17024" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Autonomous Legacy Web Application Upgrades Using a Multi-Agent System" [2025-01] [<a href="https://arxiv.org/abs/2501.19204" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating the Effectiveness of LLMs in Fixing Maintainability Issues in Real-World Projects" [2025-02] [<a href="https://arxiv.org/abs/2502.02368" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Distributed Approach to Haskell Based Applications Refactoring with LLMs Based Multi-Agent Systems" [2025-02] [<a href="https://arxiv.org/abs/2502.07928" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RefactorBench: Evaluating Stateful Reasoning in Language Agents Through Code" [2025-03] [ICLR 2025] [<a href="https://arxiv.org/abs/2503.07832" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MANTRA: Enhancing Automated Method-Level Refactoring with Contextual RAG and Multi-Agent LLM Collaboration" [2025-03] [<a href="https://arxiv.org/abs/2503.14340" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ECO: An LLM-Driven Efficient Code Optimizer for Warehouse Scale Computers" [2025-03] [<a href="https://arxiv.org/abs/2503.15669" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Migrating Code At Scale With LLMs At Google" [2025-04] [<a href="https://arxiv.org/abs/2504.09691" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Using LLMs for Library Migration" [2025-04] [<a href="https://arxiv.org/abs/2504.13272" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Leveraging LLMs to Automate Energy-Aware Refactoring of Parallel Scientific Codes" [2025-05] [<a href="https://arxiv.org/abs/2505.02184" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MIGRATION-BENCH: Repository-Level Code Migration Benchmark from Java 8" [2025-05] [<a href="https://arxiv.org/abs/2505.09569" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CODEMENV: Benchmarking Large Language Models on Code Migration" [2025-05] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2506.00894" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Type Prediction</h3><a id="user-content-type-prediction" class="anchor" aria-label="Permalink: Type Prediction" href="#type-prediction"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Learning type annotation: is big data enough?" [2021-08] [ESEC/FSE 2021] [<a href="https://dl.acm.org/doi/10.1145/3468264.3473135" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Do Machine Learning Models Produce TypeScript Types That Type Check?" [2023-02] [ECOOP 2023] [<a href="https://arxiv.org/abs/2302.12163" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"TypeT5: Seq2seq Type Inference using Static Analysis" [2023-03] [ICLR 2023] [<a href="https://arxiv.org/abs/2303.09564" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Type Prediction With Program Decomposition and Fill-in-the-Type Training" [2023-05] [<a href="https://arxiv.org/abs/2305.17145" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Generative Type Inference for Python" [2023-07] [ASE 2023] [<a href="https://arxiv.org/abs/2307.09163" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Activation Steering for Robust Type Prediction in CodeLLMs" [2024-04] [<a href="https://arxiv.org/abs/2404.01903" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Empirical Study of Large Language Models for Type and Call Graph Analysis" [2024-10] [<a href="https://arxiv.org/abs/2410.00603" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Repository-Level Coding</h3><a id="user-content-repository-level-coding" class="anchor" aria-label="Permalink: Repository-Level Coding" href="#repository-level-coding"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Repository-Level Prompt Generation for Large Language Models of Code" [2022-06] [ICML 2023] [<a href="https://arxiv.org/abs/2206.12839" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CoCoMIC: Code Completion By Jointly Modeling In-file and Cross-file Context" [2022-12] [<a href="https://arxiv.org/abs/2212.10007" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation" [2023-03] [EMNLP 2023] [<a href="https://arxiv.org/abs/2303.12570" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Coeditor: Leveraging Repo-level Diffs for Code Auto-editing" [2023-05] [ICLR 2024 Spotlight] [<a href="https://arxiv.org/abs/2305.18584" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems" [2023-06] [ICLR 2024] [<a href="https://arxiv.org/abs/2306.03091" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Guiding Language Models of Code with Global Context using Monitors" [2023-06] [<a href="https://arxiv.org/abs/2306.10763" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RepoFusion: Training Code Models to Understand Your Repository" [2023-06] [<a href="https://arxiv.org/abs/2306.10998" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodePlan: Repository-level Coding using LLMs and Planning" [2023-09] [<a href="https://arxiv.org/abs/2306.10998" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code Completion" [2023-10] [NeurIPS 2023] [<a href="https://arxiv.org/abs/2310.11248" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A^3-CodGen: A Repository-Level Code Generation Framework for Code Reuse with Local-Aware, Global-Aware, and Third-Party-Library-Aware" [2023-12] [<a href="https://arxiv.org/abs/2312.05772" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Teaching Code LLMs to Use Autocompletion Tools in Repository-Level Code Generation" [2024-01] [<a href="https://arxiv.org/abs/2401.06391" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RepoHyper: Better Context Retrieval Is All You Need for Repository-Level Code Completion" [2024-03] [<a href="https://arxiv.org/abs/2403.06095" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Repoformer: Selective Retrieval for Repository-Level Code Completion" [2024-03] [ICML 2024] [<a href="https://arxiv.org/abs/2403.10059" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeS: Natural Language to Code Repository via Multi-Layer Sketch" [2024-03] [<a href="https://arxiv.org/abs/2403.16443" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Class-Level Code Generation from Natural Language Using Iterative, Tool-Enhanced Reasoning over Repository" [2024-04] [<a href="https://arxiv.org/abs/2405.01573" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Contextual API Completion for Unseen Repositories Using LLMs" [2024-05] [<a href="https://arxiv.org/abs/2405.04600" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Dataflow-Guided Retrieval Augmentation for Repository-Level Code Completion" [2024-05][ACL 2024] [<a href="https://arxiv.org/abs/2405.19782" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How to Understand Whole Software Repository?" [2024-06] [<a href="https://arxiv.org/abs/2406.01422" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"R2C2-Coder: Enhancing and Benchmarking Real-world Repository-level Code Completion Abilities of Code Large Language Models" [2024-06] [<a href="https://arxiv.org/abs/2406.01359" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing Repository-Level Code Generation with Integrated Contextual Information" [2024-06] [<a href="https://arxiv.org/abs/2406.03283" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"On The Importance of Reasoning for Context Retrieval in Repository-Level Code Editing" [2024-06] [<a href="https://arxiv.org/abs/2406.04464" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"GraphCoder: Enhancing Repository-Level Code Completion via Code Context Graph-based Retrieval and Language Model" [2024-06] [ASE 2024] [<a href="https://arxiv.org/abs/2406.07003" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"STALL+: Boosting LLM-based Repository-level Code Completion with Static Analysis" [2024-06] [<a href="https://arxiv.org/abs/2406.10018" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Hierarchical Context Pruning: Optimizing Real-World Code Completion with Repository-Level Pretrained Code LLMs" [2024-06] [<a href="https://arxiv.org/abs/2406.18294" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RLCoder: Reinforcement Learning for Repository-Level Code Completion" [2024-07] [<a href="https://arxiv.org/abs/2407.19487" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CoEdPilot: Recommending Code Edits with Learned Prior Edit Relevance, Project-wise Awareness, and Interactive Nature" [2024-08] [<a href="https://arxiv.org/abs/2408.01733" rel="nofollow">paper</a>] [<a href="https://github.com/code-philia/CoEdPilot">repo</a>]</p>
</li>
<li>
<p dir="auto">"RAMBO: Enhancing RAG-based Repository-Level Method Body Completion" [2024-09] [<a href="https://arxiv.org/abs/2409.15204" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RepoGraph: Enhancing AI Software Engineering with Repository-level Code Graph" [2024-10] [ICLR 2025] [<a href="https://arxiv.org/abs/2410.14684" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"See-Saw Generative Mechanism for Scalable Recursive Code Generation with Generative AI" [2024-11] [<a href="https://arxiv.org/abs/2411.10861" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Beyond pip install: Evaluating LLM Agents for the Automated Installation of Python Projects" [2024-12] [<a href="https://arxiv.org/abs/2412.06294" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ContextModule: Improving Code Completion via Repository-level Contextual Information" [2024-12] [<a href="https://arxiv.org/abs/2412.08063" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MutaGReP: Execution-Free Repository-Grounded Plan Search for Code-Use" [2025-02] [<a href="https://arxiv.org/abs/2502.15872" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"aiXcoder-7B-v2: Training LLMs to Fully Utilize the Long Context in Repository-level Code Completion" [2025-03] [<a href="https://arxiv.org/abs/2503.15301" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing Repository-Level Software Repair via Repository-Aware Knowledge Graphs" [2025-03] [<a href="https://arxiv.org/abs/2503.21710" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SRLCG: Self-Rectified Large-Scale Code Generation with Multidimensional Chain-of-Thought and Dynamic Backtracking" [2025-04] [<a href="https://arxiv.org/abs/2504.00532" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Knowledge Graph Based Repository-Level Code Generation" [2025-05] [<a href="https://arxiv.org/abs/2505.14394" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks" [2025-05] [<a href="https://arxiv.org/abs/2505.16901" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Empirical Study on Strong-Weak Model Collaboration for Repo-level Code Generation" [2025-05] [<a href="https://arxiv.org/abs/2505.20182" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion" [2025-08] [<a href="https://arxiv.org/abs/2508.10068" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"GRACE: Graph-Guided Repository-Aware Code Completion through Hierarchical Code Fusion" [2025-09] [<a href="https://arxiv.org/abs/2509.05980" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeRAG: Finding Relevant and Necessary Knowledge for Retrieval-Augmented Repository-Level Code Completion" [2025-09] [<a href="https://arxiv.org/abs/2509.16112" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation" [2025-09] [<a href="https://arxiv.org/abs/2509.16198" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"On Pretraining for Project-Level Code Completion" [2025-10] [<a href="https://arxiv.org/abs/2510.13697" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Issue Resolution</h3><a id="user-content-issue-resolution" class="anchor" aria-label="Permalink: Issue Resolution" href="#issue-resolution"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"SWE-bench: Can Language Models Resolve Real-World GitHub Issues?" [2023-10] [ICLR 2024] [<a href="https://arxiv.org/abs/2310.06770" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeR: Issue Resolving with Multi-Agent and Task Graphs" [2024-06] [<a href="https://arxiv.org/abs/2406.01304" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Agentless: Demystifying LLM-based Software Engineering Agents" [2024-07] [<a href="https://arxiv.org/abs/2407.01489" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Exploring the Potential of Conversational Test Suite Based Program Repair on SWE-bench" [2024-10] [<a href="https://arxiv.org/abs/2410.04485" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Repository Structure-Aware Training Makes SLMs Better Issue Resolver" [2024-12] [<a href="https://arxiv.org/abs/2412.19031" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"PatchPilot: A Cost-Efficient Software Engineering Agent with Early Attempts on Formal Verification" [2025-02] [ICML 2025] [<a href="https://arxiv.org/abs/2502.02747" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SWE-Synth: Synthesizing Verifiable Bug-Fix Data to Enable Large Language Models in Resolving Real-World Bugs" [2025-04] [<a href="https://arxiv.org/abs/2504.14757" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Guided Search Strategies in Non-Serializable Environments with Applications to Software Engineering Agents" [2025-05] [ICML 2025] [<a href="https://arxiv.org/abs/2505.13652" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SWE-Dev: Building Software Engineering Agents with Training and Inference Scaling" [2025-06] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2506.07636" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SWE-Flow: Synthesizing Software Engineering Data in a Test-Driven Manner" [2025-06] [ICML 2025] [<a href="https://arxiv.org/abs/2506.09003" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"UTBoost: Rigorous Evaluation of Coding Agents on SWE-Bench" [2025-06] [ACL 2025] [<a href="https://arxiv.org/abs/2506.09289" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The SWE-Bench Illusion: When State-of-the-Art LLMs Remember Instead of Reason" [2025-06] [<a href="https://arxiv.org/abs/2506.12286" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs" [2025-06] [<a href="https://arxiv.org/abs/2506.19290" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SWE-Bench-CL: Continual Learning for Coding Agents" [2025-06] [<a href="https://arxiv.org/abs/2507.00014" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution" [2025-07] [<a href="https://arxiv.org/abs/2507.23348" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SWE-Exp: Experience-Driven Software Issue Resolution" [2025-07] [<a href="https://arxiv.org/abs/2507.23361" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning" [2025-08] [<a href="https://arxiv.org/abs/2508.03501" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Empirical Study on Failures in Automated Issue Solving" [2025-09] [<a href="https://arxiv.org/abs/2509.13941" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Frontend Development</h3><a id="user-content-frontend-development" class="anchor" aria-label="Permalink: Frontend Development" href="#frontend-development"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Seeking the user interface", 2014-09, ASE 2014, [<a href="https://dl.acm.org/doi/10.1145/2642937.2642976" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"pix2code: Generating Code from a Graphical User Interface Screenshot", 2017-05, EICS 2018, [<a href="https://arxiv.org/abs/1705.07962" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Machine Learning-Based Prototyping of Graphical User Interfaces for Mobile Apps", 2018-02, TSE 2020, [<a href="https://arxiv.org/abs/1802.02312" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automatic HTML Code Generation from Mock-Up Images Using Machine Learning Techniques", 2019-04, EBBT 2019, [<a href="https://ieeexplore.ieee.org/abstract/document/8741736" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Sketch2code: Generating a website from a paper mockup", 2019-05, [<a href="https://arxiv.org/abs/1905.13750" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"HTLM: Hyper-Text Pre-Training and Prompting of Language Models", 2021-07, ICLR 2022, [<a href="https://arxiv.org/abs/2107.06955" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Learning UI-to-Code Reverse Generator Using Visual Critic Without Rendering", 2023-05, [<a href="https://arxiv.org/abs/2305.14637" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Design2Code: How Far Are We From Automating Front-End Engineering?" [2024-03] [<a href="https://arxiv.org/abs/2403.03163" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Unlocking the conversion of Web Screenshots into HTML Code with the WebSight Dataset" [2024-03] [<a href="https://arxiv.org/abs/2403.09029" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"VISION2UI: A Real-World Dataset with Layout for Code Generation from UI Designs" [2024-04] [<a href="https://arxiv.org/abs/2404.06369" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LogoMotion: Visually Grounded Code Generation for Content-Aware Animation" [2024-05] [<a href="https://arxiv.org/abs/2405.07065" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"PosterLLaVa: Constructing a Unified Multi-modal Layout Generator with LLM" [2024-06] [<a href="https://arxiv.org/abs/2406.02884" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"UICoder: Finetuning Large Language Models to Generate User Interface Code through Automated Feedback" [2024-06] [<a href="https://arxiv.org/abs/2406.07739" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"On AI-Inspired UI-Design" [2024-06] [<a href="https://arxiv.org/abs/2406.13631" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Identifying User Goals from UI Trajectories" [2024-06] [<a href="https://arxiv.org/abs/2406.14314" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automatically Generating UI Code from Screenshot: A Divide-and-Conquer-Based Approach" [2024-06] [<a href="https://arxiv.org/abs/2406.16386" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework for Multimodal LLMs" [2024-06] [NeurIPS 2024] [<a href="https://arxiv.org/abs/2406.20098" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Vision-driven Automated Mobile GUI Testing via Multimodal Large Language Model" [2024-07] [<a href="https://arxiv.org/abs/2407.03037" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AUITestAgent: Automatic Requirements Oriented GUI Function Testing" [2024-07] [<a href="https://arxiv.org/abs/2407.09018" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM-based Abstraction and Concretization for GUI Test Migration" [2024-09] [<a href="https://arxiv.org/abs/2409.05028" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enabling Cost-Effective UI Automation Testing with Retrieval-Based LLMs: A Case Study in WeChat" [2024-09] [<a href="https://arxiv.org/abs/2409.07829" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Self-Elicitation of Requirements with Automated GUI Prototyping" [2024-09] [<a href="https://arxiv.org/abs/2409.16388" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Infering Alt-text For UI Icons With Large Language Models During App Development" [2024-09] [<a href="https://arxiv.org/abs/2409.18060" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Leveraging Large Vision Language Model For Better Automatic Web GUI Testing" [2024-10] [<a href="https://arxiv.org/abs/2410.12157" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Sketch2Code: Evaluating Vision-Language Models for Interactive Web Design Prototyping" [2024-10] [<a href="https://arxiv.org/abs/2410.16232" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WAFFLE: Multi-Modal Model for Automated Front-End Development" [2024-10] [<a href="https://arxiv.org/abs/2410.18362" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DesignRepair: Dual-Stream Design Guideline-Aware Frontend Repair with Large Language Models" [2024-11] [<a href="https://arxiv.org/abs/2411.01606" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Interaction2Code: How Far Are We From Automatic Interactive Webpage Generation?" [2024-11] [<a href="https://arxiv.org/abs/2411.03292" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs" [2024-11] [<a href="https://arxiv.org/abs/2411.07098" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automated Test Transfer Across Android Apps Using Large Language Models" [2024-11] [<a href="https://arxiv.org/abs/2411.17933" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Zero-Shot Prompting Approaches for LLM-based Graphical User Interface Generation" [2024-12] [<a href="https://arxiv.org/abs/2412.11328" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MRWeb: An Exploration of Generating Multi-Page Resource-Aware Web Code from UI Designs" [2024-12] [<a href="https://arxiv.org/abs/2412.15310" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Combining Language and App UI Analysis for the Automated Assessment of Bug Reproduction Steps" [2025-02] [<a href="https://arxiv.org/abs/2502.04251" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ReaderLM-v2: Small Language Model for HTML to Markdown and JSON" [2025-03] [<a href="https://arxiv.org/abs/2503.01151" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional Websites from Scratch" [2025-05] [<a href="https://arxiv.org/abs/2505.03733" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Web-Bench: A LLM Code Benchmark Based on Web Standards and Frameworks" [2025-05] [<a href="https://arxiv.org/abs/2505.07473" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WebUIBench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in WebUI-to-Code" [2025-06] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2506.07818" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A11YN: aligning LLMs for accessible web UI code generation" [2025-10] [<a href="https://arxiv.org/abs/2510.13914" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WebDevJudge: Evaluating (M)LLMs as Critiques for Web Development Quality" [2025-10] [<a href="https://arxiv.org/abs/2510.18560" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Automated Machine Learning</h3><a id="user-content-automated-machine-learning" class="anchor" aria-label="Permalink: Automated Machine Learning" href="#automated-machine-learning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Large Language Models Synergize with Automated Machine Learning" [2024-05] [<a href="https://arxiv.org/abs/2405.03727" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML" [2024-10] [<a href="https://arxiv.org/abs/2410.02958" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering" [2024-10] [<a href="https://arxiv.org/abs/2410.07095" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"UniAutoML: A Human-Centered Framework for Unified Discriminative and Generative AutoML with Large Language Models" [2024-10] [<a href="https://arxiv.org/abs/2410.12841" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"BudgetMLAgent: A Cost-Effective LLM Multi-Agent system for Automating Machine Learning Tasks" [2024-11] [<a href="https://arxiv.org/abs/2411.07464" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Performance of the LSTM-based Code Generated by Large Language Models (LLMs) in Forecasting Time Series Data" [2024-11] [<a href="https://arxiv.org/abs/2411.18731" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ML-Dev-Bench: Comparative Analysis of AI Agents on ML development workflows" [2025-02] [<a href="https://arxiv.org/abs/2502.00964" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CSR-Bench: Benchmarking LLM Agents in Deployment of Computer Science Research Repositories" [2025-02] [<a href="https://arxiv.org/abs/2502.06111" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AIDE: AI-Driven Exploration in the Space of Code" [2025-02] [<a href="https://arxiv.org/abs/2502.13138" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MLGym: A New Framework and Benchmark for Advancing AI Research Agents" [2025-02] [<a href="https://arxiv.org/abs/2502.14499" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MAS-GPT: Training LLMs to Build LLM-based Multi-Agent Systems" [2025-03] [<a href="https://arxiv.org/abs/2503.03686" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SciReplicate-Bench: Benchmarking LLMs in Agent-driven Algorithmic Reproduction from Research Papers" [2025-03] [<a href="https://arxiv.org/abs/2504.00255" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"PaperBench: Evaluating AI's Ability to Replicate AI Research" [2025-04] [<a href="https://arxiv.org/abs/2504.01848" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning" [2025-04] [<a href="https://arxiv.org/abs/2504.17192" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AutoP2C: An LLM-Based Agent Framework for Code Repository Generation from Multimodal Content in Academic Papers" [2025-04] [<a href="https://arxiv.org/abs/2504.20115" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ResearchCodeAgent: An LLM Multi-Agent System for Automated Codification of Research Methodologies" [2025-04] [<a href="https://arxiv.org/abs/2504.20117" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MLZero: A Multi-Agent System for End-to-end Machine Learning Automation" [2025-05] [<a href="https://arxiv.org/abs/2505.13941" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research" [2025-05] [<a href="https://arxiv.org/abs/2505.19955" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ResearchCodeBench: Benchmarking LLMs on Implementing Novel Machine Learning Research Code" [2025-06] [<a href="https://arxiv.org/abs/2506.02314" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"From Reproduction to Replication: Evaluating Research Agents with Progressive Code Masking" [2025-06] [<a href="https://arxiv.org/abs/2506.19724" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench" [2025-07] [<a href="https://arxiv.org/abs/2507.02554" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ML2B: Multi-Lingual ML Benchmark For AutoML" [2025-09] [<a href="https://arxiv.org/abs/2509.22768" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RECODE-H: A Benchmark for Research Code Development with Interactive Human Feedback" [2025-10] [<a href="https://arxiv.org/abs/2510.06186" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AutoMLGen: Navigating Fine-Grained Optimization for Coding Agents" [2025-10] [<a href="https://arxiv.org/abs/2510.08511" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Text-To-SQL</h3><a id="user-content-text-to-sql" class="anchor" aria-label="Permalink: Text-To-SQL" href="#text-to-sql"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models" [2021-09] [EMNLP 2021] [<a href="https://arxiv.org/abs/2109.05093" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodexDB: Generating Code for Processing SQL Queries using GPT-3 Codex" [2022-04] [<a href="https://arxiv.org/abs/2204.08941" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"T5QL: Taming language models for SQL generation" [2022-09] [<a href="https://arxiv.org/abs/2209.10254" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards Generalizable and Robust Text-to-SQL Parsing" [2022-10] [EMNLP 2022 Findings] [<a href="https://arxiv.org/abs/2210.12674" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"XRICL: Cross-lingual Retrieval-Augmented In-Context Learning for Cross-lingual Text-to-SQL Semantic Parsing" [2022-10] [EMNLP 2022 Findings] [<a href="https://arxiv.org/abs/2210.13693" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A comprehensive evaluation of ChatGPT's zero-shot Text-to-SQL capability" [2023-03] [<a href="https://arxiv.org/abs/2303.13547" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction" [2023-04] [NeurIPS 2023] [<a href="https://arxiv.org/abs/2304.11015" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings" [2023-05] [<a href="https://arxiv.org/abs/2305.11853" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing Few-shot Text-to-SQL Capabilities of Large Language Models: A Study on Prompt Design Strategies" [2023-05] [<a href="https://arxiv.org/abs/2305.12586" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SQL-PaLM: Improved Large Language Model Adaptation for Text-to-SQL" [2023-05] [<a href="https://arxiv.org/abs/2306.00739" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Retrieval-augmented GPT-3.5-based Text-to-SQL Framework with Sample-aware Prompting and Dynamic Revision Chain" [2023-07] [ICONIP 2023] [<a href="https://arxiv.org/abs/2307.05074" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation" [2023-08] [<a href="https://arxiv.org/abs/2308.15363" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MAC-SQL: A Multi-Agent Collaborative Framework for Text-to-SQL" [2023-12] [<a href="https://arxiv.org/abs/2312.11242" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models" [2024-02] [EMNLP 2024 Findings] [<a href="https://arxiv.org/abs/2402.01117" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Improving Demonstration Diversity by Human-Free Fusing for Text-to-SQL" [2024-02] [EMNLP 2024 Findings] [<a href="https://arxiv.org/abs/2402.10663" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Decomposition for Enhancing Attention: Improving LLM-based Text-to-SQL through Workflow Paradigm" [2024-02] [ACL 2024 Findings] [<a href="https://arxiv.org/abs/2402.10671" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Knowledge-to-SQL: Enhancing SQL Generation with Data Expert LLM" [2024-02] [ACL 2024 Findings] [<a href="https://arxiv.org/abs/2402.11517" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Understanding the Effects of Noise in Text-to-SQL: An Examination of the BIRD-Bench Benchmark" [2024-02] [ACL 2024 short] [<a href="https://arxiv.org/abs/2402.12243" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Structure Guided Large Language Model for SQL Generation" [2024-02] [ICML 2025] [<a href="https://arxiv.org/abs/2402.13284" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SQL-Encoder: Improving NL2SQL In-Context Learning Through a Context-Aware Encoder" [2024-03] [<a href="https://arxiv.org/abs/2403.16204" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM-R2: A Large Language Model Enhanced Rule-based Rewrite System for Boosting Query Efficiency" [2024-04] [<a href="https://arxiv.org/abs/2404.12872" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Dubo-SQL: Diverse Retrieval-Augmented Generation and Fine Tuning for Text-to-SQL" [2024-04] [<a href="https://arxiv.org/abs/2404.12560" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"EPI-SQL: Enhancing Text-to-SQL Translation with Error-Prevention Instructions" [2024-04] [<a href="https://arxiv.org/abs/2404.14453" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ProbGate at EHRSQL 2024: Enhancing SQL Query Generation Accuracy through Probabilistic Threshold Filtering and Error Handling" [2024-04] [<a href="https://arxiv.org/abs/2404.16659" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CoE-SQL: In-Context Learning for Multi-Turn Text-to-SQL with Chain-of-Editions" [2024-05] [<a href="https://arxiv.org/abs/2405.02712" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Open-SQL Framework: Enhancing Text-to-SQL on Open-source Large Language Models" [2024-05] [<a href="https://arxiv.org/abs/2405.06674" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MCS-SQL: Leveraging Multiple Prompts and Multiple-Choice Selection For Text-to-SQL Generation" [2024-05] [<a href="https://arxiv.org/abs/2405.07467" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"PromptMind Team at EHRSQL-2024: Improving Reliability of SQL Generation using Ensemble LLMs" [2024-05] [<a href="https://arxiv.org/abs/2405.08839" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LG AI Research &amp; KAIST at EHRSQL 2024: Self-Training Large Language Models with Pseudo-Labeled Unanswerable Questions for a Reliable Text-to-SQL System on EHRs" [2024-05] [<a href="https://arxiv.org/abs/2405.11162" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Before Generation, Align it! A Novel and Effective Strategy for Mitigating Hallucinations in Text-to-SQL Generation" [2024-05] [ACL 2024 Findings] [<a href="https://arxiv.org/abs/2405.15307" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CHESS: Contextual Harnessing for Efficient SQL Synthesis" [2024-05] [<a href="https://arxiv.org/abs/2405.16755" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DeTriever: Decoder-representation-based Retriever for Improving NL2SQL In-Context Learning" [2024-06] [<a href="https://arxiv.org/abs/2406.07913" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Next-Generation Database Interfaces: A Survey of LLM-based Text-to-SQL" [2024-06] [<a href="https://arxiv.org/abs/2406.08426" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RH-SQL: Refined Schema and Hardness Prompt for Text-to-SQL" [2024-06] [<a href="https://arxiv.org/abs/2406.09133" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"QDA-SQL: Questions Enhanced Dialogue Augmentation for Multi-Turn Text-to-SQL" [2024-06] [<a href="https://arxiv.org/abs/2406.10593" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"End-to-end Text-to-SQL Generation within an Analytics Insight Engine" [2024-06] [<a href="https://arxiv.org/abs/2406.12104" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MAGIC: Generating Self-Correction Guideline for In-Context Text-to-SQL" [2024-06] [<a href="https://arxiv.org/abs/2406.12692" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SQLFixAgent: Towards Semantic-Accurate SQL Generation via Multi-Agent Collaboration" [2024-06] [<a href="https://arxiv.org/abs/2406.13408" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Unmasking Database Vulnerabilities: Zero-Knowledge Schema Inference Attacks in Text-to-SQL Systems" [2024-06] [<a href="https://arxiv.org/abs/2406.14545" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning" [2024-07] [EMNLP 2024] [<a href="https://arxiv.org/abs/2407.03227" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Lucy: Think and Reason to Solve Text-to-SQL" [2024-07] [<a href="https://arxiv.org/abs/2407.05153" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ESM+: Modern Insights into Perspective on Text-to-SQL Evaluation in the Age of Large Language Models" [2024-07] [<a href="https://arxiv.org/abs/2407.07313" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RB-SQL: A Retrieval-based LLM Framework for Text-to-SQL" [2024-07] [<a href="https://arxiv.org/abs/2407.08273" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AI-Assisted SQL Authoring at Industry Scale" [2024-07] [<a href="https://arxiv.org/abs/2407.13280" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SQLfuse: Enhancing Text-to-SQL Performance through Comprehensive LLM Synergy" [2024-07] [<a href="https://arxiv.org/abs/2407.14568" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Survey on Employing Large Language Models for Text-to-SQL Tasks" [2024-07] [<a href="https://arxiv.org/abs/2407.15186" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards Automated Data Sciences with Natural Language and SageCopilot: Practices and Lessons Learned" [2024-07] [<a href="https://arxiv.org/abs/2407.21040" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating LLMs for Text-to-SQL Generation With Complex SQL Workload" [2024-07] [<a href="https://arxiv.org/abs/2407.19517" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Synthesizing Text-to-SQL Data from Weak and Strong LLMs" [2024-08] [ACL 2024] [<a href="https://arxiv.org/abs/2408.03256" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Improving Relational Database Interactions with Large Language Models: Column Descriptions and Their Impact on Text-to-SQL Performance" [2024-08] [<a href="https://arxiv.org/abs/2408.04691" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models" [2024-08] [<a href="https://arxiv.org/abs/2408.07702" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MAG-SQL: Multi-Agent Generative Approach with Soft Schema Linking and Iterative Sub-SQL Refinement for Text-to-SQL" [2024-08] [<a href="https://arxiv.org/abs/2408.07930" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing Text-to-SQL Parsing through Question Rewriting and Execution-Guided Refinement" [2024-08] [ACL 2024 Findings] [<a href="https://aclanthology.org/2024.findings-acl.120/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DAC: Decomposed Automation Correction for Text-to-SQL" [2024-08] [<a href="https://arxiv.org/abs/2408.08779" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Interactive-T2S: Multi-Turn Interactions for Text-to-SQL with Large Language Models" [2024-08] [<a href="https://arxiv.org/abs/2408.11062" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SQL-GEN: Bridging the Dialect Gap for Text-to-SQL Via Synthetic Data And Model Merging" [2024-08] [<a href="https://arxiv.org/abs/2408.12733" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing SQL Query Generation with Neurosymbolic Reasoning" [2024-08] [<a href="https://arxiv.org/abs/2408.13888" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Text2SQL is Not Enough: Unifying AI and Databases with TAG" [2024-08] [<a href="https://arxiv.org/abs/2408.14717" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Tool-Assisted Agent on SQL Inspection and Refinement in Real-World Scenarios" [2024-08] [<a href="https://arxiv.org/abs/2408.16991" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SelECT-SQL: Self-correcting ensemble Chain-of-Thought for Text-to-SQL" [2024-09] [<a href="https://arxiv.org/abs/2409.10007" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"You Only Read Once (YORO): Learning to Internalize Database Knowledge for Text-to-SQL" [2024-09] [<a href="https://arxiv.org/abs/2409.12172" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL" [2024-09] [EMNLP 2024] [<a href="https://arxiv.org/abs/2409.14082" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing Text-to-SQL Capabilities of Large Language Models via Domain Database Knowledge Injection" [2024-09] [<a href="https://arxiv.org/abs/2409.15907" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DataGpt-SQL-7B: An Open-Source Language Model for Text-to-SQL" [2024-09] [<a href="https://arxiv.org/abs/2409.15985" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"E-SQL: Direct Schema Linking via Question Enrichment in Text-to-SQL" [2024-09] [<a href="https://arxiv.org/abs/2409.16751" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"FLEX: Expert-level False-Less EXecution Metric for Reliable Text-to-SQL Benchmark" [2024-09] [<a href="https://arxiv.org/abs/2409.19014" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing LLM Fine-tuning for Text-to-SQLs by SQL Quality Measurement" [2024-10] [<a href="https://arxiv.org/abs/2410.01869" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"From Natural Language to SQL: Review of LLM-based Text-to-SQL Systems" [2024-10] [<a href="https://arxiv.org/abs/2410.01066" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CHASE-SQL: Multi-Path Reasoning and Preference Optimized Candidate Selection in Text-to-SQL" [2024-10] [ICLR 2025] [<a href="https://arxiv.org/abs/2410.01943" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Context-Aware SQL Error Correction Using Few-Shot Learning -- A Novel Approach Based on NLQ, Error, and SQL Similarity" [2024-10] [<a href="https://arxiv.org/abs/2410.09174" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Learning from Imperfect Data: Towards Efficient Knowledge Distillation of Autoregressive Language Models for Text-to-SQL" [2024-10] [EMNLP 2024 Findings] [<a href="https://arxiv.org/abs/2410.11371" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LR-SQL: A Supervised Fine-Tuning Method for Text2SQL Tasks under Low-Resource Scenarios" [2024-10] [<a href="https://arxiv.org/abs/2410.11457" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MSc-SQL: Multi-Sample Critiquing Small Language Models For Text-To-SQL Translation" [2024-10] [<a href="https://arxiv.org/abs/2410.12916" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Learning Metadata-Agnostic Representations for Text-to-SQL In-Context Example Selection" [2024-10] [<a href="https://arxiv.org/abs/2410.14049" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Actor-Critic Approach to Boosting Text-to-SQL Large Language Model" [2024-10] [<a href="https://arxiv.org/abs/2410.22082" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RSL-SQL: Robust Schema Linking in Text-to-SQL Generation" [2024-10] [<a href="https://arxiv.org/abs/2411.00073" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"KeyInst: Keyword Instruction for Improving SQL Formulation in Text-to-SQL" [2024-10] [<a href="https://arxiv.org/abs/2411.00788" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Grounding Natural Language to SQL Translation with Data-Based Self-Explanations" [2024-11] [<a href="https://arxiv.org/abs/2411.02948" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"PDC &amp; DM-SFT: A Road for LLM SQL Bug-Fix Enhancing" [2024-11] [<a href="https://arxiv.org/abs/2411.06767" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"XiYan-SQL: A Multi-Generator Ensemble Framework for Text-to-SQL" [2024-11] [<a href="https://arxiv.org/abs/2411.08599" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Leveraging Prior Experience: An Expandable Auxiliary Knowledge Base for Text-to-SQL" [2024-11] [<a href="https://arxiv.org/abs/2411.13244" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Text-to-SQL Calibration: No Need to Ask -- Just Rescale Model Probabilities" [2024-11] [<a href="https://arxiv.org/abs/2411.16742" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SecureSQL: Evaluating Data Leakage of Large Language Models as Natural Language Interfaces to Databases" [2024-11] [EMNLP 2024 Findings] [<a href="https://aclanthology.org/2024.findings-emnlp.346/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Survey of Large Language Model-Based Generative AI for Text-to-SQL: Benchmarks, Applications, Use Cases, and Challenges" [2024-12] [<a href="https://arxiv.org/abs/2412.05208" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Cooperative SQL Generation for Segmented Databases By Using Multi-functional LLM Agents" [2024-12] [<a href="https://arxiv.org/abs/2412.05850" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ROUTE: Robust Multitask Tuning and Collaboration for Text-to-SQL" [2024-12] [ICLR 2025] [<a href="https://arxiv.org/abs/2412.10138" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Solid-SQL: Enhanced Schema-linking based In-context Learning for Robust Text-to-SQL" [2024-12] [<a href="https://arxiv.org/abs/2412.12522" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating and Enhancing LLMs for Multi-turn Text-to-SQL with Multiple Question Types" [2024-12] [<a href="https://arxiv.org/abs/2412.17867" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Study of In-Context-Learning-Based Text-to-SQL Errors" [2025-01] [<a href="https://arxiv.org/abs/2501.09310" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Confidence Estimation for Error Detection in Text-to-SQL Systems" [2025-01] [<a href="https://arxiv.org/abs/2501.09527" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Reliable Text-to-SQL with Adaptive Abstention" [2025-01] [<a href="https://arxiv.org/abs/2501.10858" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Is Long Context All You Need? Leveraging LLM's Extended Context for NL2SQL" [2025-01] [<a href="https://arxiv.org/abs/2501.12372" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Text-to-SQL based on Large Language Models and Database Keyword Search" [2025-01] [<a href="https://arxiv.org/abs/2501.13594" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MCTS-SQL: An Effective Framework for Text-to-SQL with Monte Carlo Tree Search" [2025-01] [<a href="https://arxiv.org/abs/2501.16607" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Extractive Schema Linking for Text-to-SQL" [2025-01] [<a href="https://arxiv.org/abs/2501.17174" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ReFoRCE: A Text-to-SQL Agent with Self-Refinement, Format Restriction, and Column Exploration" [2025-02] [<a href="https://arxiv.org/abs/2502.00675" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"PSM-SQL: Progressive Schema Learning with Multi-granularity Semantics for Text-to-SQL" [2025-02] [<a href="https://arxiv.org/abs/2502.05237" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Rationalization Models for Text-to-SQL" [2025-02] [<a href="https://arxiv.org/abs/2502.06759" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"BASE-SQL: A powerful open source Text-To-SQL baseline approach" [2025-02] [<a href="https://arxiv.org/abs/2502.10739" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MultiTEND: A Multilingual Benchmark for Natural Language to NoSQL Query Translation" [2025-02] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2502.11022" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Bridging the Gap: Enabling Natural Language Queries for NoSQL Databases through Text-to-NoSQL Translation" [2025-02] [<a href="https://arxiv.org/abs/2502.11201" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SAFE-SQL: Self-Augmented In-Context Learning with Fine-grained Example Selection for Text-to-SQL" [2025-02] [<a href="https://arxiv.org/abs/2502.11438" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Uncovering the Impact of Chain-of-Thought Reasoning for Direct Preference Optimization: Lessons from Text-to-SQL" [2025-02] [ACL 2025] [<a href="https://arxiv.org/abs/2502.11656" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SQL-o1: A Self-Reward Heuristic Dynamic Search Method for Text-to-SQL" [2025-02] [<a href="https://arxiv.org/abs/2502.11741" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Knapsack Optimization-based Schema Linking for LLM-based Text-to-SQL Generation" [2025-02] [<a href="https://arxiv.org/abs/2502.12911" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"STaR-SQL: Self-Taught Reasoner for Text-to-SQL" [2025-02] [ACL 2025] [<a href="https://arxiv.org/abs/2502.13550" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Bridging the Gap: Transforming Natural Language Questions into SQL Queries via Abstract Query Pattern and Contextual Schema Markup" [2025-02] [<a href="https://arxiv.org/abs/2502.14682" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"OpenSearch-SQL: Enhancing Text-to-SQL with Dynamic Few-shot and Consistency Alignment" [2025-02] [<a href="https://arxiv.org/abs/2502.14913" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SQLong: Enhanced NL2SQL for Longer Contexts with LLMs" [2025-02] [<a href="https://arxiv.org/abs/2502.16747" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Alpha-SQL: Zero-Shot Text-to-SQL using Monte Carlo Tree Search" [2025-02] [ICML 2025] [<a href="https://arxiv.org/abs/2502.17248" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"OmniSQL: Synthesizing High-quality Text-to-SQL Data at Scale" [2025-03] [<a href="https://arxiv.org/abs/2503.02240" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DB-Explore: Automated Database Exploration and Instruction Synthesis for Text-to-SQL" [2025-03] [<a href="https://arxiv.org/abs/2503.04959" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SQLCritic: Correcting Text-to-SQL Generation via Clause-wise Critic" [2025-03] [<a href="https://arxiv.org/abs/2503.07996" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"TinySQL: A Progressive Text-to-SQL Dataset for Mechanistic Interpretability Research" [2025-03] [<a href="https://arxiv.org/abs/2503.12730" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Feather-SQL: A Lightweight NL2SQL Framework with Dual-Model Collaboration Paradigm for Small Language Models" [2025-03] [<a href="https://arxiv.org/abs/2503.17811" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LinkAlign: Scalable Schema Linking for Real-World Large-Scale Multi-Database Text-to-SQL" [2025-03] [<a href="https://arxiv.org/abs/2503.18596" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ExCoT: Optimizing Reasoning for Text-to-SQL with Execution Feedback" [2025-03] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2503.19988" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"EllieSQL: Cost-Efficient Text-to-SQL with Complexity-Aware Routing" [2025-03] [<a href="https://arxiv.org/abs/2503.22402" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Reasoning-SQL: Reinforcement Learning with SQL Tailored Partial Rewards for Reasoning-Enhanced Text-to-SQL" [2025-03] [<a href="https://arxiv.org/abs/2503.23157" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Distill-C: Enhanced NL2SQL via Distilled Customization with LLMs" [2025-03] [<a href="https://arxiv.org/abs/2504.00048" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Reward-SQL: Boosting Text-to-SQL via Stepwise Reasoning and Process-Supervised Rewards" [2025-05] [<a href="https://arxiv.org/abs/2505.04671" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ReEx-SQL: Reasoning with Execution-Aware Reinforcement Learning for Text-to-SQL" [2025-05] [<a href="https://arxiv.org/abs/2505.12768" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CSC-SQL: Corrective Self-Consistency in Text-to-SQL via Reinforcement Learning" [2025-05] [<a href="https://arxiv.org/abs/2505.13271" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SQLForge: Synthesizing Reliable and Diverse Data to Enhance Text-to-SQL Reasoning in LLMs" [2025-05] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2505.13725" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Cheaper, Better, Faster, Stronger: Robust Text-to-SQL without Chain-of-Thought or Fine-Tuning" [2025-05] [<a href="https://arxiv.org/abs/2505.14174" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"JOLT-SQL: Joint Loss Tuning of Text-to-SQL with Confusion-aware Noisy Schema Sampling" [2025-05] [<a href="https://arxiv.org/abs/2505.14305" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"UNJOIN: Enhancing Multi-Table Text-to-SQL Generation via Schema Simplification" [2025-05] [<a href="https://arxiv.org/abs/2505.18122" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SchemaGraphSQL: Efficient Schema Linking with Pathfinding Graph Algorithms for Text-to-SQL on Large-Scale Databases" [2025-05] [<a href="https://arxiv.org/abs/2505.18363" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DCG-SQL: Enhancing In-Context Learning for Text-to-SQL with Deep Contextual Schema Link Graph" [2025-05] [ACL 2025] [<a href="https://arxiv.org/abs/2505.19956" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Arctic-Text2SQL-R1: Simple Rewards, Strong Reasoning in Text-to-SQL" [2025-05] [<a href="https://arxiv.org/abs/2505.20315" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Pi-SQL: Enhancing Text-to-SQL with Fine-Grained Guidance from Pivot Programming Languages" [2025-05] [<a href="https://arxiv.org/abs/2506.00912" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SHARE: An SLM-based Hierarchical Action CorREction Assistant for Text-to-SQL" [2025-05] [ACL 2025] [<a href="https://arxiv.org/abs/2506.00391" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SDE-SQL: Enhancing Text-to-SQL Generation in Large Language Models via Self-Driven Exploration with SQL Probes" [2025-06] [<a href="https://arxiv.org/abs/2506.07245" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in Real-World Applications" [2025-06] [<a href="https://arxiv.org/abs/2506.18951" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"GradeSQL: Outcome Reward Models for Ranking SQL Queries from Large Language Models" [2025-09] [<a href="https://arxiv.org/abs/2509.01308" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SPFT-SQL: Enhancing Large Language Model for Text-to-SQL Parsing by Self-Play Fine-Tuning" [2025-09] [<a href="https://arxiv.org/abs/2509.03937" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating NL2SQL via SQL2NL" [2025-09] [<a href="https://arxiv.org/abs/2509.04657" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DeKeyNLU: Enhancing Natural Language to SQL Generation through Task Decomposition and Keyword Extraction" [2025-09] [<a href="https://arxiv.org/abs/2509.14507" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A State-of-the-Art SQL Reasoning Model using RLVR" [2025-09] [<a href="https://arxiv.org/abs/2509.21459" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Agentar-Scale-SQL: Advancing Text-to-SQL through Orchestrated Test-Time Scaling" [2025-09] [<a href="https://arxiv.org/abs/2509.24403" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MTSQL-R1: Towards Long-Horizon Multi-Turn Text-to-SQL via Agentic Training" [2025-10] [<a href="https://arxiv.org/abs/2510.12831" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Rethinking Schema Linking: A Context-Aware Bidirectional Retrieval Approach for Text-to-SQL" [2025-10] [<a href="https://arxiv.org/abs/2510.14296" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Program Proof</h3><a id="user-content-program-proof" class="anchor" aria-label="Permalink: Program Proof" href="#program-proof"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Baldur: Whole-Proof Generation and Repair with Large Language Models" [2023-03] [FSE 2023] [<a href="https://arxiv.org/abs/2303.04910" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An In-Context Learning Agent for Formal Theorem-Proving" [2023-10] [<a href="https://arxiv.org/abs/2310.04353" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards General Loop Invariant Generation: A Benchmark of Programs with Memory Manipulation" [2023-11] [NeurIPS 2024] [<a href="https://arxiv.org/abs/2311.10483" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards AI-Assisted Synthesis of Verified Dafny Methods" [2024-02] [FSE 2024] [<a href="https://arxiv.org/abs/2402.00247" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards Neural Synthesis for SMT-Assisted Proof-Oriented Programming" [2024-05] [<a href="https://arxiv.org/abs/2405.01787" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Laurel: Generating Dafny Assertions Using Large Language Models" [2024-05] [<a href="https://arxiv.org/abs/2405.16792" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AutoVerus: Automated Proof Generation for Rust Code" [2024-09] [<a href="https://arxiv.org/abs/2409.13082" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Proof Automation with Large Language Models" [2024-09] [<a href="https://arxiv.org/abs/2409.14274" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automated Proof Generation for Rust Code via Self-Evolution" [2024-10] [ICLR 2025] [<a href="https://arxiv.org/abs/2410.15756" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CoqPilot, a plugin for LLM-based generation of proofs" [2024-10] [<a href="https://arxiv.org/abs/2410.19605" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"dafny-annotator: AI-Assisted Verification of Dafny Programs" [2024-11] [<a href="https://arxiv.org/abs/2411.15143" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AlphaVerus: Bootstrapping Formally Verified Code Generation through Self-Improving Translation and Treefinement" [2024-12] [ICML 2025] [<a href="https://arxiv.org/abs/2412.06176" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing Automated Loop Invariant Generation for Complex Programs with Large Language Models" [2024-12] [<a href="https://arxiv.org/abs/2412.10483" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Rango: Adaptive Retrieval-Augmented Proving for Automated Software Verification" [2024-12] [<a href="https://arxiv.org/abs/2412.14063" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Dafny as Verification-Aware Intermediate Language for Code Generation" [2025-01] [<a href="https://arxiv.org/abs/2501.06283" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Next Steps in LLM-Supported Java Verification" [2025-02] [<a href="https://arxiv.org/abs/2502.01573" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Verifying LLM-Generated Code in the Context of Software Verification with Ada/SPARK" [2025-02] [<a href="https://arxiv.org/abs/2502.07728" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RAG-Verus: Repository-Level Program Verification with LLMs using Retrieval Augmented Generation" [2025-02] [<a href="https://arxiv.org/abs/2502.05344" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"FormalSpecCpp: A Dataset of C++ Formal Specifications created using LLMs" [2025-02] [<a href="https://arxiv.org/abs/2502.15217" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can LLMs Reason About Program Semantics? A Comprehensive Evaluation of LLMs on Formal Specification Inference" [2025-02] [ACL 2025] [<a href="https://arxiv.org/abs/2503.04779" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can LLMs Formally Reason as Abstract Interpreters for Program Analysis?" [2025-03] [<a href="https://arxiv.org/abs/2503.12686" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can LLMs Enable Verification in Mainstream Programming?" [2025-03] [<a href="https://arxiv.org/abs/2503.14183" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Re:Form -- Reducing Human Priors in Scalable Formal Software Verification with RL in LLMs: A Preliminary Study on Dafny" [2025-07] [<a href="https://arxiv.org/abs/2507.16331" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"PyVeritas: On Verifying Python via LLM-Based Transpilation and Bounded Model Checking for C" [2025-08] [<a href="https://arxiv.org/abs/2508.08171" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"InvBench: Can LLMs Accelerate Program Verification with Invariant Synthesis?" [2025-09] [<a href="https://arxiv.org/abs/2509.21629" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards Repository-Level Program Verification with Large Language Models" [2025-09] [<a href="https://arxiv.org/abs/2509.25197" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Test Generation</h3><a id="user-content-test-generation" class="anchor" aria-label="Permalink: Test Generation" href="#test-generation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Unit Test Case Generation with Transformers and Focal Context" [2020-09] [AST@ICSE 2022] [<a href="https://arxiv.org/abs/2009.05617" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation" [2023-02] [IEEE TSE] [<a href="https://arxiv.org/abs/2302.06527" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A3Test: Assertion-Augmented Automated Test Case Generation" [2023-02] [<a href="https://arxiv.org/abs/2302.10352" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Learning Deep Semantics for Test Completion" [2023-02] [ICSE 2023] [<a href="https://arxiv.org/abs/2302.10166" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Using Large Language Models to Generate JUnit Tests: An Empirical Study" [2023-04] [EASE 2024] [<a href="https://arxiv.org/abs/2305.00418" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodaMosa: Escaping Coverage Plateaus in Test Generation with Pre-Trained Large Language Models" [2023-05] [ICSE 2023] [<a href="https://dl.acm.org/doi/abs/10.1109/ICSE48619.2023.00085" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"No More Manual Tests? Evaluating and Improving ChatGPT for Unit Test Generation" [2023-05] [<a href="https://arxiv.org/abs/2305.04207" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ChatUniTest: a ChatGPT-based automated unit test generation tool" [2023-05] [<a href="https://arxiv.org/abs/2305.04764" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ChatGPT vs SBST: A Comparative Assessment of Unit Test Suite Generation" [2023-07] [<a href="https://arxiv.org/abs/2307.00588" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can Large Language Models Write Good Property-Based Tests?" [2023-07] [<a href="https://arxiv.org/abs/2307.04346" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Domain Adaptation for Deep Unit Test Case Generation" [2023-08] [<a href="https://arxiv.org/abs/2308.08033" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Effective Test Generation Using Pre-trained Large Language Models and Mutation Testing" [2023-08] [<a href="https://arxiv.org/abs/2308.16557" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How well does LLM generate security tests?" [2023-10] [<a href="https://arxiv.org/abs/2310.00710" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Reinforcement Learning from Automatic Feedback for High-Quality Unit Test Generation" [2023-10] [<a href="https://arxiv.org/abs/2310.02368" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An initial investigation of ChatGPT unit test generation capability" [2023-10] [SAST 2023] [<a href="https://dl.acm.org/doi/abs/10.1145/3624032.3624035" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CoverUp: Coverage-Guided LLM-Based Test Generation" [2024-03] [<a href="https://arxiv.org/abs/2403.16218" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing LLM-based Test Generation for Hard-to-Cover Branches via Program Analysis" [2024-04] [<a href="https://arxiv.org/abs/2404.04966" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Models for Mobile GUI Text Input Generation: An Empirical Study" [2024-04] [<a href="https://arxiv.org/abs/2404.08948" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Test Code Generation for Telecom Software Systems using Two-Stage Generative Model" [2024-04] [<a href="https://arxiv.org/abs/2404.09249" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM-Powered Test Case Generation for Detecting Bugs in Plausible Programs" [2024-04] [ACL 2025] [<a href="https://arxiv.org/abs/2404.10304" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Generating Test Scenarios from NL Requirements using Retrieval-Augmented LLMs: An Industrial Study" [2024-04] [<a href="https://arxiv.org/abs/2404.12772" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Models as Test Case Generators: Performance Evaluation and Enhancement" [2024-04] [<a href="https://arxiv.org/abs/2404.13340" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Leveraging Large Language Models for Automated Web-Form-Test Generation: An Empirical Study" [2024-05] [<a href="https://arxiv.org/abs/2405.09965" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis" [2024-06] [<a href="https://arxiv.org/abs/2406.07944" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Exploring Fuzzing as Data Augmentation for Neural Test Generation" [2024-06] [<a href="https://arxiv.org/abs/2406.08665" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Mokav: Execution-driven Differential Testing with LLMs" [2024-06] [<a href="https://arxiv.org/abs/2406.10375" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SWT-Bench: Testing and Validating Real-World Bug-Fixes with Code Agents" [2024-06] [NeurIPS 2024] [<a href="https://arxiv.org/abs/2406.12952" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CasModaTest: A Cascaded and Model-agnostic Self-directed Framework for Unit Test Generation" [2024-06] [<a href="https://arxiv.org/abs/2406.15743" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Empirical Study of Unit Test Generation with Large Language Models" [2024-06] [<a href="https://arxiv.org/abs/2406.18181" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large-scale, Independent and Comprehensive study of the power of LLMs for test case generation" [2024-06] [<a href="https://arxiv.org/abs/2407.00225" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Augmenting LLMs to Repair Obsolete Test Cases with Static Collector and Neural Reranker" [2024-07] [<a href="https://arxiv.org/abs/2407.03625" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Harnessing the Power of LLMs: Automating Unit Test Generation for High-Performance Computing" [2024-07] [<a href="https://arxiv.org/abs/2407.05202" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An LLM-based Readability Measurement for Unit Tests' Context-aware Inputs" [2024-07] [<a href="https://arxiv.org/abs/2407.21369" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A System for Automated Unit Test Generation Using Large Language Models and Assessment of Generated Test Suites" [2024-08] [<a href="https://arxiv.org/abs/2408.07846" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Leveraging Large Language Models for Enhancing the Understandability of Generated Unit Tests" [2024-08] [<a href="https://arxiv.org/abs/2408.11710" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Multi-language Unit Test Generation using LLMs" [2024-09] [<a href="https://arxiv.org/abs/2409.03093" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Exploring the Integration of Large Language Models in Industrial Test Maintenance Processes" [2024-09] [<a href="https://arxiv.org/abs/2409.06416" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Python Symbolic Execution with LLM-powered Code Generation" [2024-09] [<a href="https://arxiv.org/abs/2409.09271" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Rethinking the Influence of Source Code on Test Case Generation" [2024-09] [<a href="https://arxiv.org/abs/2409.09464" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"On the Effectiveness of LLMs for Manual Test Verifications" [2024-09] [<a href="https://arxiv.org/abs/2409.12405" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Retrieval-Augmented Test Generation: How Far Are We?" [2024-09] [<a href="https://arxiv.org/abs/2409.12682" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Context-Enhanced LLM-Based Framework for Automatic Test Refactoring" [2024-09] [<a href="https://arxiv.org/abs/2409.16739" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"TestBench: Evaluating Class-Level Test Case Generation Capability of Large Language Models" [2024-09] [<a href="https://arxiv.org/abs/2409.17561" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Advancing Bug Detection in Fastjson2 with Large Language Models Driven Unit Test Generation" [2024-10] [<a href="https://arxiv.org/abs/2410.09414" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Test smells in LLM-Generated Unit Tests" [2024-10] [<a href="https://arxiv.org/abs/2410.10628" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM-based Unit Test Generation via Property Retrieval" [2024-10] [<a href="https://arxiv.org/abs/2410.13542" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Disrupting Test Development with AI Assistants" [2024-11] [<a href="https://arxiv.org/abs/2411.02328" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Parameter-Efficient Fine-Tuning of Large Language Models for Unit Test Generation: An Empirical Study" [2024-11] [<a href="https://arxiv.org/abs/2411.02462" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"VALTEST: Automated Validation of Language Model Generated Test Cases" [2024-11] [<a href="https://arxiv.org/abs/2411.08254" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"REACCEPT: Automated Co-evolution of Production and Test Code Based on Dynamic Validation and Large Language Models" [2024-11] [<a href="https://arxiv.org/abs/2411.11033" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"What You See Is What You Get: Attention-based Self-guided Automatic Unit Test Generation" [2024-12] [<a href="https://arxiv.org/abs/2412.00828" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"System Test Case Design from Requirements Specifications: Insights and Challenges of Using ChatGPT" [2024-12] [<a href="https://arxiv.org/abs/2412.03693" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"TDD-Bench Verified: Can LLMs Generate Tests for Issues Before They Get Resolved?" [2024-12] [<a href="https://arxiv.org/abs/2412.02883" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CPP-UT-Bench: Can LLMs Write Complex Unit Tests in C++?" [2024-12] [<a href="https://arxiv.org/abs/2412.02735" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Design choices made by LLM-based test generators prevent them from finding bugs" [2024-12] [<a href="https://arxiv.org/abs/2412.14137" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Large-scale Empirical Study on Fine-tuning Large Language Models for Unit Testing" [2024-12] [<a href="https://arxiv.org/abs/2412.16620" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Improving the Readability of Automatically Generated Tests using Large Language Models" [2024-12] [<a href="https://arxiv.org/abs/2412.18843" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Potential of LLMs in Automating Software Testing: From Generation to Reporting" [2024-12] [<a href="https://arxiv.org/abs/2501.00217" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Prompt Alchemist: Automated LLM-Tailored Prompt Optimization for Test Case Generation" [2025-01] [<a href="https://arxiv.org/abs/2501.01329" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Contextual Information Injection" [2025-01] [<a href="https://arxiv.org/abs/2501.07425" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Test Wars: A Comparative Study of SBST, Symbolic Execution, and LLM-Based Approaches to Unit Test Generation" [2025-01] [<a href="https://arxiv.org/abs/2501.10200" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can LLM Generate Regression Tests for Software Commits?" [2025-01] [<a href="https://arxiv.org/abs/2501.11086" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Boundary Value Test Input Generation Using Prompt Engineering with LLMs: Fault Detection and Coverage Analysis" [2025-01] [<a href="https://arxiv.org/abs/2501.14465" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Systematic Approach for Assessing Large Language Models' Test Case Generation Capability" [2025-02] [<a href="https://arxiv.org/abs/2502.02866" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ProjectTest: A Project-level LLM Unit Test Generation Benchmark and Impact of Error Fixing Mechanisms" [2025-02] [<a href="https://arxiv.org/abs/2502.06556" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CLOVER: A Test Case Generation Benchmark with Coverage, Long-Context, and Verification" [2025-02] [<a href="https://arxiv.org/abs/2502.08806" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM-based Unit Test Generation for Dynamically-Typed Programs" [2025-03] [<a href="https://arxiv.org/abs/2503.14000" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM Test Generation via Iterative Hybrid Program Analysis" [2025-03] [<a href="https://arxiv.org/abs/2503.13580" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"TestForge: Feedback-Driven, Agentic Test Suite Generation" [2025-03] [<a href="https://arxiv.org/abs/2503.14713" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Unify and Triumph: Polyglot, Diverse, and Self-Consistent Generation of Unit Tests with LLMs" [2025-03] [<a href="https://arxiv.org/abs/2503.16144" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Issue2Test: Generating Reproducing Test Cases from Issue Reports" [2025-03] [<a href="https://arxiv.org/abs/2503.16320" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"HardTests: Synthesizing High-Quality Test Cases for LLM Coding" [2025-05] [<a href="https://arxiv.org/abs/2505.24098" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeContests+: High-Quality Test Case Generation for Competitive Programming" [2025-06] [<a href="https://arxiv.org/abs/2506.05817" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can LLMs Generate Reliable Test Case Generators? A Study on Competition-Level Programming Problems" [2025-06] [<a href="https://arxiv.org/abs/2506.06821" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Rethinking Verification for LLM Code Generation: From Generation to Testing" [2025-07] [<a href="https://arxiv.org/abs/2507.06920" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Klear-CodeTest: Scalable Test Case Generation for Code Reinforcement Learning" [2025-08] [<a href="https://arxiv.org/abs/2508.05710" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Navigating the Labyrinth: Path-Sensitive Unit Test Generation with Large Language Models" [2025-09] [<a href="https://arxiv.org/abs/2509.23812" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Oracle Generation</h3><a id="user-content-oracle-generation" class="anchor" aria-label="Permalink: Oracle Generation" href="#oracle-generation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Generating Accurate Assert Statements for Unit Test Cases using Pretrained Transformers" [2020-09] [<a href="https://arxiv.org/abs/2009.05634" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"TOGA: A Neural Method for Test Oracle Generation" [2021-09] [ICSE 2022] [<a href="https://arxiv.org/abs/2109.09262" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"TOGLL: Correct and Strong Test Oracle Generation with LLMs" [2024-05] [<a href="https://arxiv.org/abs/2405.03786" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Test Oracle Automation in the era of LLMs" [2024-05] [<a href="https://arxiv.org/abs/2405.12766" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Beyond Code Generation: Assessing Code LLM Maturity with Postconditions" [2024-07] [<a href="https://arxiv.org/abs/2407.14118" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Chat-like Asserts Prediction with the Support of Large Language Model" [2024-07] [<a href="https://arxiv.org/abs/2407.21429" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Do LLMs generate test oracles that capture the actual or the expected program behaviour?" [2024-10] [<a href="https://arxiv.org/abs/2410.21136" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Generating executable oracles to check conformance of client code to requirements of JDK Javadocs using LLMs" [2024-11] [<a href="https://arxiv.org/abs/2411.01789" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automatically Write Code Checker: An LLM-based Approach with Logic-guided API Retrieval and Case by Case Iteration" [2024-11] [<a href="https://arxiv.org/abs/2411.06796" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ASSERTIFY: Utilizing Large Language Models to Generate Assertions for Production Code" [2024-11] [<a href="https://arxiv.org/abs/2411.16927" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DeCon: Detecting Incorrect Assertions via Postconditions Generated by a Large Language Model" [2025-01] [<a href="https://arxiv.org/abs/2501.02901" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AugmenTest: Enhancing Tests with LLM-Driven Oracles" [2025-01] [<a href="https://arxiv.org/abs/2501.17461" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AsserT5: Test Assertion Generation Using a Fine-Tuned Code Language Model" [2025-02] [<a href="https://arxiv.org/abs/2502.02708" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Improving Retrieval-Augmented Deep Assertion Generation via Joint Training" [2025-02] [<a href="https://arxiv.org/abs/2502.10696" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Improving Deep Assertion Generation via Fine-Tuning Retrieval-Augmented Pre-trained Language Models" [2025-02] [<a href="https://arxiv.org/abs/2502.16071" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Mutation Testing</h3><a id="user-content-mutation-testing" class="anchor" aria-label="Permalink: Mutation Testing" href="#mutation-testing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"BERT: Mutation Testing using Pre-Trained Language Models" [2022-03] [<a href="https://arxiv.org/abs/2203.03289" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Efficient Mutation Testing via Pre-Trained Language Models" [2023-01] [<a href="https://arxiv.org/abs/2301.03543" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLMorpheus: Mutation Testing using Large Language Models" [2024-04] [<a href="https://arxiv.org/abs/2404.09952" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Exploratory Study on Using Large Language Models for Mutation Testing" [2024-06] [<a href="https://arxiv.org/abs/2406.09843" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Fine-Tuning LLMs for Code Mutation: A New Era of Cyber Threats" [2024-10] [<a href="https://arxiv.org/abs/2410.22293" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Simulink Mutation Testing using CodeBERT" [2025-01] [<a href="https://arxiv.org/abs/2501.07553" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Mutation-Guided LLM-based Test Generation at Meta" [2025-01] [<a href="https://arxiv.org/abs/2501.12862" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Fuzz Testing</h3><a id="user-content-fuzz-testing" class="anchor" aria-label="Permalink: Fuzz Testing" href="#fuzz-testing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Large Language Models are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models" [2022-12] [<a href="https://arxiv.org/abs/2212.14834" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Fuzz4All: Universal Fuzzing with Large Language Models" [2023-08] [<a href="https://arxiv.org/abs/2308.04748" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WhiteFox: White-Box Compiler Fuzzing Empowered by Large Language Models" [2023-10] [<a href="https://arxiv.org/abs/2310.15991" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLAMAFUZZ: Large Language Model Enhanced Greybox Fuzzing" [2024-06] [<a href="https://arxiv.org/abs/2406.07714" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"FuzzCoder: Byte-level Fuzzing Test via Large Language Model" [2024-09] [<a href="https://arxiv.org/abs/2409.01944" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ISC4DGF: Enhancing Directed Grey-box Fuzzing with LLM-Driven Initial Seed Corpus Generation" [2024-09] [<a href="https://arxiv.org/abs/2409.14329" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Models Based JSON Parser Fuzzing for Bug Discovery and Behavioral Analysis" [2024-10] [<a href="https://arxiv.org/abs/2410.21806" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Fixing Security Vulnerabilities with AI in OSS-Fuzz" [2024-11] [<a href="https://arxiv.org/abs/2411.03346" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Code Knowledge Graph-Enhanced System for LLM-Based Fuzz Driver Generation" [2024-11] [<a href="https://arxiv.org/abs/2411.11532" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Harnessing Large Language Models for Seed Generation in Greybox Fuzzing" [2024-11] [<a href="https://arxiv.org/abs/2411.18143" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Model assisted Hybrid Fuzzing" [2024-12] [<a href="https://arxiv.org/abs/2412.15931" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Your Fix Is My Exploit: Enabling Comprehensive DL Library API Fuzzing with Large Language Models" [2025-01] [<a href="https://arxiv.org/abs/2501.04312" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Vulnerability Detection</h3><a id="user-content-vulnerability-detection" class="anchor" aria-label="Permalink: Vulnerability Detection" href="#vulnerability-detection"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"VulDeePecker: A Deep Learning-Based System for Vulnerability Detection" [2018-01] [NDSS 2018] [<a href="https://arxiv.org/abs/1801.01681" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DeepBugs: A Learning Approach to Name-based Bug Detection" [2018-04] [Proc. ACM Program. Lang.] [<a href="https://arxiv.org/abs/1805.11683" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automated Vulnerability Detection in Source Code Using Deep Representation Learning" [2018-07] [ICMLA 2018] [<a href="https://arxiv.org/abs/1807.04320" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SySeVR: A Framework for Using Deep Learning to Detect Software Vulnerabilities" [2018-07] [IEEE TDSC] [<a href="https://arxiv.org/abs/1807.06756" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks" [2019-09] [NeurIPS 2019] [<a href="https://arxiv.org/abs/1909.03496" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Improving bug detection via context-based code representation learning and attention-based neural networks" [2019-10] [Proc. ACM Program. Lang.] [<a href="https://dl.acm.org/doi/10.1145/3360588" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Global Relational Models of Source Code" [2019-12] [ICLR 2020] [<a href="https://openreview.net/forum?id=B1lnbRNtwr" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"VulDeeLocator: A Deep Learning-based Fine-grained Vulnerability Detector" [2020-01] [IEEE TDSC] [<a href="https://arxiv.org/abs/2001.02350" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Deep Learning based Vulnerability Detection: Are We There Yet?" [2020-09] [IEEE TSE] [<a href="https://arxiv.org/abs/2009.07235" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Security Vulnerability Detection Using Deep Learning Natural Language Processing" [2021-05] [INFOCOM Workshops 2021] [<a href="https://arxiv.org/abs/2105.02388" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Self-Supervised Bug Detection and Repair" [2021-05] [NeurIPS 2021] [<a href="https://arxiv.org/abs/2105.12787" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Vulnerability Detection with Fine-grained Interpretations" [2021-06] [ESEC/SIGSOFT FSE 2021] [<a href="https://arxiv.org/abs/2106.10478" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ReGVD: Revisiting Graph Neural Networks for Vulnerability Detection" [2021-10] [ICSE Companion 2022] [<a href="https://arxiv.org/abs/2110.07317" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"VUDENC: Vulnerability Detection with Deep Learning on a Natural Codebase for Python" [2022-01] [Inf. Softw. Technol] [<a href="https://arxiv.org/abs/2201.08441" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Transformer-Based Language Models for Software Vulnerability Detection" [222-04] [ACSAC 2022] [<a href="https://arxiv.org/abs/2204.03214" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LineVul: A Transformer-based Line-Level Vulnerability Prediction" [2022-05] [MSR 2022] [<a href="https://ieeexplore.ieee.org/document/9796256" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"VulBERTa: Simplified Source Code Pre-Training for Vulnerability Detection" [2022-05] [IJCNN 2022] [<a href="https://arxiv.org/abs/2205.12424" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Open Science in Software Engineering: A Study on Deep Learning-Based Vulnerability Detection" [2022-09] [IEEE TSE] [<a href="https://ieeexplore.ieee.org/document/9894099" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Empirical Study of Deep Learning Models for Vulnerability Detection" [2022-12] [ICSE 2023] [<a href="https://arxiv.org/abs/2212.08109" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CSGVD: A deep learning approach combining sequence and graph embedding for source code vulnerability detection" [2023-01] [J. Syst. Softw.] [<a href="https://www.sciencedirect.com/science/article/pii/S0164121223000183" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Benchmarking Software Vulnerability Detection Techniques: A Survey" [2023-03] [<a href="https://arxiv.org/abs/2303.16362" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Transformer-based Vulnerability Detection in Code at EditTime: Zero-shot, Few-shot, or Fine-tuning?" [2023-05] [<a href="https://arxiv.org/abs/2306.01754" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Survey on Automated Software Vulnerability Detection Using Machine Learning and Deep Learning" [2023-06] [<a href="https://arxiv.org/abs/2306.11673" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Limits of Machine Learning for Automatic Vulnerability Detection" [2023-06] [<a href="https://arxiv.org/abs/2306.17193" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation" [2023-08] [<a href="https://arxiv.org/abs/2308.01240" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Prompt-Enhanced Software Vulnerability Detection Using ChatGPT" [2023-08] [<a href="https://arxiv.org/abs/2308.12697" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards Causal Deep Learning for Vulnerability Detection" [2023-10] [<a href="https://arxiv.org/abs/2310.07958" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Understanding the Effectiveness of Large Language Models in Detecting Security Vulnerabilities" [2023-11] [<a href="https://arxiv.org/abs/2311.16169" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How Far Have We Gone in Vulnerability Detection Using Large Language Models" [2023-11] [<a href="https://arxiv.org/abs/2311.12420" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can Large Language Models Identify And Reason About Security Vulnerabilities? Not Yet" [2023-12] [<a href="https://arxiv.org/abs/2312.12575" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM4Vuln: A Unified Evaluation Framework for Decoupling and Enhancing LLMs' Vulnerability Reasoning" [2024-01] [<a href="https://arxiv.org/abs/2401.16185" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Security Code Review by LLMs: A Deep Dive into Responses" [2024-01] [<a href="https://arxiv.org/abs/2401.16310" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLMDFA: Analyzing Dataflow in Code with Large Language Models" [2024-02] [NeurIPS 2024] [<a href="https://arxiv.org/abs/2402.10754" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Chain-of-Thought Prompting of Large Language Models for Discovering and Fixing Software Vulnerabilities" [2024-02] [<a href="https://arxiv.org/abs/2402.17230" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Multi-role Consensus through LLMs Discussions for Vulnerability Detection" [2024-03] [<a href="https://arxiv.org/abs/2403.14274" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Comprehensive Study of the Capabilities of Large Language Models for Vulnerability Detection" [2024-03] [<a href="https://arxiv.org/abs/2403.17218" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Vulnerability Detection with Code Language Models: How Far Are We?" [2024-03] [<a href="https://arxiv.org/abs/2403.18624" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Multitask-based Evaluation of Open-Source LLM on Software Vulnerability" [2024-04] [<a href="https://arxiv.org/abs/2404.02056" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Model for Vulnerability Detection and Repair: Literature Review and Roadmap" [2024-04] [<a href="https://arxiv.org/abs/2404.02525" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Pros and Cons! Evaluating ChatGPT on Software Vulnerability" [2024-04] [<a href="https://arxiv.org/abs/2404.03994" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"VulEval: Towards Repository-Level Evaluation of Software Vulnerability Detection" [2024-04] [<a href="https://arxiv.org/abs/2404.15596" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DLAP: A Deep Learning Augmented Large Language Model Prompting Framework for Software Vulnerability Detection" [2024-05] [<a href="https://arxiv.org/abs/2405.01202" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Bridging the Gap: A Study of AI-based Vulnerability Management between Industry and Academia" [2024-05] [<a href="https://arxiv.org/abs/2405.02435" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Bridge and Hint: Extending Pre-trained Language Models for Long-Range Code" [2024-05] [<a href="https://arxiv.org/abs/2405.11233" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Harnessing Large Language Models for Software Vulnerability Detection: A Comprehensive Benchmarking Study" [2024-05] [<a href="https://arxiv.org/abs/2405.15614" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM-Assisted Static Analysis for Detecting Security Vulnerabilities" [2024-05] [<a href="https://arxiv.org/abs/2405.17238" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Generalization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning" [2024-06] [ACL 2024 Findings] [<a href="https://arxiv.org/abs/2406.03718" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Security Vulnerability Detection with Multitask Self-Instructed Fine-Tuning of Large Language Models" [2024-06] [<a href="https://arxiv.org/abs/2406.05892" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"M2CVD: Multi-Model Collaboration for Code Vulnerability Detection" [2024-06] [<a href="https://arxiv.org/abs/2406.05940" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards Effectively Detecting and Explaining Vulnerabilities Using Large Language Models" [2024-06] [<a href="https://arxiv.org/abs/2406.09701" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Vul-RAG: Enhancing LLM-based Vulnerability Detection via Knowledge-level RAG" [2024-06] [<a href="https://arxiv.org/abs/2406.11147" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Bug In the Code Stack: Can LLMs Find Bugs in Large Python Code Stacks" [2024-06] [<a href="https://arxiv.org/abs/2406.15325" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Supporting Cross-language Cross-project Bug Localization Using Pre-trained Language Models" [2024-07] [<a href="https://arxiv.org/abs/2407.02732" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ALPINE: An adaptive language-agnostic pruning method for language models for code" [2024-07] [<a href="https://arxiv.org/abs/2407.04147" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SCoPE: Evaluating LLMs for Software Vulnerability Detection" [2024-07] [<a href="https://arxiv.org/abs/2407.14372" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Comparison of Static Application Security Testing Tools and Large Language Models for Repo-level Vulnerability Detection" [2024-07] [<a href="https://arxiv.org/abs/2407.16235" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code Structure-Aware through Line-level Semantic Learning for Code Vulnerability Detection" [2024-07] [<a href="https://arxiv.org/abs/2407.18877" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Study of Using Multimodal LLMs for Non-Crash Functional Bug Detection in Android Apps" [2024-07] [<a href="https://arxiv.org/abs/2407.19053" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"EaTVul: ChatGPT-based Evasion Attack Against Software Vulnerability Detection" [2024-07] [<a href="https://arxiv.org/abs/2407.19216" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating Large Language Models in Detecting Test Smells" [2024-07] [<a href="https://arxiv.org/abs/2407.19261" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automated Software Vulnerability Static Code Analysis Using Generative Pre-Trained Transformer Models" [2024-07] [<a href="https://arxiv.org/abs/2408.00197" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Qualitative Study on Using ChatGPT for Software Security: Perception vs. Practicality" [2024-08] [<a href="https://arxiv.org/abs/2408.00435" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Models for Secure Code Assessment: A Multi-Language Empirical Study" [2024-08] [<a href="https://arxiv.org/abs/2408.06428" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"VulCatch: Enhancing Binary Vulnerability Detection through CodeT5 Decompilation and KAN Advanced Feature Extraction" [2024-08] [<a href="https://arxiv.org/abs/2408.07181" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Impact of Large Language Models of Code on Fault Localization" [2024-08] [<a href="https://arxiv.org/abs/2408.09657" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Better Debugging: Combining Static Analysis and LLMs for Explainable Crashing Fault Localization" [2024-08] [<a href="https://arxiv.org/abs/2408.12070" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Beyond ChatGPT: Enhancing Software Quality Assurance Tasks with Diverse LLMs and Validation Techniques" [2024-09] [<a href="https://arxiv.org/abs/2409.01001" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CLNX: Bridging Code and Natural Language for C/C++ Vulnerability-Contributing Commits Identification" [2024-09] [<a href="https://arxiv.org/abs/2409.07407" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code Vulnerability Detection: A Comparative Analysis of Emerging Large Language Models" [2024-09] [<a href="https://arxiv.org/abs/2409.10490" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Program Slicing in the Era of Large Language Models" [2024-09] [<a href="https://arxiv.org/abs/2409.12369" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Generating API Parameter Security Rules with LLM for API Misuse Detection" [2024-09] [<a href="https://arxiv.org/abs/2409.09288" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing Fault Localization Through Ordered Code Analysis with LLM Agents and Self-Reflection" [2024-09] [<a href="https://arxiv.org/abs/2409.13642" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Comparing Unidirectional, Bidirectional, and Word2vec Models for Discovering Vulnerabilities in Compiled Lifted Code" [2024-09] [<a href="https://arxiv.org/abs/2409.17513" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing Pre-Trained Language Models for Vulnerability Detection via Semantic-Preserving Data Augmentation" [2024-10] [<a href="https://arxiv.org/abs/2410.00249" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"StagedVulBERT: Multi-Granular Vulnerability Detection with a Novel Pre-trained Code Model" [2024-10] [<a href="https://arxiv.org/abs/2410.05766" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Understanding the AI-powered Binary Code Similarity Detection" [2024-10] [<a href="https://arxiv.org/abs/2410.07537" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RealVul: Can We Detect Vulnerabilities in Web Applications with LLM?" [2024-10] [<a href="https://arxiv.org/abs/2410.07573" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Just-In-Time Software Defect Prediction via Bi-modal Change Representation Learning" [2024-10] [<a href="https://arxiv.org/abs/2410.12107" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DFEPT: Data Flow Embedding for Enhancing Pre-Trained Model Based Vulnerability Detection" [2024-10] [<a href="https://arxiv.org/abs/2410.18479" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Utilizing Precise and Complete Code Context to Guide LLM in Automatic False Positive Mitigation" [2024-11] [<a href="https://arxiv.org/abs/2411.03079" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Smart-LLaMA: Two-Stage Post-Training of Large Language Models for Smart Contract Vulnerability Detection and Explanation" [2024-11] [<a href="https://arxiv.org/abs/2411.06221" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"FlexFL: Flexible and Effective Fault Localization with Open-Source Large Language Models" [2024-11] [<a href="https://arxiv.org/abs/2411.10714" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Breaking the Cycle of Recurring Failures: Applying Generative AI to Root Cause Analysis in Legacy Banking Systems" [2024-11] [<a href="https://arxiv.org/abs/2411.13017" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Are Large Language Models Memorizing Bug Benchmarks?" [2024-11] [<a href="https://arxiv.org/abs/2411.13323" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Empirical Study of Vulnerability Detection using Federated Learning" [2024-11] [<a href="https://arxiv.org/abs/2411.16099" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Fault Localization from the Semantic Code Search Perspective" [2024-11] [<a href="https://arxiv.org/abs/2411.17230" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Applying Contrastive Learning to Code Vulnerability Type Classification" [2024-11] [EMNLP 2024] [<a href="https://aclanthology.org/2024.emnlp-main.666/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing IR-based Fault Localization using Large Language Models" [2024-12] [<a href="https://arxiv.org/abs/2412.03754" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can LLM Prompting Serve as a Proxy for Static Analysis in Vulnerability Detection" [2024-12] [<a href="https://arxiv.org/abs/2412.12039" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Large Language Model Approach to Identify Flakiness in C++ Projects" [2024-12] [<a href="https://arxiv.org/abs/2412.12340" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on Method-Level Code Smell Detection" [2024-12] [<a href="https://arxiv.org/abs/2412.13801" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Closing the Gap: A User Study on the Real-world Usefulness of AI-powered Vulnerability Detection &amp; Repair in the IDE" [2024-12] [<a href="https://arxiv.org/abs/2412.14306" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Models and Code Security: A Systematic Literature Review" [2024-12] [<a href="https://arxiv.org/abs/2412.15004" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Vulnerability Detection in Popular Programming Languages with Language Models" [2024-12] [<a href="https://arxiv.org/abs/2412.15905" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study" [2024-12] [<a href="https://arxiv.org/abs/2412.18260" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Impact of Input Order Bias on Large Language Models for Software Fault Localization" [2024-12] [<a href="https://arxiv.org/abs/2412.18750" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CGP-Tuning: Structure-Aware Soft Prompt Tuning for Code Vulnerability Detection" [2025-01] [<a href="https://arxiv.org/abs/2501.04510" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automating the Detection of Code Vulnerabilities by Analyzing GitHub Issues" [2025-01] [<a href="https://arxiv.org/abs/2501.05258" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Improved IR-based Bug Localization with Intelligent Relevance Feedback" [2025-01] [<a href="https://arxiv.org/abs/2501.10542" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Assessing Large Language Models in Comprehending and Verifying Concurrent Programs across Memory Models" [2025-01] [<a href="https://arxiv.org/abs/2501.14326" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RepoAudit: An Autonomous LLM-Agent for Repository-Level Code Auditing" [2025-01] [ICML 2025] [<a href="https://arxiv.org/abs/2501.18160" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Streamlining Security Vulnerability Triage with Large Language Models" [2025-01] [<a href="https://arxiv.org/abs/2501.18908" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"COSMosFL: Ensemble of Small Language Models for Fault Localisation" [2025-02] [<a href="https://arxiv.org/abs/2502.02908" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Models for In-File Vulnerability Localization Can Be "Lost in the End"" [2025-02] [<a href="https://arxiv.org/abs/2502.06898" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Where's the Bug? Attention Probing for Scalable Fault Localization" [2025-02] [<a href="https://arxiv.org/abs/2502.13966" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Bridging Bug Localization and Issue Fixing: A Hierarchical Localization Framework Leveraging Large Language Models" [2025-02] [<a href="https://arxiv.org/abs/2502.15292" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Contemporary Survey of Large Language Model Assisted Program Analysis" [2025-02] [<a href="https://arxiv.org/abs/2502.18474" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Beyond Natural Language Perplexity: Detecting Dead Code Poisoning in Code Generation Datasets" [2025-02] [<a href="https://arxiv.org/abs/2502.20246" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Benchmarking LLMs and LLM-based Agents in Practical Vulnerability Detection for Code Repositories" [2025-03] [ACL 2025] [<a href="https://arxiv.org/abs/2503.03586" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LocAgent: Graph-Guided LLM Agents for Code Localization" [2025-03] [ACL 2025] [<a href="https://arxiv.org/abs/2503.09089" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"HALURust: Exploiting Hallucinations of Large Language Models to Detect Vulnerabilities in Rust" [2025-03] [<a href="https://arxiv.org/abs/2503.10793" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CoSIL: Software Issue Localization via LLM-Driven Code Repository Graph Searching" [2025-03] [<a href="https://arxiv.org/abs/2503.22424" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How Accurately Do Large Language Models Understand Code?" [2025-04] [<a href="https://arxiv.org/abs/2504.04372" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Program Semantic Inequivalence Game with Large Language Models" [2025-05] [<a href="https://arxiv.org/abs/2505.03818" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Preliminary Study of Large Language Models for Multilingual Vulnerability Detection" [2025-05] [<a href="https://arxiv.org/abs/2505.07376" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Learning to Focus: Context Extraction for Efficient Code Vulnerability Detection with Language Models" [2025-05] [<a href="https://arxiv.org/abs/2505.17460" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data" [2025-06] [<a href="https://arxiv.org/abs/2506.07390" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MLDebugging: Towards Benchmarking Code Debugging Across Multi-Library Scenarios" [2025-06] [ACL 2025 Findings] [<a href="https://www.arxiv.org/abs/2506.13824" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Smart-LLaMA-DPO: Reinforced Large Language Model for Explainable Smart Contract Vulnerability Detection" [2025-06] [ISSTA 2025] [<a href="https://arxiv.org/abs/2506.18245" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Black-Box Test Code Fault Localization Driven by Large Language Models and Execution Estimation" [2025-06] [<a href="https://arxiv.org/abs/2506.19045" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CLeVeR: Multi-modal Contrastive Learning for Vulnerability Code Representation" [2025-07] [ACL 2025 Findings] [<a href="https://aclanthology.org/2025.findings-acl.414/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code-SPA: Style Preference Alignment to Large Language Models for Effective and Robust Code Debugging" [2025-07] [ACL 2025 Findings] [<a href="https://aclanthology.org/2025.findings-acl.912/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLaVul: A Multimodal LLM for Interpretable Vulnerability Reasoning about Source Code" [2025-09] [<a href="https://arxiv.org/abs/2509.17337" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Improving Code Localization with Repository Memory" [2025-10] [<a href="https://arxiv.org/abs/2510.01003" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Vul-R2: A Reasoning LLM for Automated Vulnerability Repair" [2025-10] [<a href="https://arxiv.org/abs/2510.05480" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Malicious Code Detection</h3><a id="user-content-malicious-code-detection" class="anchor" aria-label="Permalink: Malicious Code Detection" href="#malicious-code-detection"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"I-MAD: Interpretable Malware Detector Using Galaxy Transformer", 2019-09, Comput. Secur. 2021, [<a href="https://arxiv.org/abs/1909.06865" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Malbert: A novel pre-training method for malware detection", 2021-09, Comput. Secur. 2021, [<a href="https://www.sciencedirect.com/science/article/pii/S0167404821002820" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Single-Shot Black-Box Adversarial Attacks Against Malware Detectors: A Causal Language Model Approach", 2021-12, ISI 2021, [<a href="https://arxiv.org/abs/2112.01724" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"M2VMapper: Malware-to-Vulnerability mapping for Android using text processing", 2021-12, Expert Syst. Appl. 2022, [<a href="https://www.sciencedirect.com/science/article/pii/S0957417421016572" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Ensemble of Pre-trained Transformer Models For Imbalanced Multiclass Malware Classification", 2021-12, Comput. Secur. 2022, [<a href="https://arxiv.org/abs/2112.13236" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Static Malware Detection Using Stacked BiLSTM and GPT-2", 2022-05, IEEE Access 2022, [<a href="https://ieeexplore.ieee.org/document/9785789" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"APT Malicious Sample Organization Traceability Based on Text Transformer Model", 2022-07, PRML 2022, [<a href="https://ieeexplore.ieee.org/document/9882232" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Self-Supervised Vision Transformers for Malware Detection", 2022-08, IEEE Access 2022, [<a href="https://arxiv.org/abs/2208.07049" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Survey of Recent Advances in Deep Learning Models for Detecting Malware in Desktop and Mobile Platforms", 2022-09, ACM Computing Surveys, [<a href="https://dl.acm.org/doi/abs/10.1145/3638240" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Malicious Source Code Detection Using Transformer", 2022-09, [<a href="https://arxiv.org/abs/2209.07957" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MalBERTv2: Code Aware BERT-Based Model for Malware Identification" [2023-03] [Big Data Cogn. Comput. 2023] [<a href="https://www.mdpi.com/2504-2289/7/2/60" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"GPThreats-3: Is Automatic Malware Generation a Threat?" [2023-05] [SPW 2023] [<a href="https://ieeexplore.ieee.org/abstract/document/10188649" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"GitHub Copilot: A Threat to High School Security? Exploring GitHub Copilot's Proficiency in Generating Malware from Simple User Prompts" [2023-08] [ETNCC 2023] [<a href="https://ieeexplore.ieee.org/abstract/document/10284976" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Attackers Dream? Exploring the Capabilities of ChatGPT for Developing Malware" [2023-08] [CSET 2023] [<a href="https://dl.acm.org/doi/abs/10.1145/3607505.3607513" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Malicious code detection in android: the role of sequence characteristics and disassembling methods" [2023-12] [Int. J. Inf. Sec. 2023] [<a href="https://arxiv.org/abs/2312.01113" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4" [2023-12] [<a href="https://arxiv.org/abs/2312.08317" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Shifting the Lens: Detecting Malware in npm Ecosystem with Large Language Models" [2024-03] [<a href="https://arxiv.org/abs/2403.12196" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AppPoet: Large Language Model based Android malware detection via multi-view prompt engineering" [2024-04] [<a href="https://arxiv.org/abs/2404.18816" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Tactics, Techniques, and Procedures (TTPs) in Interpreted Malware: A Zero-Shot Generation with Large Language Models" [2024-07] [<a href="https://arxiv.org/abs/2407.08532" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DetectBERT: Towards Full App-Level Representation Learning to Detect Android Malware" [2024-08] [<a href="https://arxiv.org/abs/2408.16353" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"PackageIntel: Leveraging Large Language Models for Automated Intelligence Extraction in Package Ecosystems" [2024-09] [<a href="https://arxiv.org/abs/2409.15049" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AgentDroid: A Multi-Agent Framework for Detecting Fraudulent Android Applications" [2025-03] [<a href="https://arxiv.org/abs/2503.12163" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Model (LLM) for Software Security: Code Analysis, Malware Analysis, Reverse Engineering" [2025-04] [<a href="https://arxiv.org/abs/2504.07137" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Compiler Optimization</h3><a id="user-content-compiler-optimization" class="anchor" aria-label="Permalink: Compiler Optimization" href="#compiler-optimization"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Learning Performance-Improving Code Edits" [2023-06] [ICLR 2024 Spotlight] [<a href="https://arxiv.org/abs/2302.07867" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Models for Compiler Optimization" [2023-09] [<a href="https://arxiv.org/abs/2309.07062" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Refining Decompiled C Code with Large Language Models" [2023-10] [<a href="https://arxiv.org/abs/2310.06530" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Priority Sampling of Large Language Models for Compilers" [2024-02] [<a href="https://arxiv.org/abs/2402.18734" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Should AI Optimize Your Code? A Comparative Study of Current Large Language Models Versus Classical Optimizing Compilers" [2024-06] [<a href="https://arxiv.org/abs/2406.12146" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Iterative or Innovative? A Problem-Oriented Perspective for Code Optimization" [2024-06] [<a href="https://arxiv.org/abs/2406.11935" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Meta Large Language Model Compiler: Foundation Models of Compiler Optimization" [2024-06] [<a href="https://arxiv.org/abs/2407.02524" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ViC: Virtual Compiler Is All You Need For Assembly Code Search" [2024-08] [<a href="https://arxiv.org/abs/2408.06385" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Search-Based LLMs for Code Optimization" [2024-08] [<a href="https://arxiv.org/abs/2408.12159" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"E-code: Mastering Efficient Code Generation through Pretrained Models and Expert Encoder Group" [2024-08] [<a href="https://arxiv.org/abs/2408.12948" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Models for Energy-Efficient Code: Emerging Results and Future Directions" [2024-10] [<a href="https://arxiv.org/abs/2410.09241" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of C to x86 Assembly" [2024-11] [EMNLP 2024 Findings] [<a href="https://aclanthology.org/2024.findings-emnlp.55/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards LLM-based optimization compilers. Can LLMs learn how to apply a single peephole optimization? Reasoning is all LLMs need!" [2024-12] [<a href="https://arxiv.org/abs/2412.12163" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can LLMs Obfuscate Code? A Systematic Analysis of Large Language Models into Assembly Code Obfuscation" [2024-12] [<a href="https://arxiv.org/abs/2412.16135" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Finding Missed Code Size Optimizations in Compilers using LLMs" [2024-12] [<a href="https://arxiv.org/abs/2501.00655" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Optimizing Code Runtime Performance through Context-Aware Retrieval-Augmented Generation" [2025-01] [<a href="https://arxiv.org/abs/2501.16692" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"VecTrans: LLM Transformation Framework for Better Auto-vectorization on High-performance CPU" [2025-03] [<a href="https://arxiv.org/abs/2503.19449" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Improving Assembly Code Performance with Large Language Models via Reinforcement Learning" [2025-05] [<a href="https://arxiv.org/abs/2505.11480" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Autocomp: LLM-Driven Code Optimization for Tensor Accelerators" [2025-05] [<a href="https://arxiv.org/abs/2505.18574" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning" [2025-07] [<a href="https://arxiv.org/abs/2507.14111" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Speed Up Your Code: Progressive Code Acceleration Through Bidirectional Tree Editing" [2025-07] [ACL 2025] [<a href="https://aclanthology.org/2025.acl-long.1387/" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ECO: Enhanced Code Optimization via Performance-Aware Prompting for Code-LLMs" [2025-10] [<a href="https://arxiv.org/abs/2510.10517" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Binary Analysis and Decompilation</h3><a id="user-content-binary-analysis-and-decompilation" class="anchor" aria-label="Permalink: Binary Analysis and Decompilation" href="#binary-analysis-and-decompilation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Using recurrent neural networks for decompilation" [2018-03] [SANER 2018] [<a href="https://ieeexplore.ieee.org/document/8330222" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evolving Exact Decompilation" [2018] [<a href="https://eschulte.github.io/data/bed.pdf" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards Neural Decompilation" [2019-05] [<a href="https://arxiv.org/abs/1905.08325" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Coda: An End-to-End Neural Program Decompiler" [2019-06] [NeurIPS 2019] [<a href="https://arxiv.org/abs/1906.12029" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"N-Bref : A High-fidelity Decompiler Exploiting Programming Structures" [2020-09] [<a href="https://openreview.net/forum?id=6GkL6qM3LV" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Neutron: an attention-based neural decompiler" [2021-03] [Cybersecurity 2021] [<a href="https://cybersecurity.springeropen.com/articles/10.1186/s42400-021-00070-0" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Beyond the C: Retargetable Decompilation using Neural Machine Translation" [2022-12] [<a href="https://arxiv.org/abs/2212.08950" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Boosting Neural Networks to Decompile Optimized Binaries" [2023-01] [ACSAC 2022] [<a href="https://arxiv.org/abs/2301.00969" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SLaDe: A Portable Small Language Model Decompiler for Optimized Assembly" [2023-05] [<a href="https://arxiv.org/abs/2305.12520" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Nova: Generative Language Models for Assembly Code with Hierarchical Attention and Contrastive Learning" [2023-11] [ICLR 2025] [<a href="https://arxiv.org/abs/2311.13721" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeArt: Better Code Models by Attention Regularization When Symbols Are Lacking" [2024-11] [<a href="https://arxiv.org/abs/2402.11842" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM4Decompile: Decompiling Binary Code with Large Language Models" [2024-03] [EMNLP 2024] [<a href="https://arxiv.org/abs/2403.05286" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"WaDec: Decompile WebAssembly Using Large Language Model" [2024-06] [<a href="https://arxiv.org/abs/2406.11346" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MAD: Move AI Decompiler to Improve Transparency and Auditability on Non-Open-Source Blockchain Smart Contract" [2024-10] [<a href="https://arxiv.org/abs/2410.15275" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Source Code Foundation Models are Transferable Binary Analysis Knowledge Bases" [2024-11] [NeurIPS 2024] [<a href="https://arxiv.org/abs/2405.19581" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Progressive Transformer for Unifying Binary Code Embedding and Knowledge Transfer" [2024-12] [<a href="https://arxiv.org/abs/2412.11177" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Augmenting Smart Contract Decompiler Output through Fine-grained Dependency Analysis and LLM-facilitated Semantic Recovery" [2025-01] [<a href="https://arxiv.org/abs/2501.08670" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Idioms: Neural Decompilation With Joint Code and Type Prediction" [2025-02] [<a href="https://arxiv.org/abs/2502.04536" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can Large Language Models Understand Intermediate Representations?" [2025-02] [<a href="https://arxiv.org/abs/2502.06854" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"On the Role of Pre-trained Embeddings in Binary Code Analysis" [2025-02] [<a href="https://arxiv.org/abs/2502.08682" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Control Flow-Augmented Decompiler based on Large Language Model" [2025-03] [<a href="https://arxiv.org/abs/2503.07215" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ASMA-Tune: Unlocking LLMs' Assembly Code Comprehension via Structural-Semantic Instruction Tuning" [2025-03] [<a href="https://arxiv.org/abs/2503.11617" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"BinMetric: A Comprehensive Binary Analysis Benchmark for Large Language Models" [2025-05] [<a href="https://arxiv.org/abs/2505.07360" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Commit Message Generation</h3><a id="user-content-commit-message-generation" class="anchor" aria-label="Permalink: Commit Message Generation" href="#commit-message-generation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Automated Commit Message Generation with Large Language Models: An Empirical Study and Beyond" [2024-04] [<a href="https://arxiv.org/abs/2404.14824" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards Realistic Evaluation of Commit Message Generation by Matching Online and Offline Settings" [2024-10] [<a href="https://arxiv.org/abs/2410.12046" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Optimization is Better than Generation: Optimizing Commit Message Leveraging Human-written Commit Message" [2025-01] [<a href="https://arxiv.org/abs/2501.09861" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Empirical Study on Commit Message Generation using LLMs via In-Context Learning" [2025-02] [<a href="https://arxiv.org/abs/2502.18904" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Consider What Humans Consider: Optimizing Commit Message Leveraging Contexts Considered By Human" [2025-03] [<a href="https://arxiv.org/abs/2503.11960" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating Generated Commit Messages with Large Language Models" [2025-07] [<a href="https://arxiv.org/abs/2507.10906" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CoRaCMG: Contextual Retrieval-Augmented Framework for Commit Message Generation" [2025-09] [<a href="https://arxiv.org/abs/2509.18337" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Code Review</h3><a id="user-content-code-review" class="anchor" aria-label="Permalink: Code Review" href="#code-review"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Using Pre-Trained Models to Boost Code Review Automation" [2022-01] [ICSE 2022] [<a href="https://arxiv.org/abs/2201.06850" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AUGER: Automatically Generating Review Comments with Pre-training Models" [2022-08] [ESEC/FSE 2022] [<a href="https://arxiv.org/abs/2208.08014" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automatic Code Review by Learning the Structure Information of Code Graph" [2023-02] [Sensors] [<a href="https://www.mdpi.com/1424-8220/23/5/2551" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLaMA-Reviewer: Advancing Code Review Automation with Large Language Models through Parameter-Efficient Fine-Tuning" [2023-08] [ISSRE 2023] [<a href="https://arxiv.org/abs/2308.11148" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeAgent: Autonomous Communicative Agents for Code Review" [2024-02] [EMNLP 2024] [<a href="https://arxiv.org/abs/2402.02172" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AI-powered Code Review with LLMs: Early Results" [2024-04] [<a href="https://arxiv.org/abs/2404.18496" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AI-Assisted Assessment of Coding Practices in Modern Code Review" [2024-05] [<a href="https://arxiv.org/abs/2405.13565" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A GPT-based Code Review System for Programming Language Learning" [2024-07] [<a href="https://arxiv.org/abs/2407.04722" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM Critics Help Catch LLM Bugs" [2024-06] [<a href="https://arxiv.org/abs/2407.00215" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Exploring the Capabilities of LLMs for Code Change Related Tasks" [2024-07] [<a href="https://arxiv.org/abs/2407.02824" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating Language Models for Generating and Judging Programming Feedback" [2024-07] [<a href="https://arxiv.org/abs/2407.04873" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can LLMs Replace Manual Annotation of Software Engineering Artifacts?" [2024-08] [<a href="https://arxiv.org/abs/2408.05534" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Leveraging Reviewer Experience in Code Review Comment Generation" [2024-09] [<a href="https://arxiv.org/abs/2409.10959" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CRScore: Grounding Automated Evaluation of Code Review Comments in Code Claims and Smells" [2024-09] [<a href="https://arxiv.org/abs/2409.19801" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing Code Annotation Reliability: Generative AI's Role in Comment Quality Assessment Models" [2024-10] [<a href="https://arxiv.org/abs/2410.22323" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Knowledge-Guided Prompt Learning for Request Quality Assurance in Public Code Review" [2024-10] [<a href="https://arxiv.org/abs/2410.21673" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Impact of LLM-based Review Comment Generation in Practice: A Mixed Open-/Closed-source User Study" [2024-11] [<a href="https://arxiv.org/abs/2411.07091" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation" [2024-11] [<a href="https://arxiv.org/abs/2411.10129" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Deep Learning-based Code Reviews: A Paradigm Shift or a Double-Edged Sword?" [2024-11] [<a href="https://arxiv.org/abs/2411.11401" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Redefining Crowdsourced Test Report Prioritization: An Innovative Approach with Large Language Model" [2024-11] [<a href="https://arxiv.org/abs/2411.17045" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Exploring the Potential of Llama Models in Automated Code Refinement: A Replication Study" [2024-12] [<a href="https://arxiv.org/abs/2412.02789" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automated Code Review In Practice" [2024-12] [<a href="https://arxiv.org/abs/2412.18531" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code Review Automation Via Multi-task Federated LLM -- An Empirical Study" [2024-12] [<a href="https://arxiv.org/abs/2412.15676" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DeepCRCEval: Revisiting the Evaluation of Code Review Comment Generation" [2024-12] [<a href="https://arxiv.org/abs/2412.18291" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Distilling Desired Comments for Enhanced Code Review with Large Language Models" [2024-12] [<a href="https://arxiv.org/abs/2412.20340" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Deep Assessment of Code Review Generation Approaches: Beyond Lexical Similarity" [2025-01] [<a href="https://arxiv.org/abs/2501.05176" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Debugging Without Error Messages: How LLM Prompting Strategy Affects Programming Error Explanation Effectiveness" [2025-01] [<a href="https://arxiv.org/abs/2501.05706" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"I Can Find You in Seconds! Leveraging Large Language Models for Code Authorship Attribution" [2025-01] [<a href="https://arxiv.org/abs/2501.08165" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code Change Intention, Development Artifact and History Vulnerability: Putting Them Together for Vulnerability Fix Detection by LLM" [2025-01] [<a href="https://arxiv.org/abs/2501.14983" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"BitsAI-CR: Automated Code Review via LLM in Practice" [2025-01] [<a href="https://arxiv.org/abs/2501.15134" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Model Critics for Execution-Free Evaluation of Code Changes" [2025-01] [<a href="https://arxiv.org/abs/2501.16655" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Too Noisy To Learn: Enhancing Data Quality for Code Review C" [2025-02] [<a href="https://arxiv.org/abs/2502.02757" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Harnessing Large Language Models for Curated Code Reviews" [2025-02] [<a href="https://arxiv.org/abs/2502.03425" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Combining Large Language Models with Static Analyzers for Code Review Generation" [2025-02] [<a href="https://arxiv.org/abs/2502.06633" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automating Code Review: A Systematic Literature Review" [2025-03] [<a href="https://arxiv.org/abs/2503.09510" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards Practical Defect-Focused Automated Code Review" [2025-05] [ICML 2025] [<a href="https://arxiv.org/abs/2505.17928" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CRScore++: Reinforcement Learning with Verifiable Tool and AI Feedback for Code Review" [2025-05] [<a href="https://arxiv.org/abs/2506.00296" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Fine-Tuning Multilingual Language Models for Code Review: An Empirical Study on Industrial C# Projects" [2025-07] [<a href="https://arxiv.org/abs/2507.19271" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects" [2025-09] [<a href="https://arxiv.org/abs/2509.14856" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Fine-Tuning LLMs to Analyze Multiple Dimensions of Code Review: A Maximum Entropy Regulated Long Chain-of-Thought Approach" [2025-09] [<a href="https://arxiv.org/abs/2509.21170" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Log Analysis</h3><a id="user-content-log-analysis" class="anchor" aria-label="Permalink: Log Analysis" href="#log-analysis"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"LogStamp: Automatic Online Log Parsing Based on Sequence Labelling" [2022-08] [<a href="https://arxiv.org/abs/2208.10282" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Log Parsing with Prompt-based Few-shot Learning" [2023-02] [ICSE 2023] [<a href="https://arxiv.org/abs/2302.07435" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Log Parsing: How Far Can ChatGPT Go?" [2023-06] [ASE 2023] [<a href="https://arxiv.org/abs/2306.01590" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis" [2023-08] [<a href="https://arxiv.org/abs/2308.07610" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection" [2023-09] [<a href="https://arxiv.org/abs/2309.01189" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Assessment of ChatGPT on Log Data" [2023-09] [<a href="https://arxiv.org/abs/2309.07938" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LILAC: Log Parsing using LLMs with Adaptive Parsing Cache" [2023-10] [<a href="https://arxiv.org/abs/2310.01796" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLMParser: An Exploratory Study on Using Large Language Models for Log Parsing" [2024-04] [<a href="https://arxiv.org/abs/2404.18001" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"On the Influence of Data Resampling for Deep Learning-Based Log Anomaly Detection: Insights and Recommendations" [2024-05] [<a href="https://arxiv.org/abs/2405.03489" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Log Parsing with Self-Generated In-Context Learning and Self-Correction" [2024-06] [<a href="https://arxiv.org/abs/2406.03376" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Stronger, Faster, and Cheaper Log Parsing with LLMs" [2024-06] [<a href="https://arxiv.org/abs/2406.06156" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ULog: Unsupervised Log Parsing with Large Language Models through Log Contrastive Units" [2024-06] [<a href="https://arxiv.org/abs/2406.07174" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Anomaly Detection on Unstable Logs with GPT Models" [2024-06] [<a href="https://arxiv.org/abs/2406.07467" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LogParser-LLM: Advancing Efficient Log Parsing with Large Language Models" [2024-08] [KDD 2024] [<a href="https://arxiv.org/abs/2408.13727" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LUK: Empowering Log Understanding with Expert Knowledge from Large Language Models" [2024-09] [<a href="https://arxiv.org/abs/2409.01909" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Comparative Study on Large Language Models for Log Parsing" [2024-09] [<a href="https://arxiv.org/abs/2409.02474" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"What Information Contributes to Log-based Anomaly Detection? Insights from a Configurable Transformer-Based Approach" [2024-10] [<a href="https://arxiv.org/abs/2409.20503" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LogLM: From Task-based to Instruction-based Automated Log Analysis" [2024-10] [<a href="https://arxiv.org/abs/2410.09352" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LogLLM: Log-based Anomaly Detection Using Large Language Models" [2024-11] [<a href="https://arxiv.org/abs/2411.08561" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Adapting Large Language Models to Log Analysis with Interpretable Domain Knowledge" [2024-12] [<a href="https://arxiv.org/abs/2412.01377" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Chatting with Logs: An exploratory study on Finetuning LLMs for LogQL" [2024-12] [<a href="https://arxiv.org/abs/2412.03612" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LogBabylon: A Unified Framework for Cross-Log File Integration and Analysis" [2024-12] [<a href="https://arxiv.org/abs/2412.12364" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AdaptiveLog: An Adaptive Log Analysis Framework with the Collaboration of Large and Small Language Model" [2025-01] [<a href="https://arxiv.org/abs/2501.11031" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Explaining GitHub Actions Failures with Large Language Models: Challenges, Insights, and Limitations" [2025-01] [<a href="https://arxiv.org/abs/2501.16495" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Software Configuration</h3><a id="user-content-software-configuration" class="anchor" aria-label="Permalink: Software Configuration" href="#software-configuration"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Configuration Validation with Large Language Models" [2023-10] [<a href="https://arxiv.org/abs/2310.09690" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CloudEval-YAML: A Practical Benchmark for Cloud Configuration Generation" [2023-11] [<a href="https://arxiv.org/abs/2401.06786" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can LLMs Configure Software Tools" [2023-12] [<a href="https://arxiv.org/abs/2312.06121" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LuaTaint: A Static Analysis System for Web Configuration Interface Vulnerability of Internet of Things Devices" [2024-02] [IOT] [<a href="https://arxiv.org/abs/2402.16043" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM-Based Misconfiguration Detection for AWS Serverless Computing" [2024-11] [<a href="https://arxiv.org/abs/2411.00642" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Leveraging LLM Agents for Translating Network Configurations" [2025-01] [<a href="https://arxiv.org/abs/2501.08760" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Raiders of the Lost Dependency: Fixing Dependency Conflicts in Python using LLMs" [2025-01] [<a href="https://arxiv.org/abs/2501.16191" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enabling Autonomic Microservice Management through Self-Learning Agents" [2025-01] [<a href="https://arxiv.org/abs/2501.19056" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLMSecConfig: An LLM-Based Approach for Fixing Software Container Misconfigurations" [2025-02] [<a href="https://arxiv.org/abs/2502.02009" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An LLM-based Agent for Reliable Docker Environment Configuration" [2025-02] [<a href="https://arxiv.org/abs/2502.13681" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automated Benchmark Generation for Repository-Level Coding Tasks" [2025-03] [ICML 2025] [<a href="https://arxiv.org/abs/2503.07701" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"BYOS: Knowledge-driven Large Language Models Bring Your Own Operating System More Excellent" [2025-03] [<a href="https://arxiv.org/abs/2503.09663" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"EnvBench: A Benchmark for Automated Environment Setup" [2025-03] [<a href="https://arxiv.org/abs/2503.14443" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Prompting for Performance: Exploring LLMs for Configuring Software" [2025-07] [<a href="https://arxiv.org/abs/2507.09790" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software" [2025-09] [<a href="https://arxiv.org/abs/2509.25248" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Code QA &amp; Reasoning</h3><a id="user-content-code-qa--reasoning" class="anchor" aria-label="Permalink: Code QA &amp; Reasoning" href="#code-qa--reasoning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"DialogAgent: An Auto-engagement Agent for Code Question Answering Data Production" [2024-12] [<a href="https://arxiv.org/abs/2412.08069" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Unveiling the Magic of Code Reasoning through Hypothesis Decomposition and Amendment" [2025-02] [ICLR 2025] [<a href="https://arxiv.org/abs/2502.13170" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeReviewQA: The Code Review Comprehension Assessment for Large Language Models" [2025-03] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2503.16167" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating the Generalization Capabilities of Large Language Models on Code Reasoning" [2025-04] [<a href="https://arxiv.org/abs/2504.05518" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Code Barrier: What LLMs Actually Understand?" [2025-04] [<a href="https://arxiv.org/abs/2504.10557" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can Large Language Models Predict Parallel Code Performance?" [2025-05] [<a href="https://arxiv.org/abs/2505.03988" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LongCodeBench: Evaluating Coding LLMs at 1M Context Windows" [2025-05] [<a href="https://arxiv.org/abs/2505.07897" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Do Code LLMs Do Static Analysis?" [2025-05] [<a href="https://arxiv.org/abs/2505.12118" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Sense and Sensitivity: Examining the Influence of Semantic Recall on Long Context Code Reasoning" [2025-05] [<a href="https://arxiv.org/abs/2505.13353" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MARCO: Meta-Reflection with Cross-Referencing for Code Reasoning" [2025-05] [<a href="https://arxiv.org/abs/2505.17481" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Complex Logical Instruction Generation" [2025-08] [<a href="https://arxiv.org/abs/2508.09125" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Regression Language Models for Code" [2025-09] [<a href="https://arxiv.org/abs/2509.26476" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"When Names Disappear: Revealing What LLMs Actually Understand About Code" [2025-10] [<a href="https://arxiv.org/abs/2510.03178" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MEC3O: Multi-Expert Consensus for Code Time Complexity Prediction" [2025-10] [<a href="https://arxiv.org/abs/2510.09049" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Software Modeling</h3><a id="user-content-software-modeling" class="anchor" aria-label="Permalink: Software Modeling" href="#software-modeling"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Towards using Few-Shot Prompt Learning for Automating Model Completion" [2022-12] [<a href="https://arxiv.org/abs/2212.03404" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Model Generation from Requirements with LLMs: an Exploratory Study" [2024-04] [<a href="https://arxiv.org/abs/2404.06371" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How LLMs Aid in UML Modeling: An Exploratory Study with Novice Analysts" [2024-04] [<a href="https://arxiv.org/abs/2404.17739" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Leveraging Large Language Models for Software Model Completion: Results from Industrial and Public Datasets" [2024-06] [<a href="https://arxiv.org/abs/2406.17651" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Studying and Benchmarking Large Language Models For Log Level Suggestion" [2024-10] [<a href="https://arxiv.org/abs/2410.08499" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Model Is Not Built By A Single Prompt: LLM-Based Domain Modeling With Question Decomposition" [2024-10] [<a href="https://arxiv.org/abs/2410.09854" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"On the Utility of Domain Modeling Assistance with Large Language Models" [2024-10] [<a href="https://arxiv.org/abs/2410.12577" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"On the use of Large Language Models in Model-Driven Engineering" [2024-10] [<a href="https://arxiv.org/abs/2410.17370" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM as a code generator in Agile Model Driven Development" [2024-10] [<a href="https://arxiv.org/abs/2410.18489" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Assessing UML Models by ChatGPT: Implications for Education" [2024-12] [<a href="https://arxiv.org/abs/2412.17200" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Requirement Engineering</h3><a id="user-content-requirement-engineering" class="anchor" aria-label="Permalink: Requirement Engineering" href="#requirement-engineering"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"A Transformer-based Approach for Abstractive Summarization of Requirements from Obligations in Software Engineering Contracts" [2023-09] [RE 2023] [<a href="https://ieeexplore.ieee.org/document/10260954" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Advancing Requirements Engineering through Generative AI: Assessing the Role of LLMs" [2023-10] [<a href="https://arxiv.org/abs/2310.13976" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Requirements Engineering using Generative AI: Prompts and Prompting Patterns" [2023-11] [<a href="https://arxiv.org/abs/2311.03832" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Prioritizing Software Requirements Using Large Language Models" [2024-04] [<a href="https://arxiv.org/abs/2405.01564" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Lessons from the Use of Natural Language Inference (NLI) in Requirements Engineering Tasks" [2024-04] [<a href="https://arxiv.org/abs/2405.05135" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing Legal Compliance and Regulation Analysis with Large Language Models" [2024-04] [<a href="https://arxiv.org/abs/2404.17522" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MARE: Multi-Agents Collaboration Framework for Requirements Engineering" [2024-05] [<a href="https://arxiv.org/abs/2405.03256" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Natural Language Processing for Requirements Traceability" [2024-05] [<a href="https://arxiv.org/abs/2405.10845" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Multilingual Crowd-Based Requirements Engineering Using Large Language Models" [2024-08] [<a href="https://arxiv.org/abs/2408.06505" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"From Specifications to Prompts: On the Future of Generative LLMs in Requirements Engineering" [2024-08] [<a href="https://arxiv.org/abs/2408.09127" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Leveraging LLMs for the Quality Assurance of Software Requirements" [2024-08] [<a href="https://arxiv.org/abs/2408.10886" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Generative AI for Requirements Engineering: A Systematic Literature Review" [2024-09] [<a href="https://arxiv.org/abs/2409.06741" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Fine-grained Sentiment Analysis of App Reviews using Large Language Models: An Evaluation Study" [2024-09] [<a href="https://arxiv.org/abs/2409.07162" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Leveraging Large Language Models for Predicting Cost and Duration in Software Engineering Projects" [2024-09] [<a href="https://arxiv.org/abs/2409.09617" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Privacy Policy Analysis through Prompt Engineering for LLMs" [2024-09] [<a href="https://arxiv.org/abs/2409.14879" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Exploring Requirements Elicitation from App Store User Reviews Using Large Language Models" [2024-09] [<a href="https://arxiv.org/abs/2409.15473" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM-Cure: LLM-based Competitor User Review Analysis for Feature Enhancement" [2024-09] [<a href="https://arxiv.org/abs/2409.15724" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automatic Instantiation of Assurance Cases from Patterns Using Large Language Models" [2024-10] [<a href="https://arxiv.org/abs/2410.05488" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Whose fault is it anyway? SILC: Safe Integration of LLM-Generated Code" [2024-10] [<a href="https://arxiv.org/abs/2410.18703" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Assured Automatic Programming via Large Language Models" [2024-10] [<a href="https://arxiv.org/abs/2410.18494" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Does GenAI Make Usability Testing Obsolete?" [2024-11] [<a href="https://arxiv.org/abs/2411.00634" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Exploring LLMs for Verifying Technical System Specifications Against Requirements" [2024-11] [<a href="https://arxiv.org/abs/2411.11582" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards the LLM-Based Generation of Formal Specifications from Natural-Language Contracts: Early Experiments with Symboleo" [2024-11] [<a href="https://arxiv.org/abs/2411.15898" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"PassionNet: An Innovative Framework for Duplicate and Conflicting Requirements Identification" [2024-12] [<a href="https://arxiv.org/abs/2412.01657" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Generative Language Models Potential for Requirement Engineering Applications: Insights into Current Strengths and Limitations" [2024-12] [<a href="https://arxiv.org/abs/2412.00959" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LicenseGPT: A Fine-tuned Foundation Model for Publicly Available Dataset License Compliance" [2024-12] [<a href="https://arxiv.org/abs/2501.00106" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"On the Impact of Requirements Smells in Prompts: The Case of Automated Traceability" [2025-01] [<a href="https://arxiv.org/abs/2501.04810" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Analysis of LLMs vs Human Experts in Requirements Engineering" [2025-01] [<a href="https://arxiv.org/abs/2501.19297" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">6. Analysis of AI-Generated Code</h2><a id="user-content-6-analysis-of-ai-generated-code" class="anchor" aria-label="Permalink: 6. Analysis of AI-Generated Code" href="#6-analysis-of-ai-generated-code"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Security and Vulnerabilities</h3><a id="user-content-security-and-vulnerabilities" class="anchor" aria-label="Permalink: Security and Vulnerabilities" href="#security-and-vulnerabilities"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion" [2021-08] [USENIX Security Symposium 2021] [<a href="https://www.usenix.org/conference/usenixsecurity21/presentation/schuster" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Is GitHub's Copilot as Bad as Humans at Introducing Vulnerabilities in Code?" [2022-04] [Empir. Softw. Eng.] [<a href="https://arxiv.org/abs/2204.04741" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Lost at C: A User Study on the Security Implications of Large Language Model Code Assistants" [2022-08] [USENIX Security Symposium 2023] [<a href="https://arxiv.org/abs/2208.09727" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Do Users Write More Insecure Code with AI Assistants?" [2022-1] [CCS 2023] [<a href="https://arxiv.org/abs/2211.03622" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Models for Code: Security Hardening and Adversarial Testing" [2023-02] [CCS 2023] [<a href="https://arxiv.org/abs/2302.05319" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Purple Llama CyberSecEval: A Secure Coding Benchmark for Language Models" [2023-12] [<a href="https://arxiv.org/abs/2312.04724" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeAttack: Revealing Safety Generalization Challenges of Large Language Models via Code Completion" [2024-03] [ACL 2024 Findings] [<a href="https://arxiv.org/abs/2403.07865" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Just another copy and paste? Comparing the security vulnerabilities of ChatGPT generated code and StackOverflow answers" [2024-03] [<a href="https://arxiv.org/abs/2403.15600" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DeVAIC: A Tool for Security Assessment of AI-generated Code" [2024-04] [<a href="https://arxiv.org/abs/2404.07548" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CyberSecEval 2: A Wide-Ranging Cybersecurity Evaluation Suite for Large Language Models" [2024-04] [<a href="https://arxiv.org/abs/2404.13161" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLMs in Web-Development: Evaluating LLM-Generated PHP code unveiling vulnerabilities and limitations" [2024-04] [<a href="https://arxiv.org/abs/2404.14459" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Do Neutral Prompts Produce Insecure Code? FormAI-v2 Dataset: Labelling Vulnerabilities in Code Generated by Large Language Models" [2024-04] [<a href="https://arxiv.org/abs/2404.18353" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Codexity: Secure AI-assisted Code Generation" [2024-05] [<a href="https://arxiv.org/abs/2405.03927" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Measuring Impacts of Poisoning on Model Parameters and Embeddings for Large Language Models of Code" [2024-05] [<a href="https://arxiv.org/abs/2405.11466" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection" [2024-06] [<a href="https://arxiv.org/abs/2406.06822" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Is Your AI-Generated Code Really Secure? Evaluating Large Language Models on Secure Code Generation with CodeSecEval" [2024-07] [<a href="https://arxiv.org/abs/2407.02395" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Prompting Techniques for Secure Code Generation: A Systematic Investigation" [2024-07] [<a href="https://arxiv.org/abs/2407.07064" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"TAPI: Towards Target-Specific and Adversarial Prompt Injection against Code LLMs" [2024-07] [<a href="https://arxiv.org/abs/2407.09164" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MaPPing Your Model: Assessing the Impact of Adversarial Attacks on LLM-based Programming Assistants" [2024-07] [<a href="https://arxiv.org/abs/2407.11072" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Black-Box Adversarial Attacks on LLM-Based Code Completion" [2024-08] [ICML 2025] [<a href="https://arxiv.org/abs/2408.02509" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Eliminating Backdoors in Neural Code Models via Trigger Inversion" [2024-08] [<a href="https://arxiv.org/abs/2408.04683" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">""You still have to study" -- On the Security of LLM generated code" [2024-08] [<a href="https://arxiv.org/abs/2408.07106" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How Well Do Large Language Models Serve as End-to-End Secure Code Producers?" [2024-08] [<a href="https://arxiv.org/abs/2408.10495" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"While GitHub Copilot Excels at Coding, Does It Ensure Responsible Output?" [2024-08] [<a href="https://arxiv.org/abs/2408.11006" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"PromSec: Prompt Optimization for Secure Generation of Functional Source Code with Large Language Models (LLMs)" [2024-09] [<a href="https://arxiv.org/abs/2409.12699" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RMCBench: Benchmarking Large Language Models' Resistance to Malicious Code" [2024-09] [<a href="https://arxiv.org/abs/2409.15154" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Artificial-Intelligence Generated Code Considered Harmful: A Road Map for Secure and High-Quality Code Generation" [2024-09] [<a href="https://arxiv.org/abs/2409.19182" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SecCoder: Towards Generalizable and Robust Secure Code Generation" [2024-10] [EMNLP 2024] [<a href="https://arxiv.org/abs/2410.01488" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Demonstration Attack against In-Context Learning for Code Intelligence" [2024-10] [<a href="https://arxiv.org/abs/2410.02841" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Hallucinating AI Hijacking Attack: Large Language Models and Malicious Code Recommenders" [2024-10] [<a href="https://arxiv.org/abs/2410.06462" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SecCodePLT: A Unified Platform for Evaluating the Security of Code GenAI" [2024-10] [<a href="https://arxiv.org/abs/2410.11096" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Security of Language Models for Code: A Systematic Literature Review" [2024-10] [<a href="https://arxiv.org/abs/2410.15631" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RedCode: Risky Code Execution and Generation Benchmark for Code Agents" [2024-11] [<a href="https://arxiv.org/abs/2411.07781" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ProSec: Fortifying Code LLMs with Proactive Security Alignment" [2024-11] [ICML 2025] [<a href="https://arxiv.org/abs/2411.12882" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs" [2024-11] [<a href="https://arxiv.org/abs/2411.18216" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SABER: Model-agnostic Backdoor Attack on Chain-of-Thought in Neural Code Generation" [2024-12] [<a href="https://arxiv.org/abs/2412.05829" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CWEval: Outcome-driven Evaluation on Functionality and Security of LLM Code Generation" [2025-01] [<a href="https://arxiv.org/abs/2501.08200" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Security and Quality in LLM-Generated Code: A Multi-Language, Multi-Model Analysis" [2025-02] [<a href="https://arxiv.org/abs/2502.01853" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Exploring the Security Threats of Knowledge Base Poisoning in Retrieval-Augmented Code Generation" [2025-02] [<a href="https://arxiv.org/abs/2502.03233" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Benchmarking Prompt Engineering Techniques for Secure Code Generation with GPT Models" [2025-02] [<a href="https://arxiv.org/abs/2502.06039" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Do LLMs Consider Security? An Empirical Study on Responses to Programming Questions" [2025-02] [<a href="https://arxiv.org/abs/2502.14202" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"XOXO: Stealthy Cross-Origin Context Poisoning Attacks against AI Coding Assistants" [2025-03] [<a href="https://arxiv.org/abs/2503.14281" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Comprehensive Study of LLM Secure Code Generation" [2025-03] [<a href="https://arxiv.org/abs/2503.15554" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Smoke and Mirrors: Jailbreaking LLM-based Code Generation via Implicit Malicious Prompts" [2025-03] [<a href="https://arxiv.org/abs/2503.17953" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation via Knowledge Injection" [2025-04] [<a href="https://arxiv.org/abs/2504.16429" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can You Really Trust Code Copilots? Evaluating Large Language Models from a Code Security Perspective" [2025-05] [ACL 2025] [<a href="https://arxiv.org/abs/2505.10494" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Teaching an Old LLM Secure Coding: Localized Preference Optimization on Distilled Preferences" [2025-05] [ACL 2025] [<a href="https://arxiv.org/abs/2506.00419" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code" [2025-06] [<a href="https://arxiv.org/abs/2506.05692" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"PurpCode: Reasoning for Safer Code Generation" [2025-07] [<a href="https://arxiv.org/abs/2507.19060" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RedCoder: Automated Multi-Turn Red Teaming for Code LLMs" [2025-06] [<a href="https://arxiv.org/abs/2507.22063" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A.S.E: A Repository-Level Benchmark for Evaluating Security in AI-Generated Code" [2025-08] [<a href="https://arxiv.org/abs/2508.18106" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Localizing Malicious Outputs from CodeLLM" [2025-09] [<a href="https://arxiv.org/abs/2509.17070" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"SecureAgentBench: Benchmarking Secure Code Generation under Realistic Vulnerability Scenarios" [2025-09] [<a href="https://arxiv.org/abs/2509.22097" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Breaking the Code: Security Assessment of AI Code Agents Through Systematic Jailbreaking Attacks" [2025-10] [<a href="https://arxiv.org/abs/2510.01359" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"When "Correct" Is Not Safe: Can We Trust Functionally Correct Patches Generated by Code Agents?" [2025-10] [<a href="https://arxiv.org/abs/2510.17862" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Correctness</h3><a id="user-content-correctness" class="anchor" aria-label="Permalink: Correctness" href="#correctness"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"An Empirical Evaluation of GitHub Copilot's Code Suggestions" [2022-05] [MSR 2022] [<a href="https://ieeexplore.ieee.org/document/9796235" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Models and Simple, Stupid Bugs" [2023-03] [MSR 2023] [<a href="https://arxiv.org/abs/2303.11455" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating the Code Quality of AI-Assisted Code Generation Tools: An Empirical Study on GitHub Copilot, Amazon CodeWhisperer, and ChatGPT" [2023-04] [<a href="https://arxiv.org/abs/2304.10778" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"No Need to Lift a Finger Anymore? Assessing the Quality of Code Generation by ChatGPT" [2023-08] [<a href="https://arxiv.org/abs/2308.04838" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?" [2024-02] [ACL 2024 Findings] [<a href="https://arxiv.org/abs/2402.19475" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Bugs in Large Language Models Generated Code: An Empirical Study" [2024-03] [<a href="https://arxiv.org/abs/2403.08937" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ChatGPT Incorrectness Detection in Software Reviews" [2024-03] [<a href="https://arxiv.org/abs/2403.16347" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Validating LLM-Generated Programs with Metamorphic Prompt Testing" [2024-06] [<a href="https://arxiv.org/abs/2406.06864" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Where Do Large Language Models Fail When Generating Code?" [2024-06] [<a href="https://arxiv.org/abs/2406.08731" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"GitHub Copilot: the perfect Code compLeeter?" [2024-06] [<a href="https://arxiv.org/abs/2406.11326" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"What's Wrong with Your Code Generated by Large Language Models? An Extensive Study" [2024-07] [<a href="https://arxiv.org/abs/2407.06153" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Uncovering Weaknesses in Neural Code Generation" [2024-07] [<a href="https://arxiv.org/abs/2407.09793" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Understanding Defects in Generated Codes by Language Models" [2024-08] [<a href="https://arxiv.org/abs/2408.13372" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeSift: An LLM-Based Reference-Less Framework for Automatic Code Validation" [2024-08] [<a href="https://arxiv.org/abs/2408.15630" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Examination of Code generated by Large Language Models" [2024-08] [<a href="https://arxiv.org/abs/2408.16601" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Fixing Code Generation Errors for Large Language Models" [2024-09] [<a href="https://arxiv.org/abs/2409.00676" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can OpenSource beat ChatGPT? -- A Comparative Study of Large Language Models for Text-to-Code Generation" [2024-09] [<a href="https://arxiv.org/abs/2409.04164" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Insights from Benchmarking Frontier Language Models on Web App Code Generation" [2024-09] [<a href="https://arxiv.org/abs/2409.05177" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating the Performance of Large Language Models in Competitive Programming: A Multi-Year, Multi-Grade Analysis" [2024-09] [<a href="https://arxiv.org/abs/2409.09054" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Case Study of Web App Coding with OpenAI Reasoning Models" [2024-09] [<a href="https://arxiv.org/abs/2409.13773" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An evaluation of LLM code generation capabilities through graded exercises" [2024-10] [<a href="https://arxiv.org/abs/2410.16292" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Deep Dive Into Large Language Model Code Generation Mistakes: What and Why?" [2024-11] [<a href="https://arxiv.org/abs/2411.01414" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating ChatGPT-3.5 Efficiency in Solving Coding Problems of Different Complexity Levels: An Empirical Analysis" [2024-11] [<a href="https://arxiv.org/abs/2411.07529" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM4DS: Evaluating Large Language Models for Data Science Code Generation" [2024-11] [<a href="https://arxiv.org/abs/2411.11908" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Preliminary Study of Multilingual Code Language Models for Code Generation Task Using Translated Benchmarks" [2024-11] [<a href="https://arxiv.org/abs/2411.15470" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Analyzing the Energy and Accuracy of LLMs in Software Development" [2024-11] [<a href="https://arxiv.org/abs/2412.00329" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How Well Do LLMs Generate Code for Different Application Domains? Benchmark and Evaluation" [2024-12] [<a href="https://arxiv.org/abs/2412.18573" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM-ProS: Analyzing Large Language Models' Performance in Competitive Problem Solving" [2025-02] [<a href="https://arxiv.org/abs/2502.04355" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Assessing Correctness in LLM-Based Code Generation via Uncertainty Estimation" [2025-02] [<a href="https://arxiv.org/abs/2502.11620" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Performance Evaluation of Large Language Models in Statistical Programming" [2025-02] [<a href="https://arxiv.org/abs/2502.13117" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Unveiling Pitfalls: Understanding Why AI-driven Code Agents Fail at GitHub Issue Resolution" [2025-03] [<a href="https://arxiv.org/abs/2503.12374" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Are "Solved Issues" in SWE-bench Really Solved Correctly? An Empirical Study" [2025-03] [<a href="https://arxiv.org/abs/2503.15223" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Hallucination</h3><a id="user-content-hallucination" class="anchor" aria-label="Permalink: Hallucination" href="#hallucination"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Exploring and Evaluating Hallucinations in LLM-Powered Code Generation" [2024-04] [<a href="https://arxiv.org/abs/2404.00971" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeHalu: Code Hallucinations in LLMs Driven by Execution-based Verification" [2024-04] [<a href="https://arxiv.org/abs/2405.00253" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs" [2024-06] [<a href="https://arxiv.org/abs/2406.10279" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code Hallucination" [2024-07] [<a href="https://arxiv.org/abs/2407.04831" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"On Mitigating Code LLM Hallucinations with API Documentation" [2024-07] [<a href="https://arxiv.org/abs/2407.09726" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeMirage: Hallucinations in Code Generated by Large Language Models" [2024-08] [<a href="https://arxiv.org/abs/2408.08333" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLM Hallucinations in Practical Code Generation: Phenomena, Mechanism, and Mitigation" [2024-09] [<a href="https://arxiv.org/abs/2409.20550" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Collu-Bench: A Benchmark for Predicting Language Model Hallucinations in Code" [2024-10] [<a href="https://arxiv.org/abs/2410.09997" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ETF: An Entity Tracing Framework for Hallucination Detection in Code Summaries" [2024-10] [ACL 2025] [<a href="https://arxiv.org/abs/2410.14748" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Hallucination by Code Generation LLMs: Taxonomy, Benchmarks, Mitigation, and Challenges" [2025-04] [<a href="https://arxiv.org/abs/2504.20799" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Hallucinations in Code Change to Natural Language Generation: Prevalence and Evaluation of Detection Metrics" [2025-08] [<a href="https://arxiv.org/abs/2508.08661" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Efficiency</h3><a id="user-content-efficiency" class="anchor" aria-label="Permalink: Efficiency" href="#efficiency"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"EffiBench: Benchmarking the Efficiency of Automatically Generated Code" [2024-02] [NeurIPS 2024] [<a href="https://arxiv.org/abs/2402.02037" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Mercury: A Code Efficiency Benchmark for Code Large Language Models" [2024-02] [NeurIPS 2024] [<a href="https://arxiv.org/abs/2402.07844" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"On Evaluating the Efficiency of Source Code Generated by LLMs" [2024-04] [<a href="https://arxiv.org/abs/2404.06041" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Controlled Experiment on the Energy Efficiency of the Source Code Generated by Code Llama" [2024-05] [<a href="https://arxiv.org/abs/2405.03616" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"From Effectiveness to Efficiency: Comparative Evaluation of Code Generated by LCGMs for Bilingual Programming Questions" [2024-06] [<a href="https://arxiv.org/abs/2406.00602" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How Efficient is LLM-Generated Code? A Rigorous &amp; High-Standard Benchmark" [2024-06] [ICLR 2025] [<a href="https://arxiv.org/abs/2406.06647" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?" [2024-07] [EMNLP 2024] [<a href="https://arxiv.org/abs/2407.14044" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Performance Study of LLM-Generated Code on Leetcode" [2024-07] [<a href="https://arxiv.org/abs/2407.21579" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating Language Models for Efficient Code Generation" [2024-08] [<a href="https://arxiv.org/abs/2408.06450" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"EffiCoder: Enhancing Code Generation in Large Language Models through Efficiency-Aware Fine-tuning" [2024-10] [ICML 2025] [<a href="https://arxiv.org/abs/2410.10209" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Rethinking Code Refinement: Learning to Judge Code Efficiency" [2024-10] [EMNLP 2024 Findings] [<a href="https://arxiv.org/abs/2410.22375" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Generating Energy-efficient code with LLMs" [2024-11] [<a href="https://arxiv.org/abs/2411.10599" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An exploration of the effect of quantisation on energy consumption and inference time of StarCoder2" [2024-11] [<a href="https://arxiv.org/abs/2411.12758" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ACECode: A Reinforcement Learning Framework for Aligning Code Efficiency and Correctness in Code Language Models" [2024-12] [<a href="https://arxiv.org/abs/2412.17264" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AI-Powered, But Power-Hungry? Energy Efficiency of LLM-Generated Code" [2025-02] [<a href="https://arxiv.org/abs/2502.02412" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Unveiling Inefficiencies in LLM-Generated Code: Toward a Comprehensive Taxonomy" [2025-03] [<a href="https://arxiv.org/abs/2503.06327" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"EffiBench-X: A Multi-Language Benchmark for Measuring Efficiency of LLM-Generated Code" [2025-05] [<a href="https://arxiv.org/abs/2505.13004" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Evaluating the Energy-Efficiency of the Code Generated by LLMs" [2025-05] [<a href="https://arxiv.org/abs/2505.20324" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Robustness</h3><a id="user-content-robustness" class="anchor" aria-label="Permalink: Robustness" href="#robustness"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Beyond Accuracy: Evaluating Self-Consistency of Code Large Language Models with IdentityChain" [2023-10] [<a href="https://arxiv.org/abs/2310.14053" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Do Large Code Models Understand Programming Concepts? A Black-box Approach" [2024-02] [ICML 2024] [<a href="https://arxiv.org/abs/2402.05980" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Syntactic Robustness for LLM-based Code Generation" [2024-04] [<a href="https://arxiv.org/abs/2404.01535" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"NLPerturbator: Studying the Robustness of Code LLMs to Natural Language Variations" [2024-06] [<a href="https://arxiv.org/abs/2406.19783" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Empirical Study on Capability of Large Language Models in Understanding Code Semantics" [2024-07] [<a href="https://arxiv.org/abs/2407.03611" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Comparing Robustness Against Adversarial Attacks in Code Generation: LLM-Generated vs. Human-Written" [2024-11] [<a href="https://arxiv.org/abs/2411.10565" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"On the Adversarial Robustness of Instruction-Tuned Large Language Models for Code" [2024-11] [<a href="https://arxiv.org/abs/2411.19508" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"What You See Is Not Always What You Get: An Empirical Study of Code Comprehension by Large Language Models" [2024-12] [<a href="https://arxiv.org/abs/2412.08098" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing the Robustness of LLM-Generated Code: Empirical Study and Framework" [2025-03] [<a href="https://arxiv.org/abs/2503.20197" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CODECRASH: Stress Testing LLM Reasoning under Structural and Semantic Perturbations" [2025-04] [<a href="https://arxiv.org/abs/2504.14119" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Success is in the Details: Evaluate and Enhance Details Sensitivity of Code LLMs through Counterfactuals" [2025-05] [<a href="https://arxiv.org/abs/2505.14597" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Prompt Variability Effects On LLM Code Generation" [2025-06] [<a href="https://arxiv.org/abs/2506.10204" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MOCHA: Are Code Language Models Robust Against Multi-Turn Malicious Coding Prompts?" [2025-07] [<a href="https://arxiv.org/abs/2507.19598" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"When Prompts Go Wrong: Evaluating Code Model Robustness to Ambiguous, Contradictory, and Incomplete Task Descriptions" [2025-07] [<a href="https://arxiv.org/abs/2507.20439" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Prompt Stability in Code LLMs: Measuring Sensitivity across Emotion- and Personality-Driven Variations" [2025-09] [<a href="https://arxiv.org/abs/2509.13680" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Interpretability</h3><a id="user-content-interpretability" class="anchor" aria-label="Permalink: Interpretability" href="#interpretability"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"A Critical Study of What Code-LLMs (Do Not) Learn" [2024-06] [ACL 2024 Findings] [<a href="https://arxiv.org/abs/2406.11930" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Looking into Black Box Code Language Models" [2024-07] [<a href="https://arxiv.org/abs/2407.04868" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DeepCodeProbe: Towards Understanding What Models Trained on Code Learn" [2024-07] [<a href="https://arxiv.org/abs/2407.08890" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations" [2024-07] [<a href="https://arxiv.org/abs/2407.08983" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Exploring Coding Spot: Understanding Parametric Contributions to LLM Coding Performance" [2024-12] [<a href="https://arxiv.org/abs/2412.07113" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Correctness Assessment of Code Generated by Large Language Models Using Internal Representations" [2025-01] [<a href="https://arxiv.org/abs/2501.12934" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeSCM: Causal Analysis for Multi-Modal Code Generation" [2025-02] [<a href="https://arxiv.org/abs/2502.05150" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Mechanistic Understanding of Language Models in Syntactic Code Completion" [2025-02] [<a href="https://arxiv.org/abs/2502.18499" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"On Explaining (Large) Language Models For Code Using Global Code-Based Explanations" [2025-03] [<a href="https://arxiv.org/abs/2503.16771" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How Programming Concepts and Neurons Are Shared in Code Language Models" [2025-06] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2506.01074" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Analyzing Latent Concepts in Code Language Models" [2025-10] [<a href="https://arxiv.org/abs/2510.00476" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">API Usage</h3><a id="user-content-api-usage" class="anchor" aria-label="Permalink: API Usage" href="#api-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study" [2024-06] [<a href="https://arxiv.org/abs/2406.09834" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Is ChatGPT a Good Software Librarian? An Exploratory Study on the Use of ChatGPT for Software Library Recommendations" [2024-08] [<a href="https://arxiv.org/abs/2408.05128" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Systematic Evaluation of Large Code Models in API Suggestion: When, Which, and How" [2024-09] [<a href="https://arxiv.org/abs/2409.13178" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AutoAPIEval: A Framework for Automated Evaluation of LLMs in API-Oriented Code Generation" [2024-09] [<a href="https://arxiv.org/abs/2409.15228" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ExploraCoder: Advancing code generation for multiple unseen APIs via planning and chained exploration" [2024-12] [ACL 2025] [<a href="https://arxiv.org/abs/2412.05366" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ADC: Enhancing Function Calling Via Adversarial Datasets and Code Line-Level Feedback" [2024-12] [<a href="https://arxiv.org/abs/2412.17754" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CODESYNC: Synchronizing Large Language Models with Dynamic Code Evolution at Scale" [2025-02] [ICML 2025] [<a href="https://arxiv.org/abs/2502.16645" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"RustEvo^2: An Evolving Benchmark for API Evolution in LLM-based Rust Code Generation" [2025-03] [<a href="https://arxiv.org/abs/2503.16922" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Identifying and Mitigating API Misuse in Large Language Models" [2025-03] [<a href="https://arxiv.org/abs/2503.22821" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ReCode: Updating Code API Knowledge with Reinforcement Learning" [2025-06] [<a href="https://arxiv.org/abs/2506.20495" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Privacy</h3><a id="user-content-privacy" class="anchor" aria-label="Permalink: Privacy" href="#privacy"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Does Your Neural Code Completion Model Use My Code? A Membership Inference Approach" [2024-04] [<a href="https://arxiv.org/abs/2404.14296" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeCipher: Learning to Obfuscate Source Code Against LLMs" [2024-10] [<a href="https://arxiv.org/abs/2410.05797" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Decoding Secret Memorization in Code LLMs Through Token-Level Characterization" [2024-10] [<a href="https://arxiv.org/abs/2410.08858" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"When Fine-Tuning LLMs Meets Data Privacy: An Empirical Study of Federated Learning in LLM-Based Program Repair" [2024-12] [<a href="https://arxiv.org/abs/2412.01072" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CallNavi: A Study and Challenge on Function Calling Routing and Invocation in Large Language Models" [2025-01] [<a href="https://arxiv.org/abs/2501.05255" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Mitigating Sensitive Information Leakage in LLMs4Code through Machine Unlearning" [2025-02] [<a href="https://arxiv.org/abs/2502.05739" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards Mitigating API Hallucination in Code Generated by LLMs with Hierarchical Dependency Aware" [2025-05] [<a href="https://arxiv.org/abs/2505.05057" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Bias</h3><a id="user-content-bias" class="anchor" aria-label="Permalink: Bias" href="#bias"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Exploring Multi-Lingual Bias of Large Code Models in Code Generation" [2024-04] [<a href="https://arxiv.org/abs/2404.19368" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Mitigating Gender Bias in Code Large Language Models via Model Editing" [2024-10] [<a href="https://arxiv.org/abs/2410.07820" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Bias Unveiled: Investigating Social Bias in LLM-Generated Code" [2024-11] [<a href="https://arxiv.org/abs/2411.10351" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"FairCode: Evaluating Social Bias of LLMs in Code Generation" [2025-01] [<a href="https://arxiv.org/abs/2501.05396" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Invisible Hand: Unveiling Provider Bias in Large Language Models for Code Generation" [2025-01] [ACL 2025] [<a href="https://arxiv.org/abs/2501.07849" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Addressing Popularity Bias in Third-Party Library Recommendations Using LLMs" [2025-01] [<a href="https://arxiv.org/abs/2501.10313" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLMs Love Python: A Study of LLMs' Bias for Programming Languages and Libraries" [2025-03] [<a href="https://arxiv.org/abs/2503.17181" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Contamination</h3><a id="user-content-contamination" class="anchor" aria-label="Permalink: Contamination" href="#contamination"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Investigating the Impact of Data Contamination of Large Language Models in Text-to-SQL Translation" [2024-02] [ACL 2024 Findings] [<a href="https://arxiv.org/abs/2402.08100" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Quantifying Contamination in Evaluating Code Generation Capabilities of Language Models" [2024-03] [ACL 2024] [<a href="https://arxiv.org/abs/2403.04811" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Rethinking the effects of data contamination in Code Intelligence" [2025-06] [<a href="https://arxiv.org/abs/2506.02791" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">AI-Generated Code Detection</h3><a id="user-content-ai-generated-code-detection" class="anchor" aria-label="Permalink: AI-Generated Code Detection" href="#ai-generated-code-detection"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Who Wrote this Code? Watermarking for Code Generation" [2023-05] [ACL 2024] [<a href="https://arxiv.org/abs/2305.15060" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Zero-Shot Detection of Machine-Generated Codes" [2023-10] [<a href="https://arxiv.org/abs/2310.05103" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers" [2024-01] [ICSE 2025] [<a href="https://arxiv.org/abs/2401.06461" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code" [2024-04] [EMNLP 2024 Findings] [<a href="https://arxiv.org/abs/2404.15639" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ChatGPT Code Detection: Techniques for Uncovering the Source of Code" [2024-05] [<a href="https://arxiv.org/abs/2405.15512" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Uncovering LLM-Generated Code: A Zero-Shot Synthetic Code Detector via Code Rewriting" [2024-05] [<a href="https://arxiv.org/abs/2405.16133" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automatic Detection of LLM-generated Code: A Case Study of Claude 3 Haiku" [2024-09] [<a href="https://arxiv.org/abs/2409.01382" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Empirical Study on Automatically Detecting AI-Generated Source Code: How Far Are We?" [2024-11] [<a href="https://arxiv.org/abs/2411.04299" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Distinguishing LLM-generated from Human-written Code by Contrastive Learning" [2024-11] [<a href="https://arxiv.org/abs/2411.04704" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Is This You, LLM? Recognizing AI-written Programs with Multilingual Code Stylometry" [2024-12] [<a href="https://arxiv.org/abs/2412.14611" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Investigating Efficacy of Perplexity in Detecting LLM-Generated Code" [2024-12] [<a href="https://arxiv.org/abs/2412.16525" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"AIGCodeSet: A New Annotated Dataset for AI Generated Code Detection" [2024-12] [<a href="https://arxiv.org/abs/2412.16594" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeVision: Detecting LLM-Generated Code Using 2D Token Probability Maps and Vision Models" [2025-01] [<a href="https://arxiv.org/abs/2501.03288" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Robust and Secure Code Watermarking for Large Language Models via ML/Crypto Codesign" [2025-02] [<a href="https://arxiv.org/abs/2502.02068" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Detection of LLM-Generated Java Code Using Discretized Nested Bigrams" [2025-02] [<a href="https://arxiv.org/abs/2502.15740" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Detection of LLM-Paraphrased Code and Identification of the Responsible LLM Using Coding Style Features" [2025-02] [<a href="https://arxiv.org/abs/2502.17749" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Marking Code Without Breaking It: Code Watermarking for Detecting LLM-Generated Code" [2025-02] [<a href="https://arxiv.org/abs/2502.18851" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual, Multi-Generator and Multi-Domain Settings" [2025-03] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2503.13733" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeMirage: A Multi-Lingual Benchmark for Detecting AI-Generated and Paraphrased Source Code from Production-Level LLMs" [2025-05] [<a href="https://arxiv.org/abs/2506.11059" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"I Know Which LLM Wrote Your Code Last Summer: LLM generated Code Stylometry for Authorship Attribution" [2025-06] [<a href="https://arxiv.org/abs/2506.17323" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Disappearing Ink: Obfuscation Breaks N-gram Code Watermarks in Theory and Practice" [2025-07] [<a href="https://arxiv.org/abs/2507.05512" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Droid: A Resource Suite for AI-Generated Code Detection" [2025-07] [<a href="https://arxiv.org/abs/2507.10583" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Optimizing Token Choice for Code Watermarking: A RL Approach" [2025-08] [<a href="https://arxiv.org/abs/2508.11925" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Models Are Effective Code Watermarkers" [2025-10] [<a href="https://arxiv.org/abs/2510.11251" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Others</h3><a id="user-content-others" class="anchor" aria-label="Permalink: Others" href="#others"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Code Membership Inference for Detecting Unauthorized Data Use in Code Pre-trained Language Models" [2023-12] [EMNLP 2024 Findings] [<a href="https://arxiv.org/abs/2312.07200" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Testing the Effect of Code Documentation on Large Language Model Code Understanding" [2024-04] [<a href="https://arxiv.org/abs/2404.03114" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Where Are Large Language Models for Code Generation on GitHub?" [2024-06] [<a href="https://arxiv.org/abs/2406.19544" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Beyond Functional Correctness: Investigating Coding Style Inconsistencies in Large Language Models" [2024-06] [<a href="https://arxiv.org/abs/2407.00456" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Benchmarking Language Model Creativity: A Case Study on Code Generation" [2024-07] [<a href="https://arxiv.org/abs/2407.09007" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Beyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models" [2024-07] [<a href="https://arxiv.org/abs/2407.11470" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Is Functional Correctness Enough to Evaluate Code Language Models? Exploring Diversity of Generated Codes" [2024-08] [<a href="https://arxiv.org/abs/2408.14504" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Strategic Optimization and Challenges of Large Language Models in Object-Oriented Programming" [2024-08] [<a href="https://arxiv.org/abs/2408.14834" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Survey on Evaluating Large Language Models in Code Generation Tasks" [2024-08] [<a href="https://arxiv.org/abs/2408.16498" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An exploratory analysis of Community-based Question-Answering Platforms and GPT-3-driven Generative AI: Is it the end of online community-based learning?" [2024-09] [<a href="https://arxiv.org/abs/2409.17473" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code Generation and Algorithmic Problem Solving Using Llama 3.1 405B" [2024-09] [<a href="https://arxiv.org/abs/2409.19027" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Benchmarking ChatGPT, Codeium, and GitHub Copilot: A Comparative Study of AI-Driven Programming and Debugging Assistants" [2024-09] [<a href="https://arxiv.org/abs/2409.19922" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Model Editing for LLMs4Code: How Far are We?" [2024-11] [<a href="https://arxiv.org/abs/2411.06638" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"An Empirical Study on LLM-based Agents for Automated Bug Fixing" [2024-11] [<a href="https://arxiv.org/abs/2411.10213" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Precision or Peril: Evaluating Code Quality from Quantized Large Language Models" [2024-11] [<a href="https://arxiv.org/abs/2411.10656" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Measuring Emergent Capabilities of LLMs for Software Engineering: How Far Are We?" [2024-11] [<a href="https://arxiv.org/abs/2411.17927" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Addressing Data Leakage in HumanEval Using Combinatorial Test Design" [2024-12] [<a href="https://arxiv.org/abs/2412.01526" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Less is More: Towards Green Code Large Language Models via Unified Structural Pruning" [2024-12] [<a href="https://arxiv.org/abs/2412.15921" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How Propense Are Large Language Models at Producing Code Smells? A Benchmarking Study" [2024-12] [<a href="https://arxiv.org/abs/2412.18989" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Deriving Coding-Specific Sub-Models from LLMs using Resource-Efficient Pruning" [2025-01] [<a href="https://arxiv.org/abs/2501.05248" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Do LLMs Provide Links to Code Similar to what they Generate? A Study with Gemini and Bing CoPilot" [2025-01] [<a href="https://arxiv.org/abs/2501.12134" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Comparing Human and LLM Generated Code: The Jury is Still Out!" [2025-01] [<a href="https://arxiv.org/abs/2501.16857" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"On the Possibility of Breaking Copyleft Licenses When Reusing Code Generated by ChatGPT" [2025-02] [<a href="https://arxiv.org/abs/2502.05023" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeIF: Benchmarking the Instruction-Following Capabilities of Large Language Models for Code Generation" [2025-02] [<a href="https://arxiv.org/abs/2502.19166" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How Diversely Can Language Models Solve Problems? Exploring the Algorithmic Diversity of Model-Generated Code" [2025-03] [<a href="https://arxiv.org/abs/2503.00691" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Memorize or Generalize? Evaluating LLM Code Generation with Evolved Questions" [2025-03] [<a href="https://arxiv.org/abs/2503.02296" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Human or LLM? A Comparative Study on Accessible Code Generation Capability" [2025-03] [<a href="https://arxiv.org/abs/2503.15885" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Automated Harmfulness Testing for Code Large Language Models" [2025-03] [<a href="https://arxiv.org/abs/2503.16740" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code Red! On the Harmfulness of Applying Off-the-shelf Large Language Models to Programming Tasks" [2025-04] [<a href="https://arxiv.org/abs/2504.01850" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Rethinking Repetition Problems of LLMs in Code Generation" [2025-05] [ACL 2025] [<a href="https://arxiv.org/abs/2505.10402" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Style2Code: A Style-Controllable Code Generation Framework with Dual-Modal Contrastive Representation Learning" [2025-05] [<a href="https://arxiv.org/abs/2505.19442" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">7. Human-LLM Interaction</h2><a id="user-content-7-human-llm-interaction" class="anchor" aria-label="Permalink: 7. Human-LLM Interaction" href="#7-human-llm-interaction"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models" [2022-04] [CHI EA 2022] [<a href="https://dl.acm.org/doi/abs/10.1145/3491101.3519665" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Grounded Copilot: How Programmers Interact with Code-Generating Models" [2022-06] [OOPSLA 2023] [<a href="https://arxiv.org/abs/2206.15000" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming" [2022-10] [<a href="https://arxiv.org/abs/2210.14306" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Impact of AI on Developer Productivity: Evidence from GitHub Copilot" [2023-02] [<a href="https://arxiv.org/abs/2302.06590" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Programmer's Assistant: Conversational Interaction with a Large Language Model for Software Development" [2023-02] [IUI 2023] [<a href="https://arxiv.org/abs/2302.07080" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">""It's Weird That it Knows What I Want": Usability and Interactions with Copilot for Novice Programmers" [2023-04] [ACM TCHI] [<a href="https://arxiv.org/abs/2304.02491" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"DevGPT: Studying Developer-ChatGPT Conversations" [2023-08] [<a href="https://arxiv.org/abs/2309.03914" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How Do Analysts Understand and Verify AI-Assisted Data Analyses?" [2023-09] [<a href="https://arxiv.org/abs/2309.10947" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How Novices Use LLM-Based Code Generators to Solve CS1 Coding Tasks in a Self-Paced Learning Environment" [2023-09] [Koli Calling 2023] [<a href="https://arxiv.org/abs/2309.14049" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Conversational Challenges in AI-Powered Data Science: Obstacles, Needs, and Design Opportunities" [2023-10] [<a href="https://arxiv.org/abs/2310.16164" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The RealHumanEval: Evaluating Large Language Models' Abilities to Support Programmers" [2024-04] [<a href="https://arxiv.org/abs/2404.02806" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Unlocking Adaptive User Experience with Generative AI" [2024-04] [<a href="https://arxiv.org/abs/2404.05442" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"BISCUIT: Scaffolding LLM-Generated Code with Ephemeral UIs in Computational Notebooks" [2024-04] [<a href="https://arxiv.org/abs/2404.07387" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How far are AI-powered programming assistants from meeting developers' needs?" [2024-04] [<a href="https://arxiv.org/abs/2404.12000" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Beyond Code Generation: An Observational Study of ChatGPT Usage in Software Engineering Practice" [2024-04] [<a href="https://arxiv.org/abs/2404.14901" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The GPT Surprise: Offering Large Language Model Chat in a Massive Coding Class Reduced Engagement but Increased Adopters Exam Performances" [2024-04] [<a href="https://arxiv.org/abs/2407.09975" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"amplified.dev: a living document that begins to sketch a vision for a future where developers are amplified, not automated" [2024-05] [<a href="https://amplified.dev" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Sketch Then Generate: Providing Incremental User Feedback and Guiding LLM Code Generation through Language-Oriented Code Sketches" [2024-05] [<a href="https://arxiv.org/abs/2405.03998" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Using AI Assistants in Software Development: A Qualitative Study on Security Practices and Concerns" [2024-05] [<a href="https://arxiv.org/abs/2405.06371" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Full Line Code Completion: Bringing AI to Desktop" [2024-05] [<a href="https://arxiv.org/abs/2405.08704" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Developers' Perceptions on the Impact of ChatGPT in Software Development: A Survey" [2024-05] [<a href="https://arxiv.org/abs/2405.12195" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Transformer-Based Approach for Smart Invocation of Automatic Code Completion" [2024-05] [<a href="https://arxiv.org/abs/2405.14753" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"A Study on Developer Behaviors for Validating and Repairing LLM-Generated Code Using Eye Tracking and IDE Actions" [2024-05] [<a href="https://arxiv.org/abs/2405.16081" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Analyzing Chat Protocols of Novice Programmers Solving Introductory Programming Tasks with ChatGPT" [2024-05] [<a href="https://arxiv.org/abs/2405.19132" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Benchmarking the Communication Competence of Code Generation for LLMs and LLM Agent" [2024-05] [<a href="https://arxiv.org/abs/2406.00215" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Learning Task Decomposition to Assist Humans in Competitive Programming" [2024-06] [ACL 2024] [<a href="https://arxiv.org/abs/2406.04604" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Hints-In-Browser: Benchmarking Language Models for Programming Feedback Generation" [2024-07] [NeurIPS 2024] [<a href="https://arxiv.org/abs/2406.05053" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Impact of AI-tooling on the Engineering Workspace" [2024-06] [<a href="https://arxiv.org/abs/2406.07683" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Using AI-Based Coding Assistants in Practice: State of Affairs, Perceptions, and Ways Forward" [2024-06] [<a href="https://arxiv.org/abs/2406.07765" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging" [2024-06] [EMNLP 2024 Findings] [<a href="https://arxiv.org/abs/2406.11709" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Transforming Software Development: Evaluating the Efficiency and Challenges of GitHub Copilot in Real-World Projects" [2024-06] [<a href="https://arxiv.org/abs/2406.17910" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Let the Code LLM Edit Itself When You Edit the Code" [2024-07] [ICLR 2025] [<a href="https://arxiv.org/abs/2407.03157" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Enhancing Computer Programming Education with LLMs: A Study on Effective Prompt Engineering for Python Code Generation" [2024-07] [<a href="https://arxiv.org/abs/2407.05437" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How Novice Programmers Use and Experience ChatGPT when Solving Programming Exercises in an Introductory Course" [2024-07] [<a href="https://arxiv.org/abs/2407.20792" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can Developers Prompt? A Controlled Experiment for Code Documentation Generation" [2024-08] [<a href="https://arxiv.org/abs/2408.00686" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Impact of Generative AI-Powered Code Generation Tools on Software Engineer Hiring: Recruiters' Experiences, Perceptions, and Strategies" [2024-09] [<a href="https://arxiv.org/abs/2409.00875" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Investigating the Role of Cultural Values in Adopting Large Language Models for Software Engineering" [2024-09] [<a href="https://arxiv.org/abs/2409.05055" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Impact of Large Language Models on Open-source Innovation: Evidence from GitHub Copilot" [2024-09] [<a href="https://arxiv.org/abs/2409.08379" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">""I Don't Use AI for Everything": Exploring Utility, Attitude, and Responsibility of AI-empowered Tools in Software Development" [2024-09] [<a href="https://arxiv.org/abs/2409.13343" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Harnessing the Potential of Gen-AI Coding Assistants in Public Sector Software Development" [2024-09] [<a href="https://arxiv.org/abs/2409.17434" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Understanding the Human-LLM Dynamic: A Literature Survey of LLM Use in Programming Tasks" [2024-10] [<a href="https://arxiv.org/abs/2410.01026" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Code-Survey: An LLM-Driven Methodology for Analyzing Large-Scale Codebases" [2024-10] [<a href="https://arxiv.org/abs/2410.01837" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The potential of LLM-generated reports in DevSecOps" [2024-10] [<a href="https://arxiv.org/abs/2410.01899" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"The Impact of Generative AI on Collaborative Open-Source Software Development: Evidence from GitHub Copilot" [2024-10] [<a href="https://arxiv.org/abs/2410.02091" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Exploring the Design Space of Cognitive Engagement Techniques with AI-Generated Code for Enhanced Learning" [2024-10] [<a href="https://arxiv.org/abs/2410.08922" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"One Step at a Time: Combining LLMs and Static Analysis to Generate Next-Step Hints for Programming Tasks" [2024-10] [<a href="https://arxiv.org/abs/2410.09268" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How much does AI impact development speed? An enterprise-based randomized controlled trial" [2024-10] [<a href="https://arxiv.org/abs/2410.12944" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Understanding the Effect of Algorithm Transparency of Model Explanations in Text-to-SQL Semantic Parsing" [2024-10] [<a href="https://arxiv.org/abs/2410.16283" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Dear Diary: A randomized controlled trial of Generative AI coding tools in the workplace" [2024-10] [<a href="https://arxiv.org/abs/2410.18334" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"LLMs are Imperfect, Then What? An Empirical Study on LLM Failures in Software Engineering" [2024-11] [<a href="https://arxiv.org/abs/2411.09916" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Human-In-the-Loop Software Development Agents" [2024-11] [<a href="https://arxiv.org/abs/2411.12924" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Amplifying human performance in combinatorial competitive programming" [2024-11] [<a href="https://arxiv.org/abs/2411.19744" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Why Do Developers Engage with ChatGPT in Issue-Tracker? Investigating Usage and Reliance on ChatGPT-Generated Code" [2024-12] [<a href="https://arxiv.org/abs/2412.06757" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Examining the Use and Impact of an AI Code Assistant on Developer Productivity and Experience in the Enterprise" [2024-12] [<a href="https://arxiv.org/abs/2412.06603" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Human and Machine: How Software Engineers Perceive and Engage with AI-Assisted Code Reviews Compared to Their Peers" [2025-01] [<a href="https://arxiv.org/abs/2501.02092" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards Decoding Developer Cognition in the Age of AI Assistants" [2025-01] [<a href="https://arxiv.org/abs/2501.02684" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Simulated Interactive Debugging" [2025-01] [<a href="https://arxiv.org/abs/2501.09694" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Towards Detecting Prompt Knowledge Gaps for Improved LLM-guided Issue Resolution" [2025-01] [MSR 2025] [<a href="https://arxiv.org/abs/2501.11709" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Experience with GitHub Copilot for Developer Productivity at Zoominfo" [2025-01] [<a href="https://arxiv.org/abs/2501.13282" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Analysis of Student-LLM Interaction in a Software Engineering Project" [2025-02] [<a href="https://arxiv.org/abs/2502.01273" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Understanding User Mental Models in AI-Driven Code Completion Tools: Insights from an Elicitation Study" [2025-02] [<a href="https://arxiv.org/abs/2502.02194" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeA11y: Making AI Coding Assistants Useful for Accessible Web Development" [2025-02] [<a href="https://arxiv.org/abs/2502.10884" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Training Turn-by-Turn Verifiers for Dialogue Tutoring Agents: The Curious Case of LLMs as Your Coding Tutors" [2025-02] [ACL 2025 Findings] [<a href="https://arxiv.org/abs/2502.13311" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"From Tools to Teammates: Evaluating LLMs in Multi-Session Coding Interactions" [2025-02] [ACL 2025] [<a href="https://arxiv.org/abs/2502.13791" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How Scientists Use Large Language Models to Program" [2025-02] [<a href="https://arxiv.org/abs/2502.17348" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Do Comments and Expertise Still Matter? An Experiment on Programmers' Adoption of AI-Generated JavaScript Code" [2025-03] [<a href="https://arxiv.org/abs/2503.11453" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Prompting LLMs for Code Editing: Struggles and Remedies" [2025-04] [<a href="https://arxiv.org/abs/2504.20196" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming" [2025-05] [ACL 2025] [<a href="https://arxiv.org/abs/2505.16667" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Intuition to Evidence: Measuring AI's True Impact on Developer Productivity" [2025-09] [<a href="https://arxiv.org/abs/2509.19708" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">8. Datasets</h2><a id="user-content-8-datasets" class="anchor" aria-label="Permalink: 8. Datasets" href="#8-datasets"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">8.1 Pretraining</h3><a id="user-content-81-pretraining" class="anchor" aria-label="Permalink: 8.1 Pretraining" href="#81-pretraining"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>
<p dir="auto"><strong>CodeSearchNet</strong>: "CodeSearchNet Challenge: Evaluating the State of Semantic Code Search" [2019-09] [<a href="https://arxiv.org/abs/1909.09436" rel="nofollow">paper</a>] [<a href="https://github.com/github/CodeSearchNet">repo</a>] [<a href="https://huggingface.co/datasets/code_search_net" rel="nofollow">data</a>]</p>
</li>
<li>
<p dir="auto"><strong>The Pile</strong>: "The Pile: An 800GB Dataset of Diverse Text for Language Modeling" [2020-12], [<a href="https://arxiv.org/abs/2101.00027" rel="nofollow">paper</a>] [<a href="https://pile.eleuther.ai/" rel="nofollow">data</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeParrot</strong>, 2022-02, [<a href="https://huggingface.co/datasets/codeparrot/github-code" rel="nofollow">data</a>]</p>
</li>
<li>
<p dir="auto"><strong>The Stack</strong>: "The Stack: 3 TB of permissively licensed source code" [2022-11] [<a href="https://arxiv.org/abs/2211.15533" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/bigcode/the-stack" rel="nofollow">data</a>]</p>
</li>
<li>
<p dir="auto"><strong>ROOTS</strong>: "The BigScience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset" [2023-03] [NeurIPS 2022 Datasets and Benchmarks Track] [<a href="https://arxiv.org/abs/2303.03915" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets?search=bigscience-data/roots" rel="nofollow">data</a>]</p>
</li>
<li>
<p dir="auto"><strong>The Stack v2</strong>: "StarCoder 2 and The Stack v2: The Next Generation" [2024-02] [<a href="https://arxiv.org/abs/2402.19173" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/bigcode/the-stack-v2-dedup" rel="nofollow">data</a>]</p>
</li>
<li>
<p dir="auto"><strong>The Heap</strong>: "The Heap: A Contamination-Free Multilingual Code Dataset for Evaluating Large Language Models" [2025-01] [<a href="https://arxiv.org/abs/2501.09653" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Large Language Models are Qualified Benchmark Builders: Rebuilding Pre-Training Datasets for Advancing Code Intelligence Tasks" [2025-04] [<a href="https://arxiv.org/abs/2504.19444" rel="nofollow">paper</a>]</p>
</li>
</ol>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">8.2 Benchmarks</h3><a id="user-content-82-benchmarks" class="anchor" aria-label="Permalink: 8.2 Benchmarks" href="#82-benchmarks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Integrated Benchmarks</h4><a id="user-content-integrated-benchmarks" class="anchor" aria-label="Permalink: Integrated Benchmarks" href="#integrated-benchmarks"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto"><strong>CodeXGLUE</strong>: "CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation" [2021-02] [NeurIPS Datasets and Benchmarks 2021] [<a href="https://arxiv.org/abs/2102.04664" rel="nofollow">paper</a>] [<a href="https://github.com/microsoft/CodeXGLUE">repo</a>] [<a href="https://huggingface.co/datasets?search=code_x_glue" rel="nofollow">data</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodefuseEval</strong>: "CodeFuse-13B: A Pretrained Multi-lingual Code Large Language Model" [2023-10] [<a href="https://arxiv.org/abs/2310.06266" rel="nofollow">paper</a>] [<a href="https://github.com/codefuse-ai/codefuse-evaluation">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeScope</strong>: "CodeScope: An Execution-based Multilingual Multitask Multidimensional Benchmark for Evaluating LLMs on Code Understanding and Generation" [2023-11] [ACL 2024] [<a href="https://arxiv.org/abs/2311.08588" rel="nofollow">paper</a>] [<a href="https://github.com/WeixiangYAN/CodeScope">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>LiveCodeBench</strong>: "LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code" [2024-03] [ICLR 2025] [<a href="https://arxiv.org/abs/2403.07974" rel="nofollow">paper</a>] [<a href="https://github.com/LiveCodeBench/LiveCodeBench">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeEditorBench</strong>: "CodeEditorBench: Evaluating Code Editing Capability of Large Language Models" [2024-04] [<a href="https://arxiv.org/abs/2404.03543" rel="nofollow">paper</a>] [<a href="https://github.com/CodeEditorBench/CodeEditorBench">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>Long Code Arena</strong>: "Long Code Arena: a Set of Benchmarks for Long-Context Code Models" [2024-06] [<a href="https://arxiv.org/abs/2406.11612" rel="nofollow">paper</a>] [<a href="https://github.com/JetBrains-Research/lca-baselines">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>CodeRAG-Bench</strong>: "CodeRAG-Bench: Can Retrieval Augment Code Generation?" [2024-06] [<a href="https://arxiv.org/abs/2406.14497" rel="nofollow">paper</a>] [<a href="https://github.com/code-rag-bench/code-rag-bench">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>LiveBench</strong>: "LiveBench: A Challenging, Contamination-Free LLM Benchmark" [2024-06] [<a href="https://arxiv.org/abs/2406.19314" rel="nofollow">paper</a>] [<a href="https://github.com/livebench/livebench">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>DebugEval</strong>: "Enhancing the Code Debugging Ability of LLMs via Communicative Agent Based Data Refinement" [2024-08] [<a href="https://arxiv.org/abs/2408.05006" rel="nofollow">paper</a>] [<a href="https://github.com/NEUIR/DebugEval">repo</a>]</p>
</li>
<li>
<p dir="auto"><strong>FullStack Bench</strong>: "FullStack Bench: Evaluating LLMs as Full Stack Coder" [2024-11] [<a href="https://arxiv.org/abs/2412.00535" rel="nofollow">paper</a>] [<a href="https://github.com/bytedance/FullStackBench">data</a>]</p>
</li>
<li>
<p dir="auto"><strong>StackEval</strong>: "StackEval: Benchmarking LLMs in Coding Assistance" [2024-12] [NeurIPS 2024] [<a href="https://arxiv.org/abs/2412.05288" rel="nofollow">paper</a>] [<a href="https://github.com/ProsusAI/stack-eval">data</a>]</p>
</li>
<li>
<p dir="auto">"How Should I Build A Benchmark?" [2025-01] [<a href="https://arxiv.org/abs/2501.10711" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>HLE</strong>: "Humanity's Last Exam" [2025-01] [<a href="https://arxiv.org/abs/2501.14249" rel="nofollow">paper</a>] [<a href="https://github.com/centerforaisafety/hle">data</a>]</p>
</li>
<li>
<p dir="auto"><strong>SuperGPQA</strong>: "SuperGPQA: Scaling LLM Evaluation across 285 Graduate Disciplines" [2025-02] [<a href="https://arxiv.org/abs/2502.14739" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>BBEH</strong>: "BIG-Bench Extra Hard" [2025-02] [<a href="https://arxiv.org/abs/2502.19187" rel="nofollow">paper</a>] [<a href="https://github.com/google-deepmind/bbeh">data</a>]</p>
</li>
<li>
<p dir="auto">"<strong>CoCo-Bench</strong>: A Comprehensive Code Benchmark For Multi-task Large Language Model Evaluation" [2025-04] [<a href="https://arxiv.org/abs/2504.20673" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>SELU</strong>: "Evaluating Large Language Models on Non-Code Software Engineering Tasks" [2025-06] [<a href="https://arxiv.org/abs/2506.10833" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>MERA Code</strong>: "MERA Code: A Unified Framework for Evaluating Code Generation Across Tasks" [2025-07] [<a href="https://arxiv.org/abs/2507.12284" rel="nofollow">paper</a>] [<a href="https://github.com/MERA-Evaluation/MERA_CODE">data</a>]</p>
</li>
<li>
<p dir="auto"><strong>LoCoBench</strong>: "LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering" [2025-09] [<a href="https://arxiv.org/abs/2509.09614" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto"><strong>TREAT</strong>: "TREAT: A Code LLMs Trustworthiness / Reliability Evaluation and Testing Framework" [2025-10] [<a href="https://arxiv.org/abs/2510.17163" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Evaluation Metrics</h4><a id="user-content-evaluation-metrics" class="anchor" aria-label="Permalink: Evaluation Metrics" href="#evaluation-metrics"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto">"CodeBLEU: a Method for Automatic Evaluation of Code Synthesis" [2020-09] [<a href="https://arxiv.org/abs/2009.10297" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code" [2023-02] [EMNLP 2023] [<a href="https://arxiv.org/abs/2302.05527" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Unsupervised Evaluation of Code LLMs with Round-Trip Correctness" [2024-02] [ICML 2024] [<a href="https://arxiv.org/abs/2402.08699" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeJudge: Evaluating Code Generation with Large Language Models" [2024-10] [EMNLP 2024] [<a href="https://arxiv.org/abs/2410.02184" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can LLMs Replace Human Evaluators? An Empirical Study of LLM-as-a-Judge in Software Engineering" [2025-02] [<a href="https://arxiv.org/abs/2502.06193" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Bridging LLM-Generated Code and Requirements: Reverse Generation technique and SBC Metric for Developer Insights" [2025-02] [<a href="https://arxiv.org/abs/2502.07835" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Copilot Arena: A Platform for Code LLM Evaluation in the Wild" [2025-02] [ICML 2025] [<a href="https://arxiv.org/abs/2502.09328" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"MCTS-Judge: Test-Time Scaling in LLM-as-a-Judge for Code Correctness Evaluation" [2025-02] [<a href="https://arxiv.org/abs/2502.12468" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeCriticBench: A Holistic Code Critique Benchmark for Large Language Models" [2025-02] [<a href="https://arxiv.org/abs/2502.16614" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Disproving Program Equivalence with LLMs" [2025-02] [<a href="https://arxiv.org/abs/2502.18473" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Can Language Models Falsify? Evaluating Algorithmic Reasoning with Counterexample Creation" [2025-02] [<a href="https://arxiv.org/abs/2502.19414" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeVisionary: An Agent-based Framework for Evaluating Large Language Models in Code Generation" [2025-04] [<a href="https://arxiv.org/abs/2504.13472" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"EVALOOP: Assessing LLM Robustness in Programming from a Self-consistency Perspective" [2025-05] [<a href="https://arxiv.org/abs/2505.12185" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Don't Judge Code by Its Cover: Exploring Biases in LLM Judges for Code Evaluation" [2025-05] [<a href="https://arxiv.org/abs/2505.16222" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CODE-DITING: A Reasoning-Based Metric for Functional Alignment in Code Evaluation" [2025-05] [<a href="https://arxiv.org/abs/2505.19502" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"Estimating Correctness Without Oracles in LLM-Based Code Generation" [2025-06] [<a href="https://arxiv.org/abs/2507.00057" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks" [2025-07] [<a href="https://arxiv.org/abs/2507.10535" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution" [2025-10] [<a href="https://arxiv.org/abs/2510.08697" rel="nofollow">paper</a>]</p>
</li>
<li>
<p dir="auto">"How Many Code and Test Cases Are Enough? Evaluating Test Cases Generation from a Binary-Matrix Perspective" [2025-10] [<a href="https://arxiv.org/abs/2510.08720" rel="nofollow">paper</a>]</p>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Program Synthesis</h4><a id="user-content-program-synthesis" class="anchor" aria-label="Permalink: Program Synthesis" href="#program-synthesis"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Date</th>
<th>Venue</th>
<th>Benchmark</th>
<th>Size</th>
<th>Language</th>
<th>Source</th>
</tr>
</thead>
<tbody>
<tr>
<td>2018-02</td>
<td>LREC 2018</td>
<td>NL2Bash</td>
<td>9305</td>
<td>Bash</td>
<td>"NL2Bash: A Corpus and Semantic Parser for Natural Language Interface to the Linux Operating System" [<a href="https://arxiv.org/abs/1802.08979" rel="nofollow">paper</a>] [<a href="https://github.com/TellinaTool/nl2bash">data</a>]</td>
</tr>
<tr>
<td>2018-08</td>
<td>EMNLP 2018</td>
<td>CONCODE</td>
<td>104K</td>
<td>Java</td>
<td>"Mapping Language to Code in Programmatic Context" [<a href="https://arxiv.org/abs/1808.09588" rel="nofollow">paper</a>] [<a href="https://github.com/sriniiyer/concode">data</a>]</td>
</tr>
<tr>
<td>2019-10</td>
<td>EMNLP-IJCNLP 2019</td>
<td>JuICe</td>
<td>1.5M/3725 *</td>
<td>Python</td>
<td>"JuICe: A Large Scale Distantly Supervised Dataset for Open Domain Context-based Code Generation" [<a href="https://arxiv.org/abs/1910.02216" rel="nofollow">paper</a>] [<a href="https://github.com/rajasagashe/juice">data</a>]</td>
</tr>
<tr>
<td>2021-05</td>
<td>NeurIPS 2021</td>
<td>APPS</td>
<td>10000</td>
<td>Python</td>
<td>"Measuring Coding Challenge Competence With APPS" [<a href="https://arxiv.org/abs/2105.09938" rel="nofollow">paper</a>] [<a href="https://github.com/hendrycks/apps">data</a>]</td>
</tr>
<tr>
<td>2021-07</td>
<td>arXiv</td>
<td>HumanEval</td>
<td>164</td>
<td>Python</td>
<td>"Evaluating Large Language Models Trained on Code" [<a href="https://arxiv.org/abs/2107.03374" rel="nofollow">paper</a>] [<a href="https://github.com/openai/human-eval">data</a>]</td>
</tr>
<tr>
<td>2021-08</td>
<td>arXiv</td>
<td>MBPP/MathQA-Python</td>
<td>974/23914</td>
<td>Python</td>
<td>"Program Synthesis with Large Language Models" [<a href="https://arxiv.org/abs/2108.07732" rel="nofollow">paper</a>] [<a href="https://github.com/google-research/google-research/tree/master/mbpp">MBPP</a>] [<a href="https://github.com/google/trax/blob/master/trax/examples/MathQA_Python_generation_notebook.ipynb">MathQA-Python</a>]</td>
</tr>
<tr>
<td>2021-08</td>
<td>ACL/IJCNLP 2021</td>
<td>PlotCoder</td>
<td>40797</td>
<td>Python</td>
<td>"PlotCoder: Hierarchical Decoding for Synthesizing Visualization Code in Programmatic Context" [<a href="https://aclanthology.org/2021.acl-long.169/" rel="nofollow">paper</a>] [<a href="https://github.com/jungyhuk/plotcoder">data</a>]</td>
</tr>
<tr>
<td>2022-01</td>
<td>arXiv</td>
<td>DSP</td>
<td>1119</td>
<td>Python</td>
<td>"Training and Evaluating a Jupyter Notebook Data Science Assistant" [<a href="https://arxiv.org/abs/2201.12901" rel="nofollow">paper</a>] [<a href="https://github.com/microsoft/DataScienceProblems">data</a>]</td>
</tr>
<tr>
<td>2022-02</td>
<td>Science</td>
<td>CodeContests</td>
<td>13610</td>
<td>C++, Python, Java</td>
<td>"Competition-Level Code Generation with AlphaCode" [<a href="https://arxiv.org/abs/2203.07814" rel="nofollow">paper</a>] [<a href="https://github.com/google-deepmind/code_contests">data</a>]</td>
</tr>
<tr>
<td>2022-03</td>
<td>EACL 2023 Findings</td>
<td>MCoNaLa</td>
<td>896</td>
<td>Python</td>
<td>"MCoNaLa: A Benchmark for Code Generation from Multiple Natural Languages" [<a href="https://arxiv.org/abs/2203.08388" rel="nofollow">paper</a>] [<a href="https://github.com/zorazrw/multilingual-conala">data</a>]</td>
</tr>
<tr>
<td>2022-06</td>
<td>arXiv</td>
<td>AixBench</td>
<td>336</td>
<td>Java</td>
<td>"AixBench: A Code Generation Benchmark Dataset" [<a href="https://arxiv.org/abs/2206.13179" rel="nofollow">paper</a>] [<a href="https://github.com/aixcoder-plugin/nl2code-dataset">data</a>]</td>
</tr>
<tr>
<td>2022-08</td>
<td>IEEE Trans. Software Engineering</td>
<td>MultiPL-E</td>
<td></td>
<td></td>
<td>"MultiPL-E: A Scalable and Extensible Approach to Benchmarking Neural Code Generation", [<a href="https://arxiv.org/abs/2208.08227" rel="nofollow">paper</a>] [<a href="https://github.com/nuprl/MultiPL-E">data</a>]</td>
</tr>
<tr>
<td>2022-10</td>
<td>ICLR 2023</td>
<td>MBXP</td>
<td>12.4K</td>
<td>Python, Java, JS, TypeScript, Go, C#, PHP, Ruby, Kotlin, C++, Perl, Scala, Swift</td>
<td>"Multi-lingual Evaluation of Code Generation Models" [<a href="https://arxiv.org/abs/2210.14868" rel="nofollow">paper</a>] [<a href="https://github.com/amazon-science/mxeval">data</a>]</td>
</tr>
<tr>
<td>2022-10</td>
<td>ICLR 2023</td>
<td>Multilingual HumanEval</td>
<td>1.9K</td>
<td>Python, Java, JS, TypeScript, Go, C#, PHP, Ruby, Kotlin, Perl, Scala, Swift</td>
<td>"Multi-lingual Evaluation of Code Generation Models" [<a href="https://arxiv.org/abs/2210.14868" rel="nofollow">paper</a>] [<a href="https://github.com/amazon-science/mxeval">data</a>]</td>
</tr>
<tr>
<td>2022-10</td>
<td>ICLR 2023</td>
<td>MathQA-X</td>
<td>5.6K</td>
<td>Python, Java, JS</td>
<td>"Multi-lingual Evaluation of Code Generation Models" [<a href="https://arxiv.org/abs/2210.14868" rel="nofollow">paper</a>] [<a href="https://github.com/amazon-science/mxeval">data</a>]</td>
</tr>
<tr>
<td>2022-11</td>
<td>arXiv</td>
<td>ExeDS</td>
<td>534</td>
<td>Python</td>
<td>"Execution-based Evaluation for Data Science Code Generation Models" [<a href="https://arxiv.org/abs/2211.09374" rel="nofollow">paper</a>] [<a href="https://github.com/Jun-jie-Huang/ExeDS">data</a>]</td>
</tr>
<tr>
<td>2022-11</td>
<td>arXiv</td>
<td>DS-1000</td>
<td>1000</td>
<td>Python</td>
<td>"DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation" [<a href="https://arxiv.org/abs/2211.11501" rel="nofollow">paper</a>] [<a href="https://github.com/xlang-ai/DS-1000">data</a>]</td>
</tr>
<tr>
<td>2022-12</td>
<td>arXiv</td>
<td>ODEX</td>
<td>945</td>
<td>Python</td>
<td>"Execution-Based Evaluation for Open-Domain Code Generation" [<a href="https://arxiv.org/abs/2212.10481" rel="nofollow">paper</a>] [<a href="https://github.com/zorazrw/odex">data</a>]</td>
</tr>
<tr>
<td>2023-02</td>
<td>arXiv</td>
<td>CoderEval</td>
<td>460</td>
<td>Python, Java</td>
<td>"CoderEval: A Benchmark of Pragmatic Code Generation with Generative Pre-trained Models" [<a href="https://arxiv.org/abs/2302.00288" rel="nofollow">paper</a>] [<a href="https://github.com/CoderEval/CoderEval">data</a>]</td>
</tr>
<tr>
<td>2023-03</td>
<td>ACL 2024</td>
<td>xCodeEval</td>
<td>5.5M</td>
<td>C, C#, C++, Go, Java, JS, Kotlin, PHP, Python, Ruby, Rust</td>
<td>"XCodeEval: An Execution-based Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval" [<a href="https://arxiv.org/abs/2303.03004" rel="nofollow">paper</a>] [<a href="https://github.com/ntunlp/xCodeEval">data</a>]</td>
</tr>
<tr>
<td>2023-03</td>
<td>arXiv</td>
<td>HumanEval-X</td>
<td>820</td>
<td>Python, C++, Java, JS, Go</td>
<td>"CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X" [<a href="https://arxiv.org/abs/2303.17568" rel="nofollow">paper</a>] [<a href="https://hub.docker.com/r/codegeex/codegeex" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2023-05</td>
<td>arXiv</td>
<td>HumanEval+</td>
<td>164</td>
<td>Python</td>
<td>"Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation" [<a href="https://arxiv.org/abs/2305.01210" rel="nofollow">paper</a>] [<a href="https://github.com/evalplus/evalplus">data</a>]</td>
</tr>
<tr>
<td>2023-06</td>
<td>ACL 2024 Findings</td>
<td>StudentEval</td>
<td>1749 <math-renderer class="js-inline-math" style="display: inline-block" data-run-id="b3caf4e842e88b86948a693f78d2e24c">$^\dagger$</math-renderer>
</td>
<td>Python</td>
<td>"StudentEval: A Benchmark of Student-Written Prompts for Large Language Models of Code" [<a href="https://arxiv.org/abs/2306.04556" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/wellesley-easel/StudentEval" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2023-08</td>
<td>ICLR 2024 Spotlight</td>
<td>HumanEvalPack</td>
<td>984</td>
<td>Python, JS, Go, Java, C++, Rust</td>
<td>"OctoPack: Instruction Tuning Code Large Language Models" [<a href="https://arxiv.org/abs/2308.07124" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/bigcode/humanevalpack" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2023-06</td>
<td>NeurIPS 2023</td>
<td>DotPrompts</td>
<td>10538 <math-renderer class="js-inline-math" style="display: inline-block" data-run-id="b3caf4e842e88b86948a693f78d2e24c">$^\ddagger$</math-renderer>
</td>
<td>Java</td>
<td>"Guiding Language Models of Code with Global Context using Monitors" [<a href="https://arxiv.org/abs/2306.10763" rel="nofollow">paper</a>] [<a href="https://github.com/microsoft/monitors4codegen">data</a>]</td>
</tr>
<tr>
<td>2023-09</td>
<td>arXiv</td>
<td>CodeApex</td>
<td>476</td>
<td>C++</td>
<td>"CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models" [<a href="https://arxiv.org/abs/2309.01940" rel="nofollow">paper</a>] [<a href="https://github.com/APEXLAB/CodeApex">data</a>]</td>
</tr>
<tr>
<td>2023-09</td>
<td>arXiv</td>
<td>VerilogEval</td>
<td>8645/156 <math-renderer class="js-inline-math" style="display: inline-block" data-run-id="b3caf4e842e88b86948a693f78d2e24c">$^\diamond$</math-renderer>
</td>
<td>Verilog</td>
<td>"VerilogEval: Evaluating Large Language Models for Verilog Code Generation" [<a href="https://arxiv.org/abs/2309.07544" rel="nofollow">paper</a>] [<a href="https://github.com/NVlabs/verilog-eval">data</a>]</td>
</tr>
<tr>
<td>2023-11</td>
<td>arXiv</td>
<td>ML-Bench</td>
<td>10040</td>
<td>Bash</td>
<td>"ML-Bench: Large Language Models Leverage Open-source Libraries for Machine Learning Tasks" [<a href="https://arxiv.org/abs/2311.09835" rel="nofollow">paper</a>] [<a href="https://ml-bench.github.io/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2023-12</td>
<td>arXiv</td>
<td>TACO</td>
<td>26,433</td>
<td>Python</td>
<td>"TACO: Topics in Algorithmic COde generation dataset" [<a href="https://arxiv.org/abs/2312.14852" rel="nofollow">paper</a>] [<a href="https://github.com/FlagOpen/TACO">data</a>]</td>
</tr>
<tr>
<td>2024-01</td>
<td>EMNLP 2024 Findings</td>
<td>PythonSaga</td>
<td>185</td>
<td>Python</td>
<td>"PythonSaga: Redefining the Benchmark to Evaluate Code Generating LLMs" [<a href="https://arxiv.org/abs/2401.03855" rel="nofollow">paper</a>] [<a href="https://anonymous.4open.science/r/PythonSaga/README.md" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2024-01</td>
<td>HPDC</td>
<td>ParEval</td>
<td>420</td>
<td>C++, CUDA, HIP</td>
<td>"Can Large Language Models Write Parallel Code?" [<a href="https://arxiv.org/abs/2401.12554" rel="nofollow">paper</a>] [<a href="https://github.com/parallelcodefoundry/ParEval">data</a>]</td>
</tr>
<tr>
<td>2024-02</td>
<td>ACL 2024 Findings</td>
<td>OOP</td>
<td>431</td>
<td>Python</td>
<td>"OOP: Object-Oriented Programming Evaluation Benchmark for Large Language Models" [<a href="https://arxiv.org/abs/2401.06628" rel="nofollow">paper</a>] [<a href="https://github.com/alphadl/OOP-eval">data</a>]</td>
</tr>
<tr>
<td>2024-02</td>
<td>LREC-COLING 2024</td>
<td>HumanEval-XL</td>
<td>22080</td>
<td>23NL, 12PL</td>
<td>"HumanEval-XL: A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization" [<a href="https://arxiv.org/abs/2402.16694" rel="nofollow">paper</a>] [<a href="https://github.com/FloatAI/humaneval-xl">data</a>]</td>
</tr>
<tr>
<td>2024-04</td>
<td>arXiv</td>
<td>USACO</td>
<td>307</td>
<td>Python</td>
<td>"Can Language Models Solve Olympiad Programming?" [<a href="https://arxiv.org/abs/2404.10952" rel="nofollow">paper</a>] [<a href="https://github.com/princeton-nlp/USACO">data</a>]</td>
</tr>
<tr>
<td>2024-04</td>
<td>LREC-COLING 2024</td>
<td>PECC</td>
<td>2396</td>
<td>Python</td>
<td>"PECC: Problem Extraction and Coding Challenges" [<a href="https://arxiv.org/abs/2404.18766" rel="nofollow">paper</a>] [<a href="https://github.com/HallerPatrick/pecc">data</a>]</td>
</tr>
<tr>
<td>2024-04</td>
<td>arXiv</td>
<td>CodeGuard+</td>
<td>23</td>
<td>Python, C</td>
<td>"Constrained Decoding for Secure Code Generation" [<a href="https://arxiv.org/abs/2405.00218" rel="nofollow">paper</a>] [<a href="https://github.com/Dynamite321/CodeGuardPlus">data</a>]</td>
</tr>
<tr>
<td>2024-05</td>
<td>ACL 2024 Findings</td>
<td>NaturalCodeBench</td>
<td>402</td>
<td>Python, Java</td>
<td>"NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and Natural User Prompts" [<a href="https://arxiv.org/abs/2405.04520" rel="nofollow">paper</a>] [<a href="https://github.com/THUDM/NaturalCodeBench">data</a>]</td>
</tr>
<tr>
<td>2024-05</td>
<td>arXiv</td>
<td>MHPP</td>
<td>140</td>
<td>Python</td>
<td>"MHPP: Exploring the Capabilities and Limitations of Language Models Beyond Basic Code Generation" [<a href="https://arxiv.org/abs/2405.11430" rel="nofollow">paper</a>] [<a href="https://github.com/SparksofAGI/MHPP">repo</a>]</td>
</tr>
<tr>
<td>2024-06</td>
<td>arXiv</td>
<td>VHDL-Eval</td>
<td>202</td>
<td>VHDL</td>
<td>"VHDL-Eval: A Framework for Evaluating Large Language Models in VHDL Code Generation" [<a href="https://arxiv.org/abs/2406.04379" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2024-06</td>
<td>arXiv</td>
<td>AICoderEval</td>
<td>492</td>
<td>Python</td>
<td>"AICoderEval: Improving AI Domain Code Generation of Large Language Models" [<a href="https://arxiv.org/abs/2406.04712" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/vixuowis/AICoderEval" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2024-06</td>
<td>arXiv</td>
<td>VersiCode</td>
<td>98,692</td>
<td>Python</td>
<td>"VersiCode: Towards Version-controllable Code Generation" [<a href="https://arxiv.org/abs/2406.07411" rel="nofollow">paper</a>] [<a href="https://github.com/wutong8023/VersiCode">data</a>]</td>
</tr>
<tr>
<td>2024-06</td>
<td>IEEE AITest 2024</td>
<td>ScenEval</td>
<td>12,864</td>
<td>Java</td>
<td>"ScenEval: A Benchmark for Scenario-Based Evaluation of Code Generation" [<a href="https://arxiv.org/abs/2406.12635" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2024-06</td>
<td>ICLR 2025</td>
<td>BigCodeBench</td>
<td>1,140</td>
<td>Python</td>
<td>"BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions" [<a href="https://arxiv.org/abs/2406.15877" rel="nofollow">paper</a>] [<a href="https://github.com/bigcode-project/bigcodebench">data</a>]</td>
</tr>
<tr>
<td>2024-07</td>
<td>arXiv</td>
<td>CodeUpdateArena</td>
<td>670</td>
<td>Python</td>
<td>"CodeUpdateArena: Benchmarking Knowledge Editing on API Updates" [<a href="https://arxiv.org/abs/2407.06249" rel="nofollow">paper</a>] [<a href="https://github.com/leo-liuzy/CodeUpdateArena">data</a>]</td>
</tr>
<tr>
<td>2024-07</td>
<td>EMNLP 2024 Findings</td>
<td>LBPP</td>
<td>161</td>
<td>Python</td>
<td>"On Leakage of Code Generation Evaluation Datasets" [<a href="https://arxiv.org/abs/2407.07565" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/CohereForAI/lbpp" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2024-07</td>
<td>arXiv</td>
<td>NoviCode</td>
<td>150</td>
<td>Python</td>
<td>"NoviCode: Generating Programs from Natural Language Utterances by Novices" [<a href="https://arxiv.org/abs/2407.10626" rel="nofollow">paper</a>] [<a href="https://github.com/BIU-NLP/novicode">data</a>]</td>
</tr>
<tr>
<td>2024-07</td>
<td>arXiv</td>
<td>Case2Code</td>
<td>1.3M</td>
<td>Python</td>
<td>"Case2Code: Learning Inductive Reasoning with Synthetic Data" [<a href="https://arxiv.org/abs/2407.12504" rel="nofollow">paper</a>] [<a href="https://github.com/choosewhatulike/case2code">data</a>]</td>
</tr>
<tr>
<td>2024-07</td>
<td>NeurIPS 2024</td>
<td>SciCode</td>
<td>338</td>
<td>Python</td>
<td>"SciCode: A Research Coding Benchmark Curated by Scientists" [<a href="https://arxiv.org/abs/2407.13168" rel="nofollow">paper</a>] [<a href="https://github.com/scicode-bench/SciCode">data</a>]</td>
</tr>
<tr>
<td>2024-07</td>
<td>arXiv</td>
<td>auto-regression</td>
<td>460</td>
<td>Python</td>
<td>"Generating Unseen Code Tests In Infinitum" [<a href="https://arxiv.org/abs/2407.19772" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2024-07</td>
<td>arXiv</td>
<td>WebApp1K</td>
<td>1000</td>
<td>JavaScript</td>
<td>"WebApp1K: A Practical Code-Generation Benchmark for Web App Development" [<a href="https://arxiv.org/abs/2408.00019" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/onekq-ai/WebApp1K-React" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2024-08</td>
<td>ACL 2024 Findings</td>
<td>CodeInsight</td>
<td>3409</td>
<td>Python</td>
<td>"CodeInsight: A Curated Dataset of Practical Coding Solutions from Stack Overflow" [<a href="https://arxiv.org/abs/2409.16819" rel="nofollow">paper</a>] [<a href="https://github.com/NathanaelBeau/CodeInsight">data</a>]</td>
</tr>
<tr>
<td>2024-08</td>
<td>arXiv</td>
<td>DomainEval</td>
<td>2454</td>
<td>Python</td>
<td>"DOMAINEVAL: An Auto-Constructed Benchmark for Multi-Domain Code Generation" [<a href="https://arxiv.org/abs/2408.13204" rel="nofollow">paper</a>] [<a href="https://github.com/domaineval/DomainEval">data</a>]</td>
</tr>
<tr>
<td>2024-09</td>
<td>arXiv</td>
<td>ComplexCodeEval</td>
<td>7184/3897</td>
<td>Python/Java</td>
<td>"ComplexCodeEval: A Benchmark for Evaluating Large Code Models on More Complex Code" [<a href="https://arxiv.org/abs/2409.10280" rel="nofollow">paper</a>] [<a href="https://github.com/ComplexCodeEval/ComplexCodeEval">data</a>]</td>
</tr>
<tr>
<td>2024-09</td>
<td>ASE 2024</td>
<td>CoCoNote</td>
<td>58221</td>
<td>Python Notebook</td>
<td>"Contextualized Data-Wrangling Code Generation in Computational Notebooks" [<a href="https://arxiv.org/abs/2409.13551" rel="nofollow">paper</a>] [<a href="https://github.com/Jun-jie-Huang/CoCoNote">data</a>]</td>
</tr>
<tr>
<td>2024-10</td>
<td>arXiv</td>
<td>unnamed</td>
<td>77</td>
<td>Python</td>
<td>"Evaluation of Code LLMs on Geospatial Code Generation" [<a href="https://arxiv.org/abs/2410.04617" rel="nofollow">paper</a>] [<a href="https://github.com/kraina-ai/geospatial-code-llms-dataset">data</a>]</td>
</tr>
<tr>
<td>2024-10</td>
<td>arXiv</td>
<td>mHumanEval</td>
<td>836,400</td>
<td>25PL, 204NL</td>
<td>"mHumanEval -- A Multilingual Benchmark to Evaluate Large Language Models for Code Generation" [<a href="https://arxiv.org/abs/2410.15037" rel="nofollow">paper</a>] [<a href="https://github.com/mraihan-gmu/mHumanEval">data</a>]</td>
</tr>
<tr>
<td>2024-10</td>
<td>arXiv</td>
<td>FeatEng</td>
<td>103</td>
<td>Python</td>
<td>"Can Models Help Us Create Better Models? Evaluating LLMs as Data Scientists" [<a href="https://arxiv.org/abs/2410.23331" rel="nofollow">paper</a>] [<a href="https://github.com/FeatEng/FeatEng">data</a>]</td>
</tr>
<tr>
<td>2024-11</td>
<td>arXiv</td>
<td>GitChameleon</td>
<td>116</td>
<td>Python</td>
<td>"GitChameleon: Unmasking the Version-Switching Capabilities of Code Generation Models" [<a href="https://arxiv.org/abs/2411.05830" rel="nofollow">paper</a>] [<a href="https://github.com/NizarIslah/GitChameleon">data</a>]</td>
</tr>
<tr>
<td>2024-11</td>
<td>EMNLP 2024 Findings</td>
<td>MBUPP</td>
<td>466</td>
<td>Python</td>
<td>"One-to-many testing for code generation from (just) natural language" [<a href="https://aclanthology.org/2024.findings-emnlp.902/" rel="nofollow">paper</a>] [<a href="https://github.com/microsoft/prose-benchmarks/tree/main/MBUPP">data</a>]</td>
</tr>
<tr>
<td>2024-11</td>
<td>NAACL 2025</td>
<td>LibEvolutionEval</td>
<td>34.7K</td>
<td>Python</td>
<td>"LibEvolutionEval: A Benchmark and Study for Version-Specific Code Generation" [<a href="https://arxiv.org/abs/2412.04478" rel="nofollow">paper</a>][<a href="https://lib-evolution-eval.github.io/" rel="nofollow">website</a>]</td>
</tr>
<tr>
<td>2024-12</td>
<td>arXiv</td>
<td>PandasPlotBench</td>
<td>175</td>
<td>Python</td>
<td>"Drawing Pandas: A Benchmark for LLMs in Generating Plotting Code" [<a href="https://arxiv.org/abs/2412.02764" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/JetBrains-Research/plot_bench" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2024-12</td>
<td>arXiv</td>
<td>CodeArena</td>
<td>397</td>
<td>44</td>
<td>"Evaluating and Aligning CodeLLMs on Human Preference" [<a href="https://arxiv.org/abs/2412.05210" rel="nofollow">paper</a>] [<a href="https://github.com/QwenLM/Qwen2.5-Coder/tree/main/qwencoder-eval/instruct/CodeArena">data</a>]</td>
</tr>
<tr>
<td>2024-12</td>
<td>arXiv</td>
<td>OBFUSEVAL</td>
<td>1354</td>
<td>C</td>
<td>"Unseen Horizons: Unveiling the Real Capability of LLM Code Generation Beyond the Familiar" [<a href="https://arxiv.org/abs/2412.08109" rel="nofollow">paper</a>] [<a href="https://github.com/zhangbuzhang/ObfusEval">data</a>]</td>
</tr>
<tr>
<td>2024-12</td>
<td>ACL 2025 Findings</td>
<td>HumanEval Pro / MBPP Pro / BigCodeBench-Lite Pro</td>
<td>164/378/57</td>
<td>Python</td>
<td>"HumanEval Pro and MBPP Pro: Evaluating Large Language Models on Self-invoking Code Generation" [<a href="https://arxiv.org/abs/2412.21199" rel="nofollow">paper</a>] [<a href="https://github.com/CodeEval-Pro/CodeEval-Pro/tree/main">data</a>]</td>
</tr>
<tr>
<td>2025-01</td>
<td>arXiv</td>
<td>CodeElo</td>
<td>387</td>
<td>-</td>
<td>"CodeElo: Benchmarking Competition-level Code Generation of LLMs with Human-comparable Elo Ratings" [<a href="https://arxiv.org/abs/2501.01257" rel="nofollow">paper</a>] [<a href="https://codeelo-bench.github.io/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2025-02</td>
<td>FSE 2025</td>
<td>COFFE</td>
<td>756</td>
<td>Python</td>
<td>"COFFE: A Code Efficiency Benchmark for Code Generation" [<a href="https://arxiv.org/abs/2502.02827" rel="nofollow">paper</a>] [<a href="https://github.com/JohnnyPeng18/Coffe">data</a>]</td>
</tr>
<tr>
<td>2025-02</td>
<td>arXiv</td>
<td>FVAPPS</td>
<td>4715</td>
<td>Python</td>
<td>"Proving the Coding Interview: A Benchmark for Formally Verified Code Generation" [<a href="https://arxiv.org/abs/2502.05714" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/quinn-dougherty/fvapps" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2025-02</td>
<td>arXiv</td>
<td>KernelBench</td>
<td>250</td>
<td>Python</td>
<td>"KernelBench: Can LLMs Write Efficient GPU Kernels?" [<a href="https://arxiv.org/abs/2502.10517" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-02</td>
<td>arXiv</td>
<td>BaxBench</td>
<td>392</td>
<td>Go, JS, PHP, Python, Ruby, Rust</td>
<td>"BaxBench: Can LLMs Generate Correct and Secure Backends?" [<a href="https://arxiv.org/abs/2502.11844" rel="nofollow">paper</a>] [<a href="https://baxbench.com/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2025-02</td>
<td>arXiv</td>
<td>DataSciBench</td>
<td>222</td>
<td>Python</td>
<td>"DataSciBench: An LLM Agent Benchmark for Data Science" [<a href="https://arxiv.org/abs/2502.13897" rel="nofollow">paper</a>] [<a href="https://github.com/THUDM/DataSciBench">data</a>]</td>
</tr>
<tr>
<td>2025-02</td>
<td>arXiv</td>
<td>TritonBench</td>
<td>184</td>
<td>Triton</td>
<td>"TritonBench: Benchmarking Large Language Model Capabilities for Generating Triton Operators" [<a href="https://arxiv.org/abs/2502.14752" rel="nofollow">paper</a>] [<a href="https://github.com/thunlp/TritonBench">data</a>]</td>
</tr>
<tr>
<td>2025-02</td>
<td>arXiv</td>
<td>Deep-Bench</td>
<td>520</td>
<td>Python</td>
<td>"Deep-Bench: Deep Learning Benchmark Dataset for Code Generation" [<a href="https://arxiv.org/abs/2502.18726" rel="nofollow">paper</a>] [<a href="https://anonymous.4open.science/r/DL-Bench-D65E/README.md" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2025-02</td>
<td>arXiv</td>
<td>IndicEval-XL</td>
<td>6720</td>
<td>12</td>
<td>"IndicEval-XL: Bridging Linguistic Diversity in Code Generation Across Indic Languages" [<a href="https://arxiv.org/abs/2502.19067" rel="nofollow">paper</a>] [<a href="https://github.com/telekom/IndicEval-XL">data</a>]</td>
</tr>
<tr>
<td>2025-02</td>
<td>arXiv</td>
<td>PseudoEval</td>
<td>1059</td>
<td>Python, C++, Rust</td>
<td>"Isolating Language-Coding from Problem-Solving: Benchmarking LLMs with PseudoEval" [<a href="https://arxiv.org/abs/2502.19149" rel="nofollow">paper</a>] [<a href="https://anonymous.4open.science/r/PseudocodeACL25-7B74/README.md" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2025-02</td>
<td>arXiv</td>
<td>ProBench</td>
<td>790</td>
<td>C++, Java, Python</td>
<td>"ProBench: Benchmarking Large Language Models in Competitive Programming" [<a href="https://arxiv.org/abs/2502.20868" rel="nofollow">paper</a>] [<a href="https://github.com/YL-9/probench">data</a>]</td>
</tr>
<tr>
<td>2025-03</td>
<td>ICML 2025</td>
<td>DyCodeEval</td>
<td>-</td>
<td>-</td>
<td>"Dynamic Benchmarking of Reasoning Capabilities in Code Large Language Models Under Data Contamination" [<a href="https://arxiv.org/abs/2503.04149" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-03</td>
<td>ACL 2025 Findings</td>
<td>DynaCode</td>
<td>405</td>
<td>Python</td>
<td>"DynaCode: A Dynamic Complexity-Aware Code Benchmark for Evaluating Large Language Models in Code Generation" [<a href="https://arxiv.org/abs/2503.10452" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-03</td>
<td>arXiv</td>
<td>BigO(Bench)</td>
<td>3105</td>
<td>Python</td>
<td>"BigO(Bench) -- Can LLMs Generate Code with Controlled Time and Space Complexity?" [<a href="https://arxiv.org/abs/2503.15242" rel="nofollow">paper</a>] [<a href="https://github.com/facebookresearch/bigobench">data</a>]</td>
</tr>
<tr>
<td>2025-04</td>
<td>arXiv</td>
<td>-</td>
<td>842K</td>
<td>Python</td>
<td>"A Large-scale Class-level Benchmark Dataset for Code Generation with LLMs" [<a href="https://arxiv.org/abs/2504.15564" rel="nofollow">paper</a>] [<a href="https://anonymous.4open.science/r/class-level-benchmark-dataset-B132/README.md" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2025-05</td>
<td>arXiv</td>
<td>YABLoCo</td>
<td>215</td>
<td>C, C++</td>
<td>"YABLoCo: Yet Another Benchmark for Long Context Code Generation" [<a href="https://arxiv.org/abs/2505.04406" rel="nofollow">paper</a>] [<a href="https://github.com/yabloco-codegen/yabloco-benchmark">data</a>]</td>
</tr>
<tr>
<td>2025-05</td>
<td>arXiv</td>
<td>OSS-Bench</td>
<td>-</td>
<td>-</td>
<td>"OSS-Bench: Benchmark Generator for Coding LLMs" [<a href="https://arxiv.org/abs/2505.12331" rel="nofollow">paper</a>] [<a href="https://github.com/oss-bench/oss-bench">data</a>]</td>
</tr>
<tr>
<td>2025-05</td>
<td>arXiv</td>
<td>DS-Bench</td>
<td>1000</td>
<td>Python</td>
<td>"DS-Bench: A Realistic Benchmark for Data Science Code Generation" [<a href="https://arxiv.org/abs/2505.15621" rel="nofollow">paper</a>] [<a href="https://github.com/ShuyinOuyang/DS_bench">data</a>]</td>
</tr>
<tr>
<td>2025-06</td>
<td>arXiv</td>
<td>ICPC-Eval</td>
<td>118</td>
<td>C++</td>
<td>"ICPC-Eval: Probing the Frontiers of LLM Reasoning with Competitive Programming Contests" [<a href="https://arxiv.org/abs/2506.04894" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-06</td>
<td>arXiv</td>
<td>LiveCodeBench Pro</td>
<td>584</td>
<td>C++</td>
<td>"LiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive Programming?" [<a href="https://arxiv.org/abs/2506.11928" rel="nofollow">paper</a>] [<a href="https://github.com/GavinZhengOI/LiveCodeBench-Pro">data</a>]</td>
</tr>
<tr>
<td>2025-06</td>
<td>arXiv</td>
<td>HLCE</td>
<td>235</td>
<td>C++, Python</td>
<td>"Humanity's Last Code Exam: Can Advanced LLMs Conquer Human's Hardest Code Competition?" [<a href="https://arxiv.org/abs/2506.12713" rel="nofollow">paper</a>] [<a href="https://github.com/Humanity-s-Last-Code-Exam/HLCE">data</a>]</td>
</tr>
<tr>
<td>2025-06</td>
<td>arXiv</td>
<td>OJBench</td>
<td>232</td>
<td>C++, Python</td>
<td>"OJBench: A Competition Level Code Benchmark For Large Language Models" [<a href="https://arxiv.org/abs/2506.16395" rel="nofollow">paper</a>] [<a href="https://github.com/He-Ren/OJBench">data</a>]</td>
</tr>
<tr>
<td>2025-07</td>
<td>arXiv</td>
<td>IFEvalCode</td>
<td>1.6K</td>
<td>Python, Java, JS, TS, Shell, C++, PHP, C#</td>
<td>"IFEvalCode: Controlled Code Generation" [<a href="https://arxiv.org/abs/2507.22462" rel="nofollow">paper</a>] [<a href="https://ifevalcode.github.io/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2025-08</td>
<td>arXiv</td>
<td>FPBench</td>
<td>1800</td>
<td>Python</td>
<td>"Refining Critical Thinking in LLM Code Generation: A Faulty Premise-based Evaluation Framework" [<a href="https://arxiv.org/abs/2508.03622" rel="nofollow">paper</a>] [<a href="https://github.com/JialinLi13/FaultyPremise">data</a>]</td>
</tr>
<tr>
<td>2025-08</td>
<td>arXiv</td>
<td>AutoCodeBench</td>
<td>3,920</td>
<td>20</td>
<td>"AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators" [<a href="https://arxiv.org/abs/2508.09101" rel="nofollow">paper</a>] [<a href="https://autocodebench.github.io/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2025-08</td>
<td>arXiv</td>
<td>AetherCode</td>
<td>456</td>
<td>C++</td>
<td>"AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions" [<a href="https://arxiv.org/abs/2508.16402" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/m-a-p/AetherCode" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2025-10</td>
<td>arXiv</td>
<td>LiveOIBench</td>
<td>403</td>
<td></td>
<td>"LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?" [<a href="https://arxiv.org/abs/2510.09595" rel="nofollow">paper</a>] [<a href="https://liveoibench.github.io/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2025-10</td>
<td>arXiv</td>
<td>AutoCode</td>
<td>-</td>
<td>-</td>
<td>"AutoCode: LLMs as Problem Setters for Competitive Programming" [<a href="https://arxiv.org/abs/2510.12803" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-10</td>
<td>arXiv</td>
<td>UniCode</td>
<td>492</td>
<td>-</td>
<td>"UniCode: A Framework for Generating High Quality Competitive Coding Problems" [<a href="https://arxiv.org/abs/2510.17868" rel="nofollow">paper</a>]</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">* Automatically mined/human-annotated</p>
<p dir="auto"><math-renderer class="js-inline-math" style="display: inline-block" data-run-id="b3caf4e842e88b86948a693f78d2e24c">$^\dagger$</math-renderer> 1749 prompts for 48 problems</p>
<p dir="auto"><math-renderer class="js-inline-math" style="display: inline-block" data-run-id="b3caf4e842e88b86948a693f78d2e24c">$^\ddagger$</math-renderer> 10538 prompts for 1420 problems</p>
<p dir="auto"><math-renderer class="js-inline-math" style="display: inline-block" data-run-id="b3caf4e842e88b86948a693f78d2e24c">$^\diamond$</math-renderer> Machine/human prompts</p>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Visually Grounded Program Synthesis</h4><a id="user-content-visually-grounded-program-synthesis" class="anchor" aria-label="Permalink: Visually Grounded Program Synthesis" href="#visually-grounded-program-synthesis"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Date</th>
<th>Venue</th>
<th>Benchmark</th>
<th>Size</th>
<th>Language</th>
<th>Source</th>
</tr>
</thead>
<tbody>
<tr>
<td>2024-04</td>
<td>EMNLP 2024 Findings</td>
<td>MMCode</td>
<td>3548</td>
<td>Python</td>
<td>"MMCode: Evaluating Multi-Modal Code Large Language Models with Visually Rich Programming Problems" [<a href="https://arxiv.org/abs/2404.09486" rel="nofollow">paper</a>] [<a href="https://github.com/happylkx/MMCode">data</a>]</td>
</tr>
<tr>
<td>2024-05</td>
<td>arXiv</td>
<td>Plot2Code</td>
<td>132</td>
<td>Python</td>
<td>"Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots" [<a href="https://arxiv.org/abs/2405.07990" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/TencentARC/Plot2Code" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2024-06</td>
<td>ICLR 2025</td>
<td>ChartMimic</td>
<td>1000</td>
<td>Python</td>
<td>"ChartMimic: Evaluating LMM's Cross-Modal Reasoning Capability via Chart-to-Code Generation" [<a href="https://arxiv.org/abs/2406.09961" rel="nofollow">paper</a>] [<a href="https://github.com/ChartMimic/ChartMimic">data</a>]</td>
</tr>
<tr>
<td>2024-10</td>
<td>arXiv</td>
<td>HumanEval-V</td>
<td>108</td>
<td>Python</td>
<td>"HumanEval-V: Evaluating Visual Understanding and Reasoning Abilities of Large Multimodal Models Through Coding Tasks" [<a href="https://arxiv.org/abs/2410.12381" rel="nofollow">paper</a>] [<a href="https://github.com/HumanEval-V/HumanEval-V-Benchmark">data</a>]</td>
</tr>
<tr>
<td>2024-10</td>
<td>arXiv</td>
<td>TurtleBench</td>
<td>260</td>
<td>Python</td>
<td>"TurtleBench: A Visual Programming Benchmark in Turtle Geometry" [<a href="https://arxiv.org/abs/2411.00264" rel="nofollow">paper</a>] [<a href="https://github.com/sinaris76/TurtleBench">data</a>]</td>
</tr>
<tr>
<td>2024-12</td>
<td>ICLR 2025</td>
<td>BigDocs</td>
<td>7.5M</td>
<td>HTML, LaTeX, SVG, JSON, Markdown, etc</td>
<td>"BigDocs: An Open and Permissively-Licensed Dataset for Training Multimodal Models on Document and Code Tasks" [<a href="https://arxiv.org/abs/2412.04626" rel="nofollow">paper</a>] [<a href="https://bigdocs.github.io/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2024-12</td>
<td>ACL 2025 Findings</td>
<td>Visual SWEbench</td>
<td>133</td>
<td>Python</td>
<td>"CodeV: Issue Resolving with Visual Data" [<a href="https://arxiv.org/abs/2412.17315" rel="nofollow">paper</a>] [<a href="https://github.com/luolin101/CodeV">data</a>]</td>
</tr>
<tr>
<td>2025-02</td>
<td>arXiv</td>
<td>Code-Vision</td>
<td>438</td>
<td>Python</td>
<td>"Code-Vision: Evaluating Multimodal LLMs Logic Understanding and Code Generation Capabilities" [<a href="https://arxiv.org/abs/2502.11829" rel="nofollow">paper</a>] [<a href="https://github.com/wanghanbinpanda/CodeVision">data</a>]</td>
</tr>
<tr>
<td>2025-06</td>
<td>ACL 2025 Findings</td>
<td>Flow2Code</td>
<td>5622</td>
<td>15</td>
<td>"Flow2Code: Evaluating Large Language Models for Flowchart-based Code Generation Capability" [<a href="https://arxiv.org/abs/2506.02073" rel="nofollow">paper</a>] [<a href="https://github.com/hml-github/Flow2Code">data</a>]</td>
</tr>
<tr>
<td>2025-07</td>
<td>arXiv</td>
<td>ArtifactsBench</td>
<td>1825</td>
<td>HTML/JavaScript</td>
<td>"ArtifactsBench: Bridging the Visual-Interactive Gap in LLM Code Generation Evaluation" [<a href="https://arxiv.org/abs/2507.04952" rel="nofollow">paper</a>] [<a href="https://github.com/Tencent-Hunyuan/ArtifactsBenchmark">data</a>]</td>
</tr>
<tr>
<td>2025-08</td>
<td>arXiv</td>
<td>MCD</td>
<td>598K</td>
<td>HTML, Python</td>
<td>"VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models" [<a href="https://arxiv.org/abs/2508.09945" rel="nofollow">paper</a>] [<a href="https://github.com/JackLingjie/VisCodex">data</a>]</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Code Reasoning and QA</h4><a id="user-content-code-reasoning-and-qa" class="anchor" aria-label="Permalink: Code Reasoning and QA" href="#code-reasoning-and-qa"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Date</th>
<th>Venue</th>
<th>Benchmark</th>
<th>Size</th>
<th>Language</th>
<th>Source</th>
</tr>
</thead>
<tbody>
<tr>
<td>2021-09</td>
<td>EMNLP 2021 Findings</td>
<td>CodeQA</td>
<td>120K/70K</td>
<td>Java/Python</td>
<td>"CodeQA: A Question Answering Dataset for Source Code Comprehension" [<a href="https://arxiv.org/abs/2109.08365" rel="nofollow">paper</a>] [<a href="https://github.com/jadecxliu/CodeQA">data</a>]</td>
</tr>
<tr>
<td>2022-10</td>
<td>NAACL 2022</td>
<td>CS1QA</td>
<td>9237</td>
<td>Python</td>
<td>"CS1QA: A Dataset for Assisting Code-based Question Answering in an Introductory Programming Course" [<a href="https://arxiv.org/abs/2210.14494" rel="nofollow">paper</a>] [<a href="https://github.com/cyoon47/CS1QA">data</a>]</td>
</tr>
<tr>
<td>2023-09</td>
<td>arXiv</td>
<td>CodeApex</td>
<td>250</td>
<td>C++</td>
<td>"CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models" [<a href="https://arxiv.org/abs/2309.01940" rel="nofollow">paper</a>] [<a href="https://github.com/APEXLAB/CodeApex">data</a>]</td>
</tr>
<tr>
<td>2024-01</td>
<td>ICML 2024</td>
<td>CRUXEval</td>
<td>800</td>
<td>Python</td>
<td>"CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution" [<a href="https://arxiv.org/abs/2401.03065" rel="nofollow">paper</a>] [<a href="https://github.com/facebookresearch/cruxeval">data</a>]</td>
</tr>
<tr>
<td>2024-05</td>
<td>arXiv</td>
<td>PythonIO</td>
<td>2650</td>
<td>Python</td>
<td>"Multiple-Choice Questions are Efficient and Robust LLM Evaluators" [<a href="https://arxiv.org/abs/2405.11966" rel="nofollow">paper</a>] [<a href="https://github.com/Geralt-Targaryen/MC-Evaluation">data</a>]</td>
</tr>
<tr>
<td>2024-05</td>
<td>arXiv</td>
<td>StaCCQA</td>
<td>270K</td>
<td>Python</td>
<td>"Aligning LLMs through Multi-perspective User Preference Ranking-based Feedback for Programming Question Answering" [<a href="https://arxiv.org/abs/2406.00037" rel="nofollow">paper</a>] [<a href="https://anonymous.4open.science/r/PETCoQA-810A" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2024-06</td>
<td>arXiv</td>
<td>RepoQA</td>
<td>500</td>
<td>Python, C++, Java, Rust, TypeScript</td>
<td>"RepoQA: Evaluating Long Context Code Understanding" [<a href="https://arxiv.org/abs/2406.06025" rel="nofollow">paper</a>] [<a href="https://github.com/evalplus/repoqa">data</a>]</td>
</tr>
<tr>
<td>2024-08</td>
<td>ACL 2025</td>
<td>CruxEval-X</td>
<td>12.6K</td>
<td>19</td>
<td>"CRUXEval-X: A Benchmark for Multilingual Code Reasoning, Understanding and Execution" [<a href="https://arxiv.org/abs/2408.13001" rel="nofollow">paper</a>] [<a href="https://github.com/CRUXEVAL-X/cruxeval-x">data</a>]</td>
</tr>
<tr>
<td>2024-09</td>
<td>arXiv</td>
<td>SpecEval</td>
<td>204</td>
<td>Java</td>
<td>"SpecEval: Evaluating Code Comprehension in Large Language Models via Program Specifications" [<a href="https://arxiv.org/abs/2409.12866" rel="nofollow">paper</a>] [<a href="https://sites.google.com/view/speceval/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2024-10</td>
<td>ICLR 2025</td>
<td>CodeMMLU</td>
<td>19912</td>
<td>13</td>
<td>"CodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding Capabilities of CodeLLMs" [<a href="https://arxiv.org/abs/2410.01999" rel="nofollow">paper</a>] [<a href="https://github.com/FSoft-AI4Code/CodeMMLU">data</a>]</td>
</tr>
<tr>
<td>2024-11</td>
<td>arXiv</td>
<td>unnamed</td>
<td>80232</td>
<td>Python</td>
<td>"Leveraging Large Language Models in Code Question Answering: Baselines and Issues" [<a href="https://arxiv.org/abs/2411.03012" rel="nofollow">paper</a>] [<a href="https://github.com/IU-AES-AI4Code/CodeQuestionAnswering">data</a>]</td>
</tr>
<tr>
<td>2024-11</td>
<td>arXiv</td>
<td>ScratchEval</td>
<td>305</td>
<td>Scratch</td>
<td>"ScratchEval: Are GPT-4o Smarter than My Child? Evaluating Large Multimodal Models with Visual Programming Challenges" [<a href="https://arxiv.org/abs/2411.18932" rel="nofollow">paper</a>] [<a href="https://github.com/HKBUNLP/ScratchEval">data</a>]</td>
</tr>
<tr>
<td>2024-12</td>
<td>arXiv</td>
<td>CodeRepoQA</td>
<td>585,687</td>
<td>Python, Java, TS, JS, Go</td>
<td>"CodeRepoQA: A Large-scale Benchmark for Software Engineering Question Answering" [<a href="https://arxiv.org/abs/2412.14764" rel="nofollow">paper</a>] [<a href="https://github.com/kinesiatricssxilm14/CodeRepoQA">data</a>]</td>
</tr>
<tr>
<td>2025-01</td>
<td>arXiv</td>
<td>CoReQA</td>
<td>1,563</td>
<td>Python, Java, Go, TS</td>
<td>"CoReQA: Uncovering Potentials of Language Models in Code Repository Question Answering" [<a href="https://arxiv.org/abs/2501.03447" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-02</td>
<td>arXiv</td>
<td>EquiBench</td>
<td>2400</td>
<td>C, CUDA, x86-64, Python</td>
<td>"EquiBench: Benchmarking Code Reasoning Capabilities of Large Language Models via Equivalence Checking" [<a href="https://arxiv.org/abs/2502.12466" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-03</td>
<td>ACL 2025</td>
<td>LONGCODEU</td>
<td>3983</td>
<td>Python</td>
<td>"LONGCODEU: Benchmarking Long-Context Language Models on Long Code Understanding" [<a href="https://arxiv.org/abs/2503.04359" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-05</td>
<td>arXiv</td>
<td>CodeSense</td>
<td>4495</td>
<td>Python, C, Java</td>
<td>"CodeSense: a Real-World Benchmark and Dataset for Code Semantic Reasoning" [<a href="https://arxiv.org/abs/2506.00750" rel="nofollow">paper</a>] [<a href="https://codesense-bench.github.io/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2025-07</td>
<td>arXiv</td>
<td>CORE</td>
<td>12,533</td>
<td>C/C++, Java, Python</td>
<td>"CORE: Benchmarking LLMs Code Reasoning Capabilities through Static Analysis Tasks" [<a href="https://arxiv.org/abs/2507.05269" rel="nofollow">paper</a>] [<a href="https://corebench.github.io/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2025-09</td>
<td>arXiv</td>
<td>SWE-QA</td>
<td>576</td>
<td>Python</td>
<td>"SWE-QA: Can Language Models Answer Repository-level Code Questions?" [<a href="https://arxiv.org/abs/2509.14635" rel="nofollow">paper</a>] [<a href="https://github.com/peng-weihan/SWE-QA-Bench">data</a>]</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Text-to-SQL</h4><a id="user-content-text-to-sql-1" class="anchor" aria-label="Permalink: Text-to-SQL" href="#text-to-sql-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>"Deep learning driven natural languages text to SQL query conversion: A survey", 2022-08, arXiv, [<a href="https://arxiv.org/abs/2208.04415" rel="nofollow">paper</a>]</li>
<li>"Recent Advances in Text-to-SQL: A Survey of What We Have and What We Expect", 2022-08, COLING 2022, [<a href="https://arxiv.org/abs/2208.10099" rel="nofollow">paper</a>]</li>
<li>"A Survey on Text-to-SQL Parsing: Concepts, Methods, and Future Directions", 2022-08, arXiv, [<a href="https://arxiv.org/abs/2208.13629" rel="nofollow">paper</a>]</li>
<li>"A survey on deep learning approaches for text-to-SQL", 2023-01, VLDB J., [<a href="https://link.springer.com/article/10.1007/s00778-022-00776-8" rel="nofollow">paper</a>]</li>
</ul>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Date</th>
<th>Venue</th>
<th>Benchmark</th>
<th>Size</th>
<th>Language</th>
<th>Source</th>
</tr>
</thead>
<tbody>
<tr>
<td>2017-08</td>
<td>arXiv</td>
<td>WikiSQL</td>
<td>80654</td>
<td></td>
<td>"Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning" [<a href="https://arxiv.org/abs/1709.00103" rel="nofollow">paper</a>] [<a href="https://github.com/salesforce/WikiSQL">data</a>]</td>
</tr>
<tr>
<td>2018-06</td>
<td>CL 2018</td>
<td>Advising</td>
<td>4570</td>
<td></td>
<td>"Improving Text-to-SQL Evaluation Methodology" [<a href="https://arxiv.org/abs/1806.09029" rel="nofollow">paper</a>] [<a href="https://github.com/jkkummerfeld/text2sql-data/">data</a>]</td>
</tr>
<tr>
<td>2018-09</td>
<td>EMNLP 2018</td>
<td>Spider</td>
<td>10181</td>
<td></td>
<td>"Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task" [<a href="https://arxiv.org/abs/1809.08887" rel="nofollow">paper</a>] [<a href="https://yale-lily.github.io/spider" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2019-06</td>
<td>ACL 2019</td>
<td>SParC</td>
<td>12726</td>
<td></td>
<td>"SParC: Cross-Domain Semantic Parsing in Context" [<a href="https://arxiv.org/abs/1906.02285" rel="nofollow">paper</a>] [<a href="https://yale-lily.github.io/sparc" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2019-07</td>
<td>WWW 2020</td>
<td>MIMICSQL</td>
<td>10000</td>
<td></td>
<td>"Text-to-SQL Generation for Question Answering on Electronic Medical Records" [<a href="https://arxiv.org/abs/1908.01839" rel="nofollow">paper</a>] [<a href="https://github.com/wangpinggl/TREQS">data</a>]</td>
</tr>
<tr>
<td>2019-09</td>
<td>EMNLP-IJCNLP 2019</td>
<td>CoSQL</td>
<td>15598</td>
<td></td>
<td>"CoSQL: A Conversational Text-to-SQL Challenge Towards Cross-Domain Natural Language Interfaces to Databases" [<a href="https://arxiv.org/abs/1909.05378" rel="nofollow">paper</a>] [<a href="https://yale-lily.github.io/cosql" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2020-05</td>
<td>LREC 2020</td>
<td>Criteria-to-SQL</td>
<td>2003</td>
<td></td>
<td>"Dataset and Enhanced Model for Eligibility Criteria-to-SQL Semantic Parsing" [<a href="https://aclanthology.org/2020.lrec-1.714/" rel="nofollow">paper</a>] [<a href="https://github.com/xiaojingyu92/Criteria2SQL">data</a>]</td>
</tr>
<tr>
<td>2020-10</td>
<td>EMNLP 2020 Findings</td>
<td>Squall</td>
<td>11276</td>
<td></td>
<td>"On the Potential of Lexico-logical Alignments for Semantic Parsing to SQL Queries" [<a href="https://arxiv.org/abs/2010.11246" rel="nofollow">paper</a>] [<a href="https://github.com/tzshi/squall">data</a>]</td>
</tr>
<tr>
<td>2020-10</td>
<td>NAACL-HLT 2021</td>
<td>Spider-Realistic</td>
<td>508</td>
<td></td>
<td>"Structure-Grounded Pretraining for Text-to-SQL" [<a href="https://arxiv.org/abs/2010.12773" rel="nofollow">paper</a>] [<a href="https://zenodo.org/records/5205322" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2021-06</td>
<td>ACL/IJCNLP 2021</td>
<td>Spider-Syn</td>
<td>8034</td>
<td></td>
<td>"Towards Robustness of Text-to-SQL Models against Synonym Substitution" [<a href="https://arxiv.org/abs/2106.01065" rel="nofollow">paper</a>] [<a href="https://arxiv.org/abs/2106.01065" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2021-06</td>
<td>NLP4Prog 2021</td>
<td>SEDE</td>
<td>12023</td>
<td></td>
<td>"Text-to-SQL in the Wild: A Naturally-Occurring Dataset Based on Stack Exchange Data" [<a href="https://arxiv.org/abs/2106.05006" rel="nofollow">paper</a>] [<a href="https://github.com/hirupert/sede">data</a>]</td>
</tr>
<tr>
<td>2021-06</td>
<td>ACL/IJCNLP 2021</td>
<td>KaggleDBQA</td>
<td>400</td>
<td></td>
<td>"KaggleDBQA: Realistic Evaluation of Text-to-SQL Parsers" [<a href="https://arxiv.org/abs/2106.11455" rel="nofollow">paper</a>] [<a href="https://github.com/chiahsuan156/KaggleDBQA">data</a>]</td>
</tr>
<tr>
<td>2021-09</td>
<td>EMNLP</td>
<td>Spider-DK</td>
<td>535</td>
<td></td>
<td>"Exploring Underexplored Limitations of Cross-Domain Text-to-SQL Generalization" [<a href="https://arxiv.org/abs/2109.05157" rel="nofollow">paper</a>] [<a href="https://github.com/ygan/Spider-DK">data</a>]</td>
</tr>
<tr>
<td>2022-05</td>
<td>NAACL 2022 Findings</td>
<td>Spider-SS/CG</td>
<td>8034/45599</td>
<td></td>
<td>"Measuring and Improving Compositional Generalization in Text-to-SQL via Component Alignment" [<a href="https://arxiv.org/abs/2205.02054" rel="nofollow">paper</a>] [<a href="https://github.com/ygan/SpiderSS-SpiderCG">data</a>]</td>
</tr>
<tr>
<td>2023-05</td>
<td>arXiv</td>
<td>BIRD</td>
<td>12751</td>
<td></td>
<td>"Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs" [<a href="https://arxiv.org/abs/2305.03111" rel="nofollow">paper</a>] [<a href="https://bird-bench.github.io/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2023-06</td>
<td>ACL 2023</td>
<td>XSemPLR</td>
<td>24.4K</td>
<td></td>
<td>"XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations" [<a href="https://arxiv.org/abs/2306.04085" rel="nofollow">paper</a>] [<a href="https://github.com/psunlpgroup/XSemPLR">data</a>]</td>
</tr>
<tr>
<td>2024-05</td>
<td>ACL 2024 Findings</td>
<td>EHR-SeqSQL</td>
<td>31669</td>
<td></td>
<td>"EHR-SeqSQL : A Sequential Text-to-SQL Dataset For Interactively Exploring Electronic Health Records" [<a href="https://arxiv.org/abs/2406.00019" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2024-06</td>
<td>NAACL 2024</td>
<td>BookSQL</td>
<td>100K</td>
<td></td>
<td>"BookSQL: A Large Scale Text-to-SQL Dataset for Accounting Domain" [<a href="https://arxiv.org/abs/2406.07860" rel="nofollow">paper</a>] [<a href="https://github.com/Exploration-Lab/BookSQL">data</a>]</td>
</tr>
<tr>
<td>2024-08</td>
<td>ACL 2024 Findings</td>
<td>MultiSQL</td>
<td>9257</td>
<td></td>
<td>"MultiSQL: A Schema-Integrated Context-Dependent Text2SQL Dataset with Diverse SQL Operations" [<a href="https://aclanthology.org/2024.findings-acl.823/" rel="nofollow">paper</a>] [<a href="https://github.com/grandchicken/MultiSQL">data</a>]</td>
</tr>
<tr>
<td>2024-09</td>
<td>arXiv</td>
<td>BEAVER</td>
<td>93</td>
<td></td>
<td>"BEAVER: An Enterprise Benchmark for Text-to-SQL" [<a href="https://arxiv.org/abs/2409.02038" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2024-10</td>
<td>arXiv</td>
<td>PRACTIQ</td>
<td>2812</td>
<td></td>
<td>"PRACTIQ: A Practical Conversational Text-to-SQL dataset with Ambiguous and Unanswerable Queries" [<a href="https://arxiv.org/abs/2410.11076" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2024-10</td>
<td>arXiv</td>
<td>BIS</td>
<td>239</td>
<td></td>
<td>"BIS: NL2SQL Service Evaluation Benchmark for Business Intelligence Scenarios" [<a href="https://arxiv.org/abs/2410.22925" rel="nofollow">paper</a>] [<a href="https://github.com/boracaglayan/bis-nl2sql">data</a>]</td>
</tr>
<tr>
<td>2024-11</td>
<td>ICLR 2025</td>
<td>Spider 2.0</td>
<td>632</td>
<td></td>
<td>"Spider 2.0: Evaluating Language Models on Real-World Enterprise Text-to-SQL Workflows" [<a href="https://arxiv.org/abs/2411.07763" rel="nofollow">paper</a>] [<a href="https://github.com/xlang-ai/Spider2">data</a>]</td>
</tr>
<tr>
<td>2025-01</td>
<td>arXiv</td>
<td>Dialect2SQL</td>
<td>9428</td>
<td></td>
<td>"Dialect2SQL: A Novel Text-to-SQL Dataset for Arabic Dialects with a Focus on Moroccan Darija" [<a href="https://arxiv.org/abs/2501.11498" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-05</td>
<td>arXiv</td>
<td>LogicCat</td>
<td>4038</td>
<td></td>
<td>"LogicCat: A Chain-of-Thought Text-to-SQL Benchmark for Multi-Domain Reasoning Challenges" [<a href="https://arxiv.org/abs/2505.18744" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-05</td>
<td>arXiv</td>
<td>BiomedSQL</td>
<td>68,000</td>
<td></td>
<td>"BiomedSQL: Text-to-SQL for Scientific Reasoning on Biomedical Knowledge Bases" [<a href="https://arxiv.org/abs/2505.20321" rel="nofollow">paper</a>] [<a href="https://github.com/NIH-CARD/biomedsql">data</a>]</td>
</tr>
<tr>
<td>2025-09</td>
<td>arXiv</td>
<td>PARROT</td>
<td>598</td>
<td></td>
<td>"PARROT: A Benchmark for Evaluating LLMs in Cross-System SQL Translation" [<a href="https://arxiv.org/abs/2509.23338" rel="nofollow">paper</a>] [<a href="https://github.com/weAIDB/PARROT">data</a>]</td>
</tr>
<tr>
<td>2025-09</td>
<td>arXiv</td>
<td>MultiSpider 2.0</td>
<td>5056</td>
<td></td>
<td>"Multilingual Text-to-SQL: Benchmarking the Limits of Language Models with Collaborative Language Agents" [<a href="https://arxiv.org/abs/2509.24405" rel="nofollow">paper</a>] [<a href="https://github.com/phkhanhtrinh23/Multilingual_Text_to_SQL">data</a>]</td>
</tr>
<tr>
<td>2025-10</td>
<td>arXiv</td>
<td>BIRD-INTERACT</td>
<td>600</td>
<td></td>
<td>"BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language Models via Lens of Dynamic Interactions" [<a href="https://arxiv.org/abs/2510.05318" rel="nofollow">paper</a>] [<a href="https://bird-interact.github.io/" rel="nofollow">data</a>]</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Code Translation</h4><a id="user-content-code-translation-1" class="anchor" aria-label="Permalink: Code Translation" href="#code-translation-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Date</th>
<th>Venue</th>
<th>Benchmark</th>
<th>Size</th>
<th>Language</th>
<th>Source</th>
</tr>
</thead>
<tbody>
<tr>
<td>2020-06</td>
<td>NeurIPS 2020</td>
<td>Transcoder GeeksforGeeks</td>
<td>1.4K</td>
<td>C++, Java, Python</td>
<td>"Unsupervised Translation of Programming Languages" [<a href="https://arxiv.org/abs/2006.03511" rel="nofollow">paper</a>] [<a href="https://github.com/facebookresearch/TransCoder">data</a>]</td>
</tr>
<tr>
<td>2021-02</td>
<td>NeurIPS Datasets and Benchmarks 2021</td>
<td>CodeTrans</td>
<td>11.8K</td>
<td>Java, C#</td>
<td>"CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation" [<a href="https://arxiv.org/abs/2102.04664" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/code_x_glue_cc_code_to_code_trans" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2021-08</td>
<td>ACL 2023 Findings</td>
<td>Avatar</td>
<td>9515</td>
<td>Java, Python</td>
<td>"AVATAR: A Parallel Corpus for Java-Python Program Translation" [<a href="https://arxiv.org/abs/2108.11590" rel="nofollow">paper</a>] [<a href="https://github.com/wasiahmad/AVATAR">data</a>]</td>
</tr>
<tr>
<td>2022-06</td>
<td>AAAI 2022</td>
<td>CoST</td>
<td>132K</td>
<td>C++, Java, Python, C#, JS, PHP, C</td>
<td>"Multilingual Code Snippets Training for Program Translation" [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/21434" rel="nofollow">paper</a>] [<a href="https://github.com/reddy-lab-code-research/MuST-CoST">data</a>]</td>
</tr>
<tr>
<td>2022-06</td>
<td>arXiv</td>
<td>XLCoST</td>
<td>567K</td>
<td>C++, Java, Python, C#, JS, PHP, C</td>
<td>"XLCoST: A Benchmark Dataset for Cross-lingual Code Intelligence" [<a href="https://arxiv.org/abs/2206.08474" rel="nofollow">paper</a>] [<a href="https://github.com/reddy-lab-code-research/XLCoST">data</a>]</td>
</tr>
<tr>
<td>2023-03</td>
<td>arXiv</td>
<td>xCodeEval</td>
<td>5.6M</td>
<td>C, C#, C++, Go, Java, JS, Kotlin, PHP, Python, Ruby, Rust</td>
<td>"xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval" [<a href="https://arxiv.org/abs/2303.03004" rel="nofollow">paper</a>] [<a href="https://github.com/ntunlp/xCodeEval">data</a>]</td>
</tr>
<tr>
<td>2023-03</td>
<td>arXiv</td>
<td>HumanEval-X</td>
<td>1640</td>
<td>Python, C++, Java, JS, Go</td>
<td>"CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X" [<a href="https://arxiv.org/abs/2303.17568" rel="nofollow">paper</a>] [<a href="https://github.com/THUDM/CodeGeeX">data</a>]</td>
</tr>
<tr>
<td>2023-08</td>
<td>arXiv</td>
<td>G-TransEval</td>
<td>4000</td>
<td>C++, Java, C#, JS, Python</td>
<td>"On the Evaluation of Neural Code Translation: Taxonomy and Benchmark" [<a href="https://arxiv.org/abs/2308.08961" rel="nofollow">paper</a>] [<a href="https://github.com/PolyEval/G-TransEval">data</a>]</td>
</tr>
<tr>
<td>2023-10</td>
<td>arXiv</td>
<td>CodeTransOcean</td>
<td>270.5K</td>
<td>45</td>
<td>"CodeTransOcean: A Comprehensive Multilingual Benchmark for Code Translation" [<a href="https://arxiv.org/abs/2310.04951" rel="nofollow">paper</a>] [<a href="https://github.com/WeixiangYAN/CodeTransOcean">data</a>]</td>
</tr>
<tr>
<td>2024-11</td>
<td>arXiv</td>
<td>Classeval-T</td>
<td>94</td>
<td>Python, Java, C++</td>
<td>"Escalating LLM-based Code Translation Benchmarking into the Class-level Era" [<a href="https://arxiv.org/abs/2411.06145" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2024-11</td>
<td>arXiv</td>
<td>RustRepoTrans</td>
<td>375</td>
<td>C++, Java, Python, Rust</td>
<td>"Repository-level Code Translation Benchmark Targeting Rust" [<a href="https://arxiv.org/abs/2411.13990" rel="nofollow">paper</a>] [<a href="https://github.com/TrustedGPT/RustRepoTrans">data</a>]</td>
</tr>
<tr>
<td>2024-12</td>
<td>arXiv</td>
<td>RepoTransBench</td>
<td>100</td>
<td>Python, Java</td>
<td>"RepoTransBench: A Real-World Benchmark for Repository-Level Code Translation" [<a href="https://arxiv.org/abs/2412.17744" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-01</td>
<td>arXiv</td>
<td>TransRepo-Bench</td>
<td>13</td>
<td>Java, C#</td>
<td>"Skeleton-Guided-Translation: A Benchmarking Framework for Code Repository Translation with Fine-Grained Quality Evaluation" [<a href="https://arxiv.org/abs/2501.16050" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-04</td>
<td>arXiv</td>
<td>CRUST-Bench</td>
<td>100</td>
<td>C, Rust</td>
<td>"CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation" [<a href="https://arxiv.org/abs/2504.15254" rel="nofollow">paper</a>] [<a href="https://github.com/anirudhkhatry/CRUST-bench">data</a>]</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Program Repair</h4><a id="user-content-program-repair-1" class="anchor" aria-label="Permalink: Program Repair" href="#program-repair-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>"Neural Program Repair: Systems, Challenges and Solutions", 2022-02, Internetware 2022, [<a href="https://arxiv.org/abs/2202.10868" rel="nofollow">paper</a>]</li>
<li>"A Survey of Learning-based Automated Program Repair", 2023-01, arXiv, [<a href="https://arxiv.org/abs/2301.03270" rel="nofollow">paper</a>]</li>
<li>"A Survey on Automated Program Repair Techniques", 2023-03, arXiv, [<a href="https://arxiv.org/abs/2303.18184" rel="nofollow">paper</a>]</li>
</ul>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Date</th>
<th>Venue</th>
<th>Benchmark</th>
<th>Size</th>
<th>Language</th>
<th>Source</th>
</tr>
</thead>
<tbody>
<tr>
<td>2014-07</td>
<td>ISSTA 2014</td>
<td>Defects4J</td>
<td>357</td>
<td>Java</td>
<td>"Defects4J: A Database of Existing Faults to Enable Controlled Testing Studies for Java Programs" [<a href="https://dl.acm.org/doi/10.1145/2610384.2628055" rel="nofollow">paper</a>] [<a href="https://github.com/rjust/defects4j">data</a>]</td>
</tr>
<tr>
<td>2015-12</td>
<td>IEEE Trans. Software Engineering</td>
<td>ManyBugs/IntroClass</td>
<td>185/998</td>
<td>C</td>
<td>"The ManyBugs and IntroClass Benchmarks for Automated Repair of C Programs" [<a href="https://ieeexplore.ieee.org/document/7153570" rel="nofollow">paper</a>] [<a href="https://repairbenchmarks.cs.umass.edu/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2016-11</td>
<td>FSE 2016</td>
<td>BugAID</td>
<td>105K</td>
<td>JS</td>
<td>"Discovering Bug Patterns in JavaScript" [<a href="https://dl.acm.org/doi/10.1145/2950290.2950308" rel="nofollow">paper</a>] [<a href="https://salt.ece.ubc.ca/software/bugaid/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2017-02</td>
<td>AAAI 2017</td>
<td>DeepFix</td>
<td>6971</td>
<td>C</td>
<td>"DeepFix: Fixing Common C Language Errors by Deep Learning" [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/10742" rel="nofollow">paper</a>] [<a href="https://bitbucket.org/iiscseal/deepfix/src/master/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2017-05</td>
<td>ICSE-C 2017</td>
<td>Codeflaws</td>
<td>3902</td>
<td>C</td>
<td>"DeepFix: Fixing Common C Language Errors by Deep Learning" [<a href="https://dl.acm.org/doi/10.1109/ICSE-C.2017.76" rel="nofollow">paper</a>] [<a href="https://codeflaws.github.io/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2017-10</td>
<td>SPLASH 2017</td>
<td>QuixBugs</td>
<td>80</td>
<td>Java, Python</td>
<td>"QuixBugs: a multi-lingual program repair benchmark set based on the quixey challenge" [<a href="https://dl.acm.org/doi/10.1145/3135932.3135941" rel="nofollow">paper</a>] [<a href="https://github.com/jkoppel/QuixBugs">data</a>]</td>
</tr>
<tr>
<td>2018-05</td>
<td>MSR 2018</td>
<td>Bugs.jar</td>
<td>1158</td>
<td>Java</td>
<td>"Bugs.jar: a large-scale, diverse dataset of real-world Java bugs" [<a href="https://dl.acm.org/doi/10.1145/3196398.3196473" rel="nofollow">paper</a>] [<a href="https://github.com/bugs-dot-jar/bugs-dot-jar">data</a>]</td>
</tr>
<tr>
<td>2018-12</td>
<td>ACM Trans. Softw. Eng. Methodol.</td>
<td>BFP</td>
<td>124K</td>
<td>Java</td>
<td>"An Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation" [<a href="https://arxiv.org/abs/1812.08693" rel="nofollow">paper</a>] [<a href="https://sites.google.com/view/learning-fixes" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2019-01</td>
<td>SANER 2019</td>
<td>Bears</td>
<td>251</td>
<td>Java</td>
<td>"Bears: An Extensible Java Bug Benchmark for Automatic Program Repair Studies" [<a href="https://arxiv.org/abs/1901.06024" rel="nofollow">paper</a>] [<a href="https://github.com/bears-bugs/bears-benchmark">data</a>]</td>
</tr>
<tr>
<td>2019-01</td>
<td>ICSE 2019</td>
<td>unnamed</td>
<td>21.8K *</td>
<td>Java</td>
<td>"On Learning Meaningful Code Changes via Neural Machine Translation" [<a href="https://arxiv.org/abs/1901.09102" rel="nofollow">paper</a>] [<a href="https://sites.google.com/view/learning-codechanges" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2019-04</td>
<td>ICST 2019</td>
<td>BugsJS</td>
<td>453</td>
<td>JS</td>
<td>"BugsJS: a Benchmark of JavaScript Bugs" [<a href="https://ieeexplore.ieee.org/document/8730197" rel="nofollow">paper</a>] [<a href="https://bugsjs.github.io/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2019-05</td>
<td>ICSE 2019</td>
<td>BugSwarm</td>
<td>1827/1264</td>
<td>Java/Python</td>
<td>"BugSwarm: mining and continuously growing a dataset of reproducible failures and fixes" [<a href="https://dl.acm.org/doi/10.1109/ICSE.2019.00048" rel="nofollow">paper</a>] [<a href="https://www.bugswarm.org/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2019-05</td>
<td>ICSE 2019</td>
<td>CPatMiner</td>
<td>17K *</td>
<td>Java</td>
<td>"Graph-based mining of in-the-wild, fine-grained, semantic code change patterns" [<a href="https://dl.acm.org/doi/10.1109/ICSE.2019.00089" rel="nofollow">paper</a>] [<a href="https://nguyenhoan.github.io/CPatMiner/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2019-05</td>
<td>MSR 2020</td>
<td>ManySStuBs4J</td>
<td>154K</td>
<td>Java</td>
<td>"How Often Do Single-Statement Bugs Occur? The ManySStuBs4J Dataset" [<a href="https://arxiv.org/abs/1905.13334" rel="nofollow">paper</a>] [<a href="https://github.com/mast-group/mineSStuBs">data</a>]</td>
</tr>
<tr>
<td>2019-11</td>
<td>ASE 2019</td>
<td>Refactory</td>
<td>1783</td>
<td>Python</td>
<td>"Re-factoring based program repair applied to programming assignments" [<a href="https://dl.acm.org/doi/10.1109/ASE.2019.00044" rel="nofollow">paper</a>] [<a href="https://github.com/githubhuyang/refactory">data</a>]</td>
</tr>
<tr>
<td>2020-07</td>
<td>ISSTA 2020</td>
<td>CoCoNut</td>
<td>24M</td>
<td>Java, Python, C, JS</td>
<td>"CoCoNuT: combining context-aware neural translation models using ensemble for program repair" [<a href="https://dl.acm.org/doi/10.1145/3395363.3397369" rel="nofollow">paper</a>] [<a href="https://github.com/lin-tan/CoCoNut-Artifact">data</a>]</td>
</tr>
<tr>
<td>2020-10</td>
<td>Inf. Softw. Technol.</td>
<td>Review4Repair</td>
<td>58021</td>
<td>Java</td>
<td>"Review4Repair: Code Review Aided Automatic Program Repairing" [<a href="https://arxiv.org/abs/2010.01544" rel="nofollow">paper</a>] [<a href="https://github.com/Review4Repair/Review4Repair">data</a>]</td>
</tr>
<tr>
<td>2020-11</td>
<td>ESEC/FSE 2020</td>
<td>BugsInPy</td>
<td>493</td>
<td>Python</td>
<td>"BugsInPy: A Database of Existing Bugs in Python Programs to Enable Controlled Testing and Debugging Studies" [<a href="https://dl.acm.org/doi/abs/10.1145/3368089.3417943" rel="nofollow">paper</a>] [<a href="https://github.com/soarsmu/BugsInPy">data</a>]</td>
</tr>
<tr>
<td>2021-07</td>
<td>ICML 2021</td>
<td>TFix</td>
<td>105K</td>
<td>JS</td>
<td>"TFix: Learning to Fix Coding Errors with a Text-to-Text Transformer" [<a href="https://proceedings.mlr.press/v139/berabi21a.html" rel="nofollow">paper</a>] [<a href="https://github.com/eth-sri/TFix">data</a>]</td>
</tr>
<tr>
<td>2021-08</td>
<td>arXiv</td>
<td>Megadiff</td>
<td>663K *</td>
<td>Java</td>
<td>"Megadiff: A Dataset of 600k Java Source Code Changes Categorized by Diff Size" [<a href="https://arxiv.org/abs/2108.04631" rel="nofollow">paper</a>] [<a href="https://github.com/ASSERT-KTH/megadiff">data</a>]</td>
</tr>
<tr>
<td>2022-01</td>
<td>SSB/TSSB</td>
<td>MSR 2022</td>
<td>9M/3M</td>
<td>Python</td>
<td>"TSSB-3M: Mining single statement bugs at massive scale" [<a href="https://arxiv.org/abs/2201.12046" rel="nofollow">paper</a>] [<a href="https://cedricrupb.github.io/TSSB3M/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2022-10</td>
<td>MSR 2022</td>
<td>FixJS</td>
<td>324K</td>
<td>JS</td>
<td>"FixJS: a dataset of bug-fixing JavaScript commits" [<a href="https://dl.acm.org/doi/abs/10.1145/3524842.3528480" rel="nofollow">paper</a>] [<a href="https://github.com/AAI-USZ/FixJS">data</a>]</td>
</tr>
<tr>
<td>2022-11</td>
<td>ESEC/FSE 2022</td>
<td>TypeBugs</td>
<td>93</td>
<td>Python</td>
<td>"PyTER: Effective Program Repair for Python Type Errors" [<a href="https://dl.acm.org/doi/abs/10.1145/3540250.3549130" rel="nofollow">paper</a>] [<a href="https://github.com/kupl/PyTER">data</a>]</td>
</tr>
<tr>
<td>2023-03</td>
<td>arXiv</td>
<td>xCodeEval</td>
<td>4.7M</td>
<td>C, C#, C++, Go, Java, JS, Kotlin, PHP, Python, Ruby, Rust</td>
<td>"xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval" [<a href="https://arxiv.org/abs/2303.03004" rel="nofollow">paper</a>] [<a href="https://github.com/ntunlp/xCodeEval">data</a>]</td>
</tr>
<tr>
<td>2023-04</td>
<td>arXiv</td>
<td>RunBugRun</td>
<td>450K</td>
<td>C, C++, Java, Python, JS, Ruby, Go, PHP</td>
<td>"RunBugRun -- An Executable Dataset for Automated Program Repair" [<a href="https://arxiv.org/abs/2304.01102" rel="nofollow">paper</a>] [<a href="https://github.com/giganticode/run_bug_run">data</a>]</td>
</tr>
<tr>
<td>2023-08</td>
<td>arXiv</td>
<td>HumanEvalPack</td>
<td>984</td>
<td>Python, JS, Go, Java, C++, Rust</td>
<td>"OctoPack: Instruction Tuning Code Large Language Models" [<a href="https://arxiv.org/abs/2308.07124" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/bigcode/humanevalpack" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2024-01</td>
<td>arXiv</td>
<td>DebugBench</td>
<td>4253</td>
<td>C++, Java, Python</td>
<td>"DebugBench: Evaluating Debugging Capability of Large Language Models" [<a href="https://arxiv.org/abs/2401.04621" rel="nofollow">paper</a>] [<a href="https://github.com/thunlp/DebugBench">data</a>]</td>
</tr>
<tr>
<td>2024-11</td>
<td>arXiv</td>
<td>MdEval</td>
<td>3513</td>
<td>18</td>
<td>"MdEval: Massively Multilingual Code Debugging" [<a href="https://arxiv.org/abs/2411.02310" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-01</td>
<td>arXiv</td>
<td>unnamed</td>
<td>48,398</td>
<td>Python</td>
<td>"Suggesting Code Edits in Interactive Machine Learning Notebooks Using Large Language Models" [<a href="https://arxiv.org/abs/2501.09745" rel="nofollow">paper</a>] [<a href="https://zenodo.org/records/14281690" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2025-09</td>
<td>arXiv</td>
<td>AgentPack</td>
<td>1.3M</td>
<td>20+</td>
<td>"AgentPack: A Dataset of Code Changes, Co-Authored by Agents and Humans" [<a href="https://arxiv.org/abs/2509.21891" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/nuprl/AgentPack" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2025-09</td>
<td>arXiv</td>
<td>OCEDataFT</td>
<td>20K</td>
<td>Python</td>
<td>"Generating High-Quality Datasets for Code Editing via Open-Source Language Models" [<a href="https://arxiv.org/abs/2509.25203" rel="nofollow">paper</a>] [<a href="https://github.com/zkzhang88/OpenCodeEdit">data</a>]</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">* These are code-change datasest, and only a subset therein concerns bug fixing.</p>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Code Summarization</h4><a id="user-content-code-summarization" class="anchor" aria-label="Permalink: Code Summarization" href="#code-summarization"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>"A Survey of Automatic Source Code Summarization", 2022-02, Symmetry, [<a href="https://www.mdpi.com/2073-8994/14/3/471" rel="nofollow">paper</a>]</li>
</ul>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Date</th>
<th>Venue</th>
<th>Benchmark</th>
<th>Size</th>
<th>Language</th>
<th>Source</th>
</tr>
</thead>
<tbody>
<tr>
<td>2016-08</td>
<td>ACL 2016</td>
<td>CODE-NN</td>
<td>66K/32K</td>
<td>C#/SQL</td>
<td>"Summarizing Source Code using a Neural Attention Model" [<a href="https://aclanthology.org/P16-1195/" rel="nofollow">paper</a>] [<a href="https://github.com/sriniiyer/codenn">data</a>]</td>
</tr>
<tr>
<td>2017-07</td>
<td>IJCNLP 2017</td>
<td>unnamed</td>
<td>150K</td>
<td>Python</td>
<td>"A parallel corpus of Python functions and documentation strings for automated code documentation and code generation" [<a href="https://arxiv.org/abs/1707.02275" rel="nofollow">paper</a>] [<a href="https://github.com/EdinburghNLP/code-docstring-corpus">data</a>]</td>
</tr>
<tr>
<td>2018-05</td>
<td>ICPC 2018</td>
<td>DeepCom</td>
<td>588K</td>
<td>Java</td>
<td>"Deep code comment generation" [<a href="https://dl.acm.org/doi/10.1145/3196321.3196334" rel="nofollow">paper</a>] [<a href="https://github.com/xing-hu/DeepCom">data</a>]</td>
</tr>
<tr>
<td>2018-07</td>
<td>IJCAI 2018</td>
<td>TL-CodeSum</td>
<td>411K</td>
<td>Java</td>
<td>"Summarizing Source Code with Transferred API Knowledge" [<a href="https://www.ijcai.org/proceedings/2018/314" rel="nofollow">paper</a>] [<a href="https://github.com/xing-hu/TL-CodeSum">data</a>]</td>
</tr>
<tr>
<td>2018-11</td>
<td>ASE 2018</td>
<td>unnamed</td>
<td>109K</td>
<td>Python</td>
<td>"Improving Automatic Source Code Summarization via Deep Reinforcement Learning" [<a href="https://arxiv.org/abs/1811.07234" rel="nofollow">paper</a>] [<a href="https://github.com/wanyao1992/code_summarization_public">data</a>]</td>
</tr>
<tr>
<td>2019-09</td>
<td>arxiv</td>
<td>CodeSearchNet</td>
<td>2.3M</td>
<td>Go, JS, Python, PHP, Java, Ruby</td>
<td>"CodeSearchNet Challenge: Evaluating the State of Semantic Code Search" [<a href="https://arxiv.org/abs/1909.09436" rel="nofollow">paper</a>] [<a href="https://github.com/github/CodeSearchNet">data</a>]</td>
</tr>
<tr>
<td>2023-08</td>
<td>arXiv</td>
<td>HumanEvalPack</td>
<td>984</td>
<td>Python, JS, Go, Java, C++, Rust</td>
<td>"OctoPack: Instruction Tuning Code Large Language Models" [<a href="https://arxiv.org/abs/2308.07124" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/bigcode/humanevalpack" rel="nofollow">data</a>]</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Defect/Vulnerability Detection</h4><a id="user-content-defectvulnerability-detection" class="anchor" aria-label="Permalink: Defect/Vulnerability Detection" href="#defectvulnerability-detection"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>"Benchmarking Software Vulnerability Detection Techniques: A Survey", 2023-03, arXiv, [<a href="https://arxiv.org/abs/2303.16362" rel="nofollow">paper</a>]</li>
</ul>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Date</th>
<th>Venue</th>
<th>Benchmark</th>
<th>Size</th>
<th>Language</th>
<th>Source</th>
</tr>
</thead>
<tbody>
<tr>
<td>2018-01</td>
<td>NDSS 2018</td>
<td>CGD</td>
<td>62K</td>
<td>C, C++</td>
<td>"VulDeePecker: A Deep Learning-Based System for Vulnerability Detection" [<a href="https://arxiv.org/abs/1801.01681" rel="nofollow">paper</a>] [<a href="https://github.com/CGCL-codes/VulDeePecker">data</a>]</td>
</tr>
<tr>
<td>2018-04</td>
<td>IEEE Trans. Ind. Informatics</td>
<td>unnamed</td>
<td>32988</td>
<td>C, C++</td>
<td>"Cross-Project Transfer Representation Learning for Vulnerable Function Discovery" [<a href="https://ieeexplore.ieee.org/document/8329207" rel="nofollow">paper</a>] [<a href="https://github.com/DanielLin1986/TransferRepresentationLearning">data</a>]</td>
</tr>
<tr>
<td>2018-07</td>
<td>ICMLA 2018</td>
<td>Draper VDISC</td>
<td>12.8M</td>
<td>C, C++</td>
<td>"Automated Vulnerability Detection in Source Code Using Deep Representation Learning" [<a href="https://arxiv.org/abs/1807.04320" rel="nofollow">paper</a>] [<a href="https://osf.io/d45bw/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2018-07</td>
<td>IEEE TDSC</td>
<td>SySeVR</td>
<td>15591</td>
<td>C, C++</td>
<td>"SySeVR: A Framework for Using Deep Learning to Detect Software Vulnerabilities" [<a href="https://arxiv.org/abs/1807.06756" rel="nofollow">paper</a>] [<a href="https://github.com/SySeVR/SySeVR">data</a>]</td>
</tr>
<tr>
<td>2019-02</td>
<td>MSR 2019</td>
<td>unnamed</td>
<td>624</td>
<td>Java</td>
<td>"A Manually-Curated Dataset of Fixes to Vulnerabilities of Open-Source Software" [<a href="https://arxiv.org/abs/1902.02595" rel="nofollow">paper</a>] [<a href="https://github.com/SAP/project-kb/tree/main/MSR2019">data</a>]</td>
</tr>
<tr>
<td>2019-09</td>
<td>NeurIPS 2019</td>
<td>Devign</td>
<td>49K</td>
<td>C</td>
<td>"Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks" [<a href="https://arxiv.org/abs/1909.03496" rel="nofollow">paper</a>] [<a href="https://sites.google.com/view/devign" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2019-11</td>
<td>IEEE TDSC</td>
<td>unnamed</td>
<td>170K</td>
<td>C, C++</td>
<td>"Software Vulnerability Discovery via Learning Multi-Domain Knowledge Bases" [<a href="https://ieeexplore.ieee.org/document/8906156" rel="nofollow">paper</a>] [<a href="https://github.com/DanielLin1986/RepresentationsLearningFromMulti_domain">data</a>]</td>
</tr>
<tr>
<td>2019-12</td>
<td>ICLR 2020</td>
<td>GREAT</td>
<td>2.8M</td>
<td>Python</td>
<td>"Global Relational Models of Source Code" [<a href="https://openreview.net/forum?id=B1lnbRNtwr" rel="nofollow">paper</a>] [<a href="https://zenodo.org/records/3954944" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2020-01</td>
<td>IEEE TDSC</td>
<td>MVD</td>
<td>182K</td>
<td>C, C++</td>
<td>"VulDeePecker: A Deep Learning-Based System for Multiclass Vulnerability Detection" [<a href="https://arxiv.org/abs/2001.02334" rel="nofollow">paper</a>] [<a href="https://github.com/muVulDeePecker/muVulDeePecker">data</a>]</td>
</tr>
<tr>
<td>2020-02</td>
<td>ICICS 2019</td>
<td>unnamed</td>
<td>1471</td>
<td>C</td>
<td>"Deep Learning-Based Vulnerable Function Detection: A Benchmark" [<a href="https://link.springer.com/chapter/10.1007/978-3-030-41579-2_13" rel="nofollow">paper</a>] [<a href="https://github.com/DanielLin1986/Function-level-Vulnerability-Detection">data</a>]</td>
</tr>
<tr>
<td>2020-09</td>
<td>IEEE Trans. Software Eng.</td>
<td>ReVeal</td>
<td>18K</td>
<td>C</td>
<td>"Deep Learning based Vulnerability Detection: Are We There Yet?" [<a href="https://arxiv.org/abs/2009.07235" rel="nofollow">paper</a>] [<a href="https://bit.ly/3bX30ai" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2020-09</td>
<td>MSR 2020</td>
<td>Big-Vul</td>
<td>265K</td>
<td>C, C++</td>
<td>"A C/C++ Code Vulnerability Dataset with Code Changes and CVE Summaries" [<a href="https://dl.acm.org/doi/10.1145/3379597.3387501" rel="nofollow">paper</a>] [<a href="https://github.com/ZeoVan/MSR_20_Code_Vulnerability_CSV_Dataset">data</a>]</td>
</tr>
<tr>
<td>2021-02</td>
<td>ICSE (SEIP) 2021</td>
<td>D2A</td>
<td>1.3M</td>
<td>C, C++</td>
<td>"D2A: A Dataset Built for AI-Based Vulnerability Detection Methods Using Differential Analysis" [<a href="https://arxiv.org/abs/2102.07995" rel="nofollow">paper</a>] [<a href="https://github.com/ibm/D2A">data</a>]</td>
</tr>
<tr>
<td>2021-05</td>
<td>NeurIPS 2021</td>
<td>PyPIBugs</td>
<td>2374</td>
<td>Python</td>
<td>"Self-Supervised Bug Detection and Repair" [<a href="https://arxiv.org/abs/2105.12787" rel="nofollow">paper</a>] [<a href="https://www.microsoft.com/en-us/download/103554" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2021-07</td>
<td>In PROMISE 2021</td>
<td>CVEfixes</td>
<td>5495</td>
<td>27</td>
<td>"CVEfixes: Automated Collection of Vulnerabilities and Their Fixes from Open-Source Software" [<a href="https://arxiv.org/abs/2107.08760" rel="nofollow">paper</a>] [<a href="https://zenodo.org/records/7029359" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2021-08</td>
<td>ESEC/FSE 2021</td>
<td>CrossVul</td>
<td>27476</td>
<td>40+</td>
<td>"CrossVul: a cross-language vulnerability dataset with commit data" [<a href="https://dl.acm.org/doi/10.1145/3468264.3473122" rel="nofollow">paper</a>] [<a href="https://zenodo.org/records/4734050" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2023-04</td>
<td>RAID 2023</td>
<td>DiverseVul</td>
<td>349K</td>
<td>C, C++</td>
<td>"DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection" [<a href="https://arxiv.org/abs/2304.00409" rel="nofollow">paper</a>] [<a href="https://github.com/wagner-group/diversevul">data</a>]</td>
</tr>
<tr>
<td>2023-06</td>
<td>arXiv</td>
<td>VulnPatchPairs</td>
<td>26K</td>
<td>C</td>
<td>"Limits of Machine Learning for Automatic Vulnerability Detection" [<a href="https://arxiv.org/abs/2306.17193" rel="nofollow">paper</a>] [<a href="https://github.com/niklasrisse/LimitsOfML4Vuln">data</a>]</td>
</tr>
<tr>
<td>2023-11</td>
<td>arXiv</td>
<td>VulBench</td>
<td>455</td>
<td>C</td>
<td>"How Far Have We Gone in Vulnerability Detection Using Large Language Models" [<a href="https://arxiv.org/abs/2311.12420" rel="nofollow">paper</a>] [<a href="https://anonymous.4open.science/r/VulBench-EA6F/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2024-03</td>
<td>arXiv</td>
<td>PrimeVul</td>
<td>236K</td>
<td>C/C++</td>
<td>"Vulnerability Detection with Code Language Models: How Far Are We?" [<a href="https://arxiv.org/abs/2403.18624" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2024-06</td>
<td>arXiv</td>
<td>VulDetectBench</td>
<td>1000</td>
<td>C/C++</td>
<td>"VulDetectBench: Evaluating the Deep Capability of Vulnerability Detection with Large Language Models" [<a href="https://arxiv.org/abs/2406.07595" rel="nofollow">paper</a>] [<a href="https://github.com/Sweetaroo/VulDetectBench">data</a>]</td>
</tr>
<tr>
<td>2024-08</td>
<td>arXiv</td>
<td>CodeJudge-Eval</td>
<td>1860</td>
<td>Python</td>
<td>"CodeJudge-Eval: Can Large Language Models be Good Judges in Code Understanding?" [<a href="https://arxiv.org/abs/2408.10718" rel="nofollow">paper</a>] [<a href="https://github.com/CodeLLM-Research/CodeJudge-Eval">data</a>]</td>
</tr>
<tr>
<td>2024-11</td>
<td>arXiv</td>
<td>CleanVul</td>
<td>11632</td>
<td>Java, Python, JS, C#, C/C++</td>
<td>"CleanVul: Automatic Function-Level Vulnerability Detection in Code Commits Using LLM Heuristics" [<a href="https://arxiv.org/abs/2411.17274" rel="nofollow">paper</a>] [<a href="https://github.com/yikun-li/CleanVul">data</a>]</td>
</tr>
<tr>
<td>2025-03</td>
<td>arXiv</td>
<td>CASTLE</td>
<td>250</td>
<td>C</td>
<td>"CASTLE: Benchmarking Dataset for Static Code Analyzers and LLMs towards CWE Detection" [<a href="https://arxiv.org/abs/2503.09433" rel="nofollow">paper</a>] [<a href="https://github.com/CASTLE-Benchmark/Tests-C250">data</a>]</td>
</tr>
<tr>
<td>2025-03</td>
<td>arXiv</td>
<td>DSDBench</td>
<td>1117</td>
<td>Python</td>
<td>"Why Stop at One Error? Benchmarking LLMs as Data Science Code Debuggers for Multi-Hop and Multi-Bug Errors" [<a href="https://arxiv.org/abs/2503.22388" rel="nofollow">paper</a>] [<a href="https://github.com/KevinCL16/DSDBench">data</a>]</td>
</tr>
<tr>
<td>2025-05</td>
<td>arXiv</td>
<td>SecVulEval</td>
<td>25440</td>
<td>C/C++</td>
<td>"SecVulEval: Benchmarking LLMs for Real-World C/C++ Vulnerability Detection" [<a href="https://arxiv.org/abs/2505.19828" rel="nofollow">paper</a>] [<a href="https://github.com/basimbd/SecVulEval">data</a>]</td>
</tr>
<tr>
<td>2025-05</td>
<td>arXiv</td>
<td>SV-TrustEval-C</td>
<td>3,337</td>
<td>C</td>
<td>"SV-TrustEval-C: Evaluating Structure and Semantic Reasoning in Large Language Models for Source Code Vulnerability Analysis" [<a href="https://arxiv.org/abs/2505.20630" rel="nofollow">paper</a>] [<a href="https://github.com/Jackline97/SV-TrustEval-C">data</a>]</td>
</tr>
<tr>
<td>2025-09</td>
<td>arXiv</td>
<td>MULocBench</td>
<td>1,100</td>
<td>Python</td>
<td>"A Benchmark for Localizing Code and Non-Code Issues in Software Projects" [<a href="https://arxiv.org/abs/2509.25242" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/somethingone/MULocBench" rel="nofollow">data</a>]</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Code Retrieval</h4><a id="user-content-code-retrieval" class="anchor" aria-label="Permalink: Code Retrieval" href="#code-retrieval"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>"Code Search: A Survey of Techniques for Finding Code", 2022-04, ICSME 2021, [[paper](ACM Comput. Surv)]</li>
<li>"A Survey of Deep Code Search", 2023-05, arXiv, [<a href="https://arxiv.org/abs/2305.05959" rel="nofollow">paper</a>]</li>
</ul>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Date</th>
<th>Venue</th>
<th>Benchmark</th>
<th>Size</th>
<th>Language</th>
<th>Source</th>
</tr>
</thead>
<tbody>
<tr>
<td>2018-03</td>
<td>WWW 2018</td>
<td>StaQC</td>
<td>148K/120K</td>
<td>Python/SQL</td>
<td>"StaQC: A Systematically Mined Question-Code Dataset from Stack Overflow" [<a href="https://arxiv.org/abs/1803.09371" rel="nofollow">paper</a>] [<a href="https://github.com/LittleYUYU/StackOverflow-Question-Code-Dataset">data</a>]</td>
</tr>
<tr>
<td>2018-05</td>
<td>ICSE 2018</td>
<td>DeepCS</td>
<td>16.2M</td>
<td>Java</td>
<td>"Deep Code Search" [<a href="https://dl.acm.org/doi/10.1145/3180155.3180167" rel="nofollow">paper</a>] [<a href="https://github.com/guxd/deep-code-search">data</a>]</td>
</tr>
<tr>
<td>2018-05</td>
<td>MSR 2018</td>
<td>CoNaLa</td>
<td>600K/2.9K</td>
<td>Python</td>
<td>"Learning to Mine Aligned Code and Natural Language Pairs from Stack Overflow" [<a href="https://arxiv.org/abs/1805.08949" rel="nofollow">paper</a>] [<a href="https://conala-corpus.github.io/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2019-08</td>
<td>arXiv</td>
<td>unnamed</td>
<td>287</td>
<td>Java</td>
<td>"Neural Code Search Evaluation Dataset" [<a href="https://arxiv.org/abs/1908.09804" rel="nofollow">paper</a>] [<a href="https://github.com/facebookresearch/Neural-Code-Search-Evaluation-Dataset">data</a>]</td>
</tr>
<tr>
<td>2019-09</td>
<td>arXiv</td>
<td>CodeSearchNet</td>
<td>2.3M/99</td>
<td>Go, PHP, JS, Python, Java, Ruby</td>
<td>"CodeSearchNet Challenge: Evaluating the State of Semantic Code Search" [<a href="https://arxiv.org/abs/1909.09436" rel="nofollow">paper</a>] [<a href="https://github.com/github/CodeSearchNet">data</a>]</td>
</tr>
<tr>
<td>2020-02</td>
<td>SANER 2020</td>
<td>CosBench</td>
<td>52</td>
<td>Java</td>
<td>"Are the Code Snippets What We Are Searching for? A Benchmark and an Empirical Study on Code Search with Natural-Language Queries" [<a href="https://ieeexplore.ieee.org/document/9054840" rel="nofollow">paper</a>] [<a href="https://github.com/BASE-LAB-SJTU/CosBench/wiki">data</a>]</td>
</tr>
<tr>
<td>2020-08</td>
<td>arXiv</td>
<td>SO-DS</td>
<td>2.2K</td>
<td>Python</td>
<td>"Neural Code Search Revisited: Enhancing Code Snippet Retrieval through Natural Language Intent" [<a href="https://arxiv.org/abs/2008.12193" rel="nofollow">paper</a>] [<a href="https://github.com/nokia/codesearch">data</a>]</td>
</tr>
<tr>
<td>2020-10</td>
<td>ACM Trans. Knowl. Discov. Data</td>
<td>FB-Java</td>
<td>249K</td>
<td>Java</td>
<td>"Deep Graph Matching and Searching for Semantic Code Retrieval" [<a href="https://arxiv.org/abs/2010.12908" rel="nofollow">paper</a>] [<a href="https://github.com/ryderling/DGMS">data</a>]</td>
</tr>
<tr>
<td>2021-02</td>
<td>NeurIPS Datasets and Benchmarks 2021</td>
<td>AdvTest/WebQueryTest</td>
<td>280K/1K</td>
<td>Python</td>
<td>"CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation" [<a href="https://arxiv.org/abs/2102.04664" rel="nofollow">paper</a>] [[data]]</td>
</tr>
<tr>
<td>2021-05</td>
<td>ACL/IJCNLP 2021</td>
<td>CoSQA</td>
<td>21K</td>
<td>Python</td>
<td>"CoSQA: 20,000+ Web Queries for Code Search and Question Answering" [<a href="https://arxiv.org/abs/2105.13239" rel="nofollow">paper</a>] [<a href="https://github.com/microsoft/CodeXGLUE/tree/main/Text-Code/NL-code-search-WebQuery">data</a>]</td>
</tr>
<tr>
<td>2024-03</td>
<td>arXiv</td>
<td>ProCQA</td>
<td>5.2M</td>
<td>C, C++, Java, Python, Ruby, Lisp, JS, C#, Go, Rust, PHP</td>
<td>"ProCQA: A Large-scale Community-based Programming Question Answering Dataset for Code Search" [<a href="https://arxiv.org/abs/2403.16702" rel="nofollow">paper</a>] [<a href="https://github.com/jordane95/procqa">data</a>]</td>
</tr>
<tr>
<td>2024-06</td>
<td>arXiv</td>
<td>CoSQA+</td>
<td>109K</td>
<td>Python</td>
<td>"CoSQA+: Enhancing Code Search Dataset with Matching Code" [<a href="https://arxiv.org/abs/2406.11589" rel="nofollow">paper</a>] [<a href="https://github.com/DeepSoftwareAnalytics/CoSQA_Plus">data</a>]</td>
</tr>
<tr>
<td>2024-07</td>
<td>ACL 2025</td>
<td>CoIR</td>
<td>~2M</td>
<td>14</td>
<td>"CoIR: A Comprehensive Benchmark for Code Information Retrieval Models" [<a href="https://arxiv.org/abs/2407.02883" rel="nofollow">paper</a>] [<a href="https://github.com/CoIR-team/coir">data</a>]</td>
</tr>
<tr>
<td>2024-08</td>
<td>arXiv</td>
<td>SeqCoBench</td>
<td>14.5K</td>
<td>Python</td>
<td>"What can Large Language Models Capture about Code Functional Equivalence?" [<a href="https://arxiv.org/abs/2408.11081" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-05</td>
<td>arXiv</td>
<td>CoQuIR</td>
<td>42,725</td>
<td>11</td>
<td>"CoQuIR: A Comprehensive Benchmark for Code Quality-Aware Information Retrieval" [<a href="https://arxiv.org/abs/2506.11066" rel="nofollow">paper</a>] [<a href="https://github.com/TRUMANCFY/CoQuIR">data</a>]</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Type Inference</h4><a id="user-content-type-inference" class="anchor" aria-label="Permalink: Type Inference" href="#type-inference"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Date</th>
<th>Venue</th>
<th>Benchmark</th>
<th>Size</th>
<th>Language</th>
<th>Source</th>
</tr>
</thead>
<tbody>
<tr>
<td>2019-12</td>
<td>ESEC/FSE 2020</td>
<td>TypeWriter OSS</td>
<td>208K</td>
<td>Python</td>
<td>"TypeWriter: Neural Type Prediction with Search-based Validation" [<a href="https://arxiv.org/abs/1912.03768" rel="nofollow">paper</a>] [<a href="http://software-lab.org/projects/TypeWriter/data.tar.gz" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2020-04</td>
<td>PLDI 2020</td>
<td>Typilus</td>
<td>252K</td>
<td>Python</td>
<td>"Typilus: Neural Type Hints" [<a href="https://arxiv.org/abs/2004.10657" rel="nofollow">paper</a>] [<a href="https://github.com/typilus/typilus">data</a>]</td>
</tr>
<tr>
<td>2020-04</td>
<td>ICLR 2020</td>
<td>LambdaNet</td>
<td>300 *</td>
<td>TypeScript</td>
<td>"LambdaNet: Probabilistic Type Inference using Graph Neural Networks" [<a href="https://arxiv.org/abs/2005.02161" rel="nofollow">paper</a>] [<a href="https://github.com/MrVPlusOne/LambdaNet">data</a>]</td>
</tr>
<tr>
<td>2021-04</td>
<td>MSR 2021</td>
<td>ManyTypes4Py</td>
<td>869K</td>
<td>Python</td>
<td>"ManyTypes4Py: A Benchmark Python Dataset for Machine Learning-based Type Inference" [<a href="https://arxiv.org/abs/2104.04706" rel="nofollow">paper</a>] [<a href="https://github.com/saltudelft/many-types-4-py-dataset">data</a>]</td>
</tr>
<tr>
<td>2022-10</td>
<td>MSR 2022</td>
<td>ManyTypes4TypeScript</td>
<td>9.1M</td>
<td>TypeScript</td>
<td>"ManyTypes4TypeScript: a comprehensive TypeScript dataset for sequence-based type inference" [<a href="https://dl.acm.org/doi/10.1145/3524842.3528507" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/kevinjesse/ManyTypes4TypeScript" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2023-02</td>
<td>ECOOP 2023</td>
<td>TypeWeaver</td>
<td>513 *</td>
<td>TypeScript</td>
<td>"Do Machine Learning Models Produce TypeScript Types That Type Check?" [<a href="https://arxiv.org/abs/2302.12163" rel="nofollow">paper</a>] [<a href="https://zenodo.org/records/7662708" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2023-03</td>
<td>ICLR 2023</td>
<td>BetterTypes4Py/InferTypes4Py</td>
<td>608K/4.6K</td>
<td>Python</td>
<td>"TypeT5: Seq2seq Type Inference using Static Analysis" [<a href="https://arxiv.org/abs/2303.09564" rel="nofollow">paper</a>] [<a href="https://github.com/utopia-group/TypeT5">data</a>]</td>
</tr>
<tr>
<td>2023-05</td>
<td>arXiv</td>
<td>OpenTau</td>
<td>744 *</td>
<td>TypeScript</td>
<td>"Type Prediction With Program Decomposition and Fill-in-the-Type Training" [<a href="https://arxiv.org/abs/2305.17145" rel="nofollow">paper</a>] [<a href="https://github.com/GammaTauAI/opentau">data</a>]</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">* These are project counts.</p>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Commit Message Generation</h4><a id="user-content-commit-message-generation-1" class="anchor" aria-label="Permalink: Commit Message Generation" href="#commit-message-generation-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>"On the Evaluation of Commit Message Generation Models: An Experimental Study", 2021-07, ICSME 2021, [<a href="https://arxiv.org/abs/2107.05373" rel="nofollow">paper</a>]</li>
</ul>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Date</th>
<th>Venue</th>
<th>Benchmark</th>
<th>Size</th>
<th>Language</th>
<th>Source</th>
</tr>
</thead>
<tbody>
<tr>
<td>2017-03</td>
<td>ICPC 2017</td>
<td>unnamed</td>
<td>509K</td>
<td>Java</td>
<td>"Towards Automatic Generation of Short Summaries of Commits" [<a href="https://arxiv.org/abs/1703.09603" rel="nofollow">paper</a>] [<a href="https://notredame.app.box.com/s/wghwpw46x41nu6iulm6qi8j42finuxni" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2017-04</td>
<td>ACL 2017</td>
<td>CommitGen</td>
<td>153K</td>
<td>Python, JS, C++, Java</td>
<td>"A Neural Architecture for Generating Natural Language Descriptions from Source Code Changes" [<a href="https://arxiv.org/abs/1704.04856" rel="nofollow">paper</a>] [<a href="https://github.com/epochx/commitgen">data</a>]</td>
</tr>
<tr>
<td>2017-08</td>
<td>ASE 2017</td>
<td>CommitGen</td>
<td>32K/75K *</td>
<td>Java</td>
<td>"Automatically Generating Commit Messages from Diffs using Neural Machine Translation" [<a href="https://arxiv.org/abs/1708.09492" rel="nofollow">paper</a>] [<a href="https://notredame.app.box.com/s/wghwpw46x41nu6iulm6qi8j42finuxni" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2018-09</td>
<td>ASE 2018</td>
<td>NNGen</td>
<td>27K</td>
<td>Java</td>
<td>"Neural-machine-translation-based commit message generation: how far are we?" [<a href="https://dl.acm.org/doi/10.1145/3238147.3238190" rel="nofollow">paper</a>] [<a href="https://github.com/Tbabm/nngen">data</a>]</td>
</tr>
<tr>
<td>2019-05</td>
<td>MSR 2019</td>
<td>PtrGNCMsg</td>
<td>64.9K</td>
<td>Java</td>
<td>"Generating commit messages from diffs using pointer-generator network" [<a href="https://dl.acm.org/doi/10.1109/MSR.2019.00056" rel="nofollow">paper</a>] [[data(<a href="https://zenodo.org/records/2593787" rel="nofollow">https://zenodo.org/records/2593787</a>)]]</td>
</tr>
<tr>
<td>2019-08</td>
<td>IJCAI 2019</td>
<td>CoDiSum</td>
<td>90.7K</td>
<td>Java</td>
<td>"Commit message generation for source code changes" [<a href="https://www.ijcai.org/proceedings/2019/552" rel="nofollow">paper</a>] [<a href="https://github.com/SoftWiser-group/CoDiSum">data</a>]</td>
</tr>
<tr>
<td>2019-12</td>
<td>IEEE Trans. Software Eng.</td>
<td>ATOM</td>
<td>160K</td>
<td>Java</td>
<td>"ATOM: Commit Message Generation Based on Abstract Syntax Tree and Hybrid Ranking" [<a href="https://arxiv.org/abs/1912.02972" rel="nofollow">paper</a>] [<a href="https://zenodo.org/records/4077754#.X4K2b5MzZTY" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2021-05</td>
<td>arXiv</td>
<td>CommitBERT</td>
<td>346K</td>
<td>Python, PHP, Go, Java, JS, Ruby</td>
<td>"CommitBERT: Commit Message Generation Using Pre-Trained Programming Language Model" [<a href="https://arxiv.org/abs/2105.14242" rel="nofollow">paper</a>] [<a href="https://github.com/graykode/commit-autosuggestions">data</a>]</td>
</tr>
<tr>
<td>2021-07</td>
<td>ICSME 2021</td>
<td>MCMD</td>
<td>2.25M</td>
<td>Java, C#, C++, Python, JS</td>
<td>"On the Evaluation of Commit Message Generation Models: An Experimental Study" [<a href="https://arxiv.org/abs/2107.05373" rel="nofollow">paper</a>] [<a href="https://github.com/DeepSoftwareAnalytics/CommitMsgEmpirical">data</a>]</td>
</tr>
<tr>
<td>2021-07</td>
<td>ACM Trans. Softw. Eng. Methodol.</td>
<td>CoRec</td>
<td>107K</td>
<td>Java</td>
<td>"Context-aware Retrieval-based Deep Commit Message Generation" [<a href="https://dl.acm.org/doi/10.1145/3464689" rel="nofollow">paper</a>] [<a href="https://zenodo.org/records/3828107" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2023-07</td>
<td>ASE 2023</td>
<td>ExGroFi</td>
<td>19263</td>
<td>Java</td>
<td>"Delving into Commit-Issue Correlation to Enhance Commit Message Generation Models" [<a href="https://arxiv.org/abs/2308.00147" rel="nofollow">paper</a>] [<a href="https://zenodo.org/records/7885748#.ZFDT5IJBxD8" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2023-08</td>
<td>ASE 2023</td>
<td>CommitChronicle</td>
<td>10.7M</td>
<td>20</td>
<td>"From Commit Message Generation to History-Aware Commit Message Completion" [<a href="https://arxiv.org/abs/2308.07655" rel="nofollow">paper</a>] [<a href="https://github.com/JetBrains-Research/commit_message_generation">data</a>]</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">* with/without verb-direct object filter</p>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Repo-Level Coding</h4><a id="user-content-repo-level-coding" class="anchor" aria-label="Permalink: Repo-Level Coding" href="#repo-level-coding"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Date</th>
<th>Venue</th>
<th>Benchmark</th>
<th>Size</th>
<th>Language</th>
<th>Source</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023-03</td>
<td>arXiv</td>
<td>RepoEval</td>
<td>1600/1600/373 *</td>
<td>Python</td>
<td>"RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation" [<a href="https://arxiv.org/abs/2303.12570" rel="nofollow">paper</a>] [<a href="https://github.com/microsoft/CodeT/tree/main/RepoCoder">data</a>]</td>
</tr>
<tr>
<td>2023-06</td>
<td>ICLR 2024</td>
<td>RepoBench</td>
<td>890K/9M/43K <math-renderer class="js-inline-math" style="display: inline-block" data-run-id="b3caf4e842e88b86948a693f78d2e24c">$^\dagger$</math-renderer>
</td>
<td>Python, Java</td>
<td>"RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems" [<a href="https://arxiv.org/abs/2306.03091" rel="nofollow">paper</a>] [<a href="https://github.com/Leolty/repobench">data</a>]</td>
</tr>
<tr>
<td>2023-06</td>
<td>NeurIPS 2023</td>
<td>PragmaticCode</td>
<td>880 **</td>
<td>Java</td>
<td>"Guiding Language Models of Code with Global Context using Monitors" [<a href="https://arxiv.org/abs/2306.10763" rel="nofollow">paper</a>] [<a href="https://github.com/microsoft/monitors4codegen">data</a>]</td>
</tr>
<tr>
<td>2023-06</td>
<td>arXiv</td>
<td>Stack-Repo</td>
<td>816K</td>
<td>Java</td>
<td>"RepoFusion: Training Code Models to Understand Your Repository" [<a href="https://arxiv.org/abs/2306.10998" rel="nofollow">paper</a>] [<a href="https://huggingface.co/RepoFusion" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2023-09</td>
<td>ISMB 2024</td>
<td>BioCoder</td>
<td>2269/460/460</td>
<td>Python, Java</td>
<td>"BioCoder: A Benchmark for Bioinformatics Code Generation with Large Language Models" [<a href="https://arxiv.org/abs/2308.16458" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/lilbillbiscuit/biocoder_public" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2023-09</td>
<td>arXiv</td>
<td>CodePlan</td>
<td>645/21 <math-renderer class="js-inline-math" style="display: inline-block" data-run-id="b3caf4e842e88b86948a693f78d2e24c">$^\ddagger$</math-renderer>
</td>
<td>C#/Python <math-renderer class="js-inline-math" style="display: inline-block" data-run-id="b3caf4e842e88b86948a693f78d2e24c">$^\ddagger$</math-renderer>
</td>
<td>"CodePlan: Repository-level Coding using LLMs and Planning" [<a href="https://arxiv.org/abs/2309.12499" rel="nofollow">paper</a>] [<a href="https://aka.ms/CodePlan" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2023-10</td>
<td>arXiv</td>
<td>SWE-Bench</td>
<td>2294</td>
<td>Python</td>
<td>"SWE-bench: Can Language Models Resolve Real-World GitHub Issues?" [<a href="https://arxiv.org/abs/2310.06770" rel="nofollow">paper</a>] [<a href="https://www.swebench.com/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2023-10</td>
<td>arXiv</td>
<td>CrossCodeEval</td>
<td>9928</td>
<td>Python, Java, TypeScript, C#</td>
<td>"CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code Completion" [<a href="https://arxiv.org/abs/2310.11248" rel="nofollow">paper</a>] [<a href="https://crosscodeeval.github.io/" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2024-03</td>
<td>NeurIPS 2024</td>
<td>EvoCodeBench</td>
<td>275</td>
<td>Python</td>
<td>"EvoCodeBench: An Evolving Code Generation Benchmark Aligned with Real-World Code Repositories" [<a href="https://arxiv.org/abs/2404.00599" rel="nofollow">paper</a>] [<a href="https://github.com/seketeam/EvoCodeBench">data</a>]</td>
</tr>
<tr>
<td>2024-05</td>
<td>ACL 2024 Findings</td>
<td>DevEval</td>
<td>1874</td>
<td>Python</td>
<td>"DevEval: A Manually-Annotated Code Generation Benchmark Aligned with Real-World Code Repositories" [<a href="https://arxiv.org/abs/2405.19856" rel="nofollow">paper</a>] [<a href="https://github.com/seketeam/DevEval">data</a>]</td>
</tr>
<tr>
<td>2024-06</td>
<td>arXiv</td>
<td>JavaBench</td>
<td>389</td>
<td>Java</td>
<td>"Can AI Beat Undergraduates in Entry-level Java Assignments? Benchmarking Large Language Models on JavaBench" [<a href="https://arxiv.org/abs/2406.12902" rel="nofollow">paper</a>] [<a href="https://github.com/java-bench/JavaBench">data</a>]</td>
</tr>
<tr>
<td>2024-06</td>
<td>arXiv</td>
<td>HumanEvo</td>
<td>200/200</td>
<td>Python/Java</td>
<td>"Towards more realistic evaluation of LLM-based code generation: an experimental study and beyond" [<a href="https://arxiv.org/abs/2406.06918" rel="nofollow">paper</a>] [<a href="https://github.com/DeepSoftwareAnalytics/EvoEval">data</a>]</td>
</tr>
<tr>
<td>2024-06</td>
<td>arXiv</td>
<td>RepoExec</td>
<td>355</td>
<td>Python</td>
<td>"REPOEXEC: Evaluate Code Generation with a Repository-Level Executable Benchmark" [<a href="https://arxiv.org/abs/2406.11927" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2024-06</td>
<td>arXiv</td>
<td>RES-Q</td>
<td>100</td>
<td>Python, JavaScript</td>
<td>"RES-Q: Evaluating Code-Editing Large Language Model Systems at the Repository Scale" [<a href="https://arxiv.org/abs/2406.16801" rel="nofollow">paper</a>] [<a href="https://github.com/Qurrent-AI/RES-Q">data</a>]</td>
</tr>
<tr>
<td>2024-08</td>
<td>arXiv</td>
<td>SWE-bench-java</td>
<td>91</td>
<td>Java</td>
<td>"SWE-bench-java: A GitHub Issue Resolving Benchmark for Java" [<a href="https://arxiv.org/abs/2408.14354" rel="nofollow">paper</a>] [<a href="https://github.com/multi-swe-bench/multi-swe-bench.github.io">data</a>]</td>
</tr>
<tr>
<td>2024-10</td>
<td>arXiv</td>
<td>Codev-Bench</td>
<td>296</td>
<td>Python</td>
<td>"Codev-Bench: How Do LLMs Understand Developer-Centric Code Completion?" [<a href="https://arxiv.org/abs/2410.01353" rel="nofollow">paper</a>] [<a href="https://github.com/LingmaTongyi/Codev-Bench">data</a>]</td>
</tr>
<tr>
<td>2024-10</td>
<td>ICLR 2025</td>
<td>SWE-bench M</td>
<td>617</td>
<td>JavaScript</td>
<td>"SWE-bench Multimodal: Do AI Systems Generalize to Visual Software Domains?" [<a href="https://arxiv.org/abs/2410.03859" rel="nofollow">paper</a>] [<a href="https://www.swebench.com/multimodal" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2024-10</td>
<td>arXiv</td>
<td>SWE-Bench+</td>
<td>548</td>
<td>Python</td>
<td>"SWE-Bench+: Enhanced Coding Benchmark for LLMs" [<a href="https://arxiv.org/abs/2410.06992" rel="nofollow">paper</a>] [<a href="https://zenodo.org/records/13879453" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2024-10</td>
<td>EMNLP 2024</td>
<td>DA-Code</td>
<td>500</td>
<td>Python, Bash, SQL</td>
<td>"DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models" [<a href="https://arxiv.org/abs/2410.07331" rel="nofollow">paper</a>] [<a href="https://github.com/yiyihum/da-code">data</a>]</td>
</tr>
<tr>
<td>2024-10</td>
<td>ACL 2025</td>
<td>RepoCod</td>
<td>980</td>
<td>Python</td>
<td>"Can Language Models Replace Programmers? REPOCOD Says 'Not Yet'" [<a href="https://arxiv.org/abs/2410.21647" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2024-10</td>
<td>ACL 2025</td>
<td>M2rc-Eval</td>
<td>5993 repos</td>
<td>18</td>
<td>"M2rc-Eval: Massively Multilingual Repository-level Code Completion Evaluation" [<a href="https://arxiv.org/abs/2410.21157" rel="nofollow">paper</a>] [<a href="https://github.com/M2RC-Eval-Team/M2RC-Eval">data</a>]</td>
</tr>
<tr>
<td>2024-11</td>
<td>arXiv</td>
<td>FAUN-Eval</td>
<td>300</td>
<td>Python, Java, JS, TS, Go</td>
<td>"A Real-World Benchmark for Evaluating Fine-Grained Issue Solving Capabilities of Large Language Models" [<a href="https://arxiv.org/abs/2411.18019" rel="nofollow">paper</a>] [<a href="https://anonymous.4open.science/status/FAUN-Eval" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2024-12</td>
<td>arXiv</td>
<td>Commit0</td>
<td>54</td>
<td>Python</td>
<td>"Commit0: Library Generation from Scratch" [<a href="https://arxiv.org/abs/2412.01769" rel="nofollow">paper</a>] [<a href="https://github.com/commit-0/commit0">data</a>]</td>
</tr>
<tr>
<td>2024-12</td>
<td>arXiv</td>
<td>ExecRepoBench</td>
<td>1.2K</td>
<td>Python</td>
<td>"ExecRepoBench: Multi-level Executable Code Completion Evaluation" [<a href="https://arxiv.org/abs/2412.11990" rel="nofollow">paper</a>] [<a href="https://github.com/QwenLM/Qwen2.5-Coder/tree/main/qwencoder-eval/instruct/CodeArena">data</a>]</td>
</tr>
<tr>
<td>2025-01</td>
<td>arXiv</td>
<td>DI-Bench</td>
<td>581</td>
<td>Python, C#, Rust, JS</td>
<td>"DI-BENCH: Benchmarking Large Language Models on Dependency Inference with Testable Repositories at Scale" [<a href="https://arxiv.org/abs/2501.13699" rel="nofollow">paper</a>] [<a href="https://github.com/Microsoft/DI-Bench">data</a>]</td>
</tr>
<tr>
<td>2025-02</td>
<td>arXiv</td>
<td>HackerRank-ASTRA</td>
<td>65</td>
<td>frontend</td>
<td>"HackerRank-ASTRA: Evaluating Correctness &amp; Consistency of Large Language Models on cross-domain multi-file project problems" [<a href="https://arxiv.org/abs/2502.00226" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/hackerrank/astra-benchmark" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2025-02</td>
<td>ICML 2025</td>
<td>SWE-Lancer</td>
<td>237</td>
<td>JS, TS</td>
<td>"SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?" [<a href="https://arxiv.org/abs/2502.12115" rel="nofollow">paper</a>] [<a href="https://github.com/openai/SWELancer-Benchmark">data</a>]</td>
</tr>
<tr>
<td>2025-03</td>
<td>ACL 2025</td>
<td>FEA-Bench</td>
<td>1401</td>
<td>Python</td>
<td>"FEA-Bench: A Benchmark for Evaluating Repository-Level Code Generation for Feature Implementation" [<a href="https://arxiv.org/abs/2503.06680" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-03</td>
<td>arXiv</td>
<td>DependEval</td>
<td>3.4K</td>
<td>8</td>
<td>"DependEval: Benchmarking LLMs for Repository Dependency Understanding" [<a href="https://arxiv.org/abs/2503.06689" rel="nofollow">paper</a>] [<a href="https://github.com/ink7-sudo/DependEval">data</a>]</td>
</tr>
<tr>
<td>2025-03</td>
<td>ACL 2025 Findings</td>
<td>ProjectEval</td>
<td>20</td>
<td>Python</td>
<td>"ProjectEval: A Benchmark for Programming Agents Automated Evaluation on Project-Level Code Generation" [<a href="https://arxiv.org/abs/2503.07010" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-03</td>
<td>arXiv</td>
<td>RepoST-Eval</td>
<td>296</td>
<td>Python</td>
<td>"RepoST: Scalable Repository-Level Coding Environment Construction with Sandbox Testing" [<a href="https://arxiv.org/abs/2503.07358" rel="nofollow">paper</a>] [<a href="https://github.com/yiqingxyq/RepoST">data</a>]</td>
</tr>
<tr>
<td>2025-04</td>
<td>arXiv</td>
<td>Multi-SWE-bench</td>
<td>1632</td>
<td>Java, JS, TS, Go, Rust, C, C++</td>
<td>"Multi-SWE-bench: A Multilingual Benchmark for Issue Resolving" [<a href="https://arxiv.org/abs/2504.02605" rel="nofollow">paper</a>] [<a href="https://github.com/multi-swe-bench/multi-swe-bench">data</a>]</td>
</tr>
<tr>
<td>2025-04</td>
<td>arXiv</td>
<td>SWE-PolyBench</td>
<td>2110</td>
<td>Java, JS, TS, Python</td>
<td>"SWE-PolyBench: A multi-language benchmark for repository level evaluation of coding agents" [<a href="https://arxiv.org/abs/2504.08703" rel="nofollow">paper</a>] [<a href="https://github.com/amazon-science/SWE-PolyBench">data</a>]</td>
</tr>
<tr>
<td>2025-04</td>
<td>arXiv</td>
<td>SecRepoBench</td>
<td>318</td>
<td>C/C++</td>
<td>"SecRepoBench: Benchmarking LLMs for Secure Code Generation in Real-World Repositories" [<a href="https://arxiv.org/abs/2504.21205" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-05</td>
<td>arXiv</td>
<td>OmniGIRL</td>
<td>959</td>
<td>Python, JS, TS, Java</td>
<td>"OmniGIRL: A Multilingual and Multimodal Benchmark for GitHub Issue Resolution" [<a href="https://arxiv.org/abs/2505.04606" rel="nofollow">paper</a>] [<a href="https://github.com/DeepSoftwareAnalytics/OmniGIRL">data</a>]</td>
</tr>
<tr>
<td>2025-05</td>
<td>arXiv</td>
<td>SWE-Dev</td>
<td>14500</td>
<td>Python</td>
<td>"SWE-Dev: Evaluating and Training Autonomous Feature-Driven Software Development" [<a href="https://arxiv.org/abs/2505.16975" rel="nofollow">paper</a>] [<a href="https://github.com/justLittleWhite/SWE-Dev">data</a>]</td>
</tr>
<tr>
<td>2025-05</td>
<td>arXiv</td>
<td>SWE-rebench</td>
<td>21,000</td>
<td>Python</td>
<td>"SWE-rebench: An Automated Pipeline for Task Collection and Decontaminated Evaluation of Software Engineering Agents" [<a href="https://arxiv.org/abs/2505.20411" rel="nofollow">paper</a>] [<a href="https://huggingface.co/datasets/nebius/SWE-rebench" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2025-05</td>
<td>arXiv</td>
<td>AgentIssue-Bench</td>
<td>50</td>
<td></td>
<td>"Can Agents Fix Agent Issues?" [<a href="https://arxiv.org/abs/2505.20749" rel="nofollow">paper</a>] [<a href="https://github.com/alfin06/AgentIssue-Bench">data</a>]</td>
</tr>
<tr>
<td>2025-05</td>
<td>arXiv</td>
<td>GitGoodBench</td>
<td>900</td>
<td></td>
<td>"GitGoodBench: A Novel Benchmark For Evaluating Agentic Performance On Git" [<a href="https://arxiv.org/abs/2505.22583" rel="nofollow">paper</a>] [<a href="https://github.com/JetBrains-Research/git-good-bench">data</a>]</td>
</tr>
<tr>
<td>2025-05</td>
<td>arXiv</td>
<td>SwingArena</td>
<td>400</td>
<td>Rust, Python, Go, C++</td>
<td>"SwingArena: Competitive Programming Arena for Long-context GitHub Issue Solving" [<a href="https://arxiv.org/abs/2505.23932" rel="nofollow">paper</a>] [<a href="https://swing-bench.github.io" rel="nofollow">data</a>]</td>
</tr>
<tr>
<td>2025-07</td>
<td>arXiv</td>
<td>CoreCodeBench</td>
<td>1545</td>
<td>Python</td>
<td>"CoreCodeBench: A Configurable Multi-Scenario Repository-Level Benchmark" [<a href="https://arxiv.org/abs/2507.05281" rel="nofollow">paper</a>] [<a href="https://github.com/AGI-Eval-Official/CoreCodeBench">data</a>]</td>
</tr>
<tr>
<td>2025-07</td>
<td>arXiv</td>
<td>LiveRepoReflection</td>
<td>1888</td>
<td>C++, Go, Java, JS, Python, Rust</td>
<td>"Turning the Tide: Repository-based Code Reflection" [<a href="https://arxiv.org/abs/2507.09866" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-07</td>
<td>arXiv</td>
<td>SWE-Perf</td>
<td>140</td>
<td>Python</td>
<td>"SWE-Perf: Can Language Models Optimize Code Performance on Real-World Repositories?" [2025-07] [<a href="https://arxiv.org/abs/2507.12415" rel="nofollow">paper</a>] [<a href="https://github.com/swe-perf/swe-perf">data</a>]</td>
</tr>
<tr>
<td>2025-09</td>
<td>arXiv</td>
<td>RepoDebug</td>
<td>30696</td>
<td>8</td>
<td>"RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models" [<a href="https://arxiv.org/abs/2509.04078" rel="nofollow">paper</a>]</td>
</tr>
<tr>
<td>2025-09</td>
<td>arXiv</td>
<td>SWE-Bench Pro</td>
<td>1865</td>
<td>Python, Go, JS, TS</td>
<td>"SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?" [<a href="https://arxiv.org/abs/2509.16941" rel="nofollow">paper</a>] [<a href="https://github.com/scaleapi/SWE-bench_Pro-os">data</a>]</td>
</tr>
<tr>
<td>2025-10</td>
<td>arXiv</td>
<td>E2EDev</td>
<td>46</td>
<td>Python</td>
<td>"E2Edev: Benchmarking Large Language Models in End-to-End Software Development Task" [<a href="https://arxiv.org/abs/2510.14509" rel="nofollow">paper</a>] [<a href="https://github.com/SCUNLP/E2EDev">data</a>]</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">*Line Completion/API Invocation Completion/Function Completion</p>
<p dir="auto"><math-renderer class="js-inline-math" style="display: inline-block" data-run-id="b3caf4e842e88b86948a693f78d2e24c">$^\dagger$</math-renderer> Retrieval/Completion/Pipeline</p>
<p dir="auto">** File count</p>
<p dir="auto"><math-renderer class="js-inline-math" style="display: inline-block" data-run-id="b3caf4e842e88b86948a693f78d2e24c">$^\ddagger$</math-renderer> Migration/Temporal Edit</p>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto">Other tasks are coming soon!</h4><a id="user-content-other-tasks-are-coming-soon" class="anchor" aria-label="Permalink: Other tasks are coming soon!" href="#other-tasks-are-coming-soon"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">9. Recommended Readings</h2><a id="user-content-9-recommended-readings" class="anchor" aria-label="Permalink: 9. Recommended Readings" href="#9-recommended-readings"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">30 papers as a primer on LLM.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th align="center">Date</th>
<th align="center">Keyword</th>
<th>Paper</th>
<th>TL;DR</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">2014-09</td>
<td align="center">Attention</td>
<td><a href="https://arxiv.org/abs/1409.0473" rel="nofollow">Neural Machine Translation by Jointly Learning to Align and Translate</a></td>
<td>The original attention, proposed for encoder-decoder RNN</td>
</tr>
<tr>
<td align="center">2015-08</td>
<td align="center">BPE</td>
<td><a href="https://arxiv.org/abs/1508.07909" rel="nofollow">Neural Machine Translation of Rare Words with Subword Units</a></td>
<td>Byte-pair encoding: split rare words into subword units</td>
</tr>
<tr>
<td align="center">2017-06</td>
<td align="center">Transformer</td>
<td><a href="https://arxiv.org/abs/1706.03762" rel="nofollow">Attention Is All You Need</a></td>
<td>Replace LSTM with self-attention for long-range dependency and parallel training</td>
</tr>
<tr>
<td align="center">2017-10</td>
<td align="center">Mixed Precision Training</td>
<td><a href="https://arxiv.org/abs/1710.03740" rel="nofollow">Mixed Precision Training</a></td>
<td>Store model weights in fp16 to save memory</td>
</tr>
<tr>
<td align="center">2018-04</td>
<td align="center">GLUE</td>
<td><a href="https://arxiv.org/abs/1804.07461" rel="nofollow">GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding</a></td>
<td>A language understanding benchmark</td>
</tr>
<tr>
<td align="center">2018-06</td>
<td align="center">GPT</td>
<td><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" rel="nofollow">Improving Language Understanding by Generative Pre-Training</a></td>
<td>Pretraining-finetuning paradigm applied to Transformer decoder</td>
</tr>
<tr>
<td align="center">2018-10</td>
<td align="center">BERT</td>
<td><a href="https://arxiv.org/abs/1810.04805" rel="nofollow">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></td>
<td>Masked Language Modeling (MLM) applied to Transformer encoder for pretraining</td>
</tr>
<tr>
<td align="center">2019-02</td>
<td align="center">GPT-2</td>
<td><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf" rel="nofollow">Language Models are Unsupervised Multitask Learners</a></td>
<td>GPT made larger (1.5B). They found language models implicitly learn about downstream tasks (such as translation) during pretraining.</td>
</tr>
<tr>
<td align="center">2019-05</td>
<td align="center">SuperGLUE</td>
<td><a href="https://arxiv.org/abs/1905.00537" rel="nofollow">SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems</a></td>
<td>Another language understanding benchmark</td>
</tr>
<tr>
<td align="center">2019-07</td>
<td align="center">RoBERTa</td>
<td><a href="https://arxiv.org/abs/1907.11692" rel="nofollow">RoBERTa: A Robustly Optimized BERT Pretraining Approach</a></td>
<td>An optimized BERT</td>
</tr>
<tr>
<td align="center">2019-09</td>
<td align="center">Megatron-LM</td>
<td><a href="https://arxiv.org/abs/1909.08053" rel="nofollow">Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</a></td>
<td>Model parallelism</td>
</tr>
<tr>
<td align="center">2019-10</td>
<td align="center">ZeRO</td>
<td><a href="https://arxiv.org/abs/1910.02054" rel="nofollow">ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</a></td>
<td>Memory-efficient distributed optimization</td>
</tr>
<tr>
<td align="center">2019-10</td>
<td align="center">T5</td>
<td><a href="https://arxiv.org/abs/1910.10683" rel="nofollow">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a></td>
<td>Transformer encoder-decoder pretrained with an MLM-like denoising objective</td>
</tr>
<tr>
<td align="center">2020-05</td>
<td align="center">GPT-3</td>
<td><a href="https://arxiv.org/abs/2005.14165" rel="nofollow">Language Models are Few-Shot Learners</a></td>
<td>By training an even larger version of GPT-2 (175B), they discovered a new learning paradigm: In-Context Learning (ICL)</td>
</tr>
<tr>
<td align="center">2020-09</td>
<td align="center">MMLU</td>
<td><a href="https://arxiv.org/abs/2009.03300" rel="nofollow">Measuring Massive Multitask Language Understanding</a></td>
<td>A world-knowledge and complex reasoning benchmark</td>
</tr>
<tr>
<td align="center">2020-12</td>
<td align="center">Pile</td>
<td><a href="https://arxiv.org/abs/2101.00027" rel="nofollow">The Pile: An 800GB Dataset of Diverse Text for Language Modeling</a></td>
<td>A diverse pretraining dataset</td>
</tr>
<tr>
<td align="center">2021-04</td>
<td align="center">RoPE</td>
<td><a href="https://arxiv.org/abs/2104.09864" rel="nofollow">RoFormer: Enhanced Transformer with Rotary Position Embedding</a></td>
<td>Rotary position embedding</td>
</tr>
<tr>
<td align="center">2021-06</td>
<td align="center">LoRA</td>
<td><a href="https://arxiv.org/abs/2106.09685" rel="nofollow">LoRA: Low-Rank Adaptation of Large Language Models</a></td>
<td>Memory-efficient finetuning</td>
</tr>
<tr>
<td align="center">2021-09</td>
<td align="center">FLAN</td>
<td><a href="https://arxiv.org/abs/2109.01652" rel="nofollow">Finetuned Language Models Are Zero-Shot Learners</a></td>
<td>Instruction-finetuning</td>
</tr>
<tr>
<td align="center">2021-10</td>
<td align="center">T0</td>
<td><a href="https://arxiv.org/abs/2110.08207" rel="nofollow">Multitask Prompted Training Enables Zero-Shot Task Generalization</a></td>
<td>Also instruction finetuning, but applied to the much smaller T5</td>
</tr>
<tr>
<td align="center">2021-12</td>
<td align="center">Gopher</td>
<td><a href="https://arxiv.org/abs/2112.11446" rel="nofollow">Scaling Language Models: Methods, Analysis &amp; Insights from Training Gopher</a></td>
<td>A 280B LLM with comprehensive experiments</td>
</tr>
<tr>
<td align="center">2022-01</td>
<td align="center">CoT</td>
<td><a href="https://arxiv.org/abs/2201.11903" rel="nofollow">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a></td>
<td>Chain-of-Though reasoning</td>
</tr>
<tr>
<td align="center">2022-03</td>
<td align="center">InstructGPT</td>
<td><a href="https://arxiv.org/abs/2203.02155" rel="nofollow">Training language models to follow instructions with human feedback</a></td>
<td>GPT-3 instruction finetuned with RLHF (reinforcement learning from human feedback)</td>
</tr>
<tr>
<td align="center">2022-03</td>
<td align="center">Chinchilla</td>
<td><a href="https://arxiv.org/abs/2203.15556" rel="nofollow">Training Compute-Optimal Large Language Models</a></td>
<td>A smaller (70B) version of Gopher that's pretrained on more data</td>
</tr>
<tr>
<td align="center">2022-04</td>
<td align="center">PaLM</td>
<td><a href="https://arxiv.org/abs/2204.02311" rel="nofollow">PaLM: Scaling Language Modeling with Pathways</a></td>
<td>The largest dense model ever (540B)</td>
</tr>
<tr>
<td align="center">2022-05</td>
<td align="center">0-shot CoT</td>
<td><a href="https://arxiv.org/abs/2205.11916" rel="nofollow">Large Language Models are Zero-Shot Reasoners</a></td>
<td>Tell LLMs to think step by step, and they can actually do it</td>
</tr>
<tr>
<td align="center">2022-06</td>
<td align="center">Emergent Ability</td>
<td><a href="https://arxiv.org/abs/2206.07682" rel="nofollow">Emergent Abilities of Large Language Models</a></td>
<td>A review on emergent abilities</td>
</tr>
<tr>
<td align="center">2022-10</td>
<td align="center">Flan</td>
<td><a href="https://arxiv.org/abs/2210.11416" rel="nofollow">Scaling Instruction-Finetuned Language Models</a></td>
<td>Consolidate all the existing instruction tuning datasets, and you get SOTA</td>
</tr>
<tr>
<td align="center">2022-11</td>
<td align="center">BLOOM</td>
<td><a href="https://arxiv.org/abs/2211.05100" rel="nofollow">BLOOM: A 176B-Parameter Open-Access Multilingual Language Model</a></td>
<td>The largest open-source dense LLM, trained on 46 languages, with detailed discussion about training and evaluation</td>
</tr>
<tr>
<td align="center">2022-12</td>
<td align="center">Self-Instruct</td>
<td><a href="https://arxiv.org/abs/2212.10560" rel="nofollow">Self-Instruct: Aligning Language Models with Self-Generated Instructions</a></td>
<td>Instruction tuning using LLM-generated data</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">This list aims to provide the essential background for understanding current LLM technologies, and thus excludes more recent models such as <a href="https://arxiv.org/abs/2302.13971" rel="nofollow">LLaMA</a>, <a href="https://arxiv.org/abs/2303.08774" rel="nofollow">GPT-4</a> or <a href="https://arxiv.org/abs/2305.10403" rel="nofollow">PaLM 2</a>. For comprehensive reviews on these more general topics, we refer to other sources such as <a href="https://github.com/Hannibal046/Awesome-LLM">Awesome-LLM</a>, <a href="https://github.com/luban-agi/Awesome-AIGC-Tutorials">Awesome AIGC Tutorials</a>, or for LLM applications in other specific domains: <a href="https://github.com/luban-agi/Awesome-Domain-LLM">Awesome Domain LLM</a>, <a href="https://github.com/luban-agi/Awesome-Tool-Learning#awesome-tool-learning">Awesome Tool Learning</a>, <a href="https://github.com/hsing-wang/Awesome-LLM-MT">Awesome-LLM-MT</a>, <a href="https://github.com/Geralt-Targaryen/Awesome-Education-LLM">Awesome Education LLM</a>.</p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">Citation</h2><a id="user-content-citation" class="anchor" aria-label="Permalink: Citation" href="#citation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">If you find this repo or our survey helpful, please consider citing us:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="@article{zhang2024unifying,
   title={Unifying the Perspectives of {NLP} and Software Engineering: A Survey on Language Models for Code},
   author={Ziyin Zhang and Chaoyu Chen and Bingchang Liu and Cong Liao and Zi Gong and Hang Yu and Jianguo Li and Rui Wang},
   journal={Transactions on Machine Learning Research},
   issn={2835-8856},
   year={2024},
   url={https://openreview.net/forum?id=hkNnGqZnpa},
   note={}
}"><pre class="notranslate"><code>@article{zhang2024unifying,
   title={Unifying the Perspectives of {NLP} and Software Engineering: A Survey on Language Models for Code},
   author={Ziyin Zhang and Chaoyu Chen and Bingchang Liu and Cong Liao and Zi Gong and Hang Yu and Jianguo Li and Rui Wang},
   journal={Transactions on Machine Learning Research},
   issn={2835-8856},
   year={2024},
   url={https://openreview.net/forum?id=hkNnGqZnpa},
   note={}
}
</code></pre></div>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">Star History</h2><a id="user-content-star-history" class="anchor" aria-label="Permalink: Star History" href="#star-history"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a href="https://star-history.com/#codefuse-ai/Awesome-Code-LLM&amp;Date" rel="nofollow"><img src="https://camo.githubusercontent.com/e6e364feee12fd4826ece726e7b236c1a982fe800d39d60fe0e95c228b737b48/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d636f6465667573652d61692f417765736f6d652d436f64652d4c4c4d26747970653d44617465" alt="Star History Chart" data-canonical-src="https://api.star-history.com/svg?repos=codefuse-ai/Awesome-Code-LLM&amp;type=Date" style="max-width: 100%;"></a></p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">Join US</h2><a id="user-content-join-us" class="anchor" aria-label="Permalink: Join US" href="#join-us"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Recruitment</h3><a id="user-content-recruitment" class="anchor" aria-label="Permalink: Recruitment" href="#recruitment"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<details>
<summary>English version</summary>
We are the AI Native team within the Platform Technology Business Group at Ant Group, dedicated to the intelligentization of Ant Group's platform engineering. Established for over three years, our team has played a pivotal role in supporting the intelligent operation and maintenance of Ant Group's cloud computing infrastructure. Our mission is to build algorithm services and platforms with a wide user base through world-class technological innovation and impact, supporting the implementation of internal and external products and businesses.
Embracing an innovation-driven ethos, our team not only supports business implementation but also propels technological influence. Over the past three years, we have published more than 20 papers at top conferences like ICLR, NeurIPS, KDD, and ACL. Our innovative business outcomes have earned us two Ant Technology's highest T-Star awards and one SuperMA award from Ant Group. Our open-source project CodeFuse has received 4K stars as of February 2024, and our models have been downloaded over 1.5 million times on Huggingface and Modelscope.
<p dir="auto"><strong>We are on the lookout for top talents to join our vibrant team! If you're eager to develop your career in an environment filled with energy, innovation, and a culture of excellence, we welcome you to explore our career opportunities for both campus and experienced hires. Join us and be a part of creating the next milestone in the industry.</strong></p>
<p dir="auto"><strong>Campus Recruitment</strong>: <a href="https://hrrecommend.antgroup.com/guide.html?code=8uoP5mlus5DqQYbE_EnqcE2FD5JZH21MwvMUIb9mb6X3osXPuBraG54SyM8GLn_7" rel="nofollow">https://hrrecommend.antgroup.com/guide.html?code=8uoP5mlus5DqQYbE_EnqcE2FD5JZH21MwvMUIb9mb6X3osXPuBraG54SyM8GLn_7</a></p>
<p dir="auto"><strong>Experienced Hires</strong>: <a href="https://talent.antgroup.com/off-campus-position?positionId=1933830" rel="nofollow">https://talent.antgroup.com/off-campus-position?positionId=1933830</a></p>
</details>
<details>
<summary></summary>
 AI Native  3  Mission 3  ICLRNeurIPSKDDACL  20  T-Star1  SuperMA CodeFuse  4K (2024  2 )Huggingface  modelscope  150 
<p dir="auto"><strong>&amp;</strong></p>
<p dir="auto"><strong></strong><a href="https://hrrecommend.antgroup.com/guide.html?code=8uoP5mlus5DqQYbE_EnqcE2FD5JZH21MwvMUIb9mb6X3osXPuBraG54SyM8GLn_7" rel="nofollow">https://hrrecommend.antgroup.com/guide.html?code=8uoP5mlus5DqQYbE_EnqcE2FD5JZH21MwvMUIb9mb6X3osXPuBraG54SyM8GLn_7</a></p>
<p dir="auto"><strong></strong><a href="https://talent.antgroup.com/off-campus-position?positionId=1933830" rel="nofollow">https://talent.antgroup.com/off-campus-position?positionId=1933830</a></p>
</details>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto">Contact Us (WeChat)</h3><a id="user-content-contact-us-wechat" class="anchor" aria-label="Permalink: Contact Us (WeChat)" href="#contact-us-wechat"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"></p>
<p align="center" dir="auto">
<a target="_blank" rel="noopener noreferrer" href="/codefuse-ai/Awesome-Code-LLM/blob/main/imgs/wechat.PNG"><img src="/codefuse-ai/Awesome-Code-LLM/raw/main/imgs/wechat.PNG" style="width: 40%; max-width: 100%;"></a>
</p>
</article></div></div></div></div></div> <!-- --> <!-- --> <script type="application/json" id="__PRIMER_DATA_:R0:__">{"resolvedServerColorMode":"day"}</script></div>
</react-partial>


      <input type="hidden" data-csrf="true" value="EeotUZboTx8T/ieTGIpjJWlNdc/jr+jJ2/UzpvyD6C7+vR1vMlo7wRzQHeqZ5OSk6IEa1qmaF0fwYFKZJGQIOg==" />
</div>
  <div data-view-component="true" class="Layout-sidebar">      

      <div class="BorderGrid about-margin" data-pjax>
        <div class="BorderGrid-row">
          <div class="BorderGrid-cell">
            <div class="hide-sm hide-md">
  <h2 class="mb-3 h4">About</h2>

      <p class="f4 my-3">
        [TMLR] A curated list of language modeling researches for code (and other software engineering activities), plus related datasets.
      </p>
      <div class="my-3 d-flex flex-items-center">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-link flex-shrink-0 mr-2">
    <path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path>
</svg>
        <span class="flex-auto min-width-0 css-truncate css-truncate-target width-fit">
          <a title="https://arxiv.org/abs/2311.07989" role="link" target="_blank" rel="noopener noreferrer nofollow" class="text-bold" href="https://arxiv.org/abs/2311.07989">arxiv.org/abs/2311.07989</a>
        </span>
      </div>

    <h3 class="sr-only">Topics</h3>
    <div class="my-3">
        <div class="f6">
      <a href="/topics/nlp" title="Topic: nlp" data-view-component="true" class="topic-tag topic-tag-link">
  nlp
</a>
      <a href="/topics/awesome" title="Topic: awesome" data-view-component="true" class="topic-tag topic-tag-link">
  awesome
</a>
      <a href="/topics/ai" title="Topic: ai" data-view-component="true" class="topic-tag topic-tag-link">
  ai
</a>
      <a href="/topics/survey" title="Topic: survey" data-view-component="true" class="topic-tag topic-tag-link">
  survey
</a>
      <a href="/topics/software-engineering" title="Topic: software-engineering" data-view-component="true" class="topic-tag topic-tag-link">
  software-engineering
</a>
      <a href="/topics/papers" title="Topic: papers" data-view-component="true" class="topic-tag topic-tag-link">
  papers
</a>
      <a href="/topics/datasets" title="Topic: datasets" data-view-component="true" class="topic-tag topic-tag-link">
  datasets
</a>
      <a href="/topics/llm" title="Topic: llm" data-view-component="true" class="topic-tag topic-tag-link">
  llm
</a>
      <a href="/topics/tmlr" title="Topic: tmlr" data-view-component="true" class="topic-tag topic-tag-link">
  tmlr
</a>
  </div>

    </div>

    <h3 class="sr-only">Resources</h3>
    <div class="mt-2">
      <a class="Link--muted" data-analytics-event="{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:readme&quot;}" href="#readme-ov-file">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-book mr-2">
    <path d="M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z"></path>
</svg>
        Readme
</a>    </div>

  





  <include-fragment src="/codefuse-ai/Awesome-Code-LLM/hovercards/citation/sidebar_partial?tree_name=main" data-nonce="v2:6be41ebd-a31d-c9f7-f234-9eba816399f5" data-view-component="true">
  

  <div data-show-on-forbidden-error hidden>
    <div class="Box">
  <div class="blankslate-container">
    <div data-view-component="true" class="blankslate blankslate-spacious color-bg-default rounded-2">
      

      <h3 data-view-component="true" class="blankslate-heading">        Uh oh!
</h3>
      <p data-view-component="true">        <p class="color-fg-muted my-2 mb-2 ws-normal">There was an error while loading. <a class="Link--inTextBlock" data-turbo="false" href="" aria-label="Please reload this page">Please reload this page</a>.</p>
</p>

</div>  </div>
</div>  </div>
</include-fragment>
  <div class="mt-2">
    <a href="/codefuse-ai/Awesome-Code-LLM/activity" data-view-component="true" class="Link Link--muted"><svg text="gray" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-pulse mr-2">
    <path d="M6 2c.306 0 .582.187.696.471L10 10.731l1.304-3.26A.751.751 0 0 1 12 7h3.25a.75.75 0 0 1 0 1.5h-2.742l-1.812 4.528a.751.751 0 0 1-1.392 0L6 4.77 4.696 8.03A.75.75 0 0 1 4 8.5H.75a.75.75 0 0 1 0-1.5h2.742l1.812-4.529A.751.751 0 0 1 6 2Z"></path>
</svg>
      <span class="color-fg-muted">Activity</span></a>  </div>

    <div class="mt-2">
      <a href="/codefuse-ai/Awesome-Code-LLM/custom-properties" data-view-component="true" class="Link Link--muted"><svg text="gray" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-note mr-2">
    <path d="M0 3.75C0 2.784.784 2 1.75 2h12.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 14H1.75A1.75 1.75 0 0 1 0 12.25Zm1.75-.25a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-8.5a.25.25 0 0 0-.25-.25ZM3.5 6.25a.75.75 0 0 1 .75-.75h7a.75.75 0 0 1 0 1.5h-7a.75.75 0 0 1-.75-.75Zm.75 2.25h4a.75.75 0 0 1 0 1.5h-4a.75.75 0 0 1 0-1.5Z"></path>
</svg>
        <span class="color-fg-muted">Custom properties</span></a>    </div>

  <h3 class="sr-only">Stars</h3>
  <div class="mt-2">
    <a href="/codefuse-ai/Awesome-Code-LLM/stargazers" data-view-component="true" class="Link Link--muted"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-star mr-2">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
      <strong>3k</strong>
      stars</a>  </div>

  <h3 class="sr-only">Watchers</h3>
  <div class="mt-2">
    <a href="/codefuse-ai/Awesome-Code-LLM/watchers" data-view-component="true" class="Link Link--muted"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-eye mr-2">
    <path d="M8 2c1.981 0 3.671.992 4.933 2.078 1.27 1.091 2.187 2.345 2.637 3.023a1.62 1.62 0 0 1 0 1.798c-.45.678-1.367 1.932-2.637 3.023C11.67 13.008 9.981 14 8 14c-1.981 0-3.671-.992-4.933-2.078C1.797 10.83.88 9.576.43 8.898a1.62 1.62 0 0 1 0-1.798c.45-.677 1.367-1.931 2.637-3.022C4.33 2.992 6.019 2 8 2ZM1.679 7.932a.12.12 0 0 0 0 .136c.411.622 1.241 1.75 2.366 2.717C5.176 11.758 6.527 12.5 8 12.5c1.473 0 2.825-.742 3.955-1.715 1.124-.967 1.954-2.096 2.366-2.717a.12.12 0 0 0 0-.136c-.412-.621-1.242-1.75-2.366-2.717C10.824 4.242 9.473 3.5 8 3.5c-1.473 0-2.825.742-3.955 1.715-1.124.967-1.954 2.096-2.366 2.717ZM8 10a2 2 0 1 1-.001-3.999A2 2 0 0 1 8 10Z"></path>
</svg>
      <strong>88</strong>
      watching</a>  </div>

  <h3 class="sr-only">Forks</h3>
  <div class="mt-2">
    <a href="/codefuse-ai/Awesome-Code-LLM/forks" data-view-component="true" class="Link Link--muted"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo-forked mr-2">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>
      <strong>193</strong>
      forks</a>  </div>


    <div class="mt-2">
      <a class="Link--muted" href="/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fcodefuse-ai%2FAwesome-Code-LLM&amp;report=codefuse-ai+%28user%29">
          Report repository
</a>    </div>
</div>

          </div>
        </div>

        
        
        
        
            <div class="BorderGrid-row" hidden>
              <div class="BorderGrid-cell">
                <include-fragment src="/codefuse-ai/Awesome-Code-LLM/used_by_list" accept="text/fragment+html" data-nonce="v2:6be41ebd-a31d-c9f7-f234-9eba816399f5" data-view-component="true">
  

  <div data-show-on-forbidden-error hidden>
    <div class="Box">
  <div class="blankslate-container">
    <div data-view-component="true" class="blankslate blankslate-spacious color-bg-default rounded-2">
      

      <h3 data-view-component="true" class="blankslate-heading">        Uh oh!
</h3>
      <p data-view-component="true">        <p class="color-fg-muted my-2 mb-2 ws-normal">There was an error while loading. <a class="Link--inTextBlock" data-turbo="false" href="" aria-label="Please reload this page">Please reload this page</a>.</p>
</p>

</div>  </div>
</div>  </div>
</include-fragment>
              </div>
            </div>

        
            <div class="BorderGrid-row">
              <div class="BorderGrid-cell">
                <h2 class="h4 mb-3">
  <a href="/codefuse-ai/Awesome-Code-LLM/graphs/contributors" data-view-component="true" class="Link--primary no-underline Link d-flex flex-items-center">Contributors
      <span title="11" data-view-component="true" class="Counter ml-1">11</span></a></h2>


    
  <ul class="list-style-none d-flex flex-wrap mb-n2">
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/Geralt-Targaryen"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/Geralt-Targaryen/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/94539084?s=64&amp;v=4" alt="@Geralt-Targaryen" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/ss41979310"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/ss41979310/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/103973989?s=64&amp;v=4" alt="@ss41979310" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/lib-evolution-eval"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/lib-evolution-eval/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/171602383?s=64&amp;v=4" alt="@lib-evolution-eval" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/cyk1337"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/cyk1337/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/13767887?s=64&amp;v=4" alt="@cyk1337" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/twelveand0"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/twelveand0/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/17273471?s=64&amp;v=4" alt="@twelveand0" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/TyDunn"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/TyDunn/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/13314504?s=64&amp;v=4" alt="@TyDunn" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/vinzid"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/vinzid/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/18076739?s=64&amp;v=4" alt="@vinzid" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/zqb-all"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/zqb-all/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/21177884?s=64&amp;v=4" alt="@zqb-all" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/tangxiangru"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/tangxiangru/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/22478336?s=64&amp;v=4" alt="@tangxiangru" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/eltociear"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/eltociear/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/22633385?s=64&amp;v=4" alt="@eltociear" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
    <li class="mb-2 mr-2"
        >
      <a href="https://github.com/lightislost"
          class=""
            data-hovercard-type="user" data-hovercard-url="/users/lightislost/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self"
          
        >
        <img src="https://avatars.githubusercontent.com/u/31849436?s=64&amp;v=4" alt="@lightislost" size="32" height="32" width="32" data-view-component="true" class="avatar circle" />
      </a>
    </li>
</ul>





              </div>
            </div>

        
        
              </div>
</div>
  
</div></div>

  </div>


  </div>

</turbo-frame>


    </main>
  </div>

  </div>

          <footer class="footer pt-8 pb-6 f6 color-fg-muted p-responsive" role="contentinfo" >
  <h2 class='sr-only'>Footer</h2>

  


  <div class="d-flex flex-justify-center flex-items-center flex-column-reverse flex-lg-row flex-wrap flex-lg-nowrap">
    <div class="d-flex flex-items-center flex-shrink-0 mx-2">
      <a aria-label="GitHub Homepage" class="footer-octicon mr-2" href="https://github.com">
        <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-mark-github">
    <path d="M12 1C5.923 1 1 5.923 1 12c0 4.867 3.149 8.979 7.521 10.436.55.096.756-.233.756-.522 0-.262-.013-1.128-.013-2.049-2.764.509-3.479-.674-3.699-1.292-.124-.317-.66-1.293-1.127-1.554-.385-.207-.936-.715-.014-.729.866-.014 1.485.797 1.691 1.128.99 1.663 2.571 1.196 3.204.907.096-.715.385-1.196.701-1.471-2.448-.275-5.005-1.224-5.005-5.432 0-1.196.426-2.186 1.128-2.956-.111-.275-.496-1.402.11-2.915 0 0 .921-.288 3.024 1.128a10.193 10.193 0 0 1 2.75-.371c.936 0 1.871.123 2.75.371 2.104-1.43 3.025-1.128 3.025-1.128.605 1.513.221 2.64.111 2.915.701.77 1.127 1.747 1.127 2.956 0 4.222-2.571 5.157-5.019 5.432.399.344.743 1.004.743 2.035 0 1.471-.014 2.654-.014 3.025 0 .289.206.632.756.522C19.851 20.979 23 16.854 23 12c0-6.077-4.922-11-11-11Z"></path>
</svg>
</a>
      <span>
        &copy; 2025 GitHub,&nbsp;Inc.
      </span>
    </div>

    <nav aria-label="Footer">
      <h3 class="sr-only" id="sr-footer-heading">Footer navigation</h3>

      <ul class="list-style-none d-flex flex-justify-center flex-wrap mb-2 mb-lg-0" aria-labelledby="sr-footer-heading">

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to Terms&quot;,&quot;label&quot;:&quot;text:terms&quot;}" href="https://docs.github.com/site-policy/github-terms/github-terms-of-service" data-view-component="true" class="Link--secondary Link">Terms</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to privacy&quot;,&quot;label&quot;:&quot;text:privacy&quot;}" href="https://docs.github.com/site-policy/privacy-policies/github-privacy-statement" data-view-component="true" class="Link--secondary Link">Privacy</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to security&quot;,&quot;label&quot;:&quot;text:security&quot;}" href="https://github.com/security" data-view-component="true" class="Link--secondary Link">Security</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to status&quot;,&quot;label&quot;:&quot;text:status&quot;}" href="https://www.githubstatus.com/" data-view-component="true" class="Link--secondary Link">Status</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to community&quot;,&quot;label&quot;:&quot;text:community&quot;}" href="https://github.community/" data-view-component="true" class="Link--secondary Link">Community</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to docs&quot;,&quot;label&quot;:&quot;text:docs&quot;}" href="https://docs.github.com/" data-view-component="true" class="Link--secondary Link">Docs</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to contact&quot;,&quot;label&quot;:&quot;text:contact&quot;}" href="https://support.github.com?tags=dotcom-footer" data-view-component="true" class="Link--secondary Link">Contact</a>
          </li>

          <li class="mx-2" >
  <cookie-consent-link>
    <button
      type="button"
      class="Link--secondary underline-on-hover border-0 p-0 color-bg-transparent"
      data-action="click:cookie-consent-link#showConsentManagement"
      data-analytics-event="{&quot;location&quot;:&quot;footer&quot;,&quot;action&quot;:&quot;cookies&quot;,&quot;context&quot;:&quot;subfooter&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;cookies_link_subfooter_footer&quot;}"
    >
       Manage cookies
    </button>
  </cookie-consent-link>
</li>

<li class="mx-2">
  <cookie-consent-link>
    <button
      type="button"
      class="Link--secondary underline-on-hover border-0 p-0 color-bg-transparent text-left"
      data-action="click:cookie-consent-link#showConsentManagement"
      data-analytics-event="{&quot;location&quot;:&quot;footer&quot;,&quot;action&quot;:&quot;dont_share_info&quot;,&quot;context&quot;:&quot;subfooter&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;dont_share_info_link_subfooter_footer&quot;}"
    >
      Do not share my personal information
    </button>
  </cookie-consent-link>
</li>

      </ul>
    </nav>
  </div>
</footer>



    <ghcc-consent id="ghcc" class="position-fixed bottom-0 left-0" style="z-index: 999999"
      data-locale="en"
      data-initial-cookie-consent-allowed=""
      data-cookie-consent-required="false"
    ></ghcc-consent>




  <div id="ajax-error-message" class="ajax-error-message flash flash-error" hidden>
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
    <button type="button" class="flash-close js-ajax-error-dismiss" aria-label="Dismiss error">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
    </button>
    You cant perform that action at this time.
  </div>

    <template id="site-details-dialog">
  <details class="details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm" open>
    <summary role="button" aria-label="Close dialog"></summary>
    <details-dialog class="Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal">
      <button class="Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0" type="button" aria-label="Close dialog" data-close-dialog>
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
      </button>
      <div class="octocat-spinner my-6 js-details-dialog-spinner"></div>
    </details-dialog>
  </details>
</template>

    <div class="Popover js-hovercard-content position-absolute" style="display: none; outline: none;">
  <div class="Popover-message Popover-message--bottom-left Popover-message--large Box color-shadow-large" style="width:360px;">
  </div>
</div>

    <template id="snippet-clipboard-copy-button">
  <div class="zeroclipboard-container position-absolute right-0 top-0">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn js-clipboard-copy m-2 p-0" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon m-2">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>
<template id="snippet-clipboard-copy-button-unpositioned">
  <div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>




    </div>
    <div id="js-global-screen-reader-notice" class="sr-only mt-n1" aria-live="polite" aria-atomic="true" ></div>
    <div id="js-global-screen-reader-notice-assertive" class="sr-only mt-n1" aria-live="assertive" aria-atomic="true"></div>
  </body>
</html>

